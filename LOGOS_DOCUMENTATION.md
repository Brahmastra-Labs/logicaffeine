
## Grammar Rules

### Sentence Patterns

| Pattern | Example | Logic |
|---------|---------|-------|
| Universal | "All cats are mammals" | ∀x(Cat(x) → Mammal(x)) |
| Existential | "Some dogs bark" | ∃x(Dog(x) ∧ Bark(x)) |
| Generic | "Birds fly" | Gen x(Bird(x) → Fly(x)) |
| Imperative | "Let x be 5." | let x = 5; |
| Conditional | "If x > 0: Return x." | if x > 0 { return x; } |
| Network | "Send msg to peer." | peer.send(msg).await; |
| Concurrency | "Launch a task to fn." | tokio::spawn(fn()); |

### Quantifier Kinds

| Kind | Trigger | Symbol | Semantics |
|------|---------|--------|-----------|
| Universal | "all", "every", "each" | ∀ | True for every individual |
| Existential | "some", "a", "an" | ∃ | True for at least one |
| Generic | Bare plural ("birds") | Gen | Law-like/characteristic |
| Negative | "no", "none" | ¬∃ | True for none |

### Imperative Statements

| Statement | Syntax | Semantics |
|-----------|--------|-----------|
| Let | `Let [mut] x [: Type] be expr.` | Variable declaration |
| Set | `Set x to expr.` | Mutation |
| If | `If condition: ... Otherwise: ...` | Control flow |
| While | `While condition: ...` | Loop |
| Call | `Call f with x.` | Function invocation |
| Check | `Check that P.` | Mandatory security assertion |
| Assert | `Assert that P.` | Debug assertion |
| Give | `Give x to f.` | Ownership move |
| Show | `Show x to f.` | Immutable borrow |

## Statistics

### By Compiler Stage
```
Lexer (token.rs, lexer.rs):           2495 lines
Parser (ast/, parser/):               15776 lines
Transpilation:                        1528 lines
Code Generation:                      2904 lines
Semantics (lambda, context, view):    2658 lines
Type Analysis (analysis/):            2841 lines
Support Infrastructure:               4791 lines
Desktop UI:                              18854 lines
CRDT (logos_core/src/crdt/):          1854 lines
Network (logos_core/src/network/):    1596 lines
VFS (logos_core/src/fs/):             511 lines
Entry Point:                                16 lines
```

### Totals
```
Source lines:        62234
Test lines:          27960
Total Rust lines: 90194
```

## Lexicon Data

The lexicon defines all vocabulary entries that drive the lexer and parser behavior.
{
  "keywords": {
    "all": "All",
    "every": "All",
    "no": "No",
    "some": "Some",
    "any": "Any",
    "both": "Both",
    "most": "Most",
    "few": "Few",
    "many": "Many",
    "and": "And",
    "but": "And",
    "or": "Or",
    "if": "If",
    "then": "Then",
    "not": "Not",
    "is": "Is",
    "are": "Are",
    "was": "Was",
    "were": "Were",
    "that": "That",
    "who": "Who",
    "whom": "Who",
    "what": "What",
    "where": "Where",
    "when": "When",
    "why": "Why",
    "does": "Does",
    "do": "Do",
    "must": "Must",
    "shall": "Shall",
    "should": "Should",
    "can": "Can",
    "may": "May",
    "cannot": "Cannot",
    "would": "Would",
    "could": "Could",
    "might": "Might",
    "had": "Had",
    "than": "Than",
    "itself": "Reflexive",
    "himself": "Reflexive",
    "herself": "Reflexive",
    "themselves": "Reflexive",
    "because": "Because",
    "anything": "Anything",
    "anyone": "Anyone",
    "anybody": "Anyone",
    "nothing": "Nothing",
    "nobody": "Nobody",
    "nowhere": "Nowhere",
    "ever": "Ever",
    "never": "Never",
    "repeat": "Repeat",
    "for": "For",
    "from": "From",
    "trust": "Trust",
    "respectively": "Respectively",
    "decrease": "Decrease",
    "tally": "Tally",
    "sharedset": "SharedSet",
    "sharedsequence": "SharedSequence",
    "sharedmap": "SharedMap",
    "divergent": "Divergent",
    "append": "Append",
    "resolve": "Resolve",
    "removewins": "RemoveWins",
    "addwins": "AddWins",
    "yata": "YATA",
    "values": "Values"
  },
  "pronouns": [
    { "word": "i", "gender": "Unknown", "number": "Singular", "case": "Subject" },
    { "word": "he", "gender": "Male", "number": "Singular", "case": "Subject" },
    { "word": "she", "gender": "Female", "number": "Singular", "case": "Subject" },
    { "word": "it", "gender": "Neuter", "number": "Singular", "case": "Subject" },
    { "word": "they", "gender": "Unknown", "number": "Plural", "case": "Subject" },
    { "word": "you", "gender": "Unknown", "number": "Singular", "case": "Subject" },
    { "word": "him", "gender": "Male", "number": "Singular", "case": "Object" },
    { "word": "her", "gender": "Female", "number": "Singular", "case": "Object" },
    { "word": "her", "gender": "Female", "number": "Singular", "case": "Possessive" },
    { "word": "his", "gender": "Male", "number": "Singular", "case": "Possessive" },
    { "word": "its", "gender": "Neuter", "number": "Singular", "case": "Possessive" },
    { "word": "my", "gender": "Unknown", "number": "Singular", "case": "Possessive" },
    { "word": "their", "gender": "Unknown", "number": "Plural", "case": "Possessive" },
    { "word": "them", "gender": "Unknown", "number": "Plural", "case": "Object" }
  ],
  "articles": {
    "the": "Definite",
    "a": "Indefinite",
    "an": "Indefinite",
    "this": "Proximal",
    "these": "Proximal",
    "those": "Distal"
  },
  "auxiliaries": {
    "will": "Future",
    "did": "Past"
  },
  "presupposition_triggers": {
    "stop": "Stop",
    "start": "Start",
    "begin": "Start",
    "regret": "Regret",
    "continue": "Continue",
    "realize": "Realize",
    "realise": "Realize",
    "know": "Know"
  },
  "number_words": {
    "one": 1, "two": 2, "three": 3, "four": 4, "five": 5,
    "six": 6, "seven": 7, "eight": 8, "nine": 9, "ten": 10
  },
  "verbs": [
    { "lemma": "Be", "class": "State", "forms": { "past": "was", "participle": "been", "gerund": "being" } },
    { "lemma": "Have", "class": "State", "forms": { "present3s": "has", "past": "had", "participle": "had", "gerund": "having" }, "synonyms": ["possess", "own", "hold"], "antonyms": ["lack", "miss"] },
    { "lemma": "Run", "class": "Activity", "forms": { "past": "ran", "gerund": "running" } },
    { "lemma": "See", "class": "State", "forms": { "past": "saw", "participle": "seen", "gerund": "seeing" } },
    { "lemma": "Give", "class": "Achievement", "forms": { "past": "gave", "participle": "given", "gerund": "giving" }, "features": ["Ditransitive"] },
    { "lemma": "Take", "class": "Achievement", "forms": { "past": "took", "participle": "taken", "gerund": "taking" } },
    { "lemma": "Go", "class": "Activity", "forms": { "past": "went", "participle": "gone", "gerund": "going" } },
    { "lemma": "Come", "class": "Achievement", "forms": { "past": "came", "participle": "come", "gerund": "coming" } },
    { "lemma": "Make", "class": "Accomplishment", "forms": { "past": "made", "gerund": "making" } },
    { "lemma": "Say", "class": "Activity", "forms": { "past": "said", "gerund": "saying" } },
    { "lemma": "Know", "class": "State", "forms": { "past": "knew", "participle": "known", "gerund": "knowing" }, "features": ["Opaque", "Factive"] },
    { "lemma": "Wonder", "class": "State", "forms": { "past": "wondered", "gerund": "wondering" }, "features": ["Opaque"] },
    { "lemma": "Think", "class": "State", "forms": { "past": "thought", "gerund": "thinking" }, "features": ["Opaque"] },
    { "lemma": "Tell", "class": "Activity", "forms": { "past": "told", "gerund": "telling" }, "features": ["Ditransitive", "ObjectControl"] },
    { "lemma": "Find", "class": "Achievement", "forms": { "past": "found", "gerund": "finding" } },
    { "lemma": "Put", "class": "Achievement", "forms": { "past": "put", "gerund": "putting" } },
    { "lemma": "Leave", "class": "Achievement", "forms": { "past": "left", "gerund": "leaving" } },
    { "lemma": "Bring", "class": "Activity", "forms": { "past": "brought", "gerund": "bringing" }, "features": ["Ditransitive"] },
    { "lemma": "Send", "class": "Achievement", "forms": { "past": "sent", "gerund": "sending" }, "features": ["Ditransitive"] },
    { "lemma": "Build", "class": "Accomplishment", "forms": { "past": "built", "gerund": "building" } },
    { "lemma": "Speak", "class": "Activity", "forms": { "past": "spoke", "participle": "spoken", "gerund": "speaking" } },
    { "lemma": "Write", "class": "Accomplishment", "forms": { "past": "wrote", "participle": "written", "gerund": "writing" } },
    { "lemma": "Hold", "class": "Activity", "forms": { "past": "held", "gerund": "holding" } },
    { "lemma": "Meet", "class": "Achievement", "forms": { "past": "met", "gerund": "meeting" }, "features": ["Collective"] },
    { "lemma": "Read", "class": "Activity", "forms": { "past": "read", "gerund": "reading" } },
    { "lemma": "Keep", "class": "State", "forms": { "past": "kept", "gerund": "keeping" } },
    { "lemma": "Set", "class": "Achievement", "forms": { "past": "set", "gerund": "setting" } },
    { "lemma": "Hear", "class": "State", "forms": { "past": "heard", "gerund": "hearing" } },
    { "lemma": "Mean", "class": "State", "forms": { "past": "meant", "gerund": "meaning" } },
    { "lemma": "Show", "class": "Achievement", "forms": { "past": "shown", "gerund": "showing" }, "features": ["Ditransitive"] },
    { "lemma": "Eat", "class": "Activity", "forms": { "past": "ate", "participle": "eaten", "gerund": "eating" } },
    { "lemma": "Sleep", "class": "Activity", "forms": { "past": "slept", "gerund": "sleeping" } },
    { "lemma": "Drink", "class": "Activity", "forms": { "past": "drank", "participle": "drunk", "gerund": "drinking" } },
    { "lemma": "Die", "class": "Achievement", "forms": { "past": "died", "gerund": "dying" } },
    { "lemma": "Grow", "class": "Accomplishment", "forms": { "past": "grew", "participle": "grown", "gerund": "growing" } },
    { "lemma": "Blow", "class": "Activity", "forms": { "past": "blew", "participle": "blown", "gerund": "blowing" } },
    { "lemma": "Throw", "class": "Activity", "forms": { "past": "threw", "participle": "thrown", "gerund": "throwing" } },
    { "lemma": "Shoot", "class": "Activity", "forms": { "past": "shot", "participle": "shot", "gerund": "shooting" } },
    { "lemma": "Draw", "class": "Accomplishment", "forms": { "past": "drew", "participle": "drawn", "gerund": "drawing" } },
    { "lemma": "Drive", "class": "Activity", "forms": { "past": "drove", "participle": "driven", "gerund": "driving" } },
    { "lemma": "Fight", "class": "Activity", "forms": { "past": "fought", "gerund": "fighting" } },
    { "lemma": "Hide", "class": "Achievement", "forms": { "past": "hid", "participle": "hidden", "gerund": "hiding" } },
    { "lemma": "Ride", "class": "Activity", "forms": { "past": "rode", "participle": "ridden", "gerund": "riding" } },
    { "lemma": "Rise", "class": "Achievement", "forms": { "past": "rose", "participle": "risen", "gerund": "rising" } },
    { "lemma": "Shake", "class": "Activity", "forms": { "past": "shook", "participle": "shaken", "gerund": "shaking" } },
    { "lemma": "Steal", "class": "Achievement", "forms": { "past": "stole", "participle": "stolen", "gerund": "stealing" } },
    { "lemma": "Wake", "class": "Achievement", "forms": { "past": "woke", "participle": "woken", "gerund": "waking" } },
    { "lemma": "Wear", "class": "Activity", "forms": { "past": "wore", "participle": "worn", "gerund": "wearing" } },
    { "lemma": "Break", "class": "Achievement", "forms": { "past": "broke", "participle": "broken", "gerund": "breaking" }, "features": ["Unaccusative"] },
    { "lemma": "Choose", "class": "Achievement", "forms": { "past": "chose", "participle": "chosen", "gerund": "choosing" } },
    { "lemma": "Freeze", "class": "Accomplishment", "forms": { "past": "froze", "participle": "frozen", "gerund": "freezing" }, "features": ["Unaccusative"] },
    { "lemma": "Bite", "class": "Semelfactive", "forms": { "past": "bit", "participle": "bitten", "gerund": "biting" } },
    { "lemma": "Begin", "class": "Achievement", "forms": { "past": "began", "participle": "begun", "gerund": "beginning" }, "features": ["SubjectControl"] },
    { "lemma": "Sing", "class": "Activity", "forms": { "past": "sang", "participle": "sung", "gerund": "singing" } },
    { "lemma": "Swim", "class": "Activity", "forms": { "past": "swam", "participle": "swum", "gerund": "swimming" } },
    { "lemma": "Fly", "class": "Activity", "forms": { "past": "flew", "participle": "flown", "gerund": "flying" } },
    { "lemma": "Get", "class": "Achievement", "forms": { "past": "got", "participle": "gotten", "gerund": "getting" } },
    { "lemma": "Fall", "class": "Achievement", "forms": { "past": "fell", "participle": "fallen", "gerund": "falling" } },
    { "lemma": "Feel", "class": "State", "forms": { "past": "felt", "gerund": "feeling" } },
    { "lemma": "Sit", "class": "Activity", "forms": { "past": "sat", "gerund": "sitting" } },
    { "lemma": "Stand", "class": "Activity", "forms": { "past": "stood", "gerund": "standing" } },
    { "lemma": "Lose", "class": "Achievement", "forms": { "past": "lost", "gerund": "losing" } },
    { "lemma": "Win", "class": "Achievement", "forms": { "past": "won", "gerund": "winning" } },
    { "lemma": "Catch", "class": "Achievement", "forms": { "past": "caught", "gerund": "catching" } },
    { "lemma": "Teach", "class": "Accomplishment", "forms": { "past": "taught", "gerund": "teaching" }, "features": ["Ditransitive", "ObjectControl"] },
    { "lemma": "Buy", "class": "Achievement", "forms": { "past": "bought", "gerund": "buying" } },
    { "lemma": "Sell", "class": "Achievement", "forms": { "past": "sold", "gerund": "selling" } },
    { "lemma": "Pay", "class": "Achievement", "forms": { "past": "paid", "gerund": "paying" }, "features": ["Ditransitive"] },
    { "lemma": "Cut", "class": "Achievement", "forms": { "past": "cut", "gerund": "cutting" } },
    { "lemma": "Hit", "class": "Semelfactive", "forms": { "past": "hit", "gerund": "hitting" } },
    { "lemma": "Let", "class": "Achievement", "forms": { "past": "let", "gerund": "letting" } },
    { "lemma": "Shut", "class": "Achievement", "forms": { "past": "shut", "gerund": "shutting" } },
    { "lemma": "Cost", "class": "State", "forms": { "past": "cost", "gerund": "costing" } },
    { "lemma": "Hurt", "class": "Achievement", "forms": { "past": "hurt", "gerund": "hurting" } },
    { "lemma": "Chase", "class": "Activity", "forms": { "past": "chased", "gerund": "chasing" } },
    { "lemma": "Wag", "class": "Semelfactive", "forms": { "past": "wagged", "gerund": "wagging" } },
    { "lemma": "Push", "class": "Semelfactive", "forms": { "past": "pushed", "gerund": "pushing" } },
    { "lemma": "Stop", "class": "Achievement", "forms": { "past": "stopped", "gerund": "stopping" } },
    { "lemma": "Smoke", "class": "Activity", "forms": { "past": "smoked", "gerund": "smoking" } },
    { "lemma": "Open", "class": "Achievement", "forms": { "past": "opened", "gerund": "opening" }, "features": ["Unaccusative"] },
    { "lemma": "Rain", "class": "Activity", "regular": true, "features": ["Weather"] },
    { "lemma": "Snow", "class": "Activity", "regular": true, "features": ["Weather"] },
    { "lemma": "Hail", "class": "Semelfactive", "regular": true, "features": ["Weather"] },
    { "lemma": "Thunder", "class": "Activity", "regular": true, "features": ["Weather"] },
    { "lemma": "Pour", "class": "Activity", "regular": true, "features": ["Weather"] },
    { "lemma": "Gather", "class": "Activity", "regular": true, "features": ["Collective"] },
    { "lemma": "Assemble", "class": "Accomplishment", "regular": true, "features": ["Collective"] },
    { "lemma": "Convene", "class": "Activity", "regular": true, "features": ["Collective"] },
    { "lemma": "Want", "class": "State", "regular": true, "features": ["SubjectControl", "Opaque"] },
    { "lemma": "Hope", "class": "State", "regular": true, "features": ["SubjectControl", "Opaque"] },
    { "lemma": "Decide", "class": "Activity", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Try", "class": "Activity", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Intend", "class": "State", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Refuse", "class": "Activity", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Agree", "class": "Activity", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Threaten", "class": "Activity", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Prefer", "class": "State", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Manage", "class": "Accomplishment", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Fail", "class": "Achievement", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Tend", "class": "State", "regular": true, "features": ["SubjectControl", "Raising"] },
    { "lemma": "Continue", "class": "Activity", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Start", "class": "Achievement", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Promise", "class": "Activity", "regular": true, "features": ["SubjectControl", "Performative"] },
    { "lemma": "Swear", "class": "Activity", "regular": true, "features": ["SubjectControl", "Performative"] },
    { "lemma": "Vow", "class": "Activity", "regular": true, "features": ["SubjectControl", "Performative"] },
    { "lemma": "Expect", "class": "State", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Plan", "class": "Activity", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Seem", "class": "State", "regular": true, "features": ["Raising"] },
    { "lemma": "Appear", "class": "State", "regular": true, "features": ["Raising"] },
    { "lemma": "Happen", "class": "Achievement", "regular": true, "features": ["Raising"] },
    { "lemma": "Turn", "class": "Activity", "regular": true, "features": ["Raising"] },
    { "lemma": "Persuade", "class": "Accomplishment", "regular": true, "features": ["ObjectControl"] },
    { "lemma": "Convince", "class": "Accomplishment", "regular": true, "features": ["ObjectControl"] },
    { "lemma": "Force", "class": "Accomplishment", "regular": true, "features": ["ObjectControl"] },
    { "lemma": "Order", "class": "Activity", "regular": true, "features": ["ObjectControl", "Performative"] },
    { "lemma": "Command", "class": "Activity", "regular": true, "features": ["ObjectControl", "Performative"] },
    { "lemma": "Ask", "class": "Activity", "regular": true, "features": ["ObjectControl"] },
    { "lemma": "Advise", "class": "Activity", "regular": true, "features": ["ObjectControl", "Performative"] },
    { "lemma": "Encourage", "class": "Activity", "regular": true, "features": ["ObjectControl"] },
    { "lemma": "Allow", "class": "State", "regular": true, "features": ["ObjectControl"] },
    { "lemma": "Permit", "class": "State", "regular": true, "features": ["ObjectControl"] },
    { "lemma": "Forbid", "class": "State", "regular": true, "features": ["ObjectControl", "Performative"] },
    { "lemma": "Cause", "class": "Accomplishment", "regular": true, "features": ["ObjectControl"] },
    { "lemma": "Help", "class": "Activity", "regular": true, "features": ["ObjectControl"] },
    { "lemma": "Invite", "class": "Activity", "regular": true, "features": ["ObjectControl"] },
    { "lemma": "Remind", "class": "Activity", "regular": true, "features": ["ObjectControl"] },
    { "lemma": "Warn", "class": "Activity", "regular": true, "features": ["ObjectControl", "Performative"] },
    { "lemma": "Believe", "class": "State", "regular": true, "features": ["Opaque"] },
    { "lemma": "Wish", "class": "State", "regular": true, "features": ["Opaque"] },
    { "lemma": "Seek", "class": "State", "forms": {"past": "sought", "participle": "sought"}, "features": ["Opaque"] },
    { "lemma": "Fear", "class": "State", "regular": true, "features": ["Opaque"] },
    { "lemma": "Imagine", "class": "State", "regular": true, "features": ["Opaque"] },
    { "lemma": "Dream", "class": "Activity", "regular": true, "features": ["Opaque"] },
    { "lemma": "Pretend", "class": "Activity", "regular": true, "features": ["Opaque"] },
    { "lemma": "Bark", "class": "Activity", "regular": true },
    { "lemma": "Hunt", "class": "Activity", "regular": true },
    { "lemma": "Happen", "class": "Achievement", "regular": true },
    { "lemma": "Flow", "class": "Activity", "regular": true },
    { "lemma": "Remain", "class": "State", "regular": true },
    { "lemma": "Examine", "class": "Activity", "regular": true },
    { "lemma": "Walk", "class": "Activity", "regular": true },
    { "lemma": "Talk", "class": "Activity", "regular": true },
    { "lemma": "Jump", "class": "Activity", "regular": true },
    { "lemma": "Duck", "class": "Activity", "regular": true },
    { "lemma": "Love", "class": "State", "regular": true },
    { "lemma": "Hate", "class": "State", "regular": true },
    { "lemma": "Like", "class": "State", "regular": true },
    { "lemma": "Need", "class": "State", "regular": true, "features": ["Opaque"] },
    { "lemma": "Touch", "class": "Activity", "regular": true },
    { "lemma": "Smell", "class": "State", "regular": true },
    { "lemma": "Look", "class": "Activity", "regular": true },
    { "lemma": "Own", "class": "State", "regular": true },
    { "lemma": "Lack", "class": "State", "regular": true },
    { "lemma": "Enter", "class": "Activity", "regular": true },
    { "lemma": "Trigger", "class": "Achievement", "regular": true, "features": ["Unaccusative"] },
    { "lemma": "Beat", "class": "Activity", "regular": true },
    { "lemma": "Marry", "class": "Achievement", "regular": true },
    { "lemma": "Kill", "class": "Achievement", "regular": true },
    { "lemma": "Stay", "class": "Activity", "regular": true },
    { "lemma": "Work", "class": "Activity", "regular": true },
    { "lemma": "Play", "class": "Activity", "regular": true },
    { "lemma": "Pass", "class": "Activity", "regular": true, "features": ["Ditransitive"] },
    { "lemma": "Hand", "class": "Activity", "regular": true, "features": ["Ditransitive"] },
    { "lemma": "Carry", "class": "Activity", "regular": true, "features": ["Mixed"] },
    { "lemma": "Lift", "class": "Activity", "regular": true, "features": ["Mixed"] },
    { "lemma": "Move", "class": "Activity", "regular": true, "features": ["Mixed"] },
    { "lemma": "Push", "class": "Activity", "regular": true, "features": ["Mixed"] },
    { "lemma": "Pull", "class": "Activity", "regular": true, "features": ["Mixed"] },
    { "lemma": "Deliver", "class": "Accomplishment", "regular": true },
    { "lemma": "Exist", "class": "State", "regular": true },
    { "lemma": "Knock", "class": "Semelfactive", "regular": true },
    { "lemma": "Kick", "class": "Semelfactive", "regular": true },
    { "lemma": "Tap", "class": "Semelfactive", "regular": true },
    { "lemma": "Cough", "class": "Semelfactive", "regular": true },
    { "lemma": "Blink", "class": "Semelfactive", "regular": true },
    { "lemma": "Sneeze", "class": "Semelfactive", "regular": true },
    { "lemma": "Hiccup", "class": "Semelfactive", "regular": true },
    { "lemma": "Flash", "class": "Semelfactive", "regular": true },
    { "lemma": "Click", "class": "Semelfactive", "regular": true },
    { "lemma": "Beep", "class": "Semelfactive", "regular": true },
    { "lemma": "Honk", "class": "Semelfactive", "regular": true },
    { "lemma": "Slap", "class": "Semelfactive", "regular": true },
    { "lemma": "Punch", "class": "Semelfactive", "regular": true },
    { "lemma": "Poke", "class": "Semelfactive", "regular": true },
    { "lemma": "Flap", "class": "Semelfactive", "regular": true },
    { "lemma": "Nod", "class": "Semelfactive", "regular": true },
    { "lemma": "Wink", "class": "Semelfactive", "regular": true },
    { "lemma": "Create", "class": "Accomplishment", "regular": true },
    { "lemma": "Construct", "class": "Accomplishment", "regular": true },
    { "lemma": "Paint", "class": "Accomplishment", "regular": true },
    { "lemma": "Repair", "class": "Accomplishment", "regular": true },
    { "lemma": "Fix", "class": "Accomplishment", "regular": true },
    { "lemma": "Melt", "class": "Accomplishment", "regular": true, "features": ["Unaccusative"] },
    { "lemma": "Close", "class": "Achievement", "regular": true, "features": ["Unaccusative"] },
    { "lemma": "Sink", "class": "Achievement", "forms": { "past": "sank", "participle": "sunk", "gerund": "sinking" }, "features": ["Unaccusative"] },
    { "lemma": "Dry", "class": "Accomplishment", "regular": true, "features": ["Unaccusative"] },
    { "lemma": "Burn", "class": "Accomplishment", "regular": true, "features": ["Unaccusative"] },
    { "lemma": "Explode", "class": "Achievement", "regular": true, "features": ["Unaccusative"] },
    { "lemma": "Collapse", "class": "Achievement", "regular": true, "features": ["Unaccusative"] },
    { "lemma": "Evaporate", "class": "Accomplishment", "regular": true, "features": ["Unaccusative"] },
    { "lemma": "Destroy", "class": "Accomplishment", "regular": true },
    { "lemma": "Demolish", "class": "Accomplishment", "regular": true },
    { "lemma": "Dissolve", "class": "Accomplishment", "regular": true },
    { "lemma": "Recover", "class": "Accomplishment", "regular": true },
    { "lemma": "Heal", "class": "Accomplishment", "regular": true },
    { "lemma": "Cross", "class": "Accomplishment", "regular": true },
    { "lemma": "Fill", "class": "Accomplishment", "regular": true },
    { "lemma": "Empty", "class": "Accomplishment", "regular": true },
    { "lemma": "Arrive", "class": "Achievement", "regular": true },
    { "lemma": "Notice", "class": "Achievement", "regular": true },
    { "lemma": "Recognize", "class": "Achievement", "regular": true },
    { "lemma": "Realize", "class": "Achievement", "regular": true },
    { "lemma": "Discover", "class": "Achievement", "regular": true },
    { "lemma": "Reach", "class": "Achievement", "regular": true },
    { "lemma": "Born", "class": "Achievement", "regular": true },
    { "lemma": "Divorce", "class": "Achievement", "regular": true },
    { "lemma": "Graduate", "class": "Achievement", "regular": true },
    { "lemma": "Finish", "class": "Achievement", "regular": true },
    { "lemma": "Complete", "class": "Achievement", "regular": true },
    { "lemma": "Understand", "class": "State", "regular": true },
    { "lemma": "Remember", "class": "State", "regular": true },
    { "lemma": "Forget", "class": "State", "regular": true },
    { "lemma": "Deserve", "class": "State", "regular": true },
    { "lemma": "Contain", "class": "State", "regular": true },
    { "lemma": "Consist", "class": "State", "regular": true },
    { "lemma": "Belong", "class": "State", "regular": true },
    { "lemma": "Matter", "class": "State", "regular": true },
    { "lemma": "Resemble", "class": "State", "regular": true },
    { "lemma": "Dance", "class": "Activity", "regular": true },
    { "lemma": "Study", "class": "Activity", "regular": true },
    { "lemma": "Search", "class": "Activity", "regular": true },
    { "lemma": "Listen", "class": "Activity", "regular": true },
    { "lemma": "Watch", "class": "Activity", "regular": true },
    { "lemma": "Wait", "class": "Activity", "regular": true },
    { "lemma": "Lie", "class": "Activity", "regular": true },
    { "lemma": "Live", "class": "Activity", "regular": true },
    { "lemma": "Travel", "class": "Activity", "regular": true },
    { "lemma": "Move", "class": "Activity", "regular": true },
    { "lemma": "Climb", "class": "Activity", "regular": true },
    { "lemma": "Crawl", "class": "Activity", "regular": true },
    { "lemma": "Roll", "class": "Activity", "regular": true },
    { "lemma": "Spin", "class": "Activity", "regular": true },
    { "lemma": "Turn", "class": "Activity", "regular": true },
    { "lemma": "Pull", "class": "Activity", "regular": true },
    { "lemma": "Drag", "class": "Activity", "regular": true },
    { "lemma": "Lend", "class": "Activity", "regular": true, "features": ["Ditransitive"] },
    { "lemma": "Owe", "class": "Activity", "regular": true, "features": ["Ditransitive"] },
    { "lemma": "Award", "class": "Activity", "regular": true, "features": ["Ditransitive"] },
    { "lemma": "Grant", "class": "Activity", "regular": true, "features": ["Ditransitive"] },
    { "lemma": "Offer", "class": "Activity", "regular": true, "features": ["Ditransitive"] },
    { "lemma": "Bet", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Guarantee", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Pledge", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Declare", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Pronounce", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Announce", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Proclaim", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Request", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Demand", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Apologize", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Thank", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Congratulate", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Welcome", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Suggest", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Recommend", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Surround", "class": "Activity", "regular": true, "features": ["Collective"] },
    { "lemma": "Disperse", "class": "Achievement", "regular": true, "features": ["Collective"] },
    { "lemma": "Scatter", "class": "Achievement", "regular": true, "features": ["Collective"] },
    { "lemma": "Congregate", "class": "Activity", "regular": true, "features": ["Collective"] },
    { "lemma": "Unite", "class": "Achievement", "regular": true, "features": ["Collective"] },
    { "lemma": "Merge", "class": "Achievement", "regular": true, "features": ["Collective"] },
    { "lemma": "Combine", "class": "Achievement", "regular": true, "features": ["Collective"] },
    { "lemma": "Collaborate", "class": "Activity", "regular": true, "features": ["Collective"] },
    { "lemma": "Cooperate", "class": "Activity", "regular": true, "features": ["Collective"] },
    { "lemma": "Conspire", "class": "Activity", "regular": true, "features": ["Collective"] },

    { "lemma": "Accept", "class": "Achievement", "regular": true },
    { "lemma": "Achieve", "class": "Achievement", "regular": true },
    { "lemma": "Add", "class": "Achievement", "regular": true },
    { "lemma": "Admire", "class": "State", "regular": true },
    { "lemma": "Admit", "class": "Achievement", "forms": { "past": "admitted", "gerund": "admitting" } },
    { "lemma": "Advise", "class": "Activity", "regular": true },
    { "lemma": "Afford", "class": "State", "regular": true },
    { "lemma": "Aim", "class": "Activity", "regular": true },
    { "lemma": "Allow", "class": "Achievement", "regular": true },
    { "lemma": "Announce", "class": "Achievement", "regular": true },
    { "lemma": "Annoy", "class": "Achievement", "regular": true },
    { "lemma": "Answer", "class": "Activity", "regular": true },
    { "lemma": "Apologize", "class": "Achievement", "regular": true },
    { "lemma": "Appear", "class": "Achievement", "regular": true },
    { "lemma": "Apply", "class": "Achievement", "forms": { "past": "applied", "gerund": "applying" } },
    { "lemma": "Appreciate", "class": "State", "regular": true },
    { "lemma": "Approach", "class": "Achievement", "regular": true },
    { "lemma": "Approve", "class": "Achievement", "regular": true },
    { "lemma": "Argue", "class": "Activity", "regular": true },
    { "lemma": "Arrange", "class": "Accomplishment", "regular": true },
    { "lemma": "Arrest", "class": "Achievement", "regular": true },
    { "lemma": "Arrive", "class": "Achievement", "regular": true },
    { "lemma": "Ask", "class": "Activity", "regular": true },
    { "lemma": "Assume", "class": "Achievement", "regular": true },
    { "lemma": "Attach", "class": "Achievement", "regular": true },
    { "lemma": "Attack", "class": "Activity", "regular": true },
    { "lemma": "Attempt", "class": "Activity", "regular": true },
    { "lemma": "Attend", "class": "Activity", "regular": true },
    { "lemma": "Attract", "class": "Achievement", "regular": true },
    { "lemma": "Avoid", "class": "Activity", "regular": true },
    { "lemma": "Bake", "class": "Accomplishment", "regular": true },
    { "lemma": "Balance", "class": "Activity", "regular": true },
    { "lemma": "Ban", "class": "Achievement", "forms": { "past": "banned", "gerund": "banning" } },
    { "lemma": "Bark", "class": "Activity", "regular": true },
    { "lemma": "Base", "class": "Achievement", "regular": true },
    { "lemma": "Bathe", "class": "Activity", "regular": true },
    { "lemma": "Beat", "class": "Activity", "forms": { "past": "beat", "participle": "beaten", "gerund": "beating" } },
    { "lemma": "Become", "class": "Achievement", "forms": { "past": "became", "participle": "become", "gerund": "becoming" } },
    { "lemma": "Beg", "class": "Activity", "forms": { "past": "begged", "gerund": "begging" } },
    { "lemma": "Begin", "class": "Achievement", "forms": { "past": "began", "participle": "begun", "gerund": "beginning" } },
    { "lemma": "Behave", "class": "Activity", "regular": true },
    { "lemma": "Believe", "class": "State", "regular": true, "features": ["Opaque"] },
    { "lemma": "Belong", "class": "State", "regular": true },
    { "lemma": "Bend", "class": "Achievement", "forms": { "past": "bent", "gerund": "bending" } },
    { "lemma": "Bet", "class": "Activity", "forms": { "past": "bet", "gerund": "betting" } },
    { "lemma": "Bite", "class": "Activity", "forms": { "past": "bit", "participle": "bitten", "gerund": "biting" } },
    { "lemma": "Blame", "class": "Activity", "regular": true },
    { "lemma": "Bless", "class": "Achievement", "regular": true },
    { "lemma": "Block", "class": "Achievement", "regular": true },
    { "lemma": "Boil", "class": "Accomplishment", "regular": true },
    { "lemma": "Borrow", "class": "Achievement", "regular": true },
    { "lemma": "Bother", "class": "Activity", "regular": true },
    { "lemma": "Bounce", "class": "Activity", "regular": true },
    { "lemma": "Bow", "class": "Activity", "regular": true },
    { "lemma": "Breathe", "class": "Activity", "regular": true },
    { "lemma": "Broadcast", "class": "Activity", "forms": { "past": "broadcast", "gerund": "broadcasting" } },
    { "lemma": "Brush", "class": "Activity", "regular": true },
    { "lemma": "Burn", "class": "Accomplishment", "forms": { "past": "burnt", "gerund": "burning" } },
    { "lemma": "Burst", "class": "Achievement", "forms": { "past": "burst", "gerund": "bursting" } },
    { "lemma": "Bury", "class": "Achievement", "forms": { "past": "buried", "gerund": "burying" } },
    { "lemma": "Buy", "class": "Achievement", "forms": { "past": "bought", "gerund": "buying" } },
    { "lemma": "Calculate", "class": "Accomplishment", "regular": true },
    { "lemma": "Call", "class": "Activity", "regular": true },
    { "lemma": "Calm", "class": "Achievement", "regular": true },
    { "lemma": "Camp", "class": "Activity", "regular": true },
    { "lemma": "Cancel", "class": "Achievement", "regular": true },
    { "lemma": "Care", "class": "State", "regular": true },
    { "lemma": "Carry", "class": "Activity", "forms": { "past": "carried", "gerund": "carrying" } },
    { "lemma": "Carve", "class": "Accomplishment", "regular": true },
    { "lemma": "Cast", "class": "Activity", "forms": { "past": "cast", "gerund": "casting" } },
    { "lemma": "Catch", "class": "Achievement", "forms": { "past": "caught", "gerund": "catching" } },
    { "lemma": "Cause", "class": "Achievement", "regular": true },
    { "lemma": "Celebrate", "class": "Activity", "regular": true },
    { "lemma": "Challenge", "class": "Activity", "regular": true },
    { "lemma": "Change", "class": "Achievement", "regular": true },
    { "lemma": "Charge", "class": "Achievement", "regular": true },
    { "lemma": "Chase", "class": "Activity", "regular": true },
    { "lemma": "Chat", "class": "Activity", "forms": { "past": "chatted", "gerund": "chatting" } },
    { "lemma": "Cheat", "class": "Activity", "regular": true },
    { "lemma": "Check", "class": "Activity", "regular": true },
    { "lemma": "Cheer", "class": "Activity", "regular": true },
    { "lemma": "Chew", "class": "Activity", "regular": true },
    { "lemma": "Claim", "class": "Activity", "regular": true },
    { "lemma": "Clap", "class": "Activity", "forms": { "past": "clapped", "gerund": "clapping" } },
    { "lemma": "Clean", "class": "Accomplishment", "regular": true },
    { "lemma": "Clear", "class": "Achievement", "regular": true },
    { "lemma": "Climb", "class": "Activity", "regular": true },
    { "lemma": "Cling", "class": "Activity", "forms": { "past": "clung", "gerund": "clinging" } },
    { "lemma": "Close", "class": "Achievement", "regular": true },
    { "lemma": "Coach", "class": "Activity", "regular": true },
    { "lemma": "Collect", "class": "Activity", "regular": true },
    { "lemma": "Comfort", "class": "Activity", "regular": true },
    { "lemma": "Command", "class": "Activity", "regular": true },
    { "lemma": "Comment", "class": "Activity", "regular": true },
    { "lemma": "Commit", "class": "Achievement", "forms": { "past": "committed", "gerund": "committing" } },
    { "lemma": "Communicate", "class": "Activity", "regular": true },
    { "lemma": "Compare", "class": "Activity", "regular": true },
    { "lemma": "Compete", "class": "Activity", "regular": true },
    { "lemma": "Complain", "class": "Activity", "regular": true },
    { "lemma": "Complete", "class": "Achievement", "regular": true },
    { "lemma": "Concern", "class": "State", "regular": true },
    { "lemma": "Conclude", "class": "Achievement", "regular": true },
    { "lemma": "Conduct", "class": "Activity", "regular": true },
    { "lemma": "Confess", "class": "Achievement", "regular": true },
    { "lemma": "Confirm", "class": "Achievement", "regular": true },
    { "lemma": "Confuse", "class": "Achievement", "regular": true },
    { "lemma": "Connect", "class": "Achievement", "regular": true },
    { "lemma": "Consider", "class": "State", "regular": true },
    { "lemma": "Consist", "class": "State", "regular": true },
    { "lemma": "Construct", "class": "Accomplishment", "regular": true },
    { "lemma": "Consult", "class": "Activity", "regular": true },
    { "lemma": "Consume", "class": "Accomplishment", "regular": true },
    { "lemma": "Contact", "class": "Achievement", "regular": true },
    { "lemma": "Contain", "class": "State", "regular": true },
    { "lemma": "Continue", "class": "Activity", "regular": true },
    { "lemma": "Contribute", "class": "Activity", "regular": true },
    { "lemma": "Control", "class": "Activity", "regular": true },
    { "lemma": "Convert", "class": "Achievement", "regular": true },
    { "lemma": "Convince", "class": "Achievement", "regular": true },
    { "lemma": "Cook", "class": "Accomplishment", "regular": true },
    { "lemma": "Cool", "class": "Achievement", "regular": true },
    { "lemma": "Copy", "class": "Achievement", "forms": { "past": "copied", "gerund": "copying" } },
    { "lemma": "Correct", "class": "Achievement", "regular": true },
    { "lemma": "Cost", "class": "State", "forms": { "past": "cost", "gerund": "costing" } },
    { "lemma": "Cough", "class": "Activity", "regular": true },
    { "lemma": "Count", "class": "Activity", "regular": true },
    { "lemma": "Cover", "class": "Achievement", "regular": true },
    { "lemma": "Crack", "class": "Achievement", "regular": true },
    { "lemma": "Crash", "class": "Achievement", "regular": true },
    { "lemma": "Crawl", "class": "Activity", "regular": true },
    { "lemma": "Create", "class": "Accomplishment", "regular": true },
    { "lemma": "Creep", "class": "Activity", "forms": { "past": "crept", "gerund": "creeping" } },
    { "lemma": "Criticize", "class": "Activity", "regular": true },
    { "lemma": "Cross", "class": "Achievement", "regular": true },
    { "lemma": "Crush", "class": "Achievement", "regular": true },
    { "lemma": "Cry", "class": "Activity", "forms": { "past": "cried", "gerund": "crying" } },
    { "lemma": "Cure", "class": "Achievement", "regular": true },
    { "lemma": "Curl", "class": "Achievement", "regular": true },
    { "lemma": "Cut", "class": "Activity", "forms": { "past": "cut", "gerund": "cutting" } },
    { "lemma": "Damage", "class": "Achievement", "regular": true },
    { "lemma": "Dance", "class": "Activity", "regular": true },
    { "lemma": "Dare", "class": "Activity", "regular": true },
    { "lemma": "Deal", "class": "Activity", "forms": { "past": "dealt", "gerund": "dealing" } },
    { "lemma": "Debate", "class": "Activity", "regular": true },
    { "lemma": "Decay", "class": "Accomplishment", "regular": true },
    { "lemma": "Deceive", "class": "Activity", "regular": true },
    { "lemma": "Decide", "class": "Achievement", "regular": true },
    { "lemma": "Declare", "class": "Achievement", "regular": true },
    { "lemma": "Decline", "class": "Achievement", "regular": true },
    { "lemma": "Decorate", "class": "Accomplishment", "regular": true },
    { "lemma": "Decrease", "class": "Achievement", "regular": true },
    { "lemma": "Defeat", "class": "Achievement", "regular": true },
    { "lemma": "Defend", "class": "Activity", "regular": true },
    { "lemma": "Define", "class": "Achievement", "regular": true },
    { "lemma": "Delay", "class": "Achievement", "regular": true },
    { "lemma": "Delete", "class": "Achievement", "regular": true },
    { "lemma": "Deliver", "class": "Achievement", "regular": true },
    { "lemma": "Demand", "class": "Activity", "regular": true },
    { "lemma": "Demonstrate", "class": "Activity", "regular": true },
    { "lemma": "Deny", "class": "Activity", "forms": { "past": "denied", "gerund": "denying" } },
    { "lemma": "Depart", "class": "Achievement", "regular": true },
    { "lemma": "Depend", "class": "State", "regular": true },
    { "lemma": "Deposit", "class": "Achievement", "regular": true },
    { "lemma": "Describe", "class": "Activity", "regular": true },
    { "lemma": "Deserve", "class": "State", "regular": true },
    { "lemma": "Design", "class": "Accomplishment", "regular": true },
    { "lemma": "Desire", "class": "State", "regular": true },
    { "lemma": "Destroy", "class": "Achievement", "regular": true },
    { "lemma": "Detect", "class": "Achievement", "regular": true },
    { "lemma": "Determine", "class": "Achievement", "regular": true },
    { "lemma": "Develop", "class": "Accomplishment", "regular": true },
    { "lemma": "Differ", "class": "State", "regular": true },
    { "lemma": "Dig", "class": "Activity", "forms": { "past": "dug", "gerund": "digging" } },
    { "lemma": "Dine", "class": "Activity", "regular": true },
    { "lemma": "Dip", "class": "Achievement", "forms": { "past": "dipped", "gerund": "dipping" } },
    { "lemma": "Direct", "class": "Activity", "regular": true },
    { "lemma": "Disappear", "class": "Achievement", "regular": true },
    { "lemma": "Disappoint", "class": "Achievement", "regular": true },
    { "lemma": "Discover", "class": "Achievement", "regular": true },
    { "lemma": "Discuss", "class": "Activity", "regular": true },
    { "lemma": "Disguise", "class": "Achievement", "regular": true },
    { "lemma": "Dislike", "class": "State", "regular": true },
    { "lemma": "Dismiss", "class": "Achievement", "regular": true },
    { "lemma": "Display", "class": "Activity", "regular": true },
    { "lemma": "Dissolve", "class": "Accomplishment", "regular": true },
    { "lemma": "Distribute", "class": "Activity", "regular": true },
    { "lemma": "Disturb", "class": "Achievement", "regular": true },
    { "lemma": "Dive", "class": "Activity", "forms": { "past": "dove", "gerund": "diving" } },
    { "lemma": "Divide", "class": "Achievement", "regular": true },
    { "lemma": "Doubt", "class": "State", "regular": true },
    { "lemma": "Download", "class": "Achievement", "regular": true },
    { "lemma": "Drag", "class": "Activity", "forms": { "past": "dragged", "gerund": "dragging" } },
    { "lemma": "Drain", "class": "Accomplishment", "regular": true },
    { "lemma": "Dream", "class": "Activity", "forms": { "past": "dreamt", "gerund": "dreaming" } },
    { "lemma": "Dress", "class": "Achievement", "regular": true },
    { "lemma": "Drill", "class": "Activity", "regular": true },
    { "lemma": "Drip", "class": "Activity", "forms": { "past": "dripped", "gerund": "dripping" } },
    { "lemma": "Drop", "class": "Achievement", "forms": { "past": "dropped", "gerund": "dropping" } },
    { "lemma": "Drown", "class": "Achievement", "regular": true },
    { "lemma": "Dry", "class": "Accomplishment", "forms": { "past": "dried", "gerund": "drying" } },
    { "lemma": "Dump", "class": "Achievement", "regular": true },
    { "lemma": "Earn", "class": "Achievement", "regular": true },
    { "lemma": "Edit", "class": "Accomplishment", "regular": true },
    { "lemma": "Educate", "class": "Accomplishment", "regular": true },
    { "lemma": "Elect", "class": "Achievement", "regular": true },
    { "lemma": "Eliminate", "class": "Achievement", "regular": true },
    { "lemma": "Email", "class": "Activity", "regular": true },
    { "lemma": "Embarrass", "class": "Achievement", "regular": true },
    { "lemma": "Embrace", "class": "Activity", "regular": true },
    { "lemma": "Emerge", "class": "Achievement", "regular": true },
    { "lemma": "Employ", "class": "Achievement", "regular": true },
    { "lemma": "Empty", "class": "Achievement", "forms": { "past": "emptied", "gerund": "emptying" } },
    { "lemma": "Enable", "class": "Achievement", "regular": true },
    { "lemma": "Encourage", "class": "Activity", "regular": true },
    { "lemma": "End", "class": "Achievement", "regular": true },
    { "lemma": "Endure", "class": "Activity", "regular": true },
    { "lemma": "Engage", "class": "Achievement", "regular": true },
    { "lemma": "Enjoy", "class": "Activity", "regular": true },
    { "lemma": "Ensure", "class": "Achievement", "regular": true },
    { "lemma": "Enter", "class": "Achievement", "regular": true },
    { "lemma": "Entertain", "class": "Activity", "regular": true },
    { "lemma": "Envy", "class": "State", "forms": { "past": "envied", "gerund": "envying" } },
    { "lemma": "Equal", "class": "State", "regular": true },
    { "lemma": "Equip", "class": "Achievement", "forms": { "past": "equipped", "gerund": "equipping" } },
    { "lemma": "Escape", "class": "Achievement", "regular": true },
    { "lemma": "Establish", "class": "Achievement", "regular": true },
    { "lemma": "Estimate", "class": "Activity", "regular": true },
    { "lemma": "Evaluate", "class": "Activity", "regular": true },
    { "lemma": "Examine", "class": "Activity", "regular": true },
    { "lemma": "Exceed", "class": "Achievement", "regular": true },
    { "lemma": "Exchange", "class": "Achievement", "regular": true },
    { "lemma": "Excite", "class": "Achievement", "regular": true },
    { "lemma": "Exclude", "class": "Achievement", "regular": true },
    { "lemma": "Excuse", "class": "Achievement", "regular": true },
    { "lemma": "Execute", "class": "Achievement", "regular": true },
    { "lemma": "Exercise", "class": "Activity", "regular": true },
    { "lemma": "Exist", "class": "State", "regular": true },
    { "lemma": "Expand", "class": "Accomplishment", "regular": true },
    { "lemma": "Expect", "class": "State", "regular": true },
    { "lemma": "Experience", "class": "Activity", "regular": true },
    { "lemma": "Experiment", "class": "Activity", "regular": true },
    { "lemma": "Explain", "class": "Activity", "regular": true },
    { "lemma": "Explode", "class": "Achievement", "regular": true },
    { "lemma": "Explore", "class": "Activity", "regular": true },
    { "lemma": "Export", "class": "Activity", "regular": true },
    { "lemma": "Expose", "class": "Achievement", "regular": true },
    { "lemma": "Express", "class": "Activity", "regular": true },
    { "lemma": "Extend", "class": "Accomplishment", "regular": true },
    { "lemma": "Face", "class": "Activity", "regular": true },
    { "lemma": "Fail", "class": "Achievement", "regular": true },
    { "lemma": "Faint", "class": "Achievement", "regular": true },
    { "lemma": "Fall", "class": "Achievement", "forms": { "past": "fell", "participle": "fallen", "gerund": "falling" } },
    { "lemma": "Fancy", "class": "State", "forms": { "past": "fancied", "gerund": "fancying" } },
    { "lemma": "Farm", "class": "Activity", "regular": true },
    { "lemma": "Fascinate", "class": "Achievement", "regular": true },
    { "lemma": "Fasten", "class": "Achievement", "regular": true },
    { "lemma": "Favor", "class": "State", "regular": true },
    { "lemma": "Fear", "class": "State", "regular": true },
    { "lemma": "Feed", "class": "Activity", "forms": { "past": "fed", "gerund": "feeding" } },
    { "lemma": "Feel", "class": "State", "forms": { "past": "felt", "gerund": "feeling" } },
    { "lemma": "Fetch", "class": "Achievement", "regular": true },
    { "lemma": "File", "class": "Achievement", "regular": true },
    { "lemma": "Fill", "class": "Achievement", "regular": true },
    { "lemma": "Film", "class": "Activity", "regular": true },
    { "lemma": "Filter", "class": "Activity", "regular": true },
    { "lemma": "Finance", "class": "Activity", "regular": true },
    { "lemma": "Finish", "class": "Achievement", "regular": true },
    { "lemma": "Fire", "class": "Achievement", "regular": true },
    { "lemma": "Fish", "class": "Activity", "regular": true },
    { "lemma": "Fit", "class": "State", "forms": { "past": "fit", "gerund": "fitting" } },
    { "lemma": "Fix", "class": "Accomplishment", "regular": true },
    { "lemma": "Flash", "class": "Activity", "regular": true },
    { "lemma": "Flatten", "class": "Achievement", "regular": true },
    { "lemma": "Flee", "class": "Achievement", "forms": { "past": "fled", "gerund": "fleeing" } },
    { "lemma": "Float", "class": "Activity", "regular": true },
    { "lemma": "Flood", "class": "Achievement", "regular": true },
    { "lemma": "Flow", "class": "Activity", "regular": true },
    { "lemma": "Fly", "class": "Activity", "forms": { "past": "flew", "participle": "flown", "gerund": "flying" } },
    { "lemma": "Focus", "class": "Activity", "regular": true },
    { "lemma": "Fold", "class": "Achievement", "regular": true },
    { "lemma": "Follow", "class": "Activity", "regular": true },
    { "lemma": "Forbid", "class": "Achievement", "forms": { "past": "forbade", "participle": "forbidden", "gerund": "forbidding" } },
    { "lemma": "Force", "class": "Achievement", "regular": true },
    { "lemma": "Forecast", "class": "Activity", "forms": { "past": "forecast", "gerund": "forecasting" } },
    { "lemma": "Forget", "class": "Achievement", "forms": { "past": "forgot", "participle": "forgotten", "gerund": "forgetting" } },
    { "lemma": "Forgive", "class": "Achievement", "forms": { "past": "forgave", "participle": "forgiven", "gerund": "forgiving" } },
    { "lemma": "Form", "class": "Accomplishment", "regular": true },
    { "lemma": "Found", "class": "Achievement", "regular": true },
    { "lemma": "Frame", "class": "Achievement", "regular": true },
    { "lemma": "Freeze", "class": "Achievement", "forms": { "past": "froze", "participle": "frozen", "gerund": "freezing" } },
    { "lemma": "Frighten", "class": "Achievement", "regular": true },
    { "lemma": "Fry", "class": "Accomplishment", "forms": { "past": "fried", "gerund": "frying" } },
    { "lemma": "Fulfill", "class": "Achievement", "regular": true },
    { "lemma": "Function", "class": "Activity", "regular": true },
    { "lemma": "Fund", "class": "Activity", "regular": true },
    { "lemma": "Gain", "class": "Achievement", "regular": true },
    { "lemma": "Gamble", "class": "Activity", "regular": true },
    { "lemma": "Gather", "class": "Activity", "regular": true, "features": ["Collective"] },
    { "lemma": "Gaze", "class": "Activity", "regular": true },
    { "lemma": "Generate", "class": "Accomplishment", "regular": true },
    { "lemma": "Get", "class": "Achievement", "forms": { "past": "got", "participle": "gotten", "gerund": "getting" } },
    { "lemma": "Glance", "class": "Activity", "regular": true },
    { "lemma": "Glow", "class": "Activity", "regular": true },
    { "lemma": "Grab", "class": "Achievement", "forms": { "past": "grabbed", "gerund": "grabbing" } },
    { "lemma": "Graduate", "class": "Achievement", "regular": true },
    { "lemma": "Grant", "class": "Achievement", "regular": true },
    { "lemma": "Grasp", "class": "Achievement", "regular": true },
    { "lemma": "Greet", "class": "Activity", "regular": true },
    { "lemma": "Grind", "class": "Activity", "forms": { "past": "ground", "gerund": "grinding" } },
    { "lemma": "Grip", "class": "Activity", "forms": { "past": "gripped", "gerund": "gripping" } },
    { "lemma": "Guarantee", "class": "Achievement", "regular": true },
    { "lemma": "Guard", "class": "Activity", "regular": true },
    { "lemma": "Guess", "class": "Activity", "regular": true },
    { "lemma": "Guide", "class": "Activity", "regular": true },
    { "lemma": "Halt", "class": "Achievement", "regular": true },
    { "lemma": "Hand", "class": "Achievement", "regular": true },
    { "lemma": "Handle", "class": "Activity", "regular": true },
    { "lemma": "Hang", "class": "Activity", "forms": { "past": "hung", "gerund": "hanging" } },
    { "lemma": "Happen", "class": "Achievement", "regular": true },
    { "lemma": "Harm", "class": "Achievement", "regular": true },
    { "lemma": "Harvest", "class": "Accomplishment", "regular": true },
    { "lemma": "Hate", "class": "State", "regular": true },
    { "lemma": "Haunt", "class": "Activity", "regular": true },
    { "lemma": "Head", "class": "Activity", "regular": true },
    { "lemma": "Heal", "class": "Accomplishment", "regular": true },
    { "lemma": "Heat", "class": "Accomplishment", "regular": true },
    { "lemma": "Help", "class": "Activity", "regular": true },
    { "lemma": "Hesitate", "class": "Activity", "regular": true },
    { "lemma": "Highlight", "class": "Achievement", "regular": true },
    { "lemma": "Hike", "class": "Activity", "regular": true },
    { "lemma": "Hire", "class": "Achievement", "regular": true },
    { "lemma": "Hit", "class": "Activity", "forms": { "past": "hit", "gerund": "hitting" } },
    { "lemma": "Honor", "class": "Activity", "regular": true },
    { "lemma": "Hook", "class": "Achievement", "regular": true },
    { "lemma": "Hope", "class": "State", "regular": true },
    { "lemma": "Host", "class": "Activity", "regular": true },
    { "lemma": "Hug", "class": "Activity", "forms": { "past": "hugged", "gerund": "hugging" } },
    { "lemma": "Hunt", "class": "Activity", "regular": true },
    { "lemma": "Hurry", "class": "Activity", "forms": { "past": "hurried", "gerund": "hurrying" } },
    { "lemma": "Hurt", "class": "Achievement", "forms": { "past": "hurt", "gerund": "hurting" } },
    { "lemma": "Identify", "class": "Achievement", "forms": { "past": "identified", "gerund": "identifying" } },
    { "lemma": "Ignore", "class": "Activity", "regular": true },
    { "lemma": "Illustrate", "class": "Activity", "regular": true },
    { "lemma": "Imagine", "class": "State", "regular": true },
    { "lemma": "Imitate", "class": "Activity", "regular": true },
    { "lemma": "Implement", "class": "Accomplishment", "regular": true },
    { "lemma": "Imply", "class": "State", "forms": { "past": "implied", "gerund": "implying" } },
    { "lemma": "Import", "class": "Activity", "regular": true },
    { "lemma": "Impose", "class": "Achievement", "regular": true },
    { "lemma": "Impress", "class": "Achievement", "regular": true },
    { "lemma": "Improve", "class": "Accomplishment", "regular": true },
    { "lemma": "Include", "class": "State", "regular": true },
    { "lemma": "Increase", "class": "Achievement", "regular": true },
    { "lemma": "Indicate", "class": "Activity", "regular": true },
    { "lemma": "Influence", "class": "Achievement", "regular": true },
    { "lemma": "Inform", "class": "Activity", "regular": true },
    { "lemma": "Inherit", "class": "Achievement", "regular": true },
    { "lemma": "Initiate", "class": "Achievement", "regular": true },
    { "lemma": "Inject", "class": "Achievement", "regular": true },
    { "lemma": "Injure", "class": "Achievement", "regular": true },
    { "lemma": "Insert", "class": "Achievement", "regular": true },
    { "lemma": "Insist", "class": "Activity", "regular": true },
    { "lemma": "Inspect", "class": "Activity", "regular": true },
    { "lemma": "Inspire", "class": "Achievement", "regular": true },
    { "lemma": "Install", "class": "Achievement", "regular": true },
    { "lemma": "Instruct", "class": "Activity", "regular": true },
    { "lemma": "Insult", "class": "Activity", "regular": true },
    { "lemma": "Insure", "class": "Achievement", "regular": true },
    { "lemma": "Intend", "class": "State", "regular": true },
    { "lemma": "Interact", "class": "Activity", "regular": true },
    { "lemma": "Interest", "class": "State", "regular": true },
    { "lemma": "Interfere", "class": "Activity", "regular": true },
    { "lemma": "Interpret", "class": "Activity", "regular": true },
    { "lemma": "Interrupt", "class": "Achievement", "regular": true },
    { "lemma": "Interview", "class": "Activity", "regular": true },
    { "lemma": "Introduce", "class": "Achievement", "regular": true },
    { "lemma": "Invade", "class": "Achievement", "regular": true },
    { "lemma": "Invent", "class": "Achievement", "regular": true },
    { "lemma": "Invest", "class": "Activity", "regular": true },
    { "lemma": "Investigate", "class": "Activity", "regular": true },
    { "lemma": "Invite", "class": "Achievement", "regular": true },
    { "lemma": "Involve", "class": "State", "regular": true },
    { "lemma": "Iron", "class": "Activity", "regular": true },
    { "lemma": "Irritate", "class": "Achievement", "regular": true },
    { "lemma": "Isolate", "class": "Achievement", "regular": true },
    { "lemma": "Jail", "class": "Achievement", "regular": true },
    { "lemma": "Jam", "class": "Achievement", "forms": { "past": "jammed", "gerund": "jamming" } },
    { "lemma": "Jog", "class": "Activity", "forms": { "past": "jogged", "gerund": "jogging" } },
    { "lemma": "Join", "class": "Achievement", "regular": true },
    { "lemma": "Joke", "class": "Activity", "regular": true },
    { "lemma": "Judge", "class": "Activity", "regular": true },
    { "lemma": "Jump", "class": "Activity", "regular": true },
    { "lemma": "Justify", "class": "Activity", "forms": { "past": "justified", "gerund": "justifying" } },
    { "lemma": "Kick", "class": "Activity", "regular": true },
    { "lemma": "Kidnap", "class": "Achievement", "forms": { "past": "kidnapped", "gerund": "kidnapping" } },
    { "lemma": "Kill", "class": "Achievement", "regular": true },
    { "lemma": "Kiss", "class": "Activity", "regular": true },
    { "lemma": "Kneel", "class": "Activity", "forms": { "past": "knelt", "gerund": "kneeling" } },
    { "lemma": "Knit", "class": "Activity", "forms": { "past": "knit", "gerund": "knitting" } },
    { "lemma": "Label", "class": "Achievement", "regular": true },
    { "lemma": "Lack", "class": "State", "regular": true },
    { "lemma": "Land", "class": "Achievement", "regular": true },
    { "lemma": "Last", "class": "State", "regular": true },
    { "lemma": "Laugh", "class": "Activity", "regular": true },
    { "lemma": "Launch", "class": "Achievement", "regular": true },
    { "lemma": "Lay", "class": "Achievement", "forms": { "past": "laid", "gerund": "laying" } },
    { "lemma": "Lead", "class": "Activity", "forms": { "past": "led", "gerund": "leading" } },
    { "lemma": "Leak", "class": "Activity", "regular": true },
    { "lemma": "Lean", "class": "Activity", "forms": { "past": "leant", "gerund": "leaning" } },
    { "lemma": "Leap", "class": "Activity", "forms": { "past": "leapt", "gerund": "leaping" } },
    { "lemma": "Learn", "class": "Achievement", "forms": { "past": "learnt", "gerund": "learning" } },
    { "lemma": "Lend", "class": "Achievement", "forms": { "past": "lent", "gerund": "lending" } },
    { "lemma": "Lengthen", "class": "Achievement", "regular": true },
    { "lemma": "Lie", "class": "Activity", "forms": { "past": "lay", "participle": "lain", "gerund": "lying" } },
    { "lemma": "Lift", "class": "Activity", "regular": true },
    { "lemma": "Light", "class": "Achievement", "forms": { "past": "lit", "gerund": "lighting" } },
    { "lemma": "Like", "class": "State", "regular": true },
    { "lemma": "Limit", "class": "Achievement", "regular": true },
    { "lemma": "Link", "class": "Achievement", "regular": true },
    { "lemma": "List", "class": "Activity", "regular": true },
    { "lemma": "Listen", "class": "Activity", "regular": true },
    { "lemma": "Live", "class": "State", "regular": true },
    { "lemma": "Load", "class": "Achievement", "regular": true },
    { "lemma": "Loan", "class": "Achievement", "regular": true },
    { "lemma": "Locate", "class": "Achievement", "regular": true },
    { "lemma": "Lock", "class": "Achievement", "regular": true },
    { "lemma": "Log", "class": "Activity", "forms": { "past": "logged", "gerund": "logging" } },
    { "lemma": "Long", "class": "State", "regular": true },
    { "lemma": "Look", "class": "Activity", "regular": true },
    { "lemma": "Lose", "class": "Achievement", "forms": { "past": "lost", "gerund": "losing" } },
    { "lemma": "Love", "class": "State", "regular": true },
    { "lemma": "Lower", "class": "Achievement", "regular": true },
    { "lemma": "Maintain", "class": "Activity", "regular": true },
    { "lemma": "Manage", "class": "Activity", "regular": true },
    { "lemma": "Manufacture", "class": "Accomplishment", "regular": true },
    { "lemma": "Map", "class": "Accomplishment", "forms": { "past": "mapped", "gerund": "mapping" } },
    { "lemma": "March", "class": "Activity", "regular": true },
    { "lemma": "Mark", "class": "Achievement", "regular": true },
    { "lemma": "Market", "class": "Activity", "regular": true },
    { "lemma": "Marry", "class": "Achievement", "forms": { "past": "married", "gerund": "marrying" }, "features": ["Collective"] },
    { "lemma": "Match", "class": "Activity", "regular": true },
    { "lemma": "Matter", "class": "State", "regular": true },
    { "lemma": "Measure", "class": "Activity", "regular": true },
    { "lemma": "Melt", "class": "Accomplishment", "regular": true },
    { "lemma": "Memorize", "class": "Accomplishment", "regular": true },
    { "lemma": "Mend", "class": "Accomplishment", "regular": true },
    { "lemma": "Mention", "class": "Activity", "regular": true },
    { "lemma": "Mind", "class": "State", "regular": true },
    { "lemma": "Miss", "class": "Achievement", "regular": true },
    { "lemma": "Mix", "class": "Accomplishment", "regular": true },
    { "lemma": "Modify", "class": "Accomplishment", "forms": { "past": "modified", "gerund": "modifying" } },
    { "lemma": "Monitor", "class": "Activity", "regular": true },
    { "lemma": "Motivate", "class": "Achievement", "regular": true },
    { "lemma": "Mount", "class": "Achievement", "regular": true },
    { "lemma": "Mourn", "class": "Activity", "regular": true },
    { "lemma": "Move", "class": "Activity", "regular": true },
    { "lemma": "Multiply", "class": "Accomplishment", "forms": { "past": "multiplied", "gerund": "multiplying" } },
    { "lemma": "Murder", "class": "Achievement", "regular": true },
    { "lemma": "Name", "class": "Achievement", "regular": true },
    { "lemma": "Narrow", "class": "Achievement", "regular": true },
    { "lemma": "Need", "class": "State", "regular": true },
    { "lemma": "Neglect", "class": "Activity", "regular": true },
    { "lemma": "Negotiate", "class": "Activity", "regular": true },
    { "lemma": "Nod", "class": "Activity", "forms": { "past": "nodded", "gerund": "nodding" } },
    { "lemma": "Nominate", "class": "Achievement", "regular": true },
    { "lemma": "Note", "class": "Activity", "regular": true },
    { "lemma": "Notice", "class": "Achievement", "regular": true },
    { "lemma": "Notify", "class": "Achievement", "forms": { "past": "notified", "gerund": "notifying" } },
    { "lemma": "Obey", "class": "Activity", "regular": true },
    { "lemma": "Object", "class": "Activity", "regular": true },
    { "lemma": "Observe", "class": "Activity", "regular": true },
    { "lemma": "Obtain", "class": "Achievement", "regular": true },
    { "lemma": "Occupy", "class": "Activity", "forms": { "past": "occupied", "gerund": "occupying" } },
    { "lemma": "Occur", "class": "Achievement", "forms": { "past": "occurred", "gerund": "occurring" } },
    { "lemma": "Offend", "class": "Achievement", "regular": true },
    { "lemma": "Offer", "class": "Activity", "regular": true },
    { "lemma": "Open", "class": "Achievement", "regular": true },
    { "lemma": "Operate", "class": "Activity", "regular": true },
    { "lemma": "Oppose", "class": "Activity", "regular": true },
    { "lemma": "Order", "class": "Activity", "regular": true },
    { "lemma": "Organize", "class": "Accomplishment", "regular": true },
    { "lemma": "Ought", "class": "State", "regular": true },
    { "lemma": "Outline", "class": "Activity", "regular": true },
    { "lemma": "Overcome", "class": "Achievement", "forms": { "past": "overcame", "participle": "overcome", "gerund": "overcoming" } },
    { "lemma": "Overlook", "class": "Activity", "regular": true },
    { "lemma": "Owe", "class": "State", "regular": true },
    { "lemma": "Own", "class": "State", "regular": true },
    { "lemma": "Pack", "class": "Achievement", "regular": true },
    { "lemma": "Paint", "class": "Accomplishment", "regular": true },
    { "lemma": "Park", "class": "Achievement", "regular": true },
    { "lemma": "Participate", "class": "Activity", "regular": true },
    { "lemma": "Pass", "class": "Achievement", "regular": true },
    { "lemma": "Pat", "class": "Activity", "forms": { "past": "patted", "gerund": "patting" } },
    { "lemma": "Pause", "class": "Achievement", "regular": true },
    { "lemma": "Pay", "class": "Achievement", "forms": { "past": "paid", "gerund": "paying" } },
    { "lemma": "Peel", "class": "Activity", "regular": true },
    { "lemma": "Perceive", "class": "Achievement", "regular": true },
    { "lemma": "Perform", "class": "Activity", "regular": true },
    { "lemma": "Permit", "class": "Achievement", "forms": { "past": "permitted", "gerund": "permitting" } },
    { "lemma": "Persuade", "class": "Achievement", "regular": true },
    { "lemma": "Phone", "class": "Activity", "regular": true },
    { "lemma": "Photograph", "class": "Activity", "regular": true },
    { "lemma": "Pick", "class": "Activity", "regular": true },
    { "lemma": "Pile", "class": "Achievement", "regular": true },
    { "lemma": "Pinch", "class": "Activity", "regular": true },
    { "lemma": "Pioneer", "class": "Activity", "regular": true },
    { "lemma": "Pitch", "class": "Activity", "regular": true },
    { "lemma": "Place", "class": "Achievement", "regular": true },
    { "lemma": "Plan", "class": "Activity", "forms": { "past": "planned", "gerund": "planning" } },
    { "lemma": "Plant", "class": "Achievement", "regular": true },
    { "lemma": "Play", "class": "Activity", "regular": true },
    { "lemma": "Plead", "class": "Activity", "forms": { "past": "pled", "gerund": "pleading" } },
    { "lemma": "Please", "class": "Achievement", "regular": true },
    { "lemma": "Pledge", "class": "Activity", "regular": true },
    { "lemma": "Plot", "class": "Activity", "forms": { "past": "plotted", "gerund": "plotting" } },
    { "lemma": "Plug", "class": "Achievement", "forms": { "past": "plugged", "gerund": "plugging" } },
    { "lemma": "Plunge", "class": "Achievement", "regular": true },
    { "lemma": "Point", "class": "Activity", "regular": true },
    { "lemma": "Poison", "class": "Achievement", "regular": true },
    { "lemma": "Poke", "class": "Activity", "regular": true },
    { "lemma": "Polish", "class": "Accomplishment", "regular": true },
    { "lemma": "Poll", "class": "Activity", "regular": true },
    { "lemma": "Pollute", "class": "Achievement", "regular": true },
    { "lemma": "Pop", "class": "Activity", "forms": { "past": "popped", "gerund": "popping" } },
    { "lemma": "Port", "class": "Activity", "regular": true },
    { "lemma": "Pose", "class": "Activity", "regular": true },
    { "lemma": "Position", "class": "Achievement", "regular": true },
    { "lemma": "Possess", "class": "State", "regular": true },
    { "lemma": "Post", "class": "Activity", "regular": true },
    { "lemma": "Postpone", "class": "Achievement", "regular": true },
    { "lemma": "Pour", "class": "Activity", "regular": true },
    { "lemma": "Practice", "class": "Activity", "regular": true },
    { "lemma": "Praise", "class": "Activity", "regular": true },
    { "lemma": "Pray", "class": "Activity", "regular": true },
    { "lemma": "Preach", "class": "Activity", "regular": true },
    { "lemma": "Precede", "class": "State", "regular": true },
    { "lemma": "Predict", "class": "Activity", "regular": true },
    { "lemma": "Prefer", "class": "State", "forms": { "past": "preferred", "gerund": "preferring" } },
    { "lemma": "Prepare", "class": "Accomplishment", "regular": true },
    { "lemma": "Prescribe", "class": "Activity", "regular": true },
    { "lemma": "Present", "class": "Activity", "regular": true },
    { "lemma": "Preserve", "class": "Activity", "regular": true },
    { "lemma": "Preside", "class": "Activity", "regular": true },
    { "lemma": "Press", "class": "Activity", "regular": true },
    { "lemma": "Pretend", "class": "Activity", "regular": true },
    { "lemma": "Prevent", "class": "Achievement", "regular": true },
    { "lemma": "Price", "class": "Activity", "regular": true },
    { "lemma": "Print", "class": "Activity", "regular": true },
    { "lemma": "Proceed", "class": "Activity", "regular": true },
    { "lemma": "Process", "class": "Activity", "regular": true },
    { "lemma": "Produce", "class": "Accomplishment", "regular": true },
    { "lemma": "Program", "class": "Accomplishment", "forms": { "past": "programmed", "gerund": "programming" } },
    { "lemma": "Progress", "class": "Activity", "regular": true },
    { "lemma": "Project", "class": "Activity", "regular": true },
    { "lemma": "Promise", "class": "Activity", "regular": true },
    { "lemma": "Promote", "class": "Achievement", "regular": true },
    { "lemma": "Pronounce", "class": "Activity", "regular": true },
    { "lemma": "Propose", "class": "Activity", "regular": true },
    { "lemma": "Prosecute", "class": "Activity", "regular": true },
    { "lemma": "Protect", "class": "Activity", "regular": true },
    { "lemma": "Protest", "class": "Activity", "regular": true },
    { "lemma": "Prove", "class": "Achievement", "forms": { "past": "proved", "participle": "proven", "gerund": "proving" } },
    { "lemma": "Provide", "class": "Achievement", "regular": true },
    { "lemma": "Publish", "class": "Achievement", "regular": true },
    { "lemma": "Pull", "class": "Activity", "regular": true },
    { "lemma": "Pump", "class": "Activity", "regular": true },
    { "lemma": "Punch", "class": "Activity", "regular": true },
    { "lemma": "Punish", "class": "Activity", "regular": true },
    { "lemma": "Purchase", "class": "Achievement", "regular": true },
    { "lemma": "Pursue", "class": "Activity", "regular": true },
    { "lemma": "Push", "class": "Activity", "regular": true },
    { "lemma": "Qualify", "class": "Achievement", "forms": { "past": "qualified", "gerund": "qualifying" } },
    { "lemma": "Question", "class": "Activity", "regular": true },
    { "lemma": "Quit", "class": "Achievement", "forms": { "past": "quit", "gerund": "quitting" } },
    { "lemma": "Quote", "class": "Activity", "regular": true },
    { "lemma": "Race", "class": "Activity", "regular": true },
    { "lemma": "Raid", "class": "Activity", "regular": true },
    { "lemma": "Rain", "class": "Activity", "regular": true },
    { "lemma": "Raise", "class": "Achievement", "regular": true },
    { "lemma": "Rank", "class": "State", "regular": true },
    { "lemma": "Rap", "class": "Activity", "forms": { "past": "rapped", "gerund": "rapping" } },
    { "lemma": "Reach", "class": "Achievement", "regular": true },
    { "lemma": "React", "class": "Activity", "regular": true },
    { "lemma": "Realize", "class": "Achievement", "regular": true, "features": ["Factive"] },
    { "lemma": "Rebuild", "class": "Accomplishment", "forms": { "past": "rebuilt", "gerund": "rebuilding" } },
    { "lemma": "Recall", "class": "Achievement", "regular": true },
    { "lemma": "Receive", "class": "Achievement", "regular": true },
    { "lemma": "Reckon", "class": "Activity", "regular": true },
    { "lemma": "Recognize", "class": "Achievement", "regular": true },
    { "lemma": "Recommend", "class": "Activity", "regular": true },
    { "lemma": "Record", "class": "Achievement", "regular": true },
    { "lemma": "Recover", "class": "Accomplishment", "regular": true },
    { "lemma": "Recruit", "class": "Achievement", "regular": true },
    { "lemma": "Recycle", "class": "Activity", "regular": true },
    { "lemma": "Reduce", "class": "Achievement", "regular": true },
    { "lemma": "Refer", "class": "Activity", "forms": { "past": "referred", "gerund": "referring" } },
    { "lemma": "Reflect", "class": "Activity", "regular": true },
    { "lemma": "Refresh", "class": "Achievement", "regular": true },
    { "lemma": "Refuse", "class": "Achievement", "regular": true },
    { "lemma": "Regard", "class": "State", "regular": true },
    { "lemma": "Register", "class": "Achievement", "regular": true },
    { "lemma": "Regret", "class": "State", "forms": { "past": "regretted", "gerund": "regretting" }, "features": ["Factive"] },
    { "lemma": "Reign", "class": "Activity", "regular": true },
    { "lemma": "Reject", "class": "Achievement", "regular": true },
    { "lemma": "Relate", "class": "Activity", "regular": true },
    { "lemma": "Relax", "class": "Activity", "regular": true },
    { "lemma": "Release", "class": "Achievement", "regular": true },
    { "lemma": "Rely", "class": "State", "forms": { "past": "relied", "gerund": "relying" } },
    { "lemma": "Remain", "class": "State", "regular": true },
    { "lemma": "Remark", "class": "Activity", "regular": true },
    { "lemma": "Remember", "class": "State", "regular": true },
    { "lemma": "Remind", "class": "Activity", "regular": true },
    { "lemma": "Remove", "class": "Achievement", "regular": true },
    { "lemma": "Rent", "class": "Activity", "regular": true },
    { "lemma": "Repair", "class": "Accomplishment", "regular": true },
    { "lemma": "Repeat", "class": "Activity", "regular": true },
    { "lemma": "Replace", "class": "Achievement", "regular": true },
    { "lemma": "Reply", "class": "Activity", "forms": { "past": "replied", "gerund": "replying" } },
    { "lemma": "Report", "class": "Activity", "regular": true },
    { "lemma": "Represent", "class": "State", "regular": true },
    { "lemma": "Reproduce", "class": "Accomplishment", "regular": true },
    { "lemma": "Request", "class": "Activity", "regular": true },
    { "lemma": "Require", "class": "State", "regular": true },
    { "lemma": "Rescue", "class": "Achievement", "regular": true },
    { "lemma": "Research", "class": "Activity", "regular": true },
    { "lemma": "Resemble", "class": "State", "regular": true },
    { "lemma": "Resent", "class": "State", "regular": true },
    { "lemma": "Reserve", "class": "Achievement", "regular": true },
    { "lemma": "Reside", "class": "State", "regular": true },
    { "lemma": "Resign", "class": "Achievement", "regular": true },
    { "lemma": "Resist", "class": "Activity", "regular": true },
    { "lemma": "Resolve", "class": "Achievement", "regular": true },
    { "lemma": "Resort", "class": "Activity", "regular": true },
    { "lemma": "Respect", "class": "State", "regular": true },
    { "lemma": "Respond", "class": "Activity", "regular": true },
    { "lemma": "Rest", "class": "Activity", "regular": true },
    { "lemma": "Restore", "class": "Accomplishment", "regular": true },
    { "lemma": "Restrict", "class": "Achievement", "regular": true },
    { "lemma": "Result", "class": "Achievement", "regular": true },
    { "lemma": "Retain", "class": "State", "regular": true },
    { "lemma": "Retire", "class": "Achievement", "regular": true },
    { "lemma": "Retreat", "class": "Achievement", "regular": true },
    { "lemma": "Return", "class": "Achievement", "regular": true },
    { "lemma": "Reveal", "class": "Achievement", "regular": true },
    { "lemma": "Review", "class": "Activity", "regular": true },
    { "lemma": "Revise", "class": "Accomplishment", "regular": true },
    { "lemma": "Reward", "class": "Activity", "regular": true },
    { "lemma": "Ring", "class": "Activity", "forms": { "past": "rang", "participle": "rung", "gerund": "ringing" } },
    { "lemma": "Rip", "class": "Achievement", "forms": { "past": "ripped", "gerund": "ripping" } },
    { "lemma": "Risk", "class": "Activity", "regular": true },
    { "lemma": "Roar", "class": "Activity", "regular": true },
    { "lemma": "Rob", "class": "Achievement", "forms": { "past": "robbed", "gerund": "robbing" } },
    { "lemma": "Rock", "class": "Activity", "regular": true },
    { "lemma": "Roll", "class": "Activity", "regular": true },
    { "lemma": "Rub", "class": "Activity", "forms": { "past": "rubbed", "gerund": "rubbing" } },
    { "lemma": "Ruin", "class": "Achievement", "regular": true },
    { "lemma": "Rule", "class": "Activity", "regular": true },
    { "lemma": "Rush", "class": "Activity", "regular": true },
    { "lemma": "Sail", "class": "Activity", "regular": true },
    { "lemma": "Satisfy", "class": "Achievement", "forms": { "past": "satisfied", "gerund": "satisfying" } },
    { "lemma": "Save", "class": "Achievement", "regular": true },
    { "lemma": "Saw", "class": "Activity", "regular": true },
    { "lemma": "Scan", "class": "Activity", "forms": { "past": "scanned", "gerund": "scanning" } },
    { "lemma": "Scare", "class": "Achievement", "regular": true },
    { "lemma": "Schedule", "class": "Achievement", "regular": true },
    { "lemma": "Score", "class": "Achievement", "regular": true },
    { "lemma": "Scratch", "class": "Activity", "regular": true },
    { "lemma": "Scream", "class": "Activity", "regular": true },
    { "lemma": "Seal", "class": "Achievement", "regular": true },
    { "lemma": "Search", "class": "Activity", "regular": true },
    { "lemma": "Secure", "class": "Achievement", "regular": true },
    { "lemma": "Seek", "class": "Activity", "forms": { "past": "sought", "gerund": "seeking" } },
    { "lemma": "Seem", "class": "State", "regular": true },
    { "lemma": "Seize", "class": "Achievement", "regular": true },
    { "lemma": "Select", "class": "Achievement", "regular": true },
    { "lemma": "Sell", "class": "Achievement", "forms": { "past": "sold", "gerund": "selling" } },
    { "lemma": "Separate", "class": "Achievement", "regular": true },
    { "lemma": "Serve", "class": "Activity", "regular": true },
    { "lemma": "Settle", "class": "Achievement", "regular": true },
    { "lemma": "Sew", "class": "Activity", "forms": { "past": "sewed", "participle": "sewn", "gerund": "sewing" } },
    { "lemma": "Shape", "class": "Accomplishment", "regular": true },
    { "lemma": "Share", "class": "Activity", "regular": true },
    { "lemma": "Shelter", "class": "Activity", "regular": true },
    { "lemma": "Shift", "class": "Achievement", "regular": true },
    { "lemma": "Shine", "class": "Activity", "forms": { "past": "shone", "gerund": "shining" } },
    { "lemma": "Ship", "class": "Achievement", "forms": { "past": "shipped", "gerund": "shipping" } },
    { "lemma": "Shock", "class": "Achievement", "regular": true },
    { "lemma": "Shop", "class": "Activity", "forms": { "past": "shopped", "gerund": "shopping" } },
    { "lemma": "Shorten", "class": "Achievement", "regular": true },
    { "lemma": "Shout", "class": "Activity", "regular": true },
    { "lemma": "Shove", "class": "Activity", "regular": true },
    { "lemma": "Shrink", "class": "Achievement", "forms": { "past": "shrank", "participle": "shrunk", "gerund": "shrinking" } },
    { "lemma": "Shrug", "class": "Activity", "forms": { "past": "shrugged", "gerund": "shrugging" } },
    { "lemma": "Shut", "class": "Achievement", "forms": { "past": "shut", "gerund": "shutting" } },
    { "lemma": "Sign", "class": "Achievement", "regular": true },
    { "lemma": "Signal", "class": "Activity", "regular": true },
    { "lemma": "Simplify", "class": "Achievement", "forms": { "past": "simplified", "gerund": "simplifying" } },
    { "lemma": "Sing", "class": "Activity", "forms": { "past": "sang", "participle": "sung", "gerund": "singing" } },
    { "lemma": "Sink", "class": "Achievement", "forms": { "past": "sank", "participle": "sunk", "gerund": "sinking" } },
    { "lemma": "Sit", "class": "State", "forms": { "past": "sat", "gerund": "sitting" } },
    { "lemma": "Sketch", "class": "Activity", "regular": true },
    { "lemma": "Ski", "class": "Activity", "regular": true },
    { "lemma": "Skip", "class": "Activity", "forms": { "past": "skipped", "gerund": "skipping" } },
    { "lemma": "Slap", "class": "Activity", "forms": { "past": "slapped", "gerund": "slapping" } },
    { "lemma": "Slice", "class": "Activity", "regular": true },
    { "lemma": "Slide", "class": "Activity", "forms": { "past": "slid", "gerund": "sliding" } },
    { "lemma": "Slip", "class": "Achievement", "forms": { "past": "slipped", "gerund": "slipping" } },
    { "lemma": "Slow", "class": "Achievement", "regular": true },
    { "lemma": "Smash", "class": "Achievement", "regular": true },
    { "lemma": "Smell", "class": "State", "regular": true },
    { "lemma": "Smile", "class": "Activity", "regular": true },
    { "lemma": "Smoke", "class": "Activity", "regular": true },
    { "lemma": "Snap", "class": "Achievement", "forms": { "past": "snapped", "gerund": "snapping" } },
    { "lemma": "Sneeze", "class": "Activity", "regular": true },
    { "lemma": "Snow", "class": "Activity", "regular": true },
    { "lemma": "Soak", "class": "Activity", "regular": true },
    { "lemma": "Solve", "class": "Achievement", "regular": true },
    { "lemma": "Sort", "class": "Activity", "regular": true },
    { "lemma": "Sound", "class": "State", "regular": true },
    { "lemma": "Spare", "class": "Activity", "regular": true },
    { "lemma": "Spark", "class": "Achievement", "regular": true },
    { "lemma": "Specialize", "class": "Activity", "regular": true },
    { "lemma": "Specify", "class": "Activity", "forms": { "past": "specified", "gerund": "specifying" } },
    { "lemma": "Speed", "class": "Activity", "forms": { "past": "sped", "gerund": "speeding" } },
    { "lemma": "Spell", "class": "Activity", "forms": { "past": "spelt", "gerund": "spelling" } },
    { "lemma": "Spend", "class": "Accomplishment", "forms": { "past": "spent", "gerund": "spending" } },
    { "lemma": "Spill", "class": "Achievement", "forms": { "past": "spilt", "gerund": "spilling" } },
    { "lemma": "Spin", "class": "Activity", "forms": { "past": "spun", "gerund": "spinning" } },
    { "lemma": "Spit", "class": "Activity", "forms": { "past": "spat", "gerund": "spitting" } },
    { "lemma": "Split", "class": "Achievement", "forms": { "past": "split", "gerund": "splitting" } },
    { "lemma": "Spoil", "class": "Achievement", "forms": { "past": "spoilt", "gerund": "spoiling" } },
    { "lemma": "Sponsor", "class": "Activity", "regular": true },
    { "lemma": "Spot", "class": "Achievement", "forms": { "past": "spotted", "gerund": "spotting" } },
    { "lemma": "Spray", "class": "Activity", "regular": true },
    { "lemma": "Spread", "class": "Activity", "forms": { "past": "spread", "gerund": "spreading" } },
    { "lemma": "Spring", "class": "Achievement", "forms": { "past": "sprang", "participle": "sprung", "gerund": "springing" } },
    { "lemma": "Squeeze", "class": "Activity", "regular": true },
    { "lemma": "Stab", "class": "Activity", "forms": { "past": "stabbed", "gerund": "stabbing" } },
    { "lemma": "Stain", "class": "Achievement", "regular": true },
    { "lemma": "Stamp", "class": "Activity", "regular": true },
    { "lemma": "Stand", "class": "State", "forms": { "past": "stood", "gerund": "standing" } },
    { "lemma": "Stare", "class": "Activity", "regular": true },
    { "lemma": "Start", "class": "Achievement", "regular": true },
    { "lemma": "Starve", "class": "Accomplishment", "regular": true },
    { "lemma": "State", "class": "Activity", "regular": true },
    { "lemma": "Stay", "class": "State", "regular": true },
    { "lemma": "Stick", "class": "Achievement", "forms": { "past": "stuck", "gerund": "sticking" } },
    { "lemma": "Stimulate", "class": "Achievement", "regular": true },
    { "lemma": "Stir", "class": "Activity", "forms": { "past": "stirred", "gerund": "stirring" } },
    { "lemma": "Stop", "class": "Achievement", "forms": { "past": "stopped", "gerund": "stopping" } },
    { "lemma": "Store", "class": "Achievement", "regular": true },
    { "lemma": "Strain", "class": "Activity", "regular": true },
    { "lemma": "Strengthen", "class": "Achievement", "regular": true },
    { "lemma": "Stress", "class": "Activity", "regular": true },
    { "lemma": "Stretch", "class": "Activity", "regular": true },
    { "lemma": "Strike", "class": "Achievement", "forms": { "past": "struck", "gerund": "striking" } },
    { "lemma": "Strip", "class": "Achievement", "forms": { "past": "stripped", "gerund": "stripping" } },
    { "lemma": "Strive", "class": "Activity", "forms": { "past": "strove", "participle": "striven", "gerund": "striving" } },
    { "lemma": "Stroke", "class": "Activity", "regular": true },
    { "lemma": "Struggle", "class": "Activity", "regular": true },
    { "lemma": "Study", "class": "Activity", "forms": { "past": "studied", "gerund": "studying" } },
    { "lemma": "Stuff", "class": "Achievement", "regular": true },
    { "lemma": "Submit", "class": "Achievement", "forms": { "past": "submitted", "gerund": "submitting" } },
    { "lemma": "Substitute", "class": "Achievement", "regular": true },
    { "lemma": "Succeed", "class": "Achievement", "regular": true },
    { "lemma": "Suck", "class": "Activity", "regular": true },
    { "lemma": "Suffer", "class": "Activity", "regular": true },
    { "lemma": "Suggest", "class": "Activity", "regular": true },
    { "lemma": "Suit", "class": "State", "regular": true },
    { "lemma": "Summarize", "class": "Activity", "regular": true },
    { "lemma": "Supervise", "class": "Activity", "regular": true },
    { "lemma": "Supply", "class": "Achievement", "forms": { "past": "supplied", "gerund": "supplying" } },
    { "lemma": "Support", "class": "Activity", "regular": true },
    { "lemma": "Suppose", "class": "State", "regular": true },
    { "lemma": "Suppress", "class": "Achievement", "regular": true },
    { "lemma": "Surf", "class": "Activity", "regular": true },
    { "lemma": "Surprise", "class": "Achievement", "regular": true },
    { "lemma": "Surround", "class": "State", "regular": true },
    { "lemma": "Survey", "class": "Activity", "regular": true },
    { "lemma": "Survive", "class": "Achievement", "regular": true },
    { "lemma": "Suspect", "class": "State", "regular": true },
    { "lemma": "Suspend", "class": "Achievement", "regular": true },
    { "lemma": "Sustain", "class": "Activity", "regular": true },
    { "lemma": "Swallow", "class": "Achievement", "regular": true },
    { "lemma": "Swap", "class": "Achievement", "forms": { "past": "swapped", "gerund": "swapping" } },
    { "lemma": "Swear", "class": "Activity", "forms": { "past": "swore", "participle": "sworn", "gerund": "swearing" } },
    { "lemma": "Sweat", "class": "Activity", "regular": true },
    { "lemma": "Sweep", "class": "Activity", "forms": { "past": "swept", "gerund": "sweeping" } },
    { "lemma": "Swell", "class": "Achievement", "forms": { "past": "swelled", "participle": "swollen", "gerund": "swelling" } },
    { "lemma": "Swim", "class": "Activity", "forms": { "past": "swam", "participle": "swum", "gerund": "swimming" } },
    { "lemma": "Swing", "class": "Activity", "forms": { "past": "swung", "gerund": "swinging" } },
    { "lemma": "Switch", "class": "Achievement", "regular": true },
    { "lemma": "Tackle", "class": "Activity", "regular": true },
    { "lemma": "Tag", "class": "Activity", "forms": { "past": "tagged", "gerund": "tagging" } },
    { "lemma": "Talk", "class": "Activity", "regular": true },
    { "lemma": "Tame", "class": "Achievement", "regular": true },
    { "lemma": "Tap", "class": "Activity", "forms": { "past": "tapped", "gerund": "tapping" } },
    { "lemma": "Target", "class": "Activity", "regular": true },
    { "lemma": "Taste", "class": "State", "regular": true },
    { "lemma": "Tax", "class": "Activity", "regular": true },
    { "lemma": "Teach", "class": "Activity", "forms": { "past": "taught", "gerund": "teaching" } },
    { "lemma": "Tear", "class": "Achievement", "forms": { "past": "tore", "participle": "torn", "gerund": "tearing" } },
    { "lemma": "Tease", "class": "Activity", "regular": true },
    { "lemma": "Telephone", "class": "Activity", "regular": true },
    { "lemma": "Tempt", "class": "Activity", "regular": true },
    { "lemma": "Tend", "class": "State", "regular": true },
    { "lemma": "Terminate", "class": "Achievement", "regular": true },
    { "lemma": "Terrify", "class": "Achievement", "forms": { "past": "terrified", "gerund": "terrifying" } },
    { "lemma": "Test", "class": "Activity", "regular": true },
    { "lemma": "Testify", "class": "Activity", "forms": { "past": "testified", "gerund": "testifying" } },
    { "lemma": "Text", "class": "Activity", "regular": true },
    { "lemma": "Thank", "class": "Activity", "regular": true },
    { "lemma": "Threaten", "class": "Activity", "regular": true },
    { "lemma": "Thrill", "class": "Achievement", "regular": true },
    { "lemma": "Tick", "class": "Activity", "regular": true },
    { "lemma": "Tie", "class": "Achievement", "forms": { "past": "tied", "gerund": "tying" } },
    { "lemma": "Tighten", "class": "Achievement", "regular": true },
    { "lemma": "Tip", "class": "Activity", "forms": { "past": "tipped", "gerund": "tipping" } },
    { "lemma": "Tire", "class": "Achievement", "regular": true },
    { "lemma": "Toast", "class": "Activity", "regular": true },
    { "lemma": "Tolerate", "class": "State", "regular": true },
    { "lemma": "Top", "class": "Achievement", "forms": { "past": "topped", "gerund": "topping" } },
    { "lemma": "Toss", "class": "Activity", "regular": true },
    { "lemma": "Touch", "class": "Activity", "regular": true },
    { "lemma": "Tour", "class": "Activity", "regular": true },
    { "lemma": "Tow", "class": "Activity", "regular": true },
    { "lemma": "Trace", "class": "Activity", "regular": true },
    { "lemma": "Track", "class": "Activity", "regular": true },
    { "lemma": "Trade", "class": "Activity", "regular": true },
    { "lemma": "Train", "class": "Accomplishment", "regular": true },
    { "lemma": "Transfer", "class": "Achievement", "forms": { "past": "transferred", "gerund": "transferring" } },
    { "lemma": "Transform", "class": "Achievement", "regular": true },
    { "lemma": "Translate", "class": "Accomplishment", "regular": true },
    { "lemma": "Transmit", "class": "Activity", "forms": { "past": "transmitted", "gerund": "transmitting" } },
    { "lemma": "Transport", "class": "Activity", "regular": true },
    { "lemma": "Trap", "class": "Achievement", "forms": { "past": "trapped", "gerund": "trapping" } },
    { "lemma": "Travel", "class": "Activity", "regular": true },
    { "lemma": "Treasure", "class": "State", "regular": true },
    { "lemma": "Treat", "class": "Activity", "regular": true },
    { "lemma": "Trick", "class": "Activity", "regular": true },
    { "lemma": "Trigger", "class": "Achievement", "regular": true },
    { "lemma": "Trim", "class": "Activity", "forms": { "past": "trimmed", "gerund": "trimming" } },
    { "lemma": "Trip", "class": "Achievement", "forms": { "past": "tripped", "gerund": "tripping" } },
    { "lemma": "Trouble", "class": "Achievement", "regular": true },
    { "lemma": "Trust", "class": "State", "regular": true },
    { "lemma": "Try", "class": "Activity", "forms": { "past": "tried", "gerund": "trying" } },
    { "lemma": "Tune", "class": "Activity", "regular": true },
    { "lemma": "Turn", "class": "Achievement", "regular": true },
    { "lemma": "Twist", "class": "Achievement", "regular": true },
    { "lemma": "Type", "class": "Activity", "regular": true },
    { "lemma": "Undergo", "class": "Activity", "forms": { "past": "underwent", "participle": "undergone", "gerund": "undergoing" } },
    { "lemma": "Understand", "class": "State", "forms": { "past": "understood", "gerund": "understanding" } },
    { "lemma": "Undertake", "class": "Achievement", "forms": { "past": "undertook", "participle": "undertaken", "gerund": "undertaking" } },
    { "lemma": "Undo", "class": "Achievement", "forms": { "past": "undid", "participle": "undone", "gerund": "undoing" } },
    { "lemma": "Unfold", "class": "Accomplishment", "regular": true },
    { "lemma": "Unify", "class": "Achievement", "forms": { "past": "unified", "gerund": "unifying" } },
    { "lemma": "Unlock", "class": "Achievement", "regular": true },
    { "lemma": "Unpack", "class": "Activity", "regular": true },
    { "lemma": "Update", "class": "Achievement", "regular": true },
    { "lemma": "Upgrade", "class": "Achievement", "regular": true },
    { "lemma": "Upload", "class": "Achievement", "regular": true },
    { "lemma": "Urge", "class": "Activity", "regular": true },
    { "lemma": "Use", "class": "Activity", "regular": true },
    { "lemma": "Utilize", "class": "Activity", "regular": true },
    { "lemma": "Value", "class": "State", "regular": true },
    { "lemma": "Vanish", "class": "Achievement", "regular": true },
    { "lemma": "Vary", "class": "State", "forms": { "past": "varied", "gerund": "varying" } },
    { "lemma": "Venture", "class": "Activity", "regular": true },
    { "lemma": "Verify", "class": "Achievement", "forms": { "past": "verified", "gerund": "verifying" } },
    { "lemma": "View", "class": "Activity", "regular": true },
    { "lemma": "Violate", "class": "Achievement", "regular": true },
    { "lemma": "Visit", "class": "Activity", "regular": true },
    { "lemma": "Voice", "class": "Activity", "regular": true },
    { "lemma": "Volunteer", "class": "Activity", "regular": true },
    { "lemma": "Vote", "class": "Activity", "regular": true },
    { "lemma": "Wander", "class": "Activity", "regular": true },
    { "lemma": "Wanna", "class": "State", "regular": true },
    { "lemma": "Want", "class": "State", "regular": true },
    { "lemma": "Warm", "class": "Achievement", "regular": true },
    { "lemma": "Warn", "class": "Activity", "regular": true },
    { "lemma": "Wash", "class": "Accomplishment", "regular": true },
    { "lemma": "Waste", "class": "Accomplishment", "regular": true },
    { "lemma": "Watch", "class": "Activity", "regular": true },
    { "lemma": "Water", "class": "Activity", "regular": true },
    { "lemma": "Wave", "class": "Activity", "regular": true },
    { "lemma": "Weaken", "class": "Achievement", "regular": true },
    { "lemma": "Weave", "class": "Activity", "forms": { "past": "wove", "participle": "woven", "gerund": "weaving" } },
    { "lemma": "Weigh", "class": "State", "regular": true },
    { "lemma": "Welcome", "class": "Activity", "regular": true },
    { "lemma": "Whisper", "class": "Activity", "regular": true },
    { "lemma": "Whistle", "class": "Activity", "regular": true },
    { "lemma": "Widen", "class": "Achievement", "regular": true },
    { "lemma": "Win", "class": "Achievement", "forms": { "past": "won", "gerund": "winning" } },
    { "lemma": "Wind", "class": "Activity", "forms": { "past": "wound", "gerund": "winding" } },
    { "lemma": "Wink", "class": "Activity", "regular": true },
    { "lemma": "Wipe", "class": "Activity", "regular": true },
    { "lemma": "Wish", "class": "State", "regular": true },
    { "lemma": "Withdraw", "class": "Achievement", "forms": { "past": "withdrew", "participle": "withdrawn", "gerund": "withdrawing" } },
    { "lemma": "Witness", "class": "Activity", "regular": true },
    { "lemma": "Work", "class": "Activity", "regular": true },
    { "lemma": "Worry", "class": "State", "forms": { "past": "worried", "gerund": "worrying" } },
    { "lemma": "Worship", "class": "Activity", "regular": true },
    { "lemma": "Wound", "class": "Achievement", "regular": true },
    { "lemma": "Wrap", "class": "Achievement", "forms": { "past": "wrapped", "gerund": "wrapping" } },
    { "lemma": "Wreck", "class": "Achievement", "regular": true },
    { "lemma": "Wrestle", "class": "Activity", "regular": true },
    { "lemma": "Wring", "class": "Activity", "forms": { "past": "wrung", "gerund": "wringing" } },
    { "lemma": "Yawn", "class": "Activity", "regular": true },
    { "lemma": "Yell", "class": "Activity", "regular": true },
    { "lemma": "Yield", "class": "Achievement", "regular": true },
    { "lemma": "Zip", "class": "Achievement", "forms": { "past": "zipped", "gerund": "zipping" } },
    { "lemma": "Zone", "class": "Activity", "regular": true }
  ],
  "nouns": [
    { "lemma": "Man", "forms": { "plural": "men" }, "features": ["Masculine"], "sort": "Human" },
    { "lemma": "Woman", "forms": { "plural": "women" }, "features": ["Feminine"], "sort": "Human" },
    { "lemma": "Child", "forms": { "plural": "children" }, "sort": "Human" },
    { "lemma": "Person", "forms": { "plural": "people" }, "sort": "Human" },
    { "lemma": "Mouse", "forms": { "plural": "mice" } },
    { "lemma": "Tooth", "forms": { "plural": "teeth" } },
    { "lemma": "Foot", "forms": { "plural": "feet" } },
    { "lemma": "Goose", "forms": { "plural": "geese" } },
    { "lemma": "Fish", "forms": { "plural": "fish" } },
    { "lemma": "Deer", "forms": { "plural": "deer" } },
    { "lemma": "Sheep", "forms": { "plural": "sheep" } },
    { "lemma": "Species", "forms": { "plural": "species" } },
    { "lemma": "Series", "forms": { "plural": "series" } },
    { "lemma": "Car", "sort": "Physical" },
    { "lemma": "Engine", "sort": "Physical" },
    { "lemma": "Wheel", "sort": "Physical" },
    { "lemma": "Door", "sort": "Physical" },
    { "lemma": "Alarm", "sort": "Physical" },
    { "lemma": "Window", "sort": "Physical" },
    { "lemma": "Tire", "sort": "Physical" },
    { "lemma": "House", "sort": "Physical" },
    { "lemma": "Roof", "sort": "Physical" },
    { "lemma": "Room", "sort": "Physical" },
    { "lemma": "Wall", "sort": "Physical" },
    { "lemma": "Floor", "sort": "Physical" },
    { "lemma": "Ceiling", "sort": "Physical" },
    { "lemma": "Bike", "sort": "Physical" },
    { "lemma": "Pedal", "sort": "Physical" },
    { "lemma": "Chain", "sort": "Physical" },
    { "lemma": "Seat", "sort": "Physical" },
    { "lemma": "Rock", "sort": "Physical", "features": ["Inanimate"] },
    { "lemma": "Stone", "sort": "Physical", "features": ["Inanimate"] },
    { "lemma": "John", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "James", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Bob", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Bill", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Tom", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Mike", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "David", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Peter", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Paul", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Jack", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Joe", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Jim", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Steve", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Mark", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Chris", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Dan", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Sam", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Alex", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Romeo", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Mary", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Jane", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Susan", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Sarah", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Alice", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Lisa", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Anna", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Emily", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Emma", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Kate", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Amy", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Lucy", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Rachel", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Laura", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Helen", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Nancy", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Betty", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Juliet", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Boy", "features": ["Masculine"], "sort": "Human" },
    { "lemma": "King", "features": ["Masculine"], "sort": "Human" },
    { "lemma": "Prince", "features": ["Masculine"], "sort": "Human" },
    { "lemma": "Father", "features": ["Masculine"], "sort": "Human" },
    { "lemma": "Brother", "features": ["Masculine"], "sort": "Human" },
    { "lemma": "Son", "features": ["Masculine"], "sort": "Human" },
    { "lemma": "Husband", "features": ["Masculine"], "sort": "Human" },
    { "lemma": "Actor", "features": ["Masculine"], "sort": "Human" },
    { "lemma": "Waiter", "features": ["Masculine"], "sort": "Human" },
    { "lemma": "Girl", "features": ["Feminine"], "sort": "Human" },
    { "lemma": "Queen", "features": ["Feminine"], "sort": "Human" },
    { "lemma": "Princess", "features": ["Feminine"], "sort": "Human" },
    { "lemma": "Mother", "features": ["Feminine"], "sort": "Human" },
    { "lemma": "Sister", "features": ["Feminine"], "sort": "Human" },
    { "lemma": "Daughter", "features": ["Feminine"], "sort": "Human" },
    { "lemma": "Wife", "features": ["Feminine"], "sort": "Human" },
    { "lemma": "Actress", "features": ["Feminine"], "sort": "Human" },
    { "lemma": "Waitress", "features": ["Feminine"], "sort": "Human" },
    { "lemma": "Ring" }, { "lemma": "Thing" }, { "lemma": "Spring" }, { "lemma": "String" },
    { "lemma": "Swing" }, { "lemma": "Wing" }, { "lemma": "Bus" }, { "lemma": "Gas" },
    { "lemma": "Focus" }, { "lemma": "Campus" }, { "lemma": "Status" }, { "lemma": "Bonus" },
    { "lemma": "Set", "forms": { "plural": "sets" } },
    { "lemma": "Cardinality" },
    { "lemma": "Dog", "sort": "Animate" }, { "lemma": "Cat", "sort": "Animate" }, { "lemma": "Bird", "sort": "Animate" }, { "lemma": "Student", "sort": "Human" },
    { "lemma": "Hunter", "sort": "Human", "derivation": { "root": "Hunt", "pos": "Verb", "relation": "Agent" } },
    { "lemma": "Book", "sort": "Information" }, { "lemma": "Code" },
    { "lemma": "User", "sort": "Human" }, { "lemma": "Logic", "sort": "Abstract" }, { "lemma": "Time", "sort": "Abstract" }, { "lemma": "Letter" },
    { "lemma": "Logician", "sort": "Human" }, { "lemma": "Philosopher", "sort": "Human" },
    { "lemma": "Teacher", "sort": "Human", "derivation": { "root": "Teach", "pos": "Verb", "relation": "Agent" } },
    { "lemma": "Writer", "sort": "Human", "derivation": { "root": "Write", "pos": "Verb", "relation": "Agent" } },
    { "lemma": "Athlete", "sort": "Human" }, { "lemma": "World" }, { "lemma": "Unicorn", "sort": "Animate" }, { "lemma": "Toast", "sort": "Physical" },
    { "lemma": "Bathroom", "sort": "Place" }, { "lemma": "Knife", "sort": "Physical" }, { "lemma": "Gun", "sort": "Physical" }, { "lemma": "Thief", "sort": "Human" },
    { "lemma": "Senator", "sort": "Human" }, { "lemma": "Ball", "sort": "Physical" }, { "lemma": "President", "sort": "Human" }, { "lemma": "Hero", "sort": "Human" },
    { "lemma": "Friend", "sort": "Human" }, { "lemma": "Story", "sort": "Information" }, { "lemma": "Horse", "sort": "Animate" }, { "lemma": "Water", "sort": "Physical" },
    { "lemma": "Money", "sort": "Value" }, { "lemma": "Apple", "sort": "Physical" }, { "lemma": "Rat", "sort": "Animate" }, { "lemma": "Tail", "sort": "Physical" },
    { "lemma": "Key", "sort": "Physical" }, { "lemma": "Glass", "sort": "Physical" }, { "lemma": "Ice", "sort": "Physical" },
    { "lemma": "Sun", "sort": "Celestial" }, { "lemma": "Moon", "sort": "Celestial" }, { "lemma": "Star", "sort": "Celestial" },
    { "lemma": "Justice", "sort": "Abstract" }, { "lemma": "Love", "sort": "Abstract" },
    { "lemma": "Team", "features": ["Collective"], "sort": "Group" }, { "lemma": "Army", "features": ["Collective"], "sort": "Group" },
    { "lemma": "Animal", "sort": "Animate" },
    { "lemma": "Duck", "sort": "Animate" }, { "lemma": "Donkey", "features": ["Neuter"], "sort": "Animate" },
    { "lemma": "Elephant", "sort": "Animate" }, { "lemma": "Lion", "sort": "Animate" }, { "lemma": "Tiger", "sort": "Animate" },
    { "lemma": "Bear", "sort": "Animate" }, { "lemma": "Wolf", "forms": { "plural": "wolves" }, "sort": "Animate" },
    { "lemma": "Fox", "forms": { "plural": "foxes" }, "sort": "Animate" }, { "lemma": "Rabbit", "sort": "Animate" },
    { "lemma": "Cow", "sort": "Animate" }, { "lemma": "Pig", "sort": "Animate" }, { "lemma": "Chicken", "sort": "Animate" },
    { "lemma": "Frog", "sort": "Animate" }, { "lemma": "Snake", "sort": "Animate" }, { "lemma": "Turtle", "sort": "Animate" },
    { "lemma": "Whale", "sort": "Animate" }, { "lemma": "Shark", "sort": "Animate" }, { "lemma": "Dolphin", "sort": "Animate" },
    { "lemma": "Eagle", "sort": "Animate" }, { "lemma": "Owl", "sort": "Animate" }, { "lemma": "Crow", "sort": "Animate" },
    { "lemma": "Bee", "sort": "Animate" }, { "lemma": "Butterfly", "forms": { "plural": "butterflies" }, "sort": "Animate" },
    { "lemma": "Spider", "sort": "Animate" }, { "lemma": "Ant", "sort": "Animate" }, { "lemma": "Monkey", "sort": "Animate" },
    { "lemma": "Gorilla", "sort": "Animate" }, { "lemma": "Zebra", "sort": "Animate" }, { "lemma": "Giraffe", "sort": "Animate" },
    { "lemma": "Crocodile", "sort": "Animate" }, { "lemma": "Penguin", "sort": "Animate" }, { "lemma": "Parrot", "sort": "Animate" },
    { "lemma": "Table", "sort": "Physical" }, { "lemma": "Chair", "sort": "Physical" }, { "lemma": "Desk", "sort": "Physical" },
    { "lemma": "Bed", "sort": "Physical" }, { "lemma": "Couch", "sort": "Physical" }, { "lemma": "Lamp", "sort": "Physical" },
    { "lemma": "Mirror", "sort": "Physical" }, { "lemma": "Shelf", "forms": { "plural": "shelves" }, "sort": "Physical" },
    { "lemma": "Cabinet", "sort": "Physical" }, { "lemma": "Drawer", "sort": "Physical" }, { "lemma": "Closet", "sort": "Physical" },
    { "lemma": "Phone", "sort": "Physical" }, { "lemma": "Computer", "sort": "Physical" }, { "lemma": "Laptop", "sort": "Physical" },
    { "lemma": "Keyboard", "sort": "Physical" }, { "lemma": "Screen", "sort": "Physical" }, { "lemma": "Camera", "sort": "Physical" },
    { "lemma": "Television", "sort": "Physical" }, { "lemma": "Radio", "sort": "Physical" }, { "lemma": "Speaker", "sort": "Physical" },
    { "lemma": "Microphone", "sort": "Physical" }, { "lemma": "Headphone", "sort": "Physical" }, { "lemma": "Battery", "sort": "Physical" },
    { "lemma": "Bread", "sort": "Physical" }, { "lemma": "Butter", "sort": "Physical" }, { "lemma": "Cheese", "sort": "Physical" },
    { "lemma": "Milk", "sort": "Physical" }, { "lemma": "Egg", "sort": "Physical" }, { "lemma": "Meat", "sort": "Physical" },
    { "lemma": "Rice", "sort": "Physical" }, { "lemma": "Pasta", "sort": "Physical" }, { "lemma": "Soup", "sort": "Physical" },
    { "lemma": "Salad", "sort": "Physical" }, { "lemma": "Cake", "sort": "Physical" }, { "lemma": "Cookie", "sort": "Physical" },
    { "lemma": "Candy", "sort": "Physical" }, { "lemma": "Fruit", "sort": "Physical" }, { "lemma": "Vegetable", "sort": "Physical" },
    { "lemma": "Orange", "sort": "Physical" }, { "lemma": "Banana", "sort": "Physical" }, { "lemma": "Grape", "sort": "Physical" },
    { "lemma": "Strawberry", "forms": { "plural": "strawberries" }, "sort": "Physical" }, { "lemma": "Lemon", "sort": "Physical" },
    { "lemma": "Tomato", "forms": { "plural": "tomatoes" }, "sort": "Physical" }, { "lemma": "Potato", "forms": { "plural": "potatoes" }, "sort": "Physical" },
    { "lemma": "Carrot", "sort": "Physical" }, { "lemma": "Onion", "sort": "Physical" }, { "lemma": "Pepper", "sort": "Physical" },
    { "lemma": "Coffee", "sort": "Physical" }, { "lemma": "Tea", "sort": "Physical" }, { "lemma": "Juice", "sort": "Physical" },
    { "lemma": "Wine", "sort": "Physical" }, { "lemma": "Beer", "sort": "Physical" }, { "lemma": "Soda", "sort": "Physical" },
    { "lemma": "Shirt", "sort": "Physical" }, { "lemma": "Pants", "sort": "Physical" }, { "lemma": "Dress", "sort": "Physical" },
    { "lemma": "Skirt", "sort": "Physical" }, { "lemma": "Jacket", "sort": "Physical" }, { "lemma": "Coat", "sort": "Physical" },
    { "lemma": "Sweater", "sort": "Physical" }, { "lemma": "Shoe", "sort": "Physical" }, { "lemma": "Boot", "sort": "Physical" },
    { "lemma": "Sock", "sort": "Physical" }, { "lemma": "Hat", "sort": "Physical" }, { "lemma": "Glove", "sort": "Physical" },
    { "lemma": "Scarf", "forms": { "plural": "scarves" }, "sort": "Physical" }, { "lemma": "Belt", "sort": "Physical" },
    { "lemma": "Watch", "sort": "Physical" }, { "lemma": "Necklace", "sort": "Physical" }, { "lemma": "Bracelet", "sort": "Physical" },
    { "lemma": "Tree", "sort": "Physical" }, { "lemma": "Flower", "sort": "Physical" }, { "lemma": "Grass", "sort": "Physical" },
    { "lemma": "Leaf", "forms": { "plural": "leaves" }, "sort": "Physical" }, { "lemma": "Branch", "sort": "Physical" },
    { "lemma": "Root", "sort": "Physical" }, { "lemma": "Seed", "sort": "Physical" }, { "lemma": "Plant", "sort": "Physical" },
    { "lemma": "Forest", "sort": "Place" }, { "lemma": "Garden", "sort": "Place" }, { "lemma": "Park", "sort": "Place" },
    { "lemma": "Mountain", "sort": "Physical" }, { "lemma": "Hill", "sort": "Physical" }, { "lemma": "Valley", "sort": "Physical" },
    { "lemma": "River", "sort": "Physical" }, { "lemma": "Lake", "sort": "Physical" }, { "lemma": "Ocean", "sort": "Physical" },
    { "lemma": "Sea", "sort": "Physical" }, { "lemma": "Beach", "sort": "Place" }, { "lemma": "Island", "sort": "Physical" },
    { "lemma": "Desert", "sort": "Physical" }, { "lemma": "Cave", "sort": "Physical" }, { "lemma": "Cliff", "sort": "Physical" },
    { "lemma": "City", "forms": { "plural": "cities" }, "sort": "Place" }, { "lemma": "Town", "sort": "Place" },
    { "lemma": "Village", "sort": "Place" }, { "lemma": "Country", "forms": { "plural": "countries" }, "sort": "Place" },
    { "lemma": "Street", "sort": "Place" }, { "lemma": "Road", "sort": "Physical" }, { "lemma": "Bridge", "sort": "Physical" },
    { "lemma": "Building", "sort": "Physical" }, { "lemma": "Tower", "sort": "Physical" }, { "lemma": "Castle", "sort": "Physical" },
    { "lemma": "Church", "sort": "Physical" }, { "lemma": "Temple", "sort": "Physical" }, { "lemma": "School", "sort": "Place" },
    { "lemma": "Hospital", "sort": "Place" }, { "lemma": "Library", "forms": { "plural": "libraries" }, "sort": "Place" },
    { "lemma": "Museum", "sort": "Place" }, { "lemma": "Theater", "sort": "Place" }, { "lemma": "Restaurant", "sort": "Place" },
    { "lemma": "Hotel", "sort": "Place" }, { "lemma": "Airport", "sort": "Place" }, { "lemma": "Station", "sort": "Place" },
    { "lemma": "Store", "sort": "Place" }, { "lemma": "Shop", "sort": "Place" }, { "lemma": "Market", "sort": "Place" },
    { "lemma": "Office", "sort": "Place" }, { "lemma": "Factory", "forms": { "plural": "factories" }, "sort": "Place" },
    { "lemma": "Bank", "sort": "Place" }, { "lemma": "Prison", "sort": "Place" }, { "lemma": "Court", "sort": "Place" },
    { "lemma": "Doctor", "sort": "Human" }, { "lemma": "Nurse", "sort": "Human" }, { "lemma": "Lawyer", "sort": "Human" },
    { "lemma": "Judge", "sort": "Human" }, { "lemma": "Police", "sort": "Human" }, { "lemma": "Soldier", "sort": "Human" },
    { "lemma": "Farmer", "sort": "Human", "derivation": { "root": "Farm", "pos": "Verb", "relation": "Agent" } },
    { "lemma": "Merchant", "sort": "Human" }, { "lemma": "Chef", "sort": "Human" }, { "lemma": "Artist", "sort": "Human" },
    { "lemma": "Musician", "sort": "Human" }, { "lemma": "Engineer", "sort": "Human" },
    { "lemma": "Scientist", "sort": "Human", "derivation": { "root": "Science", "pos": "Noun", "relation": "Practitioner" } },
    { "lemma": "Pilot", "sort": "Human" },
    { "lemma": "Driver", "sort": "Human", "derivation": { "root": "Drive", "pos": "Verb", "relation": "Agent" } },
    { "lemma": "Manager", "sort": "Human", "derivation": { "root": "Manage", "pos": "Verb", "relation": "Agent" } },
    { "lemma": "Boss", "sort": "Human" }, { "lemma": "Employee", "sort": "Human" }, { "lemma": "Customer", "sort": "Human" },
    { "lemma": "Guest", "sort": "Human" }, { "lemma": "Neighbor", "sort": "Human" }, { "lemma": "Stranger", "sort": "Human" },
    { "lemma": "Baby", "forms": { "plural": "babies" }, "sort": "Human" }, { "lemma": "Teenager", "sort": "Human" },
    { "lemma": "Adult", "sort": "Human" }, { "lemma": "Elder", "sort": "Human" }, { "lemma": "Citizen", "sort": "Human" },
    { "lemma": "Leader", "sort": "Human", "derivation": { "root": "Lead", "pos": "Verb", "relation": "Agent" } },
    { "lemma": "Follower", "sort": "Human", "derivation": { "root": "Follow", "pos": "Verb", "relation": "Agent" } },
    { "lemma": "Winner", "sort": "Human", "derivation": { "root": "Win", "pos": "Verb", "relation": "Agent" } },
    { "lemma": "Player", "sort": "Human", "derivation": { "root": "Play", "pos": "Verb", "relation": "Agent" } },
    { "lemma": "Loser", "sort": "Human", "derivation": { "root": "Lose", "pos": "Verb", "relation": "Agent" } },
    { "lemma": "Victim", "sort": "Human" },
    { "lemma": "Survivor", "sort": "Human", "derivation": { "root": "Survive", "pos": "Verb", "relation": "Agent" } },
    { "lemma": "Prisoner", "sort": "Human" }, { "lemma": "Criminal", "sort": "Human" },
    { "lemma": "Killer", "sort": "Human", "derivation": { "root": "Kill", "pos": "Verb", "relation": "Agent" } },
    { "lemma": "Dancer", "sort": "Human", "derivation": { "root": "Dance", "pos": "Verb", "relation": "Agent" } },
    { "lemma": "Runner", "sort": "Human", "derivation": { "root": "Run", "pos": "Verb", "relation": "Agent" } },
    { "lemma": "Singer", "sort": "Human", "derivation": { "root": "Sing", "pos": "Verb", "relation": "Agent" } },
    { "lemma": "Speaker", "sort": "Human", "derivation": { "root": "Speak", "pos": "Verb", "relation": "Agent" } },
    { "lemma": "Worker", "sort": "Human", "derivation": { "root": "Work", "pos": "Verb", "relation": "Agent" } },
    { "lemma": "Swimmer", "sort": "Human", "derivation": { "root": "Swim", "pos": "Verb", "relation": "Agent" } },
    { "lemma": "Jumper", "sort": "Human", "derivation": { "root": "Jump", "pos": "Verb", "relation": "Agent" } },
    { "lemma": "Walker", "sort": "Human", "derivation": { "root": "Walk", "pos": "Verb", "relation": "Agent" } },
    { "lemma": "Thinker", "sort": "Human", "derivation": { "root": "Think", "pos": "Verb", "relation": "Agent" } },
    { "lemma": "Reader", "sort": "Human", "derivation": { "root": "Read", "pos": "Verb", "relation": "Agent" } },
    { "lemma": "Fighter", "sort": "Human", "derivation": { "root": "Fight", "pos": "Verb", "relation": "Agent" } },
    { "lemma": "Painter", "sort": "Human", "derivation": { "root": "Paint", "pos": "Verb", "relation": "Agent" } },
    { "lemma": "Builder", "sort": "Human", "derivation": { "root": "Build", "pos": "Verb", "relation": "Agent" } },
    { "lemma": "Baker", "sort": "Human", "derivation": { "root": "Bake", "pos": "Verb", "relation": "Agent" } },
    { "lemma": "Catcher", "sort": "Human", "derivation": { "root": "Catch", "pos": "Verb", "relation": "Agent" } },
    { "lemma": "Problem", "sort": "Abstract" }, { "lemma": "Solution", "sort": "Abstract" }, { "lemma": "Question", "sort": "Abstract" },
    { "lemma": "Answer", "sort": "Abstract" }, { "lemma": "Idea", "sort": "Abstract" }, { "lemma": "Thought", "sort": "Abstract" },
    { "lemma": "Dream", "sort": "Abstract" }, { "lemma": "Hope", "sort": "Abstract" }, { "lemma": "Fear", "sort": "Abstract" },
    { "lemma": "Anger", "sort": "Abstract" }, { "lemma": "Joy", "sort": "Abstract" }, { "lemma": "Happiness", "sort": "Abstract" },
    { "lemma": "Sadness", "sort": "Abstract" }, { "lemma": "Pain", "sort": "Abstract" }, { "lemma": "Pleasure", "sort": "Abstract" },
    { "lemma": "Truth", "sort": "Abstract" }, { "lemma": "Lie", "sort": "Abstract" }, { "lemma": "Secret", "sort": "Abstract" },
    { "lemma": "Mystery", "forms": { "plural": "mysteries" }, "sort": "Abstract" }, { "lemma": "Miracle", "sort": "Abstract" },
    { "lemma": "Chance", "sort": "Abstract" }, { "lemma": "Luck", "sort": "Abstract" }, { "lemma": "Fate", "sort": "Abstract" },
    { "lemma": "Destiny", "sort": "Abstract" }, { "lemma": "Freedom", "sort": "Abstract" }, { "lemma": "Peace", "sort": "Abstract" },
    { "lemma": "War", "sort": "Abstract" }, { "lemma": "Battle", "sort": "Abstract" }, { "lemma": "Victory", "sort": "Abstract" },
    { "lemma": "Defeat", "sort": "Abstract" }, { "lemma": "Success", "sort": "Abstract" }, { "lemma": "Failure", "sort": "Abstract" },
    { "lemma": "Power", "sort": "Abstract" }, { "lemma": "Strength", "sort": "Abstract" }, { "lemma": "Weakness", "sort": "Abstract" },
    { "lemma": "Knowledge", "sort": "Abstract" }, { "lemma": "Wisdom", "sort": "Abstract" }, { "lemma": "Intelligence", "sort": "Abstract" },
    { "lemma": "Memory", "forms": { "plural": "memories" }, "sort": "Abstract" }, { "lemma": "Experience", "sort": "Abstract" },
    { "lemma": "Skill", "sort": "Abstract" }, { "lemma": "Talent", "sort": "Abstract" }, { "lemma": "Ability", "sort": "Abstract" },
    { "lemma": "Art", "sort": "Abstract" }, { "lemma": "Music", "sort": "Abstract" }, { "lemma": "Dance", "sort": "Abstract" },
    { "lemma": "Song", "sort": "Abstract" }, { "lemma": "Poem", "sort": "Abstract" }, { "lemma": "Movie", "sort": "Abstract" },
    { "lemma": "Game", "sort": "Abstract" }, { "lemma": "Sport", "sort": "Abstract" }, { "lemma": "Race", "sort": "Abstract" },
    { "lemma": "Competition", "sort": "Abstract" }, { "lemma": "Prize", "sort": "Physical" }, { "lemma": "Award", "sort": "Physical" },
    { "lemma": "Gift", "sort": "Physical" }, { "lemma": "Reward", "sort": "Physical" }, { "lemma": "Punishment", "sort": "Abstract" },
    { "lemma": "Crime", "sort": "Abstract" }, { "lemma": "Law", "sort": "Abstract" }, { "lemma": "Rule", "sort": "Abstract" },
    { "lemma": "Right", "sort": "Abstract" }, { "lemma": "Wrong", "sort": "Abstract" }, { "lemma": "Duty", "sort": "Abstract" },
    { "lemma": "Responsibility", "sort": "Abstract" }, { "lemma": "Promise", "sort": "Abstract" }, { "lemma": "Agreement", "sort": "Abstract" },
    { "lemma": "Contract", "sort": "Abstract" }, { "lemma": "Deal", "sort": "Abstract" }, { "lemma": "Trade", "sort": "Abstract" },
    { "lemma": "Price", "sort": "Abstract" }, { "lemma": "Cost", "sort": "Abstract" }, { "lemma": "Value", "sort": "Abstract" },
    { "lemma": "Profit", "sort": "Abstract" }, { "lemma": "Loss", "sort": "Abstract" }, { "lemma": "Debt", "sort": "Abstract" },
    { "lemma": "Tax", "sort": "Abstract" }, { "lemma": "Income", "sort": "Abstract" }, { "lemma": "Salary", "sort": "Abstract" },
    { "lemma": "Wage", "sort": "Abstract" }, { "lemma": "Job", "sort": "Abstract" }, { "lemma": "Work", "sort": "Abstract" },
    { "lemma": "Career", "sort": "Abstract" }, { "lemma": "Business", "sort": "Abstract" }, { "lemma": "Company", "sort": "Group" },
    { "lemma": "Corporation", "sort": "Group" }, { "lemma": "Organization", "sort": "Group" }, { "lemma": "Government", "sort": "Group" },
    { "lemma": "Society", "sort": "Group" }, { "lemma": "Community", "sort": "Group" }, { "lemma": "Family", "sort": "Group" },
    { "lemma": "Class", "sort": "Group" }, { "lemma": "Group", "sort": "Group" }, { "lemma": "Crowd", "sort": "Group" },
    { "lemma": "Population", "sort": "Group" }, { "lemma": "Nation", "sort": "Group" }, { "lemma": "State", "sort": "Abstract" },
    { "lemma": "Region", "sort": "Place" }, { "lemma": "Area", "sort": "Place" }, { "lemma": "Zone", "sort": "Place" },
    { "lemma": "Space", "sort": "Abstract" }, { "lemma": "Place", "sort": "Place" }, { "lemma": "Position", "sort": "Abstract" },
    { "lemma": "Location", "sort": "Place" }, { "lemma": "Direction", "sort": "Abstract" }, { "lemma": "Distance", "sort": "Abstract" },
    { "lemma": "Height", "sort": "Abstract" }, { "lemma": "Width", "sort": "Abstract" }, { "lemma": "Depth", "sort": "Abstract" },
    { "lemma": "Length", "sort": "Abstract" }, { "lemma": "Size", "sort": "Abstract" }, { "lemma": "Shape", "sort": "Abstract" },
    { "lemma": "Form", "sort": "Abstract" }, { "lemma": "Color", "sort": "Abstract" }, { "lemma": "Sound", "sort": "Abstract" },
    { "lemma": "Smell", "sort": "Abstract" }, { "lemma": "Taste", "sort": "Abstract" }, { "lemma": "Touch", "sort": "Abstract" },
    { "lemma": "Feeling", "sort": "Abstract" }, { "lemma": "Emotion", "sort": "Abstract" }, { "lemma": "Mood", "sort": "Abstract" },
    { "lemma": "Spirit", "sort": "Abstract" }, { "lemma": "Soul", "sort": "Abstract" }, { "lemma": "Mind", "sort": "Abstract" },
    { "lemma": "Brain", "sort": "Physical" }, { "lemma": "Heart", "sort": "Physical" }, { "lemma": "Blood", "sort": "Physical" },
    { "lemma": "Bone", "sort": "Physical" }, { "lemma": "Muscle", "sort": "Physical" }, { "lemma": "Skin", "sort": "Physical" },
    { "lemma": "Hair", "sort": "Physical" }, { "lemma": "Eye", "sort": "Physical" }, { "lemma": "Ear", "sort": "Physical" },
    { "lemma": "Nose", "sort": "Physical" }, { "lemma": "Mouth", "sort": "Physical" }, { "lemma": "Tongue", "sort": "Physical" },
    { "lemma": "Lip", "sort": "Physical" }, { "lemma": "Face", "sort": "Physical" }, { "lemma": "Head", "sort": "Physical" },
    { "lemma": "Neck", "sort": "Physical" }, { "lemma": "Shoulder", "sort": "Physical" }, { "lemma": "Arm", "sort": "Physical" },
    { "lemma": "Hand", "sort": "Physical" }, { "lemma": "Finger", "sort": "Physical" }, { "lemma": "Thumb", "sort": "Physical" },
    { "lemma": "Leg", "sort": "Physical" }, { "lemma": "Knee", "sort": "Physical" }, { "lemma": "Back", "sort": "Physical" },
    { "lemma": "Stomach", "sort": "Physical" }, { "lemma": "Chest", "sort": "Physical" }, { "lemma": "Body", "sort": "Physical" },
    { "lemma": "Voice", "sort": "Abstract" }, { "lemma": "Word", "sort": "Abstract" }, { "lemma": "Sentence", "sort": "Abstract" },
    { "lemma": "Paragraph", "sort": "Abstract" }, { "lemma": "Page", "sort": "Physical" }, { "lemma": "Chapter", "sort": "Abstract" },
    { "lemma": "Text", "sort": "Abstract" }, { "lemma": "Message", "sort": "Abstract" }, { "lemma": "Letter", "sort": "Physical" },
    { "lemma": "Email", "sort": "Abstract" }, { "lemma": "Call", "sort": "Abstract" }, { "lemma": "Conversation", "sort": "Abstract" },
    { "lemma": "Discussion", "sort": "Abstract" }, { "lemma": "Debate", "sort": "Abstract" }, { "lemma": "Argument", "sort": "Abstract" },
    { "lemma": "Speech", "sort": "Abstract" }, { "lemma": "Language", "sort": "Abstract" }, { "lemma": "Grammar", "sort": "Abstract" },
    { "lemma": "Name", "sort": "Abstract" }, { "lemma": "Title", "sort": "Abstract" }, { "lemma": "Number", "sort": "Abstract" },
    { "lemma": "Amount", "sort": "Abstract" }, { "lemma": "Quantity", "sort": "Abstract" }, { "lemma": "Quality", "sort": "Abstract" },
    { "lemma": "Type", "sort": "Abstract" }, { "lemma": "Kind", "sort": "Abstract" }, { "lemma": "Sort", "sort": "Abstract" },
    { "lemma": "Part", "sort": "Abstract" }, { "lemma": "Piece", "sort": "Physical" }, { "lemma": "Half", "forms": { "plural": "halves" }, "sort": "Abstract" },
    { "lemma": "Whole", "sort": "Abstract" }, { "lemma": "Beginning", "sort": "Abstract" }, { "lemma": "End", "sort": "Abstract" },
    { "lemma": "Middle", "sort": "Abstract" }, { "lemma": "Edge", "sort": "Physical" }, { "lemma": "Corner", "sort": "Physical" },
    { "lemma": "Side", "sort": "Physical" }, { "lemma": "Top", "sort": "Physical" }, { "lemma": "Bottom", "sort": "Physical" },
    { "lemma": "Front", "sort": "Physical" }, { "lemma": "Center", "sort": "Physical" }, { "lemma": "Surface", "sort": "Physical" },
    { "lemma": "Line", "sort": "Abstract" }, { "lemma": "Circle", "sort": "Abstract" }, { "lemma": "Square", "sort": "Abstract" },
    { "lemma": "Triangle", "sort": "Abstract" }, { "lemma": "Point", "sort": "Abstract" }, { "lemma": "Angle", "sort": "Abstract" },
    { "lemma": "Curve", "sort": "Abstract" }, { "lemma": "Pattern", "sort": "Abstract" }, { "lemma": "Design", "sort": "Abstract" },
    { "lemma": "Structure", "sort": "Abstract" }, { "lemma": "System", "sort": "Abstract" }, { "lemma": "Method", "sort": "Abstract" },
    { "lemma": "Process", "sort": "Abstract" }, { "lemma": "Step", "sort": "Abstract" }, { "lemma": "Stage", "sort": "Abstract" },
    { "lemma": "Phase", "sort": "Abstract" }, { "lemma": "Level", "sort": "Abstract" }, { "lemma": "Degree", "sort": "Abstract" },
    { "lemma": "Measure", "sort": "Abstract" }, { "lemma": "Unit", "sort": "Abstract" }, { "lemma": "Standard", "sort": "Abstract" },
    { "lemma": "Limit", "sort": "Abstract" }, { "lemma": "Range", "sort": "Abstract" }, { "lemma": "Scale", "sort": "Abstract" },
    { "lemma": "Rate", "sort": "Abstract" }, { "lemma": "Speed", "sort": "Abstract" }, { "lemma": "Pace", "sort": "Abstract" },
    { "lemma": "Force", "sort": "Abstract" }, { "lemma": "Energy", "sort": "Abstract" }, { "lemma": "Heat", "sort": "Physical" },
    { "lemma": "Light", "sort": "Physical" }, { "lemma": "Shadow", "sort": "Physical" }, { "lemma": "Darkness", "sort": "Abstract" },
    { "lemma": "Fire", "sort": "Physical" }, { "lemma": "Flame", "sort": "Physical" }, { "lemma": "Smoke", "sort": "Physical" },
    { "lemma": "Ash", "sort": "Physical" }, { "lemma": "Dust", "sort": "Physical" }, { "lemma": "Dirt", "sort": "Physical" },
    { "lemma": "Mud", "sort": "Physical" }, { "lemma": "Sand", "sort": "Physical" }, { "lemma": "Clay", "sort": "Physical" },
    { "lemma": "Metal", "sort": "Physical" }, { "lemma": "Gold", "sort": "Physical" }, { "lemma": "Silver", "sort": "Physical" },
    { "lemma": "Iron", "sort": "Physical" }, { "lemma": "Steel", "sort": "Physical" }, { "lemma": "Copper", "sort": "Physical" },
    { "lemma": "Wood", "sort": "Physical" }, { "lemma": "Plastic", "sort": "Physical" }, { "lemma": "Paper", "features": ["Neuter"], "sort": "Physical" }, { "lemma": "Trophy", "features": ["Neuter"], "sort": "Physical" },
    { "lemma": "Cloth", "sort": "Physical" }, { "lemma": "Fabric", "sort": "Physical" }, { "lemma": "Thread", "sort": "Physical" },
    { "lemma": "Rope", "sort": "Physical" }, { "lemma": "Wire", "sort": "Physical" }, { "lemma": "Tube", "sort": "Physical" },
    { "lemma": "Pipe", "sort": "Physical" }, { "lemma": "Hole", "sort": "Physical" }, { "lemma": "Gap", "sort": "Physical" },
    { "lemma": "Crack", "sort": "Physical" }, { "lemma": "Break", "sort": "Physical" }, { "lemma": "Cut", "sort": "Physical" },
    { "lemma": "Spot", "sort": "Physical" }, { "lemma": "Stain", "sort": "Physical" },
    { "lemma": "Weather", "sort": "Abstract" }, { "lemma": "Climate", "sort": "Abstract" }, { "lemma": "Temperature", "sort": "Abstract" },
    { "lemma": "Rain", "sort": "Physical" }, { "lemma": "Snow", "sort": "Physical" }, { "lemma": "Storm", "sort": "Abstract" },
    { "lemma": "Wind", "sort": "Physical" }, { "lemma": "Cloud", "sort": "Physical" }, { "lemma": "Fog", "sort": "Physical" },
    { "lemma": "Sky", "sort": "Physical" }, { "lemma": "Air", "sort": "Physical" }, { "lemma": "Atmosphere", "sort": "Physical" },
    { "lemma": "Earth", "sort": "Physical" }, { "lemma": "Ground", "sort": "Physical" }, { "lemma": "Land", "sort": "Physical" },
    { "lemma": "Soil", "sort": "Physical" }, { "lemma": "Field", "sort": "Physical" }, { "lemma": "Farm", "sort": "Place" },
    { "lemma": "Crop", "sort": "Physical" }, { "lemma": "Harvest", "sort": "Abstract" }, { "lemma": "Season", "sort": "Abstract" },
    { "lemma": "Spring", "sort": "Abstract" }, { "lemma": "Summer", "sort": "Abstract" }, { "lemma": "Autumn", "sort": "Abstract" },
    { "lemma": "Winter", "sort": "Abstract" }, { "lemma": "Year", "sort": "Abstract" }, { "lemma": "Month", "sort": "Abstract" },
    { "lemma": "Week", "sort": "Abstract" }, { "lemma": "Day", "sort": "Abstract" }, { "lemma": "Hour", "sort": "Abstract" },
    { "lemma": "Minute", "sort": "Abstract" }, { "lemma": "Second", "sort": "Abstract" }, { "lemma": "Moment", "sort": "Abstract" },
    { "lemma": "Period", "sort": "Abstract" }, { "lemma": "Era", "sort": "Abstract" }, { "lemma": "Age", "sort": "Abstract" },
    { "lemma": "Century", "forms": { "plural": "centuries" }, "sort": "Abstract" }, { "lemma": "Decade", "sort": "Abstract" },
    { "lemma": "Past", "sort": "Abstract" }, { "lemma": "Present", "sort": "Abstract" }, { "lemma": "Future", "sort": "Abstract" },
    { "lemma": "History", "sort": "Abstract" }, { "lemma": "Event", "sort": "Abstract" }, { "lemma": "Situation", "sort": "Abstract" },
    { "lemma": "Condition", "sort": "Abstract" }, { "lemma": "Circumstance", "sort": "Abstract" }, { "lemma": "Case", "sort": "Abstract" },
    { "lemma": "Example", "sort": "Abstract" }, { "lemma": "Instance", "sort": "Abstract" }, { "lemma": "Sample", "sort": "Abstract" },
    { "lemma": "Model", "sort": "Abstract" }, { "lemma": "Version", "sort": "Abstract" }, { "lemma": "Copy", "sort": "Physical" },
    { "lemma": "Original", "sort": "Abstract" }, { "lemma": "Difference", "sort": "Abstract" }, { "lemma": "Similarity", "sort": "Abstract" },
    { "lemma": "Comparison", "sort": "Abstract" }, { "lemma": "Contrast", "sort": "Abstract" }, { "lemma": "Connection", "sort": "Abstract" },
    { "lemma": "Relationship", "sort": "Abstract" }, { "lemma": "Link", "sort": "Abstract" }, { "lemma": "Bond", "sort": "Abstract" },
    { "lemma": "Union", "sort": "Abstract" }, { "lemma": "Marriage", "sort": "Abstract" }, { "lemma": "Divorce", "sort": "Abstract" },
    { "lemma": "Birth", "sort": "Abstract" }, { "lemma": "Death", "sort": "Abstract" }, { "lemma": "Life", "forms": { "plural": "lives" }, "sort": "Abstract" },
    { "lemma": "Health", "sort": "Abstract" }, { "lemma": "Disease", "sort": "Abstract" }, { "lemma": "Illness", "sort": "Abstract" },
    { "lemma": "Injury", "sort": "Abstract" }, { "lemma": "Wound", "sort": "Physical" }, { "lemma": "Cure", "sort": "Abstract" },
    { "lemma": "Medicine", "sort": "Physical" }, { "lemma": "Drug", "sort": "Physical" }, { "lemma": "Treatment", "sort": "Abstract" },
    { "lemma": "Surgery", "sort": "Abstract" }, { "lemma": "Operation", "sort": "Abstract" }, { "lemma": "Test", "sort": "Abstract" },
    { "lemma": "Exam", "sort": "Abstract" }, { "lemma": "Result", "sort": "Abstract" }, { "lemma": "Effect", "sort": "Abstract" },
    { "lemma": "Cause", "sort": "Abstract" }, { "lemma": "Reason", "sort": "Abstract" }, { "lemma": "Purpose", "sort": "Abstract" },
    { "lemma": "Goal", "sort": "Abstract" }, { "lemma": "Aim", "sort": "Abstract" }, { "lemma": "Target", "sort": "Abstract" },
    { "lemma": "Object", "sort": "Physical" }, { "lemma": "Subject", "sort": "Abstract" }, { "lemma": "Topic", "sort": "Abstract" },
    { "lemma": "Theme", "sort": "Abstract" }, { "lemma": "Issue", "sort": "Abstract" }, { "lemma": "Matter", "sort": "Abstract" },
    { "lemma": "Fact", "sort": "Abstract" }, { "lemma": "Detail", "sort": "Abstract" }, { "lemma": "Information", "sort": "Abstract" },
    { "lemma": "Data", "sort": "Abstract" }, { "lemma": "Evidence", "sort": "Abstract" }, { "lemma": "Proof", "sort": "Abstract" },
    { "lemma": "Claim", "sort": "Abstract" }, { "lemma": "Statement", "sort": "Abstract" }, { "lemma": "Declaration", "sort": "Abstract" },
    { "lemma": "Announcement", "sort": "Abstract" }, { "lemma": "Report", "sort": "Abstract" }, { "lemma": "News", "sort": "Abstract" },
    { "lemma": "Article", "sort": "Abstract" }, { "lemma": "Document", "sort": "Physical" }, { "lemma": "File", "sort": "Abstract" },
    { "lemma": "Record", "sort": "Abstract" }, { "lemma": "List", "sort": "Abstract" },
    { "lemma": "Chart", "sort": "Abstract" }, { "lemma": "Graph", "sort": "Abstract" }, { "lemma": "Map", "sort": "Physical" },
    { "lemma": "Plan", "sort": "Abstract" }, { "lemma": "Project", "sort": "Abstract" }, { "lemma": "Program", "sort": "Abstract" },
    { "lemma": "Activity", "sort": "Abstract" }, { "lemma": "Action", "sort": "Abstract" }, { "lemma": "Movement", "sort": "Abstract" },
    { "lemma": "Change", "sort": "Abstract" }, { "lemma": "Development", "sort": "Abstract" }, { "lemma": "Growth", "sort": "Abstract" },
    { "lemma": "Progress", "sort": "Abstract" }, { "lemma": "Improvement", "sort": "Abstract" }, { "lemma": "Increase", "sort": "Abstract" },
    { "lemma": "Decrease", "sort": "Abstract" }, { "lemma": "Reduction", "sort": "Abstract" }, { "lemma": "Rise", "sort": "Abstract" },
    { "lemma": "Fall", "sort": "Abstract" }, { "lemma": "Shift", "sort": "Abstract" }, { "lemma": "Turn", "sort": "Abstract" },
    { "lemma": "Return", "sort": "Abstract" }, { "lemma": "Arrival", "sort": "Abstract" }, { "lemma": "Departure", "sort": "Abstract" },
    { "lemma": "Journey", "sort": "Abstract" }, { "lemma": "Trip", "sort": "Abstract" }, { "lemma": "Travel", "sort": "Abstract" },
    { "lemma": "Visit", "sort": "Abstract" }, { "lemma": "Tour", "sort": "Abstract" }, { "lemma": "Adventure", "sort": "Abstract" },
    { "lemma": "Expedition", "sort": "Abstract" }, { "lemma": "Mission", "sort": "Abstract" }, { "lemma": "Task", "sort": "Abstract" },
    { "lemma": "Assignment", "sort": "Abstract" }, { "lemma": "Homework", "sort": "Abstract" }, { "lemma": "Lesson", "sort": "Abstract" },
    { "lemma": "Course", "sort": "Abstract" }, { "lemma": "Training", "sort": "Abstract" }, { "lemma": "Education", "sort": "Abstract" },
    { "lemma": "Study", "sort": "Abstract" }, { "lemma": "Research", "sort": "Abstract" }, { "lemma": "Analysis", "sort": "Abstract" },
    { "lemma": "Theory", "sort": "Abstract" }, { "lemma": "Hypothesis", "forms": { "plural": "hypotheses" }, "sort": "Abstract" },
    { "lemma": "Experiment", "sort": "Abstract" }, { "lemma": "Discovery", "sort": "Abstract" }, { "lemma": "Invention", "sort": "Abstract" },
    { "lemma": "Creation", "sort": "Abstract" }, { "lemma": "Production", "sort": "Abstract" }, { "lemma": "Construction", "sort": "Abstract" },
    { "lemma": "Destruction", "sort": "Abstract" }, { "lemma": "Damage", "sort": "Abstract" }, { "lemma": "Repair", "sort": "Abstract" },
    { "lemma": "Maintenance", "sort": "Abstract" }, { "lemma": "Care", "sort": "Abstract" }, { "lemma": "Protection", "sort": "Abstract" },
    { "lemma": "Defense", "sort": "Abstract" }, { "lemma": "Attack", "sort": "Abstract" }, { "lemma": "Fight", "sort": "Abstract" },
    { "lemma": "Conflict", "sort": "Abstract" }, { "lemma": "Struggle", "sort": "Abstract" }, { "lemma": "Effort", "sort": "Abstract" },
    { "lemma": "Attempt", "sort": "Abstract" }, { "lemma": "Trial", "sort": "Abstract" }, { "lemma": "Challenge", "sort": "Abstract" },
    { "lemma": "Difficulty", "sort": "Abstract" }, { "lemma": "Trouble", "sort": "Abstract" }, { "lemma": "Danger", "sort": "Abstract" },
    { "lemma": "Risk", "sort": "Abstract" }, { "lemma": "Threat", "sort": "Abstract" }, { "lemma": "Warning", "sort": "Abstract" },
    { "lemma": "Signal", "sort": "Abstract" }, { "lemma": "Sign", "sort": "Physical" }, { "lemma": "Symbol", "sort": "Abstract" },
    { "lemma": "Image", "sort": "Abstract" }, { "lemma": "Picture", "sort": "Physical" }, { "lemma": "Photo", "sort": "Physical" },
    { "lemma": "Painting", "sort": "Physical" }, { "lemma": "Drawing", "sort": "Physical" }, { "lemma": "Sculpture", "sort": "Physical" },
    { "lemma": "Statue", "sort": "Physical" }, { "lemma": "Monument", "sort": "Physical" }, { "lemma": "Memorial", "sort": "Physical" },
    { "lemma": "Celebration", "sort": "Abstract" }, { "lemma": "Party", "sort": "Abstract" }, { "lemma": "Festival", "sort": "Abstract" },
    { "lemma": "Holiday", "sort": "Abstract" }, { "lemma": "Vacation", "sort": "Abstract" }, { "lemma": "Rest", "sort": "Abstract" },
    { "lemma": "Sleep", "sort": "Abstract" }, { "lemma": "Food", "sort": "Physical" }, { "lemma": "Meal", "sort": "Physical" },
    { "lemma": "Breakfast", "sort": "Physical" }, { "lemma": "Lunch", "sort": "Physical" }, { "lemma": "Dinner", "sort": "Physical" },
    { "lemma": "Snack", "sort": "Physical" }, { "lemma": "Drink", "sort": "Physical" }, { "lemma": "Bottle", "sort": "Physical" },
    { "lemma": "Cup", "sort": "Physical" }, { "lemma": "Plate", "sort": "Physical" }, { "lemma": "Bowl", "sort": "Physical" },
    { "lemma": "Spoon", "sort": "Physical" }, { "lemma": "Fork", "sort": "Physical" }, { "lemma": "Pan", "sort": "Physical" },
    { "lemma": "Pot", "sort": "Physical" }, { "lemma": "Oven", "sort": "Physical" }, { "lemma": "Stove", "sort": "Physical" },
    { "lemma": "Refrigerator", "sort": "Physical" }, { "lemma": "Sink", "sort": "Physical" }, { "lemma": "Faucet", "sort": "Physical" },
    { "lemma": "Shower", "sort": "Physical" }, { "lemma": "Bath", "sort": "Physical" }, { "lemma": "Toilet", "sort": "Physical" },
    { "lemma": "Towel", "sort": "Physical" }, { "lemma": "Soap", "sort": "Physical" }, { "lemma": "Shampoo", "sort": "Physical" },
    { "lemma": "Toothbrush", "sort": "Physical" }, { "lemma": "Toothpaste", "sort": "Physical" }, { "lemma": "Comb", "sort": "Physical" },
    { "lemma": "Brush", "sort": "Physical" }, { "lemma": "Razor", "sort": "Physical" }, { "lemma": "Scissors", "sort": "Physical" },
    { "lemma": "Needle", "sort": "Physical" }, { "lemma": "Button", "sort": "Physical" }, { "lemma": "Zipper", "sort": "Physical" },
    { "lemma": "Pocket", "sort": "Physical" }, { "lemma": "Bag", "sort": "Physical" }, { "lemma": "Box", "sort": "Physical" },
    { "lemma": "Package", "sort": "Physical" }, { "lemma": "Container", "sort": "Physical" }, { "lemma": "Basket", "sort": "Physical" },
    { "lemma": "Bucket", "sort": "Physical" }, { "lemma": "Barrel", "sort": "Physical" }, { "lemma": "Tank", "sort": "Physical" },
    { "lemma": "Tool", "sort": "Physical" }, { "lemma": "Hammer", "sort": "Physical" }, { "lemma": "Nail", "sort": "Physical" },
    { "lemma": "Screw", "sort": "Physical" }, { "lemma": "Wrench", "sort": "Physical" }, { "lemma": "Drill", "sort": "Physical" },
    { "lemma": "Saw", "sort": "Physical" }, { "lemma": "Axe", "sort": "Physical" }, { "lemma": "Shovel", "sort": "Physical" },
    { "lemma": "Rake", "sort": "Physical" }, { "lemma": "Hose", "sort": "Physical" }, { "lemma": "Ladder", "sort": "Physical" },
    { "lemma": "Stairs", "sort": "Physical" }, { "lemma": "Elevator", "sort": "Physical" }, { "lemma": "Escalator", "sort": "Physical" },
    { "lemma": "Ramp", "sort": "Physical" }, { "lemma": "Gate", "sort": "Physical" }, { "lemma": "Fence", "sort": "Physical" },
    { "lemma": "Lock", "sort": "Physical" }, { "lemma": "Handle", "sort": "Physical" }, { "lemma": "Knob", "sort": "Physical" },
    { "lemma": "Switch", "sort": "Physical" }, { "lemma": "Plug", "sort": "Physical" }, { "lemma": "Outlet", "sort": "Physical" },
    { "lemma": "Cord", "sort": "Physical" }, { "lemma": "Cable", "sort": "Physical" }, { "lemma": "Network", "sort": "Abstract" },
    { "lemma": "Internet", "sort": "Abstract" }, { "lemma": "Website", "sort": "Abstract" }, { "lemma": "Software", "sort": "Abstract" },
    { "lemma": "Hardware", "sort": "Physical" }, { "lemma": "Database", "sort": "Abstract" }, { "lemma": "Server", "sort": "Physical" },
    { "lemma": "Machine", "sort": "Physical" }, { "lemma": "Device", "sort": "Physical" }, { "lemma": "Equipment", "sort": "Physical" },
    { "lemma": "Instrument", "sort": "Physical" }, { "lemma": "Appliance", "sort": "Physical" }, { "lemma": "Gadget", "sort": "Physical" },
    { "lemma": "Vehicle", "sort": "Physical" }, { "lemma": "Truck", "sort": "Physical" }, { "lemma": "Van", "sort": "Physical" },
    { "lemma": "Motorcycle", "sort": "Physical" }, { "lemma": "Bicycle", "sort": "Physical" }, { "lemma": "Boat", "sort": "Physical" },
    { "lemma": "Ship", "sort": "Physical" }, { "lemma": "Plane", "sort": "Physical" }, { "lemma": "Helicopter", "sort": "Physical" },
    { "lemma": "Train", "sort": "Physical" }, { "lemma": "Subway", "sort": "Physical" }, { "lemma": "Taxi", "sort": "Physical" },
    { "lemma": "Hayden", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Charlie", "features": ["Proper"], "sort": "Human" },
    { "lemma": "Tristen", "features": ["Proper"], "sort": "Human" },
    { "lemma": "Collin", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Max", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Jake", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Ryan", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Tyler", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Brandon", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Justin", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Kevin", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Brian", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Eric", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Jason", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Adam", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Andrew", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Matthew", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Michael", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Daniel", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "William", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Robert", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Richard", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Joseph", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Thomas", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Charles", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Christopher", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Anthony", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Steven", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Kenneth", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "George", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Edward", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Jennifer", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Elizabeth", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Linda", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Barbara", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Patricia", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Margaret", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Sandra", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Ashley", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Dorothy", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Kimberly", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Michelle", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Carol", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Amanda", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Melissa", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Deborah", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Stephanie", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Rebecca", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Sharon", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Cynthia", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Kathleen", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Karen", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Nicole", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Christine", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Samantha", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Janet", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Catherine", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Frances", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Ann", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Joyce", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Diane", "features": ["Proper", "Feminine"], "sort": "Human" }
  ],
  "adjectives": [
    { "lemma": "Red", "regular": true, "features": ["Intersective"] },
    { "lemma": "Blue", "regular": true, "features": ["Intersective"] },
    { "lemma": "Green", "regular": true, "features": ["Intersective"] },
    { "lemma": "Black", "regular": true, "features": ["Intersective"] },
    { "lemma": "White", "regular": true, "features": ["Intersective"] },
    { "lemma": "Happy", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Sad", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Great", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Dangerous", "regular": true, "features": ["Intersective"] },
    { "lemma": "Open", "regular": true, "features": ["Intersective"] },
    { "lemma": "Closed", "regular": true, "features": ["Intersective"] },
    { "lemma": "Flat", "regular": true, "features": ["Intersective"] },
    { "lemma": "Fake", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Former", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Alleged", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Counterfeit", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Would-Be", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Putative", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Supposed", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "So-Called", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Pseudo", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Quasi", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Potential", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Possible", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Future", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Imaginary", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Fictional", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Tall", "regular": true, "features": ["Subsective", "Gradable"] },
    { "lemma": "Short", "regular": true, "features": ["Subsective", "Gradable"] },
    { "lemma": "Big", "regular": true, "features": ["Subsective", "Gradable"] },
    { "lemma": "Large", "regular": true, "features": ["Subsective", "Gradable"] },
    { "lemma": "Small", "regular": true, "features": ["Subsective", "Gradable"] },
    { "lemma": "Fast", "regular": true, "features": ["Subsective", "Gradable", "EventModifier"] },
    { "lemma": "Slow", "regular": true, "features": ["Subsective", "Gradable", "EventModifier"] },
    { "lemma": "Old", "regular": true, "features": ["Subsective", "Gradable"] },
    { "lemma": "Young", "regular": true, "features": ["Subsective", "Gradable"] },
    { "lemma": "Strong", "regular": true, "features": ["Subsective", "Gradable"] },
    { "lemma": "Weak", "regular": true, "features": ["Subsective", "Gradable"] },
    { "lemma": "Loud", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Quiet", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Smart", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Dumb", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Rich", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Poor", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "High", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Low", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Long", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Wide", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Deep", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Thick", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Thin", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Hot", "regular": true, "features": ["Intersective", "Gradable", "Weather"] },
    { "lemma": "Cold", "regular": true, "features": ["Intersective", "Gradable", "Weather"] },
    { "lemma": "Warm", "regular": true, "features": ["Intersective", "Gradable", "Weather"] },
    { "lemma": "Cool", "regular": true, "features": ["Intersective", "Gradable", "Weather"] },
    { "lemma": "Hard", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Soft", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Dark", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Light", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Clean", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Dirty", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Dry", "regular": true, "features": ["Intersective", "Gradable", "Weather"] },
    { "lemma": "Wet", "regular": true, "features": ["Intersective", "Gradable", "Weather"] },
    { "lemma": "Sunny", "regular": true, "features": ["Intersective", "Weather"] },
    { "lemma": "Cloudy", "regular": true, "features": ["Intersective", "Weather"] },
    { "lemma": "Foggy", "regular": true, "features": ["Intersective", "Weather"] },
    { "lemma": "Humid", "regular": true, "features": ["Intersective", "Gradable", "Weather"] },
    { "lemma": "Windy", "regular": true, "features": ["Intersective", "Gradable", "Weather"] },
    { "lemma": "New", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Bright", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Sweet", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Sour", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Good", "regular": true, "features": ["Subsective"] },
    { "lemma": "Bad", "regular": true, "features": ["Subsective"] },
    { "lemma": "Beautiful", "regular": true, "features": ["Intersective", "Gradable", "EventModifier"] },
    { "lemma": "Graceful", "regular": true, "features": ["Intersective", "Gradable", "EventModifier"] },
    { "lemma": "Skillful", "regular": true, "features": ["Intersective", "Gradable", "EventModifier"] },
    { "lemma": "Clumsy", "regular": true, "features": ["Intersective", "Gradable", "EventModifier"] },
    { "lemma": "Elegant", "regular": true, "features": ["Intersective", "Gradable", "EventModifier"] },
    { "lemma": "Awkward", "regular": true, "features": ["Intersective", "Gradable", "EventModifier"] },
    { "lemma": "Careful", "regular": true, "features": ["Intersective", "Gradable", "EventModifier"] },
    { "lemma": "Careless", "regular": true, "features": ["Intersective", "Gradable", "EventModifier"] },
    { "lemma": "Angry", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Afraid", "regular": true, "features": ["Intersective"] },
    { "lemma": "Alive", "regular": true, "features": ["Intersective"] },
    { "lemma": "Dead", "regular": true, "features": ["Intersective"] },
    { "lemma": "Asleep", "regular": true, "features": ["Intersective"] },
    { "lemma": "Awake", "regular": true, "features": ["Intersective"] },
    { "lemma": "Busy", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Calm", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Cheap", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Expensive", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Clever", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Crazy", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Curious", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Delicious", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Different", "regular": true, "features": ["Intersective"] },
    { "lemma": "Same", "regular": true, "features": ["Intersective"] },
    { "lemma": "Easy", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Empty", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Full", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Excited", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Famous", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Friendly", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Funny", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Gentle", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Guilty", "regular": true, "features": ["Intersective"] },
    { "lemma": "Innocent", "regular": true, "features": ["Intersective"] },
    { "lemma": "Healthy", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Sick", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Heavy", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Helpful", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Honest", "regular": true, "features": ["Intersective"] },
    { "lemma": "Hungry", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Thirsty", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Important", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Impossible", "regular": true, "features": ["Intersective"] },
    { "lemma": "Interesting", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Boring", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Jealous", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Kind", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Lazy", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Lonely", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Lucky", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Modern", "regular": true, "features": ["Intersective"] },
    { "lemma": "Ancient", "regular": true, "features": ["Intersective"] },
    { "lemma": "Narrow", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Nervous", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Nice", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Normal", "regular": true, "features": ["Intersective"] },
    { "lemma": "Strange", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Obvious", "regular": true, "features": ["Intersective"] },
    { "lemma": "Perfect", "regular": true, "features": ["Intersective"] },
    { "lemma": "Pleasant", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Polite", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Rude", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Popular", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Powerful", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Pretty", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Ugly", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Private", "regular": true, "features": ["Intersective"] },
    { "lemma": "Public", "regular": true, "features": ["Intersective"] },
    { "lemma": "Proud", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Ready", "regular": true, "features": ["Intersective"] },
    { "lemma": "Real", "regular": true, "features": ["Intersective"] },
    { "lemma": "Reasonable", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Relaxed", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Relevant", "regular": true, "features": ["Intersective"] },
    { "lemma": "Responsible", "regular": true, "features": ["Intersective"] },
    { "lemma": "Rough", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Smooth", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Round", "regular": true, "features": ["Intersective"] },
    { "lemma": "Safe", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Scared", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Serious", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Sharp", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Dull", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Silent", "regular": true, "features": ["Intersective"] },
    { "lemma": "Silly", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Simple", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Complex", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Single", "regular": true, "features": ["Intersective"] },
    { "lemma": "Sleepy", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Sorry", "regular": true, "features": ["Intersective"] },
    { "lemma": "Special", "regular": true, "features": ["Intersective"] },
    { "lemma": "Steep", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Strict", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Stupid", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Successful", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Sudden", "regular": true, "features": ["Intersective"] },
    { "lemma": "Sure", "regular": true, "features": ["Intersective"] },
    { "lemma": "Surprised", "regular": true, "features": ["Intersective"] },
    { "lemma": "Terrible", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Tired", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Traditional", "regular": true, "features": ["Intersective"] },
    { "lemma": "True", "regular": true, "features": ["Intersective"] },
    { "lemma": "False", "regular": true, "features": ["Intersective"] },
    { "lemma": "Typical", "regular": true, "features": ["Intersective"] },
    { "lemma": "Unusual", "regular": true, "features": ["Intersective"] },
    { "lemma": "Useful", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Useless", "regular": true, "features": ["Intersective"] },
    { "lemma": "Various", "regular": true, "features": ["Intersective"] },
    { "lemma": "Visible", "regular": true, "features": ["Intersective"] },
    { "lemma": "Invisible", "regular": true, "features": ["Intersective"] },
    { "lemma": "Warm", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Wild", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Wise", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Wonderful", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Wooden", "regular": true, "features": ["Intersective"] },
    { "lemma": "Worried", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Worth", "regular": true, "features": ["Intersective"] },
    { "lemma": "Wrong", "regular": true, "features": ["Intersective"] },
    { "lemma": "Yellow", "regular": true, "features": ["Intersective"] },
    { "lemma": "Orange", "regular": true, "features": ["Intersective"] },
    { "lemma": "Purple", "regular": true, "features": ["Intersective"] },
    { "lemma": "Pink", "regular": true, "features": ["Intersective"] },
    { "lemma": "Brown", "regular": true, "features": ["Intersective"] },
    { "lemma": "Gray", "regular": true, "features": ["Intersective"] },
    { "lemma": "Golden", "regular": true, "features": ["Intersective"] },
    { "lemma": "Silver", "regular": true, "features": ["Intersective"] },
    { "lemma": "Massive", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Tiny", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Huge", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Giant", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Little", "regular": true, "features": ["Subsective", "Gradable"] },
    { "lemma": "Entire", "regular": true, "features": ["Intersective"] },
    { "lemma": "Whole", "regular": true, "features": ["Intersective"] },
    { "lemma": "Main", "regular": true, "features": ["Intersective"] },
    { "lemma": "Major", "regular": true, "features": ["Intersective"] },
    { "lemma": "Minor", "regular": true, "features": ["Intersective"] },
    { "lemma": "Only", "regular": true, "features": ["Intersective"] },
    { "lemma": "Own", "regular": true, "features": ["Intersective"] },
    { "lemma": "Other", "regular": true, "features": ["Intersective"] },
    { "lemma": "Next", "regular": true, "features": ["Intersective"] },
    { "lemma": "Last", "regular": true, "features": ["Intersective"] },
    { "lemma": "First", "regular": true, "features": ["Intersective"] },
    { "lemma": "Final", "regular": true, "features": ["Intersective"] },
    { "lemma": "Previous", "regular": true, "features": ["Intersective"] },
    { "lemma": "Current", "regular": true, "features": ["Intersective"] },
    { "lemma": "Recent", "regular": true, "features": ["Intersective"] },
    { "lemma": "Early", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Late", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Daily", "regular": true, "features": ["Intersective"] },
    { "lemma": "Weekly", "regular": true, "features": ["Intersective"] },
    { "lemma": "Monthly", "regular": true, "features": ["Intersective"] },
    { "lemma": "Annual", "regular": true, "features": ["Intersective"] },
    { "lemma": "Constant", "regular": true, "features": ["Intersective"] },
    { "lemma": "Temporary", "regular": true, "features": ["Intersective"] },
    { "lemma": "Permanent", "regular": true, "features": ["Intersective"] },
    { "lemma": "Local", "regular": true, "features": ["Intersective"] },
    { "lemma": "Global", "regular": true, "features": ["Intersective"] },
    { "lemma": "National", "regular": true, "features": ["Intersective"] },
    { "lemma": "International", "regular": true, "features": ["Intersective"] },
    { "lemma": "Foreign", "regular": true, "features": ["Intersective"] },
    { "lemma": "Native", "regular": true, "features": ["Intersective"] },
    { "lemma": "Natural", "regular": true, "features": ["Intersective"] },
    { "lemma": "Artificial", "regular": true, "features": ["Intersective"] },
    { "lemma": "Physical", "regular": true, "features": ["Intersective"] },
    { "lemma": "Mental", "regular": true, "features": ["Intersective"] },
    { "lemma": "Emotional", "regular": true, "features": ["Intersective"] },
    { "lemma": "Social", "regular": true, "features": ["Intersective"] },
    { "lemma": "Political", "regular": true, "features": ["Intersective"] },
    { "lemma": "Economic", "regular": true, "features": ["Intersective"] },
    { "lemma": "Legal", "regular": true, "features": ["Intersective"] },
    { "lemma": "Illegal", "regular": true, "features": ["Intersective"] },
    { "lemma": "Medical", "regular": true, "features": ["Intersective"] },
    { "lemma": "Scientific", "regular": true, "features": ["Intersective"] },
    { "lemma": "Technical", "regular": true, "features": ["Intersective"] },
    { "lemma": "Professional", "regular": true, "features": ["Intersective"] },
    { "lemma": "Personal", "regular": true, "features": ["Intersective"] },
    { "lemma": "Official", "regular": true, "features": ["Intersective"] },
    { "lemma": "Original", "regular": true, "features": ["Intersective"] },
    { "lemma": "Additional", "regular": true, "features": ["Intersective"] },
    { "lemma": "Available", "regular": true, "features": ["Intersective"] },
    { "lemma": "Basic", "regular": true, "features": ["Intersective"] },
    { "lemma": "Central", "regular": true, "features": ["Intersective"] },
    { "lemma": "Common", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Rare", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Complete", "regular": true, "features": ["Intersective"] },
    { "lemma": "Incomplete", "regular": true, "features": ["Intersective"] },
    { "lemma": "Correct", "regular": true, "features": ["Intersective"] },
    { "lemma": "Incorrect", "regular": true, "features": ["Intersective"] },
    { "lemma": "Direct", "regular": true, "features": ["Intersective"] },
    { "lemma": "Indirect", "regular": true, "features": ["Intersective"] },
    { "lemma": "Exact", "regular": true, "features": ["Intersective"] },
    { "lemma": "Fair", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Unfair", "regular": true, "features": ["Intersective"] },
    { "lemma": "Favorite", "regular": true, "features": ["Intersective"] },
    { "lemma": "Final", "regular": true, "features": ["Intersective"] },
    { "lemma": "Fine", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Firm", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Fit", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Flat", "regular": true, "features": ["Intersective"] },
    { "lemma": "Formal", "regular": true, "features": ["Intersective"] },
    { "lemma": "Informal", "regular": true, "features": ["Intersective"] },
    { "lemma": "Free", "regular": true, "features": ["Intersective"] },
    { "lemma": "Fresh", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "General", "regular": true, "features": ["Intersective"] },
    { "lemma": "Specific", "regular": true, "features": ["Intersective"] },
    { "lemma": "Grand", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Gross", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Net", "regular": true, "features": ["Intersective"] },
    { "lemma": "Independent", "regular": true, "features": ["Intersective"] },
    { "lemma": "Dependent", "regular": true, "features": ["Intersective"] },
    { "lemma": "Individual", "regular": true, "features": ["Intersective"] },
    { "lemma": "Inner", "regular": true, "features": ["Intersective"] },
    { "lemma": "Outer", "regular": true, "features": ["Intersective"] },
    { "lemma": "Upper", "regular": true, "features": ["Intersective"] },
    { "lemma": "Lower", "regular": true, "features": ["Intersective"] },
    { "lemma": "Latter", "regular": true, "features": ["Intersective"] },
    { "lemma": "Likely", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Unlikely", "regular": true, "features": ["Intersective"] },
    { "lemma": "Loose", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Tight", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Married", "regular": true, "features": ["Intersective"] },
    { "lemma": "Maximum", "regular": true, "features": ["Intersective"] },
    { "lemma": "Minimum", "regular": true, "features": ["Intersective"] },
    { "lemma": "Mere", "regular": true, "features": ["Intersective"] },
    { "lemma": "Mutual", "regular": true, "features": ["Intersective"] },
    { "lemma": "Naked", "regular": true, "features": ["Intersective"] },
    { "lemma": "Necessary", "regular": true, "features": ["Intersective"] },
    { "lemma": "Negative", "regular": true, "features": ["Intersective"] },
    { "lemma": "Positive", "regular": true, "features": ["Intersective"] },
    { "lemma": "Neutral", "regular": true, "features": ["Intersective"] },
    { "lemma": "Obvious", "regular": true, "features": ["Intersective"] },
    { "lemma": "Opposite", "regular": true, "features": ["Intersective"] },
    { "lemma": "Parallel", "regular": true, "features": ["Intersective"] },
    { "lemma": "Particular", "regular": true, "features": ["Intersective"] },
    { "lemma": "Plain", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Primary", "regular": true, "features": ["Intersective"] },
    { "lemma": "Secondary", "regular": true, "features": ["Intersective"] },
    { "lemma": "Prime", "regular": true, "features": ["Intersective"] },
    { "lemma": "Principal", "regular": true, "features": ["Intersective"] },
    { "lemma": "Proper", "regular": true, "features": ["Intersective"] },
    { "lemma": "Pure", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Quick", "regular": true, "features": ["Intersective", "Gradable", "EventModifier"] },
    { "lemma": "Rapid", "regular": true, "features": ["Intersective", "Gradable", "EventModifier"] },
    { "lemma": "Raw", "regular": true, "features": ["Intersective"] },
    { "lemma": "Regular", "regular": true, "features": ["Intersective"] },
    { "lemma": "Irregular", "regular": true, "features": ["Intersective"] },
    { "lemma": "Relative", "regular": true, "features": ["Intersective"] },
    { "lemma": "Absolute", "regular": true, "features": ["Intersective"] },
    { "lemma": "Remote", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Royal", "regular": true, "features": ["Intersective"] },
    { "lemma": "Rural", "regular": true, "features": ["Intersective"] },
    { "lemma": "Urban", "regular": true, "features": ["Intersective"] },
    { "lemma": "Secure", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Senior", "regular": true, "features": ["Intersective"] },
    { "lemma": "Junior", "regular": true, "features": ["Intersective"] },
    { "lemma": "Separate", "regular": true, "features": ["Intersective"] },
    { "lemma": "Severe", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Slight", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Solid", "regular": true, "features": ["Intersective"] },
    { "lemma": "Liquid", "regular": true, "features": ["Intersective"] },
    { "lemma": "Spare", "regular": true, "features": ["Intersective"] },
    { "lemma": "Stable", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Standard", "regular": true, "features": ["Intersective"] },
    { "lemma": "Steady", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Straight", "regular": true, "features": ["Intersective"] },
    { "lemma": "Sufficient", "regular": true, "features": ["Intersective"] },
    { "lemma": "Suitable", "regular": true, "features": ["Intersective"] },
    { "lemma": "Supreme", "regular": true, "features": ["Intersective"] },
    { "lemma": "Total", "regular": true, "features": ["Intersective"] },
    { "lemma": "Tough", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Ultimate", "regular": true, "features": ["Intersective"] },
    { "lemma": "Unique", "regular": true, "features": ["Intersective"] },
    { "lemma": "Universal", "regular": true, "features": ["Intersective"] },
    { "lemma": "Valid", "regular": true, "features": ["Intersective"] },
    { "lemma": "Invalid", "regular": true, "features": ["Intersective"] },
    { "lemma": "Valuable", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Worthless", "regular": true, "features": ["Intersective"] },
    { "lemma": "Vast", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Vertical", "regular": true, "features": ["Intersective"] },
    { "lemma": "Horizontal", "regular": true, "features": ["Intersective"] },
    { "lemma": "Virtual", "regular": true, "features": ["Intersective"] },
    { "lemma": "Vital", "regular": true, "features": ["Intersective"] },
    { "lemma": "Voluntary", "regular": true, "features": ["Intersective"] },
    { "lemma": "Weird", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Wicked", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Willing", "regular": true, "features": ["Intersective"] },
    { "lemma": "Wooden", "regular": true, "features": ["Intersective"] },
    { "lemma": "Worthy", "regular": true, "features": ["Intersective", "Gradable"] }
  ],
  "morphological_rules": [
    { "suffix": "ist", "base_pos": "Noun", "relation": "Practitioner" },
    { "suffix": "ian", "base_pos": "Noun", "relation": "Practitioner" },
    { "suffix": "er", "base_pos": "Verb", "relation": "Agent" },
    { "suffix": "or", "base_pos": "Verb", "relation": "Agent" },
    { "suffix": "ee", "base_pos": "Verb", "relation": "Patient" }
  ],
  "prepositions": [
    "from", "with", "for", "by", "of", "in", "on", "at", "into", "onto",
    "under", "over", "through", "about", "around", "between", "among",
    "behind", "before", "after", "near", "beside", "beneath", "above",
    "below", "inside", "outside", "within", "without", "against",
    "toward", "towards", "across", "along", "during", "until", "upon", "past"
  ],
  "adverbs": [
    "quickly", "slowly", "loudly", "quietly", "happily", "sadly",
    "carefully", "carelessly", "easily", "hardly", "barely",
    "passionately", "angrily", "gently", "roughly", "softly",
    "suddenly", "gradually", "immediately", "finally", "eventually",
    "really", "truly", "certainly", "probably", "possibly",
    "always", "never", "often", "sometimes", "rarely", "usually",
    "please"
  ],
  "scopal_adverbs": [
    "almost", "nearly", "barely", "hardly", "just",
    "merely", "still", "already",
    "allegedly", "probably", "possibly", "certainly"
  ],
  "temporal_adverbs": ["yesterday", "today", "tomorrow", "now"],
  "particles": ["up", "down", "out", "in", "off", "on", "away", "over", "back", "through", "apart", "about", "around", "along", "by"],
  "phrasal_verbs": {
    "give_up": { "lemma": "Surrender", "class": "Activity" },
    "break_down": { "lemma": "Malfunction", "class": "Achievement" },
    "pick_up": { "lemma": "Collect", "class": "Achievement" },
    "put_down": { "lemma": "Place", "class": "Activity" },
    "take_off": { "lemma": "Remove", "class": "Achievement" },
    "turn_on": { "lemma": "Activate", "class": "Achievement" },
    "turn_off": { "lemma": "Deactivate", "class": "Achievement" },
    "carry_out": { "lemma": "Execute", "class": "Activity" },
    "figure_out": { "lemma": "Understand", "class": "Achievement" },
    "find_out": { "lemma": "Discover", "class": "Achievement" },
    "give_away": { "lemma": "Donate", "class": "Activity" },
    "throw_away": { "lemma": "Discard", "class": "Activity" },
    "bring_up": { "lemma": "Mention", "class": "Activity" },
    "call_off": { "lemma": "Cancel", "class": "Achievement" },
    "make_up": { "lemma": "Fabricate", "class": "Activity" },
    "set_up": { "lemma": "Arrange", "class": "Activity" },
    "shut_down": { "lemma": "Close", "class": "Achievement" }
  },
  "not_adverbs": [
    "friendly", "lovely", "ugly", "silly", "holy", "lonely", "deadly",
    "likely", "costly", "early", "only", "daily", "weekly", "monthly",
    "yearly", "orderly", "timely", "lively", "elderly", "brotherly",
    "fatherly", "motherly", "sisterly", "beastly", "ghostly", "princely"
  ],
  "noun_patterns": [
    "dog", "cat", "man", "bird", "book", "house", "person", "thing",
    "dogs", "cats", "men", "birds", "books", "houses", "persons", "things"
  ],
  "disambiguation_not_verbs": [
    "ring", "king", "thing", "spring", "string", "swing", "wing", "bring", "sing",
    "bus", "plus", "gas", "us", "thus", "focus", "campus", "status", "bonus",
    "red", "bed", "led", "shed", "sled", "wed", "ground",
    "tired", "bored", "excited", "interested", "blessed", "wicked",
    "mortal", "happy", "friendly", "loud", "black", "old", "wise", "bald",
    "tall", "short", "big", "small", "fast", "slow", "good", "bad", "lazy",
    "dangerous", "blue", "green", "yellow", "white", "free"
  ],
  "morphology": {
    "needs_e_ing": [
      "tak", "mak", "giv", "hav", "lov", "liv", "mov", "sav",
      "writ", "rid", "hid", "bit", "driv", "shak", "wak",
      "hat", "lik", "nam", "shar", "hop", "danc", "chas"
    ],
    "needs_e_ed": [
      "persuad", "forc", "convinc", "reduc", "produc", "induc",
      "lov", "mov", "sav", "liv", "giv", "hav", "mak", "tak",
      "chas", "danc", "hop", "lik", "hat", "nam", "shar",
      "chang", "manag", "arrang", "enclos", "clos", "rais",
      "prais", "paus", "caus", "us", "refus", "excus", "abus",
      "accus", "amus", "confus", "advis", "devis", "revis",
      "promis", "compromis", "exercis", "practis", "realis",
      "organis", "recognis", "surpris", "disguis",
      "decid", "provid", "divid", "guid", "resid", "collid",
      "examin"
    ],
    "stemming_exceptions": [
      "themselves", "ourselves", "yourselves", "himself", "herself",
      "itself", "myself", "yourself", "this", "thus", "plus", "minus",
      "always", "sometimes", "perhaps", "yes", "is", "as", "was", "has",
      "does", "his", "hers", "its", "ours", "yours", "theirs", "us"
    ]
  },
  "units": {
    "inch": "Length",
    "inches": "Length",
    "meter": "Length",
    "meters": "Length",
    "foot": "Length",
    "feet": "Length",
    "yard": "Length",
    "yards": "Length",
    "mile": "Length",
    "miles": "Length",
    "second": "Time",
    "seconds": "Time",
    "minute": "Time",
    "minutes": "Time",
    "hour": "Time",
    "hours": "Time",
    "day": "Time",
    "days": "Time",
    "year": "Time",
    "years": "Time",
    "pound": "Weight",
    "pounds": "Weight",
    "kilogram": "Weight",
    "kilograms": "Weight",
    "gram": "Weight",
    "grams": "Weight",
    "ounce": "Weight",
    "ounces": "Weight",
    "degree": "Temperature",
    "degrees": "Temperature",
    "child": "Cardinality",
    "children": "Cardinality",
    "item": "Cardinality",
    "items": "Cardinality"
  },
  "multi_word_expressions": [
    { "pattern": ["fire", "engine"], "lemma": "FireEngine", "pos": "Noun" },
    { "pattern": ["ice", "cream"], "lemma": "IceCream", "pos": "Noun" },
    { "pattern": ["credit", "card"], "lemma": "CreditCard", "pos": "Noun" },
    { "pattern": ["black", "hole"], "lemma": "BlackHole", "pos": "Noun" },
    { "pattern": ["high", "school"], "lemma": "HighSchool", "pos": "Noun" },
    { "pattern": ["new", "york"], "lemma": "NewYork", "pos": "Noun", "features": ["Proper"] },
    { "pattern": ["united", "states"], "lemma": "UnitedStates", "pos": "Noun", "features": ["Proper"] },
    { "pattern": ["san", "francisco"], "lemma": "SanFrancisco", "pos": "Noun", "features": ["Proper"] },
    { "pattern": ["kick", "the", "bucket"], "lemma": "Die", "pos": "Verb", "class": "Achievement" },
    { "pattern": ["give", "up"], "lemma": "Surrender", "pos": "Verb", "class": "Activity" },
    { "pattern": ["break", "down"], "lemma": "Malfunction", "pos": "Verb", "class": "Achievement" },
    { "pattern": ["in", "front", "of"], "lemma": "InFrontOf", "pos": "Preposition" },
    { "pattern": ["as", "well", "as"], "lemma": "And", "pos": "Conjunction" },
    { "pattern": ["no", "one"], "lemma": "NoOne", "pos": "Quantifier" }
  ],
  "ontology": {
    "part_whole": [
      { "whole": "Car", "parts": ["Engine", "Wheel", "Door", "Window", "Tire"] },
      { "whole": "Bike", "parts": ["Wheel", "Pedal", "Chain", "Seat"] },
      { "whole": "House", "parts": ["Door", "Window", "Roof", "Room", "Wall"] },
      { "whole": "Body", "parts": ["Head", "Arm", "Leg", "Hand", "Foot"] },
      { "whole": "Computer", "parts": ["Screen", "Keyboard", "Mouse"] },
      { "whole": "Book", "parts": ["Page", "Cover", "Chapter"] },
      { "whole": "Tree", "parts": ["Branch", "Leaf", "Root"] },
      { "whole": "Room", "parts": ["Floor", "Ceiling", "Wall"] },
      { "whole": "Paper", "parts": ["Author", "Abstract", "Conclusion"] }
    ],
    "predicate_sorts": {
      "happy": "Animate",
      "sad": "Animate",
      "angry": "Animate",
      "hungry": "Animate",
      "tired": "Animate",
      "alive": "Animate",
      "dead": "Animate",
      "think": "Animate",
      "believe": "Animate",
      "remember": "Animate",
      "know": "Animate",
      "want": "Animate",
      "hope": "Animate",
      "fear": "Animate"
    }
  },
  "axioms": {
    "nouns": {
      "bachelor": { "entails": ["Unmarried", "Male", "Adult"] },
      "spinster": { "entails": ["Unmarried", "Female", "Adult"] },
      "widow": { "entails": ["Female", "WasMarried"] },
      "widower": { "entails": ["Male", "WasMarried"] },
      "orphan": { "entails": ["Child", "ParentsDeceased"] },
      "dog": { "hypernyms": ["Animal", "Mammal"] },
      "cat": { "hypernyms": ["Animal", "Mammal"] },
      "bird": { "hypernyms": ["Animal"] },
      "sparrow": { "hypernyms": ["Bird", "Animal"] },
      "eagle": { "hypernyms": ["Bird", "Animal"] },
      "fish": { "hypernyms": ["Animal"] },
      "salmon": { "hypernyms": ["Fish", "Animal"] },
      "human": { "hypernyms": ["Animal", "Mammal"] },
      "car": { "hypernyms": ["Vehicle"] },
      "truck": { "hypernyms": ["Vehicle"] },
      "bicycle": { "hypernyms": ["Vehicle"] }
    },
    "adjectives": {
      "fake": { "type": "Privative" },
      "counterfeit": { "type": "Privative" },
      "former": { "type": "Privative" },
      "alleged": { "type": "Privative" },
      "would-be": { "type": "Privative" },
      "imaginary": { "type": "Privative" },
      "fictional": { "type": "Privative" }
    },
    "verbs": {
      "murder": { "entails": "Kill", "manner": ["Intentional"] },
      "assassinate": { "entails": "Kill", "manner": ["Intentional", "Political"] },
      "slaughter": { "entails": "Kill", "manner": ["Violent"] },
      "execute": { "entails": "Kill", "manner": ["Legal", "Intentional"] }
    }
  }
}
```

---

## Lexer & Tokenization

Transforms text into classified tokens.
use crate::drs::{Case, Gender, Number};
use crate::intern::Symbol;
use crate::lexicon::{Aspect, Definiteness, Time, VerbClass};

#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
pub struct Span {
    pub start: usize,
    pub end: usize,
}

impl Span {
    pub fn new(start: usize, end: usize) -> Self {
        Self { start, end }
    }
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum PresupKind {
    Stop,
    Start,
    Regret,
    Continue,
    Realize,
    Know,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum FocusKind {
    Only,
    Even,
    Just,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum MeasureKind {
    Much,
    Little,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum BlockType {
    Theorem,
    Main,
    Definition,
    Proof,
    Example,
    Logic,
    Note,
    Function,  // Phase 32: ## To blocks
    TypeDef,   // Inline type definitions: ## A Point has:, ## A Color is one of:
    Policy,    // Phase 50: ## Policy blocks for security rules
}

#[derive(Debug, Clone, PartialEq, Eq)]
pub enum TokenType {
    // Document Structure
    BlockHeader { block_type: BlockType },

    // Quantifiers
    All,
    No,
    Some,
    Any,
    Both, // Correlative conjunction marker: "both X and Y"
    Most,
    Few,
    Many,
    Cardinal(u32),
    AtLeast(u32),
    AtMost(u32),

    // Negative Polarity Items (NPIs)
    Anything,
    Anyone,
    Nothing,
    Nobody,
    NoOne,
    Nowhere,
    Ever,
    Never,

    // Logical Connectives
    And,
    Or,
    If,
    Then,
    Not,
    Iff,
    Because,

    // Modal Operators
    Must,
    Shall,
    Should,
    Can,
    May,
    Cannot,
    Would,
    Could,
    Might,
    Had,

    // Imperative Statement Keywords
    Let,
    Set,
    Return,
    Be,
    While,
    Repeat,
    For,
    In,
    From,
    Assert,
    Trust,    // Phase 35: Documented assertion with justification
    Otherwise,
    Call,
    New,      // Phase 31: Constructor keyword
    Either,   // Phase 33: Sum type definition
    Inspect,  // Phase 33: Pattern matching
    Native,   // Phase 38: Native function modifier

    // Phase 10: IO Keywords
    Read,     // "Read input from..."
    Write,    // "Write x to file..."
    Console,  // "...from the console"
    File,     // "...from file..." or "...to file..."

    // Ownership Keywords (Move/Borrow Semantics)
    Give,  // Move ownership: "Give x to processor"
    Show,  // Immutable borrow: "Show x to console"

    // Phase 43D: Collection Operations
    Push,     // "Push x to items"
    Pop,      // "Pop from items"
    Copy,     // "copy of slice" → slice.to_vec()
    Through,  // "items 1 through 3" → inclusive slice
    Length,   // "length of items" → items.len()
    At,       // "items at i" → items[i]

    // Set Operations
    Add,          // "Add x to set" (insert)
    Remove,       // "Remove x from set"
    Contains,     // "set contains x"
    Union,        // "a union b"
    Intersection, // "a intersection b"

    // Phase 8.5: Memory Management (Zones)
    Inside,   // "Inside a new zone..."
    Zone,     // "...zone called..."
    Called,   // "...called 'Scratch'"
    Size,     // "...of size 1 MB"
    Mapped,   // "...mapped from 'file.bin'"

    // Phase 9: Structured Concurrency
    Attempt,        // "Attempt all of the following:" -> concurrent (async, I/O-bound)
    Following,      // "the following"
    Simultaneously, // "Simultaneously:" -> parallel (CPU-bound)

    // Phase 46: Agent System (Actor Model)
    Spawn,    // "Spawn a Worker called 'w1'" -> create agent
    Send,     // "Send Ping to 'agent'" -> send message to agent
    Await,    // "Await response from 'agent' into result" -> receive message

    // Phase 47: Serialization
    Portable, // "A Message is Portable and has:" -> serde derives

    // Phase 48: Sipping Protocol
    Manifest, // "the manifest of Zone" -> FileSipper manifest
    Chunk,    // "the chunk at N in Zone" -> FileSipper chunk

    // Phase 49: CRDT Keywords
    Shared,   // "A Counter is Shared and has:" -> CRDT struct
    Merge,    // "Merge remote into local" -> CRDT merge
    Increase, // "Increase x's count by 10" -> GCounter increment

    // Phase 49b: Extended CRDT Keywords (Wave 5)
    Decrease,       // "Decrease x's count by 5" -> PNCounter decrement
    Tally,          // "which is a Tally" -> PNCounter type
    SharedSet,      // "which is a SharedSet of T" -> ORSet type
    SharedSequence, // "which is a SharedSequence of T" -> RGA type
    CollaborativeSequence, // "which is a CollaborativeSequence of T" -> YATA type
    SharedMap,      // "which is a SharedMap from K to V" -> ORMap type
    Divergent,      // "which is a Divergent T" -> MVRegister type
    Append,         // "Append x to seq" -> RGA append
    Resolve,        // "Resolve x to value" -> MVRegister resolve
    RemoveWins,     // "(RemoveWins)" -> ORSet bias
    AddWins,        // "(AddWins)" -> ORSet bias (default)
    YATA,           // "(YATA)" -> Sequence algorithm
    Values,         // "x's values" -> MVRegister values accessor

    // Phase 50: Security Keywords
    Check,    // "Check that user is admin" -> mandatory runtime guard

    // Phase 51: P2P Networking Keywords
    Listen,   // "Listen on [addr]" -> bind to network address
    NetConnect,  // "Connect to [addr]" -> dial a peer (NetConnect to avoid conflict)
    Sleep,    // "Sleep N." -> pause execution for N milliseconds

    // Phase 52: GossipSub Keywords
    Sync,     // "Sync x on 'topic'" -> automatic CRDT replication

    // Phase 53: Persistence Keywords
    Mount,      // "Mount x at [path]" -> load/create persistent CRDT from journal
    Persistent, // "Persistent Counter" -> type wrapped with journaling
    Combined,   // "x combined with y" -> string concatenation

    // Phase 54: Go-like Concurrency Keywords
    Launch,     // "Launch a task to..." -> spawn green thread
    Task,       // "a task" -> identifier for task context
    Pipe,       // "Pipe of Type" -> channel creation
    Receive,    // "Receive from pipe" -> recv from channel
    Stop,       // "Stop handle" -> abort task
    Try,        // "Try to send/receive" -> non-blocking variant
    Into,       // "Send value into pipe" -> channel send
    First,      // "Await the first of:" -> select statement
    After,      // "After N seconds:" -> timeout branch

    // Block Scoping
    Colon,
    Indent,
    Dedent,
    Newline,

    // Content Words
    Noun(Symbol),
    Adjective(Symbol),
    NonIntersectiveAdjective(Symbol),
    Adverb(Symbol),
    ScopalAdverb(Symbol),
    TemporalAdverb(Symbol),
    Verb {
        lemma: Symbol,
        time: Time,
        aspect: Aspect,
        class: VerbClass,
    },
    ProperName(Symbol),

    // Lexical Ambiguity (Phase 12: Parse Forest)
    Ambiguous {
        primary: Box<TokenType>,
        alternatives: Vec<TokenType>,
    },

    // Speech Acts (Performatives)
    Performative(Symbol),
    Exclamation,

    // Articles (Definiteness)
    Article(Definiteness),

    // Temporal Auxiliaries
    Auxiliary(Time),

    // Copula & Functional
    Is,
    Are,
    Was,
    Were,
    That,
    Who,
    What,
    Where,
    When,
    Why,
    Does,
    Do,

    // Identity & Reflexive (FOL)
    Identity,
    Equals,
    Reflexive,
    Reciprocal,
    Respectively,  // Phase 35: Pairwise list coordination

    // Pronouns (Discourse)
    Pronoun {
        gender: Gender,
        number: Number,
        case: Case,
    },

    // Prepositions (for N-ary relations)
    Preposition(Symbol),

    // Phrasal Verb Particles (up, down, out, in, off, on, away)
    Particle(Symbol),

    // Comparatives & Superlatives (Pillar 3 - Degree Semantics)
    Comparative(Symbol),
    Superlative(Symbol),
    Than,

    // Control Verbs (Chomsky's Control Theory)
    To,

    // Presupposition Triggers (Austin/Strawson)
    PresupTrigger(PresupKind),

    // Focus Particles (Rooth)
    Focus(FocusKind),

    // Mass Noun Measure
    Measure(MeasureKind),

    // Numeric Literals (prover-ready: stores raw string for symbolic math)
    Number(Symbol),

    // Phase 33: String literals "hello world"
    StringLiteral(Symbol),

    // Character literal: `x` (backtick syntax)
    CharLiteral(Symbol),

    // Index Access (1-indexed)
    Item,
    Items,

    // Possession (Genitive Case)
    Possessive,

    // Punctuation
    LParen,
    RParen,
    LBracket,
    RBracket,
    Comma,
    Period,

    // Arithmetic Operators
    Plus,
    Minus,
    Star,
    Slash,
    Percent,  // Modulo operator

    // Grand Challenge: Comparison Operators
    Lt,        // <
    Gt,        // >
    LtEq,      // <=
    GtEq,      // >=
    EqEq,      // ==
    NotEq,     // !=

    // Phase 38: Arrow for return type syntax
    Arrow,  // ->

    EOF,
}

#[derive(Debug, Clone)]
pub struct Token {
    pub kind: TokenType,
    pub lexeme: Symbol,
    pub span: Span,
}

impl Token {
    pub fn new(kind: TokenType, lexeme: Symbol, span: Span) -> Self {
        Token { kind, lexeme, span }
    }
}

impl TokenType {
    pub const WH_WORDS: &'static [TokenType] = &[
        TokenType::Who,
        TokenType::What,
        TokenType::Where,
        TokenType::When,
        TokenType::Why,
    ];

    pub const MODALS: &'static [TokenType] = &[
        TokenType::Must,
        TokenType::Shall,
        TokenType::Should,
        TokenType::Can,
        TokenType::May,
        TokenType::Cannot,
        TokenType::Would,
        TokenType::Could,
        TokenType::Might,
    ];
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn span_new_stores_positions() {
        let span = Span::new(5, 10);
        assert_eq!(span.start, 5);
        assert_eq!(span.end, 10);
    }

    #[test]
    fn span_default_is_zero() {
        let span = Span::default();
        assert_eq!(span.start, 0);
        assert_eq!(span.end, 0);
    }

    #[test]
    fn token_has_span_field() {
        use crate::intern::Interner;
        let mut interner = Interner::new();
        let lexeme = interner.intern("test");
        let token = Token::new(TokenType::Noun(lexeme), lexeme, Span::new(0, 4));
        assert_eq!(token.span.start, 0);
        assert_eq!(token.span.end, 4);
    }

    #[test]
    fn wh_words_contains_all_wh_tokens() {
        assert_eq!(TokenType::WH_WORDS.len(), 5);
        assert!(TokenType::WH_WORDS.contains(&TokenType::Who));
        assert!(TokenType::WH_WORDS.contains(&TokenType::What));
        assert!(TokenType::WH_WORDS.contains(&TokenType::Where));
        assert!(TokenType::WH_WORDS.contains(&TokenType::When));
        assert!(TokenType::WH_WORDS.contains(&TokenType::Why));
    }

    #[test]
    fn modals_contains_all_modal_tokens() {
        assert_eq!(TokenType::MODALS.len(), 9);
        assert!(TokenType::MODALS.contains(&TokenType::Must));
        assert!(TokenType::MODALS.contains(&TokenType::Shall));
        assert!(TokenType::MODALS.contains(&TokenType::Should));
        assert!(TokenType::MODALS.contains(&TokenType::Can));
        assert!(TokenType::MODALS.contains(&TokenType::May));
        assert!(TokenType::MODALS.contains(&TokenType::Cannot));
        assert!(TokenType::MODALS.contains(&TokenType::Would));
        assert!(TokenType::MODALS.contains(&TokenType::Could));
        assert!(TokenType::MODALS.contains(&TokenType::Might));
    }
}

```

---

use crate::intern::Interner;
use crate::lexicon::{self, Aspect, Definiteness, Lexicon, Time};
use crate::token::{BlockType, FocusKind, MeasureKind, Span, Token, TokenType};

// ============================================================================
// Stage 1: Line Lexer (Spec §2.5.2)
// ============================================================================

/// Tokens emitted by the LineLexer (Stage 1).
/// Handles structural tokens (Indent, Dedent, Newline) while treating
/// all other content as opaque for Stage 2 word classification.
#[derive(Debug, Clone, PartialEq)]
pub enum LineToken {
    /// Block increased indentation
    Indent,
    /// Block decreased indentation
    Dedent,
    /// Logical newline (statement boundary) - reserved for future use
    Newline,
    /// Content to be further tokenized (line content, trimmed)
    Content { text: String, start: usize, end: usize },
}

/// Stage 1 Lexer: Handles only lines, indentation, and structural tokens.
/// Treats all other text as opaque `Content` for the Stage 2 WordLexer.
pub struct LineLexer<'a> {
    source: &'a str,
    bytes: &'a [u8],
    indent_stack: Vec<usize>,
    pending_dedents: usize,
    position: usize,
    /// True if we need to emit Content for current line
    has_pending_content: bool,
    pending_content_start: usize,
    pending_content_end: usize,
    pending_content_text: String,
    /// True after we've finished processing all lines
    finished_lines: bool,
    /// True if we've emitted at least one Indent (need to emit Dedents at EOF)
    emitted_indent: bool,
}

impl<'a> LineLexer<'a> {
    pub fn new(source: &'a str) -> Self {
        Self {
            source,
            bytes: source.as_bytes(),
            indent_stack: vec![0],
            pending_dedents: 0,
            position: 0,
            has_pending_content: false,
            pending_content_start: 0,
            pending_content_end: 0,
            pending_content_text: String::new(),
            finished_lines: false,
            emitted_indent: false,
        }
    }

    /// Calculate indentation level at current position (at start of line).
    /// Returns (indent_level, content_start_pos).
    fn measure_indent(&self, line_start: usize) -> (usize, usize) {
        let mut indent = 0;
        let mut pos = line_start;

        while pos < self.bytes.len() {
            match self.bytes[pos] {
                b' ' => {
                    indent += 1;
                    pos += 1;
                }
                b'\t' => {
                    indent += 4; // Tab = 4 spaces
                    pos += 1;
                }
                _ => break,
            }
        }

        (indent, pos)
    }

    /// Read content from current position until end of line or EOF.
    /// Returns (content_text, content_start, content_end, next_line_start).
    fn read_line_content(&self, content_start: usize) -> (String, usize, usize, usize) {
        let mut pos = content_start;

        // Find end of line
        while pos < self.bytes.len() && self.bytes[pos] != b'\n' {
            pos += 1;
        }

        let content_end = pos;
        let text = self.source[content_start..content_end].trim_end().to_string();

        // Move past newline if present
        let next_line_start = if pos < self.bytes.len() && self.bytes[pos] == b'\n' {
            pos + 1
        } else {
            pos
        };

        (text, content_start, content_end, next_line_start)
    }

    /// Check if the line starting at `pos` is blank (only whitespace).
    fn is_blank_line(&self, line_start: usize) -> bool {
        let mut pos = line_start;
        while pos < self.bytes.len() {
            match self.bytes[pos] {
                b' ' | b'\t' => pos += 1,
                b'\n' => return true,
                _ => return false,
            }
        }
        true // EOF counts as blank
    }

    /// Process the next line and update internal state.
    /// Returns true if we have tokens to emit, false if we're done.
    fn process_next_line(&mut self) -> bool {
        // Skip blank lines
        while self.position < self.bytes.len() && self.is_blank_line(self.position) {
            // Skip to next line
            while self.position < self.bytes.len() && self.bytes[self.position] != b'\n' {
                self.position += 1;
            }
            if self.position < self.bytes.len() {
                self.position += 1; // Skip the newline
            }
        }

        // Check if we've reached EOF
        if self.position >= self.bytes.len() {
            self.finished_lines = true;
            // Emit remaining dedents at EOF
            if self.indent_stack.len() > 1 {
                self.pending_dedents = self.indent_stack.len() - 1;
                self.indent_stack.truncate(1);
            }
            return self.pending_dedents > 0;
        }

        // Measure indentation of current line
        let (line_indent, content_start) = self.measure_indent(self.position);

        // Read line content
        let (text, start, end, next_pos) = self.read_line_content(content_start);

        // Skip if content is empty (shouldn't happen after blank line skip, but be safe)
        if text.is_empty() {
            self.position = next_pos;
            return self.process_next_line();
        }

        let current_indent = *self.indent_stack.last().unwrap();

        // Handle indentation changes
        if line_indent > current_indent {
            // Indent: push new level
            self.indent_stack.push(line_indent);
            self.emitted_indent = true;
            // Store content to emit after Indent
            self.has_pending_content = true;
            self.pending_content_text = text;
            self.pending_content_start = start;
            self.pending_content_end = end;
            self.position = next_pos;
            // We'll emit Indent first, then Content
            return true;
        } else if line_indent < current_indent {
            // Dedent: pop until we match
            while self.indent_stack.len() > 1 {
                let top = *self.indent_stack.last().unwrap();
                if line_indent < top {
                    self.indent_stack.pop();
                    self.pending_dedents += 1;
                } else {
                    break;
                }
            }
            // Store content to emit after Dedents
            self.has_pending_content = true;
            self.pending_content_text = text;
            self.pending_content_start = start;
            self.pending_content_end = end;
            self.position = next_pos;
            return true;
        } else {
            // Same indentation level
            self.has_pending_content = true;
            self.pending_content_text = text;
            self.pending_content_start = start;
            self.pending_content_end = end;
            self.position = next_pos;
            return true;
        }
    }
}

impl<'a> Iterator for LineLexer<'a> {
    type Item = LineToken;

    fn next(&mut self) -> Option<LineToken> {
        // 1. Emit pending dedents first
        if self.pending_dedents > 0 {
            self.pending_dedents -= 1;
            return Some(LineToken::Dedent);
        }

        // 2. Emit pending content
        if self.has_pending_content {
            self.has_pending_content = false;
            let text = std::mem::take(&mut self.pending_content_text);
            let start = self.pending_content_start;
            let end = self.pending_content_end;
            return Some(LineToken::Content { text, start, end });
        }

        // 3. Check if we need to emit Indent (after pushing to stack)
        // This happens when we detected an indent but haven't emitted the token yet
        // We need to check if indent_stack was just modified

        // 4. Process next line
        if !self.finished_lines {
            let had_indent = self.indent_stack.len();
            if self.process_next_line() {
                // Check if we added an indent level
                if self.indent_stack.len() > had_indent {
                    return Some(LineToken::Indent);
                }
                // Check if we have pending dedents
                if self.pending_dedents > 0 {
                    self.pending_dedents -= 1;
                    return Some(LineToken::Dedent);
                }
                // Otherwise emit content
                if self.has_pending_content {
                    self.has_pending_content = false;
                    let text = std::mem::take(&mut self.pending_content_text);
                    let start = self.pending_content_start;
                    let end = self.pending_content_end;
                    return Some(LineToken::Content { text, start, end });
                }
            } else if self.pending_dedents > 0 {
                // EOF with pending dedents
                self.pending_dedents -= 1;
                return Some(LineToken::Dedent);
            }
        }

        // 5. Emit any remaining dedents at EOF
        if self.pending_dedents > 0 {
            self.pending_dedents -= 1;
            return Some(LineToken::Dedent);
        }

        None
    }
}

// ============================================================================
// Stage 2: Word Lexer (existing Lexer)
// ============================================================================

#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
pub enum LexerMode {
    #[default]
    Declarative, // Logic, Theorems, Definitions
    Imperative,  // Main, Functions, Code
}

pub struct Lexer<'a> {
    words: Vec<WordItem>,
    pos: usize,
    lexicon: Lexicon,
    interner: &'a mut Interner,
    input_len: usize,
    in_let_context: bool,
    mode: LexerMode,
    source: String,
}

struct WordItem {
    word: String,
    trailing_punct: Option<char>,
    start: usize,
    end: usize,
    punct_pos: Option<usize>,
}

impl<'a> Lexer<'a> {
    pub fn new(input: &str, interner: &'a mut Interner) -> Self {
        let words = Self::split_into_words(input);
        let input_len = input.len();

        Lexer {
            words,
            pos: 0,
            lexicon: Lexicon::new(),
            interner,
            input_len,
            in_let_context: false,
            mode: LexerMode::Declarative,
            source: input.to_string(),
        }
    }

    fn split_into_words(input: &str) -> Vec<WordItem> {
        let mut items = Vec::new();
        let mut current_word = String::new();
        let mut word_start = 0;
        let chars: Vec<char> = input.chars().collect();
        let mut char_idx = 0;
        let mut skip_count = 0;

        for (i, c) in input.char_indices() {
            if skip_count > 0 {
                skip_count -= 1;
                char_idx += 1;
                continue;
            }
            let next_pos = i + c.len_utf8();
            match c {
                ' ' | '\t' | '\n' | '\r' => {
                    if !current_word.is_empty() {
                        items.push(WordItem {
                            word: std::mem::take(&mut current_word),
                            trailing_punct: None,
                            start: word_start,
                            end: i,
                            punct_pos: None,
                        });
                    }
                    word_start = next_pos;
                }
                '.' => {
                    // Check if this is a decimal point (digit before and after)
                    let prev_is_digit = !current_word.is_empty()
                        && current_word.chars().last().map_or(false, |ch| ch.is_ascii_digit());
                    let next_is_digit = char_idx + 1 < chars.len()
                        && chars[char_idx + 1].is_ascii_digit();

                    if prev_is_digit && next_is_digit {
                        // This is a decimal point, include it in the current word
                        current_word.push(c);
                    } else {
                        // This is a sentence period
                        if !current_word.is_empty() {
                            items.push(WordItem {
                                word: std::mem::take(&mut current_word),
                                trailing_punct: Some(c),
                                start: word_start,
                                end: i,
                                punct_pos: Some(i),
                            });
                        } else {
                            items.push(WordItem {
                                word: String::new(),
                                trailing_punct: Some(c),
                                start: i,
                                end: next_pos,
                                punct_pos: Some(i),
                            });
                        }
                        word_start = next_pos;
                    }
                }
                '#' => {
                    // Check for ## block header (markdown-style)
                    if char_idx + 1 < chars.len() && chars[char_idx + 1] == '#' {
                        // This is a ## block header
                        // Skip the second # and capture the next word as a block header
                        if !current_word.is_empty() {
                            items.push(WordItem {
                                word: std::mem::take(&mut current_word),
                                trailing_punct: None,
                                start: word_start,
                                end: i,
                                punct_pos: None,
                            });
                        }
                        // Skip whitespace after ##
                        let header_start = i;
                        let mut j = char_idx + 2;
                        while j < chars.len() && (chars[j] == ' ' || chars[j] == '\t') {
                            j += 1;
                        }
                        // Capture the block type word
                        let mut block_word = String::from("##");
                        while j < chars.len() && chars[j].is_alphabetic() {
                            block_word.push(chars[j]);
                            j += 1;
                        }
                        if block_word.len() > 2 {
                            items.push(WordItem {
                                word: block_word,
                                trailing_punct: None,
                                start: header_start,
                                end: header_start + (j - char_idx),
                                punct_pos: None,
                            });
                        }
                        skip_count = j - char_idx - 1;
                        word_start = header_start + (j - char_idx);
                    } else {
                        // Single # - treat as comment, skip to end of line
                        // Count how many chars to skip (without modifying char_idx here -
                        // the main loop's skip handler will increment it)
                        let mut look_ahead = char_idx + 1;
                        while look_ahead < chars.len() && chars[look_ahead] != '\n' {
                            skip_count += 1;
                            look_ahead += 1;
                        }
                        if !current_word.is_empty() {
                            items.push(WordItem {
                                word: std::mem::take(&mut current_word),
                                trailing_punct: None,
                                start: word_start,
                                end: i,
                                punct_pos: None,
                            });
                        }
                        word_start = look_ahead + 1; // Start after the newline
                    }
                }
                // Phase 33: String literals "hello world"
                '"' => {
                    // Push any pending word
                    if !current_word.is_empty() {
                        items.push(WordItem {
                            word: std::mem::take(&mut current_word),
                            trailing_punct: None,
                            start: word_start,
                            end: i,
                            punct_pos: None,
                        });
                    }

                    // Scan until closing quote
                    let string_start = i;
                    let mut j = char_idx + 1;
                    let mut string_content = String::new();
                    while j < chars.len() && chars[j] != '"' {
                        if chars[j] == '\\' && j + 1 < chars.len() {
                            // Escape sequence - skip backslash, include next char
                            j += 1;
                            if j < chars.len() {
                                string_content.push(chars[j]);
                            }
                        } else {
                            string_content.push(chars[j]);
                        }
                        j += 1;
                    }

                    // Create a special marker for string literals
                    // We prefix with a special character to identify in tokenize()
                    items.push(WordItem {
                        word: format!("\x00STR:{}", string_content),
                        trailing_punct: None,
                        start: string_start,
                        end: if j < chars.len() { j + 1 } else { j },
                        punct_pos: None,
                    });

                    // Skip past the closing quote
                    if j < chars.len() {
                        skip_count = j - char_idx;
                    } else {
                        skip_count = j - char_idx - 1;
                    }
                    word_start = if j < chars.len() { j + 1 } else { j };
                }
                // Character literals with backticks: `x`
                '`' => {
                    // Push any pending word
                    if !current_word.is_empty() {
                        items.push(WordItem {
                            word: std::mem::take(&mut current_word),
                            trailing_punct: None,
                            start: word_start,
                            end: i,
                            punct_pos: None,
                        });
                    }

                    // Scan for character content and closing backtick
                    let char_start = i;
                    let mut j = char_idx + 1;
                    let mut char_content = String::new();

                    if j < chars.len() {
                        if chars[j] == '\\' && j + 1 < chars.len() {
                            // Escape sequence
                            j += 1;
                            let escaped_char = match chars[j] {
                                'n' => '\n',
                                't' => '\t',
                                'r' => '\r',
                                '\\' => '\\',
                                '`' => '`',
                                '0' => '\0',
                                c => c,
                            };
                            char_content.push(escaped_char);
                            j += 1;
                        } else if chars[j] != '`' {
                            // Regular character
                            char_content.push(chars[j]);
                            j += 1;
                        }
                    }

                    // Expect closing backtick
                    if j < chars.len() && chars[j] == '`' {
                        j += 1; // skip closing backtick
                    }

                    // Create a special marker for char literals
                    items.push(WordItem {
                        word: format!("\x00CHAR:{}", char_content),
                        trailing_punct: None,
                        start: char_start,
                        end: if j <= chars.len() { char_start + (j - char_idx) } else { char_start + 1 },
                        punct_pos: None,
                    });

                    if j > char_idx + 1 {
                        skip_count = j - char_idx - 1;
                    }
                    word_start = char_start + (j - char_idx);
                }
                // Phase 38: Handle -> as a single token for return type syntax
                '-' if char_idx + 1 < chars.len() && chars[char_idx + 1] == '>' => {
                    // Push any pending word first
                    if !current_word.is_empty() {
                        items.push(WordItem {
                            word: std::mem::take(&mut current_word),
                            trailing_punct: None,
                            start: word_start,
                            end: i,
                            punct_pos: None,
                        });
                    }
                    // Push -> as its own word
                    items.push(WordItem {
                        word: "->".to_string(),
                        trailing_punct: None,
                        start: i,
                        end: i + 2,
                        punct_pos: None,
                    });
                    skip_count = 1; // Skip the '>' character
                    word_start = i + 2;
                }
                // Grand Challenge: Handle <= as a single token
                '<' if char_idx + 1 < chars.len() && chars[char_idx + 1] == '=' => {
                    if !current_word.is_empty() {
                        items.push(WordItem {
                            word: std::mem::take(&mut current_word),
                            trailing_punct: None,
                            start: word_start,
                            end: i,
                            punct_pos: None,
                        });
                    }
                    items.push(WordItem {
                        word: "<=".to_string(),
                        trailing_punct: None,
                        start: i,
                        end: i + 2,
                        punct_pos: None,
                    });
                    skip_count = 1;
                    word_start = i + 2;
                }
                // Grand Challenge: Handle >= as a single token
                '>' if char_idx + 1 < chars.len() && chars[char_idx + 1] == '=' => {
                    if !current_word.is_empty() {
                        items.push(WordItem {
                            word: std::mem::take(&mut current_word),
                            trailing_punct: None,
                            start: word_start,
                            end: i,
                            punct_pos: None,
                        });
                    }
                    items.push(WordItem {
                        word: ">=".to_string(),
                        trailing_punct: None,
                        start: i,
                        end: i + 2,
                        punct_pos: None,
                    });
                    skip_count = 1;
                    word_start = i + 2;
                }
                // Handle == as a single token
                '=' if char_idx + 1 < chars.len() && chars[char_idx + 1] == '=' => {
                    if !current_word.is_empty() {
                        items.push(WordItem {
                            word: std::mem::take(&mut current_word),
                            trailing_punct: None,
                            start: word_start,
                            end: i,
                            punct_pos: None,
                        });
                    }
                    items.push(WordItem {
                        word: "==".to_string(),
                        trailing_punct: None,
                        start: i,
                        end: i + 2,
                        punct_pos: None,
                    });
                    skip_count = 1;
                    word_start = i + 2;
                }
                // Handle != as a single token
                '!' if char_idx + 1 < chars.len() && chars[char_idx + 1] == '=' => {
                    if !current_word.is_empty() {
                        items.push(WordItem {
                            word: std::mem::take(&mut current_word),
                            trailing_punct: None,
                            start: word_start,
                            end: i,
                            punct_pos: None,
                        });
                    }
                    items.push(WordItem {
                        word: "!=".to_string(),
                        trailing_punct: None,
                        start: i,
                        end: i + 2,
                        punct_pos: None,
                    });
                    skip_count = 1;
                    word_start = i + 2;
                }
                '(' | ')' | '[' | ']' | ',' | '?' | '!' | ':' | '+' | '-' | '*' | '/' | '%' | '<' | '>' | '=' => {
                    if !current_word.is_empty() {
                        items.push(WordItem {
                            word: std::mem::take(&mut current_word),
                            trailing_punct: Some(c),
                            start: word_start,
                            end: i,
                            punct_pos: Some(i),
                        });
                    } else {
                        items.push(WordItem {
                            word: String::new(),
                            trailing_punct: Some(c),
                            start: i,
                            end: next_pos,
                            punct_pos: Some(i),
                        });
                    }
                    word_start = next_pos;
                }
                '\'' => {
                    // Handle contractions: expand "don't" → "do" + "not", etc.
                    let remaining: String = chars[char_idx + 1..].iter().collect();
                    let remaining_lower = remaining.to_lowercase();

                    if remaining_lower.starts_with("t ") || remaining_lower.starts_with("t.") ||
                       remaining_lower.starts_with("t,") || remaining_lower == "t" ||
                       (char_idx + 1 < chars.len() && chars[char_idx + 1] == 't' &&
                        (char_idx + 2 >= chars.len() || !chars[char_idx + 2].is_alphabetic())) {
                        // This is a contraction ending in 't (don't, doesn't, won't, can't, etc.)
                        let word_lower = current_word.to_lowercase();
                        if word_lower == "don" || word_lower == "doesn" || word_lower == "didn" {
                            // do/does/did + not
                            let base = if word_lower == "don" { "do" }
                                      else if word_lower == "doesn" { "does" }
                                      else { "did" };
                            items.push(WordItem {
                                word: base.to_string(),
                                trailing_punct: None,
                                start: word_start,
                                end: i,
                                punct_pos: None,
                            });
                            items.push(WordItem {
                                word: "not".to_string(),
                                trailing_punct: None,
                                start: i,
                                end: i + 2,
                                punct_pos: None,
                            });
                            current_word.clear();
                            word_start = next_pos + 1;
                            skip_count = 1;
                        } else if word_lower == "won" {
                            // will + not
                            items.push(WordItem {
                                word: "will".to_string(),
                                trailing_punct: None,
                                start: word_start,
                                end: i,
                                punct_pos: None,
                            });
                            items.push(WordItem {
                                word: "not".to_string(),
                                trailing_punct: None,
                                start: i,
                                end: i + 2,
                                punct_pos: None,
                            });
                            current_word.clear();
                            word_start = next_pos + 1;
                            skip_count = 1;
                        } else if word_lower == "can" {
                            // cannot
                            items.push(WordItem {
                                word: "cannot".to_string(),
                                trailing_punct: None,
                                start: word_start,
                                end: i + 2,
                                punct_pos: None,
                            });
                            current_word.clear();
                            word_start = next_pos + 1;
                            skip_count = 1;
                        } else {
                            // Unknown contraction, split normally
                            if !current_word.is_empty() {
                                items.push(WordItem {
                                    word: std::mem::take(&mut current_word),
                                    trailing_punct: Some('\''),
                                    start: word_start,
                                    end: i,
                                    punct_pos: Some(i),
                                });
                            }
                            word_start = next_pos;
                        }
                    } else {
                        // Not a 't contraction, handle normally
                        if !current_word.is_empty() {
                            items.push(WordItem {
                                word: std::mem::take(&mut current_word),
                                trailing_punct: Some('\''),
                                start: word_start,
                                end: i,
                                punct_pos: Some(i),
                            });
                        }
                        word_start = next_pos;
                    }
                }
                c if c.is_alphabetic() || c.is_ascii_digit() || (c == '.' && !current_word.is_empty() && current_word.chars().all(|ch| ch.is_ascii_digit())) || c == '_' => {
                    if current_word.is_empty() {
                        word_start = i;
                    }
                    current_word.push(c);
                }
                _ => {
                    word_start = next_pos;
                }
            }
            char_idx += 1;
        }

        if !current_word.is_empty() {
            items.push(WordItem {
                word: current_word,
                trailing_punct: None,
                start: word_start,
                end: input.len(),
                punct_pos: None,
            });
        }

        items
    }

    fn peek_word(&self, offset: usize) -> Option<&str> {
        self.words.get(self.pos + offset).map(|w| w.word.as_str())
    }

    fn peek_sequence(&self, expected: &[&str]) -> bool {
        for (i, &exp) in expected.iter().enumerate() {
            match self.peek_word(i + 1) {
                Some(w) if w.to_lowercase() == exp => continue,
                _ => return false,
            }
        }
        true
    }

    fn consume_words(&mut self, count: usize) {
        self.pos += count;
    }

    pub fn tokenize(&mut self) -> Vec<Token> {
        let mut tokens = Vec::new();

        while self.pos < self.words.len() {
            let item = &self.words[self.pos];
            let word = item.word.clone();
            let trailing_punct = item.trailing_punct;
            let word_start = item.start;
            let word_end = item.end;
            let punct_pos = item.punct_pos;

            if word.is_empty() {
                if let Some(punct) = trailing_punct {
                    let kind = match punct {
                        '(' => TokenType::LParen,
                        ')' => TokenType::RParen,
                        '[' => TokenType::LBracket,
                        ']' => TokenType::RBracket,
                        ',' => TokenType::Comma,
                        ':' => TokenType::Colon,
                        '.' | '?' => {
                            self.in_let_context = false;
                            TokenType::Period
                        }
                        '!' => TokenType::Exclamation,
                        '+' => TokenType::Plus,
                        '-' => TokenType::Minus,
                        '*' => TokenType::Star,
                        '/' => TokenType::Slash,
                        '%' => TokenType::Percent,
                        '<' => TokenType::Lt,
                        '>' => TokenType::Gt,
                        _ => {
                            self.pos += 1;
                            continue;
                        }
                    };
                    let lexeme = self.interner.intern(&punct.to_string());
                    let span = Span::new(word_start, word_end);
                    tokens.push(Token::new(kind, lexeme, span));
                }
                self.pos += 1;
                continue;
            }

            // Phase 33: Check for string literal marker
            if word.starts_with("\x00STR:") {
                let content = &word[5..]; // Skip the marker prefix
                let sym = self.interner.intern(content);
                let span = Span::new(word_start, word_end);
                tokens.push(Token::new(TokenType::StringLiteral(sym), sym, span));
                self.pos += 1;
                continue;
            }

            // Check for character literal marker
            if word.starts_with("\x00CHAR:") {
                let content = &word[6..]; // Skip the marker prefix
                let sym = self.interner.intern(content);
                let span = Span::new(word_start, word_end);
                tokens.push(Token::new(TokenType::CharLiteral(sym), sym, span));
                self.pos += 1;
                continue;
            }

            let kind = self.classify_with_lookahead(&word);
            let lexeme = self.interner.intern(&word);
            let span = Span::new(word_start, word_end);
            tokens.push(Token::new(kind, lexeme, span));

            if let Some(punct) = trailing_punct {
                if punct == '\'' {
                    if let Some(next_item) = self.words.get(self.pos + 1) {
                        if next_item.word.to_lowercase() == "s" {
                            let poss_lexeme = self.interner.intern("'s");
                            let poss_start = punct_pos.unwrap_or(word_end);
                            let poss_end = next_item.end;
                            tokens.push(Token::new(TokenType::Possessive, poss_lexeme, Span::new(poss_start, poss_end)));
                            self.pos += 1;
                            if let Some(s_punct) = next_item.trailing_punct {
                                let kind = match s_punct {
                                    '(' => TokenType::LParen,
                                    ')' => TokenType::RParen,
                                    '[' => TokenType::LBracket,
                                    ']' => TokenType::RBracket,
                                    ',' => TokenType::Comma,
                                    ':' => TokenType::Colon,
                                    '.' | '?' => TokenType::Period,
                                    '!' => TokenType::Exclamation,
                                    '+' => TokenType::Plus,
                                    '-' => TokenType::Minus,
                                    '*' => TokenType::Star,
                                    '/' => TokenType::Slash,
                                    '%' => TokenType::Percent,
                                    '<' => TokenType::Lt,
                                    '>' => TokenType::Gt,
                                    _ => {
                                        self.pos += 1;
                                        continue;
                                    }
                                };
                                let s_punct_pos = next_item.punct_pos.unwrap_or(next_item.end);
                                let lexeme = self.interner.intern(&s_punct.to_string());
                                tokens.push(Token::new(kind, lexeme, Span::new(s_punct_pos, s_punct_pos + 1)));
                            }
                            self.pos += 1;
                            continue;
                        }
                    }
                    self.pos += 1;
                    continue;
                }

                let kind = match punct {
                    '(' => TokenType::LParen,
                    ')' => TokenType::RParen,
                    '[' => TokenType::LBracket,
                    ']' => TokenType::RBracket,
                    ',' => TokenType::Comma,
                    ':' => TokenType::Colon,
                    '.' | '?' => {
                        self.in_let_context = false;
                        TokenType::Period
                    }
                    '!' => TokenType::Exclamation,
                    '+' => TokenType::Plus,
                    '-' => TokenType::Minus,
                    '*' => TokenType::Star,
                    '/' => TokenType::Slash,
                    '%' => TokenType::Percent,
                    '<' => TokenType::Lt,
                    '>' => TokenType::Gt,
                    _ => {
                        self.pos += 1;
                        continue;
                    }
                };
                let p_start = punct_pos.unwrap_or(word_end);
                let lexeme = self.interner.intern(&punct.to_string());
                tokens.push(Token::new(kind, lexeme, Span::new(p_start, p_start + 1)));
            }

            self.pos += 1;
        }

        let eof_lexeme = self.interner.intern("");
        let eof_span = Span::new(self.input_len, self.input_len);
        tokens.push(Token::new(TokenType::EOF, eof_lexeme, eof_span));

        self.insert_indentation_tokens(tokens)
    }

    /// Insert Indent/Dedent tokens using LineLexer's two-pass architecture (Spec §2.5.2).
    ///
    /// Phase 1: LineLexer determines the structural layout (where indents/dedents occur)
    /// Phase 2: We correlate these with word token positions
    fn insert_indentation_tokens(&mut self, tokens: Vec<Token>) -> Vec<Token> {
        let mut result = Vec::new();
        let empty_sym = self.interner.intern("");

        // Phase 1: Run LineLexer to determine structural positions
        let line_lexer = LineLexer::new(&self.source);
        let line_tokens: Vec<LineToken> = line_lexer.collect();

        // Build a list of (byte_position, is_indent) for structural tokens
        // Position is where the NEXT Content starts after the Indent/Dedent
        let mut structural_events: Vec<(usize, bool)> = Vec::new(); // (byte_pos, true=Indent, false=Dedent)
        let mut pending_indents = 0usize;
        let mut pending_dedents = 0usize;

        for line_token in &line_tokens {
            match line_token {
                LineToken::Indent => {
                    pending_indents += 1;
                }
                LineToken::Dedent => {
                    pending_dedents += 1;
                }
                LineToken::Content { start, .. } => {
                    // Emit pending dedents first (they come BEFORE the content)
                    for _ in 0..pending_dedents {
                        structural_events.push((*start, false)); // false = Dedent
                    }
                    pending_dedents = 0;

                    // Emit pending indents (they also come BEFORE the content)
                    for _ in 0..pending_indents {
                        structural_events.push((*start, true)); // true = Indent
                    }
                    pending_indents = 0;
                }
                LineToken::Newline => {}
            }
        }

        // Handle any remaining dedents at EOF
        for _ in 0..pending_dedents {
            structural_events.push((self.input_len, false));
        }

        // Sort events by position, with dedents before indents at same position
        structural_events.sort_by(|a, b| {
            if a.0 != b.0 {
                a.0.cmp(&b.0)
            } else {
                // Dedents (false) before Indents (true) at same position
                a.1.cmp(&b.1)
            }
        });

        // Phase 2: Insert structural tokens at the right positions
        // Strategy: For each word token, check if any structural events should be inserted
        // before it (based on byte position)

        let mut event_idx = 0;
        let mut last_colon_pos: Option<usize> = None;

        for token in tokens.iter() {
            let token_start = token.span.start;

            // Insert any structural tokens that should come BEFORE this token
            while event_idx < structural_events.len() {
                let (event_pos, is_indent) = structural_events[event_idx];

                // Insert structural tokens before this token if the event position <= token start
                if event_pos <= token_start {
                    let span = if is_indent {
                        // Indent is inserted after the preceding Colon
                        Span::new(last_colon_pos.unwrap_or(event_pos), last_colon_pos.unwrap_or(event_pos))
                    } else {
                        Span::new(event_pos, event_pos)
                    };
                    let kind = if is_indent { TokenType::Indent } else { TokenType::Dedent };
                    result.push(Token::new(kind, empty_sym, span));
                    event_idx += 1;
                } else {
                    break;
                }
            }

            result.push(token.clone());

            // Track colon positions for Indent span calculation
            if token.kind == TokenType::Colon && self.is_end_of_line(token.span.end) {
                last_colon_pos = Some(token.span.end);
            }
        }

        // Insert any remaining structural tokens (typically Dedents at EOF)
        while event_idx < structural_events.len() {
            let (event_pos, is_indent) = structural_events[event_idx];
            let span = Span::new(event_pos, event_pos);
            let kind = if is_indent { TokenType::Indent } else { TokenType::Dedent };
            result.push(Token::new(kind, empty_sym, span));
            event_idx += 1;
        }

        // Ensure EOF is at the end
        let eof_pos = result.iter().position(|t| t.kind == TokenType::EOF);
        if let Some(pos) = eof_pos {
            let eof = result.remove(pos);
            result.push(eof);
        }

        result
    }

    /// Check if position is at end of line (only whitespace until newline)
    fn is_end_of_line(&self, from_pos: usize) -> bool {
        let bytes = self.source.as_bytes();
        let mut pos = from_pos;
        while pos < bytes.len() {
            match bytes[pos] {
                b' ' | b'\t' => pos += 1,
                b'\n' => return true,
                _ => return false,
            }
        }
        true // End of input is also end of line
    }

    fn measure_next_line_indent(&self, from_pos: usize) -> Option<usize> {
        let bytes = self.source.as_bytes();
        let mut pos = from_pos;

        while pos < bytes.len() && bytes[pos] != b'\n' {
            pos += 1;
        }

        if pos >= bytes.len() {
            return None;
        }

        pos += 1;

        let mut indent = 0;
        while pos < bytes.len() {
            match bytes[pos] {
                b' ' => indent += 1,
                b'\t' => indent += 4,
                b'\n' => {
                    indent = 0;
                }
                _ => break,
            }
            pos += 1;
        }

        if pos >= bytes.len() {
            return None;
        }

        Some(indent)
    }

    fn word_to_number(word: &str) -> Option<u32> {
        lexicon::word_to_number(&word.to_lowercase())
    }

    fn is_numeric_literal(word: &str) -> bool {
        if word.is_empty() {
            return false;
        }
        let chars: Vec<char> = word.chars().collect();
        let first = chars[0];
        if first.is_ascii_digit() {
            // Numeric literal: starts with digit (may have underscore separators like 1_000)
            return true;
        }
        // Symbolic numbers: only recognize known mathematical symbols
        // (aleph, omega, beth) followed by underscore and digits
        if let Some(underscore_pos) = word.rfind('_') {
            let before_underscore = &word[..underscore_pos];
            let after_underscore = &word[underscore_pos + 1..];
            // Must be a known mathematical symbol prefix AND digits after underscore
            let is_math_symbol = matches!(
                before_underscore.to_lowercase().as_str(),
                "aleph" | "omega" | "beth"
            );
            if is_math_symbol
                && !after_underscore.is_empty()
                && after_underscore.chars().all(|c| c.is_ascii_digit())
            {
                return true;
            }
        }
        false
    }

    fn classify_with_lookahead(&mut self, word: &str) -> TokenType {
        // Handle block headers (##Theorem, ##Main, etc.)
        if word.starts_with("##") {
            let block_name = &word[2..];
            let block_type = match block_name.to_lowercase().as_str() {
                "theorem" => BlockType::Theorem,
                "main" => BlockType::Main,
                "definition" => BlockType::Definition,
                "proof" => BlockType::Proof,
                "example" => BlockType::Example,
                "logic" => BlockType::Logic,
                "note" => BlockType::Note,
                "to" => BlockType::Function,  // Phase 32: ## To blocks
                "a" | "an" => BlockType::TypeDef,  // Inline type definitions: ## A Point has:
                "policy" => BlockType::Policy,  // Phase 50: Security policy definitions
                _ => BlockType::Note, // Default unknown block types to Note
            };

            // Update lexer mode based on block type
            self.mode = match block_type {
                BlockType::Main | BlockType::Function => LexerMode::Imperative,
                _ => LexerMode::Declarative,
            };

            return TokenType::BlockHeader { block_type };
        }

        let lower = word.to_lowercase();

        if lower == "each" && self.peek_sequence(&["other"]) {
            self.consume_words(1);
            return TokenType::Reciprocal;
        }

        if lower == "to" {
            if let Some(next) = self.peek_word(1) {
                if self.is_verb_like(next) {
                    return TokenType::To;
                }
            }
            let sym = self.interner.intern("to");
            return TokenType::Preposition(sym);
        }

        if lower == "at" {
            if let Some(next) = self.peek_word(1) {
                let next_lower = next.to_lowercase();
                if next_lower == "least" {
                    if let Some(num_word) = self.peek_word(2) {
                        if let Some(n) = Self::word_to_number(num_word) {
                            self.consume_words(2);
                            return TokenType::AtLeast(n);
                        }
                    }
                }
                if next_lower == "most" {
                    if let Some(num_word) = self.peek_word(2) {
                        if let Some(n) = Self::word_to_number(num_word) {
                            self.consume_words(2);
                            return TokenType::AtMost(n);
                        }
                    }
                }
            }
        }

        if let Some(n) = Self::word_to_number(&lower) {
            return TokenType::Cardinal(n);
        }

        if Self::is_numeric_literal(word) {
            let sym = self.interner.intern(word);
            return TokenType::Number(sym);
        }

        if lower == "if" && self.peek_sequence(&["and", "only", "if"]) {
            self.consume_words(3);
            return TokenType::Iff;
        }

        if lower == "is" {
            if self.peek_sequence(&["equal", "to"]) {
                self.consume_words(2);
                return TokenType::Identity;
            }
            if self.peek_sequence(&["identical", "to"]) {
                self.consume_words(2);
                return TokenType::Identity;
            }
        }

        if (lower == "a" || lower == "an") && word.chars().next().unwrap().is_uppercase() {
            // Capitalized "A" or "An" - disambiguate article vs proper name
            // Heuristic: articles are followed by nouns/adjectives, not verbs or keywords
            if let Some(next) = self.peek_word(1) {
                let next_lower = next.to_lowercase();
                let next_starts_lowercase = next.chars().next().map(|c| c.is_lowercase()).unwrap_or(false);

                // If followed by logical keyword, treat as proper name (propositional variable)
                if matches!(next_lower.as_str(), "if" | "and" | "or" | "implies" | "iff") {
                    let sym = self.interner.intern(word);
                    return TokenType::ProperName(sym);
                }

                // If next word is ONLY a verb (like "has", "is", "ran"), A is likely a name
                // Exception: gerunds (like "running") can follow articles
                // Exception: words in disambiguation_not_verbs (like "red") are not verbs
                // Exception: words that are also nouns/adjectives (like "fire") can follow articles
                let is_verb = self.lexicon.lookup_verb(&next_lower).is_some()
                    && !lexicon::is_disambiguation_not_verb(&next_lower);
                let is_gerund = next_lower.ends_with("ing");
                let is_also_noun_or_adj = self.is_noun_like(&next_lower) || self.is_adjective_like(&next_lower);
                if is_verb && !is_gerund && !is_also_noun_or_adj {
                    let sym = self.interner.intern(word);
                    return TokenType::ProperName(sym);
                }

                // Definition pattern: "A [TypeName] is a..." or "A [TypeName] has:" - treat A as article
                // even when TypeName is capitalized and unknown
                if let Some(third) = self.peek_word(2) {
                    let third_lower = third.to_lowercase();
                    // Phase 31: Added "has" for struct definitions
                    if third_lower == "is" || third_lower == "are" || third_lower == "has" {
                        return TokenType::Article(Definiteness::Indefinite);
                    }
                }

                // It's an article if next word is:
                // - A known noun or adjective, or
                // - Lowercase (likely a common word we don't recognize)
                let is_content_word = self.is_noun_like(&next_lower) || self.is_adjective_like(&next_lower);
                if is_content_word || next_starts_lowercase {
                    return TokenType::Article(Definiteness::Indefinite);
                }
            }
            let sym = self.interner.intern(word);
            return TokenType::ProperName(sym);
        }

        self.classify_word(word)
    }

    fn is_noun_like(&self, word: &str) -> bool {
        if lexicon::is_noun_pattern(word) || lexicon::is_common_noun(word) {
            return true;
        }
        if word.ends_with("er") || word.ends_with("ian") || word.ends_with("ist") {
            return true;
        }
        false
    }

    fn is_adjective_like(&self, word: &str) -> bool {
        lexicon::is_adjective(word) || lexicon::is_non_intersective(word)
    }

    fn classify_word(&mut self, word: &str) -> TokenType {
        let lower = word.to_lowercase();
        let first_char = word.chars().next().unwrap();

        // Disambiguate "that" as determiner vs complementizer
        // "that dog" → Article(Distal), "I know that he ran" → That (complementizer)
        if lower == "that" {
            if let Some(next) = self.peek_word(1) {
                let next_lower = next.to_lowercase();
                if self.is_noun_like(&next_lower) || self.is_adjective_like(&next_lower) {
                    return TokenType::Article(Definiteness::Distal);
                }
            }
        }

        // Phase 38: Arrow token for return type syntax
        if word == "->" {
            return TokenType::Arrow;
        }

        // Grand Challenge: Comparison operator tokens
        if word == "<=" {
            return TokenType::LtEq;
        }
        if word == ">=" {
            return TokenType::GtEq;
        }
        if word == "==" {
            return TokenType::EqEq;
        }
        if word == "!=" {
            return TokenType::NotEq;
        }
        if word == "<" {
            return TokenType::Lt;
        }
        if word == ">" {
            return TokenType::Gt;
        }

        if let Some(kind) = lexicon::lookup_keyword(&lower) {
            return kind;
        }

        if let Some(kind) = lexicon::lookup_pronoun(&lower) {
            return kind;
        }

        if let Some(def) = lexicon::lookup_article(&lower) {
            return TokenType::Article(def);
        }

        if let Some(time) = lexicon::lookup_auxiliary(&lower) {
            return TokenType::Auxiliary(time);
        }

        // Handle imperative keywords that might conflict with prepositions
        match lower.as_str() {
            "call" => return TokenType::Call,
            "in" if self.mode == LexerMode::Imperative => return TokenType::In,
            // Phase 8.5: Zone keywords (must come before is_preposition check)
            "inside" if self.mode == LexerMode::Imperative => return TokenType::Inside,
            // Phase 48: "at" for chunk access (must come before is_preposition check)
            "at" if self.mode == LexerMode::Imperative => return TokenType::At,
            // Phase 54: "into" for pipe send (must come before is_preposition check)
            "into" if self.mode == LexerMode::Imperative => return TokenType::Into,
            _ => {}
        }

        if lexicon::is_preposition(&lower) {
            let sym = self.interner.intern(&lower);
            return TokenType::Preposition(sym);
        }

        match lower.as_str() {
            "equals" => return TokenType::Equals,
            "item" => return TokenType::Item,
            "items" => return TokenType::Items,
            "let" => {
                self.in_let_context = true;
                return TokenType::Let;
            }
            "set" => {
                // Check if "set" is used as a type (followed by "of") - "Set of Int"
                // This takes priority over the assignment keyword
                if self.peek_word(1).map_or(false, |w| w.to_lowercase() == "of") {
                    // It's a type like "Set of Int" - don't return keyword, let it be a noun
                } else if self.mode == LexerMode::Imperative {
                    // In Imperative mode, treat "set" as the assignment keyword
                    return TokenType::Set;
                } else {
                    // Phase 31: In Declarative mode, check positions 2-5 for "to"
                    // (handles field access like "set p's x to")
                    for offset in 2..=5 {
                        if self.peek_word(offset).map_or(false, |w| w.to_lowercase() == "to") {
                            return TokenType::Set;
                        }
                    }
                }
            }
            "return" => return TokenType::Return,
            "be" if self.in_let_context => {
                self.in_let_context = false;
                return TokenType::Be;
            }
            "while" => return TokenType::While,
            "assert" => return TokenType::Assert,
            "trust" => return TokenType::Trust,  // Phase 35: Trust statement
            "check" => return TokenType::Check,  // Phase 50: Security check
            // Phase 51: P2P Networking keywords (Imperative mode only)
            "listen" if self.mode == LexerMode::Imperative => return TokenType::Listen,
            "connect" if self.mode == LexerMode::Imperative => return TokenType::NetConnect,
            "sleep" if self.mode == LexerMode::Imperative => return TokenType::Sleep,
            // Phase 52: GossipSub keywords (Imperative mode only)
            "sync" if self.mode == LexerMode::Imperative => return TokenType::Sync,
            // Phase 53: Persistence keywords
            "mount" if self.mode == LexerMode::Imperative => return TokenType::Mount,
            "persistent" => return TokenType::Persistent,  // Works in type expressions
            "combined" if self.mode == LexerMode::Imperative => return TokenType::Combined,
            // Phase 54: Go-like Concurrency keywords (Imperative mode only)
            // Note: "first" and "after" are NOT keywords - they're checked via lookahead in parser
            // to avoid conflicting with their use as variable names
            "launch" if self.mode == LexerMode::Imperative => return TokenType::Launch,
            "task" if self.mode == LexerMode::Imperative => return TokenType::Task,
            "pipe" if self.mode == LexerMode::Imperative => return TokenType::Pipe,
            "receive" if self.mode == LexerMode::Imperative => return TokenType::Receive,
            "stop" if self.mode == LexerMode::Imperative => return TokenType::Stop,
            "try" if self.mode == LexerMode::Imperative => return TokenType::Try,
            "into" if self.mode == LexerMode::Imperative => return TokenType::Into,
            "native" => return TokenType::Native,  // Phase 38: Native function modifier
            "from" => return TokenType::From,  // Phase 36: Module qualification
            "otherwise" => return TokenType::Otherwise,
            // Phase 33: Sum type definition (Declarative mode only - for enum "either...or...")
            "either" if self.mode == LexerMode::Declarative => return TokenType::Either,
            // Phase 33: Pattern matching statement
            "inspect" if self.mode == LexerMode::Imperative => return TokenType::Inspect,
            // Phase 31: Constructor keyword (Imperative mode only)
            "new" if self.mode == LexerMode::Imperative => return TokenType::New,
            // Only emit Give/Show as keywords in Imperative mode
            // In Declarative mode, they fall through to lexicon lookup as verbs
            "give" if self.mode == LexerMode::Imperative => return TokenType::Give,
            "show" if self.mode == LexerMode::Imperative => return TokenType::Show,
            // Phase 43D: Collection operation keywords (Imperative mode only)
            "push" if self.mode == LexerMode::Imperative => return TokenType::Push,
            "pop" if self.mode == LexerMode::Imperative => return TokenType::Pop,
            "copy" if self.mode == LexerMode::Imperative => return TokenType::Copy,
            "through" if self.mode == LexerMode::Imperative => return TokenType::Through,
            "length" if self.mode == LexerMode::Imperative => return TokenType::Length,
            "at" if self.mode == LexerMode::Imperative => return TokenType::At,
            // Set operation keywords (Imperative mode only)
            "add" if self.mode == LexerMode::Imperative => return TokenType::Add,
            "remove" if self.mode == LexerMode::Imperative => return TokenType::Remove,
            "contains" if self.mode == LexerMode::Imperative => return TokenType::Contains,
            "union" if self.mode == LexerMode::Imperative => return TokenType::Union,
            "intersection" if self.mode == LexerMode::Imperative => return TokenType::Intersection,
            // Phase 8.5: Zone keywords (Imperative mode only)
            "inside" if self.mode == LexerMode::Imperative => return TokenType::Inside,
            "zone" if self.mode == LexerMode::Imperative => return TokenType::Zone,
            "called" if self.mode == LexerMode::Imperative => return TokenType::Called,
            "size" if self.mode == LexerMode::Imperative => return TokenType::Size,
            "mapped" if self.mode == LexerMode::Imperative => return TokenType::Mapped,
            // Phase 9: Structured Concurrency keywords (Imperative mode only)
            "attempt" if self.mode == LexerMode::Imperative => return TokenType::Attempt,
            "following" if self.mode == LexerMode::Imperative => return TokenType::Following,
            "simultaneously" if self.mode == LexerMode::Imperative => return TokenType::Simultaneously,
            // Phase 10: IO keywords (Imperative mode only)
            "read" if self.mode == LexerMode::Imperative => return TokenType::Read,
            "write" if self.mode == LexerMode::Imperative => return TokenType::Write,
            "console" if self.mode == LexerMode::Imperative => return TokenType::Console,
            "file" if self.mode == LexerMode::Imperative => return TokenType::File,
            // Phase 46: Agent System keywords (Imperative mode only)
            "spawn" if self.mode == LexerMode::Imperative => return TokenType::Spawn,
            "send" if self.mode == LexerMode::Imperative => return TokenType::Send,
            "await" if self.mode == LexerMode::Imperative => return TokenType::Await,
            // Phase 47: Serialization keyword (works in Definition blocks too)
            "portable" => return TokenType::Portable,
            // Phase 48: Sipping Protocol keywords (Imperative mode only)
            "manifest" if self.mode == LexerMode::Imperative => return TokenType::Manifest,
            "chunk" if self.mode == LexerMode::Imperative => return TokenType::Chunk,
            // Phase 49: CRDT keywords
            "shared" => return TokenType::Shared,  // Works in Definition blocks like Portable
            "merge" if self.mode == LexerMode::Imperative => return TokenType::Merge,
            "increase" if self.mode == LexerMode::Imperative => return TokenType::Increase,
            // Phase 49b: Extended CRDT keywords (Wave 5)
            "decrease" if self.mode == LexerMode::Imperative => return TokenType::Decrease,
            "append" if self.mode == LexerMode::Imperative => return TokenType::Append,
            "resolve" if self.mode == LexerMode::Imperative => return TokenType::Resolve,
            "values" if self.mode == LexerMode::Imperative => return TokenType::Values,
            // Type keywords (work in both modes like "Shared"):
            "tally" => return TokenType::Tally,
            "sharedset" => return TokenType::SharedSet,
            "sharedsequence" => return TokenType::SharedSequence,
            "collaborativesequence" => return TokenType::CollaborativeSequence,
            "sharedmap" => return TokenType::SharedMap,
            "divergent" => return TokenType::Divergent,
            "removewins" => return TokenType::RemoveWins,
            "addwins" => return TokenType::AddWins,
            "yata" => return TokenType::YATA,
            "if" => return TokenType::If,
            "only" => return TokenType::Focus(FocusKind::Only),
            "even" => return TokenType::Focus(FocusKind::Even),
            "just" if self.peek_word(1).map_or(false, |w| {
                !self.is_verb_like(w) || w.to_lowercase() == "john" || w.chars().next().map_or(false, |c| c.is_uppercase())
            }) => return TokenType::Focus(FocusKind::Just),
            "much" => return TokenType::Measure(MeasureKind::Much),
            "little" => return TokenType::Measure(MeasureKind::Little),
            _ => {}
        }

        if lexicon::is_scopal_adverb(&lower) {
            let sym = self.interner.intern(&Self::capitalize(&lower));
            return TokenType::ScopalAdverb(sym);
        }

        if lexicon::is_temporal_adverb(&lower) {
            let sym = self.interner.intern(&Self::capitalize(&lower));
            return TokenType::TemporalAdverb(sym);
        }

        if lexicon::is_non_intersective(&lower) {
            let sym = self.interner.intern(&Self::capitalize(&lower));
            return TokenType::NonIntersectiveAdjective(sym);
        }

        if lexicon::is_adverb(&lower) {
            let sym = self.interner.intern(&Self::capitalize(&lower));
            return TokenType::Adverb(sym);
        }
        if lower.ends_with("ly") && !lexicon::is_not_adverb(&lower) && lower.len() > 4 {
            let sym = self.interner.intern(&Self::capitalize(&lower));
            return TokenType::Adverb(sym);
        }

        if let Some(base) = self.try_parse_superlative(&lower) {
            let sym = self.interner.intern(&base);
            return TokenType::Superlative(sym);
        }

        // Phase 35: Handle irregular comparatives (less, more, better, worse)
        let irregular_comparative = match lower.as_str() {
            "less" => Some("Little"),
            "more" => Some("Much"),
            "better" => Some("Good"),
            "worse" => Some("Bad"),
            _ => None,
        };
        if let Some(base) = irregular_comparative {
            let sym = self.interner.intern(base);
            return TokenType::Comparative(sym);
        }

        if let Some(base) = self.try_parse_comparative(&lower) {
            let sym = self.interner.intern(&base);
            return TokenType::Comparative(sym);
        }

        if lexicon::is_performative(&lower) {
            let sym = self.interner.intern(&Self::capitalize(&lower));
            return TokenType::Performative(sym);
        }

        if lexicon::is_base_verb_early(&lower) {
            let sym = self.interner.intern(&Self::capitalize(&lower));
            let class = lexicon::lookup_verb_class(&lower);
            return TokenType::Verb {
                lemma: sym,
                time: Time::Present,
                aspect: Aspect::Simple,
                class,
            };
        }

        // Check for gerunds/progressive verbs BEFORE ProperName check
        // "Running" at start of sentence should be Verb, not ProperName
        if lower.ends_with("ing") && lower.len() > 4 {
            if let Some(entry) = self.lexicon.lookup_verb(&lower) {
                let sym = self.interner.intern(&entry.lemma);
                return TokenType::Verb {
                    lemma: sym,
                    time: entry.time,
                    aspect: entry.aspect,
                    class: entry.class,
                };
            }
        }

        if first_char.is_uppercase() {
            // Smart Lexicon: Check if this capitalized word is actually a common noun
            // Only apply for sentence-initial words (followed by verb) to avoid
            // breaking type definitions like "A Point has:"
            //
            // Pattern: "Farmers walk." → Farmers is plural of Farmer (common noun)
            // Pattern: "A Point has:" → Point is a type name (proper name)
            if let Some(next) = self.peek_word(1) {
                let next_lower = next.to_lowercase();
                // If next word is a verb, this capitalized word is likely a subject noun
                let is_followed_by_verb = self.lexicon.lookup_verb(&next_lower).is_some()
                    || matches!(next_lower.as_str(), "is" | "are" | "was" | "were" | "has" | "have" | "had");

                if is_followed_by_verb {
                    // Check if lowercase version is a derivable common noun
                    if let Some(analysis) = lexicon::analyze_word(&lower) {
                        match analysis {
                            lexicon::WordAnalysis::Noun(meta) if meta.number == lexicon::Number::Plural => {
                                // It's a plural noun - definitely a common noun
                                let sym = self.interner.intern(&lower);
                                return TokenType::Noun(sym);
                            }
                            lexicon::WordAnalysis::DerivedNoun { number: lexicon::Number::Plural, .. } => {
                                // Derived plural agentive noun (e.g., "Bloggers")
                                let sym = self.interner.intern(&lower);
                                return TokenType::Noun(sym);
                            }
                            _ => {
                                // Singular nouns at sentence start could still be proper names
                                // e.g., "John walks." vs "Farmer walks."
                            }
                        }
                    }
                }
            }

            let sym = self.interner.intern(word);
            return TokenType::ProperName(sym);
        }

        let verb_entry = self.lexicon.lookup_verb(&lower);
        let is_noun = lexicon::is_common_noun(&lower);
        let is_adj = self.is_adjective_like(&lower);
        let is_disambiguated = lexicon::is_disambiguation_not_verb(&lower);

        // Ambiguous: word is Verb AND (Noun OR Adjective), not disambiguated
        if verb_entry.is_some() && (is_noun || is_adj) && !is_disambiguated {
            let entry = verb_entry.unwrap();
            let verb_token = TokenType::Verb {
                lemma: self.interner.intern(&entry.lemma),
                time: entry.time,
                aspect: entry.aspect,
                class: entry.class,
            };

            let mut alternatives = Vec::new();
            if is_noun {
                alternatives.push(TokenType::Noun(self.interner.intern(word)));
            }
            if is_adj {
                alternatives.push(TokenType::Adjective(self.interner.intern(word)));
            }

            return TokenType::Ambiguous {
                primary: Box::new(verb_token),
                alternatives,
            };
        }

        // Disambiguated to noun/adjective (not verb)
        if let Some(_) = &verb_entry {
            if is_disambiguated {
                let sym = self.interner.intern(word);
                if is_noun {
                    return TokenType::Noun(sym);
                }
                return TokenType::Adjective(sym);
            }
        }

        // Pure verb
        if let Some(entry) = verb_entry {
            let sym = self.interner.intern(&entry.lemma);
            return TokenType::Verb {
                lemma: sym,
                time: entry.time,
                aspect: entry.aspect,
                class: entry.class,
            };
        }

        // Pure noun
        if is_noun {
            let sym = self.interner.intern(word);
            return TokenType::Noun(sym);
        }

        if lexicon::is_base_verb(&lower) {
            let sym = self.interner.intern(&Self::capitalize(&lower));
            let class = lexicon::lookup_verb_class(&lower);
            return TokenType::Verb {
                lemma: sym,
                time: Time::Present,
                aspect: Aspect::Simple,
                class,
            };
        }

        if lower.ends_with("ian")
            || lower.ends_with("er")
            || lower == "logic"
            || lower == "time"
            || lower == "men"
            || lower == "book"
            || lower == "house"
            || lower == "code"
            || lower == "user"
        {
            let sym = self.interner.intern(word);
            return TokenType::Noun(sym);
        }

        if lexicon::is_particle(&lower) {
            let sym = self.interner.intern(&lower);
            return TokenType::Particle(sym);
        }

        let sym = self.interner.intern(word);
        TokenType::Adjective(sym)
    }

    fn capitalize(s: &str) -> String {
        let mut chars = s.chars();
        match chars.next() {
            None => String::new(),
            Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
        }
    }

    pub fn is_collective_verb(lemma: &str) -> bool {
        lexicon::is_collective_verb(&lemma.to_lowercase())
    }

    pub fn is_mixed_verb(lemma: &str) -> bool {
        lexicon::is_mixed_verb(&lemma.to_lowercase())
    }

    pub fn is_ditransitive_verb(lemma: &str) -> bool {
        lexicon::is_ditransitive_verb(&lemma.to_lowercase())
    }

    fn is_verb_like(&self, word: &str) -> bool {
        let lower = word.to_lowercase();
        if lexicon::is_infinitive_verb(&lower) {
            return true;
        }
        if let Some(entry) = self.lexicon.lookup_verb(&lower) {
            return entry.lemma.len() > 0;
        }
        false
    }

    pub fn is_subject_control_verb(lemma: &str) -> bool {
        lexicon::is_subject_control_verb(&lemma.to_lowercase())
    }

    pub fn is_raising_verb(lemma: &str) -> bool {
        lexicon::is_raising_verb(&lemma.to_lowercase())
    }

    pub fn is_object_control_verb(lemma: &str) -> bool {
        lexicon::is_object_control_verb(&lemma.to_lowercase())
    }

    pub fn is_weather_verb(lemma: &str) -> bool {
        matches!(
            lemma.to_lowercase().as_str(),
            "rain" | "snow" | "hail" | "thunder" | "pour"
        )
    }

    fn try_parse_superlative(&self, word: &str) -> Option<String> {
        if !word.ends_with("est") || word.len() < 5 {
            return None;
        }

        let base = &word[..word.len() - 3];

        if base.len() >= 2 {
            let chars: Vec<char> = base.chars().collect();
            let last = chars[chars.len() - 1];
            let second_last = chars[chars.len() - 2];
            if last == second_last && !"aeiou".contains(last) {
                let stem = &base[..base.len() - 1];
                if lexicon::is_gradable_adjective(stem) {
                    return Some(Self::capitalize(stem));
                }
            }
        }

        if base.ends_with("i") {
            let stem = format!("{}y", &base[..base.len() - 1]);
            if lexicon::is_gradable_adjective(&stem) {
                return Some(Self::capitalize(&stem));
            }
        }

        if lexicon::is_gradable_adjective(base) {
            return Some(Self::capitalize(base));
        }

        None
    }

    fn try_parse_comparative(&self, word: &str) -> Option<String> {
        if !word.ends_with("er") || word.len() < 4 {
            return None;
        }

        let base = &word[..word.len() - 2];

        if base.len() >= 2 {
            let chars: Vec<char> = base.chars().collect();
            let last = chars[chars.len() - 1];
            let second_last = chars[chars.len() - 2];
            if last == second_last && !"aeiou".contains(last) {
                let stem = &base[..base.len() - 1];
                if lexicon::is_gradable_adjective(stem) {
                    return Some(Self::capitalize(stem));
                }
            }
        }

        if base.ends_with("i") {
            let stem = format!("{}y", &base[..base.len() - 1]);
            if lexicon::is_gradable_adjective(&stem) {
                return Some(Self::capitalize(&stem));
            }
        }

        if lexicon::is_gradable_adjective(base) {
            return Some(Self::capitalize(base));
        }

        None
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn lexer_handles_apostrophe() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("it's raining", &mut interner);
        let tokens = lexer.tokenize();
        assert!(!tokens.is_empty());
    }

    #[test]
    fn lexer_handles_question_mark() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("Is it raining?", &mut interner);
        let tokens = lexer.tokenize();
        assert!(!tokens.is_empty());
    }

    #[test]
    fn ring_is_not_verb() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("ring", &mut interner);
        let tokens = lexer.tokenize();
        assert!(matches!(tokens[0].kind, TokenType::Noun(_)));
    }

    #[test]
    fn debug_that_token() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("The cat that runs", &mut interner);
        let tokens = lexer.tokenize();
        for (i, t) in tokens.iter().enumerate() {
            let lex = interner.resolve(t.lexeme);
            eprintln!("Token[{}]: {:?} -> {:?}", i, lex, t.kind);
        }
        let that_token = tokens.iter().find(|t| interner.resolve(t.lexeme) == "that");
        if let Some(t) = that_token {
            // Verify discriminant comparison works
            let check = std::mem::discriminant(&t.kind) == std::mem::discriminant(&TokenType::That);
            eprintln!("Discriminant check for That: {}", check);
            assert!(matches!(t.kind, TokenType::That), "'that' should be TokenType::That, got {:?}", t.kind);
        } else {
            panic!("No 'that' token found");
        }
    }

    #[test]
    fn bus_is_not_verb() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("bus", &mut interner);
        let tokens = lexer.tokenize();
        assert!(matches!(tokens[0].kind, TokenType::Noun(_)));
    }

    #[test]
    fn lowercase_a_is_article() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("a car", &mut interner);
        let tokens = lexer.tokenize();
        for (i, t) in tokens.iter().enumerate() {
            let lex = interner.resolve(t.lexeme);
            eprintln!("Token[{}]: {:?} -> {:?}", i, lex, t.kind);
        }
        assert_eq!(tokens[0].kind, TokenType::Article(Definiteness::Indefinite));
        assert!(matches!(tokens[1].kind, TokenType::Noun(_)), "Expected Noun, got {:?}", tokens[1].kind);
    }

    #[test]
    fn open_is_ambiguous() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("open", &mut interner);
        let tokens = lexer.tokenize();

        if let TokenType::Ambiguous { primary, alternatives } = &tokens[0].kind {
            assert!(matches!(**primary, TokenType::Verb { .. }), "Primary should be Verb");
            assert!(alternatives.iter().any(|t| matches!(t, TokenType::Adjective(_))),
                "Should have Adjective alternative");
        } else {
            panic!("Expected Ambiguous token for 'open', got {:?}", tokens[0].kind);
        }
    }

    #[test]
    fn basic_tokenization() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("All men are mortal.", &mut interner);
        let tokens = lexer.tokenize();
        assert_eq!(tokens[0].kind, TokenType::All);
        assert!(matches!(tokens[1].kind, TokenType::Noun(_)));
        assert_eq!(tokens[2].kind, TokenType::Are);
    }

    #[test]
    fn iff_tokenizes_as_single_token() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("A if and only if B", &mut interner);
        let tokens = lexer.tokenize();
        assert!(
            tokens.iter().any(|t| t.kind == TokenType::Iff),
            "should contain Iff token: got {:?}",
            tokens
        );
    }

    #[test]
    fn is_equal_to_tokenizes_as_identity() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("Socrates is equal to Socrates", &mut interner);
        let tokens = lexer.tokenize();
        assert!(
            tokens.iter().any(|t| t.kind == TokenType::Identity),
            "should contain Identity token: got {:?}",
            tokens
        );
    }

    #[test]
    fn is_identical_to_tokenizes_as_identity() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("Clark is identical to Superman", &mut interner);
        let tokens = lexer.tokenize();
        assert!(
            tokens.iter().any(|t| t.kind == TokenType::Identity),
            "should contain Identity token: got {:?}",
            tokens
        );
    }

    #[test]
    fn itself_tokenizes_as_reflexive() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("John loves itself", &mut interner);
        let tokens = lexer.tokenize();
        assert!(
            tokens.iter().any(|t| t.kind == TokenType::Reflexive),
            "should contain Reflexive token: got {:?}",
            tokens
        );
    }

    #[test]
    fn himself_tokenizes_as_reflexive() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("John sees himself", &mut interner);
        let tokens = lexer.tokenize();
        assert!(
            tokens.iter().any(|t| t.kind == TokenType::Reflexive),
            "should contain Reflexive token: got {:?}",
            tokens
        );
    }

    #[test]
    fn to_stay_tokenizes_correctly() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("to stay", &mut interner);
        let tokens = lexer.tokenize();
        assert!(
            tokens.iter().any(|t| t.kind == TokenType::To),
            "should contain To token: got {:?}",
            tokens
        );
        assert!(
            tokens.iter().any(|t| matches!(t.kind, TokenType::Verb { .. })),
            "should contain Verb token for stay: got {:?}",
            tokens
        );
    }

    #[test]
    fn possessive_apostrophe_s() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("John's dog", &mut interner);
        let tokens = lexer.tokenize();
        assert!(
            tokens.iter().any(|t| t.kind == TokenType::Possessive),
            "should contain Possessive token: got {:?}",
            tokens
        );
        assert!(
            tokens.iter().any(|t| matches!(&t.kind, TokenType::ProperName(_))),
            "should have John as proper name: got {:?}",
            tokens
        );
    }

    #[test]
    fn lexer_produces_valid_spans() {
        let input = "All men are mortal.";
        let mut interner = Interner::new();
        let mut lexer = Lexer::new(input, &mut interner);
        let tokens = lexer.tokenize();

        // "All" at 0..3
        assert_eq!(tokens[0].span.start, 0);
        assert_eq!(tokens[0].span.end, 3);
        assert_eq!(&input[tokens[0].span.start..tokens[0].span.end], "All");

        // "men" at 4..7
        assert_eq!(tokens[1].span.start, 4);
        assert_eq!(tokens[1].span.end, 7);
        assert_eq!(&input[tokens[1].span.start..tokens[1].span.end], "men");

        // "are" at 8..11
        assert_eq!(tokens[2].span.start, 8);
        assert_eq!(tokens[2].span.end, 11);
        assert_eq!(&input[tokens[2].span.start..tokens[2].span.end], "are");

        // "mortal" at 12..18
        assert_eq!(tokens[3].span.start, 12);
        assert_eq!(tokens[3].span.end, 18);
        assert_eq!(&input[tokens[3].span.start..tokens[3].span.end], "mortal");

        // "." at 18..19
        assert_eq!(tokens[4].span.start, 18);
        assert_eq!(tokens[4].span.end, 19);

        // EOF at end
        assert_eq!(tokens[5].span.start, input.len());
        assert_eq!(tokens[5].kind, TokenType::EOF);
    }
}

```

---

## Parser & AST

Recursive descent parser supporting both Logic and Imperative modes.
pub mod logic;
pub mod stmt;

pub use logic::*;
pub use stmt::{Stmt, Expr, Literal, Block, BinaryOpKind, TypeExpr, MatchArm};

```

---

use crate::arena::Arena;
use crate::intern::Symbol;
use crate::lexicon::Definiteness;
use crate::token::TokenType;

// ═══════════════════════════════════════════════════════════════════
// Semantic Types (Montague Grammar)
// ═══════════════════════════════════════════════════════════════════

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum LogicalType {
    Entity,      // e (individuals: John, the ball)
    TruthValue,  // t (propositions)
    Property,    // <e,t> (predicates: Unicorn, Water)
    Quantifier,  // <<e,t>,t> (every man, a woman)
}

// ═══════════════════════════════════════════════════════════════════
// Degree Semantics (Prover-Ready Number System)
// ═══════════════════════════════════════════════════════════════════

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum Dimension {
    Length,
    Time,
    Weight,
    Temperature,
    Cardinality,
}

#[derive(Debug, Clone, Copy, PartialEq)]
pub enum NumberKind {
    Real(f64),
    Integer(i64),
    Symbolic(Symbol),
}

// ═══════════════════════════════════════════════════════════════════
// First-Order Logic Types (FOL Upgrade)
// ═══════════════════════════════════════════════════════════════════

#[derive(Debug, Clone, Copy)]
pub enum Term<'a> {
    Constant(Symbol),
    Variable(Symbol),
    Function(Symbol, &'a [Term<'a>]),
    Group(&'a [Term<'a>]),
    Possessed { possessor: &'a Term<'a>, possessed: Symbol },
    Sigma(Symbol),
    Intension(Symbol),  // ^Predicate (Montague up-arrow for de dicto)
    Proposition(&'a LogicExpr<'a>),  // Sentential complement (embedded clause)
    Value {
        kind: NumberKind,
        unit: Option<Symbol>,
        dimension: Option<Dimension>,
    },
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum QuantifierKind {
    Universal,
    Existential,
    Most,
    Few,
    Many,
    Cardinal(u32),
    AtLeast(u32),
    AtMost(u32),
    Generic,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum BinaryOpKind {
    And,
    Or,
    Implies,
    Iff,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum UnaryOpKind {
    Not,
}

// ═══════════════════════════════════════════════════════════════════
// Temporal & Aspect Operators (Arthur Prior's Tense Logic)
// ═══════════════════════════════════════════════════════════════════

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum TemporalOperator {
    Past,
    Future,
}

// ═══════════════════════════════════════════════════════════════════
// Event Semantics (Neo-Davidsonian)
// ═══════════════════════════════════════════════════════════════════

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum ThematicRole {
    Agent,
    Patient,
    Theme,
    Recipient,
    Goal,
    Source,
    Instrument,
    Location,
    Time,
    Manner,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum AspectOperator {
    Progressive,
    Perfect,
    Habitual,
    Iterative,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum VoiceOperator {
    Passive,
}

// ═══════════════════════════════════════════════════════════════════
// Legacy Types (kept during transition)
// ═══════════════════════════════════════════════════════════════════

#[derive(Debug)]
pub struct NounPhrase<'a> {
    pub definiteness: Option<Definiteness>,
    pub adjectives: &'a [Symbol],
    pub noun: Symbol,
    pub possessor: Option<&'a NounPhrase<'a>>,
    pub pps: &'a [&'a LogicExpr<'a>],
    pub superlative: Option<Symbol>,
}

// ═══════════════════════════════════════════════════════════════════
// Boxed Variant Data (keeps LogicExpr enum small)
// ═══════════════════════════════════════════════════════════════════

#[derive(Debug)]
pub struct CategoricalData<'a> {
    pub quantifier: TokenType,
    pub subject: NounPhrase<'a>,
    pub copula_negative: bool,
    pub predicate: NounPhrase<'a>,
}

#[derive(Debug)]
pub struct RelationData<'a> {
    pub subject: NounPhrase<'a>,
    pub verb: Symbol,
    pub object: NounPhrase<'a>,
}

#[derive(Debug)]
pub struct NeoEventData<'a> {
    pub event_var: Symbol,
    pub verb: Symbol,
    pub roles: &'a [(ThematicRole, Term<'a>)],
    pub modifiers: &'a [Symbol],
    /// When true, suppress local ∃e quantification (DRT: event var will be bound by outer ∀)
    pub suppress_existential: bool,
    /// World argument for Kripke semantics. None = implicit actual world (w₀).
    pub world: Option<Symbol>,
}

impl<'a> NounPhrase<'a> {
    pub fn simple(noun: Symbol) -> Self {
        NounPhrase {
            definiteness: None,
            adjectives: &[],
            noun,
            possessor: None,
            pps: &[],
            superlative: None,
        }
    }

    pub fn with_definiteness(definiteness: Definiteness, noun: Symbol) -> Self {
        NounPhrase {
            definiteness: Some(definiteness),
            adjectives: &[],
            noun,
            possessor: None,
            pps: &[],
            superlative: None,
        }
    }
}

#[derive(Debug, Clone, Copy, PartialEq)]
pub enum ModalDomain {
    Alethic,
    Deontic,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum ModalFlavor {
    /// Root modals (ability, obligation): can, must, should, shall, could, would
    /// These get NARROW scope (de re) - modal attaches to the predicate inside quantifier
    Root,
    /// Epistemic modals (possibility, deduction): might, may
    /// These get WIDE scope (de dicto) - modal wraps the entire quantifier
    Epistemic,
}

#[derive(Debug, Clone, Copy, PartialEq)]
pub struct ModalVector {
    pub domain: ModalDomain,
    pub force: f32,
    pub flavor: ModalFlavor,
}

// ═══════════════════════════════════════════════════════════════════
// Expression Enum (hybrid: old + new variants)
// ═══════════════════════════════════════════════════════════════════

#[derive(Debug)]
pub enum LogicExpr<'a> {
    Predicate {
        name: Symbol,
        args: &'a [Term<'a>],
        /// World argument for Kripke semantics. None = implicit actual world (w₀).
        world: Option<Symbol>,
    },

    Identity {
        left: &'a Term<'a>,
        right: &'a Term<'a>,
    },

    Metaphor {
        tenor: &'a Term<'a>,
        vehicle: &'a Term<'a>,
    },

    Quantifier {
        kind: QuantifierKind,
        variable: Symbol,
        body: &'a LogicExpr<'a>,
        island_id: u32,
    },

    Categorical(Box<CategoricalData<'a>>),

    Relation(Box<RelationData<'a>>),

    Modal {
        vector: ModalVector,
        operand: &'a LogicExpr<'a>,
    },

    Temporal {
        operator: TemporalOperator,
        body: &'a LogicExpr<'a>,
    },

    Aspectual {
        operator: AspectOperator,
        body: &'a LogicExpr<'a>,
    },

    Voice {
        operator: VoiceOperator,
        body: &'a LogicExpr<'a>,
    },

    BinaryOp {
        left: &'a LogicExpr<'a>,
        op: TokenType,
        right: &'a LogicExpr<'a>,
    },

    UnaryOp {
        op: TokenType,
        operand: &'a LogicExpr<'a>,
    },

    Question {
        wh_variable: Symbol,
        body: &'a LogicExpr<'a>,
    },

    YesNoQuestion {
        body: &'a LogicExpr<'a>,
    },

    Atom(Symbol),

    Lambda {
        variable: Symbol,
        body: &'a LogicExpr<'a>,
    },

    App {
        function: &'a LogicExpr<'a>,
        argument: &'a LogicExpr<'a>,
    },

    Intensional {
        operator: Symbol,
        content: &'a LogicExpr<'a>,
    },

    Event {
        predicate: &'a LogicExpr<'a>,
        adverbs: &'a [Symbol],
    },

    NeoEvent(Box<NeoEventData<'a>>),

    Imperative {
        action: &'a LogicExpr<'a>,
    },

    SpeechAct {
        performer: Symbol,
        act_type: Symbol,
        content: &'a LogicExpr<'a>,
    },

    Counterfactual {
        antecedent: &'a LogicExpr<'a>,
        consequent: &'a LogicExpr<'a>,
    },

    Causal {
        effect: &'a LogicExpr<'a>,
        cause: &'a LogicExpr<'a>,
    },

    Comparative {
        adjective: Symbol,
        subject: &'a Term<'a>,
        object: &'a Term<'a>,
        difference: Option<&'a Term<'a>>,
    },

    Superlative {
        adjective: Symbol,
        subject: &'a Term<'a>,
        domain: Symbol,
    },

    Scopal {
        operator: Symbol,
        body: &'a LogicExpr<'a>,
    },

    Control {
        verb: Symbol,
        subject: &'a Term<'a>,
        object: Option<&'a Term<'a>>,
        infinitive: &'a LogicExpr<'a>,
    },

    Presupposition {
        assertion: &'a LogicExpr<'a>,
        presupposition: &'a LogicExpr<'a>,
    },

    Focus {
        kind: crate::token::FocusKind,
        focused: &'a Term<'a>,
        scope: &'a LogicExpr<'a>,
    },

    TemporalAnchor {
        anchor: Symbol,
        body: &'a LogicExpr<'a>,
    },

    Distributive {
        predicate: &'a LogicExpr<'a>,
    },

    /// Group existential for collective readings of cardinals
    /// ∃g(Group(g) ∧ Count(g,n) ∧ ∀x(Member(x,g) → Restriction(x)) ∧ Body(g))
    GroupQuantifier {
        group_var: Symbol,
        count: u32,
        member_var: Symbol,
        restriction: &'a LogicExpr<'a>,
        body: &'a LogicExpr<'a>,
    },
}

impl<'a> LogicExpr<'a> {
    pub fn lambda(var: Symbol, body: &'a LogicExpr<'a>, arena: &'a Arena<LogicExpr<'a>>) -> &'a LogicExpr<'a> {
        arena.alloc(LogicExpr::Lambda {
            variable: var,
            body,
        })
    }

    pub fn app(func: &'a LogicExpr<'a>, arg: &'a LogicExpr<'a>, arena: &'a Arena<LogicExpr<'a>>) -> &'a LogicExpr<'a> {
        arena.alloc(LogicExpr::App {
            function: func,
            argument: arg,
        })
    }
}

#[cfg(test)]
mod size_tests {
    use super::*;
    use std::mem::size_of;

    #[test]
    fn test_ast_node_sizes() {
        println!("LogicExpr size: {} bytes", size_of::<LogicExpr>());
        println!("Term size: {} bytes", size_of::<Term>());
        println!("NounPhrase size: {} bytes", size_of::<NounPhrase>());

        assert!(
            size_of::<LogicExpr>() <= 48,
            "LogicExpr is {} bytes - consider boxing large variants",
            size_of::<LogicExpr>()
        );
        assert!(
            size_of::<Term>() <= 32,
            "Term is {} bytes",
            size_of::<Term>()
        );
    }
}

```

---

use super::logic::LogicExpr;
use crate::intern::Symbol;

/// Type expression for explicit type annotations.
///
/// Represents type syntax like:
/// - `Int` → Primitive(Int)
/// - `User` → Named(User)
/// - `List of Int` → Generic { base: List, params: [Primitive(Int)] }
/// - `List of List of Int` → Generic { base: List, params: [Generic { base: List, params: [Primitive(Int)] }] }
/// - `Result of Int and Text` → Generic { base: Result, params: [Primitive(Int), Primitive(Text)] }
#[derive(Debug, Clone)]
pub enum TypeExpr<'a> {
    /// Primitive type: Int, Nat, Text, Bool
    Primitive(Symbol),
    /// Named type (user-defined): User, Point
    Named(Symbol),
    /// Generic type: List of Int, Option of Text, Result of Int and Text
    Generic {
        base: Symbol,
        params: &'a [TypeExpr<'a>],
    },
    /// Function type: fn(A, B) -> C (for higher-order functions)
    Function {
        inputs: &'a [TypeExpr<'a>],
        output: &'a TypeExpr<'a>,
    },
    /// Phase 43C: Refinement type with predicate constraint
    /// Example: `Int where it > 0`
    Refinement {
        /// The base type being refined
        base: &'a TypeExpr<'a>,
        /// The bound variable (usually "it")
        var: Symbol,
        /// The predicate constraint (from Logic Kernel)
        predicate: &'a LogicExpr<'a>,
    },
    /// Phase 53: Persistent storage wrapper type
    /// Example: `Persistent Counter`
    /// Semantics: Wraps a Shared type with journal-backed storage
    Persistent {
        /// The inner type (must be a Shared/CRDT type)
        inner: &'a TypeExpr<'a>,
    },
}

/// Phase 10: Source for Read statements
#[derive(Debug, Clone, Copy)]
pub enum ReadSource<'a> {
    /// Read from console (stdin)
    Console,
    /// Read from file at given path
    File(&'a Expr<'a>),
}

/// Binary operation kinds for imperative expressions.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum BinaryOpKind {
    Add,
    Subtract,
    Multiply,
    Divide,
    Modulo,
    Eq,
    NotEq,
    Lt,
    Gt,
    LtEq,
    GtEq,
    // Grand Challenge: Logical operators for compound conditions
    And,
    Or,
    // Phase 53: String concatenation ("X combined with Y")
    Concat,
}

/// Block is a sequence of statements.
pub type Block<'a> = &'a [Stmt<'a>];

/// Phase 33: Match arm for Inspect statement
#[derive(Debug)]
pub struct MatchArm<'a> {
    pub enum_name: Option<Symbol>,          // The enum type (e.g., Shape)
    pub variant: Option<Symbol>,            // None = Otherwise (wildcard)
    pub bindings: Vec<(Symbol, Symbol)>,    // (field_name, binding_name)
    pub body: Block<'a>,
}

/// Imperative statement AST (LOGOS §15.0.0).
///
/// Stmt is the primary AST node for imperative code blocks like `## Main`
/// and function bodies. The Assert variant bridges to the Logic Kernel.
#[derive(Debug)]
pub enum Stmt<'a> {
    /// Variable binding: `Let x be 5.` or `Let x: Int be 5.`
    Let {
        var: Symbol,
        ty: Option<&'a TypeExpr<'a>>,
        value: &'a Expr<'a>,
        mutable: bool,
    },

    /// Mutation: `Set x to 10.`
    Set {
        target: Symbol,
        value: &'a Expr<'a>,
    },

    /// Function call as statement: `Call process with data.`
    Call {
        function: Symbol,
        args: Vec<&'a Expr<'a>>,
    },

    /// Conditional: `If condition: ... Otherwise: ...`
    If {
        cond: &'a Expr<'a>,
        then_block: Block<'a>,
        else_block: Option<Block<'a>>,
    },

    /// Loop: `While condition: ...` or `While condition (decreasing expr): ...`
    While {
        cond: &'a Expr<'a>,
        body: Block<'a>,
        /// Phase 44: Optional decreasing variant for termination proof
        decreasing: Option<&'a Expr<'a>>,
    },

    /// Iteration: `Repeat for x in list: ...` or `Repeat for i from 1 to 10: ...`
    Repeat {
        var: Symbol,
        iterable: &'a Expr<'a>,
        body: Block<'a>,
    },

    /// Return: `Return x.` or `Return.`
    Return {
        value: Option<&'a Expr<'a>>,
    },

    /// Bridge to Logic Kernel: `Assert that P.`
    Assert {
        proposition: &'a LogicExpr<'a>,
    },

    /// Phase 35: Documented assertion with justification
    /// `Trust that P because "reason".`
    /// Semantics: Documented runtime check that could be verified statically.
    Trust {
        proposition: &'a LogicExpr<'a>,
        justification: Symbol,
    },

    /// Runtime assertion with imperative condition
    /// `Assert that condition.` (for imperative mode)
    RuntimeAssert {
        condition: &'a Expr<'a>,
    },

    /// Ownership transfer (move): `Give x to processor.`
    /// Semantics: Move ownership of `object` to `recipient`.
    Give {
        object: &'a Expr<'a>,
        recipient: &'a Expr<'a>,
    },

    /// Immutable borrow: `Show x to console.`
    /// Semantics: Immutable borrow of `object` passed to `recipient`.
    Show {
        object: &'a Expr<'a>,
        recipient: &'a Expr<'a>,
    },

    /// Phase 31: Field mutation: `Set p's x to 10.`
    SetField {
        object: &'a Expr<'a>,
        field: Symbol,
        value: &'a Expr<'a>,
    },

    /// Phase 31: Struct definition for codegen
    /// Phase 47: Added is_portable for serde derives
    StructDef {
        name: Symbol,
        fields: Vec<(Symbol, Symbol, bool)>, // (name, type_name, is_public)
        is_portable: bool,                    // Phase 47: Derives Serialize/Deserialize
    },

    /// Phase 32/38: Function definition
    /// Phase 38: Updated for native functions and TypeExpr types
    FunctionDef {
        name: Symbol,
        params: Vec<(Symbol, &'a TypeExpr<'a>)>, // Phase 38: Changed to TypeExpr
        body: Block<'a>,
        return_type: Option<&'a TypeExpr<'a>>,   // Phase 38: Changed to TypeExpr
        is_native: bool,                          // Phase 38: Native function flag
    },

    /// Phase 33: Pattern matching on sum types
    Inspect {
        target: &'a Expr<'a>,
        arms: Vec<MatchArm<'a>>,
        has_otherwise: bool,            // For exhaustiveness tracking
    },

    /// Phase 43D: Push to collection: `Push x to items.`
    Push {
        value: &'a Expr<'a>,
        collection: &'a Expr<'a>,
    },

    /// Phase 43D: Pop from collection: `Pop from items.` or `Pop from items into y.`
    Pop {
        collection: &'a Expr<'a>,
        into: Option<Symbol>,
    },

    /// Add to set: `Add x to set.`
    Add {
        value: &'a Expr<'a>,
        collection: &'a Expr<'a>,
    },

    /// Remove from set: `Remove x from set.`
    Remove {
        value: &'a Expr<'a>,
        collection: &'a Expr<'a>,
    },

    /// Index assignment: `Set item N of X to Y.`
    SetIndex {
        collection: &'a Expr<'a>,
        index: &'a Expr<'a>,
        value: &'a Expr<'a>,
    },

    /// Phase 8.5: Memory arena block (Zone)
    /// "Inside a new zone called 'Scratch':"
    /// "Inside a zone called 'Buffer' of size 1 MB:"
    /// "Inside a zone called 'Data' mapped from 'file.bin':"
    Zone {
        /// The variable name for the arena handle (e.g., "Scratch")
        name: Symbol,
        /// Optional pre-allocated capacity in bytes (Heap zones only)
        capacity: Option<usize>,
        /// Optional file path for memory-mapped zones (Mapped zones only)
        source_file: Option<Symbol>,
        /// The code block executed within this memory context
        body: Block<'a>,
    },

    /// Phase 9: Concurrent execution block (async, I/O-bound)
    /// "Attempt all of the following:"
    /// Semantics: All tasks run concurrently via tokio::join!
    /// Best for: network requests, file I/O, waiting operations
    Concurrent {
        /// The statements to execute concurrently
        tasks: Block<'a>,
    },

    /// Phase 9: Parallel execution block (CPU-bound)
    /// "Simultaneously:"
    /// Semantics: True parallelism via rayon::join or thread::spawn
    /// Best for: computation, data processing, number crunching
    Parallel {
        /// The statements to execute in parallel
        tasks: Block<'a>,
    },

    /// Phase 10: Read from console or file
    /// `Read input from the console.` or `Read data from file "path.txt".`
    ReadFrom {
        var: Symbol,
        source: ReadSource<'a>,
    },

    /// Phase 10: Write to file
    /// `Write "content" to file "output.txt".`
    WriteFile {
        content: &'a Expr<'a>,
        path: &'a Expr<'a>,
    },

    /// Phase 46: Spawn an agent
    /// `Spawn a Worker called "w1".`
    Spawn {
        agent_type: Symbol,
        name: Symbol,
    },

    /// Phase 46: Send message to agent
    /// `Send Ping to "agent".`
    SendMessage {
        message: &'a Expr<'a>,
        destination: &'a Expr<'a>,
    },

    /// Phase 46: Await response from agent
    /// `Await response from "agent" into result.`
    AwaitMessage {
        source: &'a Expr<'a>,
        into: Symbol,
    },

    /// Phase 49: Merge CRDT state
    /// `Merge remote into local.` or `Merge remote's field into local's field.`
    MergeCrdt {
        source: &'a Expr<'a>,
        target: &'a Expr<'a>,
    },

    /// Phase 49: Increment GCounter
    /// `Increase local's points by 10.`
    IncreaseCrdt {
        object: &'a Expr<'a>,
        field: Symbol,
        amount: &'a Expr<'a>,
    },

    /// Phase 49b: Decrement PNCounter (Tally)
    /// `Decrease game's score by 5.`
    DecreaseCrdt {
        object: &'a Expr<'a>,
        field: Symbol,
        amount: &'a Expr<'a>,
    },

    /// Phase 49b: Append to SharedSequence (RGA)
    /// `Append "Hello" to doc's lines.`
    AppendToSequence {
        sequence: &'a Expr<'a>,
        value: &'a Expr<'a>,
    },

    /// Phase 49b: Resolve MVRegister conflicts
    /// `Resolve page's title to "Final".`
    ResolveConflict {
        object: &'a Expr<'a>,
        field: Symbol,
        value: &'a Expr<'a>,
    },

    /// Phase 50: Security check - mandatory runtime guard
    /// `Check that user is admin.`
    /// `Check that user can publish the document.`
    /// Semantics: NEVER optimized out. Panics if condition is false.
    Check {
        /// The subject being checked (e.g., "user")
        subject: Symbol,
        /// The predicate name (e.g., "admin") or action (e.g., "publish")
        predicate: Symbol,
        /// True if this is a capability check (can [action])
        is_capability: bool,
        /// For capabilities: the object being acted on (e.g., "document")
        object: Option<Symbol>,
        /// Original English text for error message
        source_text: String,
        /// Source location for error reporting
        span: crate::token::Span,
    },

    /// Phase 51: Listen on network address
    /// `Listen on "/ip4/127.0.0.1/tcp/8000".`
    /// Semantics: Bind to address, start accepting connections via libp2p
    Listen {
        address: &'a Expr<'a>,
    },

    /// Phase 51: Connect to remote peer
    /// `Connect to "/ip4/127.0.0.1/tcp/8000".`
    /// Semantics: Dial peer via libp2p
    ConnectTo {
        address: &'a Expr<'a>,
    },

    /// Phase 51: Create PeerAgent remote handle
    /// `Let remote be a PeerAgent at "/ip4/127.0.0.1/tcp/8000".`
    /// Semantics: Create handle for remote agent communication
    LetPeerAgent {
        var: Symbol,
        address: &'a Expr<'a>,
    },

    /// Phase 51: Sleep for milliseconds
    /// `Sleep 1000.` or `Sleep delay.`
    /// Semantics: Pause execution for N milliseconds (async)
    Sleep {
        milliseconds: &'a Expr<'a>,
    },

    /// Phase 52: Sync CRDT variable on topic
    /// `Sync x on "topic".`
    /// Semantics: Subscribe to GossipSub topic, auto-publish on mutation, auto-merge on receive
    Sync {
        var: Symbol,
        topic: &'a Expr<'a>,
    },

    /// Phase 53: Mount persistent CRDT from journal file
    /// `Mount counter at "data/counter.journal".`
    /// Semantics: Load or create journal, replay operations to reconstruct state
    Mount {
        /// The variable name for the mounted value
        var: Symbol,
        /// The path expression for the journal file
        path: &'a Expr<'a>,
    },

    // =========================================================================
    // Phase 54: Go-like Concurrency (Green Threads, Channels, Select)
    // =========================================================================

    /// Phase 54: Launch a fire-and-forget task (green thread)
    /// `Launch a task to process(data).`
    /// Semantics: tokio::spawn with no handle capture
    LaunchTask {
        /// The function to call
        function: Symbol,
        /// Arguments to pass
        args: Vec<&'a Expr<'a>>,
    },

    /// Phase 54: Launch a task with handle for control
    /// `Let worker be Launch a task to process(data).`
    /// Semantics: tokio::spawn returning JoinHandle
    LaunchTaskWithHandle {
        /// Variable to bind the handle
        handle: Symbol,
        /// The function to call
        function: Symbol,
        /// Arguments to pass
        args: Vec<&'a Expr<'a>>,
    },

    /// Phase 54: Create a bounded channel (pipe)
    /// `Let jobs be a new Pipe of Int.`
    /// Semantics: tokio::sync::mpsc::channel(32)
    CreatePipe {
        /// Variable for the pipe
        var: Symbol,
        /// Type of values in the pipe
        element_type: Symbol,
        /// Optional capacity (defaults to 32)
        capacity: Option<u32>,
    },

    /// Phase 54: Blocking send into pipe
    /// `Send value into pipe.`
    /// Semantics: pipe_tx.send(value).await
    SendPipe {
        /// The value to send
        value: &'a Expr<'a>,
        /// The pipe to send into
        pipe: &'a Expr<'a>,
    },

    /// Phase 54: Blocking receive from pipe
    /// `Receive x from pipe.`
    /// Semantics: let x = pipe_rx.recv().await
    ReceivePipe {
        /// Variable to bind the received value
        var: Symbol,
        /// The pipe to receive from
        pipe: &'a Expr<'a>,
    },

    /// Phase 54: Non-blocking send (try)
    /// `Try to send value into pipe.`
    /// Semantics: pipe_tx.try_send(value) - returns immediately
    TrySendPipe {
        /// The value to send
        value: &'a Expr<'a>,
        /// The pipe to send into
        pipe: &'a Expr<'a>,
        /// Variable to bind the result (true/false)
        result: Option<Symbol>,
    },

    /// Phase 54: Non-blocking receive (try)
    /// `Try to receive x from pipe.`
    /// Semantics: pipe_rx.try_recv() - returns Option
    TryReceivePipe {
        /// Variable to bind the received value (if any)
        var: Symbol,
        /// The pipe to receive from
        pipe: &'a Expr<'a>,
    },

    /// Phase 54: Cancel a spawned task
    /// `Stop worker.`
    /// Semantics: handle.abort()
    StopTask {
        /// The handle to cancel
        handle: &'a Expr<'a>,
    },

    /// Phase 54: Select on multiple channels/timeouts
    /// `Await the first of:`
    ///     `Receive x from ch:`
    ///         `...`
    ///     `After 5 seconds:`
    ///         `...`
    /// Semantics: tokio::select! with auto-cancel
    Select {
        /// The branches to select from
        branches: Vec<SelectBranch<'a>>,
    },
}

/// Phase 54: A branch in a Select statement
#[derive(Debug)]
pub enum SelectBranch<'a> {
    /// Receive from a pipe: `Receive x from ch:`
    Receive {
        var: Symbol,
        pipe: &'a Expr<'a>,
        body: Block<'a>,
    },
    /// Timeout: `After N seconds:` or `After N milliseconds:`
    Timeout {
        milliseconds: &'a Expr<'a>,
        body: Block<'a>,
    },
}

/// Shared expression type for pure computations (LOGOS §15.0.0).
///
/// Expr is used by both LogicExpr (as terms) and Stmt (as values).
/// These are pure computations without side effects.
#[derive(Debug)]
pub enum Expr<'a> {
    /// Literal value: 42, "hello", true, nothing
    Literal(Literal),

    /// Variable reference: x
    Identifier(Symbol),

    /// Binary operation: x plus y
    BinaryOp {
        op: BinaryOpKind,
        left: &'a Expr<'a>,
        right: &'a Expr<'a>,
    },

    /// Function call as expression: f(x, y)
    Call {
        function: Symbol,
        args: Vec<&'a Expr<'a>>,
    },

    /// Phase 43D: Dynamic index access: `items at i` (1-indexed)
    Index {
        collection: &'a Expr<'a>,
        index: &'a Expr<'a>,
    },

    /// Phase 43D: Dynamic slice access: `items 1 through mid` (1-indexed, inclusive)
    Slice {
        collection: &'a Expr<'a>,
        start: &'a Expr<'a>,
        end: &'a Expr<'a>,
    },

    /// Phase 43D: Copy expression: `copy of slice` → slice.to_vec()
    Copy {
        expr: &'a Expr<'a>,
    },

    /// Phase 43D: Length expression: `length of items` → items.len()
    Length {
        collection: &'a Expr<'a>,
    },

    /// Set contains: `set contains x` or `x in set`
    Contains {
        collection: &'a Expr<'a>,
        value: &'a Expr<'a>,
    },

    /// Set union: `a union b`
    Union {
        left: &'a Expr<'a>,
        right: &'a Expr<'a>,
    },

    /// Set intersection: `a intersection b`
    Intersection {
        left: &'a Expr<'a>,
        right: &'a Expr<'a>,
    },

    /// Phase 48: Get manifest of a zone
    /// `the manifest of Zone` → FileSipper::from_zone(&zone).manifest()
    ManifestOf {
        zone: &'a Expr<'a>,
    },

    /// Phase 48: Get chunk at index from a zone
    /// `the chunk at N in Zone` → FileSipper::from_zone(&zone).get_chunk(N)
    ChunkAt {
        index: &'a Expr<'a>,
        zone: &'a Expr<'a>,
    },

    /// List literal: [1, 2, 3]
    List(Vec<&'a Expr<'a>>),

    /// Tuple literal: (1, "hello", true)
    Tuple(Vec<&'a Expr<'a>>),

    /// Range: 1 to 10 (inclusive)
    Range {
        start: &'a Expr<'a>,
        end: &'a Expr<'a>,
    },

    /// Phase 31: Field access: `p's x` or `the x of p`
    FieldAccess {
        object: &'a Expr<'a>,
        field: Symbol,
    },

    /// Phase 31: Constructor: `a new Point` or `a new Point with x 10 and y 20`
    /// Phase 34: Extended for generics: `a new Box of Int`
    New {
        type_name: Symbol,
        type_args: Vec<Symbol>,  // Empty for non-generic types
        init_fields: Vec<(Symbol, &'a Expr<'a>)>,  // Optional field initialization
    },

    /// Phase 33: Enum variant constructor: `a new Circle with radius 10`
    NewVariant {
        enum_name: Symbol,                      // Shape (resolved from registry)
        variant: Symbol,                        // Circle
        fields: Vec<(Symbol, &'a Expr<'a>)>,    // [(radius, 10)]
    },
}

/// Literal values in LOGOS.
#[derive(Debug, Clone, PartialEq)]
pub enum Literal {
    /// Integer literal
    Number(i64),
    /// Float literal
    Float(f64),
    /// Text literal
    Text(Symbol),
    /// Boolean literal
    Boolean(bool),
    /// The nothing literal (unit type)
    Nothing,
    /// Character literal
    Char(char),
}

```

---

mod clause;
mod common;
mod modal;
mod noun;
mod pragmatics;
mod quantifier;
mod question;
mod verb;

#[cfg(test)]
mod tests;

pub use clause::ClauseParsing;
pub use modal::ModalParsing;
pub use noun::NounParsing;
pub use pragmatics::PragmaticsParsing;
pub use quantifier::QuantifierParsing;
pub use question::QuestionParsing;
pub use verb::{LogicVerbParsing, ImperativeVerbParsing};

use crate::analysis::TypeRegistry;
use crate::arena_ctx::AstContext;
use crate::ast::{AspectOperator, LogicExpr, NeoEventData, NumberKind, QuantifierKind, TemporalOperator, Term, ThematicRole, Stmt, Expr, Literal, TypeExpr, BinaryOpKind, MatchArm};
use crate::ast::stmt::ReadSource;
use crate::drs::{Case, Gender, Number};
use crate::drs::{Drs, BoxType, WorldState};
use crate::error::{ParseError, ParseErrorKind};
use crate::intern::{Interner, Symbol, SymbolEq};
use crate::lexer::Lexer;
use crate::lexicon::{self, Aspect, Definiteness, Time, VerbClass};
use crate::token::{BlockType, FocusKind, Token, TokenType};

pub(super) type ParseResult<T> = Result<T, ParseError>;

use std::ops::{Deref, DerefMut};

/// Determines how the parser interprets sentences.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
pub enum ParserMode {
    /// Logicaffeine mode: propositions, NeoEvents, ambiguity allowed.
    #[default]
    Declarative,
    /// LOGOS mode: statements, strict scoping, deterministic.
    Imperative,
}

/// Controls scope of negation for lexically negative verbs (lacks, miss).
/// "user who lacks a key" can mean:
///   - Wide:   ¬∃y(Key(y) ∧ Have(x,y)) - "has NO keys" (natural reading)
///   - Narrow: ∃y(Key(y) ∧ ¬Have(x,y)) - "missing SOME key" (literal reading)
#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
pub enum NegativeScopeMode {
    /// Narrow scope negation (literal reading): ∃y(Key(y) ∧ ¬Have(x,y))
    /// "User is missing some key" - need all keys (default/traditional reading)
    #[default]
    Narrow,
    /// Wide scope negation (natural reading): ¬∃y(Key(y) ∧ Have(x,y))
    /// "User has no keys" - need at least one key
    Wide,
}

/// Controls interpretation of polysemous modals (may, can, could).
/// Used by compile_forest to generate multiple semantic readings.
///
/// Semantic Matrix:
///   may:   Default=Permission (Deontic, Root)    Epistemic=Possibility (Alethic, Epistemic)
///   can:   Default=Ability (Alethic, Root)       Deontic=Permission (Deontic, Root)
///   could: Default=PastAbility (Alethic, Root)   Epistemic=Possibility (Alethic, Epistemic)
#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
pub enum ModalPreference {
    /// Default readings: may=Permission, can=Ability, could=PastAbility
    #[default]
    Default,
    /// Epistemic readings: may=Possibility (wide scope), could=Possibility (wide scope)
    Epistemic,
    /// Deontic readings: can=Permission (narrow scope, deontic domain)
    Deontic,
}

/// Result of pronoun resolution: either a bound variable or a constant
#[derive(Debug, Clone, Copy)]
pub enum ResolvedPronoun {
    /// Bound variable from DRS or telescope (use Term::Variable)
    Variable(Symbol),
    /// Constant (deictic or proper name) (use Term::Constant)
    Constant(Symbol),
}

#[derive(Clone)]
struct ParserCheckpoint {
    pos: usize,
    var_counter: usize,
    bindings_len: usize,
    island: u32,
    time: Option<Time>,
    negative_depth: u32,
}

pub struct ParserGuard<'p, 'a, 'ctx, 'int> {
    parser: &'p mut Parser<'a, 'ctx, 'int>,
    checkpoint: ParserCheckpoint,
    committed: bool,
}

impl<'p, 'a, 'ctx, 'int> ParserGuard<'p, 'a, 'ctx, 'int> {
    pub fn commit(mut self) {
        self.committed = true;
    }
}

impl<'p, 'a, 'ctx, 'int> Drop for ParserGuard<'p, 'a, 'ctx, 'int> {
    fn drop(&mut self) {
        if !self.committed {
            self.parser.restore(self.checkpoint.clone());
        }
    }
}

impl<'p, 'a, 'ctx, 'int> Deref for ParserGuard<'p, 'a, 'ctx, 'int> {
    type Target = Parser<'a, 'ctx, 'int>;
    fn deref(&self) -> &Self::Target {
        self.parser
    }
}

impl<'p, 'a, 'ctx, 'int> DerefMut for ParserGuard<'p, 'a, 'ctx, 'int> {
    fn deref_mut(&mut self) -> &mut Self::Target {
        self.parser
    }
}

#[derive(Clone, Debug)]
pub struct EventTemplate<'a> {
    pub verb: Symbol,
    pub non_agent_roles: Vec<(ThematicRole, Term<'a>)>,
    pub modifiers: Vec<Symbol>,
}

pub struct Parser<'a, 'ctx, 'int> {
    pub(super) tokens: Vec<Token>,
    pub(super) current: usize,
    pub(super) var_counter: usize,
    pub(super) pending_time: Option<Time>,
    /// Donkey bindings: (noun, var, is_donkey_used, wide_scope_negation)
    /// The 4th field tracks if this binding's existential needs negation wrapping (for "lacks" scope)
    pub(super) donkey_bindings: Vec<(Symbol, Symbol, bool, bool)>,
    pub(super) interner: &'int mut Interner,
    pub(super) ctx: AstContext<'a>,
    pub(super) current_island: u32,
    pub(super) pp_attach_to_noun: bool,
    pub(super) filler_gap: Option<Symbol>,
    pub(super) negative_depth: u32,
    pub(super) discourse_event_var: Option<Symbol>,
    pub(super) last_event_template: Option<EventTemplate<'a>>,
    pub(super) noun_priority_mode: bool,
    pub(super) collective_mode: bool,
    pub(super) pending_cardinal: Option<u32>,
    pub(super) mode: ParserMode,
    pub(super) type_registry: Option<TypeRegistry>,
    pub(super) event_reading_mode: bool,
    /// Internal DRS for sentence-level scope tracking (swapped with WorldState's DRS)
    pub(super) drs: Drs,
    pub(super) negative_scope_mode: NegativeScopeMode,
    pub(super) modal_preference: ModalPreference,
    /// WorldState for discourse-level parsing (DRS persists across sentences)
    pub(super) world_state: &'ctx mut WorldState,
    /// Track when inside "No X" quantifier (referents are inaccessible for cross-sentence anaphora)
    pub(super) in_negative_quantifier: bool,
}

impl<'a, 'ctx, 'int> Parser<'a, 'ctx, 'int> {
    /// Create a parser with WorldState for discourse-level parsing.
    /// WorldState is REQUIRED - there is no "single sentence mode".
    /// A single sentence is just a discourse of length 1.
    pub fn new(
        tokens: Vec<Token>,
        world_state: &'ctx mut WorldState,
        interner: &'int mut Interner,
        ctx: AstContext<'a>,
        types: TypeRegistry,
    ) -> Self {
        Parser {
            tokens,
            current: 0,
            var_counter: 0,
            pending_time: None,
            donkey_bindings: Vec::new(),
            interner,
            ctx,
            current_island: 0,
            pp_attach_to_noun: false,
            filler_gap: None,
            negative_depth: 0,
            discourse_event_var: None,
            last_event_template: None,
            noun_priority_mode: false,
            collective_mode: false,
            pending_cardinal: None,
            mode: ParserMode::Declarative,
            type_registry: Some(types),
            event_reading_mode: false,
            drs: Drs::new(), // Internal DRS for sentence-level scope tracking
            negative_scope_mode: NegativeScopeMode::default(),
            modal_preference: ModalPreference::default(),
            world_state,
            in_negative_quantifier: false,
        }
    }

    pub fn set_discourse_event_var(&mut self, var: Symbol) {
        self.discourse_event_var = Some(var);
    }

    /// Get mutable reference to the active DRS (from WorldState).
    pub fn drs_mut(&mut self) -> &mut Drs {
        &mut self.world_state.drs
    }

    /// Get immutable reference to the active DRS (from WorldState).
    pub fn drs_ref(&self) -> &Drs {
        &self.world_state.drs
    }

    /// Swap DRS between Parser and WorldState.
    /// Call at start of parsing to get the accumulated DRS from WorldState.
    /// Call at end of parsing to save the updated DRS back to WorldState.
    pub fn swap_drs_with_world_state(&mut self) {
        std::mem::swap(&mut self.drs, &mut self.world_state.drs);
    }

    /// WorldState is always present (no "single sentence mode")
    pub fn has_world_state(&self) -> bool {
        true
    }

    pub fn mode(&self) -> ParserMode {
        self.mode
    }

    /// Check if a symbol is a known type in the registry.
    /// Used to disambiguate "Stack of Integers" (generic type) vs "Owner of House" (possessive).
    pub fn is_known_type(&self, sym: Symbol) -> bool {
        self.type_registry
            .as_ref()
            .map(|r| r.is_type(sym))
            .unwrap_or(false)
    }

    /// Check if a symbol is a known generic type (takes type parameters).
    /// Used to parse "Stack of Integers" as generic instantiation.
    pub fn is_generic_type(&self, sym: Symbol) -> bool {
        self.type_registry
            .as_ref()
            .map(|r| r.is_generic(sym))
            .unwrap_or(false)
    }

    /// Get the parameter count for a generic type.
    fn get_generic_param_count(&self, sym: Symbol) -> Option<usize> {
        use crate::analysis::TypeDef;
        self.type_registry.as_ref().and_then(|r| {
            match r.get(sym) {
                Some(TypeDef::Generic { param_count }) => Some(*param_count),
                _ => None,
            }
        })
    }

    /// Phase 33: Check if a symbol is a known enum variant and return the enum name.
    fn find_variant(&self, sym: Symbol) -> Option<Symbol> {
        self.type_registry
            .as_ref()
            .and_then(|r| r.find_variant(sym).map(|(enum_name, _)| enum_name))
    }

    /// Consume a type name token (doesn't check entity registration).
    fn consume_type_name(&mut self) -> ParseResult<Symbol> {
        let t = self.advance().clone();
        match t.kind {
            TokenType::Noun(s) | TokenType::Adjective(s) => Ok(s),
            TokenType::ProperName(s) => Ok(s),
            // Phase 49b: CRDT type keywords are valid type names
            TokenType::Tally => Ok(self.interner.intern("Tally")),
            TokenType::SharedSet => Ok(self.interner.intern("SharedSet")),
            TokenType::SharedSequence => Ok(self.interner.intern("SharedSequence")),
            TokenType::CollaborativeSequence => Ok(self.interner.intern("CollaborativeSequence")),
            TokenType::SharedMap => Ok(self.interner.intern("SharedMap")),
            TokenType::Divergent => Ok(self.interner.intern("Divergent")),
            other => Err(ParseError {
                kind: ParseErrorKind::ExpectedContentWord { found: other },
                span: self.current_span(),
            }),
        }
    }

    /// Parse a type expression: Int, Text, List of Int, Result of Int and Text.
    /// Phase 36: Also supports "Type from Module" for qualified imports.
    /// Uses TypeRegistry to distinguish primitives from generics.
    fn parse_type_expression(&mut self) -> ParseResult<TypeExpr<'a>> {
        use noun::NounParsing;

        // Phase 53: Handle "Persistent T" type modifier
        if self.check(&TokenType::Persistent) {
            self.advance(); // consume "Persistent"
            let inner = self.parse_type_expression()?;
            let inner_ref = self.ctx.alloc_type_expr(inner);
            return Ok(TypeExpr::Persistent { inner: inner_ref });
        }

        // Get the base type name (must be a noun or proper name - type names bypass entity check)
        let mut base = self.consume_type_name()?;

        // Phase 49c: Check for bias modifier on SharedSet: "SharedSet (RemoveWins) of T"
        let base_name = self.interner.resolve(base);
        if base_name == "SharedSet" || base_name == "ORSet" {
            if self.check(&TokenType::LParen) {
                self.advance(); // consume "("
                if self.check(&TokenType::RemoveWins) {
                    self.advance(); // consume "RemoveWins"
                    base = self.interner.intern("SharedSet_RemoveWins");
                } else if self.check(&TokenType::AddWins) {
                    self.advance(); // consume "AddWins"
                    // AddWins is default, but we can be explicit
                    base = self.interner.intern("SharedSet_AddWins");
                }
                if !self.check(&TokenType::RParen) {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedKeyword { keyword: ")".to_string() },
                        span: self.current_span(),
                    });
                }
                self.advance(); // consume ")"
            }
        }

        // Phase 49c: Check for algorithm modifier on SharedSequence: "SharedSequence (YATA) of T"
        let base_name = self.interner.resolve(base);
        if base_name == "SharedSequence" || base_name == "RGA" {
            if self.check(&TokenType::LParen) {
                self.advance(); // consume "("
                if self.check(&TokenType::YATA) {
                    self.advance(); // consume "YATA"
                    base = self.interner.intern("SharedSequence_YATA");
                }
                if !self.check(&TokenType::RParen) {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedKeyword { keyword: ")".to_string() },
                        span: self.current_span(),
                    });
                }
                self.advance(); // consume ")"
            }
        }

        // Phase 36: Check for "from Module" qualification
        let base_type = if self.check(&TokenType::From) {
            self.advance(); // consume "from"
            let module_name = self.consume_type_name()?;
            let module_str = self.interner.resolve(module_name);
            let base_str = self.interner.resolve(base);
            let qualified = format!("{}::{}", module_str, base_str);
            let qualified_sym = self.interner.intern(&qualified);
            TypeExpr::Named(qualified_sym)
        } else {
            // Phase 38: Get param count from registry OR from built-in std types
            let base_name = self.interner.resolve(base);
            let param_count = self.get_generic_param_count(base)
                .or_else(|| match base_name {
                    // Built-in generic types for Phase 38 std library
                    "Result" => Some(2),    // Result of T and E
                    "Option" => Some(1),    // Option of T
                    "Seq" | "List" | "Vec" => Some(1),  // Seq of T
                    "Set" | "HashSet" => Some(1), // Set of T
                    "Map" | "HashMap" => Some(2), // Map of K and V
                    "Pair" => Some(2),      // Pair of A and B
                    "Triple" => Some(3),    // Triple of A and B and C
                    // Phase 49b: CRDT generic types
                    "SharedSet" | "ORSet" | "SharedSet_AddWins" | "SharedSet_RemoveWins" => Some(1),
                    "SharedSequence" | "RGA" | "SharedSequence_YATA" | "CollaborativeSequence" => Some(1),
                    "SharedMap" | "ORMap" => Some(2),      // SharedMap from K to V
                    "Divergent" | "MVRegister" => Some(1), // Divergent T
                    _ => None,
                });

            // Check if it's a known generic type with parameters
            if let Some(count) = param_count {
                if self.check_of_preposition() || self.check_preposition_is("from") {
                    self.advance(); // consume "of" or "from"

                    let mut params = Vec::new();
                    for i in 0..count {
                        if i > 0 {
                            // Expect separator for params > 1: "and", "to", or ","
                            if self.check(&TokenType::And) || self.check_to_preposition() || self.check(&TokenType::Comma) {
                                self.advance();
                            }
                        }
                        let param = self.parse_type_expression()?;
                        params.push(param);
                    }

                    let params_slice = self.ctx.alloc_type_exprs(params);
                    TypeExpr::Generic { base, params: params_slice }
                } else {
                    // Generic type without parameters - treat as primitive or named
                    let is_primitive = self.type_registry.as_ref().map(|r| r.is_type(base)).unwrap_or(false)
                        || matches!(base_name, "Int" | "Nat" | "Text" | "Bool" | "Boolean" | "Real" | "Unit");
                    if is_primitive {
                        TypeExpr::Primitive(base)
                    } else {
                        TypeExpr::Named(base)
                    }
                }
            } else {
                // Check if it's a known primitive type (Int, Nat, Text, Bool, Real, Unit)
                let is_primitive = self.type_registry.as_ref().map(|r| r.is_type(base)).unwrap_or(false)
                    || matches!(base_name, "Int" | "Nat" | "Text" | "Bool" | "Boolean" | "Real" | "Unit");
                if is_primitive {
                    TypeExpr::Primitive(base)
                } else {
                    // User-defined or unknown type
                    TypeExpr::Named(base)
                }
            }
        };

        // Phase 43C: Check for refinement "where" clause
        if self.check(&TokenType::Where) {
            self.advance(); // consume "where"

            // Parse the predicate expression (supports compound: `x > 0 and x < 100`)
            let predicate_expr = self.parse_condition()?;

            // Extract bound variable from the left side of the expression
            let bound_var = self.extract_bound_var(&predicate_expr)
                .unwrap_or_else(|| self.interner.intern("it"));

            // Convert imperative Expr to logic LogicExpr
            let predicate = self.expr_to_logic_predicate(&predicate_expr, bound_var)
                .ok_or_else(|| ParseError {
                    kind: ParseErrorKind::InvalidRefinementPredicate,
                    span: self.peek().span,
                })?;

            // Allocate the base type
            let base_alloc = self.ctx.alloc_type_expr(base_type);

            return Ok(TypeExpr::Refinement { base: base_alloc, var: bound_var, predicate });
        }

        Ok(base_type)
    }

    /// Extracts the leftmost identifier from an expression as the bound variable.
    fn extract_bound_var(&self, expr: &Expr<'a>) -> Option<Symbol> {
        match expr {
            Expr::Identifier(sym) => Some(*sym),
            Expr::BinaryOp { left, .. } => self.extract_bound_var(left),
            _ => None,
        }
    }

    /// Converts an imperative comparison Expr to a Logic Kernel LogicExpr.
    /// Used for refinement type predicates: `Int where x > 0`
    fn expr_to_logic_predicate(&mut self, expr: &Expr<'a>, bound_var: Symbol) -> Option<&'a LogicExpr<'a>> {
        match expr {
            Expr::BinaryOp { op, left, right } => {
                // Map BinaryOpKind to predicate name
                let pred_name = match op {
                    BinaryOpKind::Gt => "Greater",
                    BinaryOpKind::Lt => "Less",
                    BinaryOpKind::GtEq => "GreaterEqual",
                    BinaryOpKind::LtEq => "LessEqual",
                    BinaryOpKind::Eq => "Equal",
                    BinaryOpKind::NotEq => "NotEqual",
                    BinaryOpKind::And => {
                        // Handle compound `x > 0 and x < 100`
                        let left_logic = self.expr_to_logic_predicate(left, bound_var)?;
                        let right_logic = self.expr_to_logic_predicate(right, bound_var)?;
                        return Some(self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: left_logic,
                            op: TokenType::And,
                            right: right_logic,
                        }));
                    }
                    BinaryOpKind::Or => {
                        let left_logic = self.expr_to_logic_predicate(left, bound_var)?;
                        let right_logic = self.expr_to_logic_predicate(right, bound_var)?;
                        return Some(self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: left_logic,
                            op: TokenType::Or,
                            right: right_logic,
                        }));
                    }
                    _ => return None, // Arithmetic ops not valid as predicates
                };
                let pred_sym = self.interner.intern(pred_name);

                // Convert operands to Terms
                let left_term = self.expr_to_term(left)?;
                let right_term = self.expr_to_term(right)?;

                let args = self.ctx.terms.alloc_slice([left_term, right_term]);
                Some(self.ctx.exprs.alloc(LogicExpr::Predicate { name: pred_sym, args, world: None }))
            }
            _ => None,
        }
    }

    /// Converts an imperative Expr to a logic Term.
    fn expr_to_term(&mut self, expr: &Expr<'a>) -> Option<Term<'a>> {
        match expr {
            Expr::Identifier(sym) => Some(Term::Variable(*sym)),
            Expr::Literal(lit) => {
                match lit {
                    Literal::Number(n) => Some(Term::Value {
                        kind: NumberKind::Integer(*n),
                        unit: None,
                        dimension: None,
                    }),
                    Literal::Boolean(b) => {
                        let sym = self.interner.intern(if *b { "true" } else { "false" });
                        Some(Term::Constant(sym))
                    }
                    _ => None, // Text, Nothing not supported in predicates
                }
            }
            _ => None,
        }
    }

    pub fn process_block_headers(&mut self) {
        use crate::token::BlockType;

        while self.current < self.tokens.len() {
            if let TokenType::BlockHeader { block_type } = &self.tokens[self.current].kind {
                self.mode = match block_type {
                    BlockType::Main | BlockType::Function => ParserMode::Imperative,
                    BlockType::Theorem | BlockType::Definition | BlockType::Proof |
                    BlockType::Example | BlockType::Logic | BlockType::Note | BlockType::TypeDef |
                    BlockType::Policy => ParserMode::Declarative,
                };
                self.current += 1;
            } else {
                break;
            }
        }
    }

    pub fn get_event_var(&mut self) -> Symbol {
        self.discourse_event_var.unwrap_or_else(|| self.interner.intern("e"))
    }

    pub fn capture_event_template(&mut self, verb: Symbol, roles: &[(ThematicRole, Term<'a>)], modifiers: &[Symbol]) {
        let non_agent_roles: Vec<_> = roles.iter()
            .filter(|(role, _)| *role != ThematicRole::Agent)
            .cloned()
            .collect();
        self.last_event_template = Some(EventTemplate {
            verb,
            non_agent_roles,
            modifiers: modifiers.to_vec(),
        });
    }

    fn parse_embedded_wh_clause(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        // Parse embedded question body: "who runs", "what John ate"
        let var_name = self.interner.intern("x");
        let var_term = Term::Variable(var_name);

        if self.check_verb() {
            // "who runs" pattern
            let verb = self.consume_verb();
            let body = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice([var_term]),
                world: None,
            });
            return Ok(body);
        }

        if self.check_content_word() || self.check_article() {
            // "what John ate" pattern
            let subject = self.parse_noun_phrase(true)?;
            if self.check_verb() {
                let verb = self.consume_verb();
                let body = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb,
                    args: self.ctx.terms.alloc_slice([
                        Term::Constant(subject.noun),
                        var_term,
                    ]),
                    world: None,
                });
                return Ok(body);
            }
        }

        // Fallback: just the wh-variable
        Ok(self.ctx.exprs.alloc(LogicExpr::Atom(var_name)))
    }

    pub fn set_pp_attachment_mode(&mut self, attach_to_noun: bool) {
        self.pp_attach_to_noun = attach_to_noun;
    }

    pub fn set_noun_priority_mode(&mut self, mode: bool) {
        self.noun_priority_mode = mode;
    }

    pub fn set_collective_mode(&mut self, mode: bool) {
        self.collective_mode = mode;
    }

    pub fn set_event_reading_mode(&mut self, mode: bool) {
        self.event_reading_mode = mode;
    }

    pub fn set_negative_scope_mode(&mut self, mode: NegativeScopeMode) {
        self.negative_scope_mode = mode;
    }

    pub fn set_modal_preference(&mut self, pref: ModalPreference) {
        self.modal_preference = pref;
    }

    fn checkpoint(&self) -> ParserCheckpoint {
        ParserCheckpoint {
            pos: self.current,
            var_counter: self.var_counter,
            bindings_len: self.donkey_bindings.len(),
            island: self.current_island,
            time: self.pending_time,
            negative_depth: self.negative_depth,
        }
    }

    fn restore(&mut self, cp: ParserCheckpoint) {
        self.current = cp.pos;
        self.var_counter = cp.var_counter;
        self.donkey_bindings.truncate(cp.bindings_len);
        self.current_island = cp.island;
        self.pending_time = cp.time;
        self.negative_depth = cp.negative_depth;
    }

    fn is_negative_context(&self) -> bool {
        self.negative_depth % 2 == 1
    }

    pub fn guard(&mut self) -> ParserGuard<'_, 'a, 'ctx, 'int> {
        ParserGuard {
            checkpoint: self.checkpoint(),
            parser: self,
            committed: false,
        }
    }

    pub(super) fn try_parse<F, T>(&mut self, op: F) -> Option<T>
    where
        F: FnOnce(&mut Self) -> ParseResult<T>,
    {
        let cp = self.checkpoint();
        match op(self) {
            Ok(res) => Some(res),
            Err(_) => {
                self.restore(cp);
                None
            }
        }
    }

    fn resolve_pronoun(&mut self, gender: Gender, number: Number) -> ParseResult<ResolvedPronoun> {
        // Try DRS resolution (scope-aware)
        let current_box = self.drs.current_box_index();
        match self.drs.resolve_pronoun(current_box, gender, number) {
            Ok(sym) => return Ok(ResolvedPronoun::Variable(sym)),
            Err(crate::drs::ScopeError::InaccessibleReferent { reason, .. }) => {
                // Hard error: referent exists but is trapped in inaccessible scope
                return Err(ParseError {
                    kind: ParseErrorKind::ScopeViolation(reason),
                    span: self.current_span(),
                });
            }
            Err(crate::drs::ScopeError::NoMatchingReferent { gender: g, number: n }) => {
                // Try telescoping across sentence boundaries
                if let Some(candidate) = self.world_state.resolve_via_telescope(g) {
                    return Ok(ResolvedPronoun::Variable(candidate.variable));
                }

                // In discourse mode (multi-sentence context), unresolved pronouns are an error
                if self.world_state.in_discourse_mode() {
                    return Err(ParseError {
                        kind: ParseErrorKind::UnresolvedPronoun {
                            gender: g,
                            number: n,
                        },
                        span: self.current_span(),
                    });
                }

                // No prior referent - introduce deictic referent (pointing to someone in the world)
                // This handles sentences like "She told him a story" without prior discourse
                let deictic_name = match (g, n) {
                    (Gender::Male, Number::Singular) => "Him",
                    (Gender::Female, Number::Singular) => "Her",
                    (Gender::Neuter, Number::Singular) => "It",
                    (Gender::Male, Number::Plural) | (Gender::Female, Number::Plural) => "Them",
                    (Gender::Neuter, Number::Plural) => "Them",
                    (Gender::Unknown, _) => "Someone",
                };
                let sym = self.interner.intern(deictic_name);
                // Introduce the deictic referent to DRS for potential later reference
                self.drs.introduce_referent(sym, sym, g, n);
                return Ok(ResolvedPronoun::Constant(sym));
            }
        }
    }

    fn resolve_donkey_pronoun(&mut self, gender: Gender) -> Option<Symbol> {
        for (noun_class, var_name, used, _wide_neg) in self.donkey_bindings.iter_mut().rev() {
            let noun_str = self.interner.resolve(*noun_class);
            let noun_gender = Self::infer_noun_gender(noun_str);
            if noun_gender == gender || gender == Gender::Neuter || noun_gender == Gender::Unknown {
                *used = true; // Mark as used by a pronoun (donkey anaphor)
                return Some(*var_name);
            }
        }
        None
    }

    fn infer_noun_gender(noun: &str) -> Gender {
        let lower = noun.to_lowercase();
        if lexicon::is_female_noun(&lower) {
            Gender::Female
        } else if lexicon::is_male_noun(&lower) {
            Gender::Male
        } else if lexicon::is_neuter_noun(&lower) {
            Gender::Neuter
        } else {
            Gender::Unknown
        }
    }

    fn is_plural_noun(noun: &str) -> bool {
        let lower = noun.to_lowercase();
        if lexicon::is_irregular_plural(&lower) {
            return true;
        }
        lower.ends_with('s') && !lower.ends_with("ss") && lower.len() > 2
    }

    fn singularize_noun(noun: &str) -> String {
        let lower = noun.to_lowercase();
        if let Some(singular) = lexicon::singularize(&lower) {
            return singular.to_string();
        }
        if lower.ends_with('s') && !lower.ends_with("ss") && lower.len() > 2 {
            let base = &lower[..lower.len() - 1];
            let mut chars: Vec<char> = base.chars().collect();
            if !chars.is_empty() {
                chars[0] = chars[0].to_uppercase().next().unwrap();
            }
            return chars.into_iter().collect();
        }
        let mut chars: Vec<char> = lower.chars().collect();
        if !chars.is_empty() {
            chars[0] = chars[0].to_uppercase().next().unwrap();
        }
        chars.into_iter().collect()
    }

    fn infer_gender(name: &str) -> Gender {
        let lower = name.to_lowercase();
        if lexicon::is_male_name(&lower) {
            Gender::Male
        } else if lexicon::is_female_name(&lower) {
            Gender::Female
        } else {
            Gender::Unknown
        }
    }


    fn next_var_name(&mut self) -> Symbol {
        const VARS: &[&str] = &["x", "y", "z", "w", "v", "u"];
        let idx = self.var_counter;
        self.var_counter += 1;
        if idx < VARS.len() {
            self.interner.intern(VARS[idx])
        } else {
            let name = format!("x{}", idx - VARS.len() + 1);
            self.interner.intern(&name)
        }
    }

    pub fn parse(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let mut result = self.parse_sentence()?;

        // Loop: handle ANY number of additional sentences (unlimited)
        // Handle all sentence terminators: . ? !
        while self.check(&TokenType::Period) || self.check(&TokenType::Exclamation) {
            self.advance(); // consume terminator
            if !self.is_at_end() {
                let next = self.parse_sentence()?;
                result = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: result,
                    op: TokenType::And,
                    right: next,
                });
            }
        }

        Ok(result)
    }

    pub fn parse_program(&mut self) -> ParseResult<Vec<Stmt<'a>>> {
        let mut statements = Vec::new();
        let mut in_definition_block = false;

        // Check if we started in a Definition block (from process_block_headers)
        if self.mode == ParserMode::Declarative {
            // Check if the previous token was a Definition header
            // For now, assume Definition blocks should be skipped
            // We'll detect them by checking the content pattern
        }

        while !self.is_at_end() {
            // Handle block headers
            if let Some(Token { kind: TokenType::BlockHeader { block_type }, .. }) = self.tokens.get(self.current) {
                match block_type {
                    BlockType::Definition => {
                        in_definition_block = true;
                        self.mode = ParserMode::Declarative;
                        self.advance();
                        continue;
                    }
                    BlockType::Main => {
                        in_definition_block = false;
                        self.mode = ParserMode::Imperative;
                        self.advance();
                        continue;
                    }
                    BlockType::Function => {
                        in_definition_block = false;
                        self.mode = ParserMode::Imperative;
                        self.advance();
                        // Parse function definition
                        let func_def = self.parse_function_def()?;
                        statements.push(func_def);
                        continue;
                    }
                    BlockType::TypeDef => {
                        // Type definitions are handled by DiscoveryPass
                        // Skip content until next block header
                        self.advance();
                        self.skip_type_def_content();
                        continue;
                    }
                    BlockType::Policy => {
                        // Phase 50: Policy definitions are handled by DiscoveryPass
                        // Skip content until next block header
                        in_definition_block = true;  // Reuse flag to skip content
                        self.mode = ParserMode::Declarative;
                        self.advance();
                        continue;
                    }
                    _ => {
                        in_definition_block = false;
                        self.mode = ParserMode::Declarative;
                        self.advance();
                        continue;
                    }
                }
            }

            // Skip Definition block content - handled by DiscoveryPass
            if in_definition_block {
                self.advance();
                continue;
            }

            // Skip indent/dedent/newline tokens at program level
            if self.check(&TokenType::Indent) || self.check(&TokenType::Dedent) || self.check(&TokenType::Newline) {
                self.advance();
                continue;
            }

            // In imperative mode, parse statements
            if self.mode == ParserMode::Imperative {
                let stmt = self.parse_statement()?;
                statements.push(stmt);

                if self.check(&TokenType::Period) {
                    self.advance();
                }
            } else {
                // In declarative mode (Theorem, etc.), skip for now
                self.advance();
            }
        }

        Ok(statements)
    }

    fn parse_statement(&mut self) -> ParseResult<Stmt<'a>> {
        // Phase 32: Function definitions can appear inside Main block
        // Handle both TokenType::To and Preposition("to")
        if self.check(&TokenType::To) || self.check_preposition_is("to") {
            return self.parse_function_def();
        }
        if self.check(&TokenType::Let) {
            return self.parse_let_statement();
        }
        if self.check(&TokenType::Set) {
            return self.parse_set_statement();
        }
        if self.check(&TokenType::Return) {
            return self.parse_return_statement();
        }
        if self.check(&TokenType::If) {
            return self.parse_if_statement();
        }
        if self.check(&TokenType::Assert) {
            return self.parse_assert_statement();
        }
        // Phase 35: Trust statement
        if self.check(&TokenType::Trust) {
            return self.parse_trust_statement();
        }
        // Phase 50: Security Check statement
        if self.check(&TokenType::Check) {
            return self.parse_check_statement();
        }
        // Phase 51: P2P Networking statements
        if self.check(&TokenType::Listen) {
            return self.parse_listen_statement();
        }
        if self.check(&TokenType::NetConnect) {
            return self.parse_connect_statement();
        }
        if self.check(&TokenType::Sleep) {
            return self.parse_sleep_statement();
        }
        // Phase 52: GossipSub sync statement
        if self.check(&TokenType::Sync) {
            return self.parse_sync_statement();
        }
        // Phase 53: Persistent storage mount statement
        if self.check(&TokenType::Mount) {
            return self.parse_mount_statement();
        }
        if self.check(&TokenType::While) {
            return self.parse_while_statement();
        }
        if self.check(&TokenType::Repeat) {
            return self.parse_repeat_statement();
        }
        if self.check(&TokenType::Call) {
            return self.parse_call_statement();
        }
        if self.check(&TokenType::Give) {
            return self.parse_give_statement();
        }
        if self.check(&TokenType::Show) {
            return self.parse_show_statement();
        }
        // Phase 33: Pattern matching on sum types
        if self.check(&TokenType::Inspect) {
            return self.parse_inspect_statement();
        }

        // Phase 43D: Collection operations
        if self.check(&TokenType::Push) {
            return self.parse_push_statement();
        }
        if self.check(&TokenType::Pop) {
            return self.parse_pop_statement();
        }
        // Set operations
        if self.check(&TokenType::Add) {
            return self.parse_add_statement();
        }
        if self.check(&TokenType::Remove) {
            return self.parse_remove_statement();
        }

        // Phase 8.5: Memory zone block
        if self.check(&TokenType::Inside) {
            return self.parse_zone_statement();
        }

        // Phase 9: Structured Concurrency blocks
        if self.check(&TokenType::Attempt) {
            return self.parse_concurrent_block();
        }
        if self.check(&TokenType::Simultaneously) {
            return self.parse_parallel_block();
        }

        // Phase 10: IO statements
        if self.check(&TokenType::Read) {
            return self.parse_read_statement();
        }
        if self.check(&TokenType::Write) {
            return self.parse_write_statement();
        }

        // Phase 46: Agent System statements
        if self.check(&TokenType::Spawn) {
            return self.parse_spawn_statement();
        }
        if self.check(&TokenType::Send) {
            // Phase 54: Disambiguate "Send x into pipe" vs "Send x to agent"
            if self.lookahead_contains_into() {
                return self.parse_send_pipe_statement();
            }
            return self.parse_send_statement();
        }
        if self.check(&TokenType::Await) {
            // Phase 54: Disambiguate "Await the first of:" vs "Await response from agent"
            if self.lookahead_is_first_of() {
                return self.parse_select_statement();
            }
            return self.parse_await_statement();
        }

        // Phase 49: CRDT statements
        if self.check(&TokenType::Merge) {
            return self.parse_merge_statement();
        }
        if self.check(&TokenType::Increase) {
            return self.parse_increase_statement();
        }
        // Phase 49b: Extended CRDT statements
        if self.check(&TokenType::Decrease) {
            return self.parse_decrease_statement();
        }
        if self.check(&TokenType::Append) {
            return self.parse_append_statement();
        }
        if self.check(&TokenType::Resolve) {
            return self.parse_resolve_statement();
        }

        // Phase 54: Go-like Concurrency statements
        if self.check(&TokenType::Launch) {
            return self.parse_launch_statement();
        }
        if self.check(&TokenType::Stop) {
            return self.parse_stop_statement();
        }
        if self.check(&TokenType::Try) {
            return self.parse_try_statement();
        }
        if self.check(&TokenType::Receive) {
            return self.parse_receive_pipe_statement();
        }

        // Expression-statement: function call without "Call" keyword
        // e.g., `greet("Alice").` instead of `Call greet with "Alice".`
        // Check if next token is LParen (indicating a function call)
        if self.tokens.get(self.current + 1)
            .map(|t| matches!(t.kind, TokenType::LParen))
            .unwrap_or(false)
        {
            // Get the function name from current token
            let function = self.peek().lexeme;
            self.advance(); // consume function name

            // Parse the call expression (starts from LParen)
            let expr = self.parse_call_expr(function)?;
            if let Expr::Call { function, args } = expr {
                return Ok(Stmt::Call { function: *function, args: args.clone() });
            }
        }

        Err(ParseError {
            kind: ParseErrorKind::ExpectedStatement,
            span: self.current_span(),
        })
    }

    fn parse_if_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "If"

        // Parse condition expression (simple: identifier equals value)
        let cond = self.parse_condition()?;

        // Expect colon
        if !self.check(&TokenType::Colon) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume ":"

        // Expect indent
        if !self.check(&TokenType::Indent) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedStatement,
                span: self.current_span(),
            });
        }
        self.advance(); // consume Indent

        // Parse then block
        let mut then_stmts = Vec::new();
        while !self.check(&TokenType::Dedent) && !self.is_at_end() {
            let stmt = self.parse_statement()?;
            then_stmts.push(stmt);
            if self.check(&TokenType::Period) {
                self.advance();
            }
        }

        // Consume dedent
        if self.check(&TokenType::Dedent) {
            self.advance();
        }

        // Allocate then_block in arena
        let then_block = self.ctx.stmts.expect("imperative arenas not initialized")
            .alloc_slice(then_stmts.into_iter());

        // Check for Otherwise: block
        let else_block = if self.check(&TokenType::Otherwise) {
            self.advance(); // consume "Otherwise"

            if !self.check(&TokenType::Colon) {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance(); // consume ":"

            if !self.check(&TokenType::Indent) {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedStatement,
                    span: self.current_span(),
                });
            }
            self.advance(); // consume Indent

            let mut else_stmts = Vec::new();
            while !self.check(&TokenType::Dedent) && !self.is_at_end() {
                let stmt = self.parse_statement()?;
                else_stmts.push(stmt);
                if self.check(&TokenType::Period) {
                    self.advance();
                }
            }

            if self.check(&TokenType::Dedent) {
                self.advance();
            }

            Some(self.ctx.stmts.expect("imperative arenas not initialized")
                .alloc_slice(else_stmts.into_iter()))
        } else {
            None
        };

        Ok(Stmt::If {
            cond,
            then_block,
            else_block,
        })
    }

    fn parse_while_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "While"

        let cond = self.parse_condition()?;

        // Phase 44: Parse optional (decreasing expr)
        let decreasing = if self.check(&TokenType::LParen) {
            self.advance(); // consume '('

            // Expect "decreasing" keyword
            if !self.check_word("decreasing") {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: "decreasing".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance(); // consume "decreasing"

            let variant = self.parse_imperative_expr()?;

            if !self.check(&TokenType::RParen) {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: ")".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance(); // consume ')'

            Some(variant)
        } else {
            None
        };

        if !self.check(&TokenType::Colon) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume ":"

        if !self.check(&TokenType::Indent) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedStatement,
                span: self.current_span(),
            });
        }
        self.advance(); // consume Indent

        let mut body_stmts = Vec::new();
        while !self.check(&TokenType::Dedent) && !self.is_at_end() {
            let stmt = self.parse_statement()?;
            body_stmts.push(stmt);
            if self.check(&TokenType::Period) {
                self.advance();
            }
        }

        if self.check(&TokenType::Dedent) {
            self.advance();
        }

        let body = self.ctx.stmts.expect("imperative arenas not initialized")
            .alloc_slice(body_stmts.into_iter());

        Ok(Stmt::While { cond, body, decreasing })
    }

    fn parse_repeat_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Repeat"

        // Optional "for"
        if self.check(&TokenType::For) {
            self.advance();
        }

        // Parse loop variable (using context-aware identifier parsing)
        let var = self.expect_identifier()?;

        // Determine iteration type: "in" for collection, "from" for range
        let iterable = if self.check(&TokenType::From) || self.check_preposition_is("from") {
            self.advance(); // consume "from"
            let start = self.parse_imperative_expr()?;

            // Expect "to" (can be keyword or preposition)
            if !self.check(&TokenType::To) && !self.check_preposition_is("to") {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: "to".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance();

            let end = self.parse_imperative_expr()?;
            self.ctx.alloc_imperative_expr(Expr::Range { start, end })
        } else if self.check(&TokenType::In) || self.check_preposition_is("in") {
            self.advance(); // consume "in"
            self.parse_imperative_expr()?
        } else {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "in or from".to_string() },
                span: self.current_span(),
            });
        };

        // Expect colon
        if !self.check(&TokenType::Colon) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                span: self.current_span(),
            });
        }
        self.advance();

        // Expect indent
        if !self.check(&TokenType::Indent) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedStatement,
                span: self.current_span(),
            });
        }
        self.advance();

        // Parse body statements
        let mut body_stmts = Vec::new();
        while !self.check(&TokenType::Dedent) && !self.is_at_end() {
            let stmt = self.parse_statement()?;
            body_stmts.push(stmt);
            if self.check(&TokenType::Period) {
                self.advance();
            }
        }

        if self.check(&TokenType::Dedent) {
            self.advance();
        }

        let body = self.ctx.stmts.expect("imperative arenas not initialized")
            .alloc_slice(body_stmts.into_iter());

        Ok(Stmt::Repeat { var, iterable, body })
    }

    fn parse_call_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Call"

        // Parse function name (identifier)
        // Function names can be nouns, adjectives, or verbs (e.g., "work", "process")
        // Use the token's lexeme to match function definition casing
        let function = match &self.peek().kind {
            TokenType::Noun(sym) | TokenType::Adjective(sym) => {
                let s = *sym;
                self.advance();
                s
            }
            TokenType::Verb { .. } | TokenType::Ambiguous { .. } => {
                // Use lexeme (actual text) not lemma to preserve casing
                let s = self.peek().lexeme;
                self.advance();
                s
            }
            _ => {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedIdentifier,
                    span: self.current_span(),
                });
            }
        };

        // Expect "with" followed by arguments
        let args = if self.check_preposition_is("with") {
            self.advance(); // consume "with"
            self.parse_call_arguments()?
        } else {
            Vec::new()
        };

        Ok(Stmt::Call { function, args })
    }

    fn parse_call_arguments(&mut self) -> ParseResult<Vec<&'a Expr<'a>>> {
        let mut args = Vec::new();

        // Parse first argument
        let arg = self.parse_imperative_expr()?;
        args.push(arg);

        // Parse additional comma-separated arguments
        while self.check(&TokenType::Comma) {
            self.advance(); // consume ","
            let arg = self.parse_imperative_expr()?;
            args.push(arg);
        }

        Ok(args)
    }

    fn parse_condition(&mut self) -> ParseResult<&'a Expr<'a>> {
        // Grand Challenge: Parse compound conditions with "and" and "or"
        // "or" has lower precedence than "and"
        self.parse_or_condition()
    }

    /// Parse "or" conditions (lower precedence than "and")
    fn parse_or_condition(&mut self) -> ParseResult<&'a Expr<'a>> {
        let mut left = self.parse_and_condition()?;

        while self.check(&TokenType::Or) || self.check_word("or") {
            self.advance();
            let right = self.parse_and_condition()?;
            left = self.ctx.alloc_imperative_expr(Expr::BinaryOp {
                op: BinaryOpKind::Or,
                left,
                right,
            });
        }

        Ok(left)
    }

    /// Parse "and" conditions (higher precedence than "or")
    fn parse_and_condition(&mut self) -> ParseResult<&'a Expr<'a>> {
        let mut left = self.parse_comparison()?;

        while self.check(&TokenType::And) || self.check_word("and") {
            self.advance();
            let right = self.parse_comparison()?;
            left = self.ctx.alloc_imperative_expr(Expr::BinaryOp {
                op: BinaryOpKind::And,
                left,
                right,
            });
        }

        Ok(left)
    }

    /// Grand Challenge: Parse a single comparison expression
    fn parse_comparison(&mut self) -> ParseResult<&'a Expr<'a>> {
        // Handle unary "not" operator: "not a" or "not (x > 5)"
        if self.check(&TokenType::Not) || self.check_word("not") {
            self.advance(); // consume "not"
            let operand = self.parse_comparison()?; // recursive to handle "not not x"
            // Implement as: operand == false (since we don't have UnaryNot)
            return Ok(self.ctx.alloc_imperative_expr(Expr::BinaryOp {
                op: BinaryOpKind::Eq,
                left: operand,
                right: self.ctx.alloc_imperative_expr(Expr::Literal(Literal::Boolean(false))),
            }));
        }

        let left = self.parse_imperative_expr()?;

        // Check for comparison operators
        let op = if self.check(&TokenType::Equals) {
            self.advance();
            Some(BinaryOpKind::Eq)
        } else if self.check(&TokenType::Identity) {
            // "is equal to" was tokenized as TokenType::Identity
            self.advance();
            Some(BinaryOpKind::Eq)
        } else if self.check_word("is") {
            // Peek ahead to determine which comparison
            let saved_pos = self.current;
            self.advance(); // consume "is"

            if self.check_word("greater") {
                self.advance(); // consume "greater"
                if self.check_word("than") || self.check_preposition_is("than") {
                    self.advance(); // consume "than"
                    Some(BinaryOpKind::Gt)
                } else {
                    self.current = saved_pos;
                    None
                }
            } else if self.check_word("less") {
                self.advance(); // consume "less"
                if self.check_word("than") || self.check_preposition_is("than") {
                    self.advance(); // consume "than"
                    Some(BinaryOpKind::Lt)
                } else {
                    self.current = saved_pos;
                    None
                }
            } else if self.check_word("at") {
                self.advance(); // consume "at"
                if self.check_word("least") {
                    self.advance(); // consume "least"
                    Some(BinaryOpKind::GtEq)
                } else if self.check_word("most") {
                    self.advance(); // consume "most"
                    Some(BinaryOpKind::LtEq)
                } else {
                    self.current = saved_pos;
                    None
                }
            } else if self.check_word("not") || self.check(&TokenType::Not) {
                // "is not X" → NotEq
                self.advance(); // consume "not"
                Some(BinaryOpKind::NotEq)
            } else if self.check_word("equal") {
                // "is equal to X" → Eq
                self.advance(); // consume "equal"
                if self.check_preposition_is("to") {
                    self.advance(); // consume "to"
                    Some(BinaryOpKind::Eq)
                } else {
                    self.current = saved_pos;
                    None
                }
            } else {
                self.current = saved_pos;
                None
            }
        } else if self.check(&TokenType::Lt) {
            self.advance();
            Some(BinaryOpKind::Lt)
        } else if self.check(&TokenType::Gt) {
            self.advance();
            Some(BinaryOpKind::Gt)
        } else if self.check(&TokenType::LtEq) {
            self.advance();
            Some(BinaryOpKind::LtEq)
        } else if self.check(&TokenType::GtEq) {
            self.advance();
            Some(BinaryOpKind::GtEq)
        } else if self.check(&TokenType::EqEq) {
            self.advance();
            Some(BinaryOpKind::Eq)
        } else if self.check(&TokenType::NotEq) {
            self.advance();
            Some(BinaryOpKind::NotEq)
        } else {
            None
        };

        if let Some(op) = op {
            let right = self.parse_imperative_expr()?;
            Ok(self.ctx.alloc_imperative_expr(Expr::BinaryOp { op, left, right }))
        } else {
            Ok(left)
        }
    }

    fn parse_let_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Let"

        // Check for "mutable" keyword
        let mutable = if self.check_mutable_keyword() {
            self.advance();
            true
        } else {
            false
        };

        // Get identifier
        let var = self.expect_identifier()?;

        // Check for optional type annotation: `: Type`
        let ty = if self.check(&TokenType::Colon) {
            self.advance(); // consume ":"
            let type_expr = self.parse_type_expression()?;
            Some(self.ctx.alloc_type_expr(type_expr))
        } else {
            None
        };

        // Expect "be"
        if !self.check(&TokenType::Be) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "be".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "be"

        // Phase 53: Check for "mounted at [path]" pattern (for Persistent types)
        if self.check_word("mounted") {
            self.advance(); // consume "mounted"
            if !self.check(&TokenType::At) && !self.check_preposition_is("at") {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: "at".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance(); // consume "at"
            let path = self.parse_imperative_expr()?;
            return Ok(Stmt::Mount { var, path });
        }

        // Phase 51: Check for "a PeerAgent at [addr]" pattern
        if self.check_article() {
            let saved_pos = self.current;
            self.advance(); // consume article

            // Check if next word is "PeerAgent" (case insensitive)
            if let TokenType::Noun(sym) | TokenType::ProperName(sym) = self.peek().kind {
                let word = self.interner.resolve(sym).to_lowercase();
                if word == "peeragent" {
                    self.advance(); // consume "PeerAgent"

                    // Check for "at" keyword
                    if self.check(&TokenType::At) || self.check_preposition_is("at") {
                        self.advance(); // consume "at"

                        // Parse address expression
                        let address = self.parse_imperative_expr()?;

                        return Ok(Stmt::LetPeerAgent { var, address });
                    }
                }
            }
            // Not a PeerAgent, backtrack
            self.current = saved_pos;
        }

        // Phase 54: Check for "a Pipe of Type" pattern
        if self.check_article() {
            let saved_pos = self.current;
            self.advance(); // consume article

            if self.check(&TokenType::Pipe) {
                self.advance(); // consume "Pipe"

                // Expect "of"
                if !self.check_word("of") {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedKeyword { keyword: "of".to_string() },
                        span: self.current_span(),
                    });
                }
                self.advance(); // consume "of"

                // Parse element type
                let element_type = self.expect_identifier()?;

                // Variable registration now handled by DRS

                return Ok(Stmt::CreatePipe { var, element_type, capacity: None });
            }
            // Not a Pipe, backtrack
            self.current = saved_pos;
        }

        // Phase 54: Check for "Launch a task to..." pattern (for task handles)
        if self.check(&TokenType::Launch) {
            self.advance(); // consume "Launch"

            // Expect "a"
            if !self.check_article() {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: "a".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance();

            // Expect "task"
            if !self.check(&TokenType::Task) {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: "task".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance();

            // Expect "to"
            if !self.check(&TokenType::To) && !self.check_word("to") {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: "to".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance();

            // Parse function name
            let function = self.expect_identifier()?;

            // Parse optional arguments: "with arg1, arg2"
            let args = if self.check_word("with") {
                self.advance();
                self.parse_call_arguments()?
            } else {
                vec![]
            };

            return Ok(Stmt::LaunchTaskWithHandle { handle: var, function, args });
        }

        // Parse expression value (simple: just a number for now)
        let value = self.parse_imperative_expr()?;

        // Phase 43B: Type check - verify declared type matches value type
        if let Some(declared_ty) = &ty {
            if let Some(inferred) = self.infer_literal_type(value) {
                if !self.check_type_compatibility(declared_ty, inferred) {
                    let expected = match declared_ty {
                        TypeExpr::Primitive(sym) | TypeExpr::Named(sym) => {
                            self.interner.resolve(*sym).to_string()
                        }
                        _ => "unknown".to_string(),
                    };
                    return Err(ParseError {
                        kind: ParseErrorKind::TypeMismatch {
                            expected,
                            found: inferred.to_string(),
                        },
                        span: self.current_span(),
                    });
                }
            }
        }

        // Register variable in WorldState's DRS with Owned state for ownership tracking
        self.world_state.drs.introduce_referent(var, var, crate::drs::Gender::Unknown, crate::drs::Number::Singular);

        Ok(Stmt::Let { var, ty, value, mutable })
    }

    fn check_mutable_keyword(&self) -> bool {
        if let TokenType::Noun(sym) | TokenType::Adjective(sym) = self.peek().kind {
            let word = self.interner.resolve(sym).to_lowercase();
            word == "mutable" || word == "mut"
        } else {
            false
        }
    }

    /// Phase 43B: Infer the type of a literal expression
    fn infer_literal_type(&self, expr: &Expr<'_>) -> Option<&'static str> {
        match expr {
            Expr::Literal(lit) => match lit {
                crate::ast::Literal::Number(_) => Some("Int"),
                crate::ast::Literal::Float(_) => Some("Real"),
                crate::ast::Literal::Text(_) => Some("Text"),
                crate::ast::Literal::Boolean(_) => Some("Bool"),
                crate::ast::Literal::Nothing => Some("Unit"),
                crate::ast::Literal::Char(_) => Some("Char"),
            },
            _ => None, // Can't infer type for non-literals yet
        }
    }

    /// Phase 43B: Check if declared type matches inferred type
    fn check_type_compatibility(&self, declared: &TypeExpr<'_>, inferred: &str) -> bool {
        match declared {
            TypeExpr::Primitive(sym) | TypeExpr::Named(sym) => {
                let declared_name = self.interner.resolve(*sym);
                // Nat and Byte are compatible with Int literals
                declared_name.eq_ignore_ascii_case(inferred)
                    || (declared_name.eq_ignore_ascii_case("Nat") && inferred == "Int")
                    || (declared_name.eq_ignore_ascii_case("Byte") && inferred == "Int")
            }
            _ => true, // For generics/functions, skip check for now
        }
    }

    fn parse_set_statement(&mut self) -> ParseResult<Stmt<'a>> {
        use crate::ast::Expr;
        self.advance(); // consume "Set"

        // Parse target - can be identifier or field access expression
        let target_expr = self.parse_imperative_expr()?;

        // Expect "to" - can be TokenType::To or Preposition("to")
        let is_to = self.check(&TokenType::To) || matches!(
            &self.peek().kind,
            TokenType::Preposition(sym) if self.interner.resolve(*sym) == "to"
        );
        if !is_to {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "to".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "to"

        // Parse expression value
        let value = self.parse_imperative_expr()?;

        // Phase 31: Handle field access targets
        // Also handle index targets: Set item N of X to Y
        match target_expr {
            Expr::FieldAccess { object, field } => {
                Ok(Stmt::SetField { object, field: *field, value })
            }
            Expr::Identifier(target) => {
                Ok(Stmt::Set { target: *target, value })
            }
            Expr::Index { collection, index } => {
                Ok(Stmt::SetIndex { collection, index, value })
            }
            _ => Err(ParseError {
                kind: ParseErrorKind::ExpectedIdentifier,
                span: self.current_span(),
            })
        }
    }

    fn parse_return_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Return"

        // Check if there's a value or just "Return."
        if self.check(&TokenType::Period) || self.is_at_end() {
            return Ok(Stmt::Return { value: None });
        }

        // Use parse_comparison to support returning comparison results like "n equals 5"
        let value = self.parse_comparison()?;
        Ok(Stmt::Return { value: Some(value) })
    }

    fn parse_assert_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Assert"

        // Optionally consume "that"
        if self.check(&TokenType::That) {
            self.advance();
        }

        // Parse condition using imperative expression parser
        // This allows syntax like "Assert that b is not 0."
        let condition = self.parse_condition()?;

        Ok(Stmt::RuntimeAssert { condition })
    }

    /// Phase 35: Parse Trust statement
    /// Syntax: Trust [that] [proposition] because [justification].
    fn parse_trust_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Trust"

        // Optionally consume "that"
        if self.check(&TokenType::That) {
            self.advance();
        }

        // Save current mode and switch to declarative for proposition parsing
        let saved_mode = self.mode;
        self.mode = ParserMode::Declarative;

        // Parse the proposition using the Logic Kernel
        let proposition = self.parse()?;

        // Restore mode
        self.mode = saved_mode;

        // Expect "because"
        if !self.check(&TokenType::Because) {
            return Err(ParseError {
                kind: ParseErrorKind::UnexpectedToken {
                    expected: TokenType::Because,
                    found: self.peek().kind.clone(),
                },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "because"

        // Parse justification (string literal)
        let justification = match &self.peek().kind {
            TokenType::StringLiteral(sym) => {
                let s = *sym;
                self.advance();
                s
            }
            _ => {
                return Err(ParseError {
                    kind: ParseErrorKind::UnexpectedToken {
                        expected: TokenType::StringLiteral(self.interner.intern("")),
                        found: self.peek().kind.clone(),
                    },
                    span: self.current_span(),
                });
            }
        };

        Ok(Stmt::Trust { proposition, justification })
    }

    /// Phase 50: Parse Check statement - mandatory security guard
    /// Syntax: Check that [subject] is [predicate].
    /// Syntax: Check that [subject] can [action] the [object].
    fn parse_check_statement(&mut self) -> ParseResult<Stmt<'a>> {
        let start_span = self.current_span();
        self.advance(); // consume "Check"

        // Optionally consume "that"
        if self.check(&TokenType::That) {
            self.advance();
        }

        // Consume optional "the"
        if matches!(self.peek().kind, TokenType::Article(_)) {
            self.advance();
        }

        // Parse subject identifier (e.g., "user")
        let subject = match &self.peek().kind {
            TokenType::Noun(sym) | TokenType::Adjective(sym) | TokenType::ProperName(sym) => {
                let s = *sym;
                self.advance();
                s
            }
            _ => {
                // Try to get an identifier
                let tok = self.peek();
                let s = tok.lexeme;
                self.advance();
                s
            }
        };

        // Determine if this is a predicate check ("is admin") or capability check ("can publish")
        let is_capability;
        let predicate;
        let object;

        if self.check(&TokenType::Is) || self.check(&TokenType::Are) {
            // Predicate check: "user is admin"
            is_capability = false;
            self.advance(); // consume "is" / "are"

            // Parse predicate name (e.g., "admin")
            predicate = match &self.peek().kind {
                TokenType::Noun(sym) | TokenType::Adjective(sym) | TokenType::ProperName(sym) => {
                    let s = *sym;
                    self.advance();
                    s
                }
                _ => {
                    let tok = self.peek();
                    let s = tok.lexeme;
                    self.advance();
                    s
                }
            };
            object = None;
        } else if self.check(&TokenType::Can) {
            // Capability check: "user can publish the document"
            is_capability = true;
            self.advance(); // consume "can"

            // Parse action (e.g., "publish", "edit", "delete")
            predicate = match &self.peek().kind {
                TokenType::Verb { lemma, .. } => {
                    let s = *lemma;
                    self.advance();
                    s
                }
                TokenType::Noun(sym) | TokenType::Adjective(sym) | TokenType::ProperName(sym) => {
                    let s = *sym;
                    self.advance();
                    s
                }
                _ => {
                    let tok = self.peek();
                    let s = tok.lexeme;
                    self.advance();
                    s
                }
            };

            // Consume optional "the"
            if matches!(self.peek().kind, TokenType::Article(_)) {
                self.advance();
            }

            // Parse object (e.g., "document")
            let obj = match &self.peek().kind {
                TokenType::Noun(sym) | TokenType::Adjective(sym) | TokenType::ProperName(sym) => {
                    let s = *sym;
                    self.advance();
                    s
                }
                _ => {
                    let tok = self.peek();
                    let s = tok.lexeme;
                    self.advance();
                    s
                }
            };
            object = Some(obj);
        } else {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "is/can".to_string() },
                span: self.current_span(),
            });
        }

        // Build source text for error message
        let source_text = if is_capability {
            let obj_name = self.interner.resolve(object.unwrap());
            let pred_name = self.interner.resolve(predicate);
            let subj_name = self.interner.resolve(subject);
            format!("{} can {} the {}", subj_name, pred_name, obj_name)
        } else {
            let pred_name = self.interner.resolve(predicate);
            let subj_name = self.interner.resolve(subject);
            format!("{} is {}", subj_name, pred_name)
        };

        Ok(Stmt::Check {
            subject,
            predicate,
            is_capability,
            object,
            source_text,
            span: start_span,
        })
    }

    /// Phase 51: Parse Listen statement - bind to network address
    /// Syntax: Listen on [address].
    fn parse_listen_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Listen"

        // Expect "on" preposition
        if !self.check_preposition_is("on") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "on".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "on"

        // Parse address expression (string literal or variable)
        let address = self.parse_imperative_expr()?;

        Ok(Stmt::Listen { address })
    }

    /// Phase 51: Parse Connect statement - dial remote peer
    /// Syntax: Connect to [address].
    fn parse_connect_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Connect"

        // Expect "to" (can be TokenType::To or preposition)
        if !self.check(&TokenType::To) && !self.check_preposition_is("to") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "to".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "to"

        // Parse address expression
        let address = self.parse_imperative_expr()?;

        Ok(Stmt::ConnectTo { address })
    }

    /// Phase 51: Parse Sleep statement - pause execution
    /// Syntax: Sleep [milliseconds].
    fn parse_sleep_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Sleep"

        // Parse milliseconds expression (number or variable)
        let milliseconds = self.parse_imperative_expr()?;

        Ok(Stmt::Sleep { milliseconds })
    }

    /// Phase 52: Parse Sync statement - automatic CRDT replication
    /// Syntax: Sync [var] on [topic].
    fn parse_sync_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Sync"

        // Parse variable name (must be an identifier)
        // Phase 49: Also handle Verb and Ambiguous tokens (e.g., "state" can be verb or noun)
        let var = match &self.tokens[self.current].kind {
            TokenType::ProperName(sym) | TokenType::Noun(sym) | TokenType::Adjective(sym) => {
                let s = *sym;
                self.advance();
                s
            }
            TokenType::Verb { .. } | TokenType::Ambiguous { .. } => {
                let s = self.tokens[self.current].lexeme;
                self.advance();
                s
            }
            _ => {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: "variable name".to_string() },
                    span: self.current_span(),
                });
            }
        };

        // Expect "on" preposition
        if !self.check_preposition_is("on") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "on".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "on"

        // Parse topic expression (string literal or variable)
        let topic = self.parse_imperative_expr()?;

        Ok(Stmt::Sync { var, topic })
    }

    /// Phase 53: Parse Mount statement
    /// Syntax: Mount [var] at [path].
    /// Example: Mount counter at "data/counter.journal".
    fn parse_mount_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Mount"

        // Parse variable name (must be an identifier)
        // Phase 49: Also handle Verb and Ambiguous tokens
        let var = match &self.tokens[self.current].kind {
            TokenType::ProperName(sym) | TokenType::Noun(sym) | TokenType::Adjective(sym) => {
                let s = *sym;
                self.advance();
                s
            }
            TokenType::Verb { .. } | TokenType::Ambiguous { .. } => {
                let s = self.tokens[self.current].lexeme;
                self.advance();
                s
            }
            _ => {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: "variable name".to_string() },
                    span: self.current_span(),
                });
            }
        };

        // Expect "at" keyword (TokenType::At in imperative mode)
        if !self.check(&TokenType::At) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "at".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "at"

        // Parse path expression (string literal or variable)
        let path = self.parse_imperative_expr()?;

        Ok(Stmt::Mount { var, path })
    }

    // =========================================================================
    // Phase 54: Go-like Concurrency Parser Methods
    // =========================================================================

    /// Helper: Check if lookahead contains "into" (for Send...into pipe disambiguation)
    fn lookahead_contains_into(&self) -> bool {
        for i in self.current..std::cmp::min(self.current + 5, self.tokens.len()) {
            if matches!(self.tokens[i].kind, TokenType::Into) {
                return true;
            }
        }
        false
    }

    /// Helper: Check if lookahead is "the first of" (for Await select disambiguation)
    fn lookahead_is_first_of(&self) -> bool {
        // Check for "Await the first of:"
        self.current + 3 < self.tokens.len()
            && matches!(self.tokens.get(self.current + 1), Some(t) if matches!(t.kind, TokenType::Article(_)))
            && self.tokens.get(self.current + 2)
                .map(|t| self.interner.resolve(t.lexeme).to_lowercase() == "first")
                .unwrap_or(false)
    }

    /// Phase 54: Parse Launch statement - spawn a task
    /// Syntax: Launch a task to verb(args).
    fn parse_launch_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Launch"

        // Expect "a"
        if !self.check_article() {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "a".to_string() },
                span: self.current_span(),
            });
        }
        self.advance();

        // Expect "task"
        if !self.check(&TokenType::Task) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "task".to_string() },
                span: self.current_span(),
            });
        }
        self.advance();

        // Expect "to"
        if !self.check(&TokenType::To) && !self.check_preposition_is("to") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "to".to_string() },
                span: self.current_span(),
            });
        }
        self.advance();

        // Parse function name
        // Phase 49: Also handle Verb and Ambiguous tokens (e.g., "greet" can be a verb)
        let function = match &self.tokens[self.current].kind {
            TokenType::ProperName(sym) | TokenType::Noun(sym) | TokenType::Adjective(sym) => {
                let s = *sym;
                self.advance();
                s
            }
            TokenType::Verb { .. } | TokenType::Ambiguous { .. } => {
                let s = self.tokens[self.current].lexeme;
                self.advance();
                s
            }
            _ => {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: "function name".to_string() },
                    span: self.current_span(),
                });
            }
        };

        // Optional arguments in parentheses or with "with" keyword
        let args = if self.check(&TokenType::LParen) {
            self.parse_call_arguments()?
        } else if self.check_word("with") {
            self.advance(); // consume "with"
            let mut args = Vec::new();
            let arg = self.parse_imperative_expr()?;
            args.push(arg);
            // Handle additional args separated by "and"
            while self.check(&TokenType::And) {
                self.advance();
                let arg = self.parse_imperative_expr()?;
                args.push(arg);
            }
            args
        } else {
            Vec::new()
        };

        Ok(Stmt::LaunchTask { function, args })
    }

    /// Phase 54: Parse Send into pipe statement
    /// Syntax: Send value into pipe.
    fn parse_send_pipe_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Send"

        // Parse value expression
        let value = self.parse_imperative_expr()?;

        // Expect "into"
        if !self.check(&TokenType::Into) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "into".to_string() },
                span: self.current_span(),
            });
        }
        self.advance();

        // Parse pipe expression
        let pipe = self.parse_imperative_expr()?;

        Ok(Stmt::SendPipe { value, pipe })
    }

    /// Phase 54: Parse Receive from pipe statement
    /// Syntax: Receive x from pipe.
    fn parse_receive_pipe_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Receive"

        // Get variable name - use expect_identifier which handles various token types
        let var = self.expect_identifier()?;

        // Expect "from"
        if !self.check(&TokenType::From) && !self.check_preposition_is("from") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "from".to_string() },
                span: self.current_span(),
            });
        }
        self.advance();

        // Parse pipe expression
        let pipe = self.parse_imperative_expr()?;

        Ok(Stmt::ReceivePipe { var, pipe })
    }

    /// Phase 54: Parse Try statement (non-blocking send/receive)
    /// Syntax: Try to send x into pipe. OR Try to receive x from pipe.
    fn parse_try_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Try"

        // Expect "to"
        if !self.check(&TokenType::To) && !self.check_preposition_is("to") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "to".to_string() },
                span: self.current_span(),
            });
        }
        self.advance();

        // Check if send or receive
        if self.check(&TokenType::Send) {
            self.advance(); // consume "Send"
            let value = self.parse_imperative_expr()?;

            if !self.check(&TokenType::Into) {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: "into".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance();

            let pipe = self.parse_imperative_expr()?;
            Ok(Stmt::TrySendPipe { value, pipe, result: None })
        } else if self.check(&TokenType::Receive) {
            self.advance(); // consume "Receive"

            let var = self.expect_identifier()?;

            if !self.check(&TokenType::From) && !self.check_preposition_is("from") {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: "from".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance();

            let pipe = self.parse_imperative_expr()?;
            Ok(Stmt::TryReceivePipe { var, pipe })
        } else {
            Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "send or receive".to_string() },
                span: self.current_span(),
            })
        }
    }

    /// Phase 54: Parse Stop statement
    /// Syntax: Stop handle.
    fn parse_stop_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Stop"

        let handle = self.parse_imperative_expr()?;

        Ok(Stmt::StopTask { handle })
    }

    /// Phase 54: Parse Select statement
    /// Syntax:
    /// Await the first of:
    ///     Receive x from pipe:
    ///         ...
    ///     After N seconds:
    ///         ...
    fn parse_select_statement(&mut self) -> ParseResult<Stmt<'a>> {
        use crate::ast::stmt::SelectBranch;

        self.advance(); // consume "Await"

        // Expect "the"
        if !self.check_article() {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "the".to_string() },
                span: self.current_span(),
            });
        }
        self.advance();

        // Expect "first"
        if !self.check_word("first") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "first".to_string() },
                span: self.current_span(),
            });
        }
        self.advance();

        // Expect "of"
        if !self.check_preposition_is("of") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "of".to_string() },
                span: self.current_span(),
            });
        }
        self.advance();

        // Expect colon
        if !self.check(&TokenType::Colon) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                span: self.current_span(),
            });
        }
        self.advance();

        // Expect indent
        if !self.check(&TokenType::Indent) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedStatement,
                span: self.current_span(),
            });
        }
        self.advance();

        // Parse branches
        let mut branches = Vec::new();
        while !self.check(&TokenType::Dedent) && !self.is_at_end() {
            let branch = self.parse_select_branch()?;
            branches.push(branch);
        }

        // Consume dedent
        if self.check(&TokenType::Dedent) {
            self.advance();
        }

        Ok(Stmt::Select { branches })
    }

    /// Phase 54: Parse a single select branch
    fn parse_select_branch(&mut self) -> ParseResult<crate::ast::stmt::SelectBranch<'a>> {
        use crate::ast::stmt::SelectBranch;

        if self.check(&TokenType::Receive) {
            self.advance(); // consume "Receive"

            let var = match &self.tokens[self.current].kind {
                TokenType::ProperName(sym) | TokenType::Noun(sym) | TokenType::Adjective(sym) => {
                    let s = *sym;
                    self.advance();
                    s
                }
                _ => {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedKeyword { keyword: "variable name".to_string() },
                        span: self.current_span(),
                    });
                }
            };

            if !self.check(&TokenType::From) && !self.check_preposition_is("from") {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: "from".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance();

            let pipe = self.parse_imperative_expr()?;

            // Expect colon
            if !self.check(&TokenType::Colon) {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance();

            // Parse body
            let body = self.parse_indented_block()?;

            Ok(SelectBranch::Receive { var, pipe, body })
        } else if self.check_word("after") {
            self.advance(); // consume "After"

            let milliseconds = self.parse_imperative_expr()?;

            // Skip "seconds" or "milliseconds" if present
            if self.check_word("seconds") || self.check_word("milliseconds") {
                self.advance();
            }

            // Expect colon
            if !self.check(&TokenType::Colon) {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance();

            // Parse body
            let body = self.parse_indented_block()?;

            Ok(SelectBranch::Timeout { milliseconds, body })
        } else {
            Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "Receive or After".to_string() },
                span: self.current_span(),
            })
        }
    }

    /// Phase 54: Parse an indented block of statements
    fn parse_indented_block(&mut self) -> ParseResult<crate::ast::stmt::Block<'a>> {
        // Expect indent
        if !self.check(&TokenType::Indent) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedStatement,
                span: self.current_span(),
            });
        }
        self.advance();

        let mut stmts = Vec::new();
        while !self.check(&TokenType::Dedent) && !self.is_at_end() {
            let stmt = self.parse_statement()?;
            stmts.push(stmt);
            if self.check(&TokenType::Period) {
                self.advance();
            }
        }

        // Consume dedent
        if self.check(&TokenType::Dedent) {
            self.advance();
        }

        let block = self.ctx.stmts.expect("imperative arenas not initialized")
            .alloc_slice(stmts.into_iter());

        Ok(block)
    }

    fn parse_give_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Give"

        // Parse the object being given: "x" or "the data"
        let object = self.parse_imperative_expr()?;

        // Expect "to" preposition
        if !self.check_preposition_is("to") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "to".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "to"

        // Parse the recipient: "processor" or "the console"
        let recipient = self.parse_imperative_expr()?;

        // Mark variable as Moved after Give
        if let Expr::Identifier(sym) = object {
            self.world_state.set_ownership_by_var(*sym, crate::drs::OwnershipState::Moved);
        }

        Ok(Stmt::Give { object, recipient })
    }

    fn parse_show_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Show"

        // Parse the object being shown - use parse_condition to support
        // comparisons (x is less than y) and boolean operators (a and b)
        let object = self.parse_condition()?;

        // Optional "to" preposition - if not present, default to "show" function
        let recipient = if self.check_preposition_is("to") {
            self.advance(); // consume "to"

            // Phase 10: "Show x to console." or "Show x to the console."
            // is idiomatic for printing to stdout - use default show function
            if self.check_article() {
                self.advance(); // skip "the"
            }
            if self.check(&TokenType::Console) {
                self.advance(); // consume "console"
                let show_sym = self.interner.intern("show");
                self.ctx.alloc_imperative_expr(Expr::Identifier(show_sym))
            } else {
                // Parse the recipient: custom function
                self.parse_imperative_expr()?
            }
        } else {
            // Default recipient: the runtime "show" function
            let show_sym = self.interner.intern("show");
            self.ctx.alloc_imperative_expr(Expr::Identifier(show_sym))
        };

        // Mark variable as Borrowed after Show
        if let Expr::Identifier(sym) = object {
            self.world_state.set_ownership_by_var(*sym, crate::drs::OwnershipState::Borrowed);
        }

        Ok(Stmt::Show { object, recipient })
    }

    /// Phase 43D: Parse Push statement for collection operations
    /// Syntax: Push x to items.
    fn parse_push_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Push"

        // Parse the value being pushed
        let value = self.parse_imperative_expr()?;

        // Expect "to" (can be keyword or preposition)
        if !self.check(&TokenType::To) && !self.check_preposition_is("to") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "to".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "to"

        // Parse the collection
        let collection = self.parse_imperative_expr()?;

        Ok(Stmt::Push { value, collection })
    }

    /// Phase 43D: Parse Pop statement for collection operations
    /// Syntax: Pop from items. OR Pop from items into y.
    fn parse_pop_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Pop"

        // Expect "from" - can be keyword token or preposition
        if !self.check(&TokenType::From) && !self.check_preposition_is("from") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "from".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "from"

        // Parse the collection
        let collection = self.parse_imperative_expr()?;

        // Check for optional "into" binding (can be Into keyword or preposition)
        let into = if self.check(&TokenType::Into) || self.check_preposition_is("into") {
            self.advance(); // consume "into"

            // Parse variable name
            if let TokenType::Noun(sym) | TokenType::ProperName(sym) = &self.peek().kind {
                let sym = *sym;
                self.advance();
                Some(sym)
            } else if let Some(token) = self.tokens.get(self.current) {
                // Also handle identifier-like tokens
                let sym = token.lexeme;
                self.advance();
                Some(sym)
            } else {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedIdentifier,
                    span: self.current_span(),
                });
            }
        } else {
            None
        };

        Ok(Stmt::Pop { collection, into })
    }

    /// Parse Add statement for Set insertion
    /// Syntax: Add x to set.
    fn parse_add_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Add"

        // Parse the value to add
        let value = self.parse_imperative_expr()?;

        // Expect "to" preposition
        if !self.check_preposition_is("to") && !self.check(&TokenType::To) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "to".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "to"

        // Parse the collection expression
        let collection = self.parse_imperative_expr()?;

        Ok(Stmt::Add { value, collection })
    }

    /// Parse Remove statement for Set deletion
    /// Syntax: Remove x from set.
    fn parse_remove_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Remove"

        // Parse the value to remove
        let value = self.parse_imperative_expr()?;

        // Expect "from" preposition
        if !self.check(&TokenType::From) && !self.check_preposition_is("from") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "from".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "from"

        // Parse the collection expression
        let collection = self.parse_imperative_expr()?;

        Ok(Stmt::Remove { value, collection })
    }

    /// Phase 10: Parse Read statement for console/file input
    /// Syntax: Read <var> from the console.
    ///         Read <var> from file <path>.
    fn parse_read_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Read"

        // Get the variable name
        let var = self.expect_identifier()?;

        // Expect "from" preposition
        if !self.check(&TokenType::From) && !self.check_preposition_is("from") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "from".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "from"

        // Skip optional article "the"
        if self.check_article() {
            self.advance();
        }

        // Determine source: console or file
        let source = if self.check(&TokenType::Console) {
            self.advance(); // consume "console"
            ReadSource::Console
        } else if self.check(&TokenType::File) {
            self.advance(); // consume "file"
            let path = self.parse_imperative_expr()?;
            ReadSource::File(path)
        } else {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "console or file".to_string() },
                span: self.current_span(),
            });
        };

        Ok(Stmt::ReadFrom { var, source })
    }

    /// Phase 10: Parse Write statement for file output
    /// Syntax: Write <content> to file <path>.
    fn parse_write_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Write"

        // Parse the content expression
        let content = self.parse_imperative_expr()?;

        // Expect "to" (can be keyword or preposition)
        if !self.check(&TokenType::To) && !self.check_preposition_is("to") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "to".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "to"

        // Expect "file" keyword
        if !self.check(&TokenType::File) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "file".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "file"

        // Parse the path expression
        let path = self.parse_imperative_expr()?;

        Ok(Stmt::WriteFile { content, path })
    }

    /// Phase 8.5: Parse Zone statement for memory arena blocks
    /// Syntax variants:
    ///   - Inside a new zone called "Scratch":
    ///   - Inside a zone called "Buffer" of size 1 MB:
    ///   - Inside a zone called "Data" mapped from "file.bin":
    fn parse_zone_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Inside"

        // Optional article "a"
        if self.check_article() {
            self.advance();
        }

        // Optional "new"
        if self.check(&TokenType::New) {
            self.advance();
        }

        // Expect "zone"
        if !self.check(&TokenType::Zone) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "zone".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "zone"

        // Expect "called"
        if !self.check(&TokenType::Called) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "called".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "called"

        // Parse zone name (can be string literal or identifier)
        let name = match &self.peek().kind {
            TokenType::StringLiteral(sym) => {
                let s = *sym;
                self.advance();
                s
            }
            TokenType::ProperName(sym) | TokenType::Noun(sym) | TokenType::Adjective(sym) => {
                let s = *sym;
                self.advance();
                s
            }
            _ => {
                // Try to use the lexeme directly as an identifier
                let token = self.peek().clone();
                self.advance();
                token.lexeme
            }
        };

        let mut capacity = None;
        let mut source_file = None;

        // Check for "mapped from" (file-backed zone)
        if self.check(&TokenType::Mapped) {
            self.advance(); // consume "mapped"

            // Expect "from"
            if !self.check(&TokenType::From) && !self.check_preposition_is("from") {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: "from".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance(); // consume "from"

            // Parse file path (must be string literal)
            if let TokenType::StringLiteral(path) = &self.peek().kind {
                source_file = Some(*path);
                self.advance();
            } else {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: "file path string".to_string() },
                    span: self.current_span(),
                });
            }
        }
        // Check for "of size N Unit" (sized heap zone)
        else if self.check_of_preposition() {
            self.advance(); // consume "of"

            // Expect "size"
            if !self.check(&TokenType::Size) {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: "size".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance(); // consume "size"

            // Parse size number
            let size_value = match &self.peek().kind {
                TokenType::Number(sym) => {
                    let num_str = self.interner.resolve(*sym);
                    let val = num_str.replace('_', "").parse::<usize>().unwrap_or(0);
                    self.advance();
                    val
                }
                TokenType::Cardinal(n) => {
                    let val = *n as usize;
                    self.advance();
                    val
                }
                _ => {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedNumber,
                        span: self.current_span(),
                    });
                }
            };

            // Parse unit (KB, MB, GB, or B)
            let unit_multiplier = self.parse_size_unit()?;
            capacity = Some(size_value * unit_multiplier);
        }

        // Expect colon
        if !self.check(&TokenType::Colon) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume ":"

        // Expect indent
        if !self.check(&TokenType::Indent) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedStatement,
                span: self.current_span(),
            });
        }
        self.advance(); // consume Indent

        // Parse body statements
        let mut body_stmts = Vec::new();
        while !self.check(&TokenType::Dedent) && !self.is_at_end() {
            let stmt = self.parse_statement()?;
            body_stmts.push(stmt);
            if self.check(&TokenType::Period) {
                self.advance();
            }
        }

        // Consume dedent
        if self.check(&TokenType::Dedent) {
            self.advance();
        }

        let body = self.ctx.stmts.expect("imperative arenas not initialized")
            .alloc_slice(body_stmts.into_iter());

        Ok(Stmt::Zone { name, capacity, source_file, body })
    }

    /// Parse size unit (B, KB, MB, GB) and return multiplier
    fn parse_size_unit(&mut self) -> ParseResult<usize> {
        let token = self.peek().clone();
        let unit_str = self.interner.resolve(token.lexeme).to_uppercase();
        self.advance();

        match unit_str.as_str() {
            "B" | "BYTES" | "BYTE" => Ok(1),
            "KB" | "KILOBYTE" | "KILOBYTES" => Ok(1024),
            "MB" | "MEGABYTE" | "MEGABYTES" => Ok(1024 * 1024),
            "GB" | "GIGABYTE" | "GIGABYTES" => Ok(1024 * 1024 * 1024),
            _ => Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword {
                    keyword: "size unit (B, KB, MB, GB)".to_string(),
                },
                span: token.span,
            }),
        }
    }

    /// Phase 9: Parse concurrent execution block (async, I/O-bound)
    ///
    /// Syntax:
    /// ```logos
    /// Attempt all of the following:
    ///     Call fetch_user with id.
    ///     Call fetch_orders with id.
    /// ```
    fn parse_concurrent_block(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Attempt"

        // Expect "all"
        if !self.check(&TokenType::All) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "all".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "all"

        // Expect "of" (preposition)
        if !self.check_of_preposition() {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "of".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "of"

        // Expect "the"
        if !self.check_article() {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "the".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "the"

        // Expect "following"
        if !self.check(&TokenType::Following) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "following".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "following"

        // Expect colon
        if !self.check(&TokenType::Colon) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume ":"

        // Expect indent
        if !self.check(&TokenType::Indent) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedStatement,
                span: self.current_span(),
            });
        }
        self.advance(); // consume Indent

        // Parse body statements
        let mut task_stmts = Vec::new();
        while !self.check(&TokenType::Dedent) && !self.is_at_end() {
            let stmt = self.parse_statement()?;
            task_stmts.push(stmt);
            if self.check(&TokenType::Period) {
                self.advance();
            }
        }

        // Consume dedent
        if self.check(&TokenType::Dedent) {
            self.advance();
        }

        let tasks = self.ctx.stmts.expect("imperative arenas not initialized")
            .alloc_slice(task_stmts.into_iter());

        Ok(Stmt::Concurrent { tasks })
    }

    /// Phase 9: Parse parallel execution block (CPU-bound)
    ///
    /// Syntax:
    /// ```logos
    /// Simultaneously:
    ///     Call compute_hash with data1.
    ///     Call compute_hash with data2.
    /// ```
    fn parse_parallel_block(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Simultaneously"

        // Expect colon
        if !self.check(&TokenType::Colon) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume ":"

        // Expect indent
        if !self.check(&TokenType::Indent) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedStatement,
                span: self.current_span(),
            });
        }
        self.advance(); // consume Indent

        // Parse body statements
        let mut task_stmts = Vec::new();
        while !self.check(&TokenType::Dedent) && !self.is_at_end() {
            let stmt = self.parse_statement()?;
            task_stmts.push(stmt);
            if self.check(&TokenType::Period) {
                self.advance();
            }
        }

        // Consume dedent
        if self.check(&TokenType::Dedent) {
            self.advance();
        }

        let tasks = self.ctx.stmts.expect("imperative arenas not initialized")
            .alloc_slice(task_stmts.into_iter());

        Ok(Stmt::Parallel { tasks })
    }

    /// Phase 33: Parse Inspect statement for pattern matching
    /// Syntax: Inspect target:
    ///             If it is a Variant [(bindings)]:
    ///                 body...
    ///             Otherwise:
    ///                 body...
    fn parse_inspect_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Inspect"

        // Parse target expression
        let target = self.parse_imperative_expr()?;

        // Expect colon
        if !self.check(&TokenType::Colon) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume ":"

        // Expect indent
        if !self.check(&TokenType::Indent) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedStatement,
                span: self.current_span(),
            });
        }
        self.advance(); // consume Indent

        let mut arms = Vec::new();
        let mut has_otherwise = false;

        // Parse match arms until dedent
        while !self.check(&TokenType::Dedent) && !self.is_at_end() {
            if self.check(&TokenType::Otherwise) {
                // Parse "Otherwise:" default arm
                self.advance(); // consume "Otherwise"

                if !self.check(&TokenType::Colon) {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                        span: self.current_span(),
                    });
                }
                self.advance(); // consume ":"

                // Handle both inline (Otherwise: stmt.) and block body
                let body_stmts = if self.check(&TokenType::Indent) {
                    self.advance(); // consume Indent
                    let mut stmts = Vec::new();
                    while !self.check(&TokenType::Dedent) && !self.is_at_end() {
                        let stmt = self.parse_statement()?;
                        stmts.push(stmt);
                        if self.check(&TokenType::Period) {
                            self.advance();
                        }
                    }
                    if self.check(&TokenType::Dedent) {
                        self.advance();
                    }
                    stmts
                } else {
                    // Inline body: "Otherwise: Show x."
                    let stmt = self.parse_statement()?;
                    if self.check(&TokenType::Period) {
                        self.advance();
                    }
                    vec![stmt]
                };

                let body = self.ctx.stmts.expect("imperative arenas not initialized")
                    .alloc_slice(body_stmts.into_iter());

                arms.push(MatchArm { enum_name: None, variant: None, bindings: vec![], body });
                has_otherwise = true;
                break;
            }

            if self.check(&TokenType::If) {
                // Parse "If it is a VariantName [(bindings)]:"
                let arm = self.parse_match_arm()?;
                arms.push(arm);
            } else if self.check(&TokenType::When) || self.check_word("When") {
                // Parse "When Variant [(bindings)]:" (concise syntax)
                let arm = self.parse_when_arm()?;
                arms.push(arm);
            } else if self.check(&TokenType::Newline) {
                // Skip newlines between arms
                self.advance();
            } else {
                // Skip unexpected tokens
                self.advance();
            }
        }

        // Consume final dedent
        if self.check(&TokenType::Dedent) {
            self.advance();
        }

        Ok(Stmt::Inspect { target, arms, has_otherwise })
    }

    /// Parse a single match arm: "If it is a Variant [(field: binding)]:"
    fn parse_match_arm(&mut self) -> ParseResult<MatchArm<'a>> {
        self.advance(); // consume "If"

        // Expect "it"
        if !self.check_word("it") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "it".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "it"

        // Expect "is"
        if !self.check(&TokenType::Is) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "is".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "is"

        // Consume article "a" or "an"
        if self.check_article() {
            self.advance();
        }

        // Get variant name
        let variant = self.expect_identifier()?;

        // Look up the enum name for this variant
        let enum_name = self.find_variant(variant);

        // Optional: "(field)" or "(field: binding)" or "(f1, f2: b2)"
        let bindings = if self.check(&TokenType::LParen) {
            self.parse_pattern_bindings()?
        } else {
            vec![]
        };

        // Expect colon
        if !self.check(&TokenType::Colon) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume ":"

        // Expect indent
        if !self.check(&TokenType::Indent) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedStatement,
                span: self.current_span(),
            });
        }
        self.advance(); // consume Indent

        // Parse body statements
        let mut body_stmts = Vec::new();
        while !self.check(&TokenType::Dedent) && !self.is_at_end() {
            let stmt = self.parse_statement()?;
            body_stmts.push(stmt);
            if self.check(&TokenType::Period) {
                self.advance();
            }
        }

        // Consume dedent
        if self.check(&TokenType::Dedent) {
            self.advance();
        }

        let body = self.ctx.stmts.expect("imperative arenas not initialized")
            .alloc_slice(body_stmts.into_iter());

        Ok(MatchArm { enum_name, variant: Some(variant), bindings, body })
    }

    /// Parse a concise match arm: "When Variant [(bindings)]:" or "When Variant: stmt."
    fn parse_when_arm(&mut self) -> ParseResult<MatchArm<'a>> {
        self.advance(); // consume "When"

        // Get variant name
        let variant = self.expect_identifier()?;

        // Look up the enum name and variant definition for this variant
        let (enum_name, variant_fields) = self.type_registry
            .as_ref()
            .and_then(|r| r.find_variant(variant).map(|(enum_name, vdef)| {
                let fields: Vec<_> = vdef.fields.iter().map(|f| f.name).collect();
                (Some(enum_name), fields)
            }))
            .unwrap_or((None, vec![]));

        // Optional: "(binding)" or "(b1, b2)" - positional bindings
        let bindings = if self.check(&TokenType::LParen) {
            let raw_bindings = self.parse_when_bindings()?;
            // Map positional bindings to actual field names
            raw_bindings.into_iter().enumerate().map(|(i, binding)| {
                let field = variant_fields.get(i).copied().unwrap_or(binding);
                (field, binding)
            }).collect()
        } else {
            vec![]
        };

        // Expect colon
        if !self.check(&TokenType::Colon) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume ":"

        // Handle both inline body (When Variant: stmt.) and block body
        let body_stmts = if self.check(&TokenType::Indent) {
            self.advance(); // consume Indent
            let mut stmts = Vec::new();
            while !self.check(&TokenType::Dedent) && !self.is_at_end() {
                let stmt = self.parse_statement()?;
                stmts.push(stmt);
                if self.check(&TokenType::Period) {
                    self.advance();
                }
            }
            if self.check(&TokenType::Dedent) {
                self.advance();
            }
            stmts
        } else {
            // Inline body: "When Red: Show x."
            let stmt = self.parse_statement()?;
            if self.check(&TokenType::Period) {
                self.advance();
            }
            vec![stmt]
        };

        let body = self.ctx.stmts.expect("imperative arenas not initialized")
            .alloc_slice(body_stmts.into_iter());

        Ok(MatchArm { enum_name, variant: Some(variant), bindings, body })
    }

    /// Parse concise When bindings: "(r)" or "(w, h)" - just binding variable names
    fn parse_when_bindings(&mut self) -> ParseResult<Vec<Symbol>> {
        self.advance(); // consume '('
        let mut bindings = Vec::new();

        loop {
            let binding = self.expect_identifier()?;
            bindings.push(binding);

            if !self.check(&TokenType::Comma) {
                break;
            }
            self.advance(); // consume ','
        }

        if !self.check(&TokenType::RParen) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ")".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume ')'

        Ok(bindings)
    }

    /// Parse pattern bindings: "(field)" or "(field: binding)" or "(f1, f2: b2)"
    fn parse_pattern_bindings(&mut self) -> ParseResult<Vec<(Symbol, Symbol)>> {
        self.advance(); // consume '('
        let mut bindings = Vec::new();

        loop {
            let field = self.expect_identifier()?;
            let binding = if self.check(&TokenType::Colon) {
                self.advance(); // consume ":"
                self.expect_identifier()?
            } else {
                field // field name = binding name
            };
            bindings.push((field, binding));

            if !self.check(&TokenType::Comma) {
                break;
            }
            self.advance(); // consume ','
        }

        if !self.check(&TokenType::RParen) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ")".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume ')'

        Ok(bindings)
    }

    /// Parse constructor fields: "with field1 value1 [and field2 value2]..."
    /// Example: "with radius 10" or "with x 10 and y 20"
    /// Used for both variant constructors and struct initialization
    fn parse_constructor_fields(&mut self) -> ParseResult<Vec<(Symbol, &'a Expr<'a>)>> {
        use crate::ast::Expr;
        let mut fields = Vec::new();

        // Consume "with"
        self.advance();

        loop {
            // Parse field name
            let field_name = self.expect_identifier()?;

            // Parse field value expression
            let value = self.parse_imperative_expr()?;

            fields.push((field_name, value));

            // Check for "and" to continue
            if self.check(&TokenType::And) {
                self.advance(); // consume "and"
                continue;
            }
            break;
        }

        Ok(fields)
    }

    /// Alias for variant constructors (backwards compat)
    fn parse_variant_constructor_fields(&mut self) -> ParseResult<Vec<(Symbol, &'a Expr<'a>)>> {
        self.parse_constructor_fields()
    }

    /// Alias for struct initialization
    fn parse_struct_init_fields(&mut self) -> ParseResult<Vec<(Symbol, &'a Expr<'a>)>> {
        self.parse_constructor_fields()
    }

    /// Phase 34: Parse generic type arguments for constructor instantiation
    /// Parses "of Int" or "of Int and Text" after a generic type name
    /// Returns empty Vec for non-generic types
    fn parse_generic_type_args(&mut self, type_name: Symbol) -> ParseResult<Vec<Symbol>> {
        // Only parse type args if the type is a known generic
        if !self.is_generic_type(type_name) {
            return Ok(vec![]);
        }

        // Expect "of" preposition
        if !self.check_preposition_is("of") {
            return Ok(vec![]);  // Generic type without arguments - will use defaults
        }
        self.advance(); // consume "of"

        let mut type_args = Vec::new();
        loop {
            // Parse type argument (e.g., "Int", "Text", "User")
            let type_arg = self.expect_identifier()?;
            type_args.push(type_arg);

            // Check for "and" or "to" to continue (for multi-param generics like "Map of Text to Int")
            if self.check(&TokenType::And) || self.check_to_preposition() {
                self.advance(); // consume separator
                continue;
            }
            break;
        }

        Ok(type_args)
    }

    /// Skip type definition content until next block header
    /// Used for TypeDef blocks (## A Point has:, ## A Color is one of:)
    /// The actual parsing is done by DiscoveryPass
    fn skip_type_def_content(&mut self) {
        while !self.is_at_end() {
            // Stop at next block header
            if matches!(
                self.tokens.get(self.current),
                Some(Token { kind: TokenType::BlockHeader { .. }, .. })
            ) {
                break;
            }
            self.advance();
        }
    }

    /// Phase 32: Parse function definition after `## To` header
    /// Phase 32/38: Parse function definition
    /// Syntax: [To] [native] name (a: Type) [and (b: Type)] [-> ReturnType]
    ///         body statements... (only if not native)
    fn parse_function_def(&mut self) -> ParseResult<Stmt<'a>> {
        // Consume "To" if present (when called from parse_statement)
        if self.check(&TokenType::To) || self.check_preposition_is("to") {
            self.advance();
        }

        // Phase 38: Check for native modifier
        let is_native = if self.check(&TokenType::Native) {
            self.advance(); // consume "native"
            true
        } else {
            false
        };

        // Parse function name (first identifier after ## To [native])
        let name = self.expect_identifier()?;

        // Parse parameters: (name: Type) groups separated by "and", or comma-separated in one group
        let mut params = Vec::new();
        while self.check(&TokenType::LParen) {
            self.advance(); // consume (

            // Parse parameters in this group (possibly comma-separated)
            loop {
                let param_name = self.expect_identifier()?;

                // Expect colon
                if !self.check(&TokenType::Colon) {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                        span: self.current_span(),
                    });
                }
                self.advance(); // consume :

                // Phase 38: Parse full type expression instead of simple identifier
                let param_type_expr = self.parse_type_expression()?;
                let param_type = self.ctx.alloc_type_expr(param_type_expr);

                params.push((param_name, param_type));

                // Check for comma (more params in this group) or ) (end of group)
                if self.check(&TokenType::Comma) {
                    self.advance(); // consume ,
                    continue;
                }
                break;
            }

            // Expect )
            if !self.check(&TokenType::RParen) {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: ")".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance(); // consume )

            // Check for "and", preposition, or "from" between parameter groups
            // Allows: "## To withdraw (amount: Int) from (balance: Int)"
            if self.check_word("and") || self.check_preposition() || self.check(&TokenType::From) {
                self.advance();
            }
        }

        // Phase 38: Parse optional return type -> Type
        let return_type = if self.check(&TokenType::Arrow) {
            self.advance(); // consume ->
            let ret_type_expr = self.parse_type_expression()?;
            Some(self.ctx.alloc_type_expr(ret_type_expr))
        } else {
            None
        };

        // Phase 38: Native functions have no body
        if is_native {
            // Consume trailing period or newline if present
            if self.check(&TokenType::Period) {
                self.advance();
            }
            if self.check(&TokenType::Newline) {
                self.advance();
            }

            // Return with empty body
            let empty_body = self.ctx.stmts.expect("imperative arenas not initialized")
                .alloc_slice(std::iter::empty());

            return Ok(Stmt::FunctionDef {
                name,
                params,
                body: empty_body,
                return_type,
                is_native: true,
            });
        }

        // Non-native: expect colon after parameter list / return type
        if !self.check(&TokenType::Colon) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume :

        // Expect indent for function body
        if !self.check(&TokenType::Indent) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedStatement,
                span: self.current_span(),
            });
        }
        self.advance(); // consume Indent

        // Parse body statements
        let mut body_stmts = Vec::new();
        while !self.check(&TokenType::Dedent) && !self.is_at_end() {
            // Skip newlines between statements
            if self.check(&TokenType::Newline) {
                self.advance();
                continue;
            }
            // Stop if we hit another block header
            if matches!(self.peek().kind, TokenType::BlockHeader { .. }) {
                break;
            }
            let stmt = self.parse_statement()?;
            body_stmts.push(stmt);
            if self.check(&TokenType::Period) {
                self.advance();
            }
        }

        // Consume dedent if present
        if self.check(&TokenType::Dedent) {
            self.advance();
        }

        // Allocate body in arena
        let body = self.ctx.stmts.expect("imperative arenas not initialized")
            .alloc_slice(body_stmts.into_iter());

        Ok(Stmt::FunctionDef {
            name,
            params,
            body,
            return_type,
            is_native: false,
        })
    }

    /// Parse a primary expression (literal, identifier, index, slice, list, etc.)
    fn parse_primary_expr(&mut self) -> ParseResult<&'a Expr<'a>> {
        use crate::ast::{Expr, Literal};

        let token = self.peek().clone();
        match &token.kind {
            // Phase 31: Constructor expression "new TypeName" or "a new TypeName"
            // Phase 33: Extended for variant constructors "new Circle with radius 10"
            // Phase 34: Extended for generic instantiation "new Box of Int"
            TokenType::New => {
                self.advance(); // consume "new"
                let base_type_name = self.expect_identifier()?;

                // Phase 36: Check for "from Module" qualification
                let type_name = if self.check(&TokenType::From) {
                    self.advance(); // consume "from"
                    let module_name = self.expect_identifier()?;
                    let module_str = self.interner.resolve(module_name);
                    let base_str = self.interner.resolve(base_type_name);
                    let qualified = format!("{}::{}", module_str, base_str);
                    self.interner.intern(&qualified)
                } else {
                    base_type_name
                };

                // Phase 33: Check if this is a variant constructor
                if let Some(enum_name) = self.find_variant(type_name) {
                    // Parse optional "with field value" pairs
                    let fields = if self.check_word("with") {
                        self.parse_variant_constructor_fields()?
                    } else {
                        vec![]
                    };
                    let base = self.ctx.alloc_imperative_expr(Expr::NewVariant {
                        enum_name,
                        variant: type_name,
                        fields,
                    });
                    return self.parse_field_access_chain(base);
                }

                // Phase 34: Parse generic type arguments "of Int" or "of Int and Text"
                let type_args = self.parse_generic_type_args(type_name)?;

                // Parse optional "with field value" pairs for struct initialization
                let init_fields = if self.check_word("with") {
                    self.parse_struct_init_fields()?
                } else {
                    vec![]
                };

                let base = self.ctx.alloc_imperative_expr(Expr::New { type_name, type_args, init_fields });
                return self.parse_field_access_chain(base);
            }

            // Phase 31: Handle "a new TypeName" pattern OR single-letter identifier
            // Phase 33: Extended for variant constructors "a new Circle with radius 10"
            // Phase 34: Extended for generic instantiation "a new Box of Int"
            TokenType::Article(_) => {
                // Phase 48: Check if followed by Manifest or Chunk token
                // Pattern: "the manifest of Zone" or "the chunk at N in Zone"
                if let Some(next) = self.tokens.get(self.current + 1) {
                    if matches!(next.kind, TokenType::Manifest) {
                        self.advance(); // consume "the"
                        // Delegate to Manifest handling
                        return self.parse_primary_expr();
                    }
                    if matches!(next.kind, TokenType::Chunk) {
                        self.advance(); // consume "the"
                        // Delegate to Chunk handling
                        return self.parse_primary_expr();
                    }
                }
                // Check if followed by New token
                if let Some(next) = self.tokens.get(self.current + 1) {
                    if matches!(next.kind, TokenType::New) {
                        self.advance(); // consume article "a"/"an"
                        self.advance(); // consume "new"
                        let base_type_name = self.expect_identifier()?;

                        // Phase 36: Check for "from Module" qualification
                        let type_name = if self.check(&TokenType::From) {
                            self.advance(); // consume "from"
                            let module_name = self.expect_identifier()?;
                            let module_str = self.interner.resolve(module_name);
                            let base_str = self.interner.resolve(base_type_name);
                            let qualified = format!("{}::{}", module_str, base_str);
                            self.interner.intern(&qualified)
                        } else {
                            base_type_name
                        };

                        // Phase 33: Check if this is a variant constructor
                        if let Some(enum_name) = self.find_variant(type_name) {
                            // Parse optional "with field value" pairs
                            let fields = if self.check_word("with") {
                                self.parse_variant_constructor_fields()?
                            } else {
                                vec![]
                            };
                            let base = self.ctx.alloc_imperative_expr(Expr::NewVariant {
                                enum_name,
                                variant: type_name,
                                fields,
                            });
                            return self.parse_field_access_chain(base);
                        }

                        // Phase 34: Parse generic type arguments "of Int" or "of Int and Text"
                        let type_args = self.parse_generic_type_args(type_name)?;

                        // Parse optional "with field value" pairs for struct initialization
                        let init_fields = if self.check_word("with") {
                            self.parse_struct_init_fields()?
                        } else {
                            vec![]
                        };

                        let base = self.ctx.alloc_imperative_expr(Expr::New { type_name, type_args, init_fields });
                        return self.parse_field_access_chain(base);
                    }
                }
                // Phase 32: Treat as identifier (single-letter var like "a", "b")
                let sym = token.lexeme;
                self.advance();
                let base = self.ctx.alloc_imperative_expr(Expr::Identifier(sym));
                return self.parse_field_access_chain(base);
            }

            // Index access: "item N of collection" or "item i of collection"
            TokenType::Item => {
                self.advance(); // consume "item"

                // Grand Challenge: Parse index as expression (number, identifier, or parenthesized)
                let index = if let TokenType::Number(sym) = &self.peek().kind {
                    // Literal number - check for zero index at compile time
                    let sym = *sym;
                    self.advance();
                    let num_str = self.interner.resolve(sym);
                    let index_val = num_str.parse::<i64>().unwrap_or(0);

                    // Index 0 Guard: LOGOS uses 1-based indexing
                    if index_val == 0 {
                        return Err(ParseError {
                            kind: ParseErrorKind::ZeroIndex,
                            span: self.current_span(),
                        });
                    }

                    self.ctx.alloc_imperative_expr(
                        Expr::Literal(crate::ast::Literal::Number(index_val))
                    )
                } else if self.check(&TokenType::LParen) {
                    // Parenthesized expression like (mid + 1)
                    self.advance(); // consume '('
                    let inner = self.parse_imperative_expr()?;
                    if !self.check(&TokenType::RParen) {
                        return Err(ParseError {
                            kind: ParseErrorKind::ExpectedKeyword { keyword: ")".to_string() },
                            span: self.current_span(),
                        });
                    }
                    self.advance(); // consume ')'
                    inner
                } else if let TokenType::StringLiteral(sym) = self.peek().kind {
                    // Phase 57B: String literal key for Map access like item "iron" of prices
                    let sym = sym;
                    self.advance();
                    self.ctx.alloc_imperative_expr(Expr::Literal(crate::ast::Literal::Text(sym)))
                } else if !self.check_preposition_is("of") {
                    // Variable identifier like i, j, idx (any token that's not "of")
                    let sym = self.peek().lexeme;
                    self.advance();
                    self.ctx.alloc_imperative_expr(Expr::Identifier(sym))
                } else {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedExpression,
                        span: self.current_span(),
                    });
                };

                // Expect "of"
                if !self.check_preposition_is("of") {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedKeyword { keyword: "of".to_string() },
                        span: self.current_span(),
                    });
                }
                self.advance(); // consume "of"

                // Parse collection as primary expression (identifier or field chain)
                // Using primary_expr instead of imperative_expr prevents consuming operators
                let collection = self.parse_primary_expr()?;

                Ok(self.ctx.alloc_imperative_expr(Expr::Index {
                    collection,
                    index,
                }))
            }

            // Slice access: "items N through M of collection"
            // OR variable named "items" - disambiguate by checking if next token starts an expression
            TokenType::Items => {
                // Peek ahead to determine if this is slice syntax or variable usage
                // Slice syntax: "items" followed by number or paren (clear indicators of index)
                // Variable: "items" followed by something else (operator, dot, etc.)
                let is_slice_syntax = if let Some(next) = self.tokens.get(self.current + 1) {
                    matches!(next.kind, TokenType::Number(_) | TokenType::LParen)
                } else {
                    false
                };

                if !is_slice_syntax {
                    // Treat "items" as a variable identifier
                    let sym = token.lexeme;
                    self.advance();
                    let base = self.ctx.alloc_imperative_expr(Expr::Identifier(sym));
                    return self.parse_field_access_chain(base);
                }

                self.advance(); // consume "items"

                // Grand Challenge: Parse start index as expression (number, identifier, or parenthesized)
                let start = if let TokenType::Number(sym) = &self.peek().kind {
                    // Literal number - check for zero index at compile time
                    let sym = *sym;
                    self.advance();
                    let num_str = self.interner.resolve(sym);
                    let start_val = num_str.parse::<i64>().unwrap_or(0);

                    // Index 0 Guard for start
                    if start_val == 0 {
                        return Err(ParseError {
                            kind: ParseErrorKind::ZeroIndex,
                            span: self.current_span(),
                        });
                    }

                    self.ctx.alloc_imperative_expr(
                        Expr::Literal(crate::ast::Literal::Number(start_val))
                    )
                } else if self.check(&TokenType::LParen) {
                    // Parenthesized expression like (mid + 1)
                    self.advance(); // consume '('
                    let inner = self.parse_imperative_expr()?;
                    if !self.check(&TokenType::RParen) {
                        return Err(ParseError {
                            kind: ParseErrorKind::ExpectedKeyword { keyword: ")".to_string() },
                            span: self.current_span(),
                        });
                    }
                    self.advance(); // consume ')'
                    inner
                } else if !self.check_preposition_is("through") {
                    // Variable identifier like mid, idx
                    let sym = self.peek().lexeme;
                    self.advance();
                    self.ctx.alloc_imperative_expr(Expr::Identifier(sym))
                } else {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedExpression,
                        span: self.current_span(),
                    });
                };

                // Expect "through"
                if !self.check_preposition_is("through") {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedKeyword { keyword: "through".to_string() },
                        span: self.current_span(),
                    });
                }
                self.advance(); // consume "through"

                // Grand Challenge: Parse end index as expression (number, identifier, or parenthesized)
                let end = if let TokenType::Number(sym) = &self.peek().kind {
                    // Literal number - check for zero index at compile time
                    let sym = *sym;
                    self.advance();
                    let num_str = self.interner.resolve(sym);
                    let end_val = num_str.parse::<i64>().unwrap_or(0);

                    // Index 0 Guard for end
                    if end_val == 0 {
                        return Err(ParseError {
                            kind: ParseErrorKind::ZeroIndex,
                            span: self.current_span(),
                        });
                    }

                    self.ctx.alloc_imperative_expr(
                        Expr::Literal(crate::ast::Literal::Number(end_val))
                    )
                } else if self.check(&TokenType::LParen) {
                    // Parenthesized expression like (mid + 1)
                    self.advance(); // consume '('
                    let inner = self.parse_imperative_expr()?;
                    if !self.check(&TokenType::RParen) {
                        return Err(ParseError {
                            kind: ParseErrorKind::ExpectedKeyword { keyword: ")".to_string() },
                            span: self.current_span(),
                        });
                    }
                    self.advance(); // consume ')'
                    inner
                } else if !self.check_preposition_is("of") {
                    // Variable identifier like n, length
                    let sym = self.peek().lexeme;
                    self.advance();
                    self.ctx.alloc_imperative_expr(Expr::Identifier(sym))
                } else {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedExpression,
                        span: self.current_span(),
                    });
                };

                // "of collection" is now optional - collection can be inferred from context
                // (e.g., "items 1 through mid" when items is the local variable)
                let collection = if self.check_preposition_is("of") {
                    self.advance(); // consume "of"
                    self.parse_imperative_expr()?
                } else {
                    // The variable is the collection itself (already consumed as "items")
                    // Re-intern "items" to use as the collection identifier
                    let items_sym = self.interner.intern("items");
                    self.ctx.alloc_imperative_expr(Expr::Identifier(items_sym))
                };

                Ok(self.ctx.alloc_imperative_expr(Expr::Slice {
                    collection,
                    start,
                    end,
                }))
            }

            // List literal: [1, 2, 3]
            TokenType::LBracket => {
                self.advance(); // consume "["

                let mut items = Vec::new();
                if !self.check(&TokenType::RBracket) {
                    loop {
                        items.push(self.parse_imperative_expr()?);
                        if !self.check(&TokenType::Comma) {
                            break;
                        }
                        self.advance(); // consume ","
                    }
                }

                if !self.check(&TokenType::RBracket) {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedKeyword { keyword: "]".to_string() },
                        span: self.current_span(),
                    });
                }
                self.advance(); // consume "]"

                // Check for typed empty list: [] of Int
                if items.is_empty() && self.check_word("of") {
                    self.advance(); // consume "of"
                    let type_name = self.expect_identifier()?;
                    // Generate: Seq::<Type>::default()
                    let seq_sym = self.interner.intern("Seq");
                    return Ok(self.ctx.alloc_imperative_expr(Expr::New {
                        type_name: seq_sym,
                        type_args: vec![type_name],
                        init_fields: vec![],
                    }));
                }

                Ok(self.ctx.alloc_imperative_expr(Expr::List(items)))
            }

            TokenType::Number(sym) => {
                self.advance();
                let num_str = self.interner.resolve(*sym);
                // Check if it's a float (contains decimal point)
                if num_str.contains('.') {
                    let num = num_str.parse::<f64>().unwrap_or(0.0);
                    Ok(self.ctx.alloc_imperative_expr(Expr::Literal(Literal::Float(num))))
                } else {
                    let num = num_str.parse::<i64>().unwrap_or(0);
                    Ok(self.ctx.alloc_imperative_expr(Expr::Literal(Literal::Number(num))))
                }
            }

            // Phase 33: String literals
            TokenType::StringLiteral(sym) => {
                self.advance();
                Ok(self.ctx.alloc_imperative_expr(Expr::Literal(Literal::Text(*sym))))
            }

            // Character literals
            TokenType::CharLiteral(sym) => {
                let char_str = self.interner.resolve(*sym);
                let ch = char_str.chars().next().unwrap_or('\0');
                self.advance();
                Ok(self.ctx.alloc_imperative_expr(Expr::Literal(Literal::Char(ch))))
            }

            // Handle 'nothing' literal
            TokenType::Nothing => {
                self.advance();
                Ok(self.ctx.alloc_imperative_expr(Expr::Literal(Literal::Nothing)))
            }

            // Phase 43D: Length expression: "length of items" or "length(items)"
            TokenType::Length => {
                let func_name = self.peek().lexeme;

                // Check for function call syntax: length(x)
                if self.tokens.get(self.current + 1)
                    .map(|t| matches!(t.kind, TokenType::LParen))
                    .unwrap_or(false)
                {
                    self.advance(); // consume "length"
                    return self.parse_call_expr(func_name);
                }

                self.advance(); // consume "length"

                // Expect "of" for natural syntax
                if !self.check_preposition_is("of") {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedKeyword { keyword: "of".to_string() },
                        span: self.current_span(),
                    });
                }
                self.advance(); // consume "of"

                let collection = self.parse_imperative_expr()?;
                Ok(self.ctx.alloc_imperative_expr(Expr::Length { collection }))
            }

            // Phase 43D: Copy expression: "copy of slice" or "copy(slice)"
            TokenType::Copy => {
                let func_name = self.peek().lexeme;

                // Check for function call syntax: copy(x)
                if self.tokens.get(self.current + 1)
                    .map(|t| matches!(t.kind, TokenType::LParen))
                    .unwrap_or(false)
                {
                    self.advance(); // consume "copy"
                    return self.parse_call_expr(func_name);
                }

                self.advance(); // consume "copy"

                // Expect "of" for natural syntax
                if !self.check_preposition_is("of") {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedKeyword { keyword: "of".to_string() },
                        span: self.current_span(),
                    });
                }
                self.advance(); // consume "of"

                let expr = self.parse_imperative_expr()?;
                Ok(self.ctx.alloc_imperative_expr(Expr::Copy { expr }))
            }

            // Phase 48: Manifest expression: "manifest of Zone"
            TokenType::Manifest => {
                self.advance(); // consume "manifest"

                // Expect "of"
                if !self.check_preposition_is("of") {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedKeyword { keyword: "of".to_string() },
                        span: self.current_span(),
                    });
                }
                self.advance(); // consume "of"

                let zone = self.parse_imperative_expr()?;
                Ok(self.ctx.alloc_imperative_expr(Expr::ManifestOf { zone }))
            }

            // Phase 48: Chunk expression: "chunk at N in Zone"
            TokenType::Chunk => {
                self.advance(); // consume "chunk"

                // Expect "at"
                if !self.check(&TokenType::At) {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedKeyword { keyword: "at".to_string() },
                        span: self.current_span(),
                    });
                }
                self.advance(); // consume "at"

                let index = self.parse_imperative_expr()?;

                // Expect "in"
                if !self.check_preposition_is("in") && !self.check(&TokenType::In) {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedKeyword { keyword: "in".to_string() },
                        span: self.current_span(),
                    });
                }
                self.advance(); // consume "in"

                let zone = self.parse_imperative_expr()?;
                Ok(self.ctx.alloc_imperative_expr(Expr::ChunkAt { index, zone }))
            }

            // Handle verbs in expression context:
            // - "empty" is a literal Nothing
            // - Other verbs can be function names (e.g., read, write)
            TokenType::Verb { lemma, .. } => {
                let word = self.interner.resolve(*lemma).to_lowercase();
                if word == "empty" {
                    self.advance();
                    return Ok(self.ctx.alloc_imperative_expr(Expr::Literal(Literal::Nothing)));
                }
                // Phase 38: Allow verbs to be used as function calls
                let sym = token.lexeme;
                self.advance();
                if self.check(&TokenType::LParen) {
                    return self.parse_call_expr(sym);
                }
                // Treat as identifier reference
                self.verify_identifier_access(sym)?;
                let base = self.ctx.alloc_imperative_expr(Expr::Identifier(sym));
                self.parse_field_access_chain(base)
            }

            // Phase 38: Adverbs as identifiers (e.g., "now" for time functions)
            TokenType::TemporalAdverb(_) | TokenType::ScopalAdverb(_) | TokenType::Adverb(_) => {
                let sym = token.lexeme;
                self.advance();
                if self.check(&TokenType::LParen) {
                    return self.parse_call_expr(sym);
                }
                // Treat as identifier reference (e.g., "Let t be now.")
                self.verify_identifier_access(sym)?;
                let base = self.ctx.alloc_imperative_expr(Expr::Identifier(sym));
                self.parse_field_access_chain(base)
            }

            // Phase 10: IO keywords as function calls (e.g., "read", "write", "file")
            // Phase 57: Add/Remove keywords as function calls
            TokenType::Read | TokenType::Write | TokenType::File | TokenType::Console |
            TokenType::Add | TokenType::Remove => {
                let sym = token.lexeme;
                self.advance();
                if self.check(&TokenType::LParen) {
                    return self.parse_call_expr(sym);
                }
                // Treat as identifier reference
                self.verify_identifier_access(sym)?;
                let base = self.ctx.alloc_imperative_expr(Expr::Identifier(sym));
                self.parse_field_access_chain(base)
            }

            // Unified identifier handling - all identifier-like tokens get verified
            // First check for boolean/special literals before treating as variable
            TokenType::Noun(sym) | TokenType::ProperName(sym) | TokenType::Adjective(sym) => {
                let sym = *sym;
                let word = self.interner.resolve(sym);

                // Check for boolean literals
                if word == "true" {
                    self.advance();
                    return Ok(self.ctx.alloc_imperative_expr(Expr::Literal(Literal::Boolean(true))));
                }
                if word == "false" {
                    self.advance();
                    return Ok(self.ctx.alloc_imperative_expr(Expr::Literal(Literal::Boolean(false))));
                }

                // Check for 'empty' - treat as unit value for collections
                if word == "empty" {
                    self.advance();
                    return Ok(self.ctx.alloc_imperative_expr(Expr::Literal(Literal::Nothing)));
                }

                // Don't verify as variable - might be a function call or enum variant
                self.advance();

                // Phase 32: Check for function call: identifier(args)
                if self.check(&TokenType::LParen) {
                    return self.parse_call_expr(sym);
                }

                // Phase 33: Check if this is a bare enum variant (e.g., "North" for Direction)
                if let Some(enum_name) = self.find_variant(sym) {
                    let base = self.ctx.alloc_imperative_expr(Expr::NewVariant {
                        enum_name,
                        variant: sym,
                        fields: vec![],
                    });
                    return self.parse_field_access_chain(base);
                }

                // Centralized verification for undefined/moved checks (only for variables)
                self.verify_identifier_access(sym)?;
                let base = self.ctx.alloc_imperative_expr(Expr::Identifier(sym));
                // Phase 31: Check for field access via possessive
                self.parse_field_access_chain(base)
            }

            // Pronouns can be variable names in code context ("i", "it")
            TokenType::Pronoun { .. } => {
                let sym = token.lexeme;
                self.advance();
                let base = self.ctx.alloc_imperative_expr(Expr::Identifier(sym));
                // Phase 31: Check for field access via possessive
                self.parse_field_access_chain(base)
            }

            // Phase 49: CRDT keywords can be function names (Merge, Increase)
            TokenType::Merge | TokenType::Increase => {
                let sym = token.lexeme;
                self.advance();

                // Check for function call: Merge(args)
                if self.check(&TokenType::LParen) {
                    return self.parse_call_expr(sym);
                }

                let base = self.ctx.alloc_imperative_expr(Expr::Identifier(sym));
                self.parse_field_access_chain(base)
            }

            // Handle ambiguous tokens that might be identifiers
            TokenType::Ambiguous { primary, alternatives } => {
                let sym = match &**primary {
                    TokenType::Noun(s) | TokenType::Adjective(s) | TokenType::ProperName(s) => Some(*s),
                    _ => alternatives.iter().find_map(|t| match t {
                        TokenType::Noun(s) | TokenType::Adjective(s) | TokenType::ProperName(s) => Some(*s),
                        _ => None
                    })
                };

                if let Some(s) = sym {
                    self.verify_identifier_access(s)?;
                    self.advance();
                    let base = self.ctx.alloc_imperative_expr(Expr::Identifier(s));
                    // Phase 31: Check for field access via possessive
                    self.parse_field_access_chain(base)
                } else {
                    Err(ParseError {
                        kind: ParseErrorKind::ExpectedExpression,
                        span: self.current_span(),
                    })
                }
            }

            // Parenthesized expression: (expr) or Tuple literal: (expr, expr, ...)
            TokenType::LParen => {
                self.advance(); // consume '('
                let first = self.parse_imperative_expr()?;

                // Check if this is a tuple (has comma) or just grouping
                if self.check(&TokenType::Comma) {
                    // It's a tuple - parse remaining elements
                    let mut items = vec![first];
                    while self.check(&TokenType::Comma) {
                        self.advance(); // consume ","
                        items.push(self.parse_imperative_expr()?);
                    }

                    if !self.check(&TokenType::RParen) {
                        return Err(ParseError {
                            kind: ParseErrorKind::ExpectedKeyword { keyword: ")".to_string() },
                            span: self.current_span(),
                        });
                    }
                    self.advance(); // consume ')'

                    let base = self.ctx.alloc_imperative_expr(Expr::Tuple(items));
                    self.parse_field_access_chain(base)
                } else {
                    // Just a parenthesized expression
                    if !self.check(&TokenType::RParen) {
                        return Err(ParseError {
                            kind: ParseErrorKind::ExpectedKeyword { keyword: ")".to_string() },
                            span: self.current_span(),
                        });
                    }
                    self.advance(); // consume ')'
                    Ok(first)
                }
            }

            _ => {
                Err(ParseError {
                    kind: ParseErrorKind::ExpectedExpression,
                    span: self.current_span(),
                })
            }
        }
    }

    /// Parse a complete imperative expression including binary operators.
    /// Uses precedence climbing for correct associativity and precedence.
    fn parse_imperative_expr(&mut self) -> ParseResult<&'a Expr<'a>> {
        self.parse_additive_expr()
    }

    /// Parse additive expressions (+, -, combined with, union, intersection, contains) - left-to-right associative
    fn parse_additive_expr(&mut self) -> ParseResult<&'a Expr<'a>> {
        let mut left = self.parse_multiplicative_expr()?;

        loop {
            match &self.peek().kind {
                TokenType::Plus => {
                    self.advance();
                    let right = self.parse_multiplicative_expr()?;
                    left = self.ctx.alloc_imperative_expr(Expr::BinaryOp {
                        op: BinaryOpKind::Add,
                        left,
                        right,
                    });
                }
                TokenType::Minus => {
                    self.advance();
                    let right = self.parse_multiplicative_expr()?;
                    left = self.ctx.alloc_imperative_expr(Expr::BinaryOp {
                        op: BinaryOpKind::Subtract,
                        left,
                        right,
                    });
                }
                // Phase 53: "combined with" for string concatenation
                TokenType::Combined => {
                    self.advance(); // consume "combined"
                    // Expect "with" (preposition)
                    if !self.check_preposition_is("with") {
                        return Err(ParseError {
                            kind: ParseErrorKind::ExpectedKeyword { keyword: "with".to_string() },
                            span: self.current_span(),
                        });
                    }
                    self.advance(); // consume "with"
                    let right = self.parse_multiplicative_expr()?;
                    left = self.ctx.alloc_imperative_expr(Expr::BinaryOp {
                        op: BinaryOpKind::Concat,
                        left,
                        right,
                    });
                }
                // Set operations: union, intersection
                TokenType::Union => {
                    self.advance(); // consume "union"
                    let right = self.parse_multiplicative_expr()?;
                    left = self.ctx.alloc_imperative_expr(Expr::Union {
                        left,
                        right,
                    });
                }
                TokenType::Intersection => {
                    self.advance(); // consume "intersection"
                    let right = self.parse_multiplicative_expr()?;
                    left = self.ctx.alloc_imperative_expr(Expr::Intersection {
                        left,
                        right,
                    });
                }
                // Set membership: "set contains value"
                TokenType::Contains => {
                    self.advance(); // consume "contains"
                    let value = self.parse_multiplicative_expr()?;
                    left = self.ctx.alloc_imperative_expr(Expr::Contains {
                        collection: left,
                        value,
                    });
                }
                _ => break,
            }
        }

        Ok(left)
    }

    /// Parse unary expressions (currently just unary minus)
    fn parse_unary_expr(&mut self) -> ParseResult<&'a Expr<'a>> {
        use crate::ast::{Expr, Literal};

        if self.check(&TokenType::Minus) {
            self.advance(); // consume '-'
            let operand = self.parse_unary_expr()?; // recursive for --5
            // Implement as 0 - operand (no UnaryOp variant in Expr)
            return Ok(self.ctx.alloc_imperative_expr(Expr::BinaryOp {
                op: BinaryOpKind::Subtract,
                left: self.ctx.alloc_imperative_expr(Expr::Literal(Literal::Number(0))),
                right: operand,
            }));
        }
        self.parse_primary_expr()
    }

    /// Parse multiplicative expressions (*, /, %) - left-to-right associative
    fn parse_multiplicative_expr(&mut self) -> ParseResult<&'a Expr<'a>> {
        let mut left = self.parse_unary_expr()?;

        loop {
            let op = match &self.peek().kind {
                TokenType::Star => {
                    self.advance();
                    BinaryOpKind::Multiply
                }
                TokenType::Slash => {
                    self.advance();
                    BinaryOpKind::Divide
                }
                TokenType::Percent => {
                    self.advance();
                    BinaryOpKind::Modulo
                }
                _ => break,
            };
            let right = self.parse_unary_expr()?;
            left = self.ctx.alloc_imperative_expr(Expr::BinaryOp {
                op,
                left,
                right,
            });
        }

        Ok(left)
    }

    /// Try to parse a binary operator (+, -, *, /)
    fn try_parse_binary_op(&mut self) -> Option<BinaryOpKind> {
        match &self.peek().kind {
            TokenType::Plus => {
                self.advance();
                Some(BinaryOpKind::Add)
            }
            TokenType::Minus => {
                self.advance();
                Some(BinaryOpKind::Subtract)
            }
            TokenType::Star => {
                self.advance();
                Some(BinaryOpKind::Multiply)
            }
            TokenType::Slash => {
                self.advance();
                Some(BinaryOpKind::Divide)
            }
            _ => None,
        }
    }

    /// Phase 32: Parse function call expression: f(x, y, ...)
    fn parse_call_expr(&mut self, function: Symbol) -> ParseResult<&'a Expr<'a>> {
        use crate::ast::Expr;

        self.advance(); // consume '('

        let mut args = Vec::new();
        if !self.check(&TokenType::RParen) {
            loop {
                args.push(self.parse_imperative_expr()?);
                if !self.check(&TokenType::Comma) {
                    break;
                }
                self.advance(); // consume ','
            }
        }

        if !self.check(&TokenType::RParen) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ")".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume ')'

        Ok(self.ctx.alloc_imperative_expr(Expr::Call { function, args }))
    }

    /// Phase 31: Parse field access chain via possessive ('s) and bracket indexing
    /// Handles patterns like: p's x, p's x's y, items[1], items[i]'s field
    fn parse_field_access_chain(&mut self, base: &'a Expr<'a>) -> ParseResult<&'a Expr<'a>> {
        use crate::ast::Expr;

        let mut result = base;

        // Keep parsing field accesses and bracket indexing
        loop {
            if self.check(&TokenType::Possessive) {
                // Field access: p's x
                self.advance(); // consume "'s"
                let field = self.expect_identifier()?;
                result = self.ctx.alloc_imperative_expr(Expr::FieldAccess {
                    object: result,
                    field,
                });
            } else if self.check(&TokenType::LBracket) {
                // Bracket indexing: items[1], items[i]
                self.advance(); // consume "["
                let index = self.parse_imperative_expr()?;

                if !self.check(&TokenType::RBracket) {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedKeyword { keyword: "]".to_string() },
                        span: self.current_span(),
                    });
                }
                self.advance(); // consume "]"

                result = self.ctx.alloc_imperative_expr(Expr::Index {
                    collection: result,
                    index,
                });
            } else {
                break;
            }
        }

        Ok(result)
    }

    /// Centralized verification for identifier access in imperative mode.
    /// Checks for use-after-move errors on known variables.
    fn verify_identifier_access(&self, sym: Symbol) -> ParseResult<()> {
        if self.mode != ParserMode::Imperative {
            return Ok(());
        }

        // Check if variable has been moved
        if let Some(crate::drs::OwnershipState::Moved) = self.world_state.get_ownership_by_var(sym) {
            return Err(ParseError {
                kind: ParseErrorKind::UseAfterMove {
                    name: self.interner.resolve(sym).to_string()
                },
                span: self.current_span(),
            });
        }

        Ok(())
    }

    fn expect_identifier(&mut self) -> ParseResult<Symbol> {
        let token = self.peek().clone();
        match &token.kind {
            // Standard identifiers
            TokenType::Noun(sym) | TokenType::ProperName(sym) | TokenType::Adjective(sym) => {
                self.advance();
                Ok(*sym)
            }
            // Verbs can be variable names in code context ("empty", "run", etc.)
            // Use raw lexeme to preserve original casing
            TokenType::Verb { .. } => {
                let sym = token.lexeme;
                self.advance();
                Ok(sym)
            }
            // Phase 32: Articles can be single-letter identifiers (a, an)
            TokenType::Article(_) => {
                let sym = token.lexeme;
                self.advance();
                Ok(sym)
            }
            // Overloaded tokens that are valid identifiers in code context
            TokenType::Pronoun { .. } |  // "i", "it"
            TokenType::Items |           // "items"
            TokenType::Values |          // "values"
            TokenType::Item |            // "item"
            TokenType::Nothing |         // "nothing"
            // Phase 38: Adverbs can be function names (now, sleep, etc.)
            TokenType::TemporalAdverb(_) |
            TokenType::ScopalAdverb(_) |
            TokenType::Adverb(_) |
            // Phase 10: IO keywords can be function names (read, write, file, console)
            TokenType::Read |
            TokenType::Write |
            TokenType::File |
            TokenType::Console |
            // Phase 49: CRDT keywords can be function names (Merge, Increase)
            TokenType::Merge |
            TokenType::Increase |
            // Phase 54: "first", "second", etc. can be variable names
            // Phase 57: "add", "remove" can be function names
            TokenType::Add |
            TokenType::Remove |
            TokenType::First => {
                // Use the raw lexeme (interned string) as the symbol
                let sym = token.lexeme;
                self.advance();
                Ok(sym)
            }
            TokenType::Ambiguous { .. } => {
                // For ambiguous tokens, always use the raw lexeme to preserve original casing
                // (using verb lemma can give wrong casing like "State" instead of "state")
                let sym = token.lexeme;
                self.advance();
                Ok(sym)
            }
            _ => Err(ParseError {
                kind: ParseErrorKind::ExpectedIdentifier,
                span: self.current_span(),
            }),
        }
    }

    fn consume_content_word_for_relative(&mut self) -> ParseResult<Symbol> {
        let t = self.advance().clone();
        match t.kind {
            TokenType::Noun(s) | TokenType::Adjective(s) => Ok(s),
            TokenType::ProperName(s) => Ok(s),
            TokenType::Verb { lemma, .. } => Ok(lemma),
            other => Err(ParseError {
                kind: ParseErrorKind::ExpectedContentWord { found: other },
                span: self.current_span(),
            }),
        }
    }

    fn check_modal(&self) -> bool {
        matches!(
            self.peek().kind,
            TokenType::Must
                | TokenType::Shall
                | TokenType::Should
                | TokenType::Can
                | TokenType::May
                | TokenType::Cannot
                | TokenType::Could
                | TokenType::Would
                | TokenType::Might
        )
    }

    fn check_pronoun(&self) -> bool {
        match &self.peek().kind {
            TokenType::Pronoun { case, .. } => {
                // In noun_priority_mode, possessive pronouns start NPs, not standalone objects
                if self.noun_priority_mode && matches!(case, Case::Possessive) {
                    return false;
                }
                true
            }
            TokenType::Ambiguous { primary, alternatives } => {
                // In noun_priority_mode, if there's a possessive alternative, prefer noun path
                if self.noun_priority_mode {
                    let has_possessive = matches!(**primary, TokenType::Pronoun { case: Case::Possessive, .. })
                        || alternatives.iter().any(|t| matches!(t, TokenType::Pronoun { case: Case::Possessive, .. }));
                    if has_possessive {
                        return false;
                    }
                }
                matches!(**primary, TokenType::Pronoun { .. })
                    || alternatives.iter().any(|t| matches!(t, TokenType::Pronoun { .. }))
            }
            _ => false,
        }
    }

    fn parse_atom(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        // Handle Focus particles: "Only John loves Mary", "Even John ran"
        if self.check_focus() {
            return self.parse_focus();
        }

        // Handle mass noun measure: "Much water flows", "Little time remains"
        if self.check_measure() {
            return self.parse_measure();
        }

        if self.check_quantifier() {
            self.advance();
            return self.parse_quantified();
        }

        if self.check_npi_quantifier() {
            return self.parse_npi_quantified();
        }

        if self.check_temporal_npi() {
            return self.parse_temporal_npi();
        }

        if self.match_token(&[TokenType::LParen]) {
            let expr = self.parse_sentence()?;
            self.consume(TokenType::RParen)?;
            return Ok(expr);
        }

        // Handle pronoun as subject
        if self.check_pronoun() {
            let token = self.advance().clone();
            let (gender, number) = match &token.kind {
                TokenType::Pronoun { gender, number, .. } => (*gender, *number),
                TokenType::Ambiguous { primary, alternatives } => {
                    if let TokenType::Pronoun { gender, number, .. } = **primary {
                        (gender, number)
                    } else {
                        alternatives.iter().find_map(|t| {
                            if let TokenType::Pronoun { gender, number, .. } = t {
                                Some((*gender, *number))
                            } else {
                                None
                            }
                        }).unwrap_or((Gender::Unknown, Number::Singular))
                    }
                }
                _ => (Gender::Unknown, Number::Singular),
            };

            let token_text = self.interner.resolve(token.lexeme);

            // Weather verb + expletive "it" detection: "it rains" → ∃e(Rain(e))
            // Must check BEFORE pronoun resolution since "it" resolves to "?"
            if token_text.eq_ignore_ascii_case("it") && self.check_verb() {
                if let TokenType::Verb { lemma, time, .. } = &self.peek().kind {
                    let lemma_str = self.interner.resolve(*lemma);
                    if Lexer::is_weather_verb(lemma_str) {
                        let verb = *lemma;
                        let verb_time = *time;
                        self.advance(); // consume the weather verb

                        let event_var = self.get_event_var();
                        let suppress_existential = self.drs.in_conditional_antecedent();
                        if suppress_existential {
                            let event_class = self.interner.intern("Event");
                            self.drs.introduce_referent(event_var, event_class, Gender::Neuter, Number::Singular);
                        }
                        let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                            event_var,
                            verb,
                            roles: self.ctx.roles.alloc_slice(vec![]), // No thematic roles
                            modifiers: self.ctx.syms.alloc_slice(vec![]),
                            suppress_existential,
                            world: None,
                        })));

                        return Ok(match verb_time {
                            Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                                operator: TemporalOperator::Past,
                                body: neo_event,
                            }),
                            Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                                operator: TemporalOperator::Future,
                                body: neo_event,
                            }),
                            _ => neo_event,
                        });
                    }
                }
            }

            // Handle deictic pronouns that don't need discourse resolution
            let resolved = if token_text.eq_ignore_ascii_case("i") {
                ResolvedPronoun::Constant(self.interner.intern("Speaker"))
            } else if token_text.eq_ignore_ascii_case("you") {
                ResolvedPronoun::Constant(self.interner.intern("Addressee"))
            } else {
                // Try discourse resolution for anaphoric pronouns
                self.resolve_pronoun(gender, number)?
            };

            // Check for performative: "I promise that..." or "I promise to..."
            if self.check_performative() {
                if let TokenType::Performative(act) = self.advance().kind.clone() {
                    let sym = match resolved {
                        ResolvedPronoun::Variable(s) | ResolvedPronoun::Constant(s) => s,
                    };
                    // Check for infinitive complement: "I promise to come"
                    if self.check(&TokenType::To) {
                        self.advance(); // consume "to"

                        if self.check_verb() {
                            let infinitive_verb = self.consume_verb();

                            let content = self.ctx.exprs.alloc(LogicExpr::Predicate {
                                name: infinitive_verb,
                                args: self.ctx.terms.alloc_slice([Term::Constant(sym)]),
                                world: None,
                            });

                            return Ok(self.ctx.exprs.alloc(LogicExpr::SpeechAct {
                                performer: sym,
                                act_type: act,
                                content,
                            }));
                        }
                    }

                    // Skip "that" if present
                    if self.check(&TokenType::That) {
                        self.advance();
                    }
                    let content = self.parse_sentence()?;
                    return Ok(self.ctx.exprs.alloc(LogicExpr::SpeechAct {
                        performer: sym,
                        act_type: act,
                        content,
                    }));
                }
            }

            // Continue parsing verb phrase with resolved subject
            // Use as_var=true for bound variables, as_var=false for constants
            return match resolved {
                ResolvedPronoun::Variable(sym) => self.parse_predicate_with_subject_as_var(sym),
                ResolvedPronoun::Constant(sym) => self.parse_predicate_with_subject(sym),
            };
        }

        // Consume "both" correlative marker if present: "both X and Y"
        // The existing try_parse_plural_subject will handle the "X and Y" pattern
        let _had_both = self.match_token(&[TokenType::Both]);

        let subject = self.parse_noun_phrase(true)?;

        // Introduce subject NP to DRS for cross-sentence pronoun resolution (accommodation)
        // This allows "A man walked. He fell." to work
        // Use noun as both variable and noun_class (like proper names) so pronouns resolve to it
        // NOTE: Definite NPs are NOT introduced here - they go through wrap_with_definiteness
        // where bridging anaphora can link them to prior wholes (e.g., "I bought a car. The engine smoked.")
        if subject.definiteness == Some(Definiteness::Indefinite)
            || subject.definiteness == Some(Definiteness::Distal) {
            let gender = Self::infer_noun_gender(self.interner.resolve(subject.noun));
            let number = if Self::is_plural_noun(self.interner.resolve(subject.noun)) {
                Number::Plural
            } else {
                Number::Singular
            };
            // Use noun as variable so pronoun resolution returns the noun name
            self.drs.introduce_referent(subject.noun, subject.noun, gender, number);
        }

        // Handle plural subjects: "John and Mary verb"
        if self.check(&TokenType::And) {
            match self.try_parse_plural_subject(&subject) {
                Ok(Some(result)) => return Ok(result),
                Ok(None) => {} // Not a plural subject, continue
                Err(e) => return Err(e), // Semantic error (e.g., respectively mismatch)
            }
        }

        // Handle scopal adverbs: "John almost died"
        if self.check_scopal_adverb() {
            return self.parse_scopal_adverb(&subject);
        }

        // Handle topicalization: "The cake, John ate." - first NP is object, not subject
        if self.check(&TokenType::Comma) {
            let saved_pos = self.current;
            self.advance(); // consume comma

            // Check if followed by pronoun subject (e.g., "The book, he read.")
            if self.check_pronoun() {
                let topic_attempt = self.try_parse(|p| {
                    let token = p.peek().clone();
                    let pronoun_features = match &token.kind {
                        TokenType::Pronoun { gender, number, .. } => Some((*gender, *number)),
                        TokenType::Ambiguous { primary, alternatives } => {
                            if let TokenType::Pronoun { gender, number, .. } = **primary {
                                Some((gender, number))
                            } else {
                                alternatives.iter().find_map(|t| {
                                    if let TokenType::Pronoun { gender, number, .. } = t {
                                        Some((*gender, *number))
                                    } else {
                                        None
                                    }
                                })
                            }
                        }
                        _ => None,
                    };

                    if let Some((gender, number)) = pronoun_features {
                        p.advance(); // consume pronoun
                        let resolved = p.resolve_pronoun(gender, number)?;
                        let resolved_term = match resolved {
                            ResolvedPronoun::Variable(s) => Term::Variable(s),
                            ResolvedPronoun::Constant(s) => Term::Constant(s),
                        };

                        if p.check_verb() {
                            let verb = p.consume_verb();
                            let predicate = p.ctx.exprs.alloc(LogicExpr::Predicate {
                                name: verb,
                                args: p.ctx.terms.alloc_slice([
                                    resolved_term,
                                    Term::Constant(subject.noun),
                                ]),
                                world: None,
                            });
                            p.wrap_with_definiteness_full(&subject, predicate)
                        } else {
                            Err(ParseError {
                                kind: ParseErrorKind::ExpectedVerb { found: p.peek().kind.clone() },
                                span: p.current_span(),
                            })
                        }
                    } else {
                        Err(ParseError {
                            kind: ParseErrorKind::ExpectedContentWord { found: token.kind },
                            span: p.current_span(),
                        })
                    }
                });

                if let Some(result) = topic_attempt {
                    return Ok(result);
                }
            }

            // Check if followed by another NP and then a verb (topicalization pattern)
            if self.check_content_word() {
                let topic_attempt = self.try_parse(|p| {
                    let real_subject = p.parse_noun_phrase(true)?;
                    if p.check_verb() {
                        let verb = p.consume_verb();
                        let predicate = p.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: verb,
                            args: p.ctx.terms.alloc_slice([
                                Term::Constant(real_subject.noun),
                                Term::Constant(subject.noun),
                            ]),
                            world: None,
                        });
                        p.wrap_with_definiteness_full(&subject, predicate)
                    } else {
                        Err(ParseError {
                            kind: ParseErrorKind::ExpectedVerb { found: p.peek().kind.clone() },
                            span: p.current_span(),
                        })
                    }
                });

                if let Some(result) = topic_attempt {
                    return Ok(result);
                }
            }

            // Restore position if topicalization didn't match
            self.current = saved_pos;
        }

        // Handle relative clause after subject: "The cat that the dog chased ran."
        let mut relative_clause: Option<(Symbol, &'a LogicExpr<'a>)> = None;
        if self.check(&TokenType::That) || self.check(&TokenType::Who) {
            self.advance();
            let var_name = self.next_var_name();
            let rel_pred = self.parse_relative_clause(var_name)?;
            relative_clause = Some((var_name, rel_pred));
        } else if matches!(self.peek().kind, TokenType::Article(_)) && self.is_contact_clause_pattern() {
            // Contact clause (reduced relative): "The cat the dog chased ran."
            // NP + NP + Verb pattern indicates embedded relative without explicit "that"
            let var_name = self.next_var_name();
            let rel_pred = self.parse_relative_clause(var_name)?;
            relative_clause = Some((var_name, rel_pred));
        }

        // Handle main verb after relative clause: "The cat that the dog chased ran."
        if let Some((var_name, rel_clause)) = relative_clause {
            if self.check_verb() {
                let (verb, verb_time, _, _) = self.consume_verb_with_metadata();
                let var_term = Term::Variable(var_name);

                let event_var = self.get_event_var();
                let suppress_existential = self.drs.in_conditional_antecedent();
                let mut modifiers = vec![];
                if verb_time == Time::Past {
                    modifiers.push(self.interner.intern("Past"));
                }
                let main_pred = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                    event_var,
                    verb,
                    roles: self.ctx.roles.alloc_slice(vec![
                        (ThematicRole::Agent, var_term),
                    ]),
                    modifiers: self.ctx.syms.alloc_slice(modifiers),
                    suppress_existential,
                    world: None,
                })));

                let type_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: subject.noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                    world: None,
                });

                let inner = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: type_pred,
                    op: TokenType::And,
                    right: rel_clause,
                });

                let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: inner,
                    op: TokenType::And,
                    right: main_pred,
                });

                return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: var_name,
                    body,
                    island_id: self.current_island,
                }));
            }

            // No main verb - just the relative clause: "The cat that runs" as a complete NP
            // Build: ∃x(Cat(x) ∧ Runs(x) ∧ ∀y(Cat(y) → y=x))
            if self.is_at_end() || self.check(&TokenType::Period) || self.check(&TokenType::Comma) {
                let type_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: subject.noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                    world: None,
                });

                let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: type_pred,
                    op: TokenType::And,
                    right: rel_clause,
                });

                // Add uniqueness for definite description
                let uniqueness_body = if subject.definiteness == Some(Definiteness::Definite) {
                    let y_var = self.next_var_name();
                    let type_pred_y = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: subject.noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(y_var)]),
                        world: None,
                    });
                    let identity = self.ctx.exprs.alloc(LogicExpr::Identity {
                        left: self.ctx.terms.alloc(Term::Variable(y_var)),
                        right: self.ctx.terms.alloc(Term::Variable(var_name)),
                    });
                    let uniqueness_cond = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: type_pred_y,
                        op: TokenType::If,
                        right: identity,
                    });
                    let uniqueness = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                        kind: QuantifierKind::Universal,
                        variable: y_var,
                        body: uniqueness_cond,
                        island_id: self.current_island,
                    });
                    self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: body,
                        op: TokenType::And,
                        right: uniqueness,
                    })
                } else {
                    body
                };

                return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: var_name,
                    body: uniqueness_body,
                    island_id: self.current_island,
                }));
            }

            // Re-store for copula handling below
            relative_clause = Some((var_name, rel_clause));
        }

        // Identity check: "Clark is equal to Superman"
        if self.check(&TokenType::Identity) {
            self.advance();
            let right = self.consume_content_word()?;
            return Ok(self.ctx.exprs.alloc(LogicExpr::Identity {
                left: self.ctx.terms.alloc(Term::Constant(subject.noun)),
                right: self.ctx.terms.alloc(Term::Constant(right)),
            }));
        }

        if self.check_modal() {
            if let Some((var_name, rel_clause)) = relative_clause {
                let modal_pred = self.parse_aspect_chain_with_term(Term::Variable(var_name))?;

                let type_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: subject.noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                    world: None,
                });

                let inner = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: type_pred,
                    op: TokenType::And,
                    right: rel_clause,
                });

                let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: inner,
                    op: TokenType::And,
                    right: modal_pred,
                });

                return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: var_name,
                    body,
                    island_id: self.current_island,
                }));
            }

            let modal_pred = self.parse_aspect_chain(subject.noun)?;
            return self.wrap_with_definiteness_full(&subject, modal_pred);
        }

        if self.check(&TokenType::Is) || self.check(&TokenType::Are)
            || self.check(&TokenType::Was) || self.check(&TokenType::Were)
        {
            let copula_time = if self.check(&TokenType::Was) || self.check(&TokenType::Were) {
                Time::Past
            } else {
                Time::Present
            };
            self.advance();

            // Check for Number token (measure phrase) before comparative or adjective
            // "John is 2 inches taller than Mary" or "The rope is 5 meters long"
            if self.check_number() {
                let measure = self.parse_measure_phrase()?;

                // Check if followed by comparative: "2 inches taller than"
                if self.check_comparative() {
                    return self.parse_comparative(&subject, copula_time, Some(measure));
                }

                // Check for dimensional adjective: "5 meters long"
                if self.check_content_word() {
                    let adj = self.consume_content_word()?;
                    let result = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: adj,
                        args: self.ctx.terms.alloc_slice([
                            Term::Constant(subject.noun),
                            *measure,
                        ]),
                        world: None,
                    });
                    return self.wrap_with_definiteness_full(&subject, result);
                }

                // Bare measure phrase: "The temperature is 98.6 degrees."
                // Output: Identity(subject, measure)
                if self.check(&TokenType::Period) || self.is_at_end() {
                    // In imperative mode, reject "x is 5" - suggest "x equals 5"
                    if self.mode == ParserMode::Imperative {
                        let variable = self.interner.resolve(subject.noun).to_string();
                        let value = if let Term::Value { kind, .. } = measure {
                            format!("{:?}", kind)
                        } else {
                            "value".to_string()
                        };
                        return Err(ParseError {
                            kind: ParseErrorKind::IsValueEquality { variable, value },
                            span: self.current_span(),
                        });
                    }
                    let result = self.ctx.exprs.alloc(LogicExpr::Identity {
                        left: self.ctx.terms.alloc(Term::Constant(subject.noun)),
                        right: measure,
                    });
                    return self.wrap_with_definiteness_full(&subject, result);
                }
            }

            // Check for comparative: "is taller than"
            if self.check_comparative() {
                return self.parse_comparative(&subject, copula_time, None);
            }

            // Check for existential "is": "God is." - bare copula followed by period/EOF
            if self.check(&TokenType::Period) || self.is_at_end() {
                let var = self.next_var_name();
                let body = self.ctx.exprs.alloc(LogicExpr::Identity {
                    left: self.ctx.terms.alloc(Term::Variable(var)),
                    right: self.ctx.terms.alloc(Term::Constant(subject.noun)),
                });
                return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: var,
                    body,
                    island_id: self.current_island,
                }));
            }

            // Check for superlative: "is the tallest man"
            if self.check(&TokenType::Article(Definiteness::Definite)) {
                let saved_pos = self.current;
                self.advance();
                if self.check_superlative() {
                    return self.parse_superlative(&subject);
                }
                self.current = saved_pos;
            }

            // Check for predicate NP: "Juliet is the sun" or "John is a man"
            if self.check_article() {
                let predicate_np = self.parse_noun_phrase(true)?;
                let predicate_noun = predicate_np.noun;

                // Phase 41: Event adjective reading
                // "beautiful dancer" in event mode → ∃e(Dance(e) ∧ Agent(e, x) ∧ Beautiful(e))
                if self.event_reading_mode {
                    let noun_str = self.interner.resolve(predicate_noun);
                    if let Some(base_verb) = lexicon::lookup_agentive_noun(noun_str) {
                        // Check if any adjective can modify events
                        let event_adj = predicate_np.adjectives.iter().find(|adj| {
                            lexicon::is_event_modifier_adjective(self.interner.resolve(**adj))
                        });

                        if let Some(&adj_sym) = event_adj {
                            // Build event reading: ∃e(Verb(e) ∧ Agent(e, subject) ∧ Adj(e))
                            let verb_sym = self.interner.intern(base_verb);
                            let event_var = self.get_event_var();

                            let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                                name: verb_sym,
                                args: self.ctx.terms.alloc_slice([Term::Variable(event_var)]),
                                world: None,
                            });

                            let agent_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                                name: self.interner.intern("Agent"),
                                args: self.ctx.terms.alloc_slice([
                                    Term::Variable(event_var),
                                    Term::Constant(subject.noun),
                                ]),
                                world: None,
                            });

                            let adj_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                                name: adj_sym,
                                args: self.ctx.terms.alloc_slice([Term::Variable(event_var)]),
                                world: None,
                            });

                            // Conjoin: Verb(e) ∧ Agent(e, x)
                            let verb_agent = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                left: verb_pred,
                                op: TokenType::And,
                                right: agent_pred,
                            });

                            // Conjoin: (Verb(e) ∧ Agent(e, x)) ∧ Adj(e)
                            let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                left: verb_agent,
                                op: TokenType::And,
                                right: adj_pred,
                            });

                            // Wrap in existential: ∃e(...)
                            let event_reading = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                                kind: QuantifierKind::Existential,
                                variable: event_var,
                                body,
                                island_id: self.current_island,
                            });

                            return self.wrap_with_definiteness(subject.definiteness, subject.noun, event_reading);
                        }
                    }
                }

                let subject_sort = lexicon::lookup_sort(self.interner.resolve(subject.noun));
                let predicate_sort = lexicon::lookup_sort(self.interner.resolve(predicate_noun));

                if let (Some(s_sort), Some(p_sort)) = (subject_sort, predicate_sort) {
                    if !s_sort.is_compatible_with(p_sort) && !p_sort.is_compatible_with(s_sort) {
                        let metaphor = self.ctx.exprs.alloc(LogicExpr::Metaphor {
                            tenor: self.ctx.terms.alloc(Term::Constant(subject.noun)),
                            vehicle: self.ctx.terms.alloc(Term::Constant(predicate_noun)),
                        });
                        return self.wrap_with_definiteness(subject.definiteness, subject.noun, metaphor);
                    }
                }

                // Default: intersective reading for adjectives
                // Build Adj1(x) ∧ Adj2(x) ∧ ... ∧ Noun(x)
                let mut predicates: Vec<&'a LogicExpr<'a>> = Vec::new();

                // Add adjective predicates
                for &adj_sym in predicate_np.adjectives {
                    let adj_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: adj_sym,
                        args: self.ctx.terms.alloc_slice([Term::Constant(subject.noun)]),
                        world: None,
                    });
                    predicates.push(adj_pred);
                }

                // Add noun predicate
                let noun_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: predicate_noun,
                    args: self.ctx.terms.alloc_slice([Term::Constant(subject.noun)]),
                    world: None,
                });
                predicates.push(noun_pred);

                // Conjoin all predicates
                let result = if predicates.len() == 1 {
                    predicates[0]
                } else {
                    let mut combined = predicates[0];
                    for pred in &predicates[1..] {
                        combined = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: combined,
                            op: TokenType::And,
                            right: *pred,
                        });
                    }
                    combined
                };

                return self.wrap_with_definiteness(subject.definiteness, subject.noun, result);
            }

            // After copula, prefer Adjective over simple-aspect Verb for ambiguous tokens
            // "is open" (Adj: state) is standard; "is open" (Verb: habitual) is ungrammatical here
            let prefer_adjective = if let TokenType::Ambiguous { primary, alternatives } = &self.peek().kind {
                let is_simple_verb = if let TokenType::Verb { aspect, .. } = **primary {
                    aspect == Aspect::Simple
                } else {
                    false
                };
                let has_adj_alt = alternatives.iter().any(|t| matches!(t, TokenType::Adjective(_)));
                is_simple_verb && has_adj_alt
            } else {
                false
            };

            if !prefer_adjective && self.check_verb() {
                let (verb, _verb_time, verb_aspect, verb_class) = self.consume_verb_with_metadata();

                // Stative verbs cannot be progressive
                if verb_class.is_stative() && verb_aspect == Aspect::Progressive {
                    return Err(ParseError {
                        kind: ParseErrorKind::StativeProgressiveConflict,
                        span: self.current_span(),
                    });
                }

                // Collect any prepositional phrases before "by" (for ditransitives)
                // "given to Mary by John" → goal = Mary, then agent = John
                let mut goal_args: Vec<Term<'a>> = Vec::new();
                while self.check_to_preposition() {
                    self.advance(); // consume "to"
                    let goal = self.parse_noun_phrase(true)?;
                    goal_args.push(self.noun_phrase_to_term(&goal));
                }

                // Check for passive: "was loved by John" or "was given to Mary by John"
                if self.check_by_preposition() {
                    self.advance(); // consume "by"
                    let agent = self.parse_noun_phrase(true)?;

                    // Build args: agent, theme (subject), then any goals
                    let mut args = vec![
                        self.noun_phrase_to_term(&agent),
                        self.noun_phrase_to_term(&subject),
                    ];
                    args.extend(goal_args);

                    let predicate = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: verb,
                        args: self.ctx.terms.alloc_slice(args),
                        world: None,
                    });

                    let with_time = if copula_time == Time::Past {
                        self.ctx.exprs.alloc(LogicExpr::Temporal {
                            operator: TemporalOperator::Past,
                            body: predicate,
                        })
                    } else {
                        predicate
                    };

                    return self.wrap_with_definiteness(subject.definiteness, subject.noun, with_time);
                }

                // Agentless passive: "The book was read" → ∃x.Read(x, Book)
                if copula_time == Time::Past && verb_aspect == Aspect::Simple {
                    // Could be agentless passive - treat as existential
                    let var_name = self.next_var_name();
                    let predicate = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: verb,
                        args: self.ctx.terms.alloc_slice([
                            Term::Variable(var_name),
                            Term::Constant(subject.noun),
                        ]),
                        world: None,
                    });

                    let type_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: subject.noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                        world: None,
                    });

                    let temporal = self.ctx.exprs.alloc(LogicExpr::Temporal {
                        operator: TemporalOperator::Past,
                        body: predicate,
                    });

                    let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: type_pred,
                        op: TokenType::And,
                        right: temporal,
                    });

                    return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                        kind: QuantifierKind::Existential,
                        variable: var_name,
                        body,
                        island_id: self.current_island,
                    }));
                }

                let predicate = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb,
                    args: self.ctx.terms.alloc_slice([Term::Constant(subject.noun)]),
                    world: None,
                });

                let with_aspect = if verb_aspect == Aspect::Progressive {
                    // Semelfactive + Progressive → Iterative
                    let operator = if verb_class == VerbClass::Semelfactive {
                        AspectOperator::Iterative
                    } else {
                        AspectOperator::Progressive
                    };
                    self.ctx.exprs.alloc(LogicExpr::Aspectual {
                        operator,
                        body: predicate,
                    })
                } else {
                    predicate
                };

                let with_time = if copula_time == Time::Past {
                    self.ctx.exprs.alloc(LogicExpr::Temporal {
                        operator: TemporalOperator::Past,
                        body: with_aspect,
                    })
                } else {
                    with_aspect
                };

                return self.wrap_with_definiteness(subject.definiteness, subject.noun, with_time);
            }

            // Handle relative clause with copula: "The book that John read is good."
            if let Some((var_name, rel_clause)) = relative_clause {
                let var_term = Term::Variable(var_name);
                let pred_word = self.consume_content_word()?;

                let main_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: pred_word,
                    args: self.ctx.terms.alloc_slice([var_term]),
                    world: None,
                });

                let type_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: subject.noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                    world: None,
                });

                let inner = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: type_pred,
                    op: TokenType::And,
                    right: rel_clause,
                });

                let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: inner,
                    op: TokenType::And,
                    right: main_pred,
                });

                return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: var_name,
                    body,
                    island_id: self.current_island,
                }));
            }

            // Handle "The king is bald" - NP copula ADJ/NOUN
            // Also handles bare noun predicates like "Time is money"
            let predicate_name = self.consume_content_word()?;

            // Check for sort violation (metaphor detection)
            let subject_sort = lexicon::lookup_sort(self.interner.resolve(subject.noun));
            let predicate_str = self.interner.resolve(predicate_name);

            // Check ontology's predicate sort requirements (for adjectives like "happy")
            if let Some(s_sort) = subject_sort {
                if !crate::ontology::check_sort_compatibility(predicate_str, s_sort) {
                    let metaphor = self.ctx.exprs.alloc(LogicExpr::Metaphor {
                        tenor: self.ctx.terms.alloc(Term::Constant(subject.noun)),
                        vehicle: self.ctx.terms.alloc(Term::Constant(predicate_name)),
                    });
                    return self.wrap_with_definiteness(subject.definiteness, subject.noun, metaphor);
                }
            }

            // Check copular NP predicate sort compatibility (for "Time is money")
            let predicate_sort = lexicon::lookup_sort(predicate_str);
            if let (Some(s_sort), Some(p_sort)) = (subject_sort, predicate_sort) {
                if s_sort != p_sort && !s_sort.is_compatible_with(p_sort) && !p_sort.is_compatible_with(s_sort) {
                    let metaphor = self.ctx.exprs.alloc(LogicExpr::Metaphor {
                        tenor: self.ctx.terms.alloc(Term::Constant(subject.noun)),
                        vehicle: self.ctx.terms.alloc(Term::Constant(predicate_name)),
                    });
                    return self.wrap_with_definiteness(subject.definiteness, subject.noun, metaphor);
                }
            }

            let predicate = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: predicate_name,
                args: self.ctx.terms.alloc_slice([Term::Constant(subject.noun)]),
                world: None,
            });
            return self.wrap_with_definiteness(subject.definiteness, subject.noun, predicate);
        }

        // Handle auxiliary: set pending_time, handle negation
        if self.check_auxiliary() {
            let aux_time = if let TokenType::Auxiliary(time) = self.advance().kind {
                time
            } else {
                Time::None
            };
            self.pending_time = Some(aux_time);

            // Handle negation: "John did not see dogs"
            if self.match_token(&[TokenType::Not]) {
                self.negative_depth += 1;

                // Skip "ever" if present: "John did not ever run"
                if self.check(&TokenType::Ever) {
                    self.advance();
                }

                if self.check_verb() {
                    let verb = self.consume_verb();
                    let subject_term = self.noun_phrase_to_term(&subject);

                    // Check for NPI object first: "John did not see anything"
                    if self.check_npi_object() {
                        let npi_token = self.advance().kind.clone();
                        let obj_var = self.next_var_name();

                        let restriction_name = match npi_token {
                            TokenType::Anything => "Thing",
                            TokenType::Anyone => "Person",
                            _ => "Thing",
                        };

                        let restriction_sym = self.interner.intern(restriction_name);
                        let obj_restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: restriction_sym,
                            args: self.ctx.terms.alloc_slice([Term::Variable(obj_var)]),
                            world: None,
                        });

                        let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: verb,
                            args: self.ctx.terms.alloc_slice([subject_term.clone(), Term::Variable(obj_var)]),
                            world: None,
                        });

                        let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: obj_restriction,
                            op: TokenType::And,
                            right: verb_pred,
                        });

                        let quantified = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                            kind: QuantifierKind::Existential,
                            variable: obj_var,
                            body,
                            island_id: self.current_island,
                        });

                        let effective_time = self.pending_time.take().unwrap_or(Time::None);
                        let with_time = match effective_time {
                            Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                                operator: TemporalOperator::Past,
                                body: quantified,
                            }),
                            Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                                operator: TemporalOperator::Future,
                                body: quantified,
                            }),
                            _ => quantified,
                        };

                        self.negative_depth -= 1;
                        return Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                            op: TokenType::Not,
                            operand: with_time,
                        }));
                    }

                    // Check for quantifier object: "John did not see any dogs"
                    if self.check_quantifier() {
                        let quantifier_token = self.advance().kind.clone();
                        let object_np = self.parse_noun_phrase(false)?;
                        let obj_var = self.next_var_name();

                        let obj_restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: object_np.noun,
                            args: self.ctx.terms.alloc_slice([Term::Variable(obj_var)]),
                            world: None,
                        });

                        let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: verb,
                            args: self.ctx.terms.alloc_slice([subject_term.clone(), Term::Variable(obj_var)]),
                            world: None,
                        });

                        let (kind, body) = match quantifier_token {
                            TokenType::Any => {
                                if self.is_negative_context() {
                                    (
                                        QuantifierKind::Existential,
                                        self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                            left: obj_restriction,
                                            op: TokenType::And,
                                            right: verb_pred,
                                        }),
                                    )
                                } else {
                                    (
                                        QuantifierKind::Universal,
                                        self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                            left: obj_restriction,
                                            op: TokenType::If,
                                            right: verb_pred,
                                        }),
                                    )
                                }
                            }
                            TokenType::Some => (
                                QuantifierKind::Existential,
                                self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                    left: obj_restriction,
                                    op: TokenType::And,
                                    right: verb_pred,
                                }),
                            ),
                            TokenType::All => (
                                QuantifierKind::Universal,
                                self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                    left: obj_restriction,
                                    op: TokenType::If,
                                    right: verb_pred,
                                }),
                            ),
                            _ => (
                                QuantifierKind::Existential,
                                self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                    left: obj_restriction,
                                    op: TokenType::And,
                                    right: verb_pred,
                                }),
                            ),
                        };

                        let quantified = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                            kind,
                            variable: obj_var,
                            body,
                            island_id: self.current_island,
                        });

                        let effective_time = self.pending_time.take().unwrap_or(Time::None);
                        let with_time = match effective_time {
                            Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                                operator: TemporalOperator::Past,
                                body: quantified,
                            }),
                            Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                                operator: TemporalOperator::Future,
                                body: quantified,
                            }),
                            _ => quantified,
                        };

                        self.negative_depth -= 1;
                        return Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                            op: TokenType::Not,
                            operand: with_time,
                        }));
                    }

                    let mut roles: Vec<(ThematicRole, Term<'a>)> = vec![(ThematicRole::Agent, subject_term)];

                    // Add temporal modifier from pending_time
                    let effective_time = self.pending_time.take().unwrap_or(Time::None);
                    let mut modifiers: Vec<Symbol> = vec![];
                    match effective_time {
                        Time::Past => modifiers.push(self.interner.intern("Past")),
                        Time::Future => modifiers.push(self.interner.intern("Future")),
                        _ => {}
                    }

                    // Check for object
                    if self.check_content_word() || self.check_article() {
                        let object = self.parse_noun_phrase(false)?;
                        let object_term = self.noun_phrase_to_term(&object);
                        roles.push((ThematicRole::Theme, object_term));
                    }

                    let event_var = self.get_event_var();
                    let suppress_existential = self.drs.in_conditional_antecedent();
                    if suppress_existential {
                        let event_class = self.interner.intern("Event");
                        self.drs.introduce_referent(event_var, event_class, Gender::Neuter, Number::Singular);
                    }
                    let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                        event_var,
                        verb,
                        roles: self.ctx.roles.alloc_slice(roles),
                        modifiers: self.ctx.syms.alloc_slice(modifiers),
                        suppress_existential,
                        world: None,
                    })));

                    self.negative_depth -= 1;
                    return Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                        op: TokenType::Not,
                        operand: neo_event,
                    }));
                }

                self.negative_depth -= 1;
            }
            // Non-negated auxiliary: pending_time is set, fall through to normal verb handling
        }

        // Check for presupposition triggers: "stopped", "started", "regrets", "knows"
        // Factive verbs like "know" only trigger presupposition with clausal complements
        // "John knows that..." → presupposition, "John knows Mary" → regular verb
        // Only trigger presupposition if followed by a gerund (e.g., "stopped smoking")
        // "John stopped." alone should parse as intransitive verb, not presupposition
        if self.check_presup_trigger() && !self.is_followed_by_np_object() && self.is_followed_by_gerund() {
            let presup_kind = match self.advance().kind {
                TokenType::PresupTrigger(kind) => kind,
                TokenType::Verb { lemma, .. } => {
                    let s = self.interner.resolve(lemma).to_lowercase();
                    crate::lexicon::lookup_presup_trigger(&s)
                        .expect("Lexicon mismatch: Verb flagged as trigger but lookup failed")
                }
                _ => panic!("Expected presupposition trigger"),
            };
            return self.parse_presupposition(&subject, presup_kind);
        }

        // Handle bare plurals: "Birds fly." → Gen x. Bird(x) → Fly(x)
        let noun_str = self.interner.resolve(subject.noun);
        let is_bare_plural = subject.definiteness.is_none()
            && subject.possessor.is_none()
            && Self::is_plural_noun(noun_str)
            && self.check_verb();

        if is_bare_plural {
            let var_name = self.next_var_name();
            let (verb, verb_time, verb_aspect, _) = self.consume_verb_with_metadata();

            let type_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: subject.noun,
                args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                world: None,
            });

            let mut args = vec![Term::Variable(var_name)];
            if self.check_content_word() {
                let object = self.parse_noun_phrase(false)?;
                args.push(self.noun_phrase_to_term(&object));
            }

            let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice(args),
                world: None,
            });

            let effective_time = self.pending_time.take().unwrap_or(verb_time);
            let with_time = match effective_time {
                Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                    operator: TemporalOperator::Past,
                    body: verb_pred,
                }),
                Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                    operator: TemporalOperator::Future,
                    body: verb_pred,
                }),
                _ => verb_pred,
            };

            let with_aspect = if verb_aspect == Aspect::Progressive {
                self.ctx.exprs.alloc(LogicExpr::Aspectual {
                    operator: AspectOperator::Progressive,
                    body: with_time,
                })
            } else {
                with_time
            };

            let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: type_pred,
                op: TokenType::If,
                right: with_aspect,
            });

            return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                kind: QuantifierKind::Generic,
                variable: var_name,
                body,
                island_id: self.current_island,
            }));
        }

        // Handle do-support: "John does not exist" or "John does run"
        if self.check(&TokenType::Does) || self.check(&TokenType::Do) {
            self.advance(); // consume does/do
            let is_negated = self.match_token(&[TokenType::Not]);

            if self.check_verb() {
                let verb = self.consume_verb();
                let verb_lemma = self.interner.resolve(verb).to_lowercase();

                // Check for embedded wh-clause with negation: "I don't know who"
                if self.check_wh_word() {
                    let wh_token = self.advance().kind.clone();
                    let is_who = matches!(wh_token, TokenType::Who);
                    let is_what = matches!(wh_token, TokenType::What);

                    let is_sluicing = self.is_at_end() ||
                        self.check(&TokenType::Period) ||
                        self.check(&TokenType::Comma);

                    if is_sluicing {
                        if let Some(template) = self.last_event_template.clone() {
                            let wh_var = self.next_var_name();
                            let subject_term = self.noun_phrase_to_term(&subject);

                            let roles: Vec<_> = if is_who {
                                std::iter::once((ThematicRole::Agent, Term::Variable(wh_var)))
                                    .chain(template.non_agent_roles.iter().cloned())
                                    .collect()
                            } else if is_what {
                                vec![
                                    (ThematicRole::Agent, subject_term.clone()),
                                    (ThematicRole::Theme, Term::Variable(wh_var)),
                                ]
                            } else {
                                std::iter::once((ThematicRole::Agent, Term::Variable(wh_var)))
                                    .chain(template.non_agent_roles.iter().cloned())
                                    .collect()
                            };

                            let event_var = self.get_event_var();
                            let suppress_existential = self.drs.in_conditional_antecedent();
                            if suppress_existential {
                                let event_class = self.interner.intern("Event");
                                self.drs.introduce_referent(event_var, event_class, Gender::Neuter, Number::Singular);
                            }
                            let reconstructed = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                                event_var,
                                verb: template.verb,
                                roles: self.ctx.roles.alloc_slice(roles),
                                modifiers: self.ctx.syms.alloc_slice(template.modifiers.clone()),
                                suppress_existential,
                                world: None,
                            })));

                            let question = self.ctx.exprs.alloc(LogicExpr::Question {
                                wh_variable: wh_var,
                                body: reconstructed,
                            });

                            let know_event_var = self.get_event_var();
                            let suppress_existential2 = self.drs.in_conditional_antecedent();
                            if suppress_existential2 {
                                let event_class = self.interner.intern("Event");
                                self.drs.introduce_referent(know_event_var, event_class, Gender::Neuter, Number::Singular);
                            }
                            let know_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                                event_var: know_event_var,
                                verb,
                                roles: self.ctx.roles.alloc_slice(vec![
                                    (ThematicRole::Agent, subject_term),
                                    (ThematicRole::Theme, Term::Proposition(question)),
                                ]),
                                modifiers: self.ctx.syms.alloc_slice(vec![]),
                                suppress_existential: suppress_existential2,
                                world: None,
                            })));

                            let result = if is_negated {
                                self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                                    op: TokenType::Not,
                                    operand: know_event,
                                })
                            } else {
                                know_event
                            };

                            return self.wrap_with_definiteness_full(&subject, result);
                        }
                    }
                }

                // Special handling for "exist" with negation
                if verb_lemma == "exist" && is_negated {
                    // "The King of France does not exist" -> ¬∃x(KingOfFrance(x))
                    let var_name = self.next_var_name();
                    let restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: subject.noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                        world: None,
                    });
                    let exists = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                        kind: QuantifierKind::Existential,
                        variable: var_name,
                        body: restriction,
                        island_id: self.current_island,
                    });
                    return Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                        op: TokenType::Not,
                        operand: exists,
                    }));
                }

                // Regular do-support: "John does run" or "John does not run"
                let subject_term = self.noun_phrase_to_term(&subject);
                let roles: Vec<(ThematicRole, Term<'a>)> = vec![(ThematicRole::Agent, subject_term)];
                let modifiers: Vec<Symbol> = vec![];
                let event_var = self.get_event_var();
                let suppress_existential = self.drs.in_conditional_antecedent();
                if suppress_existential {
                    let event_class = self.interner.intern("Event");
                    self.drs.introduce_referent(event_var, event_class, Gender::Neuter, Number::Singular);
                }

                let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                    event_var,
                    verb,
                    roles: self.ctx.roles.alloc_slice(roles),
                    modifiers: self.ctx.syms.alloc_slice(modifiers),
                    suppress_existential,
                    world: None,
                })));

                if is_negated {
                    return Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                        op: TokenType::Not,
                        operand: neo_event,
                    }));
                }
                return Ok(neo_event);
            }
        }

        // Garden path detection: "The horse raced past the barn fell."
        // If we have a definite NP + past verb + more content + another verb,
        // try reduced relative interpretation
        // Skip if pending_time is set (auxiliary like "will" was just consumed)
        // Skip if verb is has/have/had (perfect aspect, not reduced relative)
        let is_perfect_aux = if self.check_verb() {
            let word = self.interner.resolve(self.peek().lexeme).to_lowercase();
            word == "has" || word == "have" || word == "had"
        } else {
            false
        };
        if subject.definiteness == Some(Definiteness::Definite) && self.check_verb() && self.pending_time.is_none() && !is_perfect_aux {
            let saved_pos = self.current;

            // Try parsing as reduced relative: first verb is modifier, look for main verb after
            if let Some(garden_path_result) = self.try_parse(|p| {
                let (modifier_verb, _modifier_time, _, _) = p.consume_verb_with_metadata();

                // Collect any PP modifiers on the reduced relative
                let mut pp_mods: Vec<&'a LogicExpr<'a>> = Vec::new();
                while p.check_preposition() {
                    let prep = if let TokenType::Preposition(prep) = p.advance().kind {
                        prep
                    } else {
                        break;
                    };
                    if p.check_article() || p.check_content_word() {
                        let pp_obj = p.parse_noun_phrase(false)?;
                        let pp_pred = p.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: prep,
                            args: p.ctx.terms.alloc_slice([Term::Variable(p.interner.intern("x")), Term::Constant(pp_obj.noun)]),
                            world: None,
                        });
                        pp_mods.push(pp_pred);
                    }
                }

                // Now check if there's ANOTHER verb (the real main verb)
                if !p.check_verb() {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedVerb { found: p.peek().kind.clone() },
                        span: p.current_span(),
                    });
                }

                let (main_verb, main_time, _, _) = p.consume_verb_with_metadata();

                // Build: ∃x((Horse(x) ∧ ∀y(Horse(y) → y=x)) ∧ Raced(x) ∧ Past(x, Barn) ∧ Fell(x))
                let var = p.interner.intern("x");

                // Type predicate
                let type_pred = p.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: subject.noun,
                    args: p.ctx.terms.alloc_slice([Term::Variable(var)]),
                    world: None,
                });

                // Modifier verb predicate (reduced relative)
                let mod_pred = p.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: modifier_verb,
                    args: p.ctx.terms.alloc_slice([Term::Variable(var)]),
                    world: None,
                });

                // Main verb predicate
                let main_pred = p.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: main_verb,
                    args: p.ctx.terms.alloc_slice([Term::Variable(var)]),
                    world: None,
                });

                // Combine type + modifier
                let mut body = p.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: type_pred,
                    op: TokenType::And,
                    right: mod_pred,
                });

                // Add PP modifiers
                for pp in pp_mods {
                    body = p.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: body,
                        op: TokenType::And,
                        right: pp,
                    });
                }

                // Add main predicate
                body = p.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: body,
                    op: TokenType::And,
                    right: main_pred,
                });

                // Wrap with temporal if needed
                let with_time = match main_time {
                    Time::Past => p.ctx.exprs.alloc(LogicExpr::Temporal {
                        operator: TemporalOperator::Past,
                        body,
                    }),
                    Time::Future => p.ctx.exprs.alloc(LogicExpr::Temporal {
                        operator: TemporalOperator::Future,
                        body,
                    }),
                    _ => body,
                };

                // Wrap in existential quantifier for definite
                Ok(p.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: var,
                    body: with_time,
                    island_id: p.current_island,
                }))
            }) {
                return Ok(garden_path_result);
            }

            // Restore position if garden path didn't work
            self.current = saved_pos;
        }

        if self.check_modal() {
            return self.parse_aspect_chain(subject.noun);
        }

        // Handle "has/have/had" perfect aspect: "John has run"
        if self.check_content_word() {
            let word = self.interner.resolve(self.peek().lexeme).to_lowercase();
            if word == "has" || word == "have" || word == "had" {
                // Lookahead to distinguish perfect aspect ("has eaten") from possession ("has 3 children")
                let is_perfect_aspect = if self.current + 1 < self.tokens.len() {
                    let next_token = &self.tokens[self.current + 1].kind;
                    matches!(
                        next_token,
                        TokenType::Verb { .. } | TokenType::Not
                    ) && !matches!(next_token, TokenType::Number(_))
                } else {
                    false
                };
                if is_perfect_aspect {
                    return self.parse_aspect_chain(subject.noun);
                }
                // Otherwise fall through to verb parsing below
            }
        }

        // Handle TokenType::Had for past perfect: "John had run"
        if self.check(&TokenType::Had) {
            return self.parse_aspect_chain(subject.noun);
        }

        // Handle "never" temporal negation: "John never runs"
        if self.check(&TokenType::Never) {
            self.advance();
            let verb = self.consume_verb();
            let subject_term = self.noun_phrase_to_term(&subject);
            let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice([subject_term]),
                world: None,
            });
            let result = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                op: TokenType::Not,
                operand: verb_pred,
            });
            return self.wrap_with_definiteness_full(&subject, result);
        }

        if self.check_verb() {
            let (mut verb, verb_time, verb_aspect, verb_class) = self.consume_verb_with_metadata();

            // Check for verb sort violation (metaphor detection)
            let subject_sort = lexicon::lookup_sort(self.interner.resolve(subject.noun));
            let verb_str = self.interner.resolve(verb);
            if let Some(s_sort) = subject_sort {
                if !crate::ontology::check_sort_compatibility(verb_str, s_sort) {
                    let metaphor = self.ctx.exprs.alloc(LogicExpr::Metaphor {
                        tenor: self.ctx.terms.alloc(Term::Constant(subject.noun)),
                        vehicle: self.ctx.terms.alloc(Term::Constant(verb)),
                    });
                    return self.wrap_with_definiteness(subject.definiteness, subject.noun, metaphor);
                }
            }

            // Check for control verb + infinitive
            if self.is_control_verb(verb) {
                return self.parse_control_structure(&subject, verb, verb_time);
            }

            // If we have a relative clause, use variable binding
            if let Some((var_name, rel_clause)) = relative_clause {
                let main_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                    world: None,
                });

                let effective_time = self.pending_time.take().unwrap_or(verb_time);
                let with_time = match effective_time {
                    Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                        operator: TemporalOperator::Past,
                        body: main_pred,
                    }),
                    Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                        operator: TemporalOperator::Future,
                        body: main_pred,
                    }),
                    _ => main_pred,
                };

                // Build: ∃x(Type(x) ∧ RelClause(x) ∧ MainPred(x))
                let type_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: subject.noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                    world: None,
                });

                let inner = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: type_pred,
                    op: TokenType::And,
                    right: rel_clause,
                });

                let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: inner,
                    op: TokenType::And,
                    right: with_time,
                });

                return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: var_name,
                    body,
                    island_id: self.current_island,
                }));
            }

            let subject_term = self.noun_phrase_to_term(&subject);
            let mut args = vec![subject_term.clone()];

            let unknown = self.interner.intern("?");

            // Check for embedded wh-clause: "I know who/what"
            if self.check_wh_word() {
                let wh_token = self.advance().kind.clone();

                // Determine wh-type for slot matching
                let is_who = matches!(wh_token, TokenType::Who);
                let is_what = matches!(wh_token, TokenType::What);

                // Check for sluicing: wh-word followed by terminator
                let is_sluicing = self.is_at_end() ||
                    self.check(&TokenType::Period) ||
                    self.check(&TokenType::Comma);

                if is_sluicing {
                    // Reconstruct from template
                    if let Some(template) = self.last_event_template.clone() {
                        let wh_var = self.next_var_name();

                        // Build roles with wh-variable in appropriate slot
                        let roles: Vec<_> = if is_who {
                            // "who" replaces Agent
                            std::iter::once((ThematicRole::Agent, Term::Variable(wh_var)))
                                .chain(template.non_agent_roles.iter().cloned())
                                .collect()
                        } else if is_what {
                            // "what" replaces Theme - use Agent from context, Theme is variable
                            vec![
                                (ThematicRole::Agent, subject_term.clone()),
                                (ThematicRole::Theme, Term::Variable(wh_var)),
                            ]
                        } else {
                            // Default: wh-variable as Agent
                            std::iter::once((ThematicRole::Agent, Term::Variable(wh_var)))
                                .chain(template.non_agent_roles.iter().cloned())
                                .collect()
                        };

                        let event_var = self.get_event_var();
                        let suppress_existential = self.drs.in_conditional_antecedent();
                        if suppress_existential {
                            let event_class = self.interner.intern("Event");
                            self.drs.introduce_referent(event_var, event_class, Gender::Neuter, Number::Singular);
                        }
                        let reconstructed = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                            event_var,
                            verb: template.verb,
                            roles: self.ctx.roles.alloc_slice(roles),
                            modifiers: self.ctx.syms.alloc_slice(template.modifiers.clone()),
                            suppress_existential,
                            world: None,
                        })));

                        let question = self.ctx.exprs.alloc(LogicExpr::Question {
                            wh_variable: wh_var,
                            body: reconstructed,
                        });

                        // Build: Know(subject, question)
                        let know_event_var = self.get_event_var();
                        let suppress_existential2 = self.drs.in_conditional_antecedent();
                        if suppress_existential2 {
                            let event_class = self.interner.intern("Event");
                            self.drs.introduce_referent(know_event_var, event_class, Gender::Neuter, Number::Singular);
                        }
                        let know_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                            event_var: know_event_var,
                            verb,
                            roles: self.ctx.roles.alloc_slice(vec![
                                (ThematicRole::Agent, subject_term),
                                (ThematicRole::Theme, Term::Proposition(question)),
                            ]),
                            modifiers: self.ctx.syms.alloc_slice(vec![]),
                            suppress_existential: suppress_existential2,
                            world: None,
                        })));

                        return self.wrap_with_definiteness_full(&subject, know_event);
                    }
                }

                // Non-sluicing embedded question: "I know who runs"
                let embedded = self.parse_embedded_wh_clause()?;
                let question = self.ctx.exprs.alloc(LogicExpr::Question {
                    wh_variable: self.interner.intern("x"),
                    body: embedded,
                });

                // Build: Know(subject, question)
                let know_event_var = self.get_event_var();
                let suppress_existential = self.drs.in_conditional_antecedent();
                if suppress_existential {
                    let event_class = self.interner.intern("Event");
                    self.drs.introduce_referent(know_event_var, event_class, Gender::Neuter, Number::Singular);
                }
                let know_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                    event_var: know_event_var,
                    verb,
                    roles: self.ctx.roles.alloc_slice(vec![
                        (ThematicRole::Agent, subject_term),
                        (ThematicRole::Theme, Term::Proposition(question)),
                    ]),
                    modifiers: self.ctx.syms.alloc_slice(vec![]),
                    suppress_existential,
                    world: None,
                })));

                return self.wrap_with_definiteness_full(&subject, know_event);
            }

            let mut object_term: Option<Term<'a>> = None;
            let mut second_object_term: Option<Term<'a>> = None;
            let mut object_superlative: Option<(Symbol, Symbol)> = None; // (adjective, noun)
            if self.check(&TokenType::Reflexive) {
                self.advance();
                let term = self.noun_phrase_to_term(&subject);
                object_term = Some(term.clone());
                args.push(term);

                // Check for distanced phrasal verb particle: "gave himself up"
                if let TokenType::Particle(particle_sym) = self.peek().kind {
                    let verb_str = self.interner.resolve(verb).to_lowercase();
                    let particle_str = self.interner.resolve(particle_sym).to_lowercase();
                    if let Some((phrasal_lemma, _class)) = crate::lexicon::lookup_phrasal_verb(&verb_str, &particle_str) {
                        self.advance();
                        verb = self.interner.intern(phrasal_lemma);
                    }
                }
            } else if self.check_pronoun() {
                let token = self.advance().clone();
                if let TokenType::Pronoun { gender, number, .. } = token.kind {
                    let resolved = self.resolve_pronoun(gender, number)?;
                    let term = match resolved {
                        ResolvedPronoun::Variable(s) => Term::Variable(s),
                        ResolvedPronoun::Constant(s) => Term::Constant(s),
                    };
                    object_term = Some(term.clone());
                    args.push(term);

                    // Check for distanced phrasal verb particle: "gave it up"
                    if let TokenType::Particle(particle_sym) = self.peek().kind {
                        let verb_str = self.interner.resolve(verb).to_lowercase();
                        let particle_str = self.interner.resolve(particle_sym).to_lowercase();
                        if let Some((phrasal_lemma, _class)) = crate::lexicon::lookup_phrasal_verb(&verb_str, &particle_str) {
                            self.advance();
                            verb = self.interner.intern(phrasal_lemma);
                        }
                    }
                }
            } else if self.check_quantifier() || self.check_article() {
                // Quantified object: "John loves every woman" or "John saw a dog"
                let (obj_quantifier, was_definite_article) = if self.check_quantifier() {
                    (Some(self.advance().kind.clone()), false)
                } else {
                    let art = self.advance().kind.clone();
                    if let TokenType::Article(def) = art {
                        if def == Definiteness::Indefinite {
                            (Some(TokenType::Some), false)
                        } else {
                            (None, true)  // Was a definite article
                        }
                    } else {
                        (None, false)
                    }
                };

                let object_np = self.parse_noun_phrase(false)?;

                // Capture superlative info for constraint generation
                if let Some(adj) = object_np.superlative {
                    object_superlative = Some((adj, object_np.noun));
                }

                // Check for distanced phrasal verb particle: "gave the book up"
                if let TokenType::Particle(particle_sym) = self.peek().kind {
                    let verb_str = self.interner.resolve(verb).to_lowercase();
                    let particle_str = self.interner.resolve(particle_sym).to_lowercase();
                    if let Some((phrasal_lemma, _class)) = crate::lexicon::lookup_phrasal_verb(&verb_str, &particle_str) {
                        self.advance(); // consume the particle
                        verb = self.interner.intern(phrasal_lemma);
                    }
                }

                if let Some(obj_q) = obj_quantifier {
                    // Check for opaque verb with indefinite object (de dicto reading)
                    // For verbs like "seek", "want", "believe" with indefinite objects,
                    // use Term::Intension to represent the intensional (concept) reading
                    let verb_str = self.interner.resolve(verb).to_lowercase();
                    let is_opaque = lexicon::lookup_verb_db(&verb_str)
                        .map(|meta| meta.features.contains(&lexicon::Feature::Opaque))
                        .unwrap_or(false);

                    if is_opaque && matches!(obj_q, TokenType::Some) {
                        // De dicto reading: use Term::Intension for the theme
                        let intension_term = Term::Intension(object_np.noun);

                        // Register intensional entity for anaphora resolution
                        let event_var = self.get_event_var();
                        let mut modifiers = self.collect_adverbs();
                        let effective_time = self.pending_time.take().unwrap_or(verb_time);
                        match effective_time {
                            Time::Past => modifiers.push(self.interner.intern("Past")),
                            Time::Future => modifiers.push(self.interner.intern("Future")),
                            _ => {}
                        }

                        let subject_term_for_event = self.noun_phrase_to_term(&subject);
                        let roles = vec![
                            (ThematicRole::Agent, subject_term_for_event),
                            (ThematicRole::Theme, intension_term),
                        ];

                        let suppress_existential = self.drs.in_conditional_antecedent();
                        if suppress_existential {
                            let event_class = self.interner.intern("Event");
                            self.drs.introduce_referent(event_var, event_class, Gender::Neuter, Number::Singular);
                        }
                        let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                            event_var,
                            verb,
                            roles: self.ctx.roles.alloc_slice(roles),
                            modifiers: self.ctx.syms.alloc_slice(modifiers),
                            suppress_existential,
                            world: None,
                        })));

                        return self.wrap_with_definiteness_full(&subject, neo_event);
                    }

                    let obj_var = self.next_var_name();

                    // Introduce object referent in DRS for cross-sentence anaphora
                    let obj_gender = Self::infer_noun_gender(self.interner.resolve(object_np.noun));
                    let obj_number = if Self::is_plural_noun(self.interner.resolve(object_np.noun)) {
                        Number::Plural
                    } else {
                        Number::Singular
                    };
                    self.drs.introduce_referent(obj_var, object_np.noun, obj_gender, obj_number);

                    let type_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: object_np.noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(obj_var)]),
                        world: None,
                    });

                    let obj_restriction = if self.check(&TokenType::That) || self.check(&TokenType::Who) {
                        self.advance();
                        let rel_clause = self.parse_relative_clause(obj_var)?;
                        self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: type_pred,
                            op: TokenType::And,
                            right: rel_clause,
                        })
                    } else {
                        type_pred
                    };

                    let event_var = self.get_event_var();
                    let mut modifiers = self.collect_adverbs();
                    let effective_time = self.pending_time.take().unwrap_or(verb_time);
                    match effective_time {
                        Time::Past => modifiers.push(self.interner.intern("Past")),
                        Time::Future => modifiers.push(self.interner.intern("Future")),
                        _ => {}
                    }

                    let subject_term_for_event = self.noun_phrase_to_term(&subject);
                    let roles = vec![
                        (ThematicRole::Agent, subject_term_for_event),
                        (ThematicRole::Theme, Term::Variable(obj_var)),
                    ];

                    // Capture template with object type for ellipsis reconstruction
                    // Use the object noun type instead of variable for reconstruction
                    let template_roles = vec![
                        (ThematicRole::Agent, subject_term_for_event),
                        (ThematicRole::Theme, Term::Constant(object_np.noun)),
                    ];
                    self.capture_event_template(verb, &template_roles, &modifiers);

                    let suppress_existential = self.drs.in_conditional_antecedent();
                    if suppress_existential {
                        let event_class = self.interner.intern("Event");
                        self.drs.introduce_referent(event_var, event_class, Gender::Neuter, Number::Singular);
                    }
                    let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                        event_var,
                        verb,
                        roles: self.ctx.roles.alloc_slice(roles),
                        modifiers: self.ctx.syms.alloc_slice(modifiers),
                        suppress_existential,
                        world: None,
                    })));

                    let obj_kind = match obj_q {
                        TokenType::All => QuantifierKind::Universal,
                        TokenType::Some => QuantifierKind::Existential,
                        TokenType::No => QuantifierKind::Universal,
                        TokenType::Most => QuantifierKind::Most,
                        TokenType::Few => QuantifierKind::Few,
                        TokenType::Many => QuantifierKind::Many,
                        TokenType::Cardinal(n) => QuantifierKind::Cardinal(n),
                        TokenType::AtLeast(n) => QuantifierKind::AtLeast(n),
                        TokenType::AtMost(n) => QuantifierKind::AtMost(n),
                        _ => QuantifierKind::Existential,
                    };

                    let obj_body = match obj_q {
                        TokenType::All => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: obj_restriction,
                            op: TokenType::If,
                            right: neo_event,
                        }),
                        TokenType::No => {
                            let neg = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                                op: TokenType::Not,
                                operand: neo_event,
                            });
                            self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                left: obj_restriction,
                                op: TokenType::If,
                                right: neg,
                            })
                        }
                        _ => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: obj_restriction,
                            op: TokenType::And,
                            right: neo_event,
                        }),
                    };

                    // Wrap object with its quantifier
                    let obj_quantified = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                        kind: obj_kind,
                        variable: obj_var,
                        body: obj_body,
                        island_id: self.current_island,
                    });

                    // Now wrap the SUBJECT (don't skip it with early return!)
                    return self.wrap_with_definiteness_full(&subject, obj_quantified);
                } else {
                    // Definite object NP (e.g., "the house")
                    // Introduce to DRS for cross-sentence bridging anaphora
                    // E.g., "John entered the house. The door was open." - door bridges to house
                    // Note: was_definite_article is true because the article was consumed before parse_noun_phrase
                    if was_definite_article {
                        let obj_gender = Self::infer_noun_gender(self.interner.resolve(object_np.noun));
                        let obj_number = if Self::is_plural_noun(self.interner.resolve(object_np.noun)) {
                            Number::Plural
                        } else {
                            Number::Singular
                        };
                        self.drs.introduce_referent(object_np.noun, object_np.noun, obj_gender, obj_number);
                    }

                    let term = self.noun_phrase_to_term(&object_np);
                    object_term = Some(term.clone());
                    args.push(term);
                }
            } else if self.check_focus() {
                let focus_kind = if let TokenType::Focus(k) = self.advance().kind {
                    k
                } else {
                    FocusKind::Only
                };

                let event_var = self.get_event_var();
                let mut modifiers = self.collect_adverbs();
                let effective_time = self.pending_time.take().unwrap_or(verb_time);
                match effective_time {
                    Time::Past => modifiers.push(self.interner.intern("Past")),
                    Time::Future => modifiers.push(self.interner.intern("Future")),
                    _ => {}
                }

                let subject_term_for_event = self.noun_phrase_to_term(&subject);

                if self.check_preposition() {
                    let prep_token = self.advance().clone();
                    let prep_name = if let TokenType::Preposition(sym) = prep_token.kind {
                        sym
                    } else {
                        self.interner.intern("to")
                    };
                    let pp_obj = self.parse_noun_phrase(false)?;
                    let pp_obj_term = Term::Constant(pp_obj.noun);

                    let roles = vec![(ThematicRole::Agent, subject_term_for_event)];
                    let suppress_existential = self.drs.in_conditional_antecedent();
                    if suppress_existential {
                        let event_class = self.interner.intern("Event");
                        self.drs.introduce_referent(event_var, event_class, Gender::Neuter, Number::Singular);
                    }
                    let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                        event_var,
                        verb,
                        roles: self.ctx.roles.alloc_slice(roles),
                        modifiers: self.ctx.syms.alloc_slice(modifiers),
                        suppress_existential,
                        world: None,
                    })));

                    let pp_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: prep_name,
                        args: self.ctx.terms.alloc_slice([Term::Variable(event_var), pp_obj_term]),
                        world: None,
                    });

                    let with_pp = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: neo_event,
                        op: TokenType::And,
                        right: pp_pred,
                    });

                    let focused_ref = self.ctx.terms.alloc(pp_obj_term);
                    return Ok(self.ctx.exprs.alloc(LogicExpr::Focus {
                        kind: focus_kind,
                        focused: focused_ref,
                        scope: with_pp,
                    }));
                }

                let focused_np = self.parse_noun_phrase(false)?;
                let focused_term = self.noun_phrase_to_term(&focused_np);
                args.push(focused_term.clone());

                let roles = vec![
                    (ThematicRole::Agent, subject_term_for_event),
                    (ThematicRole::Theme, focused_term.clone()),
                ];

                let suppress_existential = self.drs.in_conditional_antecedent();
                if suppress_existential {
                    let event_class = self.interner.intern("Event");
                    self.drs.introduce_referent(event_var, event_class, Gender::Neuter, Number::Singular);
                }
                let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                    event_var,
                    verb,
                    roles: self.ctx.roles.alloc_slice(roles),
                    modifiers: self.ctx.syms.alloc_slice(modifiers),
                    suppress_existential,
                    world: None,
                })));

                let focused_ref = self.ctx.terms.alloc(focused_term);
                return Ok(self.ctx.exprs.alloc(LogicExpr::Focus {
                    kind: focus_kind,
                    focused: focused_ref,
                    scope: neo_event,
                }));
            } else if self.check_number() {
                // Handle "has 3 children" or "has cardinality aleph_0"
                let measure = self.parse_measure_phrase()?;

                // If there's a noun after the measure (for "3 children" where children wasn't a unit)
                if self.check_content_word() {
                    let noun_sym = self.consume_content_word()?;
                    // Build: Has(Subject, 3, Children) where 3 is the count
                    let count_term = *measure;
                    object_term = Some(count_term.clone());
                    args.push(count_term);
                    second_object_term = Some(Term::Constant(noun_sym));
                    args.push(Term::Constant(noun_sym));
                } else {
                    // Just the measure: "has cardinality 5"
                    object_term = Some(*measure);
                    args.push(*measure);
                }
            } else if self.check_content_word() || self.check_article() {
                let object = self.parse_noun_phrase(false)?;
                if let Some(adj) = object.superlative {
                    object_superlative = Some((adj, object.noun));
                }

                // Collect all objects for potential "respectively" handling
                let mut all_objects: Vec<Symbol> = vec![object.noun];

                // Check for coordinated objects: "Tom and Jerry and Bob"
                while self.check(&TokenType::And) {
                    let saved = self.current;
                    self.advance(); // consume "and"
                    if self.check_content_word() || self.check_article() {
                        let next_obj = match self.parse_noun_phrase(false) {
                            Ok(np) => np,
                            Err(_) => {
                                self.current = saved;
                                break;
                            }
                        };
                        all_objects.push(next_obj.noun);
                    } else {
                        self.current = saved;
                        break;
                    }
                }

                // Check for "respectively" with single subject
                if self.check(&TokenType::Respectively) {
                    let respectively_span = self.peek().span;
                    // Single subject with multiple objects + respectively = error
                    if all_objects.len() > 1 {
                        return Err(ParseError {
                            kind: ParseErrorKind::RespectivelyLengthMismatch {
                                subject_count: 1,
                                object_count: all_objects.len(),
                            },
                            span: respectively_span,
                        });
                    }
                    // Single subject, single object + respectively is valid (trivially pairwise)
                    self.advance(); // consume "respectively"
                }

                // Use the first object (or only object) for normal processing
                let term = self.noun_phrase_to_term(&object);
                object_term = Some(term.clone());
                args.push(term.clone());

                // For multiple objects without "respectively", use group semantics
                if all_objects.len() > 1 {
                    let obj_members: Vec<Term<'a>> = all_objects.iter()
                        .map(|o| Term::Constant(*o))
                        .collect();
                    let obj_group = Term::Group(self.ctx.terms.alloc_slice(obj_members));
                    // Replace the single object with the group
                    args.pop();
                    args.push(obj_group);
                }

                // Check for distanced phrasal verb particle: "gave the book up"
                if let TokenType::Particle(particle_sym) = self.peek().kind {
                    let verb_str = self.interner.resolve(verb).to_lowercase();
                    let particle_str = self.interner.resolve(particle_sym).to_lowercase();
                    if let Some((phrasal_lemma, _class)) = crate::lexicon::lookup_phrasal_verb(&verb_str, &particle_str) {
                        self.advance(); // consume the particle
                        verb = self.interner.intern(phrasal_lemma);
                    }
                }

                // Check for "has cardinality aleph_0" pattern: noun followed by number
                if self.check_number() {
                    let measure = self.parse_measure_phrase()?;
                    second_object_term = Some(*measure);
                    args.push(*measure);
                }
                // Check for ditransitive: "John gave Mary a book"
                else {
                    let verb_str = self.interner.resolve(verb);
                    if Lexer::is_ditransitive_verb(verb_str) && (self.check_content_word() || self.check_article()) {
                        let second_np = self.parse_noun_phrase(false)?;
                        let second_term = self.noun_phrase_to_term(&second_np);
                        second_object_term = Some(second_term.clone());
                        args.push(second_term);
                    }
                }
            }

            let mut pp_predicates: Vec<&'a LogicExpr<'a>> = Vec::new();
            while self.check_preposition() || self.check_to() {
                let prep_token = self.advance().clone();
                let prep_name = if let TokenType::Preposition(sym) = prep_token.kind {
                    sym
                } else if matches!(prep_token.kind, TokenType::To) {
                    self.interner.intern("To")
                } else {
                    continue;
                };

                let pp_obj_term = if self.check(&TokenType::Reflexive) {
                    self.advance();
                    self.noun_phrase_to_term(&subject)
                } else if self.check_pronoun() {
                    let token = self.advance().clone();
                    if let TokenType::Pronoun { gender, number, .. } = token.kind {
                        let resolved = self.resolve_pronoun(gender, number)?;
                        match resolved {
                            ResolvedPronoun::Variable(s) => Term::Variable(s),
                            ResolvedPronoun::Constant(s) => Term::Constant(s),
                        }
                    } else {
                        continue;
                    }
                } else if self.check_content_word() || self.check_article() {
                    let prep_obj = self.parse_noun_phrase(false)?;
                    self.noun_phrase_to_term(&prep_obj)
                } else {
                    continue;
                };

                if self.pp_attach_to_noun {
                    if let Some(ref obj) = object_term {
                        // NP-attachment: PP modifies the object noun
                        let pp_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: prep_name,
                            args: self.ctx.terms.alloc_slice([obj.clone(), pp_obj_term]),
                            world: None,
                        });
                        pp_predicates.push(pp_pred);
                    } else {
                        args.push(pp_obj_term);
                    }
                } else {
                    // VP-attachment: PP modifies the event (instrument/manner)
                    let event_sym = self.get_event_var();
                    let pp_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: prep_name,
                        args: self.ctx.terms.alloc_slice([Term::Variable(event_sym), pp_obj_term]),
                        world: None,
                    });
                    pp_predicates.push(pp_pred);
                }
            }

            // Check for trailing relative clause on object NP: "the girl with the telescope that laughed"
            if self.check(&TokenType::That) || self.check(&TokenType::Who) {
                self.advance();
                let rel_var = self.next_var_name();
                let rel_pred = self.parse_relative_clause(rel_var)?;
                pp_predicates.push(rel_pred);
            }

            // Collect any trailing adverbs FIRST (before building NeoEvent)
            let mut modifiers = self.collect_adverbs();

            // Add temporal modifier as part of event semantics
            let effective_time = self.pending_time.take().unwrap_or(verb_time);
            match effective_time {
                Time::Past => modifiers.push(self.interner.intern("Past")),
                Time::Future => modifiers.push(self.interner.intern("Future")),
                _ => {}
            }

            // Add aspect modifier if applicable
            if verb_aspect == Aspect::Progressive {
                modifiers.push(self.interner.intern("Progressive"));
            } else if verb_aspect == Aspect::Perfect {
                modifiers.push(self.interner.intern("Perfect"));
            }

            // Build thematic roles for Neo-Davidsonian event semantics
            let mut roles: Vec<(ThematicRole, Term<'a>)> = Vec::new();

            // Check if verb is unaccusative (intransitive subject is Theme, not Agent)
            let verb_str_for_check = self.interner.resolve(verb).to_lowercase();
            let is_unaccusative = crate::lexicon::lookup_verb_db(&verb_str_for_check)
                .map(|meta| meta.features.contains(&crate::lexicon::Feature::Unaccusative))
                .unwrap_or(false);

            // Unaccusative verbs used intransitively: subject is Theme
            let has_object = object_term.is_some() || second_object_term.is_some();
            let subject_role = if is_unaccusative && !has_object {
                ThematicRole::Theme
            } else {
                ThematicRole::Agent
            };

            roles.push((subject_role, subject_term));
            if let Some(second_obj) = second_object_term {
                // Ditransitive: first object is Recipient, second is Theme
                if let Some(first_obj) = object_term {
                    roles.push((ThematicRole::Recipient, first_obj));
                }
                roles.push((ThematicRole::Theme, second_obj));
            } else if let Some(obj) = object_term {
                // Normal transitive: object is Theme
                roles.push((ThematicRole::Theme, obj));
            }

            // Create event variable
            let event_var = self.get_event_var();

            // Capture template for ellipsis reconstruction before consuming roles
            self.capture_event_template(verb, &roles, &modifiers);

            // Create NeoEvent structure with all modifiers including time/aspect
            let suppress_existential = self.drs.in_conditional_antecedent();
            if suppress_existential {
                let event_class = self.interner.intern("Event");
                self.drs.introduce_referent(event_var, event_class, Gender::Neuter, Number::Singular);
            }
            let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                event_var,
                verb,
                roles: self.ctx.roles.alloc_slice(roles),
                modifiers: self.ctx.syms.alloc_slice(modifiers),
                suppress_existential,
                world: None,
            })));

            // Combine with PP predicates if any
            let with_pps = if pp_predicates.is_empty() {
                neo_event
            } else {
                let mut combined = neo_event;
                for pp in pp_predicates {
                    combined = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: combined,
                        op: TokenType::And,
                        right: pp,
                    });
                }
                combined
            };

            // Apply aspectual operators based on verb class
            let with_aspect = if verb_aspect == Aspect::Progressive {
                // Semelfactive + Progressive → Iterative
                if verb_class == crate::lexicon::VerbClass::Semelfactive {
                    self.ctx.exprs.alloc(LogicExpr::Aspectual {
                        operator: AspectOperator::Iterative,
                        body: with_pps,
                    })
                } else {
                    // Other verbs + Progressive → Progressive
                    self.ctx.exprs.alloc(LogicExpr::Aspectual {
                        operator: AspectOperator::Progressive,
                        body: with_pps,
                    })
                }
            } else if verb_aspect == Aspect::Perfect {
                self.ctx.exprs.alloc(LogicExpr::Aspectual {
                    operator: AspectOperator::Perfect,
                    body: with_pps,
                })
            } else if effective_time == Time::Present && verb_aspect == Aspect::Simple {
                // Non-state verbs in simple present get Habitual reading
                if !verb_class.is_stative() {
                    self.ctx.exprs.alloc(LogicExpr::Aspectual {
                        operator: AspectOperator::Habitual,
                        body: with_pps,
                    })
                } else {
                    // State verbs in present: direct predication
                    with_pps
                }
            } else {
                with_pps
            };

            let with_adverbs = with_aspect;

            // Check for temporal anchor adverb at end of sentence
            let with_temporal = if self.check_temporal_adverb() {
                let anchor = if let TokenType::TemporalAdverb(adv) = self.advance().kind.clone() {
                    adv
                } else {
                    panic!("Expected temporal adverb");
                };
                self.ctx.exprs.alloc(LogicExpr::TemporalAnchor {
                    anchor,
                    body: with_adverbs,
                })
            } else {
                with_adverbs
            };

            let wrapped = self.wrap_with_definiteness_full(&subject, with_temporal)?;

            // Add superlative constraint for object NP if applicable
            if let Some((adj, noun)) = object_superlative {
                let superlative_expr = self.ctx.exprs.alloc(LogicExpr::Superlative {
                    adjective: adj,
                    subject: self.ctx.terms.alloc(Term::Constant(noun)),
                    domain: noun,
                });
                return Ok(self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: wrapped,
                    op: TokenType::And,
                    right: superlative_expr,
                }));
            }

            return Ok(wrapped);
        }

        Ok(self.ctx.exprs.alloc(LogicExpr::Atom(subject.noun)))
    }

    fn check_preposition(&self) -> bool {
        matches!(self.peek().kind, TokenType::Preposition(_))
    }

    fn check_by_preposition(&self) -> bool {
        if let TokenType::Preposition(p) = self.peek().kind {
            p.is(self.interner, "by")
        } else {
            false
        }
    }

    fn check_preposition_is(&self, word: &str) -> bool {
        if let TokenType::Preposition(p) = self.peek().kind {
            p.is(self.interner, word)
        } else {
            false
        }
    }

    /// Check if current token is a word (noun/adj/verb lexeme) matching the given string
    fn check_word(&self, word: &str) -> bool {
        let token = self.peek();
        let lexeme = self.interner.resolve(token.lexeme);
        lexeme.eq_ignore_ascii_case(word)
    }

    fn check_to_preposition(&self) -> bool {
        match self.peek().kind {
            TokenType::To => true,
            TokenType::Preposition(p) => p.is(self.interner, "to"),
            _ => false,
        }
    }

    fn check_content_word(&self) -> bool {
        match &self.peek().kind {
            TokenType::Noun(_)
            | TokenType::Adjective(_)
            | TokenType::NonIntersectiveAdjective(_)
            | TokenType::Verb { .. }
            | TokenType::ProperName(_)
            | TokenType::Article(_) => true,
            TokenType::Ambiguous { primary, alternatives } => {
                Self::is_content_word_type(primary)
                    || alternatives.iter().any(Self::is_content_word_type)
            }
            _ => false,
        }
    }

    fn is_content_word_type(t: &TokenType) -> bool {
        matches!(
            t,
            TokenType::Noun(_)
                | TokenType::Adjective(_)
                | TokenType::NonIntersectiveAdjective(_)
                | TokenType::Verb { .. }
                | TokenType::ProperName(_)
                | TokenType::Article(_)
        )
    }

    fn check_verb(&self) -> bool {
        match &self.peek().kind {
            TokenType::Verb { .. } => true,
            TokenType::Ambiguous { primary, alternatives } => {
                if self.noun_priority_mode {
                    return false;
                }
                matches!(**primary, TokenType::Verb { .. })
                    || alternatives.iter().any(|t| matches!(t, TokenType::Verb { .. }))
            }
            _ => false,
        }
    }

    fn check_adverb(&self) -> bool {
        matches!(self.peek().kind, TokenType::Adverb(_))
    }

    fn check_performative(&self) -> bool {
        matches!(self.peek().kind, TokenType::Performative(_))
    }

    fn collect_adverbs(&mut self) -> Vec<Symbol> {
        let mut adverbs = Vec::new();
        while self.check_adverb() {
            if let TokenType::Adverb(adv) = self.advance().kind.clone() {
                adverbs.push(adv);
            }
            // Skip "and" between adverbs
            if self.check(&TokenType::And) {
                self.advance();
            }
        }
        adverbs
    }

    fn check_auxiliary(&self) -> bool {
        matches!(self.peek().kind, TokenType::Auxiliary(_))
    }

    fn check_to(&self) -> bool {
        matches!(self.peek().kind, TokenType::To)
    }


    fn consume_verb(&mut self) -> Symbol {
        let t = self.advance().clone();
        match t.kind {
            TokenType::Verb { lemma, .. } => lemma,
            TokenType::Ambiguous { primary, .. } => match *primary {
                TokenType::Verb { lemma, .. } => lemma,
                _ => panic!("Expected verb in Ambiguous primary, got {:?}", primary),
            },
            _ => panic!("Expected verb, got {:?}", t.kind),
        }
    }

    fn consume_verb_with_metadata(&mut self) -> (Symbol, Time, Aspect, VerbClass) {
        let t = self.advance().clone();
        match t.kind {
            TokenType::Verb { lemma, time, aspect, class } => (lemma, time, aspect, class),
            TokenType::Ambiguous { primary, .. } => match *primary {
                TokenType::Verb { lemma, time, aspect, class } => (lemma, time, aspect, class),
                _ => panic!("Expected verb in Ambiguous primary, got {:?}", primary),
            },
            _ => panic!("Expected verb, got {:?}", t.kind),
        }
    }

    fn match_token(&mut self, types: &[TokenType]) -> bool {
        for t in types {
            if self.check(t) {
                self.advance();
                return true;
            }
        }
        false
    }

    fn check_quantifier(&self) -> bool {
        matches!(
            self.peek().kind,
            TokenType::All
                | TokenType::No
                | TokenType::Some
                | TokenType::Any
                | TokenType::Most
                | TokenType::Few
                | TokenType::Many
                | TokenType::Cardinal(_)
                | TokenType::AtLeast(_)
                | TokenType::AtMost(_)
        )
    }

    fn check_npi_quantifier(&self) -> bool {
        matches!(
            self.peek().kind,
            TokenType::Nobody | TokenType::Nothing | TokenType::NoOne
        )
    }

    fn check_npi_object(&self) -> bool {
        matches!(
            self.peek().kind,
            TokenType::Anything | TokenType::Anyone
        )
    }

    fn check_temporal_npi(&self) -> bool {
        matches!(
            self.peek().kind,
            TokenType::Ever | TokenType::Never
        )
    }

    fn parse_npi_quantified(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let npi_token = self.advance().kind.clone();
        let var_name = self.next_var_name();

        let (restriction_name, is_person) = match npi_token {
            TokenType::Nobody | TokenType::NoOne => ("Person", true),
            TokenType::Nothing => ("Thing", false),
            _ => ("Thing", false),
        };

        let restriction_sym = self.interner.intern(restriction_name);
        let subject_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
            name: restriction_sym,
            args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
            world: None,
        });

        self.negative_depth += 1;

        let verb = self.consume_verb();

        if self.check_npi_object() {
            let obj_npi_token = self.advance().kind.clone();
            let obj_var = self.next_var_name();

            let obj_restriction_name = match obj_npi_token {
                TokenType::Anything => "Thing",
                TokenType::Anyone => "Person",
                _ => "Thing",
            };

            let obj_restriction_sym = self.interner.intern(obj_restriction_name);
            let obj_restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: obj_restriction_sym,
                args: self.ctx.terms.alloc_slice([Term::Variable(obj_var)]),
                world: None,
            });

            let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice([Term::Variable(var_name), Term::Variable(obj_var)]),
                world: None,
            });

            let verb_and_obj = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: obj_restriction,
                op: TokenType::And,
                right: verb_pred,
            });

            let inner_existential = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                kind: crate::ast::QuantifierKind::Existential,
                variable: obj_var,
                body: verb_and_obj,
                island_id: self.current_island,
            });

            self.negative_depth -= 1;

            let negated = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                op: TokenType::Not,
                operand: inner_existential,
            });

            let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: subject_pred,
                op: TokenType::If,
                right: negated,
            });

            return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                kind: crate::ast::QuantifierKind::Universal,
                variable: var_name,
                body,
                island_id: self.current_island,
            }));
        }

        let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
            name: verb,
            args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
            world: None,
        });

        self.negative_depth -= 1;

        let negated_verb = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
            op: TokenType::Not,
            operand: verb_pred,
        });

        let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
            left: subject_pred,
            op: TokenType::If,
            right: negated_verb,
        });

        Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
            kind: crate::ast::QuantifierKind::Universal,
            variable: var_name,
            body,
            island_id: self.current_island,
        }))
    }

    fn parse_temporal_npi(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let npi_token = self.advance().kind.clone();
        let is_never = matches!(npi_token, TokenType::Never);

        let subject = self.parse_noun_phrase(true)?;

        if is_never {
            self.negative_depth += 1;
        }

        let verb = self.consume_verb();
        let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
            name: verb,
            args: self.ctx.terms.alloc_slice([Term::Constant(subject.noun)]),
            world: None,
        });

        if is_never {
            self.negative_depth -= 1;
            Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                op: TokenType::Not,
                operand: verb_pred,
            }))
        } else {
            Ok(verb_pred)
        }
    }

    fn check(&self, kind: &TokenType) -> bool {
        if self.is_at_end() {
            return false;
        }
        std::mem::discriminant(&self.peek().kind) == std::mem::discriminant(kind)
    }

    fn check_any(&self, kinds: &[TokenType]) -> bool {
        if self.is_at_end() {
            return false;
        }
        let current = std::mem::discriminant(&self.peek().kind);
        kinds.iter().any(|k| std::mem::discriminant(k) == current)
    }

    fn check_article(&self) -> bool {
        matches!(self.peek().kind, TokenType::Article(_))
    }

    fn advance(&mut self) -> &Token {
        if !self.is_at_end() {
            self.current += 1;
        }
        self.previous()
    }

    fn is_at_end(&self) -> bool {
        self.peek().kind == TokenType::EOF
    }

    fn peek(&self) -> &Token {
        &self.tokens[self.current]
    }

    /// Phase 35: Check if the next token (after current) is a string literal.
    /// Used to distinguish causal `because` from Trust's `because "reason"`.
    fn peek_next_is_string_literal(&self) -> bool {
        self.tokens.get(self.current + 1)
            .map(|t| matches!(t.kind, TokenType::StringLiteral(_)))
            .unwrap_or(false)
    }

    fn previous(&self) -> &Token {
        &self.tokens[self.current - 1]
    }

    fn current_span(&self) -> crate::token::Span {
        self.peek().span
    }

    fn consume(&mut self, kind: TokenType) -> ParseResult<&Token> {
        if self.check(&kind) {
            Ok(self.advance())
        } else {
            Err(ParseError {
                kind: ParseErrorKind::UnexpectedToken {
                    expected: kind,
                    found: self.peek().kind.clone(),
                },
                span: self.current_span(),
            })
        }
    }

    fn consume_content_word(&mut self) -> ParseResult<Symbol> {
        let t = self.advance().clone();
        match t.kind {
            TokenType::Noun(s) | TokenType::Adjective(s) | TokenType::NonIntersectiveAdjective(s) => Ok(s),
            // Phase 35: Allow single-letter articles (a, an) to be used as variable names
            TokenType::Article(_) => Ok(t.lexeme),
            // Phase 35: Allow numeric literals as content words (e.g., "equal to 42")
            TokenType::Number(s) => Ok(s),
            TokenType::ProperName(s) => {
                // In imperative mode, proper names are variable references that must be defined
                if self.mode == ParserMode::Imperative {
                    if !self.drs.has_referent_by_variable(s) {
                        return Err(ParseError {
                            kind: ParseErrorKind::UndefinedVariable {
                                name: self.interner.resolve(s).to_string()
                            },
                            span: t.span,
                        });
                    }
                    return Ok(s);
                }

                // Declarative mode: auto-register proper names as entities
                let s_str = self.interner.resolve(s);
                let gender = Self::infer_gender(s_str);

                // Register in DRS for cross-sentence anaphora resolution
                self.drs.introduce_proper_name(s, s, gender);

                Ok(s)
            }
            TokenType::Verb { lemma, .. } => Ok(lemma),
            TokenType::Ambiguous { primary, .. } => {
                match *primary {
                    TokenType::Noun(s) | TokenType::Adjective(s) | TokenType::NonIntersectiveAdjective(s) => Ok(s),
                    TokenType::Verb { lemma, .. } => Ok(lemma),
                    TokenType::ProperName(s) => {
                        // In imperative mode, proper names must be defined
                        if self.mode == ParserMode::Imperative {
                            if !self.drs.has_referent_by_variable(s) {
                                return Err(ParseError {
                                    kind: ParseErrorKind::UndefinedVariable {
                                        name: self.interner.resolve(s).to_string()
                                    },
                                    span: t.span,
                                });
                            }
                            return Ok(s);
                        }
                        // Register proper name in DRS for ambiguous tokens too
                        let s_str = self.interner.resolve(s);
                        let gender = Self::infer_gender(s_str);
                        self.drs.introduce_proper_name(s, s, gender);
                        Ok(s)
                    }
                    _ => Err(ParseError {
                        kind: ParseErrorKind::ExpectedContentWord { found: *primary },
                        span: self.current_span(),
                    }),
                }
            }
            other => Err(ParseError {
                kind: ParseErrorKind::ExpectedContentWord { found: other },
                span: self.current_span(),
            }),
        }
    }

    fn consume_copula(&mut self) -> ParseResult<()> {
        if self.match_token(&[TokenType::Is, TokenType::Are, TokenType::Was, TokenType::Were]) {
            Ok(())
        } else {
            Err(ParseError {
                kind: ParseErrorKind::ExpectedCopula,
                span: self.current_span(),
            })
        }
    }

    fn check_comparative(&self) -> bool {
        matches!(self.peek().kind, TokenType::Comparative(_))
    }

    fn is_contact_clause_pattern(&self) -> bool {
        // Detect "The cat [the dog chased] ran" pattern
        // Also handles nested: "The rat [the cat [the dog chased] ate] died"
        let mut pos = self.current;

        // Skip the article we're at
        if pos < self.tokens.len() && matches!(self.tokens[pos].kind, TokenType::Article(_)) {
            pos += 1;
        } else {
            return false;
        }

        // Skip adjectives
        while pos < self.tokens.len() && matches!(self.tokens[pos].kind, TokenType::Adjective(_)) {
            pos += 1;
        }

        // Must have noun/proper name (embedded subject)
        if pos < self.tokens.len() && matches!(self.tokens[pos].kind, TokenType::Noun(_) | TokenType::ProperName(_) | TokenType::Adjective(_)) {
            pos += 1;
        } else {
            return false;
        }

        // Must have verb OR another article (nested contact clause) after
        pos < self.tokens.len() && matches!(self.tokens[pos].kind, TokenType::Verb { .. } | TokenType::Article(_))
    }

    fn check_superlative(&self) -> bool {
        matches!(self.peek().kind, TokenType::Superlative(_))
    }

    fn check_scopal_adverb(&self) -> bool {
        matches!(self.peek().kind, TokenType::ScopalAdverb(_))
    }

    fn check_temporal_adverb(&self) -> bool {
        matches!(self.peek().kind, TokenType::TemporalAdverb(_))
    }

    fn check_non_intersective_adjective(&self) -> bool {
        matches!(self.peek().kind, TokenType::NonIntersectiveAdjective(_))
    }

    fn check_focus(&self) -> bool {
        matches!(self.peek().kind, TokenType::Focus(_))
    }

    fn check_measure(&self) -> bool {
        matches!(self.peek().kind, TokenType::Measure(_))
    }

    fn check_presup_trigger(&self) -> bool {
        match &self.peek().kind {
            TokenType::PresupTrigger(_) => true,
            TokenType::Verb { lemma, .. } => {
                let s = self.interner.resolve(*lemma).to_lowercase();
                crate::lexicon::lookup_presup_trigger(&s).is_some()
            }
            _ => false,
        }
    }

    fn is_followed_by_np_object(&self) -> bool {
        if self.current + 1 >= self.tokens.len() {
            return false;
        }
        let next = &self.tokens[self.current + 1].kind;
        matches!(next,
            TokenType::ProperName(_) |
            TokenType::Article(_) |
            TokenType::Noun(_) |
            TokenType::Pronoun { .. } |
            TokenType::Reflexive |
            TokenType::Who |
            TokenType::What |
            TokenType::Where |
            TokenType::When |
            TokenType::Why
        )
    }

    fn is_followed_by_gerund(&self) -> bool {
        if self.current + 1 >= self.tokens.len() {
            return false;
        }
        matches!(self.tokens[self.current + 1].kind, TokenType::Verb { .. })
    }

    // =========================================================================
    // Phase 46: Agent System Parsing
    // =========================================================================

    /// Parse spawn statement: "Spawn a Worker called 'w1'."
    fn parse_spawn_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Spawn"

        // Expect article (a/an)
        if !self.check_article() {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "a/an".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume article

        // Get agent type name (Noun or ProperName)
        let agent_type = match &self.tokens[self.current].kind {
            TokenType::Noun(sym) | TokenType::ProperName(sym) => {
                let s = *sym;
                self.advance();
                s
            }
            _ => {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: "agent type".to_string() },
                    span: self.current_span(),
                });
            }
        };

        // Expect "called"
        if !self.check(&TokenType::Called) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "called".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "called"

        // Get agent name (string literal)
        let name = if let TokenType::StringLiteral(sym) = &self.tokens[self.current].kind {
            let s = *sym;
            self.advance();
            s
        } else {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "agent name".to_string() },
                span: self.current_span(),
            });
        };

        Ok(Stmt::Spawn { agent_type, name })
    }

    /// Parse send statement: "Send Ping to 'agent'."
    fn parse_send_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Send"

        // Parse message expression
        let message = self.parse_imperative_expr()?;

        // Expect "to"
        if !self.check_preposition_is("to") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "to".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "to"

        // Parse destination expression
        let destination = self.parse_imperative_expr()?;

        Ok(Stmt::SendMessage { message, destination })
    }

    /// Parse await statement: "Await response from 'agent' into result."
    fn parse_await_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Await"

        // Skip optional "response" word
        if self.check_word("response") {
            self.advance();
        }

        // Expect "from" (can be keyword or preposition)
        if !self.check(&TokenType::From) && !self.check_preposition_is("from") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "from".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "from"

        // Parse source expression
        let source = self.parse_imperative_expr()?;

        // Expect "into"
        if !self.check_word("into") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "into".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "into"

        // Get variable name (Noun, ProperName, or Adjective - can be any content word)
        let into = match &self.tokens[self.current].kind {
            TokenType::Noun(sym) | TokenType::ProperName(sym) | TokenType::Adjective(sym) => {
                let s = *sym;
                self.advance();
                s
            }
            // Also accept lexemes from other token types if they look like identifiers
            _ if self.check_content_word() => {
                let sym = self.tokens[self.current].lexeme;
                self.advance();
                sym
            }
            _ => {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: "variable name".to_string() },
                    span: self.current_span(),
                });
            }
        };

        Ok(Stmt::AwaitMessage { source, into })
    }

    // =========================================================================
    // Phase 49: CRDT Statement Parsing
    // =========================================================================

    /// Parse merge statement: "Merge remote into local." or "Merge remote's field into local's field."
    fn parse_merge_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Merge"

        // Parse source expression
        let source = self.parse_imperative_expr()?;

        // Expect "into"
        if !self.check_word("into") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "into".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "into"

        // Parse target expression
        let target = self.parse_imperative_expr()?;

        Ok(Stmt::MergeCrdt { source, target })
    }

    /// Parse increase statement: "Increase local's points by 10."
    fn parse_increase_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Increase"

        // Parse object with field access (e.g., "local's points")
        let expr = self.parse_imperative_expr()?;

        // Must be a field access
        let (object, field) = if let Expr::FieldAccess { object, field } = expr {
            (object, field)
        } else {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "field access (e.g., 'x's count')".to_string() },
                span: self.current_span(),
            });
        };

        // Expect "by"
        if !self.check_preposition_is("by") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "by".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "by"

        // Parse amount
        let amount = self.parse_imperative_expr()?;

        Ok(Stmt::IncreaseCrdt { object, field: *field, amount })
    }

    /// Parse decrease statement: "Decrease game's score by 5."
    fn parse_decrease_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Decrease"

        // Parse object with field access (e.g., "game's score")
        let expr = self.parse_imperative_expr()?;

        // Must be a field access
        let (object, field) = if let Expr::FieldAccess { object, field } = expr {
            (object, field)
        } else {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "field access (e.g., 'x's count')".to_string() },
                span: self.current_span(),
            });
        };

        // Expect "by"
        if !self.check_preposition_is("by") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "by".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "by"

        // Parse amount
        let amount = self.parse_imperative_expr()?;

        Ok(Stmt::DecreaseCrdt { object, field: *field, amount })
    }

    /// Parse append statement: "Append value to sequence."
    fn parse_append_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Append"

        // Parse value to append
        let value = self.parse_imperative_expr()?;

        // Expect "to" (can be TokenType::To or a preposition)
        if !self.check(&TokenType::To) && !self.check_preposition_is("to") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "to".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "to"

        // Parse sequence expression
        let sequence = self.parse_imperative_expr()?;

        Ok(Stmt::AppendToSequence { sequence, value })
    }

    /// Parse resolve statement: "Resolve page's title to value."
    fn parse_resolve_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Resolve"

        // Parse object with field access (e.g., "page's title")
        let expr = self.parse_imperative_expr()?;

        // Must be a field access
        let (object, field) = if let Expr::FieldAccess { object, field } = expr {
            (object, field)
        } else {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "field access (e.g., 'x's title')".to_string() },
                span: self.current_span(),
            });
        };

        // Expect "to" (can be TokenType::To or a preposition)
        if !self.check(&TokenType::To) && !self.check_preposition_is("to") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "to".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "to"

        // Parse value
        let value = self.parse_imperative_expr()?;

        Ok(Stmt::ResolveConflict { object, field: *field, value })
    }

}


```

---

use super::modal::ModalParsing;
use super::noun::NounParsing;
use super::pragmatics::PragmaticsParsing;
use super::quantifier::QuantifierParsing;
use super::question::QuestionParsing;
use super::verb::LogicVerbParsing;
use super::{ParseResult, Parser};
use crate::ast::{AspectOperator, LogicExpr, NeoEventData, NounPhrase, QuantifierKind, TemporalOperator, Term, ThematicRole};
use crate::lexer::Lexer;
use crate::lexicon::Time;
use crate::drs::{BoxType, Gender, Number};
use super::ParserMode;
use crate::error::{ParseError, ParseErrorKind};
use crate::intern::Symbol;
use crate::lexicon::Definiteness;
use crate::token::TokenType;

pub trait ClauseParsing<'a, 'ctx, 'int> {
    fn parse_sentence(&mut self) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_conditional(&mut self) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_disjunction(&mut self) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_conjunction(&mut self) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_relative_clause(&mut self, gap_var: Symbol) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_gapped_clause(&mut self, borrowed_verb: Symbol) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_counterfactual_antecedent(&mut self) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_counterfactual_consequent(&mut self) -> ParseResult<&'a LogicExpr<'a>>;
    fn check_wh_word(&self) -> bool;
    fn is_counterfactual_context(&self) -> bool;
    fn is_complete_clause(&self, expr: &LogicExpr<'a>) -> bool;
    fn extract_verb_from_expr(&self, expr: &LogicExpr<'a>) -> Option<Symbol>;
    fn try_parse_ellipsis(&mut self) -> Option<ParseResult<&'a LogicExpr<'a>>>;
    fn check_ellipsis_auxiliary(&self) -> bool;
    fn check_ellipsis_terminator(&self) -> bool;
}

impl<'a, 'ctx, 'int> ClauseParsing<'a, 'ctx, 'int> for Parser<'a, 'ctx, 'int> {
    fn parse_sentence(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        // In imperative mode, handle Let statements by converting to LogicExpr
        // This supports declarative parser being called after process_block_headers()
        // Let x is/= value -> returns the value expression (the test just checks parsing succeeds)
        if self.mode == ParserMode::Imperative && self.check(&TokenType::Let) {
            self.advance(); // consume "Let"
            let _var = self.expect_identifier()?;
            // Accept "is", "be", "=" as assignment operators
            if self.check(&TokenType::Is) || self.check(&TokenType::Be) || self.check(&TokenType::Equals) || self.check(&TokenType::Identity) {
                self.advance(); // consume the operator
            }
            // Parse the value and return it (test just checks parsing succeeds)
            return self.parse_disjunction();
        }

        // Check for ellipsis pattern: "Mary does too." / "Mary can too."
        if let Some(result) = self.try_parse_ellipsis() {
            return result;
        }

        if self.check_verb() {
            let verb_pos = self.current;
            let mut temp_pos = self.current + 1;
            while temp_pos < self.tokens.len() {
                if matches!(self.tokens[temp_pos].kind, TokenType::Exclamation) {
                    self.current = verb_pos;
                    let verb = self.consume_verb();
                    while !matches!(self.peek().kind, TokenType::Exclamation | TokenType::EOF) {
                        self.advance();
                    }
                    if self.check(&TokenType::Exclamation) {
                        self.advance();
                    }
                    let addressee = self.interner.intern("addressee");
                    let action = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: verb,
                        args: self.ctx.terms.alloc_slice([Term::Variable(addressee)]),
                        world: None,
                    });
                    return Ok(self.ctx.exprs.alloc(LogicExpr::Imperative { action }));
                }
                if matches!(self.tokens[temp_pos].kind, TokenType::Period | TokenType::EOF) {
                    break;
                }
                temp_pos += 1;
            }
        }

        if self.check_wh_word() {
            return self.parse_wh_question();
        }

        if self.check(&TokenType::Does)
            || self.check(&TokenType::Do)
            || self.check(&TokenType::Is)
            || self.check(&TokenType::Are)
            || self.check(&TokenType::Was)
            || self.check(&TokenType::Were)
            || self.check(&TokenType::Would)
            || self.check(&TokenType::Could)
            || self.check(&TokenType::Can)
        {
            return self.parse_yes_no_question();
        }

        if self.match_token(&[TokenType::If]) {
            return self.parse_conditional();
        }

        if self.check_modal() {
            self.advance();
            return self.parse_modal();
        }

        if self.match_token(&[TokenType::Not]) {
            self.negative_depth += 1;
            let inner = self.parse_sentence()?;
            self.negative_depth -= 1;
            return Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                op: TokenType::Not,
                operand: inner,
            }));
        }

        self.parse_disjunction()
    }

    fn check_wh_word(&self) -> bool {
        if matches!(
            self.peek().kind,
            TokenType::Who
                | TokenType::What
                | TokenType::Where
                | TokenType::When
                | TokenType::Why
        ) {
            return true;
        }
        if self.check_preposition() && self.current + 1 < self.tokens.len() {
            matches!(
                self.tokens[self.current + 1].kind,
                TokenType::Who
                    | TokenType::What
                    | TokenType::Where
                    | TokenType::When
                    | TokenType::Why
            )
        } else {
            false
        }
    }

    fn parse_conditional(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let is_counterfactual = self.is_counterfactual_context();

        // Enter DRS antecedent box - indefinites here get universal force
        self.drs.enter_box(BoxType::ConditionalAntecedent);
        let antecedent = self.parse_counterfactual_antecedent()?;
        self.drs.exit_box();

        if self.check(&TokenType::Comma) {
            self.advance();
        }

        if self.check(&TokenType::Then) {
            self.advance();
        }

        // Enter DRS consequent box - can access antecedent referents
        self.drs.enter_box(BoxType::ConditionalConsequent);
        let consequent = self.parse_counterfactual_consequent()?;
        self.drs.exit_box();

        // Get DRS referents that need universal quantification
        let universal_refs = self.drs.get_universal_referents();

        // Build the conditional expression
        let conditional = if is_counterfactual {
            self.ctx.exprs.alloc(LogicExpr::Counterfactual {
                antecedent,
                consequent,
            })
        } else {
            self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: antecedent,
                op: TokenType::If,
                right: consequent,
            })
        };

        // Wrap with universal quantifiers for DRS referents
        let mut result = conditional;
        for var in universal_refs.into_iter().rev() {
            result = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                kind: QuantifierKind::Universal,
                variable: var,
                body: result,
                island_id: self.current_island,
            });
        }

        Ok(result)
    }

    fn is_counterfactual_context(&self) -> bool {
        for i in 0..5 {
            if self.current + i >= self.tokens.len() {
                break;
            }
            let token = &self.tokens[self.current + i];
            if matches!(token.kind, TokenType::Were | TokenType::Had) {
                return true;
            }
            if matches!(token.kind, TokenType::Comma | TokenType::Period) {
                break;
            }
        }
        false
    }

    fn parse_counterfactual_antecedent(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let unknown = self.interner.intern("?");
        if self.check_content_word() || self.check_pronoun() || self.check_article() {
            // Weather verb detection: "if it rains" → ∃e(Rain(e))
            // Must check BEFORE pronoun resolution since "it" would resolve to "?"
            if self.check_pronoun() {
                let token = self.peek();
                let token_text = self.interner.resolve(token.lexeme);
                if token_text.eq_ignore_ascii_case("it") {
                    // Look ahead for weather verb: "it rains" or "it is raining"
                    if self.current + 1 < self.tokens.len() {
                        // Check for "it + verb" pattern
                        if let TokenType::Verb { lemma, time, .. } = &self.tokens[self.current + 1].kind {
                            let lemma_str = self.interner.resolve(*lemma);
                            if Lexer::is_weather_verb(lemma_str) {
                                let verb = *lemma;
                                let verb_time = *time;
                                self.advance(); // consume "it"
                                self.advance(); // consume weather verb

                                let event_var = self.get_event_var();

                                // Weather verbs are impersonal - no pronoun resolution needed
                                // Event var gets universal force from transpiler when suppress_existential=true
                                let suppress_existential = self.drs.in_conditional_antecedent();

                                let mut result: &'a LogicExpr<'a> = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                                    event_var,
                                    verb,
                                    roles: self.ctx.roles.alloc_slice(vec![]),
                                    modifiers: self.ctx.syms.alloc_slice(vec![]),
                                    suppress_existential,
                                    world: None,
                                })));

                                // Handle coordinated weather verbs: "rains and thunders" or "rains or thunders"
                                // SHARE the same event_var for all coordinated verbs
                                while self.check(&TokenType::And) || self.check(&TokenType::Or) {
                                    let is_disjunction = self.check(&TokenType::Or);
                                    self.advance(); // consume "and" or "or"

                                    if let TokenType::Verb { lemma: lemma2, .. } = &self.peek().kind.clone() {
                                        let lemma2_str = self.interner.resolve(*lemma2);
                                        if Lexer::is_weather_verb(lemma2_str) {
                                            let verb2 = *lemma2;
                                            self.advance(); // consume second weather verb

                                            // REUSE same event_var - no new variable, no DRS registration
                                            let neo_event2 = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                                                event_var,  // Same variable as first weather verb
                                                verb: verb2,
                                                roles: self.ctx.roles.alloc_slice(vec![]),
                                                modifiers: self.ctx.syms.alloc_slice(vec![]),
                                                suppress_existential,
                                                world: None,
                                            })));

                                            let op = if is_disjunction { TokenType::Or } else { TokenType::And };
                                            result = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                                left: result,
                                                op,
                                                right: neo_event2,
                                            });
                                        } else {
                                            break; // Not a weather verb, stop coordination
                                        }
                                    } else {
                                        break;
                                    }
                                }

                                return Ok(match verb_time {
                                    Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                                        operator: TemporalOperator::Past,
                                        body: result,
                                    }),
                                    Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                                        operator: TemporalOperator::Future,
                                        body: result,
                                    }),
                                    _ => result,
                                });
                            }
                        }
                        // Check for "it + is/are + verb" pattern: "it is raining"
                        else if self.current + 2 < self.tokens.len() {
                            let is_copula = matches!(
                                self.tokens[self.current + 1].kind,
                                TokenType::Is | TokenType::Are | TokenType::Was | TokenType::Were
                            );
                            if is_copula {
                                if let TokenType::Verb { lemma, .. } = &self.tokens[self.current + 2].kind {
                                    let lemma_str = self.interner.resolve(*lemma);
                                    if Lexer::is_weather_verb(lemma_str) {
                                        let verb = *lemma;
                                        let verb_time = if matches!(
                                            self.tokens[self.current + 1].kind,
                                            TokenType::Was | TokenType::Were
                                        ) {
                                            Time::Past
                                        } else {
                                            Time::Present
                                        };
                                        self.advance(); // consume "it"
                                        self.advance(); // consume "is/are/was/were"
                                        self.advance(); // consume weather verb

                                        let event_var = self.get_event_var();
                                        // Weather verbs are impersonal - no pronoun resolution needed
                                        // Event var gets universal force from transpiler when suppress_existential=true
                                        let suppress_existential = self.drs.in_conditional_antecedent();

                                        let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                                            event_var,
                                            verb,
                                            roles: self.ctx.roles.alloc_slice(vec![]),
                                            modifiers: self.ctx.syms.alloc_slice(vec![]),
                                            suppress_existential,
                                            world: None,
                                        })));

                                        // Progressive aspect for "is raining"
                                        let with_aspect = self.ctx.exprs.alloc(LogicExpr::Aspectual {
                                            operator: AspectOperator::Progressive,
                                            body: neo_event,
                                        });

                                        return Ok(match verb_time {
                                            Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                                                operator: TemporalOperator::Past,
                                                body: with_aspect,
                                            }),
                                            _ => with_aspect,
                                        });
                                    }
                                }
                            }
                        }
                    }
                }
            }

            // Track if subject is an indefinite that needs DRS registration
            let (subject, subject_type_pred) = if self.check_pronoun() {
                let token = self.advance().clone();
                let token_text = self.interner.resolve(token.lexeme);
                // Handle first/second person pronouns as constants (deictic reference)
                let resolved = if token_text.eq_ignore_ascii_case("i") {
                    self.interner.intern("Speaker")
                } else if token_text.eq_ignore_ascii_case("you") {
                    self.interner.intern("Addressee")
                } else if let TokenType::Pronoun { gender, number, .. } = token.kind {
                    let resolved_pronoun = self.resolve_pronoun(gender, number)?;
                    match resolved_pronoun {
                        super::ResolvedPronoun::Variable(s) | super::ResolvedPronoun::Constant(s) => s,
                    }
                } else {
                    unknown
                };
                (resolved, None)
            } else {
                let np = self.parse_noun_phrase(true)?;

                // Check if this NP should introduce a DRS referent
                // Both indefinites ("a dog") and definites ("the dog") introduce referents
                // For definites without antecedent, this implements "global accommodation"
                if np.definiteness == Some(Definiteness::Indefinite)
                    || np.definiteness == Some(Definiteness::Definite)
                    || np.definiteness == Some(Definiteness::Distal) {
                    let gender = Self::infer_noun_gender(self.interner.resolve(np.noun));
                    let number = if Self::is_plural_noun(self.interner.resolve(np.noun)) {
                        Number::Plural
                    } else {
                        Number::Singular
                    };

                    // Register in DRS using noun as variable (for pronoun resolution)
                    self.drs.introduce_referent(np.noun, np.noun, gender, number);

                    // Create type predicate: Farmer(noun)
                    let type_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: np.noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(np.noun)]),
                        world: None,
                    });

                    (np.noun, Some(type_pred))
                } else {
                    // Proper name - use as constant (proper names have their own registration)
                    (np.noun, None)
                }
            };

            // Determine the subject term type
            let subject_term = if subject_type_pred.is_some() {
                Term::Variable(subject)
            } else {
                Term::Constant(subject)
            };

            // Handle presupposition triggers in antecedent: "If John stopped smoking, ..."
            // Only trigger if followed by gerund complement
            if self.check_presup_trigger() && self.is_followed_by_gerund() {
                let presup_kind = match self.advance().kind {
                    TokenType::PresupTrigger(kind) => kind,
                    TokenType::Verb { lemma, .. } => {
                        let s = self.interner.resolve(lemma).to_lowercase();
                        crate::lexicon::lookup_presup_trigger(&s)
                            .expect("Lexicon mismatch: Verb flagged as trigger but lookup failed")
                    }
                    _ => panic!("Expected presupposition trigger"),
                };
                let np = NounPhrase {
                    noun: subject,
                    definiteness: None,
                    adjectives: &[],
                    possessor: None,
                    pps: &[],
                    superlative: None,
                };
                return self.parse_presupposition(&np, presup_kind);
            }

            if self.check(&TokenType::Were) {
                self.advance();
                let predicate = if self.check_pronoun() {
                    let token = self.advance().clone();
                    if let TokenType::Pronoun { gender, number, .. } = token.kind {
                        let token_text = self.interner.resolve(token.lexeme);
                        if token_text.eq_ignore_ascii_case("i") {
                            self.interner.intern("Speaker")
                        } else if token_text.eq_ignore_ascii_case("you") {
                            self.interner.intern("Addressee")
                        } else {
                            let resolved_pronoun = self.resolve_pronoun(gender, number)?;
                            match resolved_pronoun {
                                super::ResolvedPronoun::Variable(s) | super::ResolvedPronoun::Constant(s) => s,
                            }
                        }
                    } else {
                        unknown
                    }
                } else {
                    self.consume_content_word()?
                };
                let be = self.interner.intern("Be");
                let be_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: be,
                    args: self.ctx.terms.alloc_slice([
                        subject_term,
                        Term::Constant(predicate),
                    ]),
                    world: None,
                });
                // Combine with type predicate if indefinite subject
                return Ok(if let Some(type_pred) = subject_type_pred {
                    self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: type_pred,
                        op: TokenType::And,
                        right: be_pred,
                    })
                } else {
                    be_pred
                });
            }

            if self.check(&TokenType::Had) {
                self.advance();
                let verb = self.consume_content_word()?;
                let main_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb,
                    args: self.ctx.terms.alloc_slice([subject_term]),
                    world: None,
                });

                // Handle "because" causal clause in antecedent
                // Phase 35: Do NOT consume if followed by string literal (Trust justification)
                if self.check(&TokenType::Because) && !self.peek_next_is_string_literal() {
                    self.advance();
                    let cause = self.parse_atom()?;
                    let causal = self.ctx.exprs.alloc(LogicExpr::Causal {
                        effect: main_pred,
                        cause,
                    });
                    // Combine with type predicate if indefinite subject
                    return Ok(if let Some(type_pred) = subject_type_pred {
                        self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: type_pred,
                            op: TokenType::And,
                            right: causal,
                        })
                    } else {
                        causal
                    });
                }

                // Combine with type predicate if indefinite subject
                return Ok(if let Some(type_pred) = subject_type_pred {
                    self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: type_pred,
                        op: TokenType::And,
                        right: main_pred,
                    })
                } else {
                    main_pred
                });
            }

            // Parse verb phrase with subject
            // Use variable term for indefinite subjects, constant for definites/proper names
            let verb_phrase = if subject_type_pred.is_some() {
                self.parse_predicate_with_subject_as_var(subject)?
            } else {
                self.parse_predicate_with_subject(subject)?
            };

            // Combine with type predicate if indefinite subject
            return Ok(if let Some(type_pred) = subject_type_pred {
                self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: type_pred,
                    op: TokenType::And,
                    right: verb_phrase,
                })
            } else {
                verb_phrase
            });
        }

        self.parse_sentence()
    }

    fn parse_counterfactual_consequent(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let unknown = self.interner.intern("?");
        if self.check_content_word() || self.check_pronoun() {
            // Check for grammatically incorrect "its" + weather adjective
            // "its" is possessive, "it's" is contraction - common typo
            if self.check_pronoun() {
                let token = self.peek();
                let token_text = self.interner.resolve(token.lexeme).to_lowercase();
                if token_text == "its" {
                    // Check if followed by weather adjective
                    if self.current + 1 < self.tokens.len() {
                        let next_token = &self.tokens[self.current + 1];
                        let next_str = self.interner.resolve(next_token.lexeme).to_lowercase();
                        if let Some(meta) = crate::lexicon::lookup_adjective_db(&next_str) {
                            if meta.features.contains(&crate::lexicon::Feature::Weather) {
                                return Err(ParseError {
                                    kind: ParseErrorKind::GrammarError(
                                        "Did you mean 'it's' (it is)? 'its' is a possessive pronoun.".to_string()
                                    ),
                                    span: self.current_span(),
                                });
                            }
                        }
                    }
                }
            }

            // Check for expletive "it" + copula + weather adjective: "it's wet" → Wet
            if self.check_pronoun() {
                let token_text = self.interner.resolve(self.peek().lexeme).to_lowercase();
                if token_text == "it" {
                    // Look ahead for copula + weather adjective
                    // Handle both "it is wet" and "it's wet" (where 's is Possessive token)
                    if self.current + 2 < self.tokens.len() {
                        let next = &self.tokens[self.current + 1].kind;
                        if matches!(next, TokenType::Is | TokenType::Was | TokenType::Possessive) {
                            // Check if followed by weather adjective
                            let adj_token = &self.tokens[self.current + 2];
                            let adj_sym = adj_token.lexeme;
                            let adj_str = self.interner.resolve(adj_sym).to_lowercase();
                            if let Some(meta) = crate::lexicon::lookup_adjective_db(&adj_str) {
                                if meta.features.contains(&crate::lexicon::Feature::Weather) {
                                    self.advance(); // consume "it"
                                    self.advance(); // consume copula
                                    self.advance(); // consume adjective token

                                    // Use the canonical lemma from lexicon (e.g., "Wet" not "wet")
                                    let adj_lemma = self.interner.intern(meta.lemma);

                                    // Get event variable from DRS (introduced in antecedent)
                                    let event_var = self.drs.get_last_event_referent(self.interner)
                                        .unwrap_or_else(|| self.interner.intern("e"));

                                    // First weather adjective predicate
                                    let mut result: &'a LogicExpr<'a> = self.ctx.exprs.alloc(LogicExpr::Predicate {
                                        name: adj_lemma,
                                        args: self.ctx.terms.alloc_slice([Term::Variable(event_var)]),
                                        world: None,
                                    });

                                    // Handle coordinated adjectives: "wet and cold"
                                    while self.check(&TokenType::And) {
                                        self.advance(); // consume "and"
                                        if self.check_content_word() {
                                            let adj2_lexeme = self.peek().lexeme;
                                            let adj2_str = self.interner.resolve(adj2_lexeme).to_lowercase();

                                            // Check if it's also a weather adjective
                                            if let Some(meta2) = crate::lexicon::lookup_adjective_db(&adj2_str) {
                                                if meta2.features.contains(&crate::lexicon::Feature::Weather) {
                                                    self.advance(); // consume adjective token
                                                    // Use the canonical lemma from lexicon (e.g., "Cold" not "cold")
                                                    let adj2_lemma = self.interner.intern(meta2.lemma);
                                                    let pred2 = self.ctx.exprs.alloc(LogicExpr::Predicate {
                                                        name: adj2_lemma,
                                                        args: self.ctx.terms.alloc_slice([Term::Variable(event_var)]),
                                                        world: None,
                                                    });
                                                    result = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                                        left: result,
                                                        op: TokenType::And,
                                                        right: pred2,
                                                    });
                                                    continue;
                                                }
                                            }
                                        }
                                        break;
                                    }

                                    return Ok(result);
                                }
                            }
                        }
                    }
                }
            }

            let subject = if self.check_pronoun() {
                let token = self.advance().clone();
                let token_text = self.interner.resolve(token.lexeme);
                // Handle first/second person pronouns as constants (deictic reference)
                if token_text.eq_ignore_ascii_case("i") {
                    self.interner.intern("Speaker")
                } else if token_text.eq_ignore_ascii_case("you") {
                    self.interner.intern("Addressee")
                } else if let TokenType::Pronoun { gender, number, .. } = token.kind {
                    let resolved_pronoun = self.resolve_pronoun(gender, number)?;
                    match resolved_pronoun {
                        super::ResolvedPronoun::Variable(s) | super::ResolvedPronoun::Constant(s) => s,
                    }
                } else {
                    unknown
                }
            } else {
                self.parse_noun_phrase(true)?.noun
            };

            if self.check(&TokenType::Would) {
                self.advance();
                if self.check_content_word() {
                    let next_word = self.interner.resolve(self.peek().lexeme).to_lowercase();
                    if next_word == "have" {
                        self.advance();
                    }
                }
                let verb = self.consume_content_word()?;
                return Ok(self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb,
                    args: self.ctx.terms.alloc_slice([Term::Constant(subject)]),
                    world: None,
                }));
            }

            return self.parse_predicate_with_subject(subject);
        }

        self.parse_sentence()
    }

    fn extract_verb_from_expr(&self, expr: &LogicExpr<'a>) -> Option<Symbol> {
        match expr {
            LogicExpr::Predicate { name, .. } => Some(*name),
            LogicExpr::NeoEvent(data) => Some(data.verb),
            LogicExpr::BinaryOp { right, .. } => self.extract_verb_from_expr(right),
            LogicExpr::Modal { operand, .. } => self.extract_verb_from_expr(operand),
            LogicExpr::Presupposition { assertion, .. } => self.extract_verb_from_expr(assertion),
            LogicExpr::Control { verb, .. } => Some(*verb),
            LogicExpr::Temporal { body, .. } => self.extract_verb_from_expr(body),
            LogicExpr::TemporalAnchor { body, .. } => self.extract_verb_from_expr(body),
            LogicExpr::Aspectual { body, .. } => self.extract_verb_from_expr(body),
            LogicExpr::Quantifier { body, .. } => self.extract_verb_from_expr(body),
            _ => None,
        }
    }

    fn parse_gapped_clause(&mut self, borrowed_verb: Symbol) -> ParseResult<&'a LogicExpr<'a>> {
        let subject = self.parse_noun_phrase(true)?;

        if self.check(&TokenType::Comma) {
            self.advance();
        }

        let subject_term = self.noun_phrase_to_term(&subject);
        let event_var = self.get_event_var();
        let suppress_existential = self.drs.in_conditional_antecedent();

        // Check if next token is temporal adverb (gapping with adjunct only)
        if self.check_temporal_adverb() {
            let adv_sym = if let TokenType::TemporalAdverb(sym) = self.advance().kind {
                sym
            } else {
                self.interner.intern("?")
            };

            return Ok(self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                event_var,
                verb: borrowed_verb,
                roles: self.ctx.roles.alloc_slice(vec![
                    (ThematicRole::Agent, subject_term),
                ]),
                modifiers: self.ctx.syms.alloc_slice(vec![adv_sym]),
                suppress_existential,
                world: None,
            }))));
        }

        // Standard gapping: subject + object
        let object = self.parse_noun_phrase(false)?;
        let object_term = self.noun_phrase_to_term(&object);

        let roles = vec![
            (ThematicRole::Agent, subject_term),
            (ThematicRole::Theme, object_term),
        ];

        Ok(self
            .ctx
            .exprs
            .alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                event_var,
                verb: borrowed_verb,
                roles: self.ctx.roles.alloc_slice(roles),
                modifiers: self.ctx.syms.alloc_slice(vec![]),
                suppress_existential,
                world: None,
            }))))
    }

    fn is_complete_clause(&self, expr: &LogicExpr<'a>) -> bool {
        match expr {
            LogicExpr::Atom(_) => false,
            LogicExpr::Predicate { .. } => true,
            LogicExpr::Quantifier { .. } => true,
            LogicExpr::Modal { .. } => true,
            LogicExpr::Temporal { .. } => true,
            LogicExpr::Aspectual { .. } => true,
            LogicExpr::BinaryOp { .. } => true,
            LogicExpr::UnaryOp { .. } => true,
            LogicExpr::Control { .. } => true,
            LogicExpr::Presupposition { .. } => true,
            LogicExpr::Categorical(_) => true,
            LogicExpr::Relation(_) => true,
            _ => true,
        }
    }

    /// Parse disjunction (Or/Iff) - lowest precedence logical connectives.
    /// Calls parse_conjunction for operands to ensure And binds tighter.
    fn parse_disjunction(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let mut expr = self.parse_conjunction()?;

        while self.check(&TokenType::Comma)
            || self.check(&TokenType::Or)
            || self.check(&TokenType::Iff)
        {
            if self.check(&TokenType::Comma) {
                self.advance();
            }
            if !self.match_token(&[TokenType::Or, TokenType::Iff]) {
                break;
            }
            let operator = self.previous().kind.clone();
            self.current_island += 1;

            let saved_pos = self.current;
            let standard_attempt = self.try_parse(|p| p.parse_conjunction());

            let use_gapping = match &standard_attempt {
                Some(right) => {
                    !self.is_complete_clause(right)
                        && (self.check(&TokenType::Comma) || self.check_content_word())
                }
                None => true,
            };

            if !use_gapping {
                if let Some(right) = standard_attempt {
                    expr = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: expr,
                        op: operator,
                        right,
                    });
                }
            } else {
                self.current = saved_pos;

                let borrowed_verb = self.extract_verb_from_expr(expr).ok_or(ParseError {
                    kind: ParseErrorKind::GappingResolutionFailed,
                    span: self.current_span(),
                })?;

                let right = self.parse_gapped_clause(borrowed_verb)?;

                expr = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: expr,
                    op: operator,
                    right,
                });
            }
        }

        Ok(expr)
    }

    /// Parse conjunction (And) - higher precedence than Or.
    /// Calls parse_atom for operands.
    fn parse_conjunction(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let mut expr = self.parse_atom()?;

        // Handle causal "because" at conjunction level
        // Phase 35: Do NOT consume if followed by string literal (Trust justification)
        if self.check(&TokenType::Because) && !self.peek_next_is_string_literal() {
            self.advance();
            let cause = self.parse_atom()?;
            return Ok(self.ctx.exprs.alloc(LogicExpr::Causal {
                effect: expr,
                cause,
            }));
        }

        while self.check(&TokenType::Comma) || self.check(&TokenType::And) {
            if self.check(&TokenType::Comma) {
                self.advance();
            }
            if !self.match_token(&[TokenType::And]) {
                break;
            }
            let operator = self.previous().kind.clone();
            self.current_island += 1;

            let saved_pos = self.current;
            let standard_attempt = self.try_parse(|p| p.parse_atom());

            let use_gapping = match &standard_attempt {
                Some(right) => {
                    !self.is_complete_clause(right)
                        && (self.check(&TokenType::Comma) || self.check_content_word())
                }
                None => true,
            };

            if !use_gapping {
                if let Some(right) = standard_attempt {
                    expr = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: expr,
                        op: operator,
                        right,
                    });
                }
            } else {
                self.current = saved_pos;

                let borrowed_verb = self.extract_verb_from_expr(expr).ok_or(ParseError {
                    kind: ParseErrorKind::GappingResolutionFailed,
                    span: self.current_span(),
                })?;

                let right = self.parse_gapped_clause(borrowed_verb)?;

                expr = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: expr,
                    op: operator,
                    right,
                });
            }
        }

        Ok(expr)
    }

    fn parse_relative_clause(&mut self, gap_var: Symbol) -> ParseResult<&'a LogicExpr<'a>> {
        if self.check_verb() {
            return self.parse_verb_phrase_for_restriction(gap_var);
        }

        if self.check_content_word() || self.check_article() {
            let rel_subject = self.parse_noun_phrase_for_relative()?;

            let nested_relative = if matches!(self.peek().kind, TokenType::Article(_)) {
                let nested_var = self.next_var_name();
                Some((nested_var, self.parse_relative_clause(nested_var)?))
            } else {
                None
            };

            if self.check_verb() {
                let verb = self.consume_verb();

                let mut roles: Vec<(ThematicRole, Term<'a>)> = vec![
                    (ThematicRole::Agent, Term::Constant(rel_subject.noun)),
                    (ThematicRole::Theme, Term::Variable(gap_var)),
                ];

                while self.check_to_preposition() {
                    self.advance();
                    if self.check_content_word() || self.check_article() {
                        let recipient = self.parse_noun_phrase(false)?;
                        roles.push((ThematicRole::Recipient, Term::Constant(recipient.noun)));
                    }
                }

                let event_var = self.get_event_var();
                let suppress_existential = self.drs.in_conditional_antecedent();
                let this_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                    event_var,
                    verb,
                    roles: self.ctx.roles.alloc_slice(roles),
                    modifiers: self.ctx.syms.alloc_slice(vec![]),
                    suppress_existential,
                    world: None,
                })));

                if let Some((nested_var, nested_clause)) = nested_relative {
                    let type_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: rel_subject.noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(nested_var)]),
                        world: None,
                    });

                    let inner = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: type_pred,
                        op: TokenType::And,
                        right: nested_clause,
                    });

                    let combined = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: inner,
                        op: TokenType::And,
                        right: this_event,
                    });

                    return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                        kind: crate::ast::QuantifierKind::Existential,
                        variable: nested_var,
                        body: combined,
                        island_id: self.current_island,
                    }));
                }

                return Ok(this_event);
            }
        }

        if self.check_verb() {
            return self.parse_verb_phrase_for_restriction(gap_var);
        }

        let unknown = self.interner.intern("?");
        Ok(self.ctx.exprs.alloc(LogicExpr::Atom(unknown)))
    }

    fn check_ellipsis_auxiliary(&self) -> bool {
        matches!(
            self.peek().kind,
            TokenType::Does | TokenType::Do |
            TokenType::Can | TokenType::Could | TokenType::Would |
            TokenType::May | TokenType::Must | TokenType::Should
        )
    }

    fn check_ellipsis_terminator(&self) -> bool {
        if self.is_at_end() || self.check(&TokenType::Period) {
            return true;
        }
        if self.check_content_word() {
            let word = self.interner.resolve(self.peek().lexeme).to_lowercase();
            return word == "too" || word == "also";
        }
        false
    }

    fn try_parse_ellipsis(&mut self) -> Option<ParseResult<&'a LogicExpr<'a>>> {
        // Need a stored template to reconstruct from
        if self.last_event_template.is_none() {
            return None;
        }

        let saved_pos = self.current;

        // Pattern: Subject + Auxiliary + (not)? + Terminator
        // Subject must be proper name or pronoun
        let subject_sym = if matches!(self.peek().kind, TokenType::ProperName(_)) {
            if let TokenType::ProperName(sym) = self.advance().kind {
                sym
            } else {
                self.current = saved_pos;
                return None;
            }
        } else if self.check_pronoun() {
            let token = self.advance().clone();
            if let TokenType::Pronoun { gender, number, .. } = token.kind {
                match self.resolve_pronoun(gender, number) {
                    Ok(resolved) => match resolved {
                        super::ResolvedPronoun::Variable(s) | super::ResolvedPronoun::Constant(s) => s,
                    },
                    Err(e) => return Some(Err(e)),
                }
            } else {
                self.current = saved_pos;
                return None;
            }
        } else {
            return None;
        };

        // Must be followed by ellipsis auxiliary
        if !self.check_ellipsis_auxiliary() {
            self.current = saved_pos;
            return None;
        }
        let aux_token = self.advance().kind.clone();

        // Check for negation
        let is_negated = self.match_token(&[TokenType::Not]);

        // Must end with terminator
        if !self.check_ellipsis_terminator() {
            self.current = saved_pos;
            return None;
        }

        // Consume "too"/"also" if present
        if self.check_content_word() {
            let word = self.interner.resolve(self.peek().lexeme).to_lowercase();
            if word == "too" || word == "also" {
                self.advance();
            }
        }

        // Reconstruct from template
        let template = self.last_event_template.clone().unwrap();
        let event_var = self.get_event_var();
        let suppress_existential = self.drs.in_conditional_antecedent();

        // Build roles with new subject as Agent
        let mut roles: Vec<(ThematicRole, Term<'a>)> = vec![
            (ThematicRole::Agent, Term::Constant(subject_sym))
        ];
        roles.extend(template.non_agent_roles.iter().cloned());

        let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
            event_var,
            verb: template.verb,
            roles: self.ctx.roles.alloc_slice(roles),
            modifiers: self.ctx.syms.alloc_slice(template.modifiers.clone()),
            suppress_existential,
            world: None,
        })));

        // Apply modal if auxiliary is modal
        let with_modal = match aux_token {
            TokenType::Can | TokenType::Could => {
                let vector = self.token_to_vector(&aux_token);
                self.ctx.modal(vector, neo_event)
            }
            TokenType::Would | TokenType::May | TokenType::Must | TokenType::Should => {
                let vector = self.token_to_vector(&aux_token);
                self.ctx.modal(vector, neo_event)
            }
            _ => neo_event,
        };

        // Apply negation if present
        let result = if is_negated {
            self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                op: TokenType::Not,
                operand: with_modal,
            })
        } else {
            with_modal
        };

        Some(Ok(result))
    }
}

```

---

use super::clause::ClauseParsing;
use super::modal::ModalParsing;
use super::noun::NounParsing;
use super::{NegativeScopeMode, ParseResult, Parser};
use crate::ast::{LogicExpr, NeoEventData, NounPhrase, QuantifierKind, Term, ThematicRole};
use crate::drs::{Gender, Number};
use crate::drs::ReferentSource;
use crate::error::{ParseError, ParseErrorKind};
use crate::intern::Symbol;
use crate::lexer::Lexer;
use crate::lexicon::{get_canonical_verb, is_subsective, lookup_verb_db, Definiteness, Feature, Time};
use crate::token::{PresupKind, TokenType};

pub trait QuantifierParsing<'a, 'ctx, 'int> {
    fn parse_quantified(&mut self) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_restriction(&mut self, var_name: Symbol) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_verb_phrase_for_restriction(&mut self, var_name: Symbol) -> ParseResult<&'a LogicExpr<'a>>;
    fn combine_with_and(&self, exprs: Vec<&'a LogicExpr<'a>>) -> ParseResult<&'a LogicExpr<'a>>;
    fn wrap_with_definiteness_full(
        &mut self,
        np: &NounPhrase<'a>,
        predicate: &'a LogicExpr<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>>;
    fn wrap_with_definiteness(
        &mut self,
        definiteness: Option<Definiteness>,
        noun: Symbol,
        predicate: &'a LogicExpr<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>>;
    fn wrap_with_definiteness_and_adjectives(
        &mut self,
        definiteness: Option<Definiteness>,
        noun: Symbol,
        adjectives: &[Symbol],
        predicate: &'a LogicExpr<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>>;
    fn wrap_with_definiteness_and_adjectives_and_pps(
        &mut self,
        definiteness: Option<Definiteness>,
        noun: Symbol,
        adjectives: &[Symbol],
        pps: &[&'a LogicExpr<'a>],
        predicate: &'a LogicExpr<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>>;
    fn wrap_with_definiteness_for_object(
        &mut self,
        definiteness: Option<Definiteness>,
        noun: Symbol,
        predicate: &'a LogicExpr<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>>;
    fn substitute_pp_placeholder(&mut self, pp: &'a LogicExpr<'a>, var: Symbol) -> &'a LogicExpr<'a>;
    fn substitute_constant_with_var(
        &self,
        expr: &'a LogicExpr<'a>,
        constant_name: Symbol,
        var_name: Symbol,
    ) -> ParseResult<&'a LogicExpr<'a>>;
    fn substitute_constant_with_var_sym(
        &self,
        expr: &'a LogicExpr<'a>,
        constant_name: Symbol,
        var_name: Symbol,
    ) -> ParseResult<&'a LogicExpr<'a>>;
    fn substitute_constant_with_sigma(
        &self,
        expr: &'a LogicExpr<'a>,
        constant_name: Symbol,
        sigma_term: Term<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>>;
    fn find_main_verb_name(&self, expr: &LogicExpr<'a>) -> Option<Symbol>;
    fn transform_cardinal_to_group(&mut self, expr: &'a LogicExpr<'a>) -> ParseResult<&'a LogicExpr<'a>>;
    fn build_verb_neo_event(
        &mut self,
        verb: Symbol,
        subject_var: Symbol,
        object: Option<Term<'a>>,
        modifiers: Vec<Symbol>,
    ) -> &'a LogicExpr<'a>;
}

impl<'a, 'ctx, 'int> QuantifierParsing<'a, 'ctx, 'int> for Parser<'a, 'ctx, 'int> {
    fn parse_quantified(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let quantifier_token = self.previous().kind.clone();
        let var_name = self.next_var_name();

        // Track if we're inside a "No" quantifier - referents introduced here
        // are inaccessible for cross-sentence anaphora
        let was_in_negative_quantifier = self.in_negative_quantifier;
        if matches!(quantifier_token, TokenType::No) {
            self.in_negative_quantifier = true;
        }

        let subject_pred = self.parse_restriction(var_name)?;

        if self.check_modal() {
            use crate::ast::ModalFlavor;

            self.advance();
            let vector = self.token_to_vector(&self.previous().kind.clone());
            let verb = self.consume_content_word()?;

            // Parse object if present (e.g., "can enter the room" -> room is object)
            let obj_term = if self.check_content_word() || self.check_article() {
                let obj_np = self.parse_noun_phrase(false)?;
                Some(self.noun_phrase_to_term(&obj_np))
            } else {
                None
            };

            let verb_pred = self.build_verb_neo_event(verb, var_name, obj_term, vec![]);

            // Determine quantifier kind first (shared by both branches)
            let kind = match quantifier_token {
                TokenType::All | TokenType::No => QuantifierKind::Universal,
                TokenType::Any => {
                    if self.is_negative_context() {
                        QuantifierKind::Existential
                    } else {
                        QuantifierKind::Universal
                    }
                }
                TokenType::Some => QuantifierKind::Existential,
                TokenType::Most => QuantifierKind::Most,
                TokenType::Few => QuantifierKind::Few,
                TokenType::Many => QuantifierKind::Many,
                TokenType::Cardinal(n) => QuantifierKind::Cardinal(n),
                TokenType::AtLeast(n) => QuantifierKind::AtLeast(n),
                TokenType::AtMost(n) => QuantifierKind::AtMost(n),
                _ => {
                    return Err(ParseError {
                        kind: ParseErrorKind::UnknownQuantifier {
                            found: quantifier_token.clone(),
                        },
                        span: self.current_span(),
                    })
                }
            };

            // Branch on modal flavor for scope handling
            if vector.flavor == ModalFlavor::Root {
                // === NARROW SCOPE (De Re) ===
                // Root modals (can, must, should) attach to the predicate inside the quantifier
                // "Some birds can fly" → ∃x(Bird(x) ∧ ◇Fly(x))

                // Wrap the verb predicate in the modal
                let modal_verb = self.ctx.exprs.alloc(LogicExpr::Modal {
                    vector,
                    operand: verb_pred,
                });

                let body = match quantifier_token {
                    TokenType::All => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: subject_pred,
                        op: TokenType::If,
                        right: modal_verb,
                    }),
                    TokenType::Any => {
                        if self.is_negative_context() {
                            self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                left: subject_pred,
                                op: TokenType::And,
                                right: modal_verb,
                            })
                        } else {
                            self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                left: subject_pred,
                                op: TokenType::If,
                                right: modal_verb,
                            })
                        }
                    }
                    TokenType::Some
                    | TokenType::Most
                    | TokenType::Few
                    | TokenType::Many
                    | TokenType::Cardinal(_)
                    | TokenType::AtLeast(_)
                    | TokenType::AtMost(_) => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: subject_pred,
                        op: TokenType::And,
                        right: modal_verb,
                    }),
                    TokenType::No => {
                        let neg = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                            op: TokenType::Not,
                            operand: modal_verb,
                        });
                        self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: subject_pred,
                            op: TokenType::If,
                            right: neg,
                        })
                    }
                    _ => {
                        return Err(ParseError {
                            kind: ParseErrorKind::UnknownQuantifier {
                                found: quantifier_token.clone(),
                            },
                            span: self.current_span(),
                        })
                    }
                };

                // Build quantifier (modal is inside)
                let mut result = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind,
                    variable: var_name,
                    body,
                    island_id: self.current_island,
                });

                // Process donkey bindings for indefinites in restrictions (e.g., "who lacks a key")
                for (_noun, donkey_var, used, wide_neg) in self.donkey_bindings.iter().rev() {
                    if *used {
                        // Donkey anaphora: wrap with ∀ at outer scope
                        result = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                            kind: QuantifierKind::Universal,
                            variable: *donkey_var,
                            body: result,
                            island_id: self.current_island,
                        });
                    } else {
                        // Non-donkey: wrap with ∃ INSIDE the restriction
                        result = self.wrap_donkey_in_restriction(result, *donkey_var, *wide_neg);
                    }
                }
                self.donkey_bindings.clear();

                self.in_negative_quantifier = was_in_negative_quantifier;
                return Ok(result);

            } else {
                // === WIDE SCOPE (De Dicto) ===
                // Epistemic modals (might, may) wrap the entire quantifier
                // "Some unicorns might exist" → ◇∃x(Unicorn(x) ∧ Exist(x))

                let body = match quantifier_token {
                    TokenType::All => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: subject_pred,
                        op: TokenType::If,
                        right: verb_pred,
                    }),
                    TokenType::Any => {
                        if self.is_negative_context() {
                            self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                left: subject_pred,
                                op: TokenType::And,
                                right: verb_pred,
                            })
                        } else {
                            self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                left: subject_pred,
                                op: TokenType::If,
                                right: verb_pred,
                            })
                        }
                    }
                    TokenType::Some
                    | TokenType::Most
                    | TokenType::Few
                    | TokenType::Many
                    | TokenType::Cardinal(_)
                    | TokenType::AtLeast(_)
                    | TokenType::AtMost(_) => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: subject_pred,
                        op: TokenType::And,
                        right: verb_pred,
                    }),
                    TokenType::No => {
                        let neg = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                            op: TokenType::Not,
                            operand: verb_pred,
                        });
                        self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: subject_pred,
                            op: TokenType::If,
                            right: neg,
                        })
                    }
                    _ => {
                        return Err(ParseError {
                            kind: ParseErrorKind::UnknownQuantifier {
                                found: quantifier_token.clone(),
                            },
                            span: self.current_span(),
                        })
                    }
                };

                let mut result = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind,
                    variable: var_name,
                    body,
                    island_id: self.current_island,
                });

                // Process donkey bindings for indefinites in restrictions (e.g., "who lacks a key")
                for (_noun, donkey_var, used, wide_neg) in self.donkey_bindings.iter().rev() {
                    if *used {
                        // Donkey anaphora: wrap with ∀ at outer scope
                        result = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                            kind: QuantifierKind::Universal,
                            variable: *donkey_var,
                            body: result,
                            island_id: self.current_island,
                        });
                    } else {
                        // Non-donkey: wrap with ∃ INSIDE the restriction
                        result = self.wrap_donkey_in_restriction(result, *donkey_var, *wide_neg);
                    }
                }
                self.donkey_bindings.clear();

                // Wrap the entire quantifier in the modal
                self.in_negative_quantifier = was_in_negative_quantifier;
                return Ok(self.ctx.exprs.alloc(LogicExpr::Modal {
                    vector,
                    operand: result,
                }));
            }
        }

        if self.check_auxiliary() {
            let aux_token = self.advance();
            let aux_time = if let TokenType::Auxiliary(time) = aux_token.kind.clone() {
                time
            } else {
                Time::None
            };
            self.pending_time = Some(aux_time);

            let is_negated = self.match_token(&[TokenType::Not]);
            if is_negated {
                self.negative_depth += 1;
            }

            if self.check_verb() {
                let verb = self.consume_verb();

                // Convert aux_time to modifier
                let modifiers = match aux_time {
                    Time::Past => vec![self.interner.intern("Past")],
                    Time::Future => vec![self.interner.intern("Future")],
                    _ => vec![],
                };

                let verb_pred = self.build_verb_neo_event(verb, var_name, None, modifiers);

                let maybe_negated = if is_negated {
                    self.negative_depth -= 1;
                    self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                        op: TokenType::Not,
                        operand: verb_pred,
                    })
                } else {
                    verb_pred
                };

                let body = match quantifier_token {
                    TokenType::All | TokenType::Any => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: subject_pred,
                        op: TokenType::If,
                        right: maybe_negated,
                    }),
                    _ => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: subject_pred,
                        op: TokenType::And,
                        right: maybe_negated,
                    }),
                };

                let kind = match quantifier_token {
                    TokenType::All | TokenType::No => QuantifierKind::Universal,
                    TokenType::Some => QuantifierKind::Existential,
                    TokenType::Most => QuantifierKind::Most,
                    TokenType::Few => QuantifierKind::Few,
                    TokenType::Cardinal(n) => QuantifierKind::Cardinal(n),
                    TokenType::AtLeast(n) => QuantifierKind::AtLeast(n),
                    TokenType::AtMost(n) => QuantifierKind::AtMost(n),
                    _ => QuantifierKind::Universal,
                };

                self.in_negative_quantifier = was_in_negative_quantifier;
                return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind,
                    variable: var_name,
                    body,
                    island_id: self.current_island,
                }));
            }
        }

        // Only trigger presupposition if followed by gerund complement
        if self.check_presup_trigger() && self.is_followed_by_gerund() {
            let presup_kind = match self.advance().kind {
                TokenType::PresupTrigger(kind) => kind,
                TokenType::Verb { lemma, .. } => {
                    let s = self.interner.resolve(lemma).to_lowercase();
                    crate::lexicon::lookup_presup_trigger(&s)
                        .expect("Lexicon mismatch: Verb flagged as trigger but lookup failed")
                }
                _ => panic!("Expected presupposition trigger"),
            };

            let complement = if self.check_verb() {
                let verb = self.consume_verb();
                self.build_verb_neo_event(verb, var_name, None, vec![])
            } else {
                let unknown = self.interner.intern("?");
                self.ctx.exprs.alloc(LogicExpr::Atom(unknown))
            };

            let verb_pred = match presup_kind {
                PresupKind::Stop => self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                    op: TokenType::Not,
                    operand: complement,
                }),
                PresupKind::Start | PresupKind::Continue => complement,
                PresupKind::Regret | PresupKind::Realize | PresupKind::Know => complement,
            };

            let body = match quantifier_token {
                TokenType::All | TokenType::Any => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: subject_pred,
                    op: TokenType::If,
                    right: verb_pred,
                }),
                _ => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: subject_pred,
                    op: TokenType::And,
                    right: verb_pred,
                }),
            };

            let kind = match quantifier_token {
                TokenType::All | TokenType::No => QuantifierKind::Universal,
                TokenType::Some => QuantifierKind::Existential,
                TokenType::Most => QuantifierKind::Most,
                TokenType::Few => QuantifierKind::Few,
                TokenType::Many => QuantifierKind::Many,
                TokenType::Cardinal(n) => QuantifierKind::Cardinal(n),
                TokenType::AtLeast(n) => QuantifierKind::AtLeast(n),
                TokenType::AtMost(n) => QuantifierKind::AtMost(n),
                _ => QuantifierKind::Universal,
            };

            self.in_negative_quantifier = was_in_negative_quantifier;
            return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                kind,
                variable: var_name,
                body,
                island_id: self.current_island,
            }));
        }

        if self.check_verb() {
            let verb = self.consume_verb();
            let mut args = vec![Term::Variable(var_name)];

            if self.check_pronoun() {
                let token = self.peek().clone();
                if let TokenType::Pronoun { gender, .. } = token.kind {
                    self.advance();
                    if let Some(donkey_var) = self.resolve_donkey_pronoun(gender) {
                        args.push(Term::Variable(donkey_var));
                    } else {
                        let resolved = self.resolve_pronoun(gender, Number::Singular)?;
                        let term = match resolved {
                            super::ResolvedPronoun::Variable(s) => Term::Variable(s),
                            super::ResolvedPronoun::Constant(s) => Term::Constant(s),
                        };
                        args.push(term);
                    }
                }
            } else if self.check_npi_object() {
                let npi_token = self.advance().kind.clone();
                let obj_var = self.next_var_name();

                let restriction_name = match npi_token {
                    TokenType::Anything => "Thing",
                    TokenType::Anyone => "Person",
                    _ => "Thing",
                };

                let restriction_sym = self.interner.intern(restriction_name);
                let obj_restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: restriction_sym,
                    args: self.ctx.terms.alloc_slice([Term::Variable(obj_var)]),
                    world: None,
                });

                let verb_with_obj = self.build_verb_neo_event(
                    verb,
                    var_name,
                    Some(Term::Variable(obj_var)),
                    vec![],
                );

                let npi_body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: obj_restriction,
                    op: TokenType::And,
                    right: verb_with_obj,
                });

                let npi_quantified = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: obj_var,
                    body: npi_body,
                    island_id: self.current_island,
                });

                let negated_npi = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                    op: TokenType::Not,
                    operand: npi_quantified,
                });

                let body = match quantifier_token {
                    TokenType::All | TokenType::No => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: subject_pred,
                        op: TokenType::If,
                        right: negated_npi,
                    }),
                    _ => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: subject_pred,
                        op: TokenType::And,
                        right: negated_npi,
                    }),
                };

                let kind = match quantifier_token {
                    TokenType::All | TokenType::No => QuantifierKind::Universal,
                    TokenType::Some => QuantifierKind::Existential,
                    TokenType::Most => QuantifierKind::Most,
                    TokenType::Few => QuantifierKind::Few,
                    TokenType::Many => QuantifierKind::Many,
                    TokenType::Cardinal(n) => QuantifierKind::Cardinal(n),
                    TokenType::AtLeast(n) => QuantifierKind::AtLeast(n),
                    TokenType::AtMost(n) => QuantifierKind::AtMost(n),
                    _ => QuantifierKind::Universal,
                };

                self.in_negative_quantifier = was_in_negative_quantifier;
                return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind,
                    variable: var_name,
                    body,
                    island_id: self.current_island,
                }));
            } else if self.check_quantifier() || self.check_article() {
                let obj_quantifier = if self.check_quantifier() {
                    Some(self.advance().kind.clone())
                } else {
                    let art = self.advance().kind.clone();
                    if let TokenType::Article(def) = art {
                        if def == Definiteness::Indefinite {
                            Some(TokenType::Some)
                        } else {
                            None
                        }
                    } else {
                        None
                    }
                };

                let object = self.parse_noun_phrase(false)?;

                if let Some(obj_q) = obj_quantifier {
                    let obj_var = self.next_var_name();

                    // Introduce object referent in DRS for cross-sentence anaphora (telescoping)
                    // BUT: If inside "No X" quantifier, mark with NegationScope to block accessibility
                    let obj_gender = Self::infer_noun_gender(self.interner.resolve(object.noun));
                    let obj_number = if Self::is_plural_noun(self.interner.resolve(object.noun)) {
                        Number::Plural
                    } else {
                        Number::Singular
                    };
                    if self.in_negative_quantifier {
                        self.drs.introduce_referent_with_source(obj_var, object.noun, obj_gender, obj_number, ReferentSource::NegationScope);
                    } else {
                        self.drs.introduce_referent(obj_var, object.noun, obj_gender, obj_number);
                    }

                    let obj_restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: object.noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(obj_var)]),
                        world: None,
                    });

                    let verb_with_obj = self.build_verb_neo_event(
                        verb,
                        var_name,
                        Some(Term::Variable(obj_var)),
                        vec![],
                    );

                    let obj_kind = match obj_q {
                        TokenType::All => QuantifierKind::Universal,
                        TokenType::Some => QuantifierKind::Existential,
                        TokenType::No => QuantifierKind::Universal,
                        TokenType::Most => QuantifierKind::Most,
                        TokenType::Few => QuantifierKind::Few,
                        TokenType::Many => QuantifierKind::Many,
                        TokenType::Cardinal(n) => QuantifierKind::Cardinal(n),
                        TokenType::AtLeast(n) => QuantifierKind::AtLeast(n),
                        TokenType::AtMost(n) => QuantifierKind::AtMost(n),
                        _ => QuantifierKind::Existential,
                    };

                    let obj_body = match obj_q {
                        TokenType::All => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: obj_restriction,
                            op: TokenType::If,
                            right: verb_with_obj,
                        }),
                        TokenType::No => {
                            let neg = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                                op: TokenType::Not,
                                operand: verb_with_obj,
                            });
                            self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                left: obj_restriction,
                                op: TokenType::If,
                                right: neg,
                            })
                        }
                        _ => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: obj_restriction,
                            op: TokenType::And,
                            right: verb_with_obj,
                        }),
                    };

                    let obj_quantified = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                        kind: obj_kind,
                        variable: obj_var,
                        body: obj_body,
                        island_id: self.current_island,
                    });

                    let subj_kind = match quantifier_token {
                        TokenType::All | TokenType::No => QuantifierKind::Universal,
                        TokenType::Any => {
                            if self.is_negative_context() {
                                QuantifierKind::Existential
                            } else {
                                QuantifierKind::Universal
                            }
                        }
                        TokenType::Some => QuantifierKind::Existential,
                        TokenType::Most => QuantifierKind::Most,
                        TokenType::Few => QuantifierKind::Few,
                        TokenType::Many => QuantifierKind::Many,
                        TokenType::Cardinal(n) => QuantifierKind::Cardinal(n),
                        TokenType::AtLeast(n) => QuantifierKind::AtLeast(n),
                        TokenType::AtMost(n) => QuantifierKind::AtMost(n),
                        _ => QuantifierKind::Universal,
                    };

                    let subj_body = match quantifier_token {
                        TokenType::All => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: subject_pred,
                            op: TokenType::If,
                            right: obj_quantified,
                        }),
                        TokenType::No => {
                            let neg = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                                op: TokenType::Not,
                                operand: obj_quantified,
                            });
                            self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                left: subject_pred,
                                op: TokenType::If,
                                right: neg,
                            })
                        }
                        _ => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: subject_pred,
                            op: TokenType::And,
                            right: obj_quantified,
                        }),
                    };

                    self.in_negative_quantifier = was_in_negative_quantifier;
                    return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                        kind: subj_kind,
                        variable: var_name,
                        body: subj_body,
                        island_id: self.current_island,
                    }));
                } else {
                    args.push(Term::Constant(object.noun));
                }
            } else if self.check_content_word() {
                let object = self.parse_noun_phrase(false)?;
                args.push(Term::Constant(object.noun));
            }

            // Extract object term from args if present (args[0] is subject, args[1] is object)
            let obj_term = if args.len() > 1 {
                Some(args.remove(1))
            } else {
                None
            };
            let verb_pred = self.build_verb_neo_event(verb, var_name, obj_term, vec![]);

            let body = match quantifier_token {
                TokenType::All => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: subject_pred,
                    op: TokenType::If,
                    right: verb_pred,
                }),
                TokenType::Any => {
                    if self.is_negative_context() {
                        self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: subject_pred,
                            op: TokenType::And,
                            right: verb_pred,
                        })
                    } else {
                        self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: subject_pred,
                            op: TokenType::If,
                            right: verb_pred,
                        })
                    }
                }
                TokenType::Some
                | TokenType::Most
                | TokenType::Few
                | TokenType::Many
                | TokenType::Cardinal(_)
                | TokenType::AtLeast(_)
                | TokenType::AtMost(_) => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: subject_pred,
                    op: TokenType::And,
                    right: verb_pred,
                }),
                TokenType::No => {
                    let neg = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                        op: TokenType::Not,
                        operand: verb_pred,
                    });
                    self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: subject_pred,
                        op: TokenType::If,
                        right: neg,
                    })
                }
                _ => {
                    return Err(ParseError {
                        kind: ParseErrorKind::UnknownQuantifier {
                            found: quantifier_token.clone(),
                        },
                        span: self.current_span(),
                    })
                }
            };

            let kind = match quantifier_token {
                TokenType::All | TokenType::No => QuantifierKind::Universal,
                TokenType::Any => {
                    if self.is_negative_context() {
                        QuantifierKind::Existential
                    } else {
                        QuantifierKind::Universal
                    }
                }
                TokenType::Some => QuantifierKind::Existential,
                TokenType::Most => QuantifierKind::Most,
                TokenType::Few => QuantifierKind::Few,
                TokenType::Many => QuantifierKind::Many,
                TokenType::Cardinal(n) => QuantifierKind::Cardinal(n),
                TokenType::AtLeast(n) => QuantifierKind::AtLeast(n),
                TokenType::AtMost(n) => QuantifierKind::AtMost(n),
                _ => {
                    return Err(ParseError {
                        kind: ParseErrorKind::UnknownQuantifier {
                            found: quantifier_token.clone(),
                        },
                        span: self.current_span(),
                    })
                }
            };

            let mut result = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                kind,
                variable: var_name,
                body,
                island_id: self.current_island,
            });

            for (_noun, donkey_var, used, wide_neg) in self.donkey_bindings.iter().rev() {
                if *used {
                    // Donkey anaphora: wrap with ∀ at outer scope
                    result = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                        kind: QuantifierKind::Universal,
                        variable: *donkey_var,
                        body: result,
                        island_id: self.current_island,
                    });
                } else {
                    // Non-donkey: wrap with ∃ INSIDE the restriction
                    result = self.wrap_donkey_in_restriction(result, *donkey_var, *wide_neg);
                }
            }
            self.donkey_bindings.clear();

            self.in_negative_quantifier = was_in_negative_quantifier;
            return Ok(result);
        }

        self.consume_copula()?;

        let negative = self.match_token(&[TokenType::Not]);
        let predicate_np = self.parse_noun_phrase(true)?;

        let predicate_expr = self.ctx.exprs.alloc(LogicExpr::Predicate {
            name: predicate_np.noun,
            args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
            world: None,
        });

        let final_predicate = if negative {
            self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                op: TokenType::Not,
                operand: predicate_expr,
            })
        } else {
            predicate_expr
        };

        let body = match quantifier_token {
            TokenType::All => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: subject_pred,
                op: TokenType::If,
                right: final_predicate,
            }),
            TokenType::Any => {
                if self.is_negative_context() {
                    self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: subject_pred,
                        op: TokenType::And,
                        right: final_predicate,
                    })
                } else {
                    self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: subject_pred,
                        op: TokenType::If,
                        right: final_predicate,
                    })
                }
            }
            TokenType::Some
            | TokenType::Most
            | TokenType::Few
            | TokenType::Many
            | TokenType::Cardinal(_)
            | TokenType::AtLeast(_)
            | TokenType::AtMost(_) => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: subject_pred,
                op: TokenType::And,
                right: final_predicate,
            }),
            TokenType::No => {
                let neg_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: predicate_np.noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                    world: None,
                });
                let neg = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                    op: TokenType::Not,
                    operand: neg_pred,
                });
                self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: subject_pred,
                    op: TokenType::If,
                    right: neg,
                })
            }
            _ => {
                return Err(ParseError {
                    kind: ParseErrorKind::UnknownQuantifier {
                        found: quantifier_token.clone(),
                    },
                    span: self.current_span(),
                })
            }
        };

        let kind = match quantifier_token {
            TokenType::All | TokenType::No => QuantifierKind::Universal,
            TokenType::Any => {
                if self.is_negative_context() {
                    QuantifierKind::Existential
                } else {
                    QuantifierKind::Universal
                }
            }
            TokenType::Some => QuantifierKind::Existential,
            TokenType::Most => QuantifierKind::Most,
            TokenType::Few => QuantifierKind::Few,
            TokenType::Many => QuantifierKind::Many,
            TokenType::Cardinal(n) => QuantifierKind::Cardinal(n),
            TokenType::AtLeast(n) => QuantifierKind::AtLeast(n),
            TokenType::AtMost(n) => QuantifierKind::AtMost(n),
            _ => {
                return Err(ParseError {
                    kind: ParseErrorKind::UnknownQuantifier {
                        found: quantifier_token.clone(),
                    },
                    span: self.current_span(),
                })
            }
        };

        let mut result = self.ctx.exprs.alloc(LogicExpr::Quantifier {
            kind,
            variable: var_name,
            body,
            island_id: self.current_island,
        });

        for (_noun, donkey_var, used, wide_neg) in self.donkey_bindings.iter().rev() {
            if *used {
                // Donkey anaphora: wrap with ∀ at outer scope
                result = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Universal,
                    variable: *donkey_var,
                    body: result,
                    island_id: self.current_island,
                });
            } else {
                // Non-donkey: wrap with ∃ INSIDE the restriction
                result = self.wrap_donkey_in_restriction(result, *donkey_var, *wide_neg);
            }
        }
        self.donkey_bindings.clear();

        self.in_negative_quantifier = was_in_negative_quantifier;
        Ok(result)
    }

    fn parse_restriction(&mut self, var_name: Symbol) -> ParseResult<&'a LogicExpr<'a>> {
        let mut conditions: Vec<&'a LogicExpr<'a>> = Vec::new();

        loop {
            if self.is_at_end() {
                break;
            }

            let is_adjective = matches!(self.peek().kind, TokenType::Adjective(_));
            if !is_adjective {
                break;
            }

            let next_is_content = if self.current + 1 < self.tokens.len() {
                matches!(
                    self.tokens[self.current + 1].kind,
                    TokenType::Noun(_) | TokenType::Adjective(_) | TokenType::ProperName(_)
                )
            } else {
                false
            };

            if next_is_content {
                if let TokenType::Adjective(adj) = self.advance().kind.clone() {
                    conditions.push(self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: adj,
                        args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                        world: None,
                    }));
                }
            } else {
                break;
            }
        }

        let noun = self.consume_content_word()?;
        conditions.push(self.ctx.exprs.alloc(LogicExpr::Predicate {
            name: noun,
            args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
            world: None,
        }));

        while self.check(&TokenType::That) || self.check(&TokenType::Who) {
            self.advance();
            let clause_pred = self.parse_relative_clause(var_name)?;
            conditions.push(clause_pred);
        }

        self.combine_with_and(conditions)
    }

    fn parse_verb_phrase_for_restriction(&mut self, var_name: Symbol) -> ParseResult<&'a LogicExpr<'a>> {
        let var_term = Term::Variable(var_name);
        let verb = self.consume_verb();
        let verb_str_owned = self.interner.resolve(verb).to_string();

        // Check EARLY if verb is lexically negative (e.g., "lacks" -> "Have" with negation)
        // This determines whether donkey bindings need wide scope negation
        let (canonical_verb, is_negative) = get_canonical_verb(&verb_str_owned.to_lowercase())
            .map(|(lemma, neg)| (self.interner.intern(lemma), neg))
            .unwrap_or((verb, false));

        // Determine if this binding needs wide scope negation wrapping
        let needs_wide_scope = is_negative && self.negative_scope_mode == NegativeScopeMode::Wide;

        if Lexer::is_raising_verb(&verb_str_owned) && self.check_to() {
            self.advance();
            if self.check_verb() {
                let inf_verb = self.consume_verb();
                let inf_verb_str = self.interner.resolve(inf_verb).to_lowercase();

                if inf_verb_str == "be" && self.check_content_word() {
                    let adj = self.consume_content_word()?;
                    let embedded = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: adj,
                        args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                        world: None,
                    });
                    return Ok(self.ctx.exprs.alloc(LogicExpr::Scopal {
                        operator: verb,
                        body: embedded,
                    }));
                }

                let embedded = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: inf_verb,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                    world: None,
                });
                return Ok(self.ctx.exprs.alloc(LogicExpr::Scopal {
                    operator: verb,
                    body: embedded,
                }));
            } else if self.check(&TokenType::Is) || self.check(&TokenType::Are) {
                self.advance();
                if self.check_content_word() {
                    let adj = self.consume_content_word()?;
                    let embedded = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: adj,
                        args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                        world: None,
                    });
                    return Ok(self.ctx.exprs.alloc(LogicExpr::Scopal {
                        operator: verb,
                        body: embedded,
                    }));
                }
            }
        }

        let mut args = vec![var_term];
        let mut extra_conditions: Vec<&'a LogicExpr<'a>> = Vec::new();

        if self.check(&TokenType::Reflexive) {
            self.advance();
            args.push(Term::Variable(var_name));
        } else if (self.check_content_word() || self.check_article()) && !self.check_verb() {
            if matches!(
                self.peek().kind,
                TokenType::Article(Definiteness::Indefinite)
            ) {
                self.advance();
                let noun = self.consume_content_word()?;
                let donkey_var = self.next_var_name();

                if needs_wide_scope {
                    // === WIDE SCOPE MODE ===
                    // Build ¬∃y(Key(y) ∧ ∃e(Have(e) ∧ Agent(e,x) ∧ Theme(e,y))) directly
                    //
                    // We capture the binding HERE and return the complete structure.
                    // DO NOT push to donkey_bindings - that would leak y to outer scope.

                    // Build: Key(y)
                    let restriction_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(donkey_var)]),
                        world: None,
                    });

                    // Build: ∃e(Have(e) ∧ Agent(e,x) ∧ Theme(e,y)) using Neo-Davidsonian semantics
                    // IMPORTANT: Use build_verb_neo_event() for consistent Full-tier formatting
                    let verb_pred = self.build_verb_neo_event(
                        canonical_verb,
                        var_name,
                        Some(Term::Variable(donkey_var)),
                        vec![],
                    );

                    // Build: Key(y) ∧ ∃e(Have(e) ∧ Agent(e,x) ∧ Theme(e,y))
                    let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: restriction_pred,
                        op: TokenType::And,
                        right: verb_pred,
                    });

                    // Build: ∃y(Key(y) ∧ ∃e(Have(e) ∧ ...))
                    let existential = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                        kind: QuantifierKind::Existential,
                        variable: donkey_var,
                        body,
                        island_id: self.current_island,
                    });

                    // Build: ¬∃y(Key(y) ∧ ∃e(Have(e) ∧ ...))
                    let negated_existential = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                        op: TokenType::Not,
                        operand: existential,
                    });

                    // Return the complete wide-scope structure directly
                    return Ok(negated_existential);
                }

                // === NARROW SCOPE MODE ===
                // Push binding for later processing (normal donkey binding flow)
                self.donkey_bindings.push((noun, donkey_var, false, false));

                extra_conditions.push(self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(donkey_var)]),
                    world: None,
                }));

                args.push(Term::Variable(donkey_var));
            } else {
                let object = self.parse_noun_phrase(false)?;

                if self.check(&TokenType::That) || self.check(&TokenType::Who) {
                    self.advance();
                    let nested_var = self.next_var_name();
                    let nested_rel = self.parse_relative_clause(nested_var)?;

                    extra_conditions.push(self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: object.noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(nested_var)]),
                        world: None,
                    }));
                    extra_conditions.push(nested_rel);
                    args.push(Term::Variable(nested_var));
                } else {
                    args.push(Term::Constant(object.noun));
                }
            }
        }

        while self.check_preposition() {
            self.advance();
            if self.check(&TokenType::Reflexive) {
                self.advance();
                args.push(Term::Variable(var_name));
            } else if self.check_content_word() || self.check_article() {
                let object = self.parse_noun_phrase(false)?;

                if self.check(&TokenType::That) || self.check(&TokenType::Who) {
                    self.advance();
                    let nested_var = self.next_var_name();
                    let nested_rel = self.parse_relative_clause(nested_var)?;
                    extra_conditions.push(self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: object.noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(nested_var)]),
                        world: None,
                    }));
                    extra_conditions.push(nested_rel);
                    args.push(Term::Variable(nested_var));
                } else {
                    args.push(Term::Constant(object.noun));
                }
            }
        }

        // Use the canonical verb determined at top of function
        // Extract object term from args if present (args[0] is subject, args[1] is object)
        let obj_term = if args.len() > 1 {
            Some(args.remove(1))
        } else {
            None
        };
        let base_pred = self.build_verb_neo_event(canonical_verb, var_name, obj_term, vec![]);

        // Wrap in negation only for NARROW scope mode (de re reading)
        // Wide scope mode: negation handled via donkey binding flag in wrap_donkey_in_restriction
        // - Narrow: ∃y(Key(y) ∧ ¬Have(x,y)) - "missing ANY key"
        // - Wide:   ¬∃y(Key(y) ∧ Have(x,y)) - "has NO keys"
        let verb_pred = if is_negative && self.negative_scope_mode == NegativeScopeMode::Narrow {
            self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                op: TokenType::Not,
                operand: base_pred,
            })
        } else {
            base_pred
        };

        if extra_conditions.is_empty() {
            Ok(verb_pred)
        } else {
            extra_conditions.push(verb_pred);
            self.combine_with_and(extra_conditions)
        }
    }

    fn combine_with_and(&self, mut exprs: Vec<&'a LogicExpr<'a>>) -> ParseResult<&'a LogicExpr<'a>> {
        if exprs.is_empty() {
            return Err(ParseError {
                kind: ParseErrorKind::EmptyRestriction,
                span: self.current_span(),
            });
        }
        if exprs.len() == 1 {
            return Ok(exprs.remove(0));
        }
        let mut root = exprs.remove(0);
        for expr in exprs {
            root = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: root,
                op: TokenType::And,
                right: expr,
            });
        }
        Ok(root)
    }

    fn wrap_with_definiteness_full(
        &mut self,
        np: &NounPhrase<'a>,
        predicate: &'a LogicExpr<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        let result = self.wrap_with_definiteness_and_adjectives_and_pps(
            np.definiteness,
            np.noun,
            np.adjectives,
            np.pps,
            predicate,
        )?;

        // If NP has a superlative, add the superlative constraint
        if let Some(adj) = np.superlative {
            let superlative_expr = self.ctx.exprs.alloc(LogicExpr::Superlative {
                adjective: adj,
                subject: self.ctx.terms.alloc(Term::Constant(np.noun)),
                domain: np.noun,
            });
            Ok(self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: result,
                op: TokenType::And,
                right: superlative_expr,
            }))
        } else {
            Ok(result)
        }
    }

    fn wrap_with_definiteness(
        &mut self,
        definiteness: Option<Definiteness>,
        noun: Symbol,
        predicate: &'a LogicExpr<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        self.wrap_with_definiteness_and_adjectives_and_pps(definiteness, noun, &[], &[], predicate)
    }

    fn wrap_with_definiteness_and_adjectives(
        &mut self,
        definiteness: Option<Definiteness>,
        noun: Symbol,
        adjectives: &[Symbol],
        predicate: &'a LogicExpr<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        self.wrap_with_definiteness_and_adjectives_and_pps(
            definiteness,
            noun,
            adjectives,
            &[],
            predicate,
        )
    }

    fn wrap_with_definiteness_and_adjectives_and_pps(
        &mut self,
        definiteness: Option<Definiteness>,
        noun: Symbol,
        adjectives: &[Symbol],
        pps: &[&'a LogicExpr<'a>],
        predicate: &'a LogicExpr<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        match definiteness {
            Some(Definiteness::Indefinite) => {
                let var = self.next_var_name();

                // Introduce referent into DRS for cross-sentence anaphora
                // If inside a "No" quantifier, mark as NegationScope (inaccessible)
                let gender = Self::infer_noun_gender(self.interner.resolve(noun));
                let number = if Self::is_plural_noun(self.interner.resolve(noun)) {
                    Number::Plural
                } else {
                    Number::Singular
                };
                if self.in_negative_quantifier {
                    self.drs.introduce_referent_with_source(var, noun, gender, number, ReferentSource::NegationScope);
                } else {
                    self.drs.introduce_referent(var, noun, gender, number);
                }

                let mut restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var)]),
                    world: None,
                });

                for adj in adjectives {
                    let adj_str = self.interner.resolve(*adj).to_lowercase();
                    let adj_pred = if is_subsective(&adj_str) {
                        self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: *adj,
                            args: self.ctx.terms.alloc_slice([
                                Term::Variable(var),
                                Term::Intension(noun),
                            ]),
                            world: None,
                        })
                    } else {
                        self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: *adj,
                            args: self.ctx.terms.alloc_slice([Term::Variable(var)]),
                            world: None,
                        })
                    };
                    restriction = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: restriction,
                        op: TokenType::And,
                        right: adj_pred,
                    });
                }

                for pp in pps {
                    let substituted_pp = self.substitute_pp_placeholder(pp, var);
                    restriction = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: restriction,
                        op: TokenType::And,
                        right: substituted_pp,
                    });
                }

                let substituted = self.substitute_constant_with_var_sym(predicate, noun, var)?;
                let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: restriction,
                    op: TokenType::And,
                    right: substituted,
                });
                Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: var,
                    body,
                    island_id: self.current_island,
                }))
            }
            Some(Definiteness::Definite) => {
                let noun_str = self.interner.resolve(noun).to_string();

                if Self::is_plural_noun(&noun_str) {
                    let singular = Self::singularize_noun(&noun_str);
                    let singular_sym = self.interner.intern(&singular);
                    let sigma_term = Term::Sigma(singular_sym);

                    let substituted =
                        self.substitute_constant_with_sigma(predicate, noun, sigma_term)?;

                    let verb_name = self.find_main_verb_name(predicate);
                    let is_collective = verb_name
                        .map(|v| {
                            let lemma = self.interner.resolve(v);
                            Lexer::is_collective_verb(lemma)
                                || (Lexer::is_mixed_verb(lemma) && self.collective_mode)
                        })
                        .unwrap_or(false);

                    // Introduce definite plural referent to DRS for cross-sentence pronoun resolution
                    // E.g., "The dogs ran. They barked." - "they" refers to "dogs"
                    let gender = Gender::Unknown;  // Plural entities have unknown gender
                    self.drs.introduce_referent(singular_sym, singular_sym, gender, Number::Plural);

                    if is_collective {
                        Ok(substituted)
                    } else {
                        Ok(self.ctx.exprs.alloc(LogicExpr::Distributive {
                            predicate: substituted,
                        }))
                    }
                } else {
                    let x = self.next_var_name();
                    let y = self.next_var_name();

                    let mut restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(x)]),
                        world: None,
                    });

                    for adj in adjectives {
                        let adj_str = self.interner.resolve(*adj).to_lowercase();
                        let adj_pred = if is_subsective(&adj_str) {
                            self.ctx.exprs.alloc(LogicExpr::Predicate {
                                name: *adj,
                                args: self.ctx.terms.alloc_slice([
                                    Term::Variable(x),
                                    Term::Intension(noun),
                                ]),
                                world: None,
                            })
                        } else {
                            self.ctx.exprs.alloc(LogicExpr::Predicate {
                                name: *adj,
                                args: self.ctx.terms.alloc_slice([Term::Variable(x)]),
                                world: None,
                            })
                        };
                        restriction = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: restriction,
                            op: TokenType::And,
                            right: adj_pred,
                        });
                    }

                    for pp in pps {
                        let substituted_pp = self.substitute_pp_placeholder(pp, x);
                        restriction = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: restriction,
                            op: TokenType::And,
                            right: substituted_pp,
                        });
                    }

                    // Bridging anaphora: check if this noun is a part of a previously mentioned whole
                    // E.g., "I bought a car. The engine smoked." - engine is part of car
                    let has_prior_antecedent = self.drs.resolve_definite(
                        self.drs.current_box_index(),
                        noun
                    ).is_some();

                    if !has_prior_antecedent {
                        if let Some((whole_var, _whole_name)) = self.drs.resolve_bridging(self.interner, noun) {
                            let part_of_sym = self.interner.intern("PartOf");
                            let part_of_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                                name: part_of_sym,
                                args: self.ctx.terms.alloc_slice([
                                    Term::Variable(x),
                                    Term::Constant(whole_var),
                                ]),
                                world: None,
                            });
                            restriction = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                left: restriction,
                                op: TokenType::And,
                                right: part_of_pred,
                            });
                        }
                    }

                    // Introduce definite referent to DRS for cross-sentence pronoun resolution
                    // E.g., "The engine smoked. It broke." - "it" refers to "engine"
                    let gender = Self::infer_noun_gender(self.interner.resolve(noun));
                    let number = if Self::is_plural_noun(self.interner.resolve(noun)) {
                        Number::Plural
                    } else {
                        Number::Singular
                    };
                    self.drs.introduce_referent(x, noun, gender, number);

                    let mut y_restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(y)]),
                        world: None,
                    });
                    for adj in adjectives {
                        let adj_str = self.interner.resolve(*adj).to_lowercase();
                        let adj_pred = if is_subsective(&adj_str) {
                            self.ctx.exprs.alloc(LogicExpr::Predicate {
                                name: *adj,
                                args: self.ctx.terms.alloc_slice([
                                    Term::Variable(y),
                                    Term::Intension(noun),
                                ]),
                                world: None,
                            })
                        } else {
                            self.ctx.exprs.alloc(LogicExpr::Predicate {
                                name: *adj,
                                args: self.ctx.terms.alloc_slice([Term::Variable(y)]),
                                world: None,
                            })
                        };
                        y_restriction = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: y_restriction,
                            op: TokenType::And,
                            right: adj_pred,
                        });
                    }

                    for pp in pps {
                        let substituted_pp = self.substitute_pp_placeholder(pp, y);
                        y_restriction = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: y_restriction,
                            op: TokenType::And,
                            right: substituted_pp,
                        });
                    }

                    let identity = self.ctx.exprs.alloc(LogicExpr::Identity {
                        left: self.ctx.terms.alloc(Term::Variable(y)),
                        right: self.ctx.terms.alloc(Term::Variable(x)),
                    });
                    let uniqueness_body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: y_restriction,
                        op: TokenType::If,
                        right: identity,
                    });
                    let uniqueness = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                        kind: QuantifierKind::Universal,
                        variable: y,
                        body: uniqueness_body,
                        island_id: self.current_island,
                    });

                    let main_pred = self.substitute_constant_with_var_sym(predicate, noun, x)?;

                    let inner = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: restriction,
                        op: TokenType::And,
                        right: uniqueness,
                    });
                    let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: inner,
                        op: TokenType::And,
                        right: main_pred,
                    });

                    Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                        kind: QuantifierKind::Existential,
                        variable: x,
                        body,
                        island_id: self.current_island,
                    }))
                }
            }
            Some(Definiteness::Proximal) | Some(Definiteness::Distal) => {
                let var = self.next_var_name();

                let mut restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var)]),
                    world: None,
                });

                let deictic_name = if matches!(definiteness, Some(Definiteness::Proximal)) {
                    self.interner.intern("Proximal")
                } else {
                    self.interner.intern("Distal")
                };
                let deictic_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: deictic_name,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var)]),
                    world: None,
                });
                restriction = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: restriction,
                    op: TokenType::And,
                    right: deictic_pred,
                });

                for adj in adjectives {
                    let adj_str = self.interner.resolve(*adj).to_lowercase();
                    let adj_pred = if is_subsective(&adj_str) {
                        self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: *adj,
                            args: self.ctx.terms.alloc_slice([
                                Term::Variable(var),
                                Term::Intension(noun),
                            ]),
                            world: None,
                        })
                    } else {
                        self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: *adj,
                            args: self.ctx.terms.alloc_slice([Term::Variable(var)]),
                            world: None,
                        })
                    };
                    restriction = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: restriction,
                        op: TokenType::And,
                        right: adj_pred,
                    });
                }

                for pp in pps {
                    let substituted_pp = self.substitute_pp_placeholder(pp, var);
                    restriction = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: restriction,
                        op: TokenType::And,
                        right: substituted_pp,
                    });
                }

                let substituted = self.substitute_constant_with_var_sym(predicate, noun, var)?;
                let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: restriction,
                    op: TokenType::And,
                    right: substituted,
                });
                Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: var,
                    body,
                    island_id: self.current_island,
                }))
            }
            None => Ok(predicate),
        }
    }

    fn wrap_with_definiteness_for_object(
        &mut self,
        definiteness: Option<Definiteness>,
        noun: Symbol,
        predicate: &'a LogicExpr<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        match definiteness {
            Some(Definiteness::Indefinite) => {
                let var = self.next_var_name();

                // Introduce referent into DRS for cross-sentence anaphora
                // If inside a "No" quantifier, mark as NegationScope (inaccessible)
                let gender = Self::infer_noun_gender(self.interner.resolve(noun));
                let number = if Self::is_plural_noun(self.interner.resolve(noun)) {
                    Number::Plural
                } else {
                    Number::Singular
                };
                if self.in_negative_quantifier {
                    self.drs.introduce_referent_with_source(var, noun, gender, number, ReferentSource::NegationScope);
                } else {
                    self.drs.introduce_referent(var, noun, gender, number);
                }

                let type_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var)]),
                    world: None,
                });
                let substituted = self.substitute_constant_with_var(predicate, noun, var)?;
                let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: type_pred,
                    op: TokenType::And,
                    right: substituted,
                });
                Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: var,
                    body,
                    island_id: self.current_island,
                }))
            }
            Some(Definiteness::Definite) => {
                let x = self.next_var_name();
                let y = self.next_var_name();

                let type_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(x)]),
                    world: None,
                });

                let identity = self.ctx.exprs.alloc(LogicExpr::Identity {
                    left: self.ctx.terms.alloc(Term::Variable(y)),
                    right: self.ctx.terms.alloc(Term::Variable(x)),
                });
                let inner_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(y)]),
                    world: None,
                });
                let uniqueness_body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: inner_pred,
                    op: TokenType::If,
                    right: identity,
                });
                let uniqueness = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Universal,
                    variable: y,
                    body: uniqueness_body,
                    island_id: self.current_island,
                });

                let main_pred = self.substitute_constant_with_var(predicate, noun, x)?;

                let type_and_unique = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: type_pred,
                    op: TokenType::And,
                    right: uniqueness,
                });
                let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: type_and_unique,
                    op: TokenType::And,
                    right: main_pred,
                });

                Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: x,
                    body,
                    island_id: self.current_island,
                }))
            }
            Some(Definiteness::Proximal) | Some(Definiteness::Distal) => {
                let var = self.next_var_name();

                let mut restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var)]),
                    world: None,
                });

                let deictic_name = if matches!(definiteness, Some(Definiteness::Proximal)) {
                    self.interner.intern("Proximal")
                } else {
                    self.interner.intern("Distal")
                };
                let deictic_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: deictic_name,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var)]),
                    world: None,
                });
                restriction = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: restriction,
                    op: TokenType::And,
                    right: deictic_pred,
                });

                let substituted = self.substitute_constant_with_var(predicate, noun, var)?;
                let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: restriction,
                    op: TokenType::And,
                    right: substituted,
                });
                Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: var,
                    body,
                    island_id: self.current_island,
                }))
            }
            None => Ok(predicate),
        }
    }

    fn substitute_pp_placeholder(&mut self, pp: &'a LogicExpr<'a>, var: Symbol) -> &'a LogicExpr<'a> {
        let placeholder = self.interner.intern("_PP_SELF_");
        match pp {
            LogicExpr::Predicate { name, args, .. } => {
                let new_args: Vec<Term<'a>> = args
                    .iter()
                    .map(|arg| match arg {
                        Term::Variable(v) if *v == placeholder => Term::Variable(var),
                        other => *other,
                    })
                    .collect();
                self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: *name,
                    args: self.ctx.terms.alloc_slice(new_args),
                    world: None,
                })
            }
            _ => pp,
        }
    }

    fn substitute_constant_with_var(
        &self,
        expr: &'a LogicExpr<'a>,
        constant_name: Symbol,
        var_name: Symbol,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        match expr {
            LogicExpr::Predicate { name, args, .. } => {
                let new_args: Vec<Term<'a>> = args
                    .iter()
                    .map(|arg| match arg {
                        Term::Constant(c) if *c == constant_name => Term::Variable(var_name),
                        Term::Constant(c) => Term::Constant(*c),
                        Term::Variable(v) => Term::Variable(*v),
                        Term::Function(n, a) => Term::Function(*n, *a),
                        Term::Group(m) => Term::Group(*m),
                        Term::Possessed { possessor, possessed } => Term::Possessed {
                            possessor: *possessor,
                            possessed: *possessed,
                        },
                        Term::Sigma(p) => Term::Sigma(*p),
                        Term::Intension(p) => Term::Intension(*p),
                        Term::Proposition(e) => Term::Proposition(*e),
                        Term::Value { kind, unit, dimension } => Term::Value {
                            kind: *kind,
                            unit: *unit,
                            dimension: *dimension,
                        },
                    })
                    .collect();
                Ok(self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: *name,
                    args: self.ctx.terms.alloc_slice(new_args),
                    world: None,
                }))
            }
            LogicExpr::Temporal { operator, body } => Ok(self.ctx.exprs.alloc(LogicExpr::Temporal {
                operator: *operator,
                body: self.substitute_constant_with_var(body, constant_name, var_name)?,
            })),
            LogicExpr::Aspectual { operator, body } => Ok(self.ctx.exprs.alloc(LogicExpr::Aspectual {
                operator: *operator,
                body: self.substitute_constant_with_var(body, constant_name, var_name)?,
            })),
            LogicExpr::UnaryOp { op, operand } => Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                op: op.clone(),
                operand: self.substitute_constant_with_var(operand, constant_name, var_name)?,
            })),
            LogicExpr::BinaryOp { left, op, right } => Ok(self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: self.substitute_constant_with_var(left, constant_name, var_name)?,
                op: op.clone(),
                right: self.substitute_constant_with_var(right, constant_name, var_name)?,
            })),
            LogicExpr::Event { predicate, adverbs } => Ok(self.ctx.exprs.alloc(LogicExpr::Event {
                predicate: self.substitute_constant_with_var(predicate, constant_name, var_name)?,
                adverbs: *adverbs,
            })),
            LogicExpr::TemporalAnchor { anchor, body } => {
                Ok(self.ctx.exprs.alloc(LogicExpr::TemporalAnchor {
                    anchor: *anchor,
                    body: self.substitute_constant_with_var(body, constant_name, var_name)?,
                }))
            }
            LogicExpr::NeoEvent(data) => {
                // Substitute constants in thematic roles (Agent, Theme, etc.)
                let new_roles: Vec<(crate::ast::ThematicRole, Term<'a>)> = data
                    .roles
                    .iter()
                    .map(|(role, term)| {
                        let new_term = match term {
                            Term::Constant(c) if *c == constant_name => Term::Variable(var_name),
                            Term::Constant(c) => Term::Constant(*c),
                            Term::Variable(v) => Term::Variable(*v),
                            Term::Function(n, a) => Term::Function(*n, *a),
                            Term::Group(m) => Term::Group(*m),
                            Term::Possessed { possessor, possessed } => Term::Possessed {
                                possessor: *possessor,
                                possessed: *possessed,
                            },
                            Term::Sigma(p) => Term::Sigma(*p),
                            Term::Intension(p) => Term::Intension(*p),
                            Term::Proposition(e) => Term::Proposition(*e),
                            Term::Value { kind, unit, dimension } => Term::Value {
                                kind: *kind,
                                unit: *unit,
                                dimension: *dimension,
                            },
                        };
                        (*role, new_term)
                    })
                    .collect();
                Ok(self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(crate::ast::NeoEventData {
                    event_var: data.event_var,
                    verb: data.verb,
                    roles: self.ctx.roles.alloc_slice(new_roles),
                    modifiers: data.modifiers,
                    suppress_existential: data.suppress_existential,
                    world: None,
                }))))
            }
            // Recurse into nested quantifiers to substitute constants in their bodies
            LogicExpr::Quantifier { kind, variable, body, island_id } => {
                let new_body = self.substitute_constant_with_var(body, constant_name, var_name)?;
                Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: *kind,
                    variable: *variable,
                    body: new_body,
                    island_id: *island_id,
                }))
            }
            _ => Ok(expr),
        }
    }

    fn substitute_constant_with_var_sym(
        &self,
        expr: &'a LogicExpr<'a>,
        constant_name: Symbol,
        var_name: Symbol,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        self.substitute_constant_with_var(expr, constant_name, var_name)
    }

    fn substitute_constant_with_sigma(
        &self,
        expr: &'a LogicExpr<'a>,
        constant_name: Symbol,
        sigma_term: Term<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        match expr {
            LogicExpr::Predicate { name, args, .. } => {
                let new_args: Vec<Term<'a>> = args
                    .iter()
                    .map(|arg| match arg {
                        Term::Constant(c) if *c == constant_name => sigma_term.clone(),
                        Term::Constant(c) => Term::Constant(*c),
                        Term::Variable(v) => Term::Variable(*v),
                        Term::Function(n, a) => Term::Function(*n, *a),
                        Term::Group(m) => Term::Group(*m),
                        Term::Possessed { possessor, possessed } => Term::Possessed {
                            possessor: *possessor,
                            possessed: *possessed,
                        },
                        Term::Sigma(p) => Term::Sigma(*p),
                        Term::Intension(p) => Term::Intension(*p),
                        Term::Proposition(e) => Term::Proposition(*e),
                        Term::Value { kind, unit, dimension } => Term::Value {
                            kind: *kind,
                            unit: *unit,
                            dimension: *dimension,
                        },
                    })
                    .collect();
                Ok(self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: *name,
                    args: self.ctx.terms.alloc_slice(new_args),
                    world: None,
                }))
            }
            LogicExpr::Temporal { operator, body } => Ok(self.ctx.exprs.alloc(LogicExpr::Temporal {
                operator: *operator,
                body: self.substitute_constant_with_sigma(body, constant_name, sigma_term)?,
            })),
            LogicExpr::Aspectual { operator, body } => Ok(self.ctx.exprs.alloc(LogicExpr::Aspectual {
                operator: *operator,
                body: self.substitute_constant_with_sigma(body, constant_name, sigma_term)?,
            })),
            LogicExpr::UnaryOp { op, operand } => Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                op: op.clone(),
                operand: self.substitute_constant_with_sigma(operand, constant_name, sigma_term)?,
            })),
            LogicExpr::BinaryOp { left, op, right } => Ok(self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: self.substitute_constant_with_sigma(
                    left,
                    constant_name,
                    sigma_term.clone(),
                )?,
                op: op.clone(),
                right: self.substitute_constant_with_sigma(right, constant_name, sigma_term)?,
            })),
            LogicExpr::Event { predicate, adverbs } => Ok(self.ctx.exprs.alloc(LogicExpr::Event {
                predicate: self.substitute_constant_with_sigma(
                    predicate,
                    constant_name,
                    sigma_term,
                )?,
                adverbs: *adverbs,
            })),
            LogicExpr::TemporalAnchor { anchor, body } => {
                Ok(self.ctx.exprs.alloc(LogicExpr::TemporalAnchor {
                    anchor: *anchor,
                    body: self.substitute_constant_with_sigma(body, constant_name, sigma_term)?,
                }))
            }
            LogicExpr::NeoEvent(data) => {
                let new_roles: Vec<(crate::ast::ThematicRole, Term<'a>)> = data
                    .roles
                    .iter()
                    .map(|(role, term)| {
                        let new_term = match term {
                            Term::Constant(c) if *c == constant_name => sigma_term.clone(),
                            Term::Constant(c) => Term::Constant(*c),
                            Term::Variable(v) => Term::Variable(*v),
                            Term::Function(n, a) => Term::Function(*n, *a),
                            Term::Group(m) => Term::Group(*m),
                            Term::Possessed { possessor, possessed } => Term::Possessed {
                                possessor: *possessor,
                                possessed: *possessed,
                            },
                            Term::Sigma(p) => Term::Sigma(*p),
                            Term::Intension(p) => Term::Intension(*p),
                            Term::Proposition(e) => Term::Proposition(*e),
                            Term::Value { kind, unit, dimension } => Term::Value {
                                kind: *kind,
                                unit: *unit,
                                dimension: *dimension,
                            },
                        };
                        (*role, new_term)
                    })
                    .collect();
                Ok(self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(crate::ast::NeoEventData {
                    event_var: data.event_var,
                    verb: data.verb,
                    roles: self.ctx.roles.alloc_slice(new_roles),
                    modifiers: data.modifiers,
                    suppress_existential: data.suppress_existential,
                    world: None,
                }))))
            }
            LogicExpr::Distributive { predicate } => Ok(self.ctx.exprs.alloc(LogicExpr::Distributive {
                predicate: self.substitute_constant_with_sigma(predicate, constant_name, sigma_term)?,
            })),
            _ => Ok(expr),
        }
    }

    fn find_main_verb_name(&self, expr: &LogicExpr<'a>) -> Option<Symbol> {
        match expr {
            LogicExpr::Predicate { name, .. } => Some(*name),
            LogicExpr::NeoEvent(data) => Some(data.verb),
            LogicExpr::Temporal { body, .. } => self.find_main_verb_name(body),
            LogicExpr::Aspectual { body, .. } => self.find_main_verb_name(body),
            LogicExpr::Event { predicate, .. } => self.find_main_verb_name(predicate),
            LogicExpr::TemporalAnchor { body, .. } => self.find_main_verb_name(body),
            LogicExpr::UnaryOp { operand, .. } => self.find_main_verb_name(operand),
            LogicExpr::BinaryOp { left, .. } => self.find_main_verb_name(left),
            _ => None,
        }
    }

    fn transform_cardinal_to_group(&mut self, expr: &'a LogicExpr<'a>) -> ParseResult<&'a LogicExpr<'a>> {
        match expr {
            LogicExpr::Quantifier { kind: QuantifierKind::Cardinal(n), variable, body, .. } => {
                let group_var = self.interner.intern("g");
                let member_var = *variable;

                // Extract the restriction (first conjunct) and the body (rest)
                // The structure is: restriction ∧ body_rest
                let (restriction, body_rest) = match body {
                    LogicExpr::BinaryOp { left, op: TokenType::And, right } => (*left, *right),
                    _ => return Ok(expr),
                };

                // Substitute the member variable with the group variable in the body
                let transformed_body = self.substitute_constant_with_var_sym(body_rest, member_var, group_var)?;

                Ok(self.ctx.exprs.alloc(LogicExpr::GroupQuantifier {
                    group_var,
                    count: *n,
                    member_var,
                    restriction,
                    body: transformed_body,
                }))
            }
            // Recursively transform nested expressions
            LogicExpr::Temporal { operator, body } => {
                let transformed = self.transform_cardinal_to_group(body)?;
                Ok(self.ctx.exprs.alloc(LogicExpr::Temporal {
                    operator: *operator,
                    body: transformed,
                }))
            }
            LogicExpr::Aspectual { operator, body } => {
                let transformed = self.transform_cardinal_to_group(body)?;
                Ok(self.ctx.exprs.alloc(LogicExpr::Aspectual {
                    operator: *operator,
                    body: transformed,
                }))
            }
            LogicExpr::UnaryOp { op, operand } => {
                let transformed = self.transform_cardinal_to_group(operand)?;
                Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                    op: op.clone(),
                    operand: transformed,
                }))
            }
            LogicExpr::BinaryOp { left, op, right } => {
                let transformed_left = self.transform_cardinal_to_group(left)?;
                let transformed_right = self.transform_cardinal_to_group(right)?;
                Ok(self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: transformed_left,
                    op: op.clone(),
                    right: transformed_right,
                }))
            }
            LogicExpr::Distributive { predicate } => {
                let transformed = self.transform_cardinal_to_group(predicate)?;
                Ok(self.ctx.exprs.alloc(LogicExpr::Distributive {
                    predicate: transformed,
                }))
            }
            LogicExpr::Quantifier { kind, variable, body, island_id } => {
                let transformed = self.transform_cardinal_to_group(body)?;
                Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: kind.clone(),
                    variable: *variable,
                    body: transformed,
                    island_id: *island_id,
                }))
            }
            _ => Ok(expr),
        }
    }

    fn build_verb_neo_event(
        &mut self,
        verb: Symbol,
        subject_var: Symbol,
        object: Option<Term<'a>>,
        modifiers: Vec<Symbol>,
    ) -> &'a LogicExpr<'a> {
        let event_var = self.get_event_var();

        // Check if verb is unaccusative (intransitive subject is Theme, not Agent)
        let verb_str = self.interner.resolve(verb).to_lowercase();
        let is_unaccusative = lookup_verb_db(&verb_str)
            .map(|meta| meta.features.contains(&Feature::Unaccusative))
            .unwrap_or(false);

        // Determine subject role: unaccusative verbs without object use Theme
        let has_object = object.is_some();
        let subject_role = if is_unaccusative && !has_object {
            ThematicRole::Theme
        } else {
            ThematicRole::Agent
        };

        // Build roles vector
        let mut roles = vec![(subject_role, Term::Variable(subject_var))];
        if let Some(obj_term) = object {
            roles.push((ThematicRole::Theme, obj_term));
        }

        // Create NeoEventData with suppress_existential: false
        // Each quantified individual gets their own event (distributive reading)
        self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
            event_var,
            verb,
            roles: self.ctx.roles.alloc_slice(roles),
            modifiers: self.ctx.syms.alloc_slice(modifiers),
            suppress_existential: false,
            world: None,
        })))
    }
}

// Helper methods for donkey binding scope handling
impl<'a, 'ctx, 'int> Parser<'a, 'ctx, 'int> {
    /// Check if an expression mentions a specific variable
    fn expr_mentions_var(&self, expr: &LogicExpr<'a>, var: Symbol) -> bool {
        match expr {
            LogicExpr::Predicate { args, .. } => {
                args.iter().any(|term| self.term_mentions_var(term, var))
            }
            LogicExpr::BinaryOp { left, right, .. } => {
                self.expr_mentions_var(left, var) || self.expr_mentions_var(right, var)
            }
            LogicExpr::UnaryOp { operand, .. } => self.expr_mentions_var(operand, var),
            LogicExpr::Quantifier { body, .. } => self.expr_mentions_var(body, var),
            LogicExpr::NeoEvent(data) => {
                data.roles.iter().any(|(_, term)| self.term_mentions_var(term, var))
            }
            LogicExpr::Temporal { body, .. } => self.expr_mentions_var(body, var),
            LogicExpr::Aspectual { body, .. } => self.expr_mentions_var(body, var),
            LogicExpr::Event { predicate, .. } => self.expr_mentions_var(predicate, var),
            LogicExpr::Modal { operand, .. } => self.expr_mentions_var(operand, var),
            LogicExpr::Scopal { body, .. } => self.expr_mentions_var(body, var),
            _ => false,
        }
    }

    fn term_mentions_var(&self, term: &Term<'a>, var: Symbol) -> bool {
        match term {
            Term::Variable(v) => *v == var,
            Term::Function(_, args) => args.iter().any(|t| self.term_mentions_var(t, var)),
            _ => false,
        }
    }

    /// Collect all conjuncts from a conjunction tree
    fn collect_conjuncts(&self, expr: &'a LogicExpr<'a>) -> Vec<&'a LogicExpr<'a>> {
        match expr {
            LogicExpr::BinaryOp { left, op: TokenType::And, right } => {
                let mut result = self.collect_conjuncts(left);
                result.extend(self.collect_conjuncts(right));
                result
            }
            _ => vec![expr],
        }
    }

    /// Wrap unused donkey bindings inside the restriction/body of a quantifier structure.
    ///
    /// For universals (implications):
    ///   Transform: ∀x((P(x) ∧ Q(y)) → R(x)) with unused y
    ///   Into:      ∀x((P(x) ∧ ∃y(Q(y))) → R(x))
    ///
    /// For existentials (conjunctions):
    ///   Transform: ∃x(P(x) ∧ Q(y) ∧ R(x)) with unused y
    ///   Into:      ∃x(P(x) ∧ ∃y(Q(y)) ∧ R(x))
    ///
    /// If wide_scope_negation is true, wrap the existential in negation:
    ///   Into:      ∀x((P(x) ∧ ¬∃y(Q(y))) → R(x))
    fn wrap_donkey_in_restriction(
        &self,
        body: &'a LogicExpr<'a>,
        donkey_var: Symbol,
        wide_scope_negation: bool,
    ) -> &'a LogicExpr<'a> {
        // Handle Quantifier wrapping first
        if let LogicExpr::Quantifier { kind, variable, body: inner_body, island_id } = body {
            let transformed = self.wrap_donkey_in_restriction(inner_body, donkey_var, wide_scope_negation);
            return self.ctx.exprs.alloc(LogicExpr::Quantifier {
                kind: kind.clone(),
                variable: *variable,
                body: transformed,
                island_id: *island_id,
            });
        }

        // Handle implication (universal quantifiers)
        if let LogicExpr::BinaryOp { left, op: TokenType::If, right } = body {
            return self.wrap_in_implication(*left, *right, donkey_var, wide_scope_negation);
        }

        // Handle conjunction (existential quantifiers)
        if let LogicExpr::BinaryOp { left: _, op: TokenType::And, right: _ } = body {
            return self.wrap_in_conjunction(body, donkey_var, wide_scope_negation);
        }

        // Not a structure we can process
        body
    }

    /// Wrap donkey binding in an implication structure (∀x(P(x) → Q(x)))
    fn wrap_in_implication(
        &self,
        restriction: &'a LogicExpr<'a>,
        consequent: &'a LogicExpr<'a>,
        donkey_var: Symbol,
        wide_scope_negation: bool,
    ) -> &'a LogicExpr<'a> {
        // Collect all conjuncts in the restriction
        let conjuncts = self.collect_conjuncts(restriction);

        // Partition into those mentioning the donkey var and those not
        let (with_var, without_var): (Vec<_>, Vec<_>) = conjuncts
            .into_iter()
            .partition(|c| self.expr_mentions_var(c, donkey_var));

        if with_var.is_empty() {
            // Variable not found in restriction, return original implication
            return self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: restriction,
                op: TokenType::If,
                right: consequent,
            });
        }

        // Combine the "with var" conjuncts
        let with_var_combined = self.combine_conjuncts(&with_var);

        // Wrap with existential
        let existential = self.ctx.exprs.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Existential,
            variable: donkey_var,
            body: with_var_combined,
            island_id: self.current_island,
        });

        // For wide scope negation (de dicto reading of "lacks"), wrap ∃ in ¬
        let wrapped = if wide_scope_negation {
            self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                op: TokenType::Not,
                operand: existential,
            })
        } else {
            existential
        };

        // Combine with "without var" conjuncts
        let new_restriction = if without_var.is_empty() {
            wrapped
        } else {
            let without_combined = self.combine_conjuncts(&without_var);
            self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: without_combined,
                op: TokenType::And,
                right: wrapped,
            })
        };

        // Rebuild the implication
        self.ctx.exprs.alloc(LogicExpr::BinaryOp {
            left: new_restriction,
            op: TokenType::If,
            right: consequent,
        })
    }

    /// Wrap donkey binding in a conjunction structure (∃x(P(x) ∧ Q(x)))
    fn wrap_in_conjunction(
        &self,
        body: &'a LogicExpr<'a>,
        donkey_var: Symbol,
        wide_scope_negation: bool,
    ) -> &'a LogicExpr<'a> {
        // Collect all conjuncts
        let conjuncts = self.collect_conjuncts(body);

        // Partition into those mentioning the donkey var and those not
        let (with_var, without_var): (Vec<_>, Vec<_>) = conjuncts
            .into_iter()
            .partition(|c| self.expr_mentions_var(c, donkey_var));

        if with_var.is_empty() {
            // Variable not found, return unchanged
            return body;
        }

        // Combine the "with var" conjuncts
        let with_var_combined = self.combine_conjuncts(&with_var);

        // Wrap with existential
        let existential = self.ctx.exprs.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Existential,
            variable: donkey_var,
            body: with_var_combined,
            island_id: self.current_island,
        });

        // For wide scope negation (de dicto reading of "lacks"), wrap ∃ in ¬
        let wrapped = if wide_scope_negation {
            self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                op: TokenType::Not,
                operand: existential,
            })
        } else {
            existential
        };

        // Combine with "without var" conjuncts
        if without_var.is_empty() {
            wrapped
        } else {
            let without_combined = self.combine_conjuncts(&without_var);
            self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: without_combined,
                op: TokenType::And,
                right: wrapped,
            })
        }
    }

    fn combine_conjuncts(&self, conjuncts: &[&'a LogicExpr<'a>]) -> &'a LogicExpr<'a> {
        if conjuncts.is_empty() {
            panic!("Cannot combine empty conjuncts");
        }
        if conjuncts.len() == 1 {
            return conjuncts[0];
        }
        let mut result = conjuncts[0];
        for c in &conjuncts[1..] {
            result = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: result,
                op: TokenType::And,
                right: *c,
            });
        }
        result
    }
}

```

---

use super::clause::ClauseParsing;
use super::modal::ModalParsing;
use super::noun::NounParsing;
use super::pragmatics::PragmaticsParsing;
use super::{ParseResult, Parser};
use crate::ast::{
    AspectOperator, LogicExpr, NeoEventData, NounPhrase, QuantifierKind, TemporalOperator, Term,
    ThematicRole,
};
use crate::drs::{Gender, Number};
use crate::error::{ParseError, ParseErrorKind};
use crate::intern::Symbol;
use crate::lexer::Lexer;
use crate::lexicon::{Aspect, Definiteness, Time};
use crate::token::{FocusKind, Span, TokenType};

use crate::ast::Stmt;

pub trait LogicVerbParsing<'a, 'ctx, 'int> {
    fn parse_predicate_with_subject(&mut self, subject_symbol: Symbol)
        -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_predicate_with_subject_as_var(&mut self, subject_symbol: Symbol)
        -> ParseResult<&'a LogicExpr<'a>>;
    /// Try to parse a plural subject construction like "John and Mary verb".
    /// Returns Ok(Some(expr)) if successful, Ok(None) if not a plural subject (backtrack),
    /// or Err if there's a semantic error (e.g., "respectively" with mismatched lengths).
    fn try_parse_plural_subject(&mut self, first_subject: &NounPhrase<'a>)
        -> Result<Option<&'a LogicExpr<'a>>, ParseError>;
    fn parse_control_structure(
        &mut self,
        subject: &NounPhrase<'a>,
        verb: Symbol,
        verb_time: Time,
    ) -> ParseResult<&'a LogicExpr<'a>>;
    fn is_control_verb(&self, verb: Symbol) -> bool;
    /// Build a group predicate for intransitive verbs with multiple subjects
    fn build_group_predicate(
        &mut self,
        subjects: &[Symbol],
        verb: Symbol,
        verb_time: Time,
    ) -> &'a LogicExpr<'a>;
    /// Build a transitive predicate with group subject and group object
    fn build_group_transitive(
        &mut self,
        subjects: &[Symbol],
        objects: &[Symbol],
        verb: Symbol,
        verb_time: Time,
    ) -> &'a LogicExpr<'a>;
}

pub trait ImperativeVerbParsing<'a, 'ctx, 'int> {
    fn parse_statement_with_subject(&mut self, subject_symbol: Symbol)
        -> ParseResult<Stmt<'a>>;
}

impl<'a, 'ctx, 'int> Parser<'a, 'ctx, 'int> {
    fn parse_predicate_impl(
        &mut self,
        subject_symbol: Symbol,
        as_variable: bool,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        let subject_term = if as_variable {
            Term::Variable(subject_symbol)
        } else {
            Term::Constant(subject_symbol)
        };

        // Weather verb + expletive "it" detection: "it rains" → ∃e(Rain(e))
        let subject_str = self.interner.resolve(subject_symbol).to_lowercase();
        if subject_str == "it" && self.check_verb() {
            if let TokenType::Verb { lemma, time, .. } = &self.peek().kind {
                let lemma_str = self.interner.resolve(*lemma);
                if Lexer::is_weather_verb(lemma_str) {
                    let verb = *lemma;
                    let verb_time = *time;
                    self.advance(); // consume the weather verb

                    let event_var = self.get_event_var();
                    let suppress_existential = self.drs.in_conditional_antecedent();
                    if suppress_existential {
                        let event_class = self.interner.intern("Event");
                        self.drs.introduce_referent(event_var, event_class, Gender::Neuter, Number::Singular);
                    }
                    let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                        event_var,
                        verb,
                        roles: self.ctx.roles.alloc_slice(vec![]), // No thematic roles
                        modifiers: self.ctx.syms.alloc_slice(vec![]),
                        suppress_existential,
                        world: None,
                    })));

                    return Ok(match verb_time {
                        Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                            operator: TemporalOperator::Past,
                            body: neo_event,
                        }),
                        Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                            operator: TemporalOperator::Future,
                            body: neo_event,
                        }),
                        _ => neo_event,
                    });
                }
            }
        }

        // Weather adjective + expletive "it" detection: "it is wet" → Wet
        // Also handle "it's wet" where 's is Possessive token
        if subject_str == "it" && (self.check(&TokenType::Is) || self.check(&TokenType::Was) || self.check(&TokenType::Possessive)) {
            let saved_pos = self.current;
            self.advance(); // consume copula

            if self.check_content_word() {
                let adj_lexeme = self.peek().lexeme;
                let adj_str = self.interner.resolve(adj_lexeme).to_lowercase();

                if let Some(meta) = crate::lexicon::lookup_adjective_db(&adj_str) {
                    if meta.features.contains(&crate::lexicon::Feature::Weather) {
                        let adj_sym = self.consume_content_word().unwrap_or(adj_lexeme);
                        // Atmospheric predicate: "it is wet" → Wet
                        return Ok(self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: adj_sym,
                            args: self.ctx.terms.alloc_slice([]),
                            world: None,
                        }));
                    }
                }
            }
            // Not a weather adjective, restore position
            self.current = saved_pos;
        }

        if self.check(&TokenType::Never) {
            self.advance();
            let verb = self.consume_verb();
            let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice([subject_term]),
                world: None,
            });
            return Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                op: TokenType::Not,
                operand: verb_pred,
            }));
        }

        if self.check_modal() {
            return self.parse_aspect_chain_with_term(subject_term.clone());
        }

        if self.check_content_word() {
            let next_word = self.interner.resolve(self.peek().lexeme).to_lowercase();
            if next_word == "has" || next_word == "have" || next_word == "had" {
                // Look ahead to distinguish perfect aspect ("has eaten") from possession ("has 3 children")
                // Perfect aspect: has/have/had + verb
                // Possession: has/have/had + number/noun
                let is_perfect_aspect = if self.current + 1 < self.tokens.len() {
                    let next_token = &self.tokens[self.current + 1].kind;
                    matches!(
                        next_token,
                        TokenType::Verb { .. } | TokenType::Not
                    ) && !matches!(next_token, TokenType::Number(_))
                } else {
                    false
                };
                if is_perfect_aspect {
                    return self.parse_aspect_chain(subject_symbol);
                }
                // Otherwise, treat "has" as a main verb (possession) and continue below
            }
        }

        if self.check(&TokenType::Had) {
            return self.parse_aspect_chain(subject_symbol);
        }

        // Handle do-support: "I do/don't know who"
        if self.check(&TokenType::Does) || self.check(&TokenType::Do) {
            self.advance();
            let is_negated = self.match_token(&[TokenType::Not]);

            if self.check(&TokenType::Ever) {
                self.advance();
            }

            if self.check_verb() {
                let verb = self.consume_verb();

                // Check for embedded wh-clause with sluicing: "I don't know who"
                if self.check_wh_word() {
                    let wh_token = self.advance().kind.clone();
                    let is_who = matches!(wh_token, TokenType::Who);
                    let is_what = matches!(wh_token, TokenType::What);

                    let is_sluicing = self.is_at_end() ||
                        self.check(&TokenType::Period) ||
                        self.check(&TokenType::Comma);

                    if is_sluicing {
                        if let Some(template) = self.last_event_template.clone() {
                            let wh_var = self.next_var_name();

                            let roles: Vec<_> = if is_who {
                                std::iter::once((ThematicRole::Agent, Term::Variable(wh_var)))
                                    .chain(template.non_agent_roles.iter().cloned())
                                    .collect()
                            } else if is_what {
                                vec![
                                    (ThematicRole::Agent, subject_term.clone()),
                                    (ThematicRole::Theme, Term::Variable(wh_var)),
                                ]
                            } else {
                                std::iter::once((ThematicRole::Agent, Term::Variable(wh_var)))
                                    .chain(template.non_agent_roles.iter().cloned())
                                    .collect()
                            };

                            let event_var = self.get_event_var();
                            let suppress_existential = self.drs.in_conditional_antecedent();
                            let reconstructed = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                                event_var,
                                verb: template.verb,
                                roles: self.ctx.roles.alloc_slice(roles),
                                modifiers: self.ctx.syms.alloc_slice(template.modifiers.clone()),
                                suppress_existential,
                                world: None,
                            })));

                            let question = self.ctx.exprs.alloc(LogicExpr::Question {
                                wh_variable: wh_var,
                                body: reconstructed,
                            });

                            let know_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                                event_var: self.get_event_var(),
                                verb,
                                roles: self.ctx.roles.alloc_slice(vec![
                                    (ThematicRole::Agent, subject_term.clone()),
                                    (ThematicRole::Theme, Term::Proposition(question)),
                                ]),
                                modifiers: self.ctx.syms.alloc_slice(vec![]),
                                suppress_existential,
                                world: None,
                            })));

                            let result = if is_negated {
                                self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                                    op: TokenType::Not,
                                    operand: know_event,
                                })
                            } else {
                                know_event
                            };

                            return Ok(result);
                        }
                    }
                }

                // Regular do-support: "I do run" or "I don't run"
                let roles: Vec<(ThematicRole, Term<'a>)> = vec![(ThematicRole::Agent, subject_term.clone())];
                let modifiers: Vec<Symbol> = vec![];
                let event_var = self.get_event_var();
                let suppress_existential = self.drs.in_conditional_antecedent();

                let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                    event_var,
                    verb,
                    roles: self.ctx.roles.alloc_slice(roles),
                    modifiers: self.ctx.syms.alloc_slice(modifiers),
                    suppress_existential,
                    world: None,
                })));

                if is_negated {
                    return Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                        op: TokenType::Not,
                        operand: neo_event,
                    }));
                }
                return Ok(neo_event);
            }
        }

        if self.check_auxiliary() {
            let aux_time = if let TokenType::Auxiliary(time) = self.advance().kind {
                time
            } else {
                Time::None
            };
            self.pending_time = Some(aux_time);

            if self.match_token(&[TokenType::Not]) {
                self.negative_depth += 1;

                if self.check_verb() {
                    let verb = self.consume_verb();

                    if self.check_quantifier() {
                        let quantifier_token = self.advance().kind.clone();
                        let object_np = self.parse_noun_phrase(false)?;
                        let obj_var = self.next_var_name();

                        let obj_restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: object_np.noun,
                            args: self.ctx.terms.alloc_slice([Term::Variable(obj_var)]),
                            world: None,
                        });

                        let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: verb,
                            args: self
                                .ctx
                                .terms
                                .alloc_slice([subject_term, Term::Variable(obj_var)]),
                            world: None,
                        });

                        let (kind, body) = match quantifier_token {
                            TokenType::Any => {
                                if self.is_negative_context() {
                                    (
                                        QuantifierKind::Existential,
                                        self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                            left: obj_restriction,
                                            op: TokenType::And,
                                            right: verb_pred,
                                        }),
                                    )
                                } else {
                                    (
                                        QuantifierKind::Universal,
                                        self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                            left: obj_restriction,
                                            op: TokenType::If,
                                            right: verb_pred,
                                        }),
                                    )
                                }
                            }
                            TokenType::Some => (
                                QuantifierKind::Existential,
                                self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                    left: obj_restriction,
                                    op: TokenType::And,
                                    right: verb_pred,
                                }),
                            ),
                            TokenType::All => (
                                QuantifierKind::Universal,
                                self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                    left: obj_restriction,
                                    op: TokenType::If,
                                    right: verb_pred,
                                }),
                            ),
                            _ => (
                                QuantifierKind::Existential,
                                self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                    left: obj_restriction,
                                    op: TokenType::And,
                                    right: verb_pred,
                                }),
                            ),
                        };

                        let quantified = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                            kind,
                            variable: obj_var,
                            body,
                            island_id: self.current_island,
                        });

                        let effective_time = self.pending_time.take().unwrap_or(Time::None);
                        let with_time = match effective_time {
                            Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                                operator: TemporalOperator::Past,
                                body: quantified,
                            }),
                            Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                                operator: TemporalOperator::Future,
                                body: quantified,
                            }),
                            _ => quantified,
                        };

                        self.negative_depth -= 1;
                        return Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                            op: TokenType::Not,
                            operand: with_time,
                        }));
                    }

                    if self.check_npi_object() {
                        let npi_token = self.advance().kind.clone();
                        let obj_var = self.next_var_name();

                        let restriction_name = match npi_token {
                            TokenType::Anything => "Thing",
                            TokenType::Anyone => "Person",
                            _ => "Thing",
                        };

                        let restriction_sym = self.interner.intern(restriction_name);
                        let obj_restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: restriction_sym,
                            args: self.ctx.terms.alloc_slice([Term::Variable(obj_var)]),
                            world: None,
                        });

                        let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: verb,
                            args: self.ctx.terms.alloc_slice([subject_term, Term::Variable(obj_var)]),
                            world: None,
                        });

                        let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: obj_restriction,
                            op: TokenType::And,
                            right: verb_pred,
                        });

                        let quantified = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                            kind: QuantifierKind::Existential,
                            variable: obj_var,
                            body,
                            island_id: self.current_island,
                        });

                        let effective_time = self.pending_time.take().unwrap_or(Time::None);
                        let with_time = match effective_time {
                            Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                                operator: TemporalOperator::Past,
                                body: quantified,
                            }),
                            Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                                operator: TemporalOperator::Future,
                                body: quantified,
                            }),
                            _ => quantified,
                        };

                        self.negative_depth -= 1;
                        return Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                            op: TokenType::Not,
                            operand: with_time,
                        }));
                    }

                    let mut roles: Vec<(ThematicRole, Term<'a>)> =
                        vec![(ThematicRole::Agent, subject_term)];

                    if self.check_content_word() || self.check_article() {
                        let object = self.parse_noun_phrase(false)?;
                        let object_term = self.noun_phrase_to_term(&object);
                        roles.push((ThematicRole::Theme, object_term));
                    }

                    let event_var = self.get_event_var();
                    let suppress_existential = self.drs.in_conditional_antecedent();
                    let effective_time = self.pending_time.take().unwrap_or(Time::None);
                    let mut modifiers = Vec::new();
                    match effective_time {
                        Time::Past => modifiers.push(self.interner.intern("Past")),
                        Time::Future => modifiers.push(self.interner.intern("Future")),
                        _ => {}
                    }

                    let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                        event_var,
                        verb,
                        roles: self.ctx.roles.alloc_slice(roles),
                        modifiers: self.ctx.syms.alloc_slice(modifiers),
                        suppress_existential,
                        world: None,
                    })));

                    self.negative_depth -= 1;
                    return Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                        op: TokenType::Not,
                        operand: neo_event,
                    }));
                }

                self.negative_depth -= 1;
            }
        }

        if self.check(&TokenType::Is)
            || self.check(&TokenType::Are)
            || self.check(&TokenType::Was)
            || self.check(&TokenType::Were)
        {
            let copula_time = if self.check(&TokenType::Was) || self.check(&TokenType::Were) {
                Time::Past
            } else {
                Time::Present
            };
            self.advance();

            if self.check_verb() {
                let (verb, _verb_time, verb_aspect, verb_class) = self.consume_verb_with_metadata();

                // Stative verbs cannot be progressive
                if verb_class.is_stative() && verb_aspect == Aspect::Progressive {
                    return Err(crate::error::ParseError {
                        kind: crate::error::ParseErrorKind::StativeProgressiveConflict,
                        span: self.current_span(),
                    });
                }

                let predicate = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb,
                    args: self.ctx.terms.alloc_slice([subject_term]),
                    world: None,
                });

                let with_aspect = if verb_aspect == Aspect::Progressive {
                    // Semelfactive + Progressive → Iterative
                    let operator = if verb_class == crate::lexicon::VerbClass::Semelfactive {
                        AspectOperator::Iterative
                    } else {
                        AspectOperator::Progressive
                    };
                    self.ctx.exprs.alloc(LogicExpr::Aspectual {
                        operator,
                        body: predicate,
                    })
                } else {
                    predicate
                };

                return Ok(if copula_time == Time::Past {
                    self.ctx.exprs.alloc(LogicExpr::Temporal {
                        operator: TemporalOperator::Past,
                        body: with_aspect,
                    })
                } else {
                    with_aspect
                });
            }

            let predicate = self.consume_content_word()?;
            return Ok(self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: predicate,
                args: self.ctx.terms.alloc_slice([subject_term]),
                world: None,
            }));
        }

        if self.check_verb() {
            let (mut verb, verb_time, verb_aspect, verb_class) = self.consume_verb_with_metadata();
            let mut args = vec![subject_term.clone()];

            // Check for embedded wh-clause: "I know who/what"
            if self.check_wh_word() {
                let wh_token = self.advance().kind.clone();

                let is_who = matches!(wh_token, TokenType::Who);
                let is_what = matches!(wh_token, TokenType::What);

                // Check for sluicing: wh-word followed by terminator
                let is_sluicing = self.is_at_end() ||
                    self.check(&TokenType::Period) ||
                    self.check(&TokenType::Comma);

                if is_sluicing {
                    if let Some(template) = self.last_event_template.clone() {
                        let wh_var = self.next_var_name();

                        let roles: Vec<_> = if is_who {
                            std::iter::once((ThematicRole::Agent, Term::Variable(wh_var)))
                                .chain(template.non_agent_roles.iter().cloned())
                                .collect()
                        } else if is_what {
                            vec![
                                (ThematicRole::Agent, subject_term.clone()),
                                (ThematicRole::Theme, Term::Variable(wh_var)),
                            ]
                        } else {
                            std::iter::once((ThematicRole::Agent, Term::Variable(wh_var)))
                                .chain(template.non_agent_roles.iter().cloned())
                                .collect()
                        };

                        let event_var = self.get_event_var();
                        let suppress_existential = self.drs.in_conditional_antecedent();
                        let reconstructed = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                            event_var,
                            verb: template.verb,
                            roles: self.ctx.roles.alloc_slice(roles),
                            modifiers: self.ctx.syms.alloc_slice(template.modifiers.clone()),
                            suppress_existential,
                            world: None,
                        })));

                        let question = self.ctx.exprs.alloc(LogicExpr::Question {
                            wh_variable: wh_var,
                            body: reconstructed,
                        });

                        let know_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                            event_var: self.get_event_var(),
                            verb,
                            roles: self.ctx.roles.alloc_slice(vec![
                                (ThematicRole::Agent, subject_term),
                                (ThematicRole::Theme, Term::Proposition(question)),
                            ]),
                            modifiers: self.ctx.syms.alloc_slice(vec![]),
                            suppress_existential,
                            world: None,
                        })));

                        return Ok(know_event);
                    }
                }

                // Non-sluicing: "I know who runs"
                let embedded = self.parse_embedded_wh_clause()?;
                let question = self.ctx.exprs.alloc(LogicExpr::Question {
                    wh_variable: self.interner.intern("x"),
                    body: embedded,
                });

                let suppress_existential = self.drs.in_conditional_antecedent();
                let know_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                    event_var: self.get_event_var(),
                    verb,
                    roles: self.ctx.roles.alloc_slice(vec![
                        (ThematicRole::Agent, subject_term),
                        (ThematicRole::Theme, Term::Proposition(question)),
                    ]),
                    modifiers: self.ctx.syms.alloc_slice(vec![]),
                    suppress_existential,
                    world: None,
                })));

                return Ok(know_event);
            }

            let mut object_term: Option<Term<'a>> = None;
            let mut second_object_term: Option<Term<'a>> = None;
            let mut object_pps: &[&LogicExpr<'a>] = &[];  // PPs attached to object NP (for NP-attachment mode)
            if self.check(&TokenType::Reflexive) {
                self.advance();
                let term = Term::Constant(subject_symbol);
                object_term = Some(term);
                args.push(term);
            } else if self.check_pronoun() {
                let token = self.advance().clone();
                let (gender, number) = match &token.kind {
                    TokenType::Pronoun { gender, number, .. } => (*gender, *number),
                    TokenType::Ambiguous { primary, alternatives } => {
                        if let TokenType::Pronoun { gender, number, .. } = **primary {
                            (gender, number)
                        } else {
                            alternatives.iter().find_map(|t| {
                                if let TokenType::Pronoun { gender, number, .. } = t {
                                    Some((*gender, *number))
                                } else {
                                    None
                                }
                            }).unwrap_or((Gender::Unknown, Number::Singular))
                        }
                    }
                    _ => (Gender::Unknown, Number::Singular),
                };

                let resolved = self.resolve_pronoun(gender, number)?;
                let term = match resolved {
                    super::ResolvedPronoun::Variable(s) => Term::Variable(s),
                    super::ResolvedPronoun::Constant(s) => Term::Constant(s),
                };
                object_term = Some(term);
                args.push(term);

                let verb_str = self.interner.resolve(verb);
                if Lexer::is_ditransitive_verb(verb_str)
                    && (self.check_content_word() || self.check_article())
                {
                    let second_np = self.parse_noun_phrase(false)?;
                    let second_term = Term::Constant(second_np.noun);
                    second_object_term = Some(second_term);
                    args.push(second_term);
                }
            } else if self.check_quantifier() || self.check_article() {
                let obj_quantifier = if self.check_quantifier() {
                    Some(self.advance().kind.clone())
                } else {
                    let art = self.advance().kind.clone();
                    if let TokenType::Article(def) = art {
                        if def == Definiteness::Indefinite {
                            Some(TokenType::Some)
                        } else {
                            None
                        }
                    } else {
                        None
                    }
                };

                let object_np = self.parse_noun_phrase(false)?;

                if let Some(obj_q) = obj_quantifier {
                    let obj_var = self.next_var_name();

                    // Introduce object referent in DRS for cross-sentence anaphora
                    let obj_gender = Self::infer_noun_gender(self.interner.resolve(object_np.noun));
                    let obj_number = if Self::is_plural_noun(self.interner.resolve(object_np.noun)) {
                        Number::Plural
                    } else {
                        Number::Singular
                    };
                    self.drs.introduce_referent(obj_var, object_np.noun, obj_gender, obj_number);

                    let obj_restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: object_np.noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(obj_var)]),
                        world: None,
                    });

                    let event_var = self.get_event_var();
                    let mut modifiers = self.collect_adverbs();
                    let effective_time = self.pending_time.take().unwrap_or(verb_time);
                    match effective_time {
                        Time::Past => modifiers.push(self.interner.intern("Past")),
                        Time::Future => modifiers.push(self.interner.intern("Future")),
                        _ => {}
                    }

                    let roles = vec![
                        (ThematicRole::Agent, subject_term),
                        (ThematicRole::Theme, Term::Variable(obj_var)),
                    ];

                    let suppress_existential = self.drs.in_conditional_antecedent();
                    let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                        event_var,
                        verb,
                        roles: self.ctx.roles.alloc_slice(roles),
                        modifiers: self.ctx.syms.alloc_slice(modifiers),
                        suppress_existential,
                        world: None,
                    })));

                    let obj_kind = match obj_q {
                        TokenType::All => QuantifierKind::Universal,
                        TokenType::Some => QuantifierKind::Existential,
                        TokenType::No => QuantifierKind::Universal,
                        TokenType::Most => QuantifierKind::Most,
                        TokenType::Few => QuantifierKind::Few,
                        TokenType::Many => QuantifierKind::Many,
                        TokenType::Cardinal(n) => QuantifierKind::Cardinal(n),
                        TokenType::AtLeast(n) => QuantifierKind::AtLeast(n),
                        TokenType::AtMost(n) => QuantifierKind::AtMost(n),
                        _ => QuantifierKind::Existential,
                    };

                    let obj_body = match obj_q {
                        TokenType::All => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: obj_restriction,
                            op: TokenType::If,
                            right: neo_event,
                        }),
                        TokenType::No => {
                            let neg = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                                op: TokenType::Not,
                                operand: neo_event,
                            });
                            self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                left: obj_restriction,
                                op: TokenType::If,
                                right: neg,
                            })
                        }
                        _ => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: obj_restriction,
                            op: TokenType::And,
                            right: neo_event,
                        }),
                    };

                    return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                        kind: obj_kind,
                        variable: obj_var,
                        body: obj_body,
                        island_id: self.current_island,
                    }));
                } else {
                    // Definite object NP (e.g., "the house")
                    // Introduce to DRS for cross-sentence bridging anaphora
                    // E.g., "John entered the house. The door was open." - door bridges to house
                    if object_np.definiteness == Some(Definiteness::Definite) {
                        let obj_gender = Self::infer_noun_gender(self.interner.resolve(object_np.noun));
                        let obj_number = if Self::is_plural_noun(self.interner.resolve(object_np.noun)) {
                            Number::Plural
                        } else {
                            Number::Singular
                        };
                        self.drs.introduce_referent(object_np.noun, object_np.noun, obj_gender, obj_number);
                    }

                    let term = Term::Constant(object_np.noun);
                    object_term = Some(term);
                    // Store PPs attached to object NP for NP-attachment mode
                    object_pps = object_np.pps;
                    args.push(term);
                }
            } else if self.check_focus() {
                let focus_kind = if let TokenType::Focus(k) = self.advance().kind {
                    k
                } else {
                    FocusKind::Only
                };

                let event_var = self.get_event_var();
                let mut modifiers = self.collect_adverbs();
                let effective_time = self.pending_time.take().unwrap_or(verb_time);
                match effective_time {
                    Time::Past => modifiers.push(self.interner.intern("Past")),
                    Time::Future => modifiers.push(self.interner.intern("Future")),
                    _ => {}
                }

                if self.check_preposition() {
                    let prep_token = self.advance().clone();
                    let prep_name = if let TokenType::Preposition(sym) = prep_token.kind {
                        sym
                    } else {
                        self.interner.intern("to")
                    };
                    let pp_obj = self.parse_noun_phrase(false)?;
                    let pp_obj_term = Term::Constant(pp_obj.noun);

                    let roles = vec![(ThematicRole::Agent, subject_term)];
                    let suppress_existential = self.drs.in_conditional_antecedent();
                    let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                        event_var,
                        verb,
                        roles: self.ctx.roles.alloc_slice(roles),
                        modifiers: self.ctx.syms.alloc_slice(modifiers),
                        suppress_existential,
                        world: None,
                    })));

                    let pp_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: prep_name,
                        args: self.ctx.terms.alloc_slice([Term::Variable(event_var), pp_obj_term]),
                        world: None,
                    });

                    let with_pp = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: neo_event,
                        op: TokenType::And,
                        right: pp_pred,
                    });

                    let focused_ref = self.ctx.terms.alloc(pp_obj_term);
                    return Ok(self.ctx.exprs.alloc(LogicExpr::Focus {
                        kind: focus_kind,
                        focused: focused_ref,
                        scope: with_pp,
                    }));
                }

                let focused_np = self.parse_noun_phrase(false)?;
                let focused_term = Term::Constant(focused_np.noun);
                args.push(focused_term);

                let roles = vec![
                    (ThematicRole::Agent, subject_term),
                    (ThematicRole::Theme, focused_term),
                ];

                let suppress_existential = self.drs.in_conditional_antecedent();
                let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                    event_var,
                    verb,
                    roles: self.ctx.roles.alloc_slice(roles),
                    modifiers: self.ctx.syms.alloc_slice(modifiers),
                    suppress_existential,
                    world: None,
                })));

                let focused_ref = self.ctx.terms.alloc(focused_term);
                return Ok(self.ctx.exprs.alloc(LogicExpr::Focus {
                    kind: focus_kind,
                    focused: focused_ref,
                    scope: neo_event,
                }));
            } else if self.check_number() {
                let measure = self.parse_measure_phrase()?;
                if self.check_content_word() {
                    let noun_sym = self.consume_content_word()?;
                    args.push(*measure);
                    args.push(Term::Constant(noun_sym));
                } else {
                    args.push(*measure);
                }
            } else if self.check_content_word() {
                let potential_object = self.parse_noun_phrase(false)?;
                // Store PPs attached to object NP for NP-attachment mode
                object_pps = potential_object.pps;

                if self.check_verb() && self.filler_gap.is_some() {
                    let embedded_subject = potential_object.noun;
                    let embedded_pred = self.parse_predicate_with_subject(embedded_subject)?;

                    let embedded_term = Term::Proposition(embedded_pred);
                    let main_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: verb,
                        args: self.ctx.terms.alloc_slice([subject_term, embedded_term]),
                        world: None,
                    });

                    let effective_time = self.pending_time.take().unwrap_or(verb_time);
                    return Ok(if effective_time == Time::Past {
                        self.ctx.exprs.alloc(LogicExpr::Temporal {
                            operator: TemporalOperator::Past,
                            body: main_pred,
                        })
                    } else {
                        main_pred
                    });
                }

                // Collect all objects for potential "respectively" handling
                let mut all_objects: Vec<Symbol> = vec![potential_object.noun];

                // Check for coordinated objects: "Tom and Jerry and Bob"
                while self.check(&TokenType::And) {
                    let saved = self.current;
                    self.advance(); // consume "and"
                    if self.check_content_word() || self.check_article() {
                        let next_obj = match self.parse_noun_phrase(false) {
                            Ok(np) => np,
                            Err(_) => {
                                self.current = saved;
                                break;
                            }
                        };
                        all_objects.push(next_obj.noun);
                    } else {
                        self.current = saved;
                        break;
                    }
                }

                // Check for "respectively" with single subject
                if self.check(&TokenType::Respectively) {
                    let respectively_span = self.peek().span;
                    // Single subject with multiple objects + respectively = error
                    if all_objects.len() > 1 {
                        return Err(ParseError {
                            kind: ParseErrorKind::RespectivelyLengthMismatch {
                                subject_count: 1,
                                object_count: all_objects.len(),
                            },
                            span: respectively_span,
                        });
                    }
                    // Single subject, single object + respectively is valid (trivially pairwise)
                    self.advance(); // consume "respectively"
                }

                // Use the first object (or only object) for normal processing
                let term = Term::Constant(all_objects[0]);
                object_term = Some(term);
                args.push(term);

                // For multiple objects without "respectively", use group semantics
                if all_objects.len() > 1 {
                    let obj_members: Vec<Term<'a>> = all_objects.iter()
                        .map(|o| Term::Constant(*o))
                        .collect();
                    let obj_group = Term::Group(self.ctx.terms.alloc_slice(obj_members));
                    // Replace the single object with the group
                    args.pop();
                    args.push(obj_group);
                }

                let verb_str = self.interner.resolve(verb);
                if Lexer::is_ditransitive_verb(verb_str)
                    && (self.check_content_word() || self.check_article())
                {
                    let second_np = self.parse_noun_phrase(false)?;
                    let second_term = Term::Constant(second_np.noun);
                    second_object_term = Some(second_term);
                    args.push(second_term);
                }
            } else if self.filler_gap.is_some() && !self.check_content_word() && !self.check_pronoun()
            {
                let gap_var = self.filler_gap.take().unwrap();
                let term = Term::Variable(gap_var);
                object_term = Some(term);
                args.push(term);
            }

            // Check for distanced phrasal verb particle: "gave the book up"
            if let TokenType::Particle(particle_sym) = self.peek().kind {
                let verb_str = self.interner.resolve(verb).to_lowercase();
                let particle_str = self.interner.resolve(particle_sym).to_lowercase();
                if let Some((phrasal_lemma, _class)) = crate::lexicon::lookup_phrasal_verb(&verb_str, &particle_str) {
                    self.advance(); // consume the particle
                    verb = self.interner.intern(phrasal_lemma);
                }
            }

            let unknown = self.interner.intern("?");
            let mut pp_predicates: Vec<&'a LogicExpr<'a>> = Vec::new();
            while self.check_preposition() || self.check_to() {
                let prep_token = self.advance().clone();
                let prep_name = if let TokenType::Preposition(sym) = prep_token.kind {
                    sym
                } else if matches!(prep_token.kind, TokenType::To) {
                    self.interner.intern("To")
                } else {
                    continue;
                };

                let pp_obj_term = if self.check(&TokenType::Reflexive) {
                    self.advance();
                    Term::Constant(subject_symbol)
                } else if self.check_pronoun() {
                    let token = self.advance().clone();
                    let (gender, number) = match &token.kind {
                        TokenType::Pronoun { gender, number, .. } => (*gender, *number),
                        TokenType::Ambiguous { primary, alternatives } => {
                            if let TokenType::Pronoun { gender, number, .. } = **primary {
                                (gender, number)
                            } else {
                                alternatives.iter().find_map(|t| {
                                    if let TokenType::Pronoun { gender, number, .. } = t {
                                        Some((*gender, *number))
                                    } else {
                                        None
                                    }
                                }).unwrap_or((Gender::Unknown, Number::Singular))
                            }
                        }
                        _ => (Gender::Unknown, Number::Singular),
                    };
                    let resolved = self.resolve_pronoun(gender, number)?;
                    match resolved {
                        super::ResolvedPronoun::Variable(s) => Term::Variable(s),
                        super::ResolvedPronoun::Constant(s) => Term::Constant(s),
                    }
                } else if self.check_content_word() || self.check_article() {
                    let prep_obj = self.parse_noun_phrase(false)?;
                    Term::Constant(prep_obj.noun)
                } else {
                    continue;
                };

                if self.pp_attach_to_noun {
                    if let Some(obj) = object_term {
                        let pp_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: prep_name,
                            args: self.ctx.terms.alloc_slice([obj, pp_obj_term]),
                            world: None,
                        });
                        pp_predicates.push(pp_pred);
                    } else {
                        args.push(pp_obj_term);
                    }
                } else {
                    let event_sym = self.get_event_var();
                    let pp_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: prep_name,
                        args: self
                            .ctx
                            .terms
                            .alloc_slice([Term::Variable(event_sym), pp_obj_term]),
                        world: None,
                    });
                    pp_predicates.push(pp_pred);
                }
            }

            if self.check(&TokenType::That) || self.check(&TokenType::Who) {
                self.advance();
                let rel_var = self.next_var_name();
                let rel_pred = self.parse_relative_clause(rel_var)?;
                pp_predicates.push(rel_pred);
            }

            let mut modifiers = self.collect_adverbs();

            let effective_time = self.pending_time.take().unwrap_or(verb_time);
            match effective_time {
                Time::Past => modifiers.push(self.interner.intern("Past")),
                Time::Future => modifiers.push(self.interner.intern("Future")),
                _ => {}
            }

            if verb_aspect == Aspect::Progressive {
                modifiers.push(self.interner.intern("Progressive"));
            } else if verb_aspect == Aspect::Perfect {
                modifiers.push(self.interner.intern("Perfect"));
            }

            let mut roles: Vec<(ThematicRole, Term<'a>)> = Vec::new();

            // Check if verb is unaccusative (intransitive subject is Theme, not Agent)
            let verb_str = self.interner.resolve(verb).to_lowercase();
            let is_unaccusative = crate::lexicon::lookup_verb_db(&verb_str)
                .map(|meta| meta.features.contains(&crate::lexicon::Feature::Unaccusative))
                .unwrap_or(false);

            // Unaccusative verbs used intransitively: subject is Theme
            // E.g., "The alarm triggers" → Theme(e, Alarm), not Agent(e, Alarm)
            let has_object = object_term.is_some() || second_object_term.is_some();
            let subject_role = if is_unaccusative && !has_object {
                ThematicRole::Theme
            } else {
                ThematicRole::Agent
            };

            roles.push((subject_role, subject_term));
            if let Some(second_obj) = second_object_term {
                if let Some(first_obj) = object_term {
                    roles.push((ThematicRole::Recipient, first_obj));
                }
                roles.push((ThematicRole::Theme, second_obj));
            } else if let Some(obj) = object_term {
                roles.push((ThematicRole::Theme, obj));
            }

            let event_var = self.get_event_var();
            let suppress_existential = self.drs.in_conditional_antecedent();
            if suppress_existential {
                let event_class = self.interner.intern("Event");
                self.drs.introduce_referent(event_var, event_class, Gender::Neuter, Number::Singular);
            }
            let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                event_var,
                verb,
                roles: self.ctx.roles.alloc_slice(roles.clone()),
                modifiers: self.ctx.syms.alloc_slice(modifiers.clone()),
                suppress_existential,
                world: None,
            })));

            // Capture template for ellipsis reconstruction
            self.capture_event_template(verb, &roles, &modifiers);

            let with_pps = if pp_predicates.is_empty() {
                neo_event
            } else {
                let mut combined = neo_event;
                for pp in pp_predicates {
                    combined = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: combined,
                        op: TokenType::And,
                        right: pp,
                    });
                }
                combined
            };

            // Include PPs attached to object NP (for NP-attachment mode)
            // These have _PP_SELF_ placeholder that needs to be replaced with the object term
            let with_object_pps = if object_pps.is_empty() {
                with_pps
            } else if let Some(obj_term) = object_term {
                let placeholder = self.interner.intern("_PP_SELF_");
                let mut combined = with_pps;
                for pp in object_pps {
                    // Substitute _PP_SELF_ placeholder with the object term
                    let substituted = match pp {
                        LogicExpr::Predicate { name, args, .. } => {
                            let new_args: Vec<Term<'a>> = args
                                .iter()
                                .map(|arg| match arg {
                                    Term::Variable(v) if *v == placeholder => obj_term,
                                    other => *other,
                                })
                                .collect();
                            self.ctx.exprs.alloc(LogicExpr::Predicate {
                                name: *name,
                                args: self.ctx.terms.alloc_slice(new_args),
                                world: None,
                            })
                        }
                        _ => *pp,
                    };
                    combined = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: combined,
                        op: TokenType::And,
                        right: substituted,
                    });
                }
                combined
            } else {
                with_pps
            };

            // Apply aspectual operators based on verb class
            let with_aspect = if verb_aspect == Aspect::Simple && effective_time == Time::Present {
                // Non-state verbs in simple present get Habitual reading
                if !verb_class.is_stative() {
                    self.ctx.exprs.alloc(LogicExpr::Aspectual {
                        operator: AspectOperator::Habitual,
                        body: with_object_pps,
                    })
                } else {
                    with_object_pps
                }
            } else if verb_aspect == Aspect::Progressive {
                // Semelfactive + Progressive → Iterative
                if verb_class == crate::lexicon::VerbClass::Semelfactive {
                    self.ctx.exprs.alloc(LogicExpr::Aspectual {
                        operator: AspectOperator::Iterative,
                        body: with_object_pps,
                    })
                } else {
                    with_object_pps
                }
            } else {
                with_object_pps
            };

            Ok(with_aspect)
        } else {
            Ok(self.ctx.exprs.alloc(LogicExpr::Atom(subject_symbol)))
        }
    }
}

impl<'a, 'ctx, 'int> LogicVerbParsing<'a, 'ctx, 'int> for Parser<'a, 'ctx, 'int> {
    fn parse_predicate_with_subject(&mut self, subject_symbol: Symbol) -> ParseResult<&'a LogicExpr<'a>> {
        self.parse_predicate_impl(subject_symbol, false)
    }

    fn parse_predicate_with_subject_as_var(&mut self, subject_symbol: Symbol) -> ParseResult<&'a LogicExpr<'a>> {
        self.parse_predicate_impl(subject_symbol, true)
    }

    fn try_parse_plural_subject(
        &mut self,
        first_subject: &NounPhrase<'a>,
    ) -> Result<Option<&'a LogicExpr<'a>>, ParseError> {
        let saved_pos = self.current;

        // Consume the 'and' we already peeked
        self.advance();

        if !self.check_content_word() {
            self.current = saved_pos;
            return Ok(None);
        }

        // Collect all subjects: "John and Mary and Sue"
        let mut subjects: Vec<Symbol> = vec![first_subject.noun];

        loop {
            if !self.check_content_word() {
                break;
            }
            let next_subject = match self.parse_noun_phrase(true) {
                Ok(np) => np,
                Err(_) => {
                    self.current = saved_pos;
                    return Ok(None);
                }
            };
            subjects.push(next_subject.noun);

            if self.check(&TokenType::And) {
                self.advance();
            } else {
                break;
            }
        }

        // Check for copula (is/are/was/were) with predicate nominative
        // "Both Socrates and Plato are men" -> M(s) ∧ M(p)
        if self.check(&TokenType::Is) || self.check(&TokenType::Are)
            || self.check(&TokenType::Was) || self.check(&TokenType::Were)
        {
            let copula_time = if self.check(&TokenType::Was) || self.check(&TokenType::Were) {
                Time::Past
            } else {
                Time::Present
            };
            self.advance(); // consume the copula

            // Parse the predicate nominative (e.g., "men" in "are men")
            if !self.check_content_word() && !self.check_article() {
                self.current = saved_pos;
                return Ok(None);
            }

            let predicate_np = match self.parse_noun_phrase(false) {
                Ok(np) => np,
                Err(_) => {
                    self.current = saved_pos;
                    return Ok(None);
                }
            };
            let predicate = predicate_np.noun;

            // Build distributed predicate: P(s1) ∧ P(s2) ∧ ...
            let mut conjuncts: Vec<&'a LogicExpr<'a>> = Vec::new();
            for subj in &subjects {
                let pred_expr = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: predicate,
                    args: self.ctx.terms.alloc_slice([Term::Constant(*subj)]),
                    world: None,
                });
                conjuncts.push(pred_expr);
            }

            // Fold conjuncts into binary conjunction tree
            let mut result = conjuncts[0];
            for conjunct in &conjuncts[1..] {
                result = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: result,
                    op: TokenType::And,
                    right: *conjunct,
                });
            }

            // Apply temporal modifier for past tense
            let with_time = match copula_time {
                Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                    operator: TemporalOperator::Past,
                    body: result,
                }),
                _ => result,
            };

            return Ok(Some(with_time));
        }

        if !self.check_verb() {
            self.current = saved_pos;
            return Ok(None);
        }

        // Coordinated subjects registered in DRS via introduce_referent

        let (verb, verb_time, _verb_aspect, _) = self.consume_verb_with_metadata();

        // Check for reciprocal: "John and Mary kicked each other"
        if self.check(&TokenType::Reciprocal) {
            self.advance();
            if subjects.len() != 2 {
                self.current = saved_pos;
                return Ok(None);
            }
            let pred1 = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice([
                    Term::Constant(subjects[0]),
                    Term::Constant(subjects[1]),
                ]),
                world: None,
            });
            let pred2 = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice([
                    Term::Constant(subjects[1]),
                    Term::Constant(subjects[0]),
                ]),
                world: None,
            });
            let expr = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: pred1,
                op: TokenType::And,
                right: pred2,
            });

            let with_time = match verb_time {
                Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                    operator: TemporalOperator::Past,
                    body: expr,
                }),
                Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                    operator: TemporalOperator::Future,
                    body: expr,
                }),
                _ => expr,
            };
            return Ok(Some(with_time));
        }

        // Check for objects (for transitive verbs with "respectively")
        let mut objects: Vec<Symbol> = Vec::new();
        if self.check_content_word() || self.check_article() {
            // Parse first object
            let first_obj = match self.parse_noun_phrase(false) {
                Ok(np) => np,
                Err(_) => {
                    // No objects, continue with intransitive
                    return Ok(Some(self.build_group_predicate(&subjects, verb, verb_time)));
                }
            };
            objects.push(first_obj.noun);

            // Parse additional objects: "Tom and Jerry and Bob"
            while self.check(&TokenType::And) {
                self.advance();
                if self.check_content_word() || self.check_article() {
                    let next_obj = match self.parse_noun_phrase(false) {
                        Ok(np) => np,
                        Err(_) => break,
                    };
                    objects.push(next_obj.noun);
                } else {
                    break;
                }
            }
        }

        // Check for "respectively" - triggers pairwise interpretation
        if self.check(&TokenType::Respectively) {
            let respectively_span = self.peek().span;
            self.advance(); // consume "respectively"

            if subjects.len() != objects.len() {
                return Err(ParseError {
                    kind: ParseErrorKind::RespectivelyLengthMismatch {
                        subject_count: subjects.len(),
                        object_count: objects.len(),
                    },
                    span: respectively_span,
                });
            }

            // Build pairwise predicates: See(J,T) ∧ See(M,J) ∧ ...
            let mut conjuncts: Vec<&'a LogicExpr<'a>> = Vec::new();
            let suppress_existential = self.drs.in_conditional_antecedent();
            for (subj, obj) in subjects.iter().zip(objects.iter()) {
                let event_var = self.get_event_var();
                let roles = vec![
                    (ThematicRole::Agent, Term::Constant(*subj)),
                    (ThematicRole::Theme, Term::Constant(*obj)),
                ];
                let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                    event_var,
                    verb,
                    roles: self.ctx.roles.alloc_slice(roles),
                    modifiers: self.ctx.syms.alloc_slice(vec![]),
                    suppress_existential,
                    world: None,
                })));
                conjuncts.push(neo_event);
            }

            // Fold conjuncts into binary conjunction tree
            let mut result = conjuncts[0];
            for conjunct in &conjuncts[1..] {
                result = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: result,
                    op: TokenType::And,
                    right: *conjunct,
                });
            }

            // Apply temporal modifier
            let with_time = match verb_time {
                Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                    operator: TemporalOperator::Past,
                    body: result,
                }),
                Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                    operator: TemporalOperator::Future,
                    body: result,
                }),
                _ => result,
            };

            return Ok(Some(with_time));
        }

        // No "respectively" - use group semantics
        if objects.is_empty() {
            // Intransitive: group subject
            Ok(Some(self.build_group_predicate(&subjects, verb, verb_time)))
        } else {
            // Transitive without "respectively": group subject, group object
            Ok(Some(self.build_group_transitive(&subjects, &objects, verb, verb_time)))
        }
    }

    /// Build a group predicate for intransitive verbs
    fn build_group_predicate(
        &mut self,
        subjects: &[Symbol],
        verb: Symbol,
        verb_time: Time,
    ) -> &'a LogicExpr<'a> {
        let group_members: Vec<Term<'a>> = subjects.iter()
            .map(|s| Term::Constant(*s))
            .collect();
        let group_members_slice = self.ctx.terms.alloc_slice(group_members);

        let expr = self.ctx.exprs.alloc(LogicExpr::Predicate {
            name: verb,
            args: self.ctx.terms.alloc_slice([Term::Group(group_members_slice)]),
            world: None,
        });

        match verb_time {
            Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                operator: TemporalOperator::Past,
                body: expr,
            }),
            Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                operator: TemporalOperator::Future,
                body: expr,
            }),
            _ => expr,
        }
    }

    /// Build a transitive predicate with group subject and group object
    fn build_group_transitive(
        &mut self,
        subjects: &[Symbol],
        objects: &[Symbol],
        verb: Symbol,
        verb_time: Time,
    ) -> &'a LogicExpr<'a> {
        let subj_members: Vec<Term<'a>> = subjects.iter()
            .map(|s| Term::Constant(*s))
            .collect();
        let obj_members: Vec<Term<'a>> = objects.iter()
            .map(|o| Term::Constant(*o))
            .collect();

        let subj_group = Term::Group(self.ctx.terms.alloc_slice(subj_members));
        let obj_group = Term::Group(self.ctx.terms.alloc_slice(obj_members));

        let expr = self.ctx.exprs.alloc(LogicExpr::Predicate {
            name: verb,
            args: self.ctx.terms.alloc_slice([subj_group, obj_group]),
            world: None,
        });

        match verb_time {
            Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                operator: TemporalOperator::Past,
                body: expr,
            }),
            Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                operator: TemporalOperator::Future,
                body: expr,
            }),
            _ => expr,
        }
    }

    fn parse_control_structure(
        &mut self,
        subject: &NounPhrase<'a>,
        verb: Symbol,
        verb_time: Time,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        let subject_sym = subject.noun;
        let verb_str = self.interner.resolve(verb);

        if Lexer::is_raising_verb(verb_str) {
            if !self.check_to() {
                return Ok(self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb,
                    args: self.ctx.terms.alloc_slice([Term::Constant(subject_sym)]),
                    world: None,
                }));
            }
            self.advance();

            if !self.check_verb() {
                return Ok(self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb,
                    args: self.ctx.terms.alloc_slice([Term::Constant(subject_sym)]),
                    world: None,
                }));
            }

            let inf_verb = self.consume_verb();

            let embedded = if self.is_control_verb(inf_verb) {
                let raised_np = NounPhrase {
                    noun: subject_sym,
                    definiteness: None,
                    adjectives: &[],
                    possessor: None,
                    pps: &[],
                    superlative: None,
                };
                self.parse_control_structure(&raised_np, inf_verb, Time::None)?
            } else {
                self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: inf_verb,
                    args: self.ctx.terms.alloc_slice([Term::Constant(subject_sym)]),
                    world: None,
                })
            };

            let result = self.ctx.exprs.alloc(LogicExpr::Scopal {
                operator: verb,
                body: embedded,
            });

            return Ok(match verb_time {
                Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                    operator: TemporalOperator::Past,
                    body: result,
                }),
                Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                    operator: TemporalOperator::Future,
                    body: result,
                }),
                _ => result,
            });
        }

        let is_object_control = Lexer::is_object_control_verb(self.interner.resolve(verb));
        let (object_term, pro_controller_sym) = if self.check_to() {
            (None, subject_sym)
        } else if self.check_content_word() {
            let object_np = self.parse_noun_phrase(false)?;
            let obj_sym = object_np.noun;

            let controller = if is_object_control {
                obj_sym
            } else {
                subject_sym
            };
            (
                Some(self.ctx.terms.alloc(Term::Constant(obj_sym))),
                controller,
            )
        } else {
            (None, subject_sym)
        };

        if !self.check_to() {
            return Ok(self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: match object_term {
                    Some(obj) => self.ctx.terms.alloc_slice([
                        Term::Constant(subject_sym),
                        Term::Constant(match obj {
                            Term::Constant(s) => *s,
                            _ => subject_sym,
                        }),
                    ]),
                    None => self.ctx.terms.alloc_slice([Term::Constant(subject_sym)]),
                },
                world: None,
            }));
        }
        self.advance();

        if !self.check_verb() {
            return Ok(self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice([Term::Constant(subject_sym)]),
                world: None,
            }));
        }

        let inf_verb = self.consume_verb();
        let inf_verb_str = self.interner.resolve(inf_verb).to_lowercase();

        let infinitive = if inf_verb_str == "be" && self.check_verb() {
            let passive_verb = self.consume_verb();
            let passive_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: passive_verb,
                args: self
                    .ctx
                    .terms
                    .alloc_slice([Term::Constant(pro_controller_sym)]),
                world: None,
            });
            self.ctx.voice(crate::ast::VoiceOperator::Passive, passive_pred)
        } else if self.is_control_verb(inf_verb) {
            let controller_np = NounPhrase {
                noun: pro_controller_sym,
                definiteness: None,
                adjectives: &[],
                possessor: None,
                pps: &[],
                superlative: None,
            };
            self.parse_control_structure(&controller_np, inf_verb, Time::None)?
        } else {
            self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: inf_verb,
                args: self
                    .ctx
                    .terms
                    .alloc_slice([Term::Constant(pro_controller_sym)]),
                world: None,
            })
        };

        let control = self.ctx.exprs.alloc(LogicExpr::Control {
            verb,
            subject: self.ctx.terms.alloc(Term::Constant(subject_sym)),
            object: object_term,
            infinitive,
        });

        Ok(match verb_time {
            Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                operator: TemporalOperator::Past,
                body: control,
            }),
            Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                operator: TemporalOperator::Future,
                body: control,
            }),
            _ => control,
        })
    }

    fn is_control_verb(&self, verb: Symbol) -> bool {
        let lemma = self.interner.resolve(verb);
        Lexer::is_subject_control_verb(lemma)
            || Lexer::is_object_control_verb(lemma)
            || Lexer::is_raising_verb(lemma)
    }
}

```

---

use super::clause::ClauseParsing;
use super::{ParseResult, Parser};
use crate::ast::{LogicExpr, NounPhrase, Term};
use crate::drs::{Case, Gender, Number};
use crate::intern::SymbolEq;
use crate::lexicon::Definiteness;
use crate::token::TokenType;
use crate::transpile::capitalize_first;

pub trait NounParsing<'a, 'ctx, 'int> {
    fn parse_noun_phrase(&mut self, greedy: bool) -> ParseResult<NounPhrase<'a>>;
    fn parse_noun_phrase_for_relative(&mut self) -> ParseResult<NounPhrase<'a>>;
    fn noun_phrase_to_term(&self, np: &NounPhrase<'a>) -> Term<'a>;
    fn check_possessive(&self) -> bool;
    fn check_of_preposition(&self) -> bool;
    fn check_proper_name_or_label(&self) -> bool;
    fn check_possessive_pronoun(&self) -> bool;
}

impl<'a, 'ctx, 'int> NounParsing<'a, 'ctx, 'int> for Parser<'a, 'ctx, 'int> {
    fn parse_noun_phrase(&mut self, greedy: bool) -> ParseResult<NounPhrase<'a>> {
        let mut definiteness = None;
        let mut adjectives = Vec::new();
        let mut non_intersective_prefix: Option<crate::intern::Symbol> = None;
        let mut possessor_from_pronoun: Option<&'a NounPhrase<'a>> = None;
        let mut superlative_adj: Option<crate::intern::Symbol> = None;

        // Phase 35: Support numeric literals as noun phrases (e.g., "equal to 42")
        if let TokenType::Number(sym) = self.peek().kind {
            self.advance();
            return Ok(NounPhrase {
                definiteness: None,
                adjectives: &[],
                noun: sym,
                possessor: None,
                pps: &[],
                superlative: None,
            });
        }

        if self.check_possessive_pronoun() {
            let token = self.advance().clone();
            let (gender, number) = match &token.kind {
                TokenType::Pronoun { gender, number, case: Case::Possessive } => (*gender, *number),
                TokenType::Ambiguous { primary, alternatives } => {
                    let mut found = None;
                    if let TokenType::Pronoun { gender, number, case: Case::Possessive } = **primary {
                        found = Some((gender, number));
                    }
                    if found.is_none() {
                        for alt in alternatives {
                            if let TokenType::Pronoun { gender, number, case: Case::Possessive } = alt {
                                found = Some((*gender, *number));
                                break;
                            }
                        }
                    }
                    found.unwrap_or((Gender::Unknown, Number::Singular))
                }
                _ => (Gender::Unknown, Number::Singular),
            };

            let resolved = self.resolve_pronoun(gender, number)?;
            let resolved_sym = match resolved {
                super::ResolvedPronoun::Variable(s) | super::ResolvedPronoun::Constant(s) => s,
            };

            let possessor_np = NounPhrase {
                definiteness: None,
                adjectives: &[],
                noun: resolved_sym,
                possessor: None,
                pps: &[],
                superlative: None,
            };
            possessor_from_pronoun = Some(self.ctx.nps.alloc(possessor_np));
            definiteness = Some(Definiteness::Definite);
        } else if let TokenType::Article(def) = self.peek().kind {
            // Phase 35: Disambiguate "a" as variable vs article
            // If "a" or "an" is followed by a verb/copula/modal, it's a variable name, not an article
            let is_variable_a = {
                let lexeme = self.interner.resolve(self.peek().lexeme).to_lowercase();
                if lexeme == "a" || lexeme == "an" {
                    if let Some(next) = self.tokens.get(self.current + 1) {
                        matches!(next.kind,
                            TokenType::Is | TokenType::Are | TokenType::Was | TokenType::Were | // Copula
                            TokenType::Verb { .. } | // Main verb
                            TokenType::Auxiliary(_) | // will, did
                            TokenType::Must | TokenType::Can | TokenType::Should | TokenType::May | // Modals
                            TokenType::Could | TokenType::Would | TokenType::Shall | TokenType::Might |
                            TokenType::Identity | TokenType::Equals // "a = b"
                        )
                    } else {
                        false
                    }
                } else {
                    false
                }
            };

            if !is_variable_a {
                definiteness = Some(def);
                self.advance();
            }
        }

        if self.check_superlative() {
            if let TokenType::Superlative(adj) = self.advance().kind {
                superlative_adj = Some(adj);
            }
        }

        if self.check_non_intersective_adjective() {
            if let TokenType::NonIntersectiveAdjective(adj) = self.advance().kind {
                non_intersective_prefix = Some(adj);
            }
        }

        loop {
            if self.is_at_end() {
                break;
            }

            let is_adjective = matches!(self.peek().kind, TokenType::Adjective(_));
            if !is_adjective {
                break;
            }

            let next_is_content = if self.current + 1 < self.tokens.len() {
                matches!(
                    self.tokens[self.current + 1].kind,
                    TokenType::Noun(_)
                        | TokenType::Adjective(_)
                        | TokenType::ProperName(_)
                )
            } else {
                false
            };

            if next_is_content {
                if let TokenType::Adjective(adj) = self.advance().kind {
                    adjectives.push(adj);
                }
            } else {
                break;
            }
        }

        let base_noun = self.consume_content_word()?;

        let noun = if let Some(prefix) = non_intersective_prefix {
            let prefix_str = self.interner.resolve(prefix);
            let base_str = self.interner.resolve(base_noun);
            let compound = format!("{}-{}", prefix_str, base_str);
            self.interner.intern(&compound)
        } else {
            base_noun
        };

        let noun = if self.check_proper_name_or_label() {
            let label = self.consume_content_word()?;
            let label_str = self.interner.resolve(label);
            let base_str = self.interner.resolve(noun);
            let compound = format!("{}_{}", base_str, label_str);
            self.interner.intern(&compound)
        } else {
            noun
        };

        if self.check_possessive() {
            self.advance();

            let possessor = self.ctx.nps.alloc(NounPhrase {
                definiteness,
                adjectives: self.ctx.syms.alloc_slice(adjectives.clone()),
                noun,
                possessor: None,
                pps: &[],
                superlative: superlative_adj,
            });

            let possessed_noun = self.consume_content_word()?;

            return Ok(NounPhrase {
                definiteness: None,
                adjectives: &[],
                noun: possessed_noun,
                possessor: Some(possessor),
                pps: &[],
                superlative: None,
            });
        }

        let should_attach_pps = greedy || self.pp_attach_to_noun;

        let mut pps: Vec<&'a LogicExpr<'a>> = Vec::new();
        if should_attach_pps {
            while self.check_preposition() && !self.check_of_preposition() {
                let prep_token = self.advance().clone();
                let prep_name = if let TokenType::Preposition(sym) = prep_token.kind {
                    sym
                } else {
                    break;
                };

                if self.check_content_word() || matches!(self.peek().kind, TokenType::Article(_)) {
                    let pp_object = self.parse_noun_phrase(true)?;
                    let placeholder_var = self.interner.intern("_PP_SELF_");
                    let pp_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: prep_name,
                        args: self.ctx.terms.alloc_slice([
                            Term::Variable(placeholder_var),
                            Term::Constant(pp_object.noun),
                        ]),
                        world: None,
                    });
                    pps.push(pp_pred);
                }
            }
        }
        let pps_slice = self.ctx.pps.alloc_slice(pps);

        if self.check_of_preposition() {
            // Two-Pass Type Disambiguation:
            // If the noun is a known generic type (e.g., "Stack", "List"),
            // then "X of Y" is a type instantiation, not a possessive.
            // For now, we still parse it as possessive structurally, but
            // the type_registry enables future AST extensions for type annotations.
            let is_generic = self.is_generic_type(noun);

            if !is_generic {
                // Standard possessive: "owner of house" → possessor relationship
                self.advance();

                let possessor_np = self.parse_noun_phrase(true)?;
                let possessor = self.ctx.nps.alloc(possessor_np);

                return Ok(NounPhrase {
                    definiteness,
                    adjectives: self.ctx.syms.alloc_slice(adjectives),
                    noun,
                    possessor: Some(possessor),
                    pps: pps_slice,
                    superlative: superlative_adj,
                });
            }
            // If generic type, fall through to regular noun phrase handling.
            // The "of [Type]" will be left unparsed for now.
            // Future: Parse as GenericType { base: noun, params: [...] }
        }

        // Register ALL noun phrases as discourse entities, not just definite ones.
        // This is needed for bridging anaphora: "I bought a car. The engine smoked."
        // The indefinite "a car" must be in discourse history for "the engine" to link to it.
        let noun_str = self.interner.resolve(noun);
        let first_char = noun_str.chars().next().unwrap_or('X');
        if first_char.is_alphabetic() {
            // Use full noun name as symbol for consistent output in Full mode
            let symbol = capitalize_first(noun_str);
            let number = if noun_str.ends_with('s') && !noun_str.ends_with("ss") {
                Number::Plural
            } else {
                Number::Singular
            };
        }

        Ok(NounPhrase {
            definiteness,
            adjectives: self.ctx.syms.alloc_slice(adjectives),
            noun,
            possessor: possessor_from_pronoun,
            pps: pps_slice,
            superlative: superlative_adj,
        })
    }

    fn parse_noun_phrase_for_relative(&mut self) -> ParseResult<NounPhrase<'a>> {
        let mut definiteness = None;
        let mut adjectives = Vec::new();

        if let TokenType::Article(def) = self.peek().kind {
            definiteness = Some(def);
            self.advance();
        }

        loop {
            if self.is_at_end() {
                break;
            }

            let is_adjective = matches!(self.peek().kind, TokenType::Adjective(_));
            if !is_adjective {
                break;
            }

            let next_is_content = if self.current + 1 < self.tokens.len() {
                matches!(
                    self.tokens[self.current + 1].kind,
                    TokenType::Noun(_)
                        | TokenType::Adjective(_)
                        | TokenType::Verb { .. }
                        | TokenType::ProperName(_)
                )
            } else {
                false
            };

            if next_is_content {
                if let TokenType::Adjective(adj) = self.advance().kind.clone() {
                    adjectives.push(adj);
                }
            } else {
                break;
            }
        }

        let noun = self.consume_content_word_for_relative()?;

        if self.check(&TokenType::That) || self.check(&TokenType::Who) {
            self.advance();
            let var_name = self.interner.intern(&format!("r{}", self.var_counter));
            self.var_counter += 1;
            let _nested_clause = self.parse_relative_clause(var_name)?;
        }

        Ok(NounPhrase {
            definiteness,
            adjectives: self.ctx.syms.alloc_slice(adjectives),
            noun,
            possessor: None,
            pps: &[],
            superlative: None,
        })
    }

    fn noun_phrase_to_term(&self, np: &NounPhrase<'a>) -> Term<'a> {
        if let Some(possessor) = np.possessor {
            let possessor_term = self.noun_phrase_to_term(possessor);
            Term::Possessed {
                possessor: self.ctx.terms.alloc(possessor_term),
                possessed: np.noun,
            }
        } else {
            Term::Constant(np.noun)
        }
    }

    fn check_possessive(&self) -> bool {
        matches!(self.peek().kind, TokenType::Possessive)
    }

    fn check_of_preposition(&self) -> bool {
        if let TokenType::Preposition(p) = self.peek().kind {
            p.is(self.interner, "of")
        } else {
            false
        }
    }

    fn check_proper_name_or_label(&self) -> bool {
        match &self.peek().kind {
            TokenType::ProperName(_) => true,
            TokenType::Noun(s) => {
                let str_val = self.interner.resolve(*s);
                str_val.len() == 1 && str_val.chars().next().unwrap().is_uppercase()
            }
            _ => false,
        }
    }

    fn check_possessive_pronoun(&self) -> bool {
        match &self.peek().kind {
            TokenType::Pronoun { case: Case::Possessive, .. } => true,
            TokenType::Ambiguous { primary, alternatives } => {
                if self.noun_priority_mode {
                    if let TokenType::Pronoun { case: Case::Possessive, .. } = **primary {
                        return true;
                    }
                    for alt in alternatives {
                        if let TokenType::Pronoun { case: Case::Possessive, .. } = alt {
                            return true;
                        }
                    }
                }
                false
            }
            _ => false,
        }
    }
}

```

---

## Semantic Analysis

Lambda calculus and discourse representation.
use crate::arena::Arena;
use crate::ast::{LogicExpr, QuantifierKind, Term};
use crate::intern::{Interner, Symbol};
use crate::lexicon;
use crate::token::TokenType;

fn clone_term<'a>(term: &Term<'a>, arena: &'a Arena<Term<'a>>) -> Term<'a> {
    match term {
        Term::Constant(s) => Term::Constant(*s),
        Term::Variable(s) => Term::Variable(*s),
        Term::Function(name, args) => {
            let cloned_args: Vec<Term<'a>> = args.iter().map(|t| clone_term(t, arena)).collect();
            Term::Function(*name, arena.alloc_slice(cloned_args))
        }
        Term::Group(members) => {
            let cloned: Vec<Term<'a>> = members.iter().map(|t| clone_term(t, arena)).collect();
            Term::Group(arena.alloc_slice(cloned))
        }
        Term::Possessed { possessor, possessed } => Term::Possessed {
            possessor: arena.alloc(clone_term(possessor, arena)),
            possessed: *possessed,
        },
        Term::Sigma(predicate) => Term::Sigma(*predicate),
        Term::Intension(predicate) => Term::Intension(*predicate),
        Term::Proposition(expr) => Term::Proposition(*expr),
        Term::Value { kind, unit, dimension } => Term::Value {
            kind: *kind,
            unit: *unit,
            dimension: *dimension,
        },
    }
}

pub fn is_opaque_verb(verb: Symbol, interner: &Interner) -> bool {
    let verb_str = interner.resolve(verb);
    let lower = verb_str.to_lowercase();
    lexicon::is_opaque_verb(&lower)
}

pub fn make_intensional<'a>(
    operator: Symbol,
    content: &'a LogicExpr<'a>,
    arena: &'a Arena<LogicExpr<'a>>,
) -> &'a LogicExpr<'a> {
    arena.alloc(LogicExpr::Intensional { operator, content })
}

pub fn substitute_respecting_opacity<'a>(
    expr: &'a LogicExpr<'a>,
    var: Symbol,
    replacement: &'a LogicExpr<'a>,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
) -> &'a LogicExpr<'a> {
    match expr {
        LogicExpr::Intensional { operator, content } => {
            expr_arena.alloc(LogicExpr::Intensional {
                operator: *operator,
                content: *content,
            })
        }

        LogicExpr::Predicate { name, args, .. } => {
            let new_args: Vec<Term<'a>> = args
                .iter()
                .map(|arg| substitute_term_for_opacity(arg, var, replacement, term_arena))
                .collect();
            expr_arena.alloc(LogicExpr::Predicate {
                name: *name,
                args: term_arena.alloc_slice(new_args),
                world: None,
            })
        }

        LogicExpr::BinaryOp { left, op, right } => expr_arena.alloc(LogicExpr::BinaryOp {
            left: substitute_respecting_opacity(left, var, replacement, expr_arena, term_arena),
            op: op.clone(),
            right: substitute_respecting_opacity(right, var, replacement, expr_arena, term_arena),
        }),

        LogicExpr::UnaryOp { op, operand } => expr_arena.alloc(LogicExpr::UnaryOp {
            op: op.clone(),
            operand: substitute_respecting_opacity(operand, var, replacement, expr_arena, term_arena),
        }),

        LogicExpr::Quantifier { kind, variable, body, island_id } => {
            if *variable == var {
                expr
            } else {
                expr_arena.alloc(LogicExpr::Quantifier {
                    kind: *kind,
                    variable: *variable,
                    body: substitute_respecting_opacity(body, var, replacement, expr_arena, term_arena),
                    island_id: *island_id,
                })
            }
        }

        LogicExpr::Lambda { variable, body } => {
            if *variable == var {
                expr
            } else {
                expr_arena.alloc(LogicExpr::Lambda {
                    variable: *variable,
                    body: substitute_respecting_opacity(body, var, replacement, expr_arena, term_arena),
                })
            }
        }

        LogicExpr::App { function, argument } => expr_arena.alloc(LogicExpr::App {
            function: substitute_respecting_opacity(function, var, replacement, expr_arena, term_arena),
            argument: substitute_respecting_opacity(argument, var, replacement, expr_arena, term_arena),
        }),

        LogicExpr::Atom(s) => {
            if *s == var {
                replacement
            } else {
                expr
            }
        }

        _ => expr,
    }
}

fn substitute_term_for_opacity<'a>(
    term: &Term<'a>,
    var: Symbol,
    replacement: &LogicExpr<'a>,
    arena: &'a Arena<Term<'a>>,
) -> Term<'a> {
    match term {
        Term::Constant(c) if *c == var => {
            match replacement {
                LogicExpr::Atom(s) => Term::Constant(*s),
                _ => clone_term(term, arena),
            }
        }
        Term::Variable(v) if *v == var => {
            match replacement {
                LogicExpr::Atom(s) => Term::Constant(*s),
                _ => clone_term(term, arena),
            }
        }
        _ => clone_term(term, arena),
    }
}

pub fn to_event_semantics<'a>(
    expr: &'a LogicExpr<'a>,
    interner: &mut Interner,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
) -> &'a LogicExpr<'a> {
    match expr {
        LogicExpr::Predicate { name, args, .. } => {
            let e_sym = interner.intern("e");
            let _event_var = term_arena.alloc(Term::Variable(e_sym));

            let event_pred = expr_arena.alloc(LogicExpr::Predicate {
                name: *name,
                args: term_arena.alloc_slice([Term::Variable(e_sym)]),
                world: None,
            });

            let mut body = event_pred;

            if !args.is_empty() {
                let agent_args = term_arena.alloc_slice([Term::Variable(e_sym), clone_term(&args[0], term_arena)]);
                let agent_pred = expr_arena.alloc(LogicExpr::Predicate {
                    name: interner.intern("Agent"),
                    args: agent_args,
                    world: None,
                });
                body = expr_arena.alloc(LogicExpr::BinaryOp {
                    left: body,
                    op: TokenType::And,
                    right: agent_pred,
                });
            }

            if args.len() > 1 {
                let theme_args = term_arena.alloc_slice([Term::Variable(e_sym), clone_term(&args[1], term_arena)]);
                let theme_pred = expr_arena.alloc(LogicExpr::Predicate {
                    name: interner.intern("Theme"),
                    args: theme_args,
                    world: None,
                });
                body = expr_arena.alloc(LogicExpr::BinaryOp {
                    left: body,
                    op: TokenType::And,
                    right: theme_pred,
                });
            }

            if args.len() > 2 {
                let goal_args = term_arena.alloc_slice([Term::Variable(e_sym), clone_term(&args[2], term_arena)]);
                let goal_pred = expr_arena.alloc(LogicExpr::Predicate {
                    name: interner.intern("Goal"),
                    args: goal_args,
                    world: None,
                });
                body = expr_arena.alloc(LogicExpr::BinaryOp {
                    left: body,
                    op: TokenType::And,
                    right: goal_pred,
                });
            }

            expr_arena.alloc(LogicExpr::Quantifier {
                kind: QuantifierKind::Existential,
                variable: e_sym,
                body,
                island_id: 0,
            })
        }
        _ => expr,
    }
}

pub fn apply_adverb<'a>(
    expr: &'a LogicExpr<'a>,
    adverb: Symbol,
    interner: &mut Interner,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
) -> &'a LogicExpr<'a> {
    let e_sym = interner.intern("e");
    match expr {
        LogicExpr::Quantifier { kind, variable, body, island_id } if *variable == e_sym => {
            let adverb_str = interner.resolve(adverb);
            let capitalized = capitalize(adverb_str);
            let adverb_pred = expr_arena.alloc(LogicExpr::Predicate {
                name: interner.intern(&capitalized),
                args: term_arena.alloc_slice([Term::Variable(*variable)]),
                world: None,
            });

            let new_body = expr_arena.alloc(LogicExpr::BinaryOp {
                left: *body,
                op: TokenType::And,
                right: adverb_pred,
            });

            expr_arena.alloc(LogicExpr::Quantifier {
                kind: *kind,
                variable: *variable,
                body: new_body,
                island_id: *island_id,
            })
        }
        _ => expr,
    }
}

fn capitalize(s: &str) -> String {
    let mut chars = s.chars();
    match chars.next() {
        None => String::new(),
        Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
    }
}

fn factorial(n: usize) -> u64 {
    (1..=n as u64).product()
}

pub struct ScopeIterator<'a> {
    expr_arena: &'a Arena<LogicExpr<'a>>,
    islands: Vec<Vec<ScopalElement<'a>>>,
    core: &'a LogicExpr<'a>,
    current_index: u64,
    total: u64,
    single_result: Option<&'a LogicExpr<'a>>,
    returned_single: bool,
}

impl<'a> ScopeIterator<'a> {
    fn nth_island_aware_permutation(&self, n: u64) -> Vec<ScopalElement<'a>> {
        let mut result = Vec::new();
        let mut remainder = n;

        for island in &self.islands {
            let island_perms = factorial(island.len());
            let island_index = remainder % island_perms;
            remainder /= island_perms;

            let perm = nth_permutation_of_slice(island, island_index);
            result.extend(perm);
        }

        result
    }
}

fn nth_permutation_of_slice<T: Clone>(items: &[T], n: u64) -> Vec<T> {
    let len = items.len();
    let mut available: Vec<usize> = (0..len).collect();
    let mut result = Vec::with_capacity(len);
    let mut remainder = n;

    for i in 0..len {
        let divisor = factorial(len - i - 1);
        let index = (remainder / divisor) as usize;
        remainder %= divisor;
        result.push(items[available.remove(index)].clone());
    }
    result
}

impl<'a> Iterator for ScopeIterator<'a> {
    type Item = &'a LogicExpr<'a>;

    fn next(&mut self) -> Option<Self::Item> {
        if let Some(single) = self.single_result {
            if self.returned_single {
                return None;
            }
            self.returned_single = true;
            return Some(single);
        }

        if self.current_index >= self.total {
            return None;
        }
        let ordered = self.nth_island_aware_permutation(self.current_index);
        self.current_index += 1;
        Some(rebuild_with_scopal_elements(&ordered, self.core, self.expr_arena))
    }

    fn size_hint(&self) -> (usize, Option<usize>) {
        if self.single_result.is_some() {
            let remaining = if self.returned_single { 0 } else { 1 };
            return (remaining, Some(remaining));
        }
        let remaining = (self.total - self.current_index) as usize;
        (remaining, Some(remaining))
    }
}

impl<'a> ExactSizeIterator for ScopeIterator<'a> {}

#[derive(Clone, Debug)]
struct QuantifierInfo<'a> {
    kind: QuantifierKind,
    variable: Symbol,
    restrictor: &'a LogicExpr<'a>,
    island_id: u32,
}

#[derive(Clone, Debug)]
enum ScopalElement<'a> {
    Quantifier(QuantifierInfo<'a>),
    Negation { island_id: u32 },
}

impl<'a> ScopalElement<'a> {
    fn island_id(&self) -> u32 {
        match self {
            ScopalElement::Quantifier(q) => q.island_id,
            ScopalElement::Negation { island_id } => *island_id,
        }
    }
}

pub fn enumerate_scopings<'a>(
    expr: &'a LogicExpr<'a>,
    interner: &mut Interner,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    _term_arena: &'a Arena<Term<'a>>,
) -> ScopeIterator<'a> {
    let mut elements = Vec::new();
    let core = extract_scopal_elements(expr, &mut elements, interner, expr_arena);

    if elements.is_empty() || elements.len() == 1 {
        return ScopeIterator {
            expr_arena,
            islands: Vec::new(),
            core,
            current_index: 0,
            total: 0,
            single_result: Some(expr),
            returned_single: false,
        };
    }

    let islands = group_scopal_by_island(elements);
    let total: u64 = islands.iter().map(|island| factorial(island.len())).product();

    ScopeIterator {
        expr_arena,
        islands,
        core,
        current_index: 0,
        total,
        single_result: None,
        returned_single: false,
    }
}

fn group_by_island<'a>(quantifiers: Vec<QuantifierInfo<'a>>) -> Vec<Vec<QuantifierInfo<'a>>> {
    use std::collections::BTreeMap;

    let mut by_island: BTreeMap<u32, Vec<QuantifierInfo<'a>>> = BTreeMap::new();
    for q in quantifiers {
        by_island.entry(q.island_id).or_default().push(q);
    }

    by_island.into_values().collect()
}

fn group_scopal_by_island<'a>(elements: Vec<ScopalElement<'a>>) -> Vec<Vec<ScopalElement<'a>>> {
    use std::collections::BTreeMap;

    let mut by_island: BTreeMap<u32, Vec<ScopalElement<'a>>> = BTreeMap::new();
    for elem in elements {
        by_island.entry(elem.island_id()).or_default().push(elem);
    }

    by_island.into_values().collect()
}

fn extract_scopal_elements<'a>(
    expr: &'a LogicExpr<'a>,
    elements: &mut Vec<ScopalElement<'a>>,
    interner: &mut Interner,
    expr_arena: &'a Arena<LogicExpr<'a>>,
) -> &'a LogicExpr<'a> {
    match expr {
        LogicExpr::Quantifier { kind, variable, body, island_id } => {
            if let LogicExpr::BinaryOp { left, op, right } = body {
                if matches!(op, TokenType::If | TokenType::And) {
                    // Check if right side has a negation at the top level
                    if let LogicExpr::UnaryOp { op: TokenType::Not, operand } = right {
                        // Pattern: ∀x(R(x) → ¬P(x)) or ∃x(R(x) ∧ ¬P(x))
                        // Extract both quantifier and negation
                        elements.push(ScopalElement::Quantifier(QuantifierInfo {
                            kind: *kind,
                            variable: *variable,
                            restrictor: *left,
                            island_id: *island_id,
                        }));
                        elements.push(ScopalElement::Negation { island_id: *island_id });
                        return extract_scopal_elements(operand, elements, interner, expr_arena);
                    }
                    // No negation in right side, just extract quantifier
                    elements.push(ScopalElement::Quantifier(QuantifierInfo {
                        kind: *kind,
                        variable: *variable,
                        restrictor: *left,
                        island_id: *island_id,
                    }));
                    return extract_scopal_elements(right, elements, interner, expr_arena);
                }
            }
            // No binary op body, use a true restrictor
            elements.push(ScopalElement::Quantifier(QuantifierInfo {
                kind: *kind,
                variable: *variable,
                restrictor: expr_arena.alloc(LogicExpr::Atom(interner.intern("T"))),
                island_id: *island_id,
            }));
            extract_scopal_elements(body, elements, interner, expr_arena)
        }
        LogicExpr::UnaryOp { op: TokenType::Not, operand } => {
            // Standalone negation (not inside a quantifier body)
            elements.push(ScopalElement::Negation { island_id: 0 });
            extract_scopal_elements(operand, elements, interner, expr_arena)
        }
        _ => expr,
    }
}

fn rebuild_with_scopal_elements<'a>(
    elements: &[ScopalElement<'a>],
    core: &'a LogicExpr<'a>,
    arena: &'a Arena<LogicExpr<'a>>,
) -> &'a LogicExpr<'a> {
    let mut result = core;

    for elem in elements.iter().rev() {
        match elem {
            ScopalElement::Quantifier(q) => {
                let connective = match q.kind {
                    QuantifierKind::Universal => TokenType::If,
                    _ => TokenType::And,
                };

                let body = arena.alloc(LogicExpr::BinaryOp {
                    left: q.restrictor,
                    op: connective,
                    right: result,
                });

                result = arena.alloc(LogicExpr::Quantifier {
                    kind: q.kind,
                    variable: q.variable,
                    body,
                    island_id: q.island_id,
                });
            }
            ScopalElement::Negation { .. } => {
                result = arena.alloc(LogicExpr::UnaryOp {
                    op: TokenType::Not,
                    operand: result,
                });
            }
        }
    }

    result
}

fn extract_quantifiers<'a>(
    expr: &'a LogicExpr<'a>,
    quantifiers: &mut Vec<QuantifierInfo<'a>>,
    interner: &mut Interner,
    expr_arena: &'a Arena<LogicExpr<'a>>,
) -> &'a LogicExpr<'a> {
    match expr {
        LogicExpr::Quantifier { kind, variable, body, island_id } => {
            if let LogicExpr::BinaryOp { left, op, right } = body {
                if matches!(op, TokenType::If | TokenType::And) {
                    quantifiers.push(QuantifierInfo {
                        kind: *kind,
                        variable: *variable,
                        restrictor: *left,
                        island_id: *island_id,
                    });
                    return extract_quantifiers(right, quantifiers, interner, expr_arena);
                }
            }
            quantifiers.push(QuantifierInfo {
                kind: *kind,
                variable: *variable,
                restrictor: expr_arena.alloc(LogicExpr::Atom(interner.intern("T"))),
                island_id: *island_id,
            });
            extract_quantifiers(body, quantifiers, interner, expr_arena)
        }
        _ => expr,
    }
}

fn rebuild_with_scope_order<'a>(
    quantifiers: &[QuantifierInfo<'a>],
    core: &'a LogicExpr<'a>,
    arena: &'a Arena<LogicExpr<'a>>,
) -> &'a LogicExpr<'a> {
    let mut result = core;

    for q in quantifiers.iter().rev() {
        let connective = match q.kind {
            QuantifierKind::Universal => TokenType::If,
            _ => TokenType::And,
        };

        let body = arena.alloc(LogicExpr::BinaryOp {
            left: q.restrictor,
            op: connective,
            right: result,
        });

        result = arena.alloc(LogicExpr::Quantifier {
            kind: q.kind,
            variable: q.variable,
            body,
            island_id: q.island_id,
        });
    }

    result
}

pub fn lift_proper_name<'a>(
    name: Symbol,
    interner: &mut Interner,
    arena: &'a Arena<LogicExpr<'a>>,
) -> &'a LogicExpr<'a> {
    let p_sym = interner.intern("P");
    let inner_app = arena.alloc(LogicExpr::App {
        function: arena.alloc(LogicExpr::Atom(p_sym)),
        argument: arena.alloc(LogicExpr::Atom(name)),
    });
    arena.alloc(LogicExpr::Lambda {
        variable: p_sym,
        body: inner_app,
    })
}

pub fn lift_quantifier<'a>(
    kind: QuantifierKind,
    restrictor: Symbol,
    interner: &mut Interner,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
) -> &'a LogicExpr<'a> {
    let x_sym = interner.intern("x");
    let q_sym = interner.intern("Q");

    let restrictor_pred = expr_arena.alloc(LogicExpr::Predicate {
        name: restrictor,
        args: term_arena.alloc_slice([Term::Variable(x_sym)]),
        world: None,
    });

    let q_of_x = expr_arena.alloc(LogicExpr::App {
        function: expr_arena.alloc(LogicExpr::Atom(q_sym)),
        argument: expr_arena.alloc(LogicExpr::Atom(x_sym)),
    });

    let connective = match kind {
        QuantifierKind::Universal => TokenType::If,
        _ => TokenType::And,
    };

    let body = expr_arena.alloc(LogicExpr::BinaryOp {
        left: restrictor_pred,
        op: connective,
        right: q_of_x,
    });

    let quantifier = expr_arena.alloc(LogicExpr::Quantifier {
        kind,
        variable: x_sym,
        body,
        island_id: 0,
    });

    expr_arena.alloc(LogicExpr::Lambda {
        variable: q_sym,
        body: quantifier,
    })
}

pub fn beta_reduce<'a>(
    expr: &'a LogicExpr<'a>,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
) -> &'a LogicExpr<'a> {
    match expr {
        LogicExpr::App { function, argument } => {
            if let LogicExpr::Lambda { variable, body } = function {
                substitute(body, *variable, argument, expr_arena, term_arena)
            } else {
                expr_arena.alloc(LogicExpr::App {
                    function: beta_reduce(function, expr_arena, term_arena),
                    argument: beta_reduce(argument, expr_arena, term_arena),
                })
            }
        }
        LogicExpr::Lambda { variable, body } => expr_arena.alloc(LogicExpr::Lambda {
            variable: *variable,
            body: beta_reduce(body, expr_arena, term_arena),
        }),
        _ => expr,
    }
}

fn substitute<'a>(
    expr: &'a LogicExpr<'a>,
    var: Symbol,
    replacement: &'a LogicExpr<'a>,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
) -> &'a LogicExpr<'a> {
    match expr {
        LogicExpr::Predicate { name, args, .. } => {
            let new_args: Vec<Term<'a>> = args
                .iter()
                .map(|arg| substitute_term(arg, var, replacement, term_arena))
                .collect();
            expr_arena.alloc(LogicExpr::Predicate {
                name: *name,
                args: term_arena.alloc_slice(new_args),
                world: None,
            })
        }

        LogicExpr::Lambda { variable, body } => {
            if *variable == var {
                expr
            } else {
                expr_arena.alloc(LogicExpr::Lambda {
                    variable: *variable,
                    body: substitute(body, var, replacement, expr_arena, term_arena),
                })
            }
        }

        LogicExpr::App { function, argument } => expr_arena.alloc(LogicExpr::App {
            function: substitute(function, var, replacement, expr_arena, term_arena),
            argument: substitute(argument, var, replacement, expr_arena, term_arena),
        }),

        LogicExpr::BinaryOp { left, op, right } => expr_arena.alloc(LogicExpr::BinaryOp {
            left: substitute(left, var, replacement, expr_arena, term_arena),
            op: op.clone(),
            right: substitute(right, var, replacement, expr_arena, term_arena),
        }),

        LogicExpr::UnaryOp { op, operand } => expr_arena.alloc(LogicExpr::UnaryOp {
            op: op.clone(),
            operand: substitute(operand, var, replacement, expr_arena, term_arena),
        }),

        LogicExpr::Quantifier { kind, variable, body, island_id } => {
            if *variable == var {
                expr
            } else {
                expr_arena.alloc(LogicExpr::Quantifier {
                    kind: *kind,
                    variable: *variable,
                    body: substitute(body, var, replacement, expr_arena, term_arena),
                    island_id: *island_id,
                })
            }
        }

        LogicExpr::Atom(s) => {
            if *s == var {
                replacement
            } else {
                expr
            }
        }

        _ => expr,
    }
}

fn substitute_term<'a>(
    term: &Term<'a>,
    var: Symbol,
    replacement: &LogicExpr<'a>,
    term_arena: &'a Arena<Term<'a>>,
) -> Term<'a> {
    match term {
        Term::Variable(v) if *v == var => {
            match replacement {
                LogicExpr::Atom(s) => Term::Constant(*s),
                LogicExpr::Predicate { name, .. } => Term::Constant(*name),
                _ => clone_term(term, term_arena),
            }
        }
        _ => clone_term(term, term_arena),
    }
}

// ═══════════════════════════════════════════════════════════════════
// Intensional Reading Generation (De Re / De Dicto)
// ═══════════════════════════════════════════════════════════════════

#[derive(Debug)]
struct IntensionalContext {
    verb: Symbol,
    quantifier_var: Symbol,
    restrictor: Symbol,
}

fn find_opaque_verb_context<'a>(
    expr: &'a LogicExpr<'a>,
    interner: &Interner,
) -> Option<IntensionalContext> {
    match expr {
        LogicExpr::Quantifier { kind: QuantifierKind::Existential, variable, body, .. } => {
            if let LogicExpr::BinaryOp { left, op: TokenType::And, right } = body {
                if let LogicExpr::Predicate { name: restrictor, args, .. } = left {
                    if args.len() == 1 {
                        if let Term::Variable(v) = &args[0] {
                            if *v == *variable {
                                if let Some(verb) = find_opaque_verb_in_scope(right, *variable, interner) {
                                    return Some(IntensionalContext {
                                        verb,
                                        quantifier_var: *variable,
                                        restrictor: *restrictor,
                                    });
                                }
                            }
                        }
                    }
                }
            }
            None
        }
        _ => None,
    }
}

fn find_opaque_verb_in_scope<'a>(
    expr: &'a LogicExpr<'a>,
    theme_var: Symbol,
    interner: &Interner,
) -> Option<Symbol> {
    match expr {
        LogicExpr::Quantifier { body, .. } => find_opaque_verb_in_scope(body, theme_var, interner),
        LogicExpr::BinaryOp { left, right, .. } => {
            find_opaque_verb_in_scope(left, theme_var, interner)
                .or_else(|| find_opaque_verb_in_scope(right, theme_var, interner))
        }
        LogicExpr::NeoEvent(data) => {
            if is_opaque_verb(data.verb, interner) {
                for (role, term) in data.roles.iter() {
                    if matches!(role, crate::ast::ThematicRole::Theme) {
                        if let Term::Variable(v) = term {
                            if *v == theme_var {
                                return Some(data.verb);
                            }
                        }
                    }
                }
            }
            None
        }
        LogicExpr::Predicate { name, args, .. } => {
            if is_opaque_verb(*name, interner) && args.len() >= 2 {
                if let Term::Variable(v) = &args[1] {
                    if *v == theme_var {
                        return Some(*name);
                    }
                }
            }
            None
        }
        _ => None,
    }
}

fn build_de_dicto_reading<'a>(
    expr: &'a LogicExpr<'a>,
    ctx: &IntensionalContext,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
    role_arena: &'a Arena<(crate::ast::ThematicRole, Term<'a>)>,
) -> &'a LogicExpr<'a> {
    match expr {
        LogicExpr::Quantifier { kind: QuantifierKind::Existential, variable, body, .. }
            if *variable == ctx.quantifier_var =>
        {
            if let LogicExpr::BinaryOp { right, .. } = body {
                replace_theme_with_intension(right, ctx, expr_arena, term_arena, role_arena)
            } else {
                expr
            }
        }
        _ => expr,
    }
}

fn replace_theme_with_intension<'a>(
    expr: &'a LogicExpr<'a>,
    ctx: &IntensionalContext,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
    role_arena: &'a Arena<(crate::ast::ThematicRole, Term<'a>)>,
) -> &'a LogicExpr<'a> {
    match expr {
        LogicExpr::Quantifier { kind, variable, body, island_id } => {
            let new_body = replace_theme_with_intension(body, ctx, expr_arena, term_arena, role_arena);
            expr_arena.alloc(LogicExpr::Quantifier {
                kind: *kind,
                variable: *variable,
                body: new_body,
                island_id: *island_id,
            })
        }
        LogicExpr::BinaryOp { left, op, right } => {
            let new_left = replace_theme_with_intension(left, ctx, expr_arena, term_arena, role_arena);
            let new_right = replace_theme_with_intension(right, ctx, expr_arena, term_arena, role_arena);
            expr_arena.alloc(LogicExpr::BinaryOp {
                left: new_left,
                op: op.clone(),
                right: new_right,
            })
        }
        LogicExpr::NeoEvent(data) => {
            let new_roles: Vec<_> = data.roles.iter().map(|(role, term)| {
                if matches!(role, crate::ast::ThematicRole::Theme) {
                    if let Term::Variable(v) = term {
                        if *v == ctx.quantifier_var {
                            return (*role, Term::Intension(ctx.restrictor));
                        }
                    }
                }
                (*role, clone_term(term, term_arena))
            }).collect();

            expr_arena.alloc(LogicExpr::NeoEvent(Box::new(crate::ast::NeoEventData {
                event_var: data.event_var,
                verb: data.verb,
                roles: role_arena.alloc_slice(new_roles),
                modifiers: data.modifiers,
                suppress_existential: false,
                world: None,
            })))
        }
        LogicExpr::Predicate { name, args, .. } => {
            let new_args: Vec<_> = args.iter().map(|arg| {
                if let Term::Variable(v) = arg {
                    if *v == ctx.quantifier_var {
                        return Term::Intension(ctx.restrictor);
                    }
                }
                clone_term(arg, term_arena)
            }).collect();

            expr_arena.alloc(LogicExpr::Predicate {
                name: *name,
                args: term_arena.alloc_slice(new_args),
                world: None,
            })
        }
        _ => expr,
    }
}

pub fn enumerate_intensional_readings<'a>(
    expr: &'a LogicExpr<'a>,
    interner: &mut Interner,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
    role_arena: &'a Arena<(crate::ast::ThematicRole, Term<'a>)>,
) -> Vec<&'a LogicExpr<'a>> {
    // Check if expression already has intensional terms (de dicto from parser)
    if let Some(de_re) = build_de_re_from_de_dicto(expr, interner, expr_arena, term_arena, role_arena) {
        // Return both: de re first (existential), de dicto second (intension)
        return vec![de_re, expr];
    }

    // Original logic: check for de re that can be converted to de dicto
    if let Some(ctx) = find_opaque_verb_context(expr, interner) {
        let de_dicto = build_de_dicto_reading(expr, &ctx, expr_arena, term_arena, role_arena);
        vec![expr, de_dicto]
    } else {
        vec![expr]
    }
}

fn build_de_re_from_de_dicto<'a>(
    expr: &'a LogicExpr<'a>,
    interner: &mut Interner,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
    role_arena: &'a Arena<(crate::ast::ThematicRole, Term<'a>)>,
) -> Option<&'a LogicExpr<'a>> {
    // Find Term::Intension in NeoEvent themes and expand to existential
    match expr {
        LogicExpr::NeoEvent(data) => {
            // Check if any role has an Intension term
            for (role, term) in data.roles.iter() {
                if matches!(role, crate::ast::ThematicRole::Theme) {
                    if let Term::Intension(noun) = term {
                        // Build de re: ∃x(Noun(x) ∧ Event[Theme=x])
                        let var = interner.intern("x");

                        // Build noun predicate: Noun(x)
                        let noun_pred = expr_arena.alloc(LogicExpr::Predicate {
                            name: *noun,
                            args: term_arena.alloc_slice([Term::Variable(var)]),
                            world: None,
                        });

                        // Build new roles with variable instead of intension
                        let new_roles: Vec<_> = data.roles.iter().map(|(r, t)| {
                            if matches!(r, crate::ast::ThematicRole::Theme) {
                                (*r, Term::Variable(var))
                            } else {
                                (*r, t.clone())
                            }
                        }).collect();

                        let new_event = expr_arena.alloc(LogicExpr::NeoEvent(Box::new(crate::ast::NeoEventData {
                            event_var: data.event_var,
                            verb: data.verb,
                            roles: role_arena.alloc_slice(new_roles),
                            modifiers: data.modifiers,
                            suppress_existential: false,
                            world: None,
                        })));

                        // Build: ∃x(Noun(x) ∧ Event)
                        let body = expr_arena.alloc(LogicExpr::BinaryOp {
                            left: noun_pred,
                            op: crate::token::TokenType::And,
                            right: new_event,
                        });

                        return Some(expr_arena.alloc(LogicExpr::Quantifier {
                            kind: crate::ast::QuantifierKind::Existential,
                            variable: var,
                            body,
                            island_id: 0,
                        }));
                    }
                }
            }
            None
        }
        _ => None,
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::ast::{LogicExpr, Term};
    use crate::intern::Interner;
    use crate::registry::SymbolRegistry;
    use crate::OutputFormat;

    #[test]
    fn test_lambda_formatting_unicode() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let sleep = interner.intern("Sleep");

        let body = expr_arena.alloc(LogicExpr::Predicate {
            name: sleep,
            args: term_arena.alloc_slice([Term::Variable(x)]),
            world: None,
        });
        let lambda = expr_arena.alloc(LogicExpr::Lambda { variable: x, body });

        let mut registry = SymbolRegistry::new();
        let output = lambda.transpile(&mut registry, &interner, OutputFormat::Unicode);
        assert!(output.contains("λx"), "Unicode should use λ: {}", output);
    }

    #[test]
    fn test_lambda_formatting_latex() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let sleep = interner.intern("Sleep");

        let body = expr_arena.alloc(LogicExpr::Predicate {
            name: sleep,
            args: term_arena.alloc_slice([Term::Variable(x)]),
            world: None,
        });
        let lambda = expr_arena.alloc(LogicExpr::Lambda { variable: x, body });

        let mut registry = SymbolRegistry::new();
        let output = lambda.transpile(&mut registry, &interner, OutputFormat::LaTeX);
        assert!(output.contains("\\lambda"), "LaTeX should use \\lambda: {}", output);
    }

    #[test]
    fn test_application_formatting() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();

        let p = interner.intern("P");
        let j = interner.intern("j");

        let func = expr_arena.alloc(LogicExpr::Atom(p));
        let arg = expr_arena.alloc(LogicExpr::Atom(j));
        let app = expr_arena.alloc(LogicExpr::App { function: func, argument: arg });

        let mut registry = SymbolRegistry::new();
        let output = app.transpile(&mut registry, &interner, OutputFormat::Unicode);
        assert!(output.contains("(") && output.contains(")"), "App should have parens: {}", output);
    }

    #[test]
    fn test_nested_lambda() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();

        let x = interner.intern("x");
        let y = interner.intern("y");

        let inner_body = expr_arena.alloc(LogicExpr::Atom(x));
        let inner_lambda = expr_arena.alloc(LogicExpr::Lambda { variable: y, body: inner_body });
        let outer_lambda = expr_arena.alloc(LogicExpr::Lambda { variable: x, body: inner_lambda });

        let mut registry = SymbolRegistry::new();
        let output = outer_lambda.transpile(&mut registry, &interner, OutputFormat::Unicode);
        assert!(output.contains("λx") && output.contains("λy"), "Nested lambdas: {}", output);
    }

    #[test]
    fn test_lambda_app_helper_functions() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let _term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let p = interner.intern("P");

        let body = expr_arena.alloc(LogicExpr::Atom(x));
        let lambda = LogicExpr::lambda(x, body, &expr_arena);

        let arg = expr_arena.alloc(LogicExpr::Atom(p));
        let app = LogicExpr::app(lambda, arg, &expr_arena);

        assert!(matches!(app, LogicExpr::App { .. }));
    }

    #[test]
    fn lift_proper_name_returns_lambda() {
        let mut interner = Interner::new();
        let arena: Arena<LogicExpr> = Arena::new();

        let john = interner.intern("John");
        let lifted = lift_proper_name(john, &mut interner, &arena);

        assert!(matches!(lifted, LogicExpr::Lambda { .. }), "Should return Lambda");
    }

    #[test]
    fn lift_proper_name_applies_predicate() {
        let mut interner = Interner::new();
        let arena: Arena<LogicExpr> = Arena::new();

        let john = interner.intern("John");
        let lifted = lift_proper_name(john, &mut interner, &arena);

        if let LogicExpr::Lambda { body, .. } = lifted {
            assert!(matches!(body, LogicExpr::App { .. }), "Body should be App");
        } else {
            panic!("Expected Lambda");
        }
    }

    #[test]
    fn lift_quantifier_universal_returns_lambda() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let woman = interner.intern("woman");
        let lifted = lift_quantifier(QuantifierKind::Universal, woman, &mut interner, &expr_arena, &term_arena);

        assert!(matches!(lifted, LogicExpr::Lambda { .. }), "Should return Lambda");
    }

    #[test]
    fn lift_quantifier_universal_structure() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let woman = interner.intern("woman");
        let lifted = lift_quantifier(QuantifierKind::Universal, woman, &mut interner, &expr_arena, &term_arena);

        if let LogicExpr::Lambda { body, .. } = lifted {
            assert!(
                matches!(body, LogicExpr::Quantifier { kind: QuantifierKind::Universal, .. }),
                "Body should contain ∀, got {:?}",
                body
            );
        } else {
            panic!("Expected Lambda, got {:?}", lifted);
        }
    }

    #[test]
    fn lift_quantifier_existential_returns_lambda() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let man = interner.intern("man");
        let lifted = lift_quantifier(QuantifierKind::Existential, man, &mut interner, &expr_arena, &term_arena);

        assert!(matches!(lifted, LogicExpr::Lambda { .. }), "Should return Lambda");
    }

    #[test]
    fn lift_quantifier_existential_structure() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let man = interner.intern("man");
        let lifted = lift_quantifier(QuantifierKind::Existential, man, &mut interner, &expr_arena, &term_arena);

        if let LogicExpr::Lambda { body, .. } = lifted {
            assert!(
                matches!(body, LogicExpr::Quantifier { kind: QuantifierKind::Existential, .. }),
                "Body should contain ∃, got {:?}",
                body
            );
        } else {
            panic!("Expected Lambda, got {:?}", lifted);
        }
    }

    #[test]
    fn beta_reduce_simple_predicate() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let john = interner.intern("John");
        let run = interner.intern("Run");

        let body = expr_arena.alloc(LogicExpr::Predicate {
            name: run,
            args: term_arena.alloc_slice([Term::Variable(x)]),
            world: None,
        });
        let lambda = expr_arena.alloc(LogicExpr::Lambda { variable: x, body });
        let arg = expr_arena.alloc(LogicExpr::Atom(john));
        let app = expr_arena.alloc(LogicExpr::App { function: lambda, argument: arg });

        let reduced = beta_reduce(app, &expr_arena, &term_arena);

        let mut registry = SymbolRegistry::new();
        let output = reduced.transpile(&mut registry, &interner, OutputFormat::Unicode);
        assert!(output.contains("R(J)") || output.contains("Run(John)"), "Should substitute: {}", output);
    }

    #[test]
    fn beta_reduce_with_constant() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let c = interner.intern("c");

        let body = expr_arena.alloc(LogicExpr::Atom(c));
        let lambda = expr_arena.alloc(LogicExpr::Lambda { variable: x, body });
        let arg = expr_arena.alloc(LogicExpr::Atom(interner.intern("anything")));
        let app = expr_arena.alloc(LogicExpr::App { function: lambda, argument: arg });

        let reduced = beta_reduce(app, &expr_arena, &term_arena);
        assert!(matches!(reduced, LogicExpr::Atom(s) if *s == c), "Constant should remain");
    }

    #[test]
    fn beta_reduce_nested_lambda() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let y = interner.intern("y");

        let inner_body = expr_arena.alloc(LogicExpr::Atom(x));
        let inner_lambda = expr_arena.alloc(LogicExpr::Lambda { variable: y, body: inner_body });
        let outer_lambda = expr_arena.alloc(LogicExpr::Lambda { variable: x, body: inner_lambda });

        let reduced = beta_reduce(outer_lambda, &expr_arena, &term_arena);
        assert!(matches!(reduced, LogicExpr::Lambda { .. }), "Should still be lambda");
    }

    #[test]
    fn beta_reduce_non_application_unchanged() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let p = interner.intern("P");
        let atom = expr_arena.alloc(LogicExpr::Atom(p));

        let reduced = beta_reduce(atom, &expr_arena, &term_arena);
        assert!(matches!(reduced, LogicExpr::Atom(s) if *s == p), "Atom unchanged");
    }

    #[test]
    fn beta_reduce_preserves_unbound_variables() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let y = interner.intern("y");
        let john = interner.intern("John");
        let loves = interner.intern("Loves");

        let body = expr_arena.alloc(LogicExpr::Predicate {
            name: loves,
            args: term_arena.alloc_slice([Term::Variable(x), Term::Variable(y)]),
            world: None,
        });
        let lambda = expr_arena.alloc(LogicExpr::Lambda { variable: x, body });
        let arg = expr_arena.alloc(LogicExpr::Atom(john));
        let app = expr_arena.alloc(LogicExpr::App { function: lambda, argument: arg });

        let reduced = beta_reduce(app, &expr_arena, &term_arena);

        let mut registry = SymbolRegistry::new();
        let output = reduced.transpile(&mut registry, &interner, OutputFormat::Unicode);
        assert!(output.contains("y"), "y should remain unbound: {}", output);
    }

    #[test]
    fn enumerate_scopings_single_quantifier() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let dog = interner.intern("Dog");
        let bark = interner.intern("Bark");

        let left = expr_arena.alloc(LogicExpr::Predicate {
            name: dog,
            args: term_arena.alloc_slice([Term::Variable(x)]),
            world: None,
        });
        let right = expr_arena.alloc(LogicExpr::Predicate {
            name: bark,
            args: term_arena.alloc_slice([Term::Variable(x)]),
            world: None,
        });
        let body = expr_arena.alloc(LogicExpr::BinaryOp {
            left,
            op: TokenType::If,
            right,
        });
        let expr = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Universal,
            variable: x,
            body,
            island_id: 0,
        });

        let scopings = enumerate_scopings(expr, &mut interner, &expr_arena, &term_arena);
        assert_eq!(scopings.len(), 1, "Single quantifier should have 1 reading");
    }

    #[test]
    fn enumerate_scopings_no_quantifier() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let run = interner.intern("Run");
        let john = interner.intern("John");

        let expr = expr_arena.alloc(LogicExpr::Predicate {
            name: run,
            args: term_arena.alloc_slice([Term::Constant(john)]),
            world: None,
        });

        let scopings = enumerate_scopings(expr, &mut interner, &expr_arena, &term_arena);
        assert_eq!(scopings.len(), 1, "No quantifiers should have 1 reading");
    }

    #[test]
    fn is_opaque_verb_believes() {
        let mut interner = Interner::new();
        let believes = interner.intern("believes");
        let believes_cap = interner.intern("Believes");
        assert!(is_opaque_verb(believes, &interner), "believes should be opaque");
        assert!(is_opaque_verb(believes_cap, &interner), "Believes should be opaque");
    }

    #[test]
    fn is_opaque_verb_seeks() {
        let mut interner = Interner::new();
        let seeks = interner.intern("seeks");
        let wants = interner.intern("wants");
        assert!(is_opaque_verb(seeks, &interner), "seeks should be opaque");
        assert!(is_opaque_verb(wants, &interner), "wants should be opaque");
    }

    #[test]
    fn is_opaque_verb_normal_verbs() {
        let mut interner = Interner::new();
        let runs = interner.intern("runs");
        let loves = interner.intern("loves");
        assert!(!is_opaque_verb(runs, &interner), "runs should NOT be opaque");
        assert!(!is_opaque_verb(loves, &interner), "loves should NOT be opaque");
    }

    #[test]
    fn make_intensional_creates_wrapper() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let weak = interner.intern("Weak");
        let clark = interner.intern("Clark");
        let believes = interner.intern("believes");

        let content = expr_arena.alloc(LogicExpr::Predicate {
            name: weak,
            args: term_arena.alloc_slice([Term::Constant(clark)]),
            world: None,
        });

        let intensional = make_intensional(believes, content, &expr_arena);

        assert!(
            matches!(intensional, LogicExpr::Intensional { operator, .. } if *operator == believes),
            "Should create Intensional wrapper, got {:?}",
            intensional
        );
    }

    #[test]
    fn intensional_transpiles_with_brackets() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let weak = interner.intern("Weak");
        let clark = interner.intern("Clark");
        let believes = interner.intern("Believes");

        let content = expr_arena.alloc(LogicExpr::Predicate {
            name: weak,
            args: term_arena.alloc_slice([Term::Constant(clark)]),
            world: None,
        });

        let intensional = expr_arena.alloc(LogicExpr::Intensional {
            operator: believes,
            content,
        });

        let mut registry = SymbolRegistry::new();
        let output = intensional.transpile(&mut registry, &interner, OutputFormat::Unicode);

        assert!(
            output.contains("[") && output.contains("]"),
            "Intensional should use brackets: got {}",
            output
        );
    }

    #[test]
    fn substitute_respecting_opacity_blocks_inside_intensional() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let weak = interner.intern("Weak");
        let clark = interner.intern("Clark");
        let believes = interner.intern("Believes");
        let superman = interner.intern("Superman");

        let inner = expr_arena.alloc(LogicExpr::Predicate {
            name: weak,
            args: term_arena.alloc_slice([Term::Constant(clark)]),
            world: None,
        });
        let expr = expr_arena.alloc(LogicExpr::Intensional {
            operator: believes,
            content: inner,
        });

        let replacement = expr_arena.alloc(LogicExpr::Atom(superman));
        let result = substitute_respecting_opacity(expr, clark, replacement, &expr_arena, &term_arena);

        let mut registry = SymbolRegistry::new();
        let output = result.transpile(&mut registry, &interner, OutputFormat::Unicode);

        assert!(
            output.contains("C") && !output.contains("S"),
            "Should NOT substitute inside intensional context: got {}",
            output
        );
    }

    #[test]
    fn substitute_respecting_opacity_allows_outside() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let weak = interner.intern("Weak");
        let clark = interner.intern("Clark");
        let superman = interner.intern("Superman");

        let expr = expr_arena.alloc(LogicExpr::Predicate {
            name: weak,
            args: term_arena.alloc_slice([Term::Constant(clark)]),
            world: None,
        });

        let replacement = expr_arena.alloc(LogicExpr::Atom(superman));
        let result = substitute_respecting_opacity(expr, clark, replacement, &expr_arena, &term_arena);

        let mut registry = SymbolRegistry::new();
        let output = result.transpile(&mut registry, &interner, OutputFormat::Unicode);

        assert!(
            output.contains("S"),
            "Should substitute outside intensional context: got {}",
            output
        );
    }

    #[test]
    fn factorial_basic() {
        assert_eq!(factorial(0), 1);
        assert_eq!(factorial(1), 1);
        assert_eq!(factorial(2), 2);
        assert_eq!(factorial(3), 6);
        assert_eq!(factorial(4), 24);
        assert_eq!(factorial(5), 120);
    }

    #[test]
    fn scope_iterator_two_quantifiers_yields_two() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let y = interner.intern("y");
        let man = interner.intern("Man");
        let woman = interner.intern("Woman");
        let loves = interner.intern("Loves");

        let man_x = expr_arena.alloc(LogicExpr::Predicate {
            name: man,
            args: term_arena.alloc_slice([Term::Variable(x)]),
            world: None,
        });
        let woman_y = expr_arena.alloc(LogicExpr::Predicate {
            name: woman,
            args: term_arena.alloc_slice([Term::Variable(y)]),
            world: None,
        });
        let loves_xy = expr_arena.alloc(LogicExpr::Predicate {
            name: loves,
            args: term_arena.alloc_slice([Term::Variable(x), Term::Variable(y)]),
            world: None,
        });

        let inner = expr_arena.alloc(LogicExpr::BinaryOp {
            left: woman_y,
            op: TokenType::And,
            right: loves_xy,
        });
        let inner_q = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Existential,
            variable: y,
            body: inner,
            island_id: 0,
        });

        let outer = expr_arena.alloc(LogicExpr::BinaryOp {
            left: man_x,
            op: TokenType::If,
            right: inner_q,
        });
        let expr = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Universal,
            variable: x,
            body: outer,
            island_id: 0,
        });

        let scopings: Vec<_> = enumerate_scopings(expr, &mut interner, &expr_arena, &term_arena).collect();
        assert_eq!(scopings.len(), 2, "Two quantifiers should have 2! = 2 readings");
    }

    #[test]
    fn scope_iterator_three_quantifiers_yields_six() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let y = interner.intern("y");
        let z = interner.intern("z");
        let man = interner.intern("Man");
        let woman = interner.intern("Woman");
        let book = interner.intern("Book");
        let gives = interner.intern("Gives");

        let man_x = expr_arena.alloc(LogicExpr::Predicate {
            name: man,
            args: term_arena.alloc_slice([Term::Variable(x)]),
            world: None,
        });
        let woman_y = expr_arena.alloc(LogicExpr::Predicate {
            name: woman,
            args: term_arena.alloc_slice([Term::Variable(y)]),
            world: None,
        });
        let book_z = expr_arena.alloc(LogicExpr::Predicate {
            name: book,
            args: term_arena.alloc_slice([Term::Variable(z)]),
            world: None,
        });
        let gives_xyz = expr_arena.alloc(LogicExpr::Predicate {
            name: gives,
            args: term_arena.alloc_slice([Term::Variable(x), Term::Variable(y), Term::Variable(z)]),
            world: None,
        });

        let inner_z = expr_arena.alloc(LogicExpr::BinaryOp {
            left: book_z,
            op: TokenType::And,
            right: gives_xyz,
        });
        let q_z = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Existential,
            variable: z,
            body: inner_z,
            island_id: 0,
        });

        let inner_y = expr_arena.alloc(LogicExpr::BinaryOp {
            left: woman_y,
            op: TokenType::And,
            right: q_z,
        });
        let q_y = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Existential,
            variable: y,
            body: inner_y,
            island_id: 0,
        });

        let outer = expr_arena.alloc(LogicExpr::BinaryOp {
            left: man_x,
            op: TokenType::If,
            right: q_y,
        });
        let expr = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Universal,
            variable: x,
            body: outer,
            island_id: 0,
        });

        let scopings: Vec<_> = enumerate_scopings(expr, &mut interner, &expr_arena, &term_arena).collect();
        assert_eq!(scopings.len(), 6, "Three quantifiers should have 3! = 6 readings");
    }

    #[test]
    fn scope_iterator_no_duplicates() {
        use std::collections::HashSet;

        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let y = interner.intern("y");
        let man = interner.intern("Man");
        let woman = interner.intern("Woman");
        let loves = interner.intern("Loves");

        let man_x = expr_arena.alloc(LogicExpr::Predicate {
            name: man,
            args: term_arena.alloc_slice([Term::Variable(x)]),
            world: None,
        });
        let woman_y = expr_arena.alloc(LogicExpr::Predicate {
            name: woman,
            args: term_arena.alloc_slice([Term::Variable(y)]),
            world: None,
        });
        let loves_xy = expr_arena.alloc(LogicExpr::Predicate {
            name: loves,
            args: term_arena.alloc_slice([Term::Variable(x), Term::Variable(y)]),
            world: None,
        });

        let inner = expr_arena.alloc(LogicExpr::BinaryOp {
            left: woman_y,
            op: TokenType::And,
            right: loves_xy,
        });
        let inner_q = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Existential,
            variable: y,
            body: inner,
            island_id: 0,
        });

        let outer = expr_arena.alloc(LogicExpr::BinaryOp {
            left: man_x,
            op: TokenType::If,
            right: inner_q,
        });
        let expr = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Universal,
            variable: x,
            body: outer,
            island_id: 0,
        });

        let mut registry = SymbolRegistry::new();
        let outputs: HashSet<String> = enumerate_scopings(expr, &mut interner, &expr_arena, &term_arena)
            .map(|e| e.transpile(&mut registry, &interner, OutputFormat::Unicode))
            .collect();

        assert_eq!(outputs.len(), 2, "All scopings should be unique");
    }

    #[test]
    fn scope_iterator_exact_size() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let y = interner.intern("y");
        let man = interner.intern("Man");
        let woman = interner.intern("Woman");
        let loves = interner.intern("Loves");

        let man_x = expr_arena.alloc(LogicExpr::Predicate {
            name: man,
            args: term_arena.alloc_slice([Term::Variable(x)]),
            world: None,
        });
        let woman_y = expr_arena.alloc(LogicExpr::Predicate {
            name: woman,
            args: term_arena.alloc_slice([Term::Variable(y)]),
            world: None,
        });
        let loves_xy = expr_arena.alloc(LogicExpr::Predicate {
            name: loves,
            args: term_arena.alloc_slice([Term::Variable(x), Term::Variable(y)]),
            world: None,
        });

        let inner = expr_arena.alloc(LogicExpr::BinaryOp {
            left: woman_y,
            op: TokenType::And,
            right: loves_xy,
        });
        let inner_q = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Existential,
            variable: y,
            body: inner,
            island_id: 0,
        });

        let outer = expr_arena.alloc(LogicExpr::BinaryOp {
            left: man_x,
            op: TokenType::If,
            right: inner_q,
        });
        let expr = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Universal,
            variable: x,
            body: outer,
            island_id: 0,
        });

        let mut iter = enumerate_scopings(expr, &mut interner, &expr_arena, &term_arena);
        assert_eq!(iter.len(), 2);
        iter.next();
        assert_eq!(iter.len(), 1);
        iter.next();
        assert_eq!(iter.len(), 0);
    }

    #[test]
    fn island_constraints_reduce_permutations() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let y = interner.intern("y");
        let man = interner.intern("Man");
        let woman = interner.intern("Woman");
        let loves = interner.intern("Loves");

        let man_x = expr_arena.alloc(LogicExpr::Predicate {
            name: man,
            args: term_arena.alloc_slice([Term::Variable(x)]),
            world: None,
        });
        let woman_y = expr_arena.alloc(LogicExpr::Predicate {
            name: woman,
            args: term_arena.alloc_slice([Term::Variable(y)]),
            world: None,
        });
        let loves_xy = expr_arena.alloc(LogicExpr::Predicate {
            name: loves,
            args: term_arena.alloc_slice([Term::Variable(x), Term::Variable(y)]),
            world: None,
        });

        let inner = expr_arena.alloc(LogicExpr::BinaryOp {
            left: woman_y,
            op: TokenType::And,
            right: loves_xy,
        });
        let inner_q = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Existential,
            variable: y,
            body: inner,
            island_id: 1,
        });

        let outer = expr_arena.alloc(LogicExpr::BinaryOp {
            left: man_x,
            op: TokenType::If,
            right: inner_q,
        });
        let expr = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Universal,
            variable: x,
            body: outer,
            island_id: 0,
        });

        let scopings = enumerate_scopings(expr, &mut interner, &expr_arena, &term_arena);
        assert_eq!(
            scopings.len(),
            1,
            "Two quantifiers in different islands: 1! × 1! = 1 reading (no cross-island scoping)"
        );
    }

    #[test]
    fn multiple_quantifiers_per_island() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let y = interner.intern("y");
        let z = interner.intern("z");
        let w = interner.intern("w");
        let pred = interner.intern("P");

        let core = expr_arena.alloc(LogicExpr::Predicate {
            name: pred,
            args: term_arena.alloc_slice([
                Term::Variable(x),
                Term::Variable(y),
                Term::Variable(z),
                Term::Variable(w),
            ]),
            world: None,
        });

        let true_sym = interner.intern("T");
        let t = expr_arena.alloc(LogicExpr::Atom(true_sym));

        let q_w = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Existential,
            variable: w,
            body: expr_arena.alloc(LogicExpr::BinaryOp { left: t, op: TokenType::And, right: core }),
            island_id: 1,
        });
        let q_z = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Existential,
            variable: z,
            body: expr_arena.alloc(LogicExpr::BinaryOp { left: t, op: TokenType::And, right: q_w }),
            island_id: 1,
        });
        let q_y = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Existential,
            variable: y,
            body: expr_arena.alloc(LogicExpr::BinaryOp { left: t, op: TokenType::And, right: q_z }),
            island_id: 0,
        });
        let expr = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Universal,
            variable: x,
            body: expr_arena.alloc(LogicExpr::BinaryOp { left: t, op: TokenType::If, right: q_y }),
            island_id: 0,
        });

        let scopings = enumerate_scopings(expr, &mut interner, &expr_arena, &term_arena);
        assert_eq!(
            scopings.len(),
            4,
            "4 quantifiers split 2+2 across islands: 2! × 2! = 4 (not 4! = 24)"
        );
    }
}

```

---

use crate::intern::Symbol;
use std::fmt;

// ============================================
// CORE DISCOURSE TYPES (moved from context.rs)
// ============================================

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum TimeRelation {
    Precedes,
    Equals,
}

#[derive(Debug, Clone)]
pub struct TimeConstraint {
    pub left: String,
    pub relation: TimeRelation,
    pub right: String,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum Gender {
    Male,
    Female,
    Neuter,
    Unknown,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum Number {
    Singular,
    Plural,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum Case {
    Subject,
    Object,
    Possessive,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
pub enum OwnershipState {
    #[default]
    Owned,
    Moved,
    Borrowed,
}

// ============================================
// SCOPE ERROR TYPES
// ============================================

/// Error when pronoun resolution fails due to scope constraints
#[derive(Debug, Clone, PartialEq)]
pub enum ScopeError {
    /// Referent exists but is trapped in an inaccessible scope
    InaccessibleReferent {
        gender: Gender,
        blocking_scope: BoxType,
        reason: String,
    },
    /// No matching referent found at all
    NoMatchingReferent {
        gender: Gender,
        number: Number,
    },
}

impl fmt::Display for ScopeError {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            ScopeError::InaccessibleReferent { gender, blocking_scope, reason } => {
                write!(f, "Cannot resolve {:?} pronoun: referent is trapped in {:?} scope. {}",
                    gender, blocking_scope, reason)
            }
            ScopeError::NoMatchingReferent { gender, number } => {
                write!(f, "Cannot resolve {:?} {:?} pronoun: no matching referent in accessible scope",
                    gender, number)
            }
        }
    }
}

impl std::error::Error for ScopeError {}

// ============================================
// TELESCOPE SUPPORT
// ============================================

/// Path segment for navigating to insertion point during AST restructuring
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum ScopePath {
    /// Enter body of ∀ or ∃ quantifier
    QuantifierBody,
    /// Enter consequent of → implication
    ImplicationRight,
    /// Enter right side of ∧ conjunction
    ConjunctionRight,
}

/// A referent that may be accessed via telescoping across sentence boundaries
#[derive(Debug, Clone)]
pub struct TelescopeCandidate {
    pub variable: Symbol,
    pub noun_class: Symbol,
    pub gender: Gender,
    /// The box index where this referent was introduced
    pub origin_box: usize,
    /// Path to navigate AST for scope extension
    pub scope_path: Vec<ScopePath>,
    /// Whether this referent was introduced in a modal scope
    pub in_modal_scope: bool,
}

// ============================================
// MODAL SUBORDINATION SUPPORT
// ============================================

/// Modal context for tracking hypothetical worlds across sentences.
/// Enables modal subordination: "A wolf might walk in. It would eat you."
#[derive(Debug, Clone)]
pub struct ModalContext {
    /// Whether we're currently inside a modal scope
    pub active: bool,
    /// The modal flavor (epistemic vs root)
    pub is_epistemic: bool,
    /// Force value (0.0 = impossibility, 1.0 = necessity)
    pub force: f32,
}

// ============================================
// WORLD STATE (Unified Discourse State)
// ============================================

/// The unified discourse state that persists across sentences.
#[derive(Debug, Clone)]
pub struct WorldState {
    /// The global DRS (box hierarchy for scope tracking)
    pub drs: Drs,
    /// Event variable counter (e1, e2, e3...)
    event_counter: usize,
    /// Event history for temporal ordering
    event_history: Vec<String>,
    /// Reference time counter (r1, r2, r3...)
    reference_time_counter: usize,
    /// Current reference time
    current_reference_time: Option<String>,
    /// Temporal constraints between events
    time_constraints: Vec<TimeConstraint>,
    /// Telescope candidates from previous sentence
    telescope_candidates: Vec<TelescopeCandidate>,
    /// Whether we're in discourse mode (processing multi-sentence discourse)
    /// When true, unresolved pronouns should error instead of deictic fallback
    discourse_mode: bool,
    /// Current modal context (if any) for tracking modal scope
    current_modal_context: Option<ModalContext>,
    /// Modal context from previous sentence for subordination
    prior_modal_context: Option<ModalContext>,
}

impl WorldState {
    pub fn new() -> Self {
        Self {
            drs: Drs::new(),
            event_counter: 0,
            event_history: Vec::new(),
            reference_time_counter: 0,
            current_reference_time: None,
            time_constraints: Vec::new(),
            telescope_candidates: Vec::new(),
            discourse_mode: false,
            current_modal_context: None,
            prior_modal_context: None,
        }
    }

    /// Generate next event variable (e1, e2, e3...)
    pub fn next_event_var(&mut self) -> String {
        self.event_counter += 1;
        let var = format!("e{}", self.event_counter);
        self.event_history.push(var.clone());
        var
    }

    /// Get event history for temporal ordering
    pub fn event_history(&self) -> &[String] {
        &self.event_history
    }

    /// Generate next reference time (r1, r2, r3...)
    pub fn next_reference_time(&mut self) -> String {
        self.reference_time_counter += 1;
        let var = format!("r{}", self.reference_time_counter);
        self.current_reference_time = Some(var.clone());
        var
    }

    /// Get current reference time
    pub fn current_reference_time(&self) -> String {
        self.current_reference_time.clone().unwrap_or_else(|| "S".to_string())
    }

    /// Add a temporal constraint
    pub fn add_time_constraint(&mut self, left: String, relation: TimeRelation, right: String) {
        self.time_constraints.push(TimeConstraint { left, relation, right });
    }

    /// Get all time constraints
    pub fn time_constraints(&self) -> &[TimeConstraint] {
        &self.time_constraints
    }

    /// Clear time constraints (for sentence boundary reset if needed)
    pub fn clear_time_constraints(&mut self) {
        self.time_constraints.clear();
        self.reference_time_counter = 0;
        self.current_reference_time = None;
    }

    /// Mark a sentence boundary - collect telescope candidates
    pub fn end_sentence(&mut self) {
        // Collect referents that can telescope from current DRS state
        self.telescope_candidates = self.drs.get_telescope_candidates();
        // Capture modal context for subordination in next sentence
        self.prior_modal_context = self.current_modal_context.take();
        // Mark that we're now in discourse mode (multi-sentence context)
        self.discourse_mode = true;
    }

    /// Check if we're in discourse mode (multi-sentence context)
    /// In discourse mode, unresolved pronouns should error instead of deictic fallback
    pub fn in_discourse_mode(&self) -> bool {
        self.discourse_mode
    }

    /// Get telescope candidates from previous sentence
    pub fn telescope_candidates(&self) -> &[TelescopeCandidate] {
        &self.telescope_candidates
    }

    /// Try to resolve a pronoun via telescoping
    pub fn resolve_via_telescope(&mut self, gender: Gender) -> Option<TelescopeCandidate> {
        // Apply same Gender Accommodation rules as resolve_pronoun:
        // - Exact match (Male=Male, Female=Female, etc)
        // - Unknown referent matches any pronoun (Gender Accommodation)
        // - Unknown pronoun matches any referent
        for candidate in &self.telescope_candidates {
            let gender_match = candidate.gender == gender
                || candidate.gender == Gender::Unknown  // Gender Accommodation
                || gender == Gender::Unknown;

            if gender_match {
                return Some(candidate.clone());
            }
        }

        None
    }

    /// Set ownership state for a referent by noun class
    pub fn set_ownership(&mut self, noun_class: Symbol, state: OwnershipState) {
        self.drs.set_ownership(noun_class, state);
    }

    /// Get ownership state for a referent by noun class
    pub fn get_ownership(&self, noun_class: Symbol) -> Option<OwnershipState> {
        self.drs.get_ownership(noun_class)
    }

    /// Set ownership state for a referent by variable name
    pub fn set_ownership_by_var(&mut self, var: Symbol, state: OwnershipState) {
        self.drs.set_ownership_by_var(var, state);
    }

    /// Get ownership state for a referent by variable name
    pub fn get_ownership_by_var(&self, var: Symbol) -> Option<OwnershipState> {
        self.drs.get_ownership_by_var(var)
    }

    // ============================================
    // MODAL SUBORDINATION METHODS
    // ============================================

    /// Enter a modal context (e.g., "might", "would", "could")
    pub fn enter_modal_context(&mut self, is_epistemic: bool, force: f32) {
        self.current_modal_context = Some(ModalContext {
            active: true,
            is_epistemic,
            force,
        });
        // Also enter a modal box in the DRS
        self.drs.enter_box(BoxType::ModalScope);
    }

    /// Exit the current modal context
    pub fn exit_modal_context(&mut self) {
        self.current_modal_context = None;
        self.drs.exit_box();
    }

    /// Check if we're currently in a modal context
    pub fn in_modal_context(&self) -> bool {
        self.current_modal_context.is_some()
    }

    /// Check if there's a prior modal context for subordination
    pub fn has_prior_modal_context(&self) -> bool {
        self.prior_modal_context.is_some()
    }

    /// Check if current modal can subordinate to prior context
    /// "would" can continue a "might" world
    pub fn can_subordinate(&self) -> bool {
        self.prior_modal_context.is_some()
    }

    /// Clear the world state (reset for new discourse)
    pub fn clear(&mut self) {
        self.drs.clear();
        self.event_counter = 0;
        self.event_history.clear();
        self.reference_time_counter = 0;
        self.current_reference_time = None;
        self.time_constraints.clear();
        self.telescope_candidates.clear();
        self.discourse_mode = false;
        self.current_modal_context = None;
        self.prior_modal_context = None;
    }
}

impl Default for WorldState {
    fn default() -> Self {
        Self::new()
    }
}

// ============================================
// REFERENT SOURCE
// ============================================

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum ReferentSource {
    /// Indefinite in main clause - gets existential force
    MainClause,
    /// Proper name - no quantifier (constant)
    ProperName,
    /// Indefinite in conditional antecedent - gets universal force (DRS signature)
    ConditionalAntecedent,
    /// Indefinite in universal restrictor (relative clause) - gets universal force
    UniversalRestrictor,
    /// Inside negation scope - inaccessible outward
    NegationScope,
    /// Inside disjunction - inaccessible outward
    Disjunct,
    /// Inside modal scope - accessible via modal subordination
    ModalScope,
}

impl ReferentSource {
    pub fn gets_universal_force(&self) -> bool {
        matches!(
            self,
            ReferentSource::ConditionalAntecedent | ReferentSource::UniversalRestrictor
        )
    }
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum BoxType {
    /// Top-level discourse box
    Main,
    /// Antecedent of conditional ("if" clause)
    ConditionalAntecedent,
    /// Consequent of conditional ("then" clause)
    ConditionalConsequent,
    /// Scope of negation
    NegationScope,
    /// Restrictor of universal quantifier (relative clause in "every X who...")
    UniversalRestrictor,
    /// Nuclear scope of universal quantifier
    UniversalScope,
    /// Branch of disjunction
    Disjunct,
    /// Scope of modal operator (might, would, could, etc.)
    /// Allows modal subordination: pronouns can access referents via telescoping
    ModalScope,
}

impl BoxType {
    pub fn to_referent_source(&self) -> ReferentSource {
        match self {
            BoxType::Main => ReferentSource::MainClause,
            BoxType::ConditionalAntecedent => ReferentSource::ConditionalAntecedent,
            BoxType::ConditionalConsequent => ReferentSource::MainClause,
            BoxType::NegationScope => ReferentSource::NegationScope,
            BoxType::UniversalRestrictor => ReferentSource::UniversalRestrictor,
            BoxType::UniversalScope => ReferentSource::MainClause,
            BoxType::Disjunct => ReferentSource::Disjunct,
            BoxType::ModalScope => ReferentSource::ModalScope,
        }
    }

    /// Can referents in this box be accessed via telescoping across sentence boundaries?
    /// Universal quantifiers, conditionals, and modals CAN telescope.
    /// Negation and disjunction CANNOT telescope.
    pub fn can_telescope(&self) -> bool {
        matches!(
            self,
            BoxType::Main
            | BoxType::UniversalScope
            | BoxType::UniversalRestrictor
            | BoxType::ConditionalConsequent
            | BoxType::ConditionalAntecedent
            | BoxType::ModalScope  // Modal subordination allows cross-sentence access
        )
        // NegationScope and Disjunct return false implicitly
    }

    /// Does this box type block accessibility from outside?
    pub fn blocks_accessibility(&self) -> bool {
        matches!(self, BoxType::NegationScope | BoxType::Disjunct)
    }
}

#[derive(Debug, Clone)]
pub struct Referent {
    pub variable: Symbol,
    pub noun_class: Symbol,
    pub gender: Gender,
    pub number: Number,
    pub source: ReferentSource,
    pub used_by_pronoun: bool,
    pub ownership: OwnershipState,
}

impl Referent {
    pub fn new(variable: Symbol, noun_class: Symbol, gender: Gender, number: Number, source: ReferentSource) -> Self {
        Self {
            variable,
            noun_class,
            gender,
            number,
            source,
            used_by_pronoun: false,
            ownership: OwnershipState::Owned,
        }
    }

    pub fn should_be_universal(&self) -> bool {
        self.source.gets_universal_force() || self.used_by_pronoun
    }
}

#[derive(Debug, Clone, Default)]
pub struct DrsBox {
    pub universe: Vec<Referent>,
    pub box_type: Option<BoxType>,
    pub parent: Option<usize>,
}

impl DrsBox {
    pub fn new(box_type: BoxType, parent: Option<usize>) -> Self {
        Self {
            universe: Vec::new(),
            box_type: Some(box_type),
            parent,
        }
    }
}

#[derive(Debug, Clone)]
pub struct Drs {
    boxes: Vec<DrsBox>,
    main_box: usize,
    current_box: usize,
}

impl Drs {
    pub fn new() -> Self {
        let main = DrsBox::new(BoxType::Main, None);
        Self {
            boxes: vec![main],
            main_box: 0,
            current_box: 0,
        }
    }

    pub fn enter_box(&mut self, box_type: BoxType) -> usize {
        let parent = self.current_box;
        let new_box = DrsBox::new(box_type, Some(parent));
        let idx = self.boxes.len();
        self.boxes.push(new_box);
        self.current_box = idx;
        idx
    }

    pub fn exit_box(&mut self) {
        if let Some(parent) = self.boxes[self.current_box].parent {
            self.current_box = parent;
        }
    }

    pub fn current_box_index(&self) -> usize {
        self.current_box
    }

    pub fn current_box_type(&self) -> Option<BoxType> {
        self.boxes.get(self.current_box).and_then(|b| b.box_type)
    }

    pub fn introduce_referent(&mut self, variable: Symbol, noun_class: Symbol, gender: Gender, number: Number) {
        let source = self.boxes[self.current_box]
            .box_type
            .map(|bt| bt.to_referent_source())
            .unwrap_or(ReferentSource::MainClause);

        let referent = Referent::new(variable, noun_class, gender, number, source);
        self.boxes[self.current_box].universe.push(referent);
    }

    /// Introduce a referent with an explicit source (used for negative quantifiers like "No X")
    pub fn introduce_referent_with_source(&mut self, variable: Symbol, noun_class: Symbol, gender: Gender, number: Number, source: ReferentSource) {
        let referent = Referent::new(variable, noun_class, gender, number, source);
        self.boxes[self.current_box].universe.push(referent);
    }

    pub fn introduce_proper_name(&mut self, variable: Symbol, name: Symbol, gender: Gender) {
        // Proper names are always singular
        let referent = Referent::new(variable, name, gender, Number::Singular, ReferentSource::ProperName);
        self.boxes[self.current_box].universe.push(referent);
    }

    /// Check if a referent in box `from_box` can access referents in box `target_box`
    pub fn is_accessible(&self, target_box: usize, from_box: usize) -> bool {
        if target_box == from_box {
            return true;
        }

        let target = &self.boxes[target_box];
        let from = &self.boxes[from_box];

        // Check target box type - some boxes block outward access
        if let Some(bt) = target.box_type {
            match bt {
                BoxType::NegationScope | BoxType::Disjunct => {
                    // These boxes are NOT accessible from outside
                    return false;
                }
                _ => {}
            }
        }

        // Check if from_box can see target_box
        // Consequent can see antecedent
        if let (Some(BoxType::ConditionalConsequent), Some(BoxType::ConditionalAntecedent)) =
            (from.box_type, target.box_type)
        {
            // Check if they share the same parent (same conditional)
            if from.parent == target.parent {
                return true;
            }
        }

        // Universal scope can see universal restrictor
        if let (Some(BoxType::UniversalScope), Some(BoxType::UniversalRestrictor)) =
            (from.box_type, target.box_type)
        {
            if from.parent == target.parent {
                return true;
            }
        }

        // Can always access ancestors (parent chain)
        let mut current = from_box;
        while let Some(parent) = self.boxes[current].parent {
            if parent == target_box {
                return true;
            }
            current = parent;
        }

        false
    }

    /// Resolve a pronoun by finding accessible referents matching gender and number
    pub fn resolve_pronoun(&mut self, from_box: usize, gender: Gender, number: Number) -> Result<Symbol, ScopeError> {
        // Phase 1: Search accessible boxes (skip referents from NegationScope source)
        let mut candidates = Vec::new();

        for (box_idx, drs_box) in self.boxes.iter().enumerate() {
            if self.is_accessible(box_idx, from_box) {
                for referent in &drs_box.universe {
                    // Skip referents that are from negative quantifiers (No X)
                    if matches!(referent.source, ReferentSource::NegationScope) {
                        continue;
                    }

                    // Gender matching rules:
                    // - Exact match (Male=Male, Female=Female, etc)
                    // - Unknown referents match any pronoun (gender accommodation)
                    // - Unknown pronouns match any referent
                    // This allows "He" to refer to "farmer" even if farmer's gender is Unknown
                    let gender_match = referent.gender == gender
                        || referent.gender == Gender::Unknown
                        || gender == Gender::Unknown;

                    // Number matching: must match exactly (no number accommodation)
                    let number_match = referent.number == number;

                    if gender_match && number_match {
                        candidates.push((box_idx, referent.variable));
                    }
                }
            }
        }

        // If found in accessible scope, return success
        if let Some((box_idx, var)) = candidates.last() {
            let box_idx = *box_idx;
            let var = *var;
            for referent in &mut self.boxes[box_idx].universe {
                if referent.variable == var {
                    referent.used_by_pronoun = true;
                    return Ok(var);
                }
            }
        }

        // Phase 2: Check inaccessible boxes OR referents with NegationScope source
        // Use the same strict gender matching for consistency
        for (_box_idx, drs_box) in self.boxes.iter().enumerate() {
            for referent in &drs_box.universe {
                // Check for referents with NegationScope source (from "No X")
                // OR referents in inaccessible boxes
                let is_inaccessible = matches!(referent.source, ReferentSource::NegationScope)
                    || !self.is_accessible(_box_idx, from_box);

                if is_inaccessible {
                    // Same matching as Phase 1
                    let gender_match = referent.gender == gender
                        || (gender == Gender::Unknown)
                        || (gender == Gender::Neuter && referent.gender == Gender::Unknown);
                    let number_match = referent.number == number;

                    if gender_match && number_match {
                        // Found a matching referent but it's inaccessible
                        let blocking_scope = if matches!(referent.source, ReferentSource::NegationScope) {
                            BoxType::NegationScope
                        } else {
                            drs_box.box_type.unwrap_or(BoxType::Main)
                        };
                        let noun_class_str = format!("{:?}", referent.noun_class);
                        return Err(ScopeError::InaccessibleReferent {
                            gender,
                            blocking_scope,
                            reason: format!("'{}' is trapped in {:?} scope and cannot be accessed",
                                noun_class_str, blocking_scope),
                        });
                    }
                }
            }
        }

        // Phase 3: Not found anywhere
        Err(ScopeError::NoMatchingReferent {
            gender,
            number,
        })
    }

    /// Resolve a definite description by finding accessible referent matching noun class
    pub fn resolve_definite(&self, from_box: usize, noun_class: Symbol) -> Option<Symbol> {
        for (box_idx, drs_box) in self.boxes.iter().enumerate() {
            if self.is_accessible(box_idx, from_box) {
                for referent in drs_box.universe.iter().rev() {
                    if referent.noun_class == noun_class {
                        return Some(referent.variable);
                    }
                }
            }
        }
        None
    }

    /// Check if a referent exists by variable name (for imperative mode variable validation)
    pub fn has_referent_by_variable(&self, var: Symbol) -> bool {
        for drs_box in &self.boxes {
            for referent in &drs_box.universe {
                if referent.variable == var {
                    return true;
                }
            }
        }
        false
    }

    /// Resolve bridging anaphora by finding referents whose type contains the noun as a part.
    /// Returns matching referent and whole name for PartOf relation.
    pub fn resolve_bridging(&self, interner: &crate::Interner, noun_class: Symbol) -> Option<(Symbol, &'static str)> {
        use crate::ontology::find_bridging_wholes;

        let noun_str = interner.resolve(noun_class);
        let Some(wholes) = find_bridging_wholes(noun_str) else {
            return None;
        };

        // Look for a referent whose noun_class matches one of the possible wholes
        for whole in wholes {
            for drs_box in &self.boxes {
                for referent in drs_box.universe.iter().rev() {
                    let ref_class_str = interner.resolve(referent.noun_class);
                    if ref_class_str.eq_ignore_ascii_case(whole) {
                        return Some((referent.variable, *whole));
                    }
                }
            }
        }
        None
    }

    /// Get all referents that should receive universal quantification
    pub fn get_universal_referents(&self) -> Vec<Symbol> {
        let mut result = Vec::new();
        for drs_box in &self.boxes {
            for referent in &drs_box.universe {
                if referent.should_be_universal() {
                    result.push(referent.variable);
                }
            }
        }
        result
    }

    /// Get all referents that should receive existential quantification
    pub fn get_existential_referents(&self) -> Vec<Symbol> {
        let mut result = Vec::new();
        for drs_box in &self.boxes {
            for referent in &drs_box.universe {
                if !referent.should_be_universal()
                    && !matches!(referent.source, ReferentSource::ProperName)
                {
                    result.push(referent.variable);
                }
            }
        }
        result
    }

    /// Get the most recent event referent (for binding weather adjectives to events)
    pub fn get_last_event_referent(&self, interner: &crate::intern::Interner) -> Option<Symbol> {
        // Search all boxes in reverse order for event referents
        for drs_box in self.boxes.iter().rev() {
            for referent in drs_box.universe.iter().rev() {
                let class_str = interner.resolve(referent.noun_class);
                if class_str == "Event" {
                    return Some(referent.variable);
                }
            }
        }
        None
    }

    /// Check if we're currently in a conditional antecedent
    pub fn in_conditional_antecedent(&self) -> bool {
        matches!(
            self.boxes.get(self.current_box).and_then(|b| b.box_type),
            Some(BoxType::ConditionalAntecedent)
        )
    }

    /// Check if we're currently in a universal restrictor
    pub fn in_universal_restrictor(&self) -> bool {
        matches!(
            self.boxes.get(self.current_box).and_then(|b| b.box_type),
            Some(BoxType::UniversalRestrictor)
        )
    }

    /// Get all referents that can telescope across sentence boundaries.
    /// Only includes referents from boxes where can_telescope() is true.
    /// Excludes referents blocked by negation or disjunction.
    pub fn get_telescope_candidates(&self) -> Vec<TelescopeCandidate> {
        let mut candidates = Vec::new();

        for (box_idx, drs_box) in self.boxes.iter().enumerate() {
            // Check if this box type allows telescoping
            if let Some(box_type) = drs_box.box_type {
                if !box_type.can_telescope() {
                    continue; // Skip negation and disjunction boxes
                }
            }

            // Check if this box is blocked by an ancestor negation/disjunction
            let mut is_blocked = false;
            let mut check_idx = box_idx;
            while let Some(parent_idx) = self.boxes.get(check_idx).and_then(|b| b.parent) {
                if let Some(parent_type) = self.boxes.get(parent_idx).and_then(|b| b.box_type) {
                    if parent_type.blocks_accessibility() {
                        is_blocked = true;
                        break;
                    }
                }
                check_idx = parent_idx;
            }

            if is_blocked {
                continue;
            }

            // Collect referents from this box (skip those with blocking sources)
            let is_modal_box = drs_box.box_type == Some(BoxType::ModalScope);
            for referent in &drs_box.universe {
                // Skip referents that are marked with NegationScope or Disjunct source
                // These are trapped inside negation/disjunction and cannot telescope
                if matches!(referent.source, ReferentSource::NegationScope | ReferentSource::Disjunct) {
                    continue;
                }

                candidates.push(TelescopeCandidate {
                    variable: referent.variable,
                    noun_class: referent.noun_class,
                    gender: referent.gender,
                    origin_box: box_idx,
                    scope_path: Vec::new(), // TODO: Track scope path during parsing
                    in_modal_scope: is_modal_box || referent.source == ReferentSource::ModalScope,
                });
            }
        }

        candidates
    }

    /// Find a referent that matches but is blocked by scope.
    /// Used to generate informative error messages.
    pub fn find_blocked_referent(&self, from_box: usize, gender: Gender) -> Option<(Symbol, BoxType)> {
        for (box_idx, drs_box) in self.boxes.iter().enumerate() {
            // Only check boxes that are NOT accessible
            if self.is_accessible(box_idx, from_box) {
                continue;
            }

            // Check if this box type blocks access
            if let Some(box_type) = drs_box.box_type {
                if box_type.blocks_accessibility() {
                    for referent in &drs_box.universe {
                        let gender_match = gender == Gender::Unknown
                            || referent.gender == Gender::Unknown
                            || referent.gender == gender
                            || gender == Gender::Neuter;

                        if gender_match {
                            return Some((referent.variable, box_type));
                        }
                    }
                }
            }
        }
        None
    }

    /// Set ownership state for a referent by noun class
    pub fn set_ownership(&mut self, noun_class: Symbol, state: OwnershipState) {
        for drs_box in &mut self.boxes {
            for referent in &mut drs_box.universe {
                if referent.noun_class == noun_class {
                    referent.ownership = state;
                    return;
                }
            }
        }
    }

    /// Set ownership state for a referent by variable name
    pub fn set_ownership_by_var(&mut self, var: Symbol, state: OwnershipState) {
        for drs_box in &mut self.boxes {
            for referent in &mut drs_box.universe {
                if referent.variable == var {
                    referent.ownership = state;
                    return;
                }
            }
        }
    }

    /// Get ownership state for a referent by noun class
    pub fn get_ownership(&self, noun_class: Symbol) -> Option<OwnershipState> {
        for drs_box in &self.boxes {
            for referent in &drs_box.universe {
                if referent.noun_class == noun_class {
                    return Some(referent.ownership);
                }
            }
        }
        None
    }

    /// Get ownership state for a referent by variable name
    pub fn get_ownership_by_var(&self, var: Symbol) -> Option<OwnershipState> {
        for drs_box in &self.boxes {
            for referent in &drs_box.universe {
                if referent.variable == var {
                    return Some(referent.ownership);
                }
            }
        }
        None
    }

    pub fn clear(&mut self) {
        self.boxes.clear();
        let main = DrsBox::new(BoxType::Main, None);
        self.boxes.push(main);
        self.main_box = 0;
        self.current_box = 0;
    }
}

impl Default for Drs {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::intern::Interner;

    #[test]
    fn referent_source_universal_force() {
        assert!(ReferentSource::ConditionalAntecedent.gets_universal_force());
        assert!(ReferentSource::UniversalRestrictor.gets_universal_force());
        assert!(!ReferentSource::MainClause.gets_universal_force());
        assert!(!ReferentSource::ProperName.gets_universal_force());
    }

    #[test]
    fn drs_new_has_main_box() {
        let drs = Drs::new();
        assert_eq!(drs.boxes.len(), 1);
        assert_eq!(drs.current_box, 0);
        assert_eq!(drs.boxes[0].box_type, Some(BoxType::Main));
    }

    #[test]
    fn drs_enter_exit_box() {
        let mut drs = Drs::new();
        assert_eq!(drs.current_box, 0);

        let ant_idx = drs.enter_box(BoxType::ConditionalAntecedent);
        assert_eq!(ant_idx, 1);
        assert_eq!(drs.current_box, 1);
        assert_eq!(drs.boxes[1].parent, Some(0));

        drs.exit_box();
        assert_eq!(drs.current_box, 0);
    }

    #[test]
    fn drs_introduce_referent_tracks_source() {
        let mut interner = Interner::new();
        let mut drs = Drs::new();

        let x = interner.intern("x");
        let farmer = interner.intern("Farmer");

        // In main box - should be MainClause
        drs.introduce_referent(x, farmer, Gender::Male, Number::Singular);
        assert_eq!(drs.boxes[0].universe[0].source, ReferentSource::MainClause);

        // Enter conditional antecedent
        drs.enter_box(BoxType::ConditionalAntecedent);
        let y = interner.intern("y");
        let donkey = interner.intern("Donkey");
        drs.introduce_referent(y, donkey, Gender::Neuter, Number::Singular);
        assert_eq!(
            drs.boxes[1].universe[0].source,
            ReferentSource::ConditionalAntecedent
        );
    }

    #[test]
    fn drs_conditional_antecedent_accessible_from_consequent() {
        let mut interner = Interner::new();
        let mut drs = Drs::new();

        // Enter conditional antecedent
        let ant_idx = drs.enter_box(BoxType::ConditionalAntecedent);
        let y = interner.intern("y");
        let donkey = interner.intern("Donkey");
        drs.introduce_referent(y, donkey, Gender::Neuter, Number::Singular);
        drs.exit_box();

        // Enter conditional consequent
        let cons_idx = drs.enter_box(BoxType::ConditionalConsequent);

        // Consequent should be able to access antecedent
        assert!(drs.is_accessible(ant_idx, cons_idx));
    }

    #[test]
    fn drs_negation_blocks_accessibility() {
        let mut drs = Drs::new();

        // Enter negation scope
        let neg_idx = drs.enter_box(BoxType::NegationScope);
        drs.exit_box();

        // Main box should NOT be able to access negation scope
        assert!(!drs.is_accessible(neg_idx, 0));
    }

    #[test]
    fn drs_get_universal_referents() {
        let mut interner = Interner::new();
        let mut drs = Drs::new();

        let x = interner.intern("x");
        let farmer = interner.intern("Farmer");
        drs.introduce_referent(x, farmer, Gender::Male, Number::Singular);

        drs.enter_box(BoxType::ConditionalAntecedent);
        let y = interner.intern("y");
        let donkey = interner.intern("Donkey");
        drs.introduce_referent(y, donkey, Gender::Neuter, Number::Singular);

        let universals = drs.get_universal_referents();
        assert_eq!(universals.len(), 1);
        assert_eq!(universals[0], y);
    }

    #[test]
    fn drs_pronoun_resolution_marks_used() {
        let mut interner = Interner::new();
        let mut drs = Drs::new();

        drs.enter_box(BoxType::UniversalRestrictor);
        let y = interner.intern("y");
        let donkey = interner.intern("Donkey");
        drs.introduce_referent(y, donkey, Gender::Neuter, Number::Singular);

        // Resolve "it" - should find donkey
        let resolved = drs.resolve_pronoun(drs.current_box, Gender::Neuter, Number::Singular);
        assert_eq!(resolved, Ok(y));

        // Should be marked as used
        assert!(drs.boxes[1].universe[0].used_by_pronoun);
    }
}

```

---

## Transpilation

Converting Logic AST to string representations.
use std::fmt::Write;

use crate::ast::{LogicExpr, NounPhrase, Term, QuantifierKind};
use crate::ast::logic::NumberKind;
use crate::formatter::{KripkeFormatter, LatexFormatter, LogicFormatter, SimpleFOLFormatter, UnicodeFormatter};
use crate::intern::{Interner, Symbol};
use crate::registry::SymbolRegistry;
use crate::token::TokenType;
use crate::{OutputFormat, TranspileContext};

/// Collect event variables from NeoEvents with suppress_existential=true
/// Returns unique event variables (coordinated weather verbs share the same var)
fn collect_suppress_existential_events<'a>(expr: &LogicExpr<'a>) -> Vec<Symbol> {
    let mut events = Vec::new();
    collect_suppress_existential_events_inner(expr, &mut events);
    // Deduplicate - coordinated weather verbs share the same event variable
    // Symbol is Copy so we can use a simple O(n^2) dedup
    let mut unique = Vec::new();
    for e in events {
        if !unique.iter().any(|x| *x == e) {
            unique.push(e);
        }
    }
    unique
}

fn collect_suppress_existential_events_inner<'a>(expr: &LogicExpr<'a>, events: &mut Vec<Symbol>) {
    match expr {
        LogicExpr::NeoEvent(data) => {
            if data.suppress_existential {
                events.push(data.event_var);
            }
        }
        LogicExpr::BinaryOp { left, right, .. } => {
            collect_suppress_existential_events_inner(left, events);
            collect_suppress_existential_events_inner(right, events);
        }
        LogicExpr::UnaryOp { operand, .. } => {
            collect_suppress_existential_events_inner(operand, events);
        }
        LogicExpr::Temporal { body, .. } => {
            collect_suppress_existential_events_inner(body, events);
        }
        LogicExpr::Aspectual { body, .. } => {
            collect_suppress_existential_events_inner(body, events);
        }
        LogicExpr::Modal { operand, .. } => {
            collect_suppress_existential_events_inner(operand, events);
        }
        _ => {}
    }
}

pub fn capitalize_first(s: &str) -> String {
    let mut chars = s.chars();
    match chars.next() {
        None => String::new(),
        Some(c) => c.to_uppercase().collect::<String>() + chars.as_str(),
    }
}

fn write_capitalized<W: Write>(w: &mut W, s: &str) -> std::fmt::Result {
    let mut chars = s.chars();
    match chars.next() {
        None => Ok(()),
        Some(c) => {
            for uc in c.to_uppercase() {
                write!(w, "{}", uc)?;
            }
            write!(w, "{}", chars.as_str())
        }
    }
}

impl<'a> NounPhrase<'a> {
    pub fn to_symbol(&self, registry: &mut SymbolRegistry, interner: &Interner) -> String {
        registry.get_symbol(self.noun, interner)
    }

    pub fn to_symbol_full(&self, registry: &SymbolRegistry, interner: &Interner) -> String {
        registry.get_symbol_full(self.noun, interner)
    }
}

impl<'a> Term<'a> {
    pub fn write_to<W: Write>(
        &self,
        w: &mut W,
        registry: &mut SymbolRegistry,
        interner: &Interner,
    ) -> std::fmt::Result {
        self.write_to_inner(w, registry, interner, false)
    }

    pub fn write_to_full<W: Write>(
        &self,
        w: &mut W,
        registry: &mut SymbolRegistry,
        interner: &Interner,
    ) -> std::fmt::Result {
        self.write_to_inner(w, registry, interner, true)
    }

    /// Write term preserving original case (for code generation)
    pub fn write_to_raw<W: Write>(
        &self,
        w: &mut W,
        interner: &Interner,
    ) -> std::fmt::Result {
        match self {
            Term::Constant(name) | Term::Variable(name) => {
                write!(w, "{}", interner.resolve(*name))
            }
            Term::Function(name, args) => {
                write!(w, "{}(", interner.resolve(*name))?;
                for (i, arg) in args.iter().enumerate() {
                    if i > 0 {
                        write!(w, ", ")?;
                    }
                    arg.write_to_raw(w, interner)?;
                }
                write!(w, ")")
            }
            Term::Group(members) => {
                write!(w, "(")?;
                for (i, m) in members.iter().enumerate() {
                    if i > 0 {
                        write!(w, ", ")?;
                    }
                    m.write_to_raw(w, interner)?;
                }
                write!(w, ")")
            }
            Term::Possessed { possessor, possessed } => {
                possessor.write_to_raw(w, interner)?;
                write!(w, ".{}", interner.resolve(*possessed))
            }
            Term::Value { kind, .. } => match kind {
                NumberKind::Integer(n) => write!(w, "{}", n),
                NumberKind::Real(f) => write!(w, "{}", f),
                NumberKind::Symbolic(s) => write!(w, "{}", interner.resolve(*s)),
            }
            Term::Sigma(predicate) => write!(w, "σ({})", interner.resolve(*predicate)),
            Term::Intension(predicate) => write!(w, "^{}", interner.resolve(*predicate)),
            Term::Proposition(expr) => write!(w, "[proposition]"),
        }
    }

    fn write_to_inner<W: Write>(
        &self,
        w: &mut W,
        registry: &mut SymbolRegistry,
        interner: &Interner,
        use_full_names: bool,
    ) -> std::fmt::Result {
        match self {
            Term::Constant(name) => {
                if use_full_names {
                    write!(w, "{}", registry.get_symbol_full(*name, interner))
                } else {
                    write!(w, "{}", registry.get_symbol(*name, interner))
                }
            }
            Term::Variable(name) => write!(w, "{}", interner.resolve(*name)),
            Term::Function(name, args) => {
                let fn_name = if use_full_names {
                    registry.get_symbol_full(*name, interner)
                } else {
                    registry.get_symbol(*name, interner)
                };
                write!(w, "{}(", fn_name)?;
                for (i, arg) in args.iter().enumerate() {
                    if i > 0 {
                        write!(w, ", ")?;
                    }
                    arg.write_to_inner(w, registry, interner, use_full_names)?;
                }
                write!(w, ")")
            }
            Term::Group(members) => {
                for (i, m) in members.iter().enumerate() {
                    if i > 0 {
                        write!(w, " ⊕ ")?;
                    }
                    m.write_to_inner(w, registry, interner, use_full_names)?;
                }
                Ok(())
            }
            Term::Possessed { possessor, possessed } => {
                let poss_name = if use_full_names {
                    registry.get_symbol_full(*possessed, interner)
                } else {
                    registry.get_symbol(*possessed, interner)
                };
                write!(w, "Poss(")?;
                possessor.write_to_inner(w, registry, interner, use_full_names)?;
                write!(w, ", {})", poss_name)
            }
            Term::Sigma(predicate) => {
                let pred_name = if use_full_names {
                    registry.get_symbol_full(*predicate, interner)
                } else {
                    registry.get_symbol(*predicate, interner)
                };
                write!(w, "σ{}", pred_name)
            }
            Term::Intension(predicate) => {
                // Use full word for intensional terms, not abbreviated symbol
                let word = interner.resolve(*predicate);
                let capitalized = word.chars().next()
                    .map(|c| c.to_uppercase().collect::<String>() + &word[1..])
                    .unwrap_or_default();
                write!(w, "^{}", capitalized)
            }
            Term::Proposition(expr) => {
                write!(w, "[")?;
                expr.write_logic(w, registry, interner, &UnicodeFormatter)?;
                write!(w, "]")
            }
            Term::Value { kind, unit, dimension: _ } => {
                use crate::ast::NumberKind;
                match kind {
                    NumberKind::Real(r) => write!(w, "{}", r)?,
                    NumberKind::Integer(i) => write!(w, "{}", i)?,
                    NumberKind::Symbolic(s) => write!(w, "{}", interner.resolve(*s))?,
                }
                if let Some(u) = unit {
                    write!(w, " {}", interner.resolve(*u))?;
                }
                Ok(())
            }
        }
    }

    pub fn transpile(&self, registry: &mut SymbolRegistry, interner: &Interner) -> String {
        let mut buf = String::new();
        let _ = self.write_to(&mut buf, registry, interner);
        buf
    }
}

impl<'a> LogicExpr<'a> {
    pub fn write_logic<W: Write, F: LogicFormatter>(
        &self,
        w: &mut W,
        registry: &mut SymbolRegistry,
        interner: &Interner,
        fmt: &F,
    ) -> std::fmt::Result {
        match self {
            LogicExpr::Predicate { name, args, world } => {
                let pred_name = if fmt.use_full_names() {
                    registry.get_symbol_full(*name, interner)
                } else {
                    registry.get_symbol(*name, interner)
                };

                // If formatter wants world arguments and we have one, append it
                if fmt.include_world_arguments() {
                    if let Some(w_sym) = world {
                        // Build extended args with world variable appended
                        let mut extended: Vec<Term> = args.to_vec();
                        extended.push(Term::Variable(*w_sym));
                        return fmt.write_predicate(w, &pred_name, &extended, registry, interner);
                    }
                }
                fmt.write_predicate(w, &pred_name, args, registry, interner)
            }

            LogicExpr::Identity { left, right } => {
                if fmt.wrap_identity() {
                    write!(w, "(")?;
                }
                if fmt.preserve_case() {
                    left.write_to_raw(w, interner)?;
                } else if fmt.use_full_names() {
                    left.write_to_full(w, registry, interner)?;
                } else {
                    left.write_to(w, registry, interner)?;
                }
                write!(w, "{}", fmt.identity())?;
                if fmt.preserve_case() {
                    right.write_to_raw(w, interner)?;
                } else if fmt.use_full_names() {
                    right.write_to_full(w, registry, interner)?;
                } else {
                    right.write_to(w, registry, interner)?;
                }
                if fmt.wrap_identity() {
                    write!(w, ")")?;
                }
                Ok(())
            }

            LogicExpr::Metaphor { tenor, vehicle } => {
                write!(w, "Metaphor(")?;
                tenor.write_to(w, registry, interner)?;
                write!(w, ", ")?;
                vehicle.write_to(w, registry, interner)?;
                write!(w, ")")
            }

            LogicExpr::Quantifier { kind, variable, body, .. } => {
                let var_str = interner.resolve(*variable);

                // In SimpleFOL mode, skip event quantifiers (variables named "e" or starting with "e" followed by digits)
                if fmt.use_simple_events() && (var_str == "e" || var_str.starts_with("e") && var_str[1..].chars().all(|c| c.is_ascii_digit())) {
                    return body.write_logic(w, registry, interner, fmt);
                }

                let mut body_buf = String::new();
                body.write_logic(&mut body_buf, registry, interner, fmt)?;
                write!(w, "{}", fmt.quantifier(kind, var_str, &body_buf))
            }

            LogicExpr::Categorical(data) => {
                let s = if fmt.use_full_names() {
                    fmt.sanitize(&data.subject.to_symbol_full(registry, interner))
                } else {
                    fmt.sanitize(&data.subject.to_symbol(registry, interner))
                };
                let p = if fmt.use_full_names() {
                    fmt.sanitize(&data.predicate.to_symbol_full(registry, interner))
                } else {
                    fmt.sanitize(&data.predicate.to_symbol(registry, interner))
                };
                match (&data.quantifier, data.copula_negative) {
                    (TokenType::All, false) => write!(w, "{} {} is {}", fmt.categorical_all(), s, p),
                    (TokenType::No, false) => write!(w, "{} {} is {}", fmt.categorical_no(), s, p),
                    (TokenType::Some, false) => write!(w, "{} {} is {}", fmt.categorical_some(), s, p),
                    (TokenType::Some, true) => write!(w, "{} {} is {} {}", fmt.categorical_some(), s, fmt.categorical_not(), p),
                    (TokenType::All, true) => write!(w, "{} {} is {} {}", fmt.categorical_some(), s, fmt.categorical_not(), p),
                    _ => write!(w, "Invalid Syllogism"),
                }
            }

            LogicExpr::Relation(data) => {
                let s = if fmt.use_full_names() {
                    data.subject.to_symbol_full(registry, interner)
                } else {
                    data.subject.to_symbol(registry, interner)
                };
                let v = if fmt.use_full_names() {
                    fmt.sanitize(&registry.get_symbol_full(data.verb, interner))
                } else {
                    fmt.sanitize(&registry.get_symbol(data.verb, interner))
                };
                let o = if fmt.use_full_names() {
                    data.object.to_symbol_full(registry, interner)
                } else {
                    data.object.to_symbol(registry, interner)
                };
                write!(w, "{}({}, {})", v, s, o)
            }

            LogicExpr::Modal { vector, operand } => {
                let mut o = String::new();
                operand.write_logic(&mut o, registry, interner, fmt)?;
                write!(w, "{}", fmt.modal(vector.domain, vector.force, &o))
            }

            LogicExpr::BinaryOp { left, op, right } => {
                let mut l = String::new();
                let mut r = String::new();
                left.write_logic(&mut l, registry, interner, fmt)?;
                right.write_logic(&mut r, registry, interner, fmt)?;

                // For conditionals (If), check if there are suppress_existential events
                // that need universal quantification (DRS semantics for generic conditionals)
                if matches!(op, TokenType::If) {
                    let events = collect_suppress_existential_events(self);
                    if !events.is_empty() {
                        // Wrap with universal quantifiers for each event variable
                        let mut result = fmt.binary_op(op, &l, &r);
                        for event_var in events.into_iter().rev() {
                            let var_str = interner.resolve(event_var);
                            result = fmt.quantifier(&QuantifierKind::Universal, var_str, &result);
                        }
                        return write!(w, "{}", result);
                    }
                }

                write!(w, "{}", fmt.binary_op(op, &l, &r))
            }

            LogicExpr::UnaryOp { op, operand } => {
                let mut o = String::new();
                operand.write_logic(&mut o, registry, interner, fmt)?;
                write!(w, "{}", fmt.unary_op(op, &o))
            }

            LogicExpr::Temporal { operator, body } => {
                let mut inner = String::new();
                body.write_logic(&mut inner, registry, interner, fmt)?;
                write!(w, "{}", fmt.temporal(operator, &inner))
            }

            LogicExpr::Aspectual { operator, body } => {
                let mut inner = String::new();
                body.write_logic(&mut inner, registry, interner, fmt)?;
                write!(w, "{}", fmt.aspectual(operator, &inner))
            }

            LogicExpr::Voice { operator, body } => {
                let mut inner = String::new();
                body.write_logic(&mut inner, registry, interner, fmt)?;
                write!(w, "{}", fmt.voice(operator, &inner))
            }

            LogicExpr::Question { wh_variable, body } => {
                let mut body_str = String::new();
                body.write_logic(&mut body_str, registry, interner, fmt)?;
                write!(w, "{}", fmt.lambda(interner.resolve(*wh_variable), &body_str))
            }

            LogicExpr::YesNoQuestion { body } => {
                write!(w, "?")?;
                body.write_logic(w, registry, interner, fmt)
            }

            LogicExpr::Atom(s) => {
                let name = if fmt.preserve_case() {
                    interner.resolve(*s).to_string()
                } else if fmt.use_full_names() {
                    registry.get_symbol_full(*s, interner)
                } else {
                    registry.get_symbol(*s, interner)
                };
                write!(w, "{}", fmt.sanitize(&name))
            }

            LogicExpr::Lambda { variable, body } => {
                let mut b = String::new();
                body.write_logic(&mut b, registry, interner, fmt)?;
                write!(w, "{}", fmt.lambda(interner.resolve(*variable), &b))
            }

            LogicExpr::App { function, argument } => {
                write!(w, "(")?;
                function.write_logic(w, registry, interner, fmt)?;
                write!(w, ")(")?;
                argument.write_logic(w, registry, interner, fmt)?;
                write!(w, ")")
            }

            LogicExpr::Intensional { operator, content } => {
                write!(w, "{}[", fmt.sanitize(&registry.get_symbol(*operator, interner)))?;
                content.write_logic(w, registry, interner, fmt)?;
                write!(w, "]")
            }

            LogicExpr::Event { predicate, adverbs } => {
                let mut pred_str = String::new();
                predicate.write_logic(&mut pred_str, registry, interner, fmt)?;
                let adverb_preds: Vec<String> = adverbs
                    .iter()
                    .map(|a| format!("{}(e)", fmt.sanitize(&registry.get_symbol(*a, interner))))
                    .collect();
                write!(w, "{}", fmt.event_quantifier(&pred_str, &adverb_preds))
            }

            LogicExpr::NeoEvent(data) => {
                use crate::ast::{QuantifierKind, ThematicRole};

                if fmt.use_simple_events() {
                    write!(w, "{}", registry.get_symbol_full(data.verb, interner))?;
                    write!(w, "(")?;
                    let mut first = true;
                    for (role, term) in data.roles.iter() {
                        // Include core thematic roles in SimpleFOL output
                        if matches!(role, ThematicRole::Agent | ThematicRole::Patient | ThematicRole::Theme | ThematicRole::Goal | ThematicRole::Location) {
                            if !first {
                                write!(w, ", ")?;
                            }
                            first = false;
                            term.write_to_full(w, registry, interner)?;
                        }
                    }
                    write!(w, ")")
                } else {
                    let e = interner.resolve(data.event_var);
                    let mut body = String::new();

                    // Get world argument suffix if Kripke format
                    let world_suffix = if fmt.include_world_arguments() {
                        data.world.map(|w| format!(", {}", interner.resolve(w))).unwrap_or_default()
                    } else {
                        String::new()
                    };

                    write_capitalized(&mut body, interner.resolve(data.verb))?;
                    write!(body, "({}{})", e, world_suffix)?;
                    for (role, term) in data.roles.iter() {
                        let role_str = match role {
                            ThematicRole::Agent => "Agent",
                            ThematicRole::Patient => "Patient",
                            ThematicRole::Theme => "Theme",
                            ThematicRole::Recipient => "Recipient",
                            ThematicRole::Goal => "Goal",
                            ThematicRole::Source => "Source",
                            ThematicRole::Instrument => "Instrument",
                            ThematicRole::Location => "Location",
                            ThematicRole::Time => "Time",
                            ThematicRole::Manner => "Manner",
                        };
                        write!(body, " {} {}({}, ", fmt.and(), role_str, e)?;
                        if fmt.use_full_names() {
                            term.write_to_full(&mut body, registry, interner)?;
                        } else {
                            term.write_to(&mut body, registry, interner)?;
                        }
                        write!(body, "{})", world_suffix)?;
                    }
                    for mod_sym in data.modifiers.iter() {
                        write!(body, " {} ", fmt.and())?;
                        write_capitalized(&mut body, interner.resolve(*mod_sym))?;
                        write!(body, "({}{})", e, world_suffix)?;
                    }
                    if data.suppress_existential {
                        // Event var will be bound by outer ∀ from DRS (generic conditionals)
                        write!(w, "{}", body)
                    } else {
                        // Normal case: emit ∃e(...)
                        write!(w, "{}", fmt.quantifier(&QuantifierKind::Existential, e, &body))
                    }
                }
            }

            LogicExpr::Imperative { action } => {
                write!(w, "!")?;
                action.write_logic(w, registry, interner, fmt)
            }

            LogicExpr::SpeechAct { performer, act_type, content } => {
                write!(w, "SpeechAct({}, {}, ", interner.resolve(*act_type), fmt.sanitize(&registry.get_symbol(*performer, interner)))?;
                content.write_logic(w, registry, interner, fmt)?;
                write!(w, ")")
            }

            LogicExpr::Counterfactual { antecedent, consequent } => {
                let mut a = String::new();
                let mut c = String::new();
                antecedent.write_logic(&mut a, registry, interner, fmt)?;
                consequent.write_logic(&mut c, registry, interner, fmt)?;
                write!(w, "{}", fmt.counterfactual(&a, &c))
            }

            LogicExpr::Causal { effect, cause } => {
                write!(w, "Cause(")?;
                cause.write_logic(w, registry, interner, fmt)?;
                write!(w, ", ")?;
                effect.write_logic(w, registry, interner, fmt)?;
                write!(w, ")")
            }

            LogicExpr::Comparative { adjective, subject, object, difference } => {
                let adj = interner.resolve(*adjective);
                let mut subj_buf = String::new();
                if fmt.preserve_case() {
                    subject.write_to_raw(&mut subj_buf, interner)?;
                } else {
                    subject.write_to(&mut subj_buf, registry, interner)?;
                }
                let mut obj_buf = String::new();
                if fmt.preserve_case() {
                    object.write_to_raw(&mut obj_buf, interner)?;
                } else {
                    object.write_to(&mut obj_buf, registry, interner)?;
                }
                let diff_str = if let Some(diff) = difference {
                    let mut diff_buf = String::new();
                    if fmt.preserve_case() {
                        diff.write_to_raw(&mut diff_buf, interner)?;
                    } else {
                        diff.write_to(&mut diff_buf, registry, interner)?;
                    }
                    Some(diff_buf)
                } else {
                    None
                };
                fmt.write_comparative(w, adj, &subj_buf, &obj_buf, diff_str.as_deref())
            }

            LogicExpr::Superlative { adjective, subject, domain } => {
                let mut s = String::new();
                subject.write_to(&mut s, registry, interner)?;
                let mut d = String::new();
                write_capitalized(&mut d, interner.resolve(*domain))?;
                let comp = format!("{}er", interner.resolve(*adjective));
                write!(w, "{}", fmt.superlative(&comp, &d, &s))
            }

            LogicExpr::Scopal { operator, body } => {
                write!(w, "{}(", interner.resolve(*operator))?;
                body.write_logic(w, registry, interner, fmt)?;
                write!(w, ")")
            }

            LogicExpr::TemporalAnchor { anchor, body } => {
                write!(w, "{}(", interner.resolve(*anchor))?;
                body.write_logic(w, registry, interner, fmt)?;
                write!(w, ")")
            }

            LogicExpr::Control { verb, subject, object, infinitive } => {
                write!(w, "{}(", fmt.sanitize(&registry.get_symbol(*verb, interner)))?;
                subject.write_to(w, registry, interner)?;
                if let Some(obj) = object {
                    write!(w, ", ")?;
                    obj.write_to(w, registry, interner)?;
                }
                write!(w, ", ")?;
                infinitive.write_logic(w, registry, interner, fmt)?;
                write!(w, ")")
            }

            LogicExpr::Presupposition { assertion, presupposition } => {
                assertion.write_logic(w, registry, interner, fmt)?;
                write!(w, " [Presup: ")?;
                presupposition.write_logic(w, registry, interner, fmt)?;
                write!(w, "]")
            }

            LogicExpr::Focus { kind, focused, scope } => {
                use crate::token::FocusKind;
                let prefix = match kind {
                    FocusKind::Only => "Only",
                    FocusKind::Even => "Even",
                    FocusKind::Just => "Just",
                };
                write!(w, "{}(", prefix)?;
                focused.write_to(w, registry, interner)?;
                write!(w, ", ")?;
                scope.write_logic(w, registry, interner, fmt)?;
                write!(w, ")")
            }

            LogicExpr::Distributive { predicate } => {
                write!(w, "*")?;
                predicate.write_logic(w, registry, interner, fmt)
            }

            LogicExpr::GroupQuantifier { group_var, count, member_var, restriction, body } => {
                let g = interner.resolve(*group_var);
                let x = interner.resolve(*member_var);

                // ∃g(Group(g) ∧ Count(g,n) ∧ ∀x(Member(x,g) → restriction) ∧ body)
                write!(w, "{}{}(Group({}) {} Count({}, {}) {} {}{}(Member({}, {}) {} ",
                    fmt.existential(), g, g,
                    fmt.and(), g, count,
                    fmt.and(), fmt.universal(), x, x, g, fmt.implies())?;

                restriction.write_logic(w, registry, interner, fmt)?;

                write!(w, ") {} ", fmt.and())?;

                body.write_logic(w, registry, interner, fmt)?;

                write!(w, ")")
            }
        }
    }

    pub fn transpile_with<F: LogicFormatter>(
        &self,
        registry: &mut SymbolRegistry,
        interner: &Interner,
        fmt: &F,
    ) -> String {
        let mut buf = String::new();
        let _ = self.write_logic(&mut buf, registry, interner, fmt);
        buf
    }

    pub fn transpile(
        &self,
        registry: &mut SymbolRegistry,
        interner: &Interner,
        format: OutputFormat,
    ) -> String {
        match format {
            OutputFormat::Unicode => self.transpile_with(registry, interner, &UnicodeFormatter),
            OutputFormat::LaTeX => self.transpile_with(registry, interner, &LatexFormatter),
            OutputFormat::SimpleFOL => self.transpile_with(registry, interner, &SimpleFOLFormatter),
            OutputFormat::Kripke => self.transpile_with(registry, interner, &KripkeFormatter),
        }
    }

    pub fn transpile_ctx<F: LogicFormatter>(
        &self,
        ctx: &mut TranspileContext<'_>,
        fmt: &F,
    ) -> String {
        self.transpile_with(ctx.registry, ctx.interner, fmt)
    }

    pub fn transpile_ctx_unicode(&self, ctx: &mut TranspileContext<'_>) -> String {
        self.transpile_ctx(ctx, &UnicodeFormatter)
    }

    pub fn transpile_ctx_latex(&self, ctx: &mut TranspileContext<'_>) -> String {
        self.transpile_ctx(ctx, &LatexFormatter)
    }
}

```

---

use std::fmt::Write;

use crate::ast::{AspectOperator, ModalDomain, QuantifierKind, TemporalOperator, Term, VoiceOperator};
use crate::intern::Interner;
use crate::registry::SymbolRegistry;
use crate::token::TokenType;

pub trait LogicFormatter {
    // Quantifiers
    fn quantifier(&self, kind: &QuantifierKind, var: &str, body: &str) -> String {
        let sym = match kind {
            QuantifierKind::Universal => self.universal(),
            QuantifierKind::Existential => self.existential(),
            QuantifierKind::Most => "MOST ".to_string(),
            QuantifierKind::Few => "FEW ".to_string(),
            QuantifierKind::Many => "MANY ".to_string(),
            QuantifierKind::Cardinal(n) => self.cardinal(*n),
            QuantifierKind::AtLeast(n) => self.at_least(*n),
            QuantifierKind::AtMost(n) => self.at_most(*n),
            QuantifierKind::Generic => "Gen ".to_string(),
        };
        format!("{}{}({})", sym, var, body)
    }

    fn universal(&self) -> String;
    fn existential(&self) -> String;
    fn cardinal(&self, n: u32) -> String;
    fn at_least(&self, n: u32) -> String;
    fn at_most(&self, n: u32) -> String;

    // Binary operators
    fn binary_op(&self, op: &TokenType, left: &str, right: &str) -> String {
        match op {
            TokenType::And => format!("({} {} {})", left, self.and(), right),
            TokenType::Or => format!("({} {} {})", left, self.or(), right),
            TokenType::If => format!("({} {} {})", left, self.implies(), right),
            TokenType::Iff => format!("({} {} {})", left, self.iff(), right),
            _ => String::new(),
        }
    }

    fn and(&self) -> &'static str;
    fn or(&self) -> &'static str;
    fn implies(&self) -> &'static str;
    fn iff(&self) -> &'static str;

    // Unary operators
    fn unary_op(&self, op: &TokenType, operand: &str) -> String {
        match op {
            TokenType::Not => format!("{}{}", self.not(), operand),
            _ => String::new(),
        }
    }

    fn not(&self) -> &'static str;

    // Identity operator (used in Identity expressions)
    fn identity(&self) -> &'static str {
        " = "
    }

    // Whether to wrap identity expressions in parentheses
    fn wrap_identity(&self) -> bool {
        false
    }

    // Modal operators
    fn modal(&self, domain: ModalDomain, force: f32, body: &str) -> String {
        let sym = match domain {
            ModalDomain::Alethic if force > 0.0 && force <= 0.5 => self.possibility(),
            ModalDomain::Alethic => self.necessity(),
            ModalDomain::Deontic if force <= 0.5 => "P",
            ModalDomain::Deontic => "O",
        };
        format!("{}_{{{:.1}}} {}", sym, force, body)
    }

    fn necessity(&self) -> &'static str;
    fn possibility(&self) -> &'static str;

    // Temporal operators
    fn temporal(&self, op: &TemporalOperator, body: &str) -> String {
        let sym = match op {
            TemporalOperator::Past => self.past(),
            TemporalOperator::Future => self.future(),
        };
        format!("{}({})", sym, body)
    }

    fn past(&self) -> &'static str;
    fn future(&self) -> &'static str;

    // Aspectual operators
    fn aspectual(&self, op: &AspectOperator, body: &str) -> String {
        let sym = match op {
            AspectOperator::Progressive => self.progressive(),
            AspectOperator::Perfect => self.perfect(),
            AspectOperator::Habitual => self.habitual(),
            AspectOperator::Iterative => self.iterative(),
        };
        format!("{}({})", sym, body)
    }

    fn progressive(&self) -> &'static str;
    fn perfect(&self) -> &'static str;
    fn habitual(&self) -> &'static str;
    fn iterative(&self) -> &'static str;

    // Voice operators
    fn voice(&self, op: &VoiceOperator, body: &str) -> String {
        let sym = match op {
            VoiceOperator::Passive => self.passive(),
        };
        format!("{}({})", sym, body)
    }

    fn passive(&self) -> &'static str;

    // Lambda
    fn lambda(&self, var: &str, body: &str) -> String;

    // Counterfactual
    fn counterfactual(&self, antecedent: &str, consequent: &str) -> String;

    // Superlative expansion
    fn superlative(&self, comp: &str, domain: &str, subject: &str) -> String;

    // Event quantification (uses existential + and)
    fn event_quantifier(&self, pred: &str, adverbs: &[String]) -> String {
        if adverbs.is_empty() {
            format!("{}e({})", self.existential(), pred)
        } else {
            let conj = self.and();
            format!(
                "{}e({} {} {})",
                self.existential(),
                pred,
                conj,
                adverbs.join(&format!(" {} ", conj))
            )
        }
    }

    // Categorical (legacy)
    fn categorical_all(&self) -> &'static str;
    fn categorical_no(&self) -> &'static str;
    fn categorical_some(&self) -> &'static str;
    fn categorical_not(&self) -> &'static str;

    // Sanitization hook for LaTeX special characters
    fn sanitize(&self, s: &str) -> String {
        s.to_string()
    }

    // Whether to use simple predicate form instead of event semantics
    fn use_simple_events(&self) -> bool {
        false
    }

    // Whether to use full predicate names instead of abbreviations
    fn use_full_names(&self) -> bool {
        false
    }

    // Whether to preserve original case (for code generation)
    fn preserve_case(&self) -> bool {
        false
    }

    // Whether to include world arguments in predicates (for Kripke semantics)
    fn include_world_arguments(&self) -> bool {
        false
    }

    /// Hook for customizing how comparatives are rendered.
    /// Default implementation uses standard logic notation: tallER(subj, obj) or tallER(subj, obj, diff)
    fn write_comparative<W: Write>(
        &self,
        w: &mut W,
        adjective: &str,
        subject: &str,
        object: &str,
        difference: Option<&str>,
    ) -> std::fmt::Result {
        if let Some(diff) = difference {
            write!(w, "{}er({}, {}, {})", adjective, subject, object, diff)
        } else {
            write!(w, "{}er({}, {})", adjective, subject, object)
        }
    }

    /// Hook for customizing how predicates are rendered.
    /// Default implementation uses standard logic notation: Name(Arg1, Arg2)
    fn write_predicate<W: Write>(
        &self,
        w: &mut W,
        name: &str,
        args: &[Term],
        registry: &mut SymbolRegistry,
        interner: &Interner,
    ) -> std::fmt::Result {
        write!(w, "{}(", self.sanitize(name))?;
        for (i, arg) in args.iter().enumerate() {
            if i > 0 {
                write!(w, ", ")?;
            }
            if self.use_full_names() {
                arg.write_to_full(w, registry, interner)?;
            } else {
                arg.write_to(w, registry, interner)?;
            }
        }
        write!(w, ")")
    }
}

pub struct UnicodeFormatter;

impl LogicFormatter for UnicodeFormatter {
    fn universal(&self) -> String { "∀".to_string() }
    fn existential(&self) -> String { "∃".to_string() }
    fn cardinal(&self, n: u32) -> String { format!("∃={}.", n) }
    fn at_least(&self, n: u32) -> String { format!("∃≥{}", n) }
    fn at_most(&self, n: u32) -> String { format!("∃≤{}", n) }

    fn and(&self) -> &'static str { "∧" }
    fn or(&self) -> &'static str { "∨" }
    fn implies(&self) -> &'static str { "→" }
    fn iff(&self) -> &'static str { "↔" }
    fn not(&self) -> &'static str { "¬" }

    fn necessity(&self) -> &'static str { "□" }
    fn possibility(&self) -> &'static str { "◇" }

    fn past(&self) -> &'static str { "P" }
    fn future(&self) -> &'static str { "F" }

    fn progressive(&self) -> &'static str { "Prog" }
    fn perfect(&self) -> &'static str { "Perf" }
    fn habitual(&self) -> &'static str { "HAB" }
    fn iterative(&self) -> &'static str { "ITER" }
    fn passive(&self) -> &'static str { "Pass" }

    fn lambda(&self, var: &str, body: &str) -> String {
        format!("λ{}.{}", var, body)
    }

    fn counterfactual(&self, antecedent: &str, consequent: &str) -> String {
        format!("({} □→ {})", antecedent, consequent)
    }

    fn superlative(&self, comp: &str, domain: &str, subject: &str) -> String {
        format!(
            "∀x(({}(x) ∧ x ≠ {}) → {}({}, x))",
            domain, subject, comp, subject
        )
    }

    fn categorical_all(&self) -> &'static str { "∀" }
    fn categorical_no(&self) -> &'static str { "∀¬" }
    fn categorical_some(&self) -> &'static str { "∃" }
    fn categorical_not(&self) -> &'static str { "¬" }

    // Use full predicate names (e.g., "Wet" not "W")
    fn use_full_names(&self) -> bool { true }
}

pub struct LatexFormatter;

impl LogicFormatter for LatexFormatter {
    fn universal(&self) -> String { "\\forall ".to_string() }
    fn existential(&self) -> String { "\\exists ".to_string() }
    fn cardinal(&self, n: u32) -> String { format!("\\exists_{{={}}} ", n) }
    fn at_least(&self, n: u32) -> String { format!("\\exists_{{\\geq {}}} ", n) }
    fn at_most(&self, n: u32) -> String { format!("\\exists_{{\\leq {}}} ", n) }

    fn and(&self) -> &'static str { "\\cdot" }
    fn or(&self) -> &'static str { "\\vee" }
    fn implies(&self) -> &'static str { "\\supset" }
    fn iff(&self) -> &'static str { "\\equiv" }
    fn not(&self) -> &'static str { "\\sim " }

    fn necessity(&self) -> &'static str { "\\Box" }
    fn possibility(&self) -> &'static str { "\\Diamond" }

    fn past(&self) -> &'static str { "\\mathsf{P}" }
    fn future(&self) -> &'static str { "\\mathsf{F}" }

    fn progressive(&self) -> &'static str { "\\mathsf{Prog}" }
    fn perfect(&self) -> &'static str { "\\mathsf{Perf}" }
    fn habitual(&self) -> &'static str { "\\mathsf{HAB}" }
    fn iterative(&self) -> &'static str { "\\mathsf{ITER}" }
    fn passive(&self) -> &'static str { "\\mathsf{Pass}" }

    fn lambda(&self, var: &str, body: &str) -> String {
        format!("\\lambda {}.{}", var, body)
    }

    fn counterfactual(&self, antecedent: &str, consequent: &str) -> String {
        format!("({} \\boxright {})", antecedent, consequent)
    }

    fn superlative(&self, comp: &str, domain: &str, subject: &str) -> String {
        format!(
            "\\forall x(({}(x) \\land x \\neq {}) \\supset {}({}, x))",
            domain, subject, comp, subject
        )
    }

    fn categorical_all(&self) -> &'static str { "All" }
    fn categorical_no(&self) -> &'static str { "No" }
    fn categorical_some(&self) -> &'static str { "Some" }
    fn categorical_not(&self) -> &'static str { "not" }

    fn sanitize(&self, s: &str) -> String {
        s.replace('_', r"\_")
            .replace('^', r"\^{}")
            .replace('&', r"\&")
            .replace('%', r"\%")
            .replace('#', r"\#")
            .replace('$', r"\$")
    }
}

pub struct SimpleFOLFormatter;

impl LogicFormatter for SimpleFOLFormatter {
    fn universal(&self) -> String { "∀".to_string() }
    fn existential(&self) -> String { "∃".to_string() }
    fn cardinal(&self, n: u32) -> String { format!("∃={}", n) }
    fn at_least(&self, n: u32) -> String { format!("∃≥{}", n) }
    fn at_most(&self, n: u32) -> String { format!("∃≤{}", n) }

    fn and(&self) -> &'static str { "∧" }
    fn or(&self) -> &'static str { "∨" }
    fn implies(&self) -> &'static str { "→" }
    fn iff(&self) -> &'static str { "↔" }
    fn not(&self) -> &'static str { "¬" }

    fn necessity(&self) -> &'static str { "□" }
    fn possibility(&self) -> &'static str { "◇" }

    fn past(&self) -> &'static str { "Past" }
    fn future(&self) -> &'static str { "Future" }

    fn progressive(&self) -> &'static str { "" }
    fn perfect(&self) -> &'static str { "" }
    fn habitual(&self) -> &'static str { "" }
    fn iterative(&self) -> &'static str { "" }
    fn passive(&self) -> &'static str { "" }

    fn lambda(&self, var: &str, body: &str) -> String {
        format!("λ{}.{}", var, body)
    }

    fn counterfactual(&self, antecedent: &str, consequent: &str) -> String {
        format!("({} □→ {})", antecedent, consequent)
    }

    fn superlative(&self, comp: &str, domain: &str, subject: &str) -> String {
        format!(
            "∀x(({}(x) ∧ x ≠ {}) → {}({}, x))",
            domain, subject, comp, subject
        )
    }

    fn categorical_all(&self) -> &'static str { "∀" }
    fn categorical_no(&self) -> &'static str { "∀¬" }
    fn categorical_some(&self) -> &'static str { "∃" }
    fn categorical_not(&self) -> &'static str { "¬" }

    fn modal(&self, _domain: ModalDomain, _force: f32, body: &str) -> String {
        body.to_string()
    }

    fn aspectual(&self, _op: &AspectOperator, body: &str) -> String {
        body.to_string()
    }

    fn use_simple_events(&self) -> bool {
        true
    }

    fn use_full_names(&self) -> bool {
        true
    }
}

/// Formatter for Kripke lowered output with explicit world arguments.
/// Modals are already lowered to quantifiers; this formatter just renders
/// the result with world arguments appended to predicates.
pub struct KripkeFormatter;

impl LogicFormatter for KripkeFormatter {
    fn universal(&self) -> String { "ForAll ".to_string() }
    fn existential(&self) -> String { "Exists ".to_string() }
    fn cardinal(&self, n: u32) -> String { format!("Exists={} ", n) }
    fn at_least(&self, n: u32) -> String { format!("Exists>={} ", n) }
    fn at_most(&self, n: u32) -> String { format!("Exists<={} ", n) }

    fn and(&self) -> &'static str { " And " }
    fn or(&self) -> &'static str { " Or " }
    fn implies(&self) -> &'static str { " Implies " }
    fn iff(&self) -> &'static str { " Iff " }
    fn not(&self) -> &'static str { "Not " }

    fn necessity(&self) -> &'static str { "Box" }
    fn possibility(&self) -> &'static str { "Diamond" }

    fn past(&self) -> &'static str { "Past" }
    fn future(&self) -> &'static str { "Future" }

    fn progressive(&self) -> &'static str { "Prog" }
    fn perfect(&self) -> &'static str { "Perf" }
    fn habitual(&self) -> &'static str { "HAB" }
    fn iterative(&self) -> &'static str { "ITER" }
    fn passive(&self) -> &'static str { "Pass" }

    fn lambda(&self, var: &str, body: &str) -> String {
        format!("Lambda {}.{}", var, body)
    }

    fn counterfactual(&self, antecedent: &str, consequent: &str) -> String {
        format!("({} Counterfactual {})", antecedent, consequent)
    }

    fn superlative(&self, comp: &str, domain: &str, subject: &str) -> String {
        format!(
            "ForAll x(({}(x) And x != {}) Implies {}({}, x))",
            domain, subject, comp, subject
        )
    }

    fn categorical_all(&self) -> &'static str { "ForAll" }
    fn categorical_no(&self) -> &'static str { "ForAll Not" }
    fn categorical_some(&self) -> &'static str { "Exists" }
    fn categorical_not(&self) -> &'static str { "Not" }

    fn modal(&self, _domain: ModalDomain, _force: f32, body: &str) -> String {
        // Modals already lowered to quantifiers - just pass through
        body.to_string()
    }

    fn use_full_names(&self) -> bool { true }

    fn include_world_arguments(&self) -> bool { true }
}

/// Formatter that produces Rust boolean expressions for runtime assertions.
/// Used by codegen to convert LogicExpr into debug_assert!() compatible code.
pub struct RustFormatter;

impl LogicFormatter for RustFormatter {
    // Operators map to Rust boolean operators
    fn and(&self) -> &'static str { "&&" }
    fn or(&self) -> &'static str { "||" }
    fn not(&self) -> &'static str { "!" }
    fn implies(&self) -> &'static str { "||" } // Handled via binary_op override
    fn iff(&self) -> &'static str { "==" }
    fn identity(&self) -> &'static str { " == " } // Rust equality
    fn wrap_identity(&self) -> bool { true } // Wrap in parens for valid Rust

    // Use full variable names, not abbreviations
    fn use_full_names(&self) -> bool { true }
    fn preserve_case(&self) -> bool { true } // Keep original variable case

    // Quantifiers: runtime can't check universal quantification, emit comments
    fn universal(&self) -> String { "/* ∀ */".to_string() }
    fn existential(&self) -> String { "/* ∃ */".to_string() }
    fn cardinal(&self, n: u32) -> String { format!("/* ∃={} */", n) }
    fn at_least(&self, n: u32) -> String { format!("/* ∃≥{} */", n) }
    fn at_most(&self, n: u32) -> String { format!("/* ∃≤{} */", n) }

    // Modal/Temporal operators are stripped for runtime (not checkable)
    fn necessity(&self) -> &'static str { "" }
    fn possibility(&self) -> &'static str { "" }
    fn past(&self) -> &'static str { "" }
    fn future(&self) -> &'static str { "" }
    fn progressive(&self) -> &'static str { "" }
    fn perfect(&self) -> &'static str { "" }
    fn habitual(&self) -> &'static str { "" }
    fn iterative(&self) -> &'static str { "" }
    fn passive(&self) -> &'static str { "" }
    fn categorical_all(&self) -> &'static str { "" }
    fn categorical_no(&self) -> &'static str { "" }
    fn categorical_some(&self) -> &'static str { "" }
    fn categorical_not(&self) -> &'static str { "" }

    fn lambda(&self, var: &str, body: &str) -> String {
        format!("|{}| {{ {} }}", var, body)
    }

    fn counterfactual(&self, a: &str, c: &str) -> String {
        format!("/* if {} then {} */", a, c)
    }

    fn superlative(&self, _: &str, _: &str, _: &str) -> String {
        "/* superlative */".to_string()
    }

    // Override comparative for Rust: map adjectives to comparison operators
    fn write_comparative<W: Write>(
        &self,
        w: &mut W,
        adjective: &str,
        subject: &str,
        object: &str,
        _difference: Option<&str>,
    ) -> std::fmt::Result {
        let adj_lower = adjective.to_lowercase();
        match adj_lower.as_str() {
            "great" | "big" | "large" | "tall" | "old" | "high" | "more" | "greater" => {
                write!(w, "({} > {})", subject, object)
            }
            "small" | "little" | "short" | "young" | "low" | "less" | "fewer" => {
                write!(w, "({} < {})", subject, object)
            }
            _ => write!(w, "({} > {})", subject, object) // default to greater-than
        }
    }

    // Override unary_op to wrap in parens for valid Rust
    fn unary_op(&self, op: &TokenType, operand: &str) -> String {
        match op {
            TokenType::Not => format!("(!{})", operand),
            _ => format!("/* unknown unary */({})", operand),
        }
    }

    // Override binary_op for implication desugaring: A → B = !A || B
    fn binary_op(&self, op: &TokenType, left: &str, right: &str) -> String {
        match op {
            TokenType::If | TokenType::Then => format!("(!({}) || ({}))", left, right),
            TokenType::And => format!("({} && {})", left, right),
            TokenType::Or => format!("({} || {})", left, right),
            TokenType::Iff => format!("({} == {})", left, right),
            _ => "/* unknown op */".to_string(),
        }
    }

    // Core predicate mapping: semantic interpretation of predicates to Rust operators
    fn write_predicate<W: Write>(
        &self,
        w: &mut W,
        name: &str,
        args: &[Term],
        _registry: &mut SymbolRegistry,
        interner: &Interner,
    ) -> std::fmt::Result {
        // Helper to render a term at given index to a string, preserving original case
        let render = |idx: usize| -> String {
            let mut buf = String::new();
            if let Some(arg) = args.get(idx) {
                let _ = arg.write_to_raw(&mut buf, interner);
            }
            buf
        };

        match name.to_lowercase().as_str() {
            // Comparisons
            "greater" if args.len() == 2 => write!(w, "({} > {})", render(0), render(1)),
            "less" if args.len() == 2 => write!(w, "({} < {})", render(0), render(1)),
            "equal" | "equals" if args.len() == 2 => write!(w, "({} == {})", render(0), render(1)),
            "notequal" | "not_equal" if args.len() == 2 => write!(w, "({} != {})", render(0), render(1)),
            "greaterequal" | "atleast" | "at_least" if args.len() == 2 => write!(w, "({} >= {})", render(0), render(1)),
            "lessequal" | "atmost" | "at_most" if args.len() == 2 => write!(w, "({} <= {})", render(0), render(1)),

            // Unary checks
            "positive" if args.len() == 1 => write!(w, "({} > 0)", render(0)),
            "negative" if args.len() == 1 => write!(w, "({} < 0)", render(0)),
            "zero" if args.len() == 1 => write!(w, "({} == 0)", render(0)),
            "empty" if args.len() == 1 => write!(w, "{}.is_empty()", render(0)),

            // Collection membership
            "in" if args.len() == 2 => write!(w, "{}.contains(&{})", render(1), render(0)),
            "contains" if args.len() == 2 => write!(w, "{}.contains(&{})", render(0), render(1)),

            // Fallback: method call for 1 arg, function call for N args
            _ if args.len() == 1 => write!(w, "{}.is_{}()", render(0), name.to_lowercase()),
            _ => {
                write!(w, "{}(", name.to_lowercase())?;
                for i in 0..args.len() {
                    if i > 0 { write!(w, ", ")?; }
                    write!(w, "{}", render(i))?;
                }
                write!(w, ")")
            }
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn unicode_binary_operators() {
        let f = UnicodeFormatter;
        assert_eq!(f.binary_op(&TokenType::And, "P", "Q"), "(P ∧ Q)");
        assert_eq!(f.binary_op(&TokenType::Or, "P", "Q"), "(P ∨ Q)");
        assert_eq!(f.binary_op(&TokenType::If, "P", "Q"), "(P → Q)");
        assert_eq!(f.binary_op(&TokenType::Iff, "P", "Q"), "(P ↔ Q)");
    }

    #[test]
    fn latex_binary_operators() {
        let f = LatexFormatter;
        assert_eq!(f.binary_op(&TokenType::And, "P", "Q"), r"(P \cdot Q)");
        assert_eq!(f.binary_op(&TokenType::Or, "P", "Q"), r"(P \vee Q)");
        assert_eq!(f.binary_op(&TokenType::If, "P", "Q"), r"(P \supset Q)");
        assert_eq!(f.binary_op(&TokenType::Iff, "P", "Q"), r"(P \equiv Q)");
    }

    #[test]
    fn unicode_quantifiers() {
        let f = UnicodeFormatter;
        assert_eq!(f.quantifier(&QuantifierKind::Universal, "x", "P(x)"), "∀x(P(x))");
        assert_eq!(f.quantifier(&QuantifierKind::Existential, "x", "P(x)"), "∃x(P(x))");
        assert_eq!(f.quantifier(&QuantifierKind::Cardinal(3), "x", "P(x)"), "∃=3.x(P(x))");
    }

    #[test]
    fn latex_quantifiers() {
        let f = LatexFormatter;
        assert_eq!(f.quantifier(&QuantifierKind::Universal, "x", "P(x)"), "\\forall x(P(x))");
        assert_eq!(f.quantifier(&QuantifierKind::Existential, "x", "P(x)"), "\\exists x(P(x))");
    }

    #[test]
    fn latex_sanitization() {
        let f = LatexFormatter;
        assert_eq!(f.sanitize("foo_bar"), r"foo\_bar");
        assert_eq!(f.sanitize("x^2"), r"x\^{}2");
        assert_eq!(f.sanitize("a&b"), r"a\&b");
    }

    #[test]
    fn unicode_no_sanitization() {
        let f = UnicodeFormatter;
        assert_eq!(f.sanitize("foo_bar"), "foo_bar");
    }

    #[test]
    fn unicode_lambda() {
        let f = UnicodeFormatter;
        assert_eq!(f.lambda("x", "P(x)"), "λx.P(x)");
    }

    #[test]
    fn latex_lambda() {
        let f = LatexFormatter;
        assert_eq!(f.lambda("x", "P(x)"), "\\lambda x.P(x)");
    }

    #[test]
    fn unicode_counterfactual() {
        let f = UnicodeFormatter;
        assert_eq!(f.counterfactual("P", "Q"), "(P □→ Q)");
    }

    #[test]
    fn latex_counterfactual() {
        let f = LatexFormatter;
        assert_eq!(f.counterfactual("P", "Q"), r"(P \boxright Q)");
    }

    // RustFormatter tests
    #[test]
    fn rust_binary_operators() {
        let f = RustFormatter;
        assert_eq!(f.binary_op(&TokenType::And, "P", "Q"), "(P && Q)");
        assert_eq!(f.binary_op(&TokenType::Or, "P", "Q"), "(P || Q)");
        assert_eq!(f.binary_op(&TokenType::Iff, "P", "Q"), "(P == Q)");
    }

    #[test]
    fn rust_implication_desugaring() {
        let f = RustFormatter;
        // A → B desugars to !A || B
        assert_eq!(f.binary_op(&TokenType::If, "P", "Q"), "(!(P) || (Q))");
    }

    #[test]
    fn rust_lambda() {
        let f = RustFormatter;
        assert_eq!(f.lambda("x", "x > 0"), "|x| { x > 0 }");
    }

    #[test]
    fn rust_quantifiers_as_comments() {
        let f = RustFormatter;
        assert_eq!(f.universal(), "/* ∀ */");
        assert_eq!(f.existential(), "/* ∃ */");
    }
}

```

---

## Code Generation

Converting Imperative AST to Rust.
use std::collections::{HashMap, HashSet};
use std::fmt::Write;

use crate::analysis::registry::{FieldDef, FieldType, TypeDef, TypeRegistry, VariantDef};
use crate::analysis::policy::{PolicyRegistry, PredicateDef, CapabilityDef, PolicyCondition};
use crate::ast::logic::{LogicExpr, NumberKind, Term};
use crate::ast::stmt::{BinaryOpKind, Expr, Literal, ReadSource, Stmt, TypeExpr};
use crate::formatter::RustFormatter;
use crate::intern::{Interner, Symbol};
use crate::registry::SymbolRegistry;

// =============================================================================
// Phase 43C: Refinement Type Enforcement
// =============================================================================

/// Tracks refinement type constraints across scopes for mutation enforcement.
/// When a variable with a refinement type is defined, we register its constraint.
/// When that variable is mutated via `Set`, we re-emit the assertion.
/// Phase 50: Also tracks variable types for capability Check resolution.
pub struct RefinementContext<'a> {
    /// Stack of scopes. Each scope maps variable Symbol to (bound_var, predicate).
    scopes: Vec<HashMap<Symbol, (Symbol, &'a LogicExpr<'a>)>>,
    /// Phase 50: Maps variable name Symbol to type name (for capability resolution)
    /// e.g., "doc" -> "Document" allows "Check that user can publish the document" to resolve to &doc
    variable_types: HashMap<Symbol, String>,
}

impl<'a> RefinementContext<'a> {
    pub fn new() -> Self {
        Self {
            scopes: vec![HashMap::new()],
            variable_types: HashMap::new(),
        }
    }

    fn push_scope(&mut self) {
        self.scopes.push(HashMap::new());
    }

    fn pop_scope(&mut self) {
        self.scopes.pop();
    }

    fn register(&mut self, var: Symbol, bound_var: Symbol, predicate: &'a LogicExpr<'a>) {
        if let Some(scope) = self.scopes.last_mut() {
            scope.insert(var, (bound_var, predicate));
        }
    }

    fn get_constraint(&self, var: Symbol) -> Option<(Symbol, &'a LogicExpr<'a>)> {
        for scope in self.scopes.iter().rev() {
            if let Some(entry) = scope.get(&var) {
                return Some(*entry);
            }
        }
        None
    }

    /// Phase 50: Register a variable with its type for capability resolution
    fn register_variable_type(&mut self, var: Symbol, type_name: String) {
        self.variable_types.insert(var, type_name);
    }

    /// Phase 50: Find a variable name by its type (for resolving "the document" to "doc")
    fn find_variable_by_type(&self, type_name: &str, interner: &Interner) -> Option<String> {
        let type_lower = type_name.to_lowercase();
        for (var_sym, var_type) in &self.variable_types {
            if var_type.to_lowercase() == type_lower {
                return Some(interner.resolve(*var_sym).to_string());
            }
        }
        None
    }
}

/// Emits a debug_assert for a refinement predicate, substituting the bound variable.
fn emit_refinement_check(
    var_name: &str,
    bound_var: Symbol,
    predicate: &LogicExpr,
    interner: &Interner,
    indent_str: &str,
    output: &mut String,
) {
    let assertion = codegen_assertion(predicate, interner);
    let bound = interner.resolve(bound_var);
    let check = if bound == var_name {
        assertion
    } else {
        replace_word(&assertion, bound, var_name)
    };
    writeln!(output, "{}debug_assert!({});", indent_str, check).unwrap();
}

/// Word-boundary replacement to substitute bound variable with actual variable.
fn replace_word(text: &str, from: &str, to: &str) -> String {
    let mut result = String::with_capacity(text.len());
    let mut word = String::new();
    for c in text.chars() {
        if c.is_alphanumeric() || c == '_' {
            word.push(c);
        } else {
            if !word.is_empty() {
                result.push_str(if word == from { to } else { &word });
                word.clear();
            }
            result.push(c);
        }
    }
    if !word.is_empty() {
        result.push_str(if word == from { to } else { &word });
    }
    result
}

// =============================================================================
// Phase 56: Mount+Sync Detection for Distributed<T>
// =============================================================================

/// Tracks which variables have Mount and/or Sync statements.
/// Used to detect when a variable needs Distributed<T> instead of separate wrappers.
#[derive(Debug, Default)]
pub struct VariableCapabilities {
    /// Variable has a Mount statement
    mounted: bool,
    /// Variable has a Sync statement
    synced: bool,
    /// Path expression for Mount (as generated code string)
    mount_path: Option<String>,
    /// Topic expression for Sync (as generated code string)
    sync_topic: Option<String>,
}

/// Helper to create an empty VariableCapabilities map (for tests).
pub fn empty_var_caps() -> HashMap<Symbol, VariableCapabilities> {
    HashMap::new()
}

/// Pre-scan statements to detect variables that have both Mount and Sync.
/// Returns a map from variable Symbol to its capabilities.
fn analyze_variable_capabilities<'a>(
    stmts: &[Stmt<'a>],
    interner: &Interner,
) -> HashMap<Symbol, VariableCapabilities> {
    let mut caps: HashMap<Symbol, VariableCapabilities> = HashMap::new();
    let empty_synced = HashSet::new();

    for stmt in stmts {
        match stmt {
            Stmt::Mount { var, path } => {
                let entry = caps.entry(*var).or_default();
                entry.mounted = true;
                entry.mount_path = Some(codegen_expr(path, interner, &empty_synced));
            }
            Stmt::Sync { var, topic } => {
                let entry = caps.entry(*var).or_default();
                entry.synced = true;
                entry.sync_topic = Some(codegen_expr(topic, interner, &empty_synced));
            }
            // Recursively check nested blocks (Block<'a> is &[Stmt<'a>])
            Stmt::If { then_block, else_block, .. } => {
                let nested = analyze_variable_capabilities(then_block, interner);
                for (var, cap) in nested {
                    let entry = caps.entry(var).or_default();
                    if cap.mounted { entry.mounted = true; entry.mount_path = cap.mount_path; }
                    if cap.synced { entry.synced = true; entry.sync_topic = cap.sync_topic; }
                }
                if let Some(else_b) = else_block {
                    let nested = analyze_variable_capabilities(else_b, interner);
                    for (var, cap) in nested {
                        let entry = caps.entry(var).or_default();
                        if cap.mounted { entry.mounted = true; entry.mount_path = cap.mount_path; }
                        if cap.synced { entry.synced = true; entry.sync_topic = cap.sync_topic; }
                    }
                }
            }
            Stmt::While { body, .. } | Stmt::Repeat { body, .. } => {
                let nested = analyze_variable_capabilities(body, interner);
                for (var, cap) in nested {
                    let entry = caps.entry(var).or_default();
                    if cap.mounted { entry.mounted = true; entry.mount_path = cap.mount_path; }
                    if cap.synced { entry.synced = true; entry.sync_topic = cap.sync_topic; }
                }
            }
            _ => {}
        }
    }

    caps
}

/// Phase 51: Detect if any statements require async execution.
/// Returns true if the program needs #[tokio::main] async fn main().
fn requires_async(stmts: &[Stmt]) -> bool {
    stmts.iter().any(|s| requires_async_stmt(s))
}

fn requires_async_stmt(stmt: &Stmt) -> bool {
    match stmt {
        // Phase 9: Concurrent blocks use tokio::join!
        Stmt::Concurrent { tasks } => true,
        // Phase 51: Network operations and Sleep are async
        Stmt::Listen { .. } => true,
        Stmt::ConnectTo { .. } => true,
        Stmt::Sleep { .. } => true,
        // Phase 52: Sync is async (GossipSub subscription)
        Stmt::Sync { .. } => true,
        // Phase 53: Mount is async (VFS file operations)
        Stmt::Mount { .. } => true,
        // Phase 53: File I/O is async (VFS operations)
        Stmt::ReadFrom { source: ReadSource::File(_), .. } => true,
        Stmt::WriteFile { .. } => true,
        // Phase 54: Go-like concurrency is async
        Stmt::LaunchTask { .. } => true,
        Stmt::LaunchTaskWithHandle { .. } => true,
        Stmt::SendPipe { .. } => true,
        Stmt::ReceivePipe { .. } => true,
        Stmt::Select { .. } => true,
        // While and Repeat are now always async due to check_preemption()
        // (handled below in recursive check)
        // Recursively check nested blocks
        Stmt::If { then_block, else_block, .. } => {
            then_block.iter().any(|s| requires_async_stmt(s))
                || else_block.map_or(false, |b| b.iter().any(|s| requires_async_stmt(s)))
        }
        Stmt::While { body, .. } => body.iter().any(|s| requires_async_stmt(s)),
        Stmt::Repeat { body, .. } => body.iter().any(|s| requires_async_stmt(s)),
        Stmt::Zone { body, .. } => body.iter().any(|s| requires_async_stmt(s)),
        Stmt::Parallel { tasks } => tasks.iter().any(|s| requires_async_stmt(s)),
        Stmt::FunctionDef { body, .. } => body.iter().any(|s| requires_async_stmt(s)),
        _ => false,
    }
}

/// Phase 53: Detect if any statements require VFS (Virtual File System).
/// Returns true if the program uses file operations or persistent storage.
fn requires_vfs(stmts: &[Stmt]) -> bool {
    stmts.iter().any(|s| requires_vfs_stmt(s))
}

fn requires_vfs_stmt(stmt: &Stmt) -> bool {
    match stmt {
        // Phase 53: Mount uses VFS for persistent storage
        Stmt::Mount { .. } => true,
        // Phase 53: File I/O uses VFS
        Stmt::ReadFrom { source: ReadSource::File(_), .. } => true,
        Stmt::WriteFile { .. } => true,
        // Recursively check nested blocks
        Stmt::If { then_block, else_block, .. } => {
            then_block.iter().any(|s| requires_vfs_stmt(s))
                || else_block.map_or(false, |b| b.iter().any(|s| requires_vfs_stmt(s)))
        }
        Stmt::While { body, .. } => body.iter().any(|s| requires_vfs_stmt(s)),
        Stmt::Repeat { body, .. } => body.iter().any(|s| requires_vfs_stmt(s)),
        Stmt::Zone { body, .. } => body.iter().any(|s| requires_vfs_stmt(s)),
        Stmt::Concurrent { tasks } => tasks.iter().any(|s| requires_vfs_stmt(s)),
        Stmt::Parallel { tasks } => tasks.iter().any(|s| requires_vfs_stmt(s)),
        Stmt::FunctionDef { body, .. } => body.iter().any(|s| requires_vfs_stmt(s)),
        _ => false,
    }
}

/// Phase 49b: Extract root identifier from expression for mutability analysis.
/// Works with both simple identifiers and field accesses.
fn get_root_identifier_for_mutability(expr: &Expr) -> Option<Symbol> {
    match expr {
        Expr::Identifier(sym) => Some(*sym),
        Expr::FieldAccess { object, .. } => get_root_identifier_for_mutability(object),
        _ => None,
    }
}

/// Grand Challenge: Collect all variables that need `let mut` in Rust.
/// This includes:
/// - Variables that are targets of `Set` statements (reassignment)
/// - Variables that are targets of `Push` statements (mutation via push)
/// - Variables that are targets of `Pop` statements (mutation via pop)
fn collect_mutable_vars(stmts: &[Stmt]) -> HashSet<Symbol> {
    let mut targets = HashSet::new();
    for stmt in stmts {
        collect_mutable_vars_stmt(stmt, &mut targets);
    }
    targets
}

fn collect_mutable_vars_stmt(stmt: &Stmt, targets: &mut HashSet<Symbol>) {
    match stmt {
        Stmt::Set { target, .. } => {
            targets.insert(*target);
        }
        Stmt::Push { collection, .. } => {
            // If collection is an identifier, it needs to be mutable
            if let Expr::Identifier(sym) = collection {
                targets.insert(*sym);
            }
        }
        Stmt::Pop { collection, .. } => {
            // If collection is an identifier, it needs to be mutable
            if let Expr::Identifier(sym) = collection {
                targets.insert(*sym);
            }
        }
        Stmt::Add { collection, .. } => {
            // If collection is an identifier (Set) or field access, root needs to be mutable
            if let Some(sym) = get_root_identifier_for_mutability(collection) {
                targets.insert(sym);
            }
        }
        Stmt::Remove { collection, .. } => {
            // If collection is an identifier (Set) or field access, root needs to be mutable
            if let Some(sym) = get_root_identifier_for_mutability(collection) {
                targets.insert(sym);
            }
        }
        Stmt::SetIndex { collection, .. } => {
            // If collection is an identifier, it needs to be mutable
            if let Expr::Identifier(sym) = collection {
                targets.insert(*sym);
            }
        }
        Stmt::If { then_block, else_block, .. } => {
            for s in *then_block {
                collect_mutable_vars_stmt(s, targets);
            }
            if let Some(else_stmts) = else_block {
                for s in *else_stmts {
                    collect_mutable_vars_stmt(s, targets);
                }
            }
        }
        Stmt::While { body, .. } => {
            for s in *body {
                collect_mutable_vars_stmt(s, targets);
            }
        }
        Stmt::Repeat { body, .. } => {
            for s in *body {
                collect_mutable_vars_stmt(s, targets);
            }
        }
        Stmt::Zone { body, .. } => {
            for s in *body {
                collect_mutable_vars_stmt(s, targets);
            }
        }
        // Phase 9: Structured Concurrency blocks
        Stmt::Concurrent { tasks } | Stmt::Parallel { tasks } => {
            for s in *tasks {
                collect_mutable_vars_stmt(s, targets);
            }
        }
        // Phase 49b: CRDT operations require mutable access
        Stmt::IncreaseCrdt { object, .. } | Stmt::DecreaseCrdt { object, .. } => {
            // Extract root variable from field access (e.g., g.score -> g)
            if let Some(sym) = get_root_identifier_for_mutability(object) {
                targets.insert(sym);
            }
        }
        Stmt::AppendToSequence { sequence, .. } => {
            if let Some(sym) = get_root_identifier_for_mutability(sequence) {
                targets.insert(sym);
            }
        }
        Stmt::ResolveConflict { object, .. } => {
            if let Some(sym) = get_root_identifier_for_mutability(object) {
                targets.insert(sym);
            }
        }
        // Phase 49b: SetField on MVRegister/LWWRegister uses .set() which requires &mut self
        Stmt::SetField { object, .. } => {
            if let Some(sym) = get_root_identifier_for_mutability(object) {
                targets.insert(sym);
            }
        }
        _ => {}
    }
}

// =============================================================================
// Phase 50: Policy Method Generation
// =============================================================================

/// Generate impl blocks with predicate and capability methods for security policies.
fn codegen_policy_impls(policies: &PolicyRegistry, interner: &Interner) -> String {
    let mut output = String::new();

    // Collect all types that have policies
    let mut type_predicates: HashMap<Symbol, Vec<&PredicateDef>> = HashMap::new();
    let mut type_capabilities: HashMap<Symbol, Vec<&CapabilityDef>> = HashMap::new();

    for (type_sym, predicates) in policies.iter_predicates() {
        type_predicates.entry(*type_sym).or_insert_with(Vec::new).extend(predicates.iter());
    }

    for (type_sym, capabilities) in policies.iter_capabilities() {
        type_capabilities.entry(*type_sym).or_insert_with(Vec::new).extend(capabilities.iter());
    }

    // Get all types that have any policies
    let mut all_types: HashSet<Symbol> = HashSet::new();
    all_types.extend(type_predicates.keys().copied());
    all_types.extend(type_capabilities.keys().copied());

    // Generate impl block for each type
    for type_sym in all_types {
        let type_name = interner.resolve(type_sym);

        writeln!(output, "impl {} {{", type_name).unwrap();

        // Generate predicate methods
        if let Some(predicates) = type_predicates.get(&type_sym) {
            for pred in predicates {
                let pred_name = interner.resolve(pred.predicate_name).to_lowercase();
                writeln!(output, "    pub fn is_{}(&self) -> bool {{", pred_name).unwrap();
                let condition_code = codegen_policy_condition(&pred.condition, interner);
                writeln!(output, "        {}", condition_code).unwrap();
                writeln!(output, "    }}\n").unwrap();
            }
        }

        // Generate capability methods
        if let Some(capabilities) = type_capabilities.get(&type_sym) {
            for cap in capabilities {
                let action_name = interner.resolve(cap.action).to_lowercase();
                let object_type = interner.resolve(cap.object_type);
                let object_param = object_type.to_lowercase();

                writeln!(output, "    pub fn can_{}(&self, {}: &{}) -> bool {{",
                         action_name, object_param, object_type).unwrap();
                let condition_code = codegen_policy_condition(&cap.condition, interner);
                writeln!(output, "        {}", condition_code).unwrap();
                writeln!(output, "    }}\n").unwrap();
            }
        }

        writeln!(output, "}}\n").unwrap();
    }

    output
}

/// Generate Rust code for a policy condition.
fn codegen_policy_condition(condition: &PolicyCondition, interner: &Interner) -> String {
    match condition {
        PolicyCondition::FieldEquals { field, value, is_string_literal } => {
            let field_name = interner.resolve(*field);
            let value_str = interner.resolve(*value);
            if *is_string_literal {
                format!("self.{} == \"{}\"", field_name, value_str)
            } else {
                format!("self.{} == {}", field_name, value_str)
            }
        }
        PolicyCondition::FieldBool { field, value } => {
            let field_name = interner.resolve(*field);
            format!("self.{} == {}", field_name, value)
        }
        PolicyCondition::Predicate { subject: _, predicate } => {
            let pred_name = interner.resolve(*predicate).to_lowercase();
            format!("self.is_{}()", pred_name)
        }
        PolicyCondition::ObjectFieldEquals { subject: _, object, field } => {
            let object_name = interner.resolve(*object).to_lowercase();
            let field_name = interner.resolve(*field);
            format!("self == &{}.{}", object_name, field_name)
        }
        PolicyCondition::Or(left, right) => {
            let left_code = codegen_policy_condition(left, interner);
            let right_code = codegen_policy_condition(right, interner);
            format!("{} || {}", left_code, right_code)
        }
        PolicyCondition::And(left, right) => {
            let left_code = codegen_policy_condition(left, interner);
            let right_code = codegen_policy_condition(right, interner);
            format!("{} && {}", left_code, right_code)
        }
    }
}

/// Collect LWWRegister and MVRegister field paths for special handling in SetField codegen.
/// Returns a set of (type_name, field_name) pairs where the field uses .set() method.
fn collect_lww_fields(registry: &TypeRegistry, interner: &Interner) -> HashSet<(String, String)> {
    let mut lww_fields = HashSet::new();
    for (type_sym, def) in registry.iter_types() {
        if let TypeDef::Struct { fields, .. } = def {
            let type_name = interner.resolve(*type_sym).to_string();
            for field in fields {
                if let FieldType::Generic { base, .. } = &field.ty {
                    let base_name = interner.resolve(*base);
                    // Phase 49b: Both LWWRegister and MVRegister (Divergent) use .set()
                    if base_name == "LastWriteWins" || base_name == "Divergent" || base_name == "MVRegister" {
                        let field_name = interner.resolve(field.name).to_string();
                        lww_fields.insert((type_name.clone(), field_name));
                    }
                }
            }
        }
    }
    lww_fields
}

/// Phase 54: Collect function names that are async.
/// Used by LaunchTask codegen to determine if .await is needed.
fn collect_async_functions(stmts: &[Stmt]) -> HashSet<Symbol> {
    let mut async_fns = HashSet::new();
    for stmt in stmts {
        if let Stmt::FunctionDef { name, body, .. } = stmt {
            if body.iter().any(|s| requires_async_stmt(s)) {
                async_fns.insert(*name);
            }
        }
    }
    async_fns
}

/// Phase 54: Collect parameters that are used as pipe senders in function body.
/// If a param appears in `SendPipe { pipe: Expr::Identifier(param) }`, it's a sender.
fn collect_pipe_sender_params(body: &[Stmt]) -> HashSet<Symbol> {
    let mut senders = HashSet::new();
    for stmt in body {
        collect_pipe_sender_params_stmt(stmt, &mut senders);
    }
    senders
}

fn collect_pipe_sender_params_stmt(stmt: &Stmt, senders: &mut HashSet<Symbol>) {
    match stmt {
        Stmt::SendPipe { pipe, .. } | Stmt::TrySendPipe { pipe, .. } => {
            if let Expr::Identifier(sym) = pipe {
                senders.insert(*sym);
            }
        }
        Stmt::If { then_block, else_block, .. } => {
            for s in *then_block {
                collect_pipe_sender_params_stmt(s, senders);
            }
            if let Some(else_stmts) = else_block {
                for s in *else_stmts {
                    collect_pipe_sender_params_stmt(s, senders);
                }
            }
        }
        Stmt::While { body, .. } | Stmt::Repeat { body, .. } | Stmt::Zone { body, .. } => {
            for s in *body {
                collect_pipe_sender_params_stmt(s, senders);
            }
        }
        _ => {}
    }
}

/// Phase 54: Collect variables that are pipe declarations (created with CreatePipe).
/// These have _tx/_rx suffixes, while pipe parameters don't.
fn collect_pipe_vars(stmts: &[Stmt]) -> HashSet<Symbol> {
    let mut pipe_vars = HashSet::new();
    for stmt in stmts {
        collect_pipe_vars_stmt(stmt, &mut pipe_vars);
    }
    pipe_vars
}

fn collect_pipe_vars_stmt(stmt: &Stmt, pipe_vars: &mut HashSet<Symbol>) {
    match stmt {
        Stmt::CreatePipe { var, .. } => {
            pipe_vars.insert(*var);
        }
        Stmt::If { then_block, else_block, .. } => {
            for s in *then_block {
                collect_pipe_vars_stmt(s, pipe_vars);
            }
            if let Some(else_stmts) = else_block {
                for s in *else_stmts {
                    collect_pipe_vars_stmt(s, pipe_vars);
                }
            }
        }
        Stmt::While { body, .. } | Stmt::Repeat { body, .. } | Stmt::Zone { body, .. } => {
            for s in *body {
                collect_pipe_vars_stmt(s, pipe_vars);
            }
        }
        Stmt::Concurrent { tasks } | Stmt::Parallel { tasks } => {
            for s in *tasks {
                collect_pipe_vars_stmt(s, pipe_vars);
            }
        }
        _ => {}
    }
}

/// Generate complete Rust program with struct definitions and main function.
///
/// Phase 31: Structs are wrapped in `mod user_types` to enforce visibility.
/// Phase 32: Function definitions are emitted before main.
/// Phase 50: Accepts PolicyRegistry to generate security predicate methods.
pub fn codegen_program(stmts: &[Stmt], registry: &TypeRegistry, policies: &PolicyRegistry, interner: &Interner) -> String {
    let mut output = String::new();

    // Prelude
    writeln!(output, "use logos_core::prelude::*;\n").unwrap();

    // Phase 49: Collect LWWRegister fields for special SetField handling
    let lww_fields = collect_lww_fields(registry, interner);

    // Phase 54: Collect async functions for Launch codegen
    let async_functions = collect_async_functions(stmts);

    // Phase 54: Collect pipe declarations (variables with _tx/_rx suffixes)
    let main_pipe_vars = collect_pipe_vars(stmts);

    // Collect user-defined structs from registry (Phase 34: generics, Phase 47: is_portable, Phase 49: is_shared)
    let structs: Vec<_> = registry.iter_types()
        .filter_map(|(name, def)| {
            if let TypeDef::Struct { fields, generics, is_portable, is_shared } = def {
                if !fields.is_empty() || !generics.is_empty() {
                    Some((*name, fields.clone(), generics.clone(), *is_portable, *is_shared))
                } else {
                    None
                }
            } else {
                None
            }
        })
        .collect();

    // Phase 33/34: Collect user-defined enums from registry (generics, Phase 47: is_portable, Phase 49: is_shared)
    let enums: Vec<_> = registry.iter_types()
        .filter_map(|(name, def)| {
            if let TypeDef::Enum { variants, generics, is_portable, is_shared } = def {
                if !variants.is_empty() || !generics.is_empty() {
                    Some((*name, variants.clone(), generics.clone(), *is_portable, *is_shared))
                } else {
                    None
                }
            } else {
                None
            }
        })
        .collect();

    // Emit struct and enum definitions in user_types module if any exist
    if !structs.is_empty() || !enums.is_empty() {
        writeln!(output, "pub mod user_types {{").unwrap();
        writeln!(output, "    use super::*;\n").unwrap();

        for (name, fields, generics, is_portable, is_shared) in &structs {
            output.push_str(&codegen_struct_def(*name, fields, generics, *is_portable, *is_shared, interner, 4));
        }

        for (name, variants, generics, is_portable, is_shared) in &enums {
            output.push_str(&codegen_enum_def(*name, variants, generics, *is_portable, *is_shared, interner, 4));
        }

        writeln!(output, "}}\n").unwrap();
        writeln!(output, "use user_types::*;\n").unwrap();
    }

    // Phase 50: Generate policy impl blocks with predicate and capability methods
    output.push_str(&codegen_policy_impls(policies, interner));

    // Phase 32/38: Emit function definitions before main
    for stmt in stmts {
        if let Stmt::FunctionDef { name, params, body, return_type, is_native } = stmt {
            output.push_str(&codegen_function_def(*name, params, body, return_type.as_ref().copied(), *is_native, interner, &lww_fields, &async_functions));
        }
    }

    // Grand Challenge: Collect variables that need to be mutable
    let main_stmts: Vec<&Stmt> = stmts.iter()
        .filter(|s| !matches!(s, Stmt::FunctionDef { .. }))
        .collect();
    let mut main_mutable_vars = HashSet::new();
    for stmt in &main_stmts {
        collect_mutable_vars_stmt(stmt, &mut main_mutable_vars);
    }

    // Main function
    // Phase 51: Use async main when async operations are present
    if requires_async(stmts) {
        writeln!(output, "#[tokio::main]").unwrap();
        writeln!(output, "async fn main() {{").unwrap();
    } else {
        writeln!(output, "fn main() {{").unwrap();
    }
    // Phase 53: Inject VFS when file operations or persistence is used
    if requires_vfs(stmts) {
        writeln!(output, "    let vfs = logos_core::fs::NativeVfs::new(\".\");").unwrap();
    }
    let mut main_ctx = RefinementContext::new();
    let mut main_synced_vars = HashSet::new();  // Phase 52: Track synced variables in main
    // Phase 56: Pre-scan for Mount+Sync combinations
    let main_var_caps = analyze_variable_capabilities(stmts, interner);
    for stmt in stmts {
        // Skip function definitions - they're already emitted above
        if matches!(stmt, Stmt::FunctionDef { .. }) {
            continue;
        }
        output.push_str(&codegen_stmt(stmt, interner, 1, &main_mutable_vars, &mut main_ctx, &lww_fields, &mut main_synced_vars, &main_var_caps, &async_functions, &main_pipe_vars));
    }
    writeln!(output, "}}").unwrap();
    output
}

/// Phase 32/38: Generate a function definition.
/// Phase 38: Updated for native functions and TypeExpr types.
/// Phase 49: Accepts lww_fields for LWWRegister SetField handling.
fn codegen_function_def(
    name: Symbol,
    params: &[(Symbol, &TypeExpr)],
    body: &[Stmt],
    return_type: Option<&TypeExpr>,
    is_native: bool,
    interner: &Interner,
    lww_fields: &HashSet<(String, String)>,
    async_functions: &HashSet<Symbol>,  // Phase 54
) -> String {
    let mut output = String::new();
    let func_name = interner.resolve(name);

    // Phase 54: Detect which parameters are used as pipe senders
    let pipe_sender_params = collect_pipe_sender_params(body);

    // Build parameter list using TypeExpr
    let params_str: Vec<String> = params.iter()
        .map(|(param_name, param_type)| {
            let name = interner.resolve(*param_name);
            let ty = codegen_type_expr(param_type, interner);
            // Phase 54: If param is used as a pipe sender, wrap type in Sender<T>
            if pipe_sender_params.contains(param_name) {
                format!("{}: tokio::sync::mpsc::Sender<{}>", name, ty)
            } else {
                format!("{}: {}", name, ty)
            }
        })
        .collect();

    // Get return type string from TypeExpr or infer from body
    let return_type_str = return_type
        .map(|t| codegen_type_expr(t, interner))
        .or_else(|| infer_return_type_from_body(body, interner));

    // Phase 51: Check if function body requires async
    let is_async = body.iter().any(|s| requires_async_stmt(s));
    let fn_keyword = if is_async { "async fn" } else { "fn" };

    // Build function signature
    let signature = if let Some(ref ret_ty) = return_type_str {
        if ret_ty != "()" {
            format!("{} {}({}) -> {}", fn_keyword, func_name, params_str.join(", "), ret_ty)
        } else {
            format!("{} {}({})", fn_keyword, func_name, params_str.join(", "))
        }
    } else {
        format!("{} {}({})", fn_keyword, func_name, params_str.join(", "))
    };

    // Phase 38: Handle native functions
    if is_native {
        let (module, core_fn) = map_native_function(func_name);
        writeln!(output, "{} {{", signature).unwrap();

        // Generate call to logos_core
        let arg_names: Vec<&str> = params.iter()
            .map(|(n, _)| interner.resolve(*n))
            .collect();

        writeln!(output, "    logos_core::{}::{}({})", module, core_fn, arg_names.join(", ")).unwrap();
        writeln!(output, "}}\n").unwrap();
    } else {
        // Non-native: emit body
        // Grand Challenge: Collect mutable vars for this function
        let func_mutable_vars = collect_mutable_vars(body);
        writeln!(output, "{} {{", signature).unwrap();
        let mut func_ctx = RefinementContext::new();
        let mut func_synced_vars = HashSet::new();  // Phase 52: Track synced variables in function
        // Phase 56: Pre-scan for Mount+Sync combinations in function body
        let func_var_caps = analyze_variable_capabilities(body, interner);

        // Phase 50: Register parameter types for capability Check resolution
        for (param_name, param_type) in params {
            let type_name = codegen_type_expr(param_type, interner);
            func_ctx.register_variable_type(*param_name, type_name);
        }

        // Phase 54: Functions receive pipe senders as parameters, no local pipe declarations
        let func_pipe_vars = HashSet::new();

        for stmt in body {
            output.push_str(&codegen_stmt(stmt, interner, 1, &func_mutable_vars, &mut func_ctx, lww_fields, &mut func_synced_vars, &func_var_caps, async_functions, &func_pipe_vars));
        }
        writeln!(output, "}}\n").unwrap();
    }

    output
}

/// Phase 38: Map native function names to logos_core module paths.
fn map_native_function(name: &str) -> (&'static str, &'static str) {
    match name {
        "read" => ("file", "read"),
        "write" => ("file", "write"),
        "now" => ("time", "now"),
        "sleep" => ("time", "sleep"),
        "randomInt" => ("random", "randomInt"),
        "randomFloat" => ("random", "randomFloat"),
        "get" => ("env", "get"),
        "args" => ("env", "args"),
        _ => panic!("Unknown native function: {}. Add mapping to map_native_function().", name),
    }
}

/// Phase 38: Convert TypeExpr to Rust type string.
fn codegen_type_expr(ty: &TypeExpr, interner: &Interner) -> String {
    match ty {
        TypeExpr::Primitive(sym) => {
            map_type_to_rust(interner.resolve(*sym))
        }
        TypeExpr::Named(sym) => {
            let name = interner.resolve(*sym);
            // Check for common mappings
            map_type_to_rust(name)
        }
        TypeExpr::Generic { base, params } => {
            let base_name = interner.resolve(*base);
            let params_str: Vec<String> = params.iter()
                .map(|p| codegen_type_expr(p, interner))
                .collect();

            match base_name {
                "Result" => {
                    if params_str.len() == 2 {
                        format!("Result<{}, {}>", params_str[0], params_str[1])
                    } else if params_str.len() == 1 {
                        format!("Result<{}, String>", params_str[0])
                    } else {
                        "Result<(), String>".to_string()
                    }
                }
                "Option" => {
                    if !params_str.is_empty() {
                        format!("Option<{}>", params_str[0])
                    } else {
                        "Option<()>".to_string()
                    }
                }
                "Seq" | "List" | "Vec" => {
                    if !params_str.is_empty() {
                        format!("Vec<{}>", params_str[0])
                    } else {
                        "Vec<()>".to_string()
                    }
                }
                "Map" | "HashMap" => {
                    if params_str.len() >= 2 {
                        format!("std::collections::HashMap<{}, {}>", params_str[0], params_str[1])
                    } else {
                        "std::collections::HashMap<String, String>".to_string()
                    }
                }
                "Set" | "HashSet" => {
                    if !params_str.is_empty() {
                        format!("std::collections::HashSet<{}>", params_str[0])
                    } else {
                        "std::collections::HashSet<()>".to_string()
                    }
                }
                other => {
                    if params_str.is_empty() {
                        other.to_string()
                    } else {
                        format!("{}<{}>", other, params_str.join(", "))
                    }
                }
            }
        }
        TypeExpr::Function { inputs, output } => {
            let inputs_str: Vec<String> = inputs.iter()
                .map(|i| codegen_type_expr(i, interner))
                .collect();
            let output_str = codegen_type_expr(output, interner);
            format!("fn({}) -> {}", inputs_str.join(", "), output_str)
        }
        // Phase 43C: Refinement types use the base type for Rust type annotation
        // The constraint predicate is handled separately via debug_assert!
        TypeExpr::Refinement { base, .. } => {
            codegen_type_expr(base, interner)
        }
        // Phase 53: Persistent storage wrapper
        TypeExpr::Persistent { inner } => {
            let inner_type = codegen_type_expr(inner, interner);
            format!("logos_core::storage::Persistent<{}>", inner_type)
        }
    }
}

/// Infer return type from function body by looking at Return statements.
fn infer_return_type_from_body(body: &[Stmt], _interner: &Interner) -> Option<String> {
    for stmt in body {
        if let Stmt::Return { value: Some(_) } = stmt {
            // For now, assume i64 for any expression return
            // TODO: Implement proper type inference
            return Some("i64".to_string());
        }
    }
    None
}

/// Map LOGOS type names to Rust types.
fn map_type_to_rust(ty: &str) -> String {
    match ty {
        "Int" => "i64".to_string(),
        "Nat" => "u64".to_string(),
        "Text" => "String".to_string(),
        "Bool" | "Boolean" => "bool".to_string(),
        "Real" => "f64".to_string(),
        "Char" => "char".to_string(),
        "Byte" => "u8".to_string(),
        "Unit" | "()" => "()".to_string(),
        other => other.to_string(),
    }
}

/// Generate a single struct definition with derives and visibility.
/// Phase 34: Now supports generic type parameters.
/// Phase 47: Now supports is_portable for Serialize/Deserialize derives.
/// Phase 49: Now supports is_shared for CRDT Merge impl.
fn codegen_struct_def(name: Symbol, fields: &[FieldDef], generics: &[Symbol], is_portable: bool, is_shared: bool, interner: &Interner, indent: usize) -> String {
    let ind = " ".repeat(indent);
    let mut output = String::new();

    // Build generic parameter string: <T, U> or empty
    let generic_str = if generics.is_empty() {
        String::new()
    } else {
        let params: Vec<&str> = generics.iter()
            .map(|g| interner.resolve(*g))
            .collect();
        format!("<{}>", params.join(", "))
    };

    // Phase 47: Add Serialize, Deserialize derives if portable
    // Phase 50: Add PartialEq for policy equality comparisons
    // Phase 52: Shared types also need Serialize/Deserialize for Synced<T>
    if is_portable || is_shared {
        writeln!(output, "{}#[derive(Default, Debug, Clone, PartialEq, serde::Serialize, serde::Deserialize)]", ind).unwrap();
    } else {
        writeln!(output, "{}#[derive(Default, Debug, Clone, PartialEq)]", ind).unwrap();
    }
    writeln!(output, "{}pub struct {}{} {{", ind, interner.resolve(name), generic_str).unwrap();

    for field in fields {
        let vis = if field.is_public { "pub " } else { "" };
        let rust_type = codegen_field_type(&field.ty, interner);
        writeln!(output, "{}    {}{}: {},", ind, vis, interner.resolve(field.name), rust_type).unwrap();
    }

    writeln!(output, "{}}}\n", ind).unwrap();

    // Phase 49: Generate Merge impl for Shared structs
    if is_shared {
        output.push_str(&codegen_merge_impl(name, fields, generics, interner, indent));
    }

    output
}

/// Phase 49: Generate impl Merge for a Shared struct.
fn codegen_merge_impl(name: Symbol, fields: &[FieldDef], generics: &[Symbol], interner: &Interner, indent: usize) -> String {
    let ind = " ".repeat(indent);
    let name_str = interner.resolve(name);
    let mut output = String::new();

    // Build generic parameter string: <T, U> or empty
    let generic_str = if generics.is_empty() {
        String::new()
    } else {
        let params: Vec<&str> = generics.iter()
            .map(|g| interner.resolve(*g))
            .collect();
        format!("<{}>", params.join(", "))
    };

    writeln!(output, "{}impl{} logos_core::crdt::Merge for {}{} {{", ind, generic_str, name_str, generic_str).unwrap();
    writeln!(output, "{}    fn merge(&mut self, other: &Self) {{", ind).unwrap();

    for field in fields {
        let field_name = interner.resolve(field.name);
        // Only merge fields that implement Merge (CRDT types)
        if is_crdt_field_type(&field.ty, interner) {
            writeln!(output, "{}        self.{}.merge(&other.{});", ind, field_name, field_name).unwrap();
        }
    }

    writeln!(output, "{}    }}", ind).unwrap();
    writeln!(output, "{}}}\n", ind).unwrap();

    output
}

/// Phase 49: Check if a field type is a CRDT type that implements Merge.
fn is_crdt_field_type(ty: &FieldType, interner: &Interner) -> bool {
    match ty {
        FieldType::Named(sym) => {
            let name = interner.resolve(*sym);
            matches!(name,
                "ConvergentCount" | "GCounter" |
                "Tally" | "PNCounter"
            )
        }
        FieldType::Generic { base, .. } => {
            let name = interner.resolve(*base);
            matches!(name,
                "LastWriteWins" | "LWWRegister" |
                "SharedSet" | "ORSet" | "SharedSet_AddWins" | "SharedSet_RemoveWins" |
                "SharedSequence" | "RGA" | "SharedSequence_YATA" | "CollaborativeSequence" |
                "SharedMap" | "ORMap" |
                "Divergent" | "MVRegister"
            )
        }
        _ => false,
    }
}

/// Phase 33/34: Generate enum definition with optional generic parameters.
/// Phase 47: Now supports is_portable for Serialize/Deserialize derives.
/// Phase 49: Now accepts is_shared parameter (enums don't generate Merge impl yet).
fn codegen_enum_def(name: Symbol, variants: &[VariantDef], generics: &[Symbol], is_portable: bool, _is_shared: bool, interner: &Interner, indent: usize) -> String {
    let ind = " ".repeat(indent);
    let mut output = String::new();

    // Build generic parameter string: <T, U> or empty
    let generic_str = if generics.is_empty() {
        String::new()
    } else {
        let params: Vec<&str> = generics.iter()
            .map(|g| interner.resolve(*g))
            .collect();
        format!("<{}>", params.join(", "))
    };

    // Phase 47: Add Serialize, Deserialize derives if portable
    if is_portable {
        writeln!(output, "{}#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]", ind).unwrap();
    } else {
        writeln!(output, "{}#[derive(Debug, Clone)]", ind).unwrap();
    }
    writeln!(output, "{}pub enum {}{} {{", ind, interner.resolve(name), generic_str).unwrap();

    for variant in variants {
        let variant_name = interner.resolve(variant.name);
        if variant.fields.is_empty() {
            // Unit variant
            writeln!(output, "{}    {},", ind, variant_name).unwrap();
        } else {
            // Struct variant with named fields
            let fields_str: Vec<String> = variant.fields.iter()
                .map(|f| {
                    let rust_type = codegen_field_type(&f.ty, interner);
                    format!("{}: {}", interner.resolve(f.name), rust_type)
                })
                .collect();
            writeln!(output, "{}    {} {{ {} }},", ind, variant_name, fields_str.join(", ")).unwrap();
        }
    }

    writeln!(output, "{}}}\n", ind).unwrap();
    output
}

/// Convert FieldType to Rust type string.
fn codegen_field_type(ty: &FieldType, interner: &Interner) -> String {
    match ty {
        FieldType::Primitive(sym) => {
            match interner.resolve(*sym) {
                "Int" => "i64".to_string(),
                "Nat" => "u64".to_string(),
                "Text" => "String".to_string(),
                "Bool" | "Boolean" => "bool".to_string(),
                "Real" => "f64".to_string(),
                "Char" => "char".to_string(),
                "Byte" => "u8".to_string(),
                "Unit" => "()".to_string(),
                other => other.to_string(),
            }
        }
        FieldType::Named(sym) => {
            let name = interner.resolve(*sym);
            match name {
                // Phase 49: CRDT type mapping
                "ConvergentCount" => "logos_core::crdt::GCounter".to_string(),
                // Phase 49b: New CRDT types (Wave 5)
                "Tally" => "logos_core::crdt::PNCounter".to_string(),
                _ => name.to_string(),
            }
        }
        FieldType::Generic { base, params } => {
            let base_name = interner.resolve(*base);
            let param_strs: Vec<String> = params.iter()
                .map(|p| codegen_field_type(p, interner))
                .collect();

            // Phase 49c: Handle CRDT types with bias/algorithm modifiers
            match base_name {
                // SharedSet with explicit bias
                "SharedSet_RemoveWins" => {
                    return format!("logos_core::crdt::ORSet<{}, logos_core::crdt::RemoveWins>", param_strs.join(", "));
                }
                "SharedSet_AddWins" => {
                    return format!("logos_core::crdt::ORSet<{}, logos_core::crdt::AddWins>", param_strs.join(", "));
                }
                // SharedSequence with YATA algorithm
                "SharedSequence_YATA" | "CollaborativeSequence" => {
                    return format!("logos_core::crdt::YATA<{}>", param_strs.join(", "));
                }
                _ => {}
            }

            let base_str = match base_name {
                "List" | "Seq" => "Vec",
                "Set" => "std::collections::HashSet",
                "Map" => "std::collections::HashMap",
                "Option" => "Option",
                "Result" => "Result",
                // Phase 49: CRDT generic type
                "LastWriteWins" => "logos_core::crdt::LWWRegister",
                // Phase 49b: New CRDT generic types (Wave 5) - default to AddWins for ORSet
                "SharedSet" | "ORSet" => "logos_core::crdt::ORSet",
                "SharedSequence" | "RGA" => "logos_core::crdt::RGA",
                "SharedMap" | "ORMap" => "logos_core::crdt::ORMap",
                "Divergent" | "MVRegister" => "logos_core::crdt::MVRegister",
                other => other,
            };
            format!("{}<{}>", base_str, param_strs.join(", "))
        }
        // Phase 34: Type parameter reference (T, U, etc.)
        FieldType::TypeParam(sym) => interner.resolve(*sym).to_string(),
    }
}

pub fn codegen_stmt<'a>(
    stmt: &Stmt<'a>,
    interner: &Interner,
    indent: usize,
    mutable_vars: &HashSet<Symbol>,
    ctx: &mut RefinementContext<'a>,
    lww_fields: &HashSet<(String, String)>,
    synced_vars: &mut HashSet<Symbol>,  // Phase 52: Track synced variables
    var_caps: &HashMap<Symbol, VariableCapabilities>,  // Phase 56: Mount+Sync detection
    async_functions: &HashSet<Symbol>,  // Phase 54: Functions that are async
    pipe_vars: &HashSet<Symbol>,  // Phase 54: Pipe declarations (have _tx/_rx suffixes)
) -> String {
    let indent_str = "    ".repeat(indent);
    let mut output = String::new();

    match stmt {
        Stmt::Let { var, ty, value, mutable } => {
            let var_name = interner.resolve(*var);
            let value_str = codegen_expr(value, interner, synced_vars);
            let type_annotation = ty.map(|t| codegen_type_expr(t, interner));

            // Grand Challenge: Variable is mutable if explicitly marked OR if it's a Set target
            let is_mutable = *mutable || mutable_vars.contains(var);

            match (is_mutable, type_annotation) {
                (true, Some(t)) => writeln!(output, "{}let mut {}: {} = {};", indent_str, var_name, t, value_str).unwrap(),
                (true, None) => writeln!(output, "{}let mut {} = {};", indent_str, var_name, value_str).unwrap(),
                (false, Some(t)) => writeln!(output, "{}let {}: {} = {};", indent_str, var_name, t, value_str).unwrap(),
                (false, None) => writeln!(output, "{}let {} = {};", indent_str, var_name, value_str).unwrap(),
            }

            // Phase 43C: Handle refinement type
            if let Some(TypeExpr::Refinement { base: _, var: bound_var, predicate }) = ty {
                emit_refinement_check(var_name, *bound_var, predicate, interner, &indent_str, &mut output);
                ctx.register(*var, *bound_var, predicate);
            }
        }

        Stmt::Set { target, value } => {
            let target_name = interner.resolve(*target);
            let value_str = codegen_expr(value, interner, synced_vars);
            writeln!(output, "{}{} = {};", indent_str, target_name, value_str).unwrap();

            // Phase 43C: Check if this variable has a refinement constraint
            if let Some((bound_var, predicate)) = ctx.get_constraint(*target) {
                emit_refinement_check(target_name, bound_var, predicate, interner, &indent_str, &mut output);
            }
        }

        Stmt::Call { function, args } => {
            let func_name = interner.resolve(*function);
            let args_str: Vec<String> = args.iter().map(|a| codegen_expr(a, interner, synced_vars)).collect();
            writeln!(output, "{}{}({});", indent_str, func_name, args_str.join(", ")).unwrap();
        }

        Stmt::If { cond, then_block, else_block } => {
            let cond_str = codegen_expr(cond, interner, synced_vars);
            writeln!(output, "{}if {} {{", indent_str, cond_str).unwrap();
            ctx.push_scope();
            for stmt in *then_block {
                output.push_str(&codegen_stmt(stmt, interner, indent + 1, mutable_vars, ctx, lww_fields, synced_vars, var_caps, async_functions, pipe_vars));
            }
            ctx.pop_scope();
            if let Some(else_stmts) = else_block {
                writeln!(output, "{}}} else {{", indent_str).unwrap();
                ctx.push_scope();
                for stmt in *else_stmts {
                    output.push_str(&codegen_stmt(stmt, interner, indent + 1, mutable_vars, ctx, lww_fields, synced_vars, var_caps, async_functions, pipe_vars));
                }
                ctx.pop_scope();
            }
            writeln!(output, "{}}}", indent_str).unwrap();
        }

        Stmt::While { cond, body, decreasing: _ } => {
            // decreasing is compile-time only, ignored at runtime
            let cond_str = codegen_expr(cond, interner, synced_vars);
            writeln!(output, "{}while {} {{", indent_str, cond_str).unwrap();
            ctx.push_scope();
            for stmt in *body {
                output.push_str(&codegen_stmt(stmt, interner, indent + 1, mutable_vars, ctx, lww_fields, synced_vars, var_caps, async_functions, pipe_vars));
            }
            ctx.pop_scope();
            writeln!(output, "{}}}", indent_str).unwrap();
        }

        Stmt::Repeat { var, iterable, body } => {
            let var_name = interner.resolve(*var);
            let iter_str = codegen_expr(iterable, interner, synced_vars);
            writeln!(output, "{}for {} in {} {{", indent_str, var_name, iter_str).unwrap();
            ctx.push_scope();
            for stmt in *body {
                output.push_str(&codegen_stmt(stmt, interner, indent + 1, mutable_vars, ctx, lww_fields, synced_vars, var_caps, async_functions, pipe_vars));
            }
            ctx.pop_scope();
            writeln!(output, "{}}}", indent_str).unwrap();
        }

        Stmt::Return { value } => {
            if let Some(v) = value {
                let value_str = codegen_expr(v, interner, synced_vars);
                writeln!(output, "{}return {};", indent_str, value_str).unwrap();
            } else {
                writeln!(output, "{}return;", indent_str).unwrap();
            }
        }

        Stmt::Assert { proposition } => {
            let condition = codegen_assertion(proposition, interner);
            writeln!(output, "{}debug_assert!({});", indent_str, condition).unwrap();
        }

        // Phase 35: Trust with documented justification
        Stmt::Trust { proposition, justification } => {
            let reason = interner.resolve(*justification);
            // Strip quotes if present (string literals include their quotes)
            let reason_clean = reason.trim_matches('"');
            writeln!(output, "{}// TRUST: {}", indent_str, reason_clean).unwrap();
            let condition = codegen_assertion(proposition, interner);
            writeln!(output, "{}debug_assert!({});", indent_str, condition).unwrap();
        }

        Stmt::RuntimeAssert { condition } => {
            let cond_str = codegen_expr(condition, interner, synced_vars);
            writeln!(output, "{}debug_assert!({});", indent_str, cond_str).unwrap();
        }

        // Phase 50: Security Check - mandatory runtime guard (NEVER optimized out)
        Stmt::Check { subject, predicate, is_capability, object, source_text, span } => {
            let subj_name = interner.resolve(*subject);
            let pred_name = interner.resolve(*predicate).to_lowercase();

            let call = if *is_capability {
                let obj_sym = object.expect("capability must have object");
                let obj_word = interner.resolve(obj_sym);

                // Phase 50: Type-based resolution
                // "Check that user can publish the document" -> find variable of type Document
                // First try to find a variable whose type matches the object word
                let obj_name = ctx.find_variable_by_type(obj_word, interner)
                    .unwrap_or_else(|| obj_word.to_string());

                format!("{}.can_{}(&{})", subj_name, pred_name, obj_name)
            } else {
                format!("{}.is_{}()", subj_name, pred_name)
            };

            writeln!(output, "{}if !({}) {{", indent_str, call).unwrap();
            writeln!(output, "{}    logos_core::panic_with(\"Security Check Failed at line {}: {}\");",
                     indent_str, span.start, source_text).unwrap();
            writeln!(output, "{}}}", indent_str).unwrap();
        }

        // Phase 51: P2P Networking - Listen on network address
        Stmt::Listen { address } => {
            let addr_str = codegen_expr(address, interner, synced_vars);
            // Pass &str instead of String
            writeln!(output, "{}logos_core::network::listen(&{}).await.expect(\"Failed to listen\");",
                     indent_str, addr_str).unwrap();
        }

        // Phase 51: P2P Networking - Connect to remote peer
        Stmt::ConnectTo { address } => {
            let addr_str = codegen_expr(address, interner, synced_vars);
            // Pass &str instead of String
            writeln!(output, "{}logos_core::network::connect(&{}).await.expect(\"Failed to connect\");",
                     indent_str, addr_str).unwrap();
        }

        // Phase 51: P2P Networking - Create PeerAgent remote handle
        Stmt::LetPeerAgent { var, address } => {
            let var_name = interner.resolve(*var);
            let addr_str = codegen_expr(address, interner, synced_vars);
            // Pass &str instead of String
            writeln!(output, "{}let {} = logos_core::network::PeerAgent::new(&{}).expect(\"Invalid address\");",
                     indent_str, var_name, addr_str).unwrap();
        }

        // Phase 51: Sleep for milliseconds
        Stmt::Sleep { milliseconds } => {
            let ms_str = codegen_expr(milliseconds, interner, synced_vars);
            // Use tokio async sleep
            writeln!(output, "{}tokio::time::sleep(std::time::Duration::from_millis({} as u64)).await;",
                     indent_str, ms_str).unwrap();
        }

        // Phase 52/56: Sync CRDT variable on topic
        Stmt::Sync { var, topic } => {
            let var_name = interner.resolve(*var);
            let topic_str = codegen_expr(topic, interner, synced_vars);

            // Phase 56: Check if this variable is also mounted
            if let Some(caps) = var_caps.get(var) {
                if caps.mounted {
                    // Both Mount and Sync: use Distributed<T>
                    // Mount statement will handle the Distributed::mount call
                    // Here we just track it as synced
                    synced_vars.insert(*var);
                    return output;  // Skip - Mount will emit Distributed<T>
                }
            }

            // Sync-only: use Synced<T>
            writeln!(
                output,
                "{}let {} = logos_core::crdt::Synced::new({}, &{}).await;",
                indent_str, var_name, var_name, topic_str
            ).unwrap();
            synced_vars.insert(*var);
        }

        // Phase 53/56: Mount persistent CRDT from journal
        Stmt::Mount { var, path } => {
            let var_name = interner.resolve(*var);
            let path_str = codegen_expr(path, interner, synced_vars);

            // Phase 56: Check if this variable is also synced
            if let Some(caps) = var_caps.get(var) {
                if caps.synced {
                    // Both Mount and Sync: use Distributed<T>
                    let topic_str = caps.sync_topic.as_ref()
                        .map(|s| s.as_str())
                        .unwrap_or("\"default\"");
                    writeln!(
                        output,
                        "{}let {} = logos_core::distributed::Distributed::mount(std::sync::Arc::new(vfs.clone()), &{}, Some({}.to_string())).await.expect(\"Failed to mount\");",
                        indent_str, var_name, path_str, topic_str
                    ).unwrap();
                    synced_vars.insert(*var);
                    return output;
                }
            }

            // Mount-only: use Persistent<T>
            writeln!(
                output,
                "{}let {} = logos_core::storage::Persistent::mount(&vfs, &{}).await.expect(\"Failed to mount\");",
                indent_str, var_name, path_str
            ).unwrap();
            synced_vars.insert(*var);
        }

        // =====================================================================
        // Phase 54: Go-like Concurrency Codegen
        // =====================================================================

        Stmt::LaunchTask { function, args } => {
            let fn_name = interner.resolve(*function);
            // Phase 54: When passing a pipe variable, pass the sender (_tx)
            let args_str: Vec<String> = args.iter()
                .map(|a| {
                    if let Expr::Identifier(sym) = a {
                        if pipe_vars.contains(sym) {
                            return format!("{}_tx.clone()", interner.resolve(*sym));
                        }
                    }
                    codegen_expr(a, interner, synced_vars)
                })
                .collect();
            // Phase 54: Add .await only if the function is async
            let await_suffix = if async_functions.contains(function) { ".await" } else { "" };
            writeln!(
                output,
                "{}tokio::spawn(async move {{ {}({}){await_suffix}; }});",
                indent_str, fn_name, args_str.join(", ")
            ).unwrap();
        }

        Stmt::LaunchTaskWithHandle { handle, function, args } => {
            let handle_name = interner.resolve(*handle);
            let fn_name = interner.resolve(*function);
            // Phase 54: When passing a pipe variable, pass the sender (_tx)
            let args_str: Vec<String> = args.iter()
                .map(|a| {
                    if let Expr::Identifier(sym) = a {
                        if pipe_vars.contains(sym) {
                            return format!("{}_tx.clone()", interner.resolve(*sym));
                        }
                    }
                    codegen_expr(a, interner, synced_vars)
                })
                .collect();
            // Phase 54: Add .await only if the function is async
            let await_suffix = if async_functions.contains(function) { ".await" } else { "" };
            writeln!(
                output,
                "{}let {} = tokio::spawn(async move {{ {}({}){await_suffix} }});",
                indent_str, handle_name, fn_name, args_str.join(", ")
            ).unwrap();
        }

        Stmt::CreatePipe { var, element_type, capacity } => {
            let var_name = interner.resolve(*var);
            let type_name = interner.resolve(*element_type);
            let cap = capacity.unwrap_or(32);
            // Map LOGOS types to Rust types
            let rust_type = match type_name {
                "Int" => "i64",
                "Nat" => "u64",
                "Text" => "String",
                "Bool" => "bool",
                _ => type_name,
            };
            writeln!(
                output,
                "{}let ({}_tx, mut {}_rx) = tokio::sync::mpsc::channel::<{}>({});",
                indent_str, var_name, var_name, rust_type, cap
            ).unwrap();
        }

        Stmt::SendPipe { value, pipe } => {
            let val_str = codegen_expr(value, interner, synced_vars);
            let pipe_str = codegen_expr(pipe, interner, synced_vars);
            // Phase 54: Check if pipe is a local declaration (has _tx suffix) or parameter (no suffix)
            let is_local_pipe = if let Expr::Identifier(sym) = pipe {
                pipe_vars.contains(sym)
            } else {
                false
            };
            if is_local_pipe {
                writeln!(
                    output,
                    "{}{}_tx.send({}).await.expect(\"pipe send failed\");",
                    indent_str, pipe_str, val_str
                ).unwrap();
            } else {
                writeln!(
                    output,
                    "{}{}.send({}).await.expect(\"pipe send failed\");",
                    indent_str, pipe_str, val_str
                ).unwrap();
            }
        }

        Stmt::ReceivePipe { var, pipe } => {
            let var_name = interner.resolve(*var);
            let pipe_str = codegen_expr(pipe, interner, synced_vars);
            // Phase 54: Check if pipe is a local declaration (has _rx suffix) or parameter (no suffix)
            let is_local_pipe = if let Expr::Identifier(sym) = pipe {
                pipe_vars.contains(sym)
            } else {
                false
            };
            if is_local_pipe {
                writeln!(
                    output,
                    "{}let {} = {}_rx.recv().await.expect(\"pipe closed\");",
                    indent_str, var_name, pipe_str
                ).unwrap();
            } else {
                writeln!(
                    output,
                    "{}let {} = {}.recv().await.expect(\"pipe closed\");",
                    indent_str, var_name, pipe_str
                ).unwrap();
            }
        }

        Stmt::TrySendPipe { value, pipe, result } => {
            let val_str = codegen_expr(value, interner, synced_vars);
            let pipe_str = codegen_expr(pipe, interner, synced_vars);
            // Phase 54: Check if pipe is a local declaration
            let is_local_pipe = if let Expr::Identifier(sym) = pipe {
                pipe_vars.contains(sym)
            } else {
                false
            };
            let suffix = if is_local_pipe { "_tx" } else { "" };
            if let Some(res) = result {
                let res_name = interner.resolve(*res);
                writeln!(
                    output,
                    "{}let {} = {}{}.try_send({}).is_ok();",
                    indent_str, res_name, pipe_str, suffix, val_str
                ).unwrap();
            } else {
                writeln!(
                    output,
                    "{}let _ = {}{}.try_send({});",
                    indent_str, pipe_str, suffix, val_str
                ).unwrap();
            }
        }

        Stmt::TryReceivePipe { var, pipe } => {
            let var_name = interner.resolve(*var);
            let pipe_str = codegen_expr(pipe, interner, synced_vars);
            // Phase 54: Check if pipe is a local declaration
            let is_local_pipe = if let Expr::Identifier(sym) = pipe {
                pipe_vars.contains(sym)
            } else {
                false
            };
            let suffix = if is_local_pipe { "_rx" } else { "" };
            writeln!(
                output,
                "{}let {} = {}{}.try_recv().ok();",
                indent_str, var_name, pipe_str, suffix
            ).unwrap();
        }

        Stmt::StopTask { handle } => {
            let handle_str = codegen_expr(handle, interner, synced_vars);
            writeln!(output, "{}{}.abort();", indent_str, handle_str).unwrap();
        }

        Stmt::Select { branches } => {
            use crate::ast::stmt::SelectBranch;

            writeln!(output, "{}tokio::select! {{", indent_str).unwrap();
            for branch in branches {
                match branch {
                    SelectBranch::Receive { var, pipe, body } => {
                        let var_name = interner.resolve(*var);
                        let pipe_str = codegen_expr(pipe, interner, synced_vars);
                        writeln!(
                            output,
                            "{}    {} = {}_rx.recv() => {{",
                            indent_str, var_name, pipe_str
                        ).unwrap();
                        writeln!(
                            output,
                            "{}        if let Some({}) = {} {{",
                            indent_str, var_name, var_name
                        ).unwrap();
                        for stmt in *body {
                            let stmt_code = codegen_stmt(stmt, interner, indent + 3, mutable_vars, ctx, lww_fields, synced_vars, var_caps, async_functions, pipe_vars);
                            write!(output, "{}", stmt_code).unwrap();
                        }
                        writeln!(output, "{}        }}", indent_str).unwrap();
                        writeln!(output, "{}    }}", indent_str).unwrap();
                    }
                    SelectBranch::Timeout { milliseconds, body } => {
                        let ms_str = codegen_expr(milliseconds, interner, synced_vars);
                        // Convert seconds to milliseconds if the value looks like seconds
                        writeln!(
                            output,
                            "{}    _ = tokio::time::sleep(std::time::Duration::from_secs({} as u64)) => {{",
                            indent_str, ms_str
                        ).unwrap();
                        for stmt in *body {
                            let stmt_code = codegen_stmt(stmt, interner, indent + 2, mutable_vars, ctx, lww_fields, synced_vars, var_caps, async_functions, pipe_vars);
                            write!(output, "{}", stmt_code).unwrap();
                        }
                        writeln!(output, "{}    }}", indent_str).unwrap();
                    }
                }
            }
            writeln!(output, "{}}}", indent_str).unwrap();
        }

        Stmt::Give { object, recipient } => {
            // Move semantics: pass ownership without borrowing
            let obj_str = codegen_expr(object, interner, synced_vars);
            let recv_str = codegen_expr(recipient, interner, synced_vars);
            writeln!(output, "{}{}({});", indent_str, recv_str, obj_str).unwrap();
        }

        Stmt::Show { object, recipient } => {
            // Borrow semantics: pass immutable reference
            let obj_str = codegen_expr(object, interner, synced_vars);
            let recv_str = codegen_expr(recipient, interner, synced_vars);
            writeln!(output, "{}{}(&{});", indent_str, recv_str, obj_str).unwrap();
        }

        Stmt::SetField { object, field, value } => {
            let obj_str = codegen_expr(object, interner, synced_vars);
            let field_name = interner.resolve(*field);
            let value_str = codegen_expr(value, interner, synced_vars);

            // Phase 49: Check if this field is an LWWRegister - use .set() instead of =
            // We check if ANY type has this field as LWW (heuristic - works for most cases)
            let is_lww = lww_fields.iter().any(|(_, f)| f == field_name);
            if is_lww {
                writeln!(output, "{}{}.{}.set({});", indent_str, obj_str, field_name, value_str).unwrap();
            } else {
                writeln!(output, "{}{}.{} = {};", indent_str, obj_str, field_name, value_str).unwrap();
            }
        }

        Stmt::StructDef { .. } => {
            // Struct definitions are handled in codegen_program, not here
        }

        Stmt::FunctionDef { .. } => {
            // Function definitions are handled in codegen_program, not here
        }

        Stmt::Inspect { target, arms, .. } => {
            let target_str = codegen_expr(target, interner, synced_vars);
            writeln!(output, "{}match {} {{", indent_str, target_str).unwrap();

            for arm in arms {
                if let Some(variant) = arm.variant {
                    let variant_name = interner.resolve(variant);
                    // Get the enum name from the arm, or fallback to just variant name
                    let enum_prefix = arm.enum_name
                        .map(|e| format!("{}::", interner.resolve(e)))
                        .unwrap_or_default();

                    if arm.bindings.is_empty() {
                        // Unit variant pattern
                        writeln!(output, "{}    {}{} => {{", indent_str, enum_prefix, variant_name).unwrap();
                    } else {
                        // Pattern with bindings
                        let bindings_str: Vec<String> = arm.bindings.iter()
                            .map(|(field, binding)| {
                                let field_name = interner.resolve(*field);
                                let binding_name = interner.resolve(*binding);
                                if field_name == binding_name {
                                    field_name.to_string()
                                } else {
                                    format!("{}: {}", field_name, binding_name)
                                }
                            })
                            .collect();
                        writeln!(output, "{}    {}{} {{ {} }} => {{", indent_str, enum_prefix, variant_name, bindings_str.join(", ")).unwrap();
                    }
                } else {
                    // Otherwise (wildcard) pattern
                    writeln!(output, "{}    _ => {{", indent_str).unwrap();
                }

                ctx.push_scope();
                for stmt in arm.body {
                    output.push_str(&codegen_stmt(stmt, interner, indent + 2, mutable_vars, ctx, lww_fields, synced_vars, var_caps, async_functions, pipe_vars));
                }
                ctx.pop_scope();
                writeln!(output, "{}    }}", indent_str).unwrap();
            }

            writeln!(output, "{}}}", indent_str).unwrap();
        }

        Stmt::Push { value, collection } => {
            let val_str = codegen_expr(value, interner, synced_vars);
            let coll_str = codegen_expr(collection, interner, synced_vars);
            writeln!(output, "{}{}.push({});", indent_str, coll_str, val_str).unwrap();
        }

        Stmt::Pop { collection, into } => {
            let coll_str = codegen_expr(collection, interner, synced_vars);
            match into {
                Some(var) => {
                    let var_name = interner.resolve(*var);
                    // Unwrap the Option returned by pop() - panics if empty
                    writeln!(output, "{}let {} = {}.pop().expect(\"Pop from empty collection\");", indent_str, var_name, coll_str).unwrap();
                }
                None => {
                    writeln!(output, "{}{}.pop();", indent_str, coll_str).unwrap();
                }
            }
        }

        Stmt::Add { value, collection } => {
            let val_str = codegen_expr(value, interner, synced_vars);
            let coll_str = codegen_expr(collection, interner, synced_vars);
            writeln!(output, "{}{}.insert({});", indent_str, coll_str, val_str).unwrap();
        }

        Stmt::Remove { value, collection } => {
            let val_str = codegen_expr(value, interner, synced_vars);
            let coll_str = codegen_expr(collection, interner, synced_vars);
            writeln!(output, "{}{}.remove(&{});", indent_str, coll_str, val_str).unwrap();
        }

        Stmt::SetIndex { collection, index, value } => {
            let coll_str = codegen_expr(collection, interner, synced_vars);
            let index_str = codegen_expr(index, interner, synced_vars);
            let value_str = codegen_expr(value, interner, synced_vars);
            // Phase 57: Polymorphic indexing via trait
            writeln!(output, "{}LogosIndexMut::logos_set(&mut {}, {}, {});", indent_str, coll_str, index_str, value_str).unwrap();
        }

        // Phase 8.5: Zone (memory arena) block
        Stmt::Zone { name, capacity, source_file, body } => {
            let zone_name = interner.resolve(*name);

            // Generate zone creation based on type
            if let Some(path_sym) = source_file {
                // Memory-mapped file zone
                let path = interner.resolve(*path_sym);
                writeln!(
                    output,
                    "{}let {} = logos_core::memory::Zone::new_mapped(\"{}\").expect(\"Failed to map file\");",
                    indent_str, zone_name, path
                ).unwrap();
            } else {
                // Heap arena zone
                let cap = capacity.unwrap_or(4096); // Default 4KB
                writeln!(
                    output,
                    "{}let {} = logos_core::memory::Zone::new_heap({});",
                    indent_str, zone_name, cap
                ).unwrap();
            }

            // Open block scope
            writeln!(output, "{}{{", indent_str).unwrap();
            ctx.push_scope();

            // Generate body statements
            for stmt in *body {
                output.push_str(&codegen_stmt(stmt, interner, indent + 1, mutable_vars, ctx, lww_fields, synced_vars, var_caps, async_functions, pipe_vars));
            }

            ctx.pop_scope();
            writeln!(output, "{}}}", indent_str).unwrap();
        }

        // Phase 9: Concurrent execution block (async, I/O-bound)
        // Generates tokio::join! for concurrent task execution
        // Phase 51: Variables used across multiple tasks are cloned to avoid move issues
        Stmt::Concurrent { tasks } => {
            // Collect Let statements to generate tuple destructuring
            let let_bindings: Vec<_> = tasks.iter().filter_map(|s| {
                if let Stmt::Let { var, .. } = s {
                    Some(interner.resolve(*var).to_string())
                } else {
                    None
                }
            }).collect();

            // Collect variables used in Call statements across all tasks
            let used_vars: HashSet<String> = tasks.iter().flat_map(|s| {
                if let Stmt::Call { args, .. } = s {
                    args.iter().filter_map(|arg| {
                        if let Expr::Identifier(sym) = arg {
                            Some(interner.resolve(*sym).to_string())
                        } else {
                            None
                        }
                    }).collect::<Vec<_>>()
                } else {
                    vec![]
                }
            }).collect();

            if !let_bindings.is_empty() {
                // Generate tuple destructuring for concurrent Let bindings
                writeln!(output, "{}let ({}) = tokio::join!(", indent_str, let_bindings.join(", ")).unwrap();
            } else {
                writeln!(output, "{}tokio::join!(", indent_str).unwrap();
            }

            for (i, stmt) in tasks.iter().enumerate() {
                let inner = codegen_stmt(stmt, interner, indent + 1, mutable_vars, ctx, lww_fields, synced_vars, var_caps, async_functions, pipe_vars);

                // Convert call statements to awaited calls for async context
                let inner_awaited = if let Stmt::Call { .. } = stmt {
                    // Add .await before the semicolon for function calls
                    inner.trim().trim_end_matches(';').to_string() + ".await;"
                } else {
                    inner.trim().to_string()
                };

                // For tasks that use shared variables, wrap in a block that clones them
                if !used_vars.is_empty() && i < tasks.len() - 1 {
                    // Clone variables for all tasks except the last one
                    let clones: Vec<String> = used_vars.iter()
                        .map(|v| format!("let {} = {}.clone();", v, v))
                        .collect();
                    write!(output, "{}    {{ {} async move {{ {} }} }}",
                           indent_str, clones.join(" "), inner_awaited).unwrap();
                } else {
                    // Last task can use original variables
                    write!(output, "{}    async {{ {} }}", indent_str, inner_awaited).unwrap();
                }

                if i < tasks.len() - 1 {
                    writeln!(output, ",").unwrap();
                } else {
                    writeln!(output).unwrap();
                }
            }

            writeln!(output, "{});", indent_str).unwrap();
        }

        // Phase 9: Parallel execution block (CPU-bound)
        // Generates rayon::join for two tasks, or thread::spawn for 3+ tasks
        Stmt::Parallel { tasks } => {
            // Collect Let statements to generate tuple destructuring
            let let_bindings: Vec<_> = tasks.iter().filter_map(|s| {
                if let Stmt::Let { var, .. } = s {
                    Some(interner.resolve(*var).to_string())
                } else {
                    None
                }
            }).collect();

            if tasks.len() == 2 {
                // Use rayon::join for exactly 2 tasks
                if !let_bindings.is_empty() {
                    writeln!(output, "{}let ({}) = rayon::join(", indent_str, let_bindings.join(", ")).unwrap();
                } else {
                    writeln!(output, "{}rayon::join(", indent_str).unwrap();
                }

                for (i, stmt) in tasks.iter().enumerate() {
                    let inner = codegen_stmt(stmt, interner, indent + 1, mutable_vars, ctx, lww_fields, synced_vars, var_caps, async_functions, pipe_vars);
                    write!(output, "{}    || {{ {} }}", indent_str, inner.trim()).unwrap();
                    if i == 0 {
                        writeln!(output, ",").unwrap();
                    } else {
                        writeln!(output).unwrap();
                    }
                }
                writeln!(output, "{});", indent_str).unwrap();
            } else {
                // For 3+ tasks, use thread::spawn pattern
                writeln!(output, "{}{{", indent_str).unwrap();
                writeln!(output, "{}    let handles: Vec<_> = vec![", indent_str).unwrap();
                for stmt in *tasks {
                    let inner = codegen_stmt(stmt, interner, indent + 2, mutable_vars, ctx, lww_fields, synced_vars, var_caps, async_functions, pipe_vars);
                    writeln!(output, "{}        std::thread::spawn(move || {{ {} }}),",
                             indent_str, inner.trim()).unwrap();
                }
                writeln!(output, "{}    ];", indent_str).unwrap();
                writeln!(output, "{}    for h in handles {{ h.join().unwrap(); }}", indent_str).unwrap();
                writeln!(output, "{}}}", indent_str).unwrap();
            }
        }

        // Phase 10: Read from console or file
        // Phase 53: File reads now use async VFS
        Stmt::ReadFrom { var, source } => {
            let var_name = interner.resolve(*var);
            match source {
                ReadSource::Console => {
                    writeln!(output, "{}let {} = logos_core::io::read_line();", indent_str, var_name).unwrap();
                }
                ReadSource::File(path_expr) => {
                    let path_str = codegen_expr(path_expr, interner, synced_vars);
                    // Phase 53: Use VFS with async
                    writeln!(
                        output,
                        "{}let {} = vfs.read_to_string(&{}).await.expect(\"Failed to read file\");",
                        indent_str, var_name, path_str
                    ).unwrap();
                }
            }
        }

        // Phase 10: Write to file
        // Phase 53: File writes now use async VFS
        Stmt::WriteFile { content, path } => {
            let content_str = codegen_expr(content, interner, synced_vars);
            let path_str = codegen_expr(path, interner, synced_vars);
            // Phase 53: Use VFS with async
            writeln!(
                output,
                "{}vfs.write(&{}, {}.as_bytes()).await.expect(\"Failed to write file\");",
                indent_str, path_str, content_str
            ).unwrap();
        }

        // Phase 46: Spawn an agent
        Stmt::Spawn { agent_type, name } => {
            let type_name = interner.resolve(*agent_type);
            let agent_name = interner.resolve(*name);
            // Generate agent spawn with tokio channel
            writeln!(
                output,
                "{}let {} = tokio::spawn(async move {{ /* {} agent loop */ }});",
                indent_str, agent_name, type_name
            ).unwrap();
        }

        // Phase 46: Send message to agent
        Stmt::SendMessage { message, destination } => {
            let msg_str = codegen_expr(message, interner, synced_vars);
            let dest_str = codegen_expr(destination, interner, synced_vars);
            writeln!(
                output,
                "{}{}.send({}).await.expect(\"Failed to send message\");",
                indent_str, dest_str, msg_str
            ).unwrap();
        }

        // Phase 46: Await response from agent
        Stmt::AwaitMessage { source, into } => {
            let src_str = codegen_expr(source, interner, synced_vars);
            let var_name = interner.resolve(*into);
            writeln!(
                output,
                "{}let {} = {}.recv().await.expect(\"Failed to receive message\");",
                indent_str, var_name, src_str
            ).unwrap();
        }

        // Phase 49: Merge CRDT state
        Stmt::MergeCrdt { source, target } => {
            let src_str = codegen_expr(source, interner, synced_vars);
            let tgt_str = codegen_expr(target, interner, synced_vars);
            writeln!(
                output,
                "{}{}.merge(&{});",
                indent_str, tgt_str, src_str
            ).unwrap();
        }

        // Phase 49: Increment GCounter
        // Phase 52: If object is synced, wrap in .mutate() for auto-publish
        Stmt::IncreaseCrdt { object, field, amount } => {
            let field_name = interner.resolve(*field);
            let amount_str = codegen_expr(amount, interner, synced_vars);

            // Check if the root object is synced
            let root_sym = get_root_identifier(object);
            if let Some(sym) = root_sym {
                if synced_vars.contains(&sym) {
                    // Synced: use .mutate() for auto-publish
                    let obj_name = interner.resolve(sym);
                    writeln!(
                        output,
                        "{}{}.mutate(|inner| inner.{}.increment({} as u64)).await;",
                        indent_str, obj_name, field_name, amount_str
                    ).unwrap();
                    return output;
                }
            }

            // Not synced: direct access
            let obj_str = codegen_expr(object, interner, synced_vars);
            writeln!(
                output,
                "{}{}.{}.increment({} as u64);",
                indent_str, obj_str, field_name, amount_str
            ).unwrap();
        }

        // Phase 49b: Decrement PNCounter
        Stmt::DecreaseCrdt { object, field, amount } => {
            let field_name = interner.resolve(*field);
            let amount_str = codegen_expr(amount, interner, synced_vars);

            // Check if the root object is synced
            let root_sym = get_root_identifier(object);
            if let Some(sym) = root_sym {
                if synced_vars.contains(&sym) {
                    // Synced: use .mutate() for auto-publish
                    let obj_name = interner.resolve(sym);
                    writeln!(
                        output,
                        "{}{}.mutate(|inner| inner.{}.decrement({} as u64)).await;",
                        indent_str, obj_name, field_name, amount_str
                    ).unwrap();
                    return output;
                }
            }

            // Not synced: direct access
            let obj_str = codegen_expr(object, interner, synced_vars);
            writeln!(
                output,
                "{}{}.{}.decrement({} as u64);",
                indent_str, obj_str, field_name, amount_str
            ).unwrap();
        }

        // Phase 49b: Append to SharedSequence (RGA)
        Stmt::AppendToSequence { sequence, value } => {
            let seq_str = codegen_expr(sequence, interner, synced_vars);
            let val_str = codegen_expr(value, interner, synced_vars);
            writeln!(
                output,
                "{}{}.append({});",
                indent_str, seq_str, val_str
            ).unwrap();
        }

        // Phase 49b: Resolve MVRegister conflicts
        Stmt::ResolveConflict { object, field, value } => {
            let field_name = interner.resolve(*field);
            let val_str = codegen_expr(value, interner, synced_vars);
            let obj_str = codegen_expr(object, interner, synced_vars);
            writeln!(
                output,
                "{}{}.{}.resolve({});",
                indent_str, obj_str, field_name, val_str
            ).unwrap();
        }
    }

    output
}

/// Phase 52: Extract the root identifier from an expression.
/// For `x.field.subfield`, returns `x`.
fn get_root_identifier(expr: &Expr) -> Option<Symbol> {
    match expr {
        Expr::Identifier(sym) => Some(*sym),
        Expr::FieldAccess { object, .. } => get_root_identifier(object),
        _ => None,
    }
}

pub fn codegen_expr(expr: &Expr, interner: &Interner, synced_vars: &HashSet<Symbol>) -> String {
    match expr {
        Expr::Literal(lit) => codegen_literal(lit, interner),

        Expr::Identifier(sym) => interner.resolve(*sym).to_string(),

        Expr::BinaryOp { op, left, right } => {
            let left_str = codegen_expr(left, interner, synced_vars);
            let right_str = codegen_expr(right, interner, synced_vars);
            // Phase 53: String concatenation requires special handling
            if matches!(op, BinaryOpKind::Concat) {
                return format!("format!(\"{{}}{{}}\", {}, {})", left_str, right_str);
            }
            let op_str = match op {
                BinaryOpKind::Add => "+",
                BinaryOpKind::Subtract => "-",
                BinaryOpKind::Multiply => "*",
                BinaryOpKind::Divide => "/",
                BinaryOpKind::Modulo => "%",
                BinaryOpKind::Eq => "==",
                BinaryOpKind::NotEq => "!=",
                BinaryOpKind::Lt => "<",
                BinaryOpKind::Gt => ">",
                BinaryOpKind::LtEq => "<=",
                BinaryOpKind::GtEq => ">=",
                BinaryOpKind::And => "&&",
                BinaryOpKind::Or => "||",
                BinaryOpKind::Concat => unreachable!(), // Handled above
            };
            format!("({} {} {})", left_str, op_str, right_str)
        }

        Expr::Call { function, args } => {
            let func_name = interner.resolve(*function);
            let args_str: Vec<String> = args.iter().map(|a| codegen_expr(a, interner, synced_vars)).collect();
            format!("{}({})", func_name, args_str.join(", "))
        }

        Expr::Index { collection, index } => {
            let coll_str = codegen_expr(collection, interner, synced_vars);
            let index_str = codegen_expr(index, interner, synced_vars);
            // Phase 57: Polymorphic indexing via trait
            format!("LogosIndex::logos_get(&{}, {})", coll_str, index_str)
        }

        Expr::Slice { collection, start, end } => {
            let coll_str = codegen_expr(collection, interner, synced_vars);
            let start_str = codegen_expr(start, interner, synced_vars);
            let end_str = codegen_expr(end, interner, synced_vars);
            // Phase 43D: 1-indexed inclusive to 0-indexed exclusive
            // "items 1 through 3" → &items[0..3] (elements at indices 0, 1, 2)
            format!("&{}[({} - 1) as usize..{} as usize]", coll_str, start_str, end_str)
        }

        Expr::Copy { expr } => {
            let expr_str = codegen_expr(expr, interner, synced_vars);
            // Phase 43D: Explicit clone to owned Vec
            format!("{}.to_vec()", expr_str)
        }

        Expr::Length { collection } => {
            let coll_str = codegen_expr(collection, interner, synced_vars);
            // Phase 43D: Collection length - cast to i64 for LOGOS integer semantics
            format!("({}.len() as i64)", coll_str)
        }

        Expr::Contains { collection, value } => {
            let coll_str = codegen_expr(collection, interner, synced_vars);
            let val_str = codegen_expr(value, interner, synced_vars);
            // Use LogosContains trait for unified contains across List, Set, Map, Text
            format!("{}.logos_contains(&{})", coll_str, val_str)
        }

        Expr::Union { left, right } => {
            let left_str = codegen_expr(left, interner, synced_vars);
            let right_str = codegen_expr(right, interner, synced_vars);
            format!("{}.union(&{}).cloned().collect::<std::collections::HashSet<_>>()", left_str, right_str)
        }

        Expr::Intersection { left, right } => {
            let left_str = codegen_expr(left, interner, synced_vars);
            let right_str = codegen_expr(right, interner, synced_vars);
            format!("{}.intersection(&{}).cloned().collect::<std::collections::HashSet<_>>()", left_str, right_str)
        }

        // Phase 48: Sipping Protocol expressions
        Expr::ManifestOf { zone } => {
            let zone_str = codegen_expr(zone, interner, synced_vars);
            format!("logos_core::network::FileSipper::from_zone(&{}).manifest()", zone_str)
        }

        Expr::ChunkAt { index, zone } => {
            let zone_str = codegen_expr(zone, interner, synced_vars);
            let index_str = codegen_expr(index, interner, synced_vars);
            // LOGOS uses 1-indexed, Rust uses 0-indexed
            format!("logos_core::network::FileSipper::from_zone(&{}).get_chunk(({} - 1) as usize)", zone_str, index_str)
        }

        Expr::List(ref items) => {
            let item_strs: Vec<String> = items.iter()
                .map(|i| codegen_expr(i, interner, synced_vars))
                .collect();
            format!("vec![{}]", item_strs.join(", "))
        }

        Expr::Tuple(ref items) => {
            let item_strs: Vec<String> = items.iter()
                .map(|i| format!("Value::from({})", codegen_expr(i, interner, synced_vars)))
                .collect();
            // Tuples as Vec<Value> for heterogeneous support
            format!("vec![{}]", item_strs.join(", "))
        }

        Expr::Range { start, end } => {
            let start_str = codegen_expr(start, interner, synced_vars);
            let end_str = codegen_expr(end, interner, synced_vars);
            format!("({}..={})", start_str, end_str)
        }

        Expr::FieldAccess { object, field } => {
            let field_name = interner.resolve(*field);

            // Phase 52: Check if root object is synced - use .get().await
            let root_sym = get_root_identifier(object);
            if let Some(sym) = root_sym {
                if synced_vars.contains(&sym) {
                    let obj_name = interner.resolve(sym);
                    return format!("{}.get().await.{}", obj_name, field_name);
                }
            }

            let obj_str = codegen_expr(object, interner, synced_vars);
            format!("{}.{}", obj_str, field_name)
        }

        Expr::New { type_name, type_args, init_fields } => {
            let type_str = interner.resolve(*type_name);
            if !init_fields.is_empty() {
                // Struct initialization with fields: Point { x: 10, y: 20, ..Default::default() }
                // Always add ..Default::default() to handle partial initialization (e.g., CRDT fields)
                let fields_str = init_fields.iter()
                    .map(|(name, value)| {
                        let field_name = interner.resolve(*name);
                        let value_str = codegen_expr(value, interner, synced_vars);
                        format!("{}: {}", field_name, value_str)
                    })
                    .collect::<Vec<_>>()
                    .join(", ");
                format!("{} {{ {}, ..Default::default() }}", type_str, fields_str)
            } else if type_args.is_empty() {
                format!("{}::default()", type_str)
            } else {
                // Phase 34: Turbofish syntax for generic instantiation
                let args_str = type_args.iter()
                    .map(|s| map_type_to_rust(interner.resolve(*s)))
                    .collect::<Vec<_>>()
                    .join(", ");
                format!("{}::<{}>::default()", type_str, args_str)
            }
        }

        Expr::NewVariant { enum_name, variant, fields } => {
            let enum_str = interner.resolve(*enum_name);
            let variant_str = interner.resolve(*variant);
            if fields.is_empty() {
                // Unit variant: Shape::Point
                format!("{}::{}", enum_str, variant_str)
            } else {
                // Struct variant: Shape::Circle { radius: 10 }
                let fields_str: Vec<String> = fields.iter()
                    .map(|(field_name, value)| {
                        let name = interner.resolve(*field_name);
                        let val = codegen_expr(value, interner, synced_vars);
                        format!("{}: {}", name, val)
                    })
                    .collect();
                format!("{}::{} {{ {} }}", enum_str, variant_str, fields_str.join(", "))
            }
        }
    }
}

fn codegen_literal(lit: &Literal, interner: &Interner) -> String {
    match lit {
        Literal::Number(n) => n.to_string(),
        Literal::Float(f) => format!("{}f64", f),
        // String literals are converted to String for consistent Text type handling
        Literal::Text(sym) => format!("String::from(\"{}\")", interner.resolve(*sym)),
        Literal::Boolean(b) => b.to_string(),
        Literal::Nothing => "()".to_string(),
        // Character literals
        Literal::Char(c) => {
            // Handle escape sequences for special characters
            match c {
                '\n' => "'\\n'".to_string(),
                '\t' => "'\\t'".to_string(),
                '\r' => "'\\r'".to_string(),
                '\\' => "'\\\\'".to_string(),
                '\'' => "'\\''".to_string(),
                '\0' => "'\\0'".to_string(),
                c => format!("'{}'", c),
            }
        }
    }
}

/// Converts a LogicExpr to a Rust boolean expression for debug_assert!().
/// Uses RustFormatter to unify all logic-to-Rust translation.
pub fn codegen_assertion(expr: &LogicExpr, interner: &Interner) -> String {
    let mut registry = SymbolRegistry::new();
    let formatter = RustFormatter;
    let mut buf = String::new();

    match expr.write_logic(&mut buf, &mut registry, interner, &formatter) {
        Ok(_) => buf,
        Err(_) => "/* error generating assertion */ false".to_string(),
    }
}

pub fn codegen_term(term: &Term, interner: &Interner) -> String {
    match term {
        Term::Constant(sym) => interner.resolve(*sym).to_string(),
        Term::Variable(sym) => interner.resolve(*sym).to_string(),
        Term::Value { kind, .. } => match kind {
            NumberKind::Integer(n) => n.to_string(),
            NumberKind::Real(f) => f.to_string(),
            NumberKind::Symbolic(sym) => interner.resolve(*sym).to_string(),
        },
        Term::Function(name, args) => {
            let args_str: Vec<String> = args.iter()
                .map(|a| codegen_term(a, interner))
                .collect();
            format!("{}({})", interner.resolve(*name), args_str.join(", "))
        }
        Term::Possessed { possessor, possessed } => {
            let poss_str = codegen_term(possessor, interner);
            format!("{}.{}", poss_str, interner.resolve(*possessed))
        }
        Term::Group(members) => {
            let members_str: Vec<String> = members.iter()
                .map(|m| codegen_term(m, interner))
                .collect();
            format!("({})", members_str.join(", "))
        }
        _ => "/* unsupported Term */".to_string(),
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_literal_number() {
        let interner = Interner::new();
        let synced_vars = HashSet::new();
        let expr = Expr::Literal(Literal::Number(42));
        assert_eq!(codegen_expr(&expr, &interner, &synced_vars), "42");
    }

    #[test]
    fn test_literal_boolean() {
        let interner = Interner::new();
        let synced_vars = HashSet::new();
        assert_eq!(codegen_expr(&Expr::Literal(Literal::Boolean(true)), &interner, &synced_vars), "true");
        assert_eq!(codegen_expr(&Expr::Literal(Literal::Boolean(false)), &interner, &synced_vars), "false");
    }

    #[test]
    fn test_literal_nothing() {
        let interner = Interner::new();
        let synced_vars = HashSet::new();
        assert_eq!(codegen_expr(&Expr::Literal(Literal::Nothing), &interner, &synced_vars), "()");
    }
}

```

---

//! LOGOS Compilation Pipeline
//!
//! This module provides the end-to-end compilation pipeline:
//! LOGOS source → Rust source → executable

use std::fs;
use std::io::Write;
use std::path::Path;
use std::process::Command;

// Embed runtime at compile time
const LOGOS_CORE_TOML: &str = include_str!("../logos_core/Cargo.toml");
const LOGOS_CORE_LIB: &str = include_str!("../logos_core/src/lib.rs");
const LOGOS_CORE_TYPES: &str = include_str!("../logos_core/src/types.rs");
const LOGOS_CORE_IO: &str = include_str!("../logos_core/src/io.rs");
// Phase 38: Standard library modules
const LOGOS_CORE_FILE: &str = include_str!("../logos_core/src/file.rs");
const LOGOS_CORE_TIME: &str = include_str!("../logos_core/src/time.rs");
const LOGOS_CORE_RANDOM: &str = include_str!("../logos_core/src/random.rs");
const LOGOS_CORE_ENV: &str = include_str!("../logos_core/src/env.rs");
// Phase 8.5: Zone-based memory management
const LOGOS_CORE_MEMORY: &str = include_str!("../logos_core/src/memory.rs");

use crate::analysis::{DiscoveryPass, EscapeChecker, OwnershipChecker, PolicyRegistry};
use crate::arena::Arena;
use crate::arena_ctx::AstContext;
use crate::ast::{Expr, Stmt, TypeExpr};
use crate::codegen::codegen_program;
use crate::diagnostic::{parse_rustc_json, translate_diagnostics, LogosError};
use crate::drs::WorldState;
use crate::error::ParseError;
use crate::intern::Interner;
use crate::lexer::Lexer;
use crate::parser::Parser;
use crate::sourcemap::SourceMap;

/// Compile LOGOS source to Rust source code.
pub fn compile_to_rust(source: &str) -> Result<String, ParseError> {
    let mut interner = Interner::new();
    let mut lexer = Lexer::new(source, &mut interner);
    let tokens = lexer.tokenize();

    // Pass 1: Discovery - scan for type definitions and policies
    let (type_registry, policy_registry) = {
        let mut discovery = DiscoveryPass::new(&tokens, &mut interner);
        let result = discovery.run_full();
        (result.types, result.policies)
    };
    // Clone for codegen (parser takes ownership)
    let codegen_registry = type_registry.clone();
    let codegen_policies = policy_registry.clone();

    let mut world_state = WorldState::new();
    let expr_arena = Arena::new();
    let term_arena = Arena::new();
    let np_arena = Arena::new();
    let sym_arena = Arena::new();
    let role_arena = Arena::new();
    let pp_arena = Arena::new();
    let stmt_arena: Arena<Stmt> = Arena::new();
    let imperative_expr_arena: Arena<Expr> = Arena::new();
    let type_expr_arena: Arena<TypeExpr> = Arena::new();

    let ast_ctx = AstContext::with_types(
        &expr_arena,
        &term_arena,
        &np_arena,
        &sym_arena,
        &role_arena,
        &pp_arena,
        &stmt_arena,
        &imperative_expr_arena,
        &type_expr_arena,
    );

    // Pass 2: Parse with type context
    let mut parser = Parser::new(tokens, &mut world_state, &mut interner, ast_ctx, type_registry);
    // Note: Don't call process_block_headers() - parse_program handles blocks itself

    let stmts = parser.parse_program()?;

    // Pass 3: Escape analysis - check for zone escape violations
    // This catches obvious cases like returning zone-local variables
    let mut escape_checker = EscapeChecker::new(&interner);
    escape_checker.check_program(&stmts).map_err(|e| {
        // Convert EscapeError to ParseError for now
        // The error message is already Socratic from EscapeChecker
        ParseError {
            kind: crate::error::ParseErrorKind::Custom(e.to_string()),
            span: e.span,
        }
    })?;

    // Note: Static verification (Phase 42) is available when the `verification`
    // feature is enabled, but must be explicitly invoked via compile_to_rust_verified().

    let rust_code = codegen_program(&stmts, &codegen_registry, &codegen_policies, &interner);

    Ok(rust_code)
}

/// Compile LOGOS source to Rust with ownership checking enabled.
///
/// This runs the lightweight ownership analysis pass (Phase 45) that catches
/// use-after-move errors with control flow awareness in milliseconds.
/// Use this with `--check` flag for instant feedback on ownership errors.
pub fn compile_to_rust_checked(source: &str) -> Result<String, ParseError> {
    let mut interner = Interner::new();
    let mut lexer = Lexer::new(source, &mut interner);
    let tokens = lexer.tokenize();

    // Pass 1: Discovery - scan for type definitions and policies
    let (type_registry, policy_registry) = {
        let mut discovery = DiscoveryPass::new(&tokens, &mut interner);
        let result = discovery.run_full();
        (result.types, result.policies)
    };
    // Clone for codegen (parser takes ownership)
    let codegen_registry = type_registry.clone();
    let codegen_policies = policy_registry.clone();

    let mut world_state = WorldState::new();
    let expr_arena = Arena::new();
    let term_arena = Arena::new();
    let np_arena = Arena::new();
    let sym_arena = Arena::new();
    let role_arena = Arena::new();
    let pp_arena = Arena::new();
    let stmt_arena: Arena<Stmt> = Arena::new();
    let imperative_expr_arena: Arena<Expr> = Arena::new();
    let type_expr_arena: Arena<TypeExpr> = Arena::new();

    let ast_ctx = AstContext::with_types(
        &expr_arena,
        &term_arena,
        &np_arena,
        &sym_arena,
        &role_arena,
        &pp_arena,
        &stmt_arena,
        &imperative_expr_arena,
        &type_expr_arena,
    );

    // Pass 2: Parse with type context
    let mut parser = Parser::new(tokens, &mut world_state, &mut interner, ast_ctx, type_registry);
    let stmts = parser.parse_program()?;

    // Pass 3: Escape analysis
    let mut escape_checker = EscapeChecker::new(&interner);
    escape_checker.check_program(&stmts).map_err(|e| {
        ParseError {
            kind: crate::error::ParseErrorKind::Custom(e.to_string()),
            span: e.span,
        }
    })?;

    // Pass 4: Ownership analysis (Phase 45)
    // Catches use-after-move errors with control flow awareness
    let mut ownership_checker = OwnershipChecker::new(&interner);
    ownership_checker.check_program(&stmts).map_err(|e| {
        ParseError {
            kind: crate::error::ParseErrorKind::Custom(e.to_string()),
            span: e.span,
        }
    })?;

    let rust_code = codegen_program(&stmts, &codegen_registry, &codegen_policies, &interner);

    Ok(rust_code)
}

/// Compile LOGOS source to Rust source code with static verification.
///
/// This runs the Z3-based verifier on Assert statements before codegen.
/// Requires the `verification` feature to be enabled.
#[cfg(feature = "verification")]
pub fn compile_to_rust_verified(source: &str) -> Result<String, ParseError> {
    use crate::verification::VerificationPass;

    let mut interner = Interner::new();
    let mut lexer = Lexer::new(source, &mut interner);
    let tokens = lexer.tokenize();

    // Pass 1: Discovery - scan for type definitions and policies
    let (type_registry, policy_registry) = {
        let mut discovery = DiscoveryPass::new(&tokens, &mut interner);
        let result = discovery.run_full();
        (result.types, result.policies)
    };
    // Clone for codegen (parser takes ownership)
    let codegen_registry = type_registry.clone();
    let codegen_policies = policy_registry.clone();

    let mut world_state = WorldState::new();
    let expr_arena = Arena::new();
    let term_arena = Arena::new();
    let np_arena = Arena::new();
    let sym_arena = Arena::new();
    let role_arena = Arena::new();
    let pp_arena = Arena::new();
    let stmt_arena: Arena<Stmt> = Arena::new();
    let imperative_expr_arena: Arena<Expr> = Arena::new();
    let type_expr_arena: Arena<TypeExpr> = Arena::new();

    let ast_ctx = AstContext::with_types(
        &expr_arena,
        &term_arena,
        &np_arena,
        &sym_arena,
        &role_arena,
        &pp_arena,
        &stmt_arena,
        &imperative_expr_arena,
        &type_expr_arena,
    );

    // Pass 2: Parse with type context
    let mut parser = Parser::new(tokens, &mut world_state, &mut interner, ast_ctx, type_registry);
    let stmts = parser.parse_program()?;

    // Pass 3: Escape analysis
    let mut escape_checker = EscapeChecker::new(&interner);
    escape_checker.check_program(&stmts).map_err(|e| {
        ParseError {
            kind: crate::error::ParseErrorKind::Custom(e.to_string()),
            span: e.span,
        }
    })?;

    // Pass 4: Static verification
    let mut verifier = VerificationPass::new(&interner);
    verifier.verify_program(&stmts).map_err(|e| {
        ParseError {
            kind: crate::error::ParseErrorKind::Custom(format!(
                "Verification Failed:\n\n{}",
                e
            )),
            span: crate::token::Span::default(),
        }
    })?;

    let rust_code = codegen_program(&stmts, &codegen_registry, &codegen_policies, &interner);

    Ok(rust_code)
}

/// Compile LOGOS source and write output to a directory.
/// Creates a Cargo project with logos_core dependency.
pub fn compile_to_dir(source: &str, output_dir: &Path) -> Result<(), CompileError> {
    let rust_code = compile_to_rust(source).map_err(CompileError::Parse)?;

    // Create output directory structure
    let src_dir = output_dir.join("src");
    fs::create_dir_all(&src_dir).map_err(|e| CompileError::Io(e.to_string()))?;

    // Write main.rs with logos_core import
    let main_rs = format!(
        "use logos_core::prelude::*;\n\n{}",
        rust_code
    );
    let main_path = src_dir.join("main.rs");
    let mut file = fs::File::create(&main_path).map_err(|e| CompileError::Io(e.to_string()))?;
    file.write_all(main_rs.as_bytes()).map_err(|e| CompileError::Io(e.to_string()))?;

    // Write Cargo.toml
    let cargo_toml = format!(
        r#"[package]
name = "logos_output"
version = "0.1.0"
edition = "2021"

[dependencies]
logos_core = {{ path = "./logos_core" }}
"#
    );
    let cargo_path = output_dir.join("Cargo.toml");
    let mut file = fs::File::create(&cargo_path).map_err(|e| CompileError::Io(e.to_string()))?;
    file.write_all(cargo_toml.as_bytes()).map_err(|e| CompileError::Io(e.to_string()))?;

    // Copy logos_core to output directory
    copy_logos_core(output_dir)?;

    Ok(())
}

/// Copy the logos_core crate to the output directory.
/// This recursively copies the entire crate including all modules.
pub fn copy_logos_core(output_dir: &Path) -> Result<(), CompileError> {
    let dest_dir = output_dir.join("logos_core");

    // Find the logos_core source directory relative to the CARGO_MANIFEST_DIR
    // or use the embedded constants as fallback
    let source_dir = std::env::var("CARGO_MANIFEST_DIR")
        .map(|d| Path::new(&d).join("logos_core"))
        .ok()
        .filter(|p| p.exists());

    if let Some(src) = source_dir {
        // Recursively copy the actual logos_core directory
        copy_dir_recursive(&src, &dest_dir)?;
    } else {
        // Fallback to embedded files for distribution builds
        let src_dir = dest_dir.join("src");
        fs::create_dir_all(&src_dir).map_err(|e| CompileError::Io(e.to_string()))?;

        fs::write(dest_dir.join("Cargo.toml"), LOGOS_CORE_TOML)
            .map_err(|e| CompileError::Io(e.to_string()))?;
        fs::write(src_dir.join("lib.rs"), LOGOS_CORE_LIB)
            .map_err(|e| CompileError::Io(e.to_string()))?;
        fs::write(src_dir.join("types.rs"), LOGOS_CORE_TYPES)
            .map_err(|e| CompileError::Io(e.to_string()))?;
        fs::write(src_dir.join("io.rs"), LOGOS_CORE_IO)
            .map_err(|e| CompileError::Io(e.to_string()))?;
        fs::write(src_dir.join("file.rs"), LOGOS_CORE_FILE)
            .map_err(|e| CompileError::Io(e.to_string()))?;
        fs::write(src_dir.join("time.rs"), LOGOS_CORE_TIME)
            .map_err(|e| CompileError::Io(e.to_string()))?;
        fs::write(src_dir.join("random.rs"), LOGOS_CORE_RANDOM)
            .map_err(|e| CompileError::Io(e.to_string()))?;
        fs::write(src_dir.join("env.rs"), LOGOS_CORE_ENV)
            .map_err(|e| CompileError::Io(e.to_string()))?;
        fs::write(src_dir.join("memory.rs"), LOGOS_CORE_MEMORY)
            .map_err(|e| CompileError::Io(e.to_string()))?;
    }

    Ok(())
}

/// Recursively copy a directory.
fn copy_dir_recursive(src: &Path, dst: &Path) -> Result<(), CompileError> {
    fs::create_dir_all(dst).map_err(|e| CompileError::Io(e.to_string()))?;

    for entry in fs::read_dir(src).map_err(|e| CompileError::Io(e.to_string()))? {
        let entry = entry.map_err(|e| CompileError::Io(e.to_string()))?;
        let src_path = entry.path();
        let file_name = entry.file_name();
        let dst_path = dst.join(&file_name);

        // Skip target directory and other build artifacts
        if file_name == "target" || file_name == ".git" {
            continue;
        }

        if src_path.is_dir() {
            copy_dir_recursive(&src_path, &dst_path)?;
        } else if file_name == "Cargo.toml" {
            // Special handling for Cargo.toml: remove [workspace] line
            // which can interfere with nested crate dependencies
            let content = fs::read_to_string(&src_path)
                .map_err(|e| CompileError::Io(e.to_string()))?;
            let filtered: String = content
                .lines()
                .filter(|line| !line.trim().starts_with("[workspace]"))
                .collect::<Vec<_>>()
                .join("\n");
            fs::write(&dst_path, filtered).map_err(|e| CompileError::Io(e.to_string()))?;
        } else {
            fs::copy(&src_path, &dst_path).map_err(|e| CompileError::Io(e.to_string()))?;
        }
    }

    Ok(())
}

/// Compile and run a LOGOS program.
pub fn compile_and_run(source: &str, output_dir: &Path) -> Result<String, CompileError> {
    compile_to_dir(source, output_dir)?;

    // Run cargo build with JSON message format for structured error parsing
    let build_output = Command::new("cargo")
        .arg("build")
        .arg("--message-format=json")
        .current_dir(output_dir)
        .output()
        .map_err(|e| CompileError::Io(e.to_string()))?;

    if !build_output.status.success() {
        let stderr = String::from_utf8_lossy(&build_output.stderr);
        let stdout = String::from_utf8_lossy(&build_output.stdout);

        // Try to parse JSON diagnostics and translate them
        let diagnostics = parse_rustc_json(&stdout);

        if !diagnostics.is_empty() {
            // Create a basic source map with the LOGOS source
            let source_map = SourceMap::new(source.to_string());
            let interner = Interner::new();

            if let Some(logos_error) = translate_diagnostics(&diagnostics, &source_map, &interner) {
                return Err(CompileError::Ownership(logos_error));
            }
        }

        // Fallback to raw error if translation fails
        return Err(CompileError::Build(stderr.to_string()));
    }

    // Run the compiled program
    let run_output = Command::new("cargo")
        .arg("run")
        .arg("--quiet")
        .current_dir(output_dir)
        .output()
        .map_err(|e| CompileError::Io(e.to_string()))?;

    if !run_output.status.success() {
        let stderr = String::from_utf8_lossy(&run_output.stderr);
        return Err(CompileError::Runtime(stderr.to_string()));
    }

    let stdout = String::from_utf8_lossy(&run_output.stdout);
    Ok(stdout.to_string())
}

/// Compile a LOGOS source file.
/// For single-file compilation without dependencies.
pub fn compile_file(path: &Path) -> Result<String, CompileError> {
    let source = fs::read_to_string(path).map_err(|e| CompileError::Io(e.to_string()))?;
    compile_to_rust(&source).map_err(CompileError::Parse)
}

/// Phase 36: Compile a LOGOS project with dependencies.
/// Scans the Abstract for [Alias](URI) links and loads dependencies recursively.
pub fn compile_project(path: &Path) -> Result<String, CompileError> {
    use crate::analysis::discover_with_imports;
    use crate::project::Loader;

    let source = fs::read_to_string(path).map_err(|e| CompileError::Io(e.to_string()))?;
    let root_dir = path.parent().unwrap_or(Path::new(".")).to_path_buf();

    let mut interner = Interner::new();
    let mut loader = Loader::new(root_dir);

    // Pass 1: Recursive discovery with imports
    let type_registry = discover_with_imports(path, &source, &mut loader, &mut interner)
        .map_err(|e| CompileError::Io(e))?;
    let codegen_registry = type_registry.clone();

    // Phase 50: Also discover policies from the main file
    // (discover_with_imports doesn't handle policies yet, so we do a separate pass)
    let mut lexer = Lexer::new(&source, &mut interner);
    let tokens = lexer.tokenize();
    let policy_registry = {
        let mut discovery = DiscoveryPass::new(&tokens, &mut interner);
        discovery.run_full().policies
    };
    let codegen_policies = policy_registry.clone();

    // Re-tokenize for parsing (interner may have been modified)
    let mut lexer = Lexer::new(&source, &mut interner);
    let tokens = lexer.tokenize();

    let mut world_state = WorldState::new();
    let expr_arena = Arena::new();
    let term_arena = Arena::new();
    let np_arena = Arena::new();
    let sym_arena = Arena::new();
    let role_arena = Arena::new();
    let pp_arena = Arena::new();
    let stmt_arena: Arena<Stmt> = Arena::new();
    let imperative_expr_arena: Arena<Expr> = Arena::new();
    let type_expr_arena: Arena<TypeExpr> = Arena::new();

    let ast_ctx = AstContext::with_types(
        &expr_arena,
        &term_arena,
        &np_arena,
        &sym_arena,
        &role_arena,
        &pp_arena,
        &stmt_arena,
        &imperative_expr_arena,
        &type_expr_arena,
    );

    // Pass 2: Parse with type context (includes imported types)
    let mut parser = Parser::new(tokens, &mut world_state, &mut interner, ast_ctx, type_registry);
    let stmts = parser.parse_program().map_err(CompileError::Parse)?;
    let rust_code = codegen_program(&stmts, &codegen_registry, &codegen_policies, &interner);

    Ok(rust_code)
}

/// Errors that can occur during compilation.
#[derive(Debug)]
pub enum CompileError {
    Parse(ParseError),
    Io(String),
    Build(String),
    Runtime(String),
    /// Translated ownership/borrow checker error with friendly LOGOS message
    Ownership(LogosError),
}

impl std::fmt::Display for CompileError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            CompileError::Parse(e) => write!(f, "Parse error: {:?}", e),
            CompileError::Io(e) => write!(f, "IO error: {}", e),
            CompileError::Build(e) => write!(f, "Build error: {}", e),
            CompileError::Runtime(e) => write!(f, "Runtime error: {}", e),
            CompileError::Ownership(e) => write!(f, "{}", e),
        }
    }
}

impl std::error::Error for CompileError {}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_compile_let_statement() {
        let source = "## Main\nLet x be 5.";
        let result = compile_to_rust(source);
        assert!(result.is_ok(), "Should compile: {:?}", result);
        let rust = result.unwrap();
        assert!(rust.contains("fn main()"));
        assert!(rust.contains("let x = 5;"));
    }

    #[test]
    fn test_compile_return_statement() {
        let source = "## Main\nReturn 42.";
        let result = compile_to_rust(source);
        assert!(result.is_ok(), "Should compile: {:?}", result);
        let rust = result.unwrap();
        assert!(rust.contains("return 42;"));
    }
}

```

---

use std::collections::HashMap;
use crate::drs::OwnershipState;

#[derive(Debug, Clone)]
pub struct ScopeEntry {
    pub symbol: String,
    pub ownership: OwnershipState,
}

impl ScopeEntry {
    pub fn variable(name: &str) -> Self {
        Self {
            symbol: name.to_string(),
            ownership: OwnershipState::Owned,
        }
    }
}

#[derive(Debug, Default)]
pub struct ScopeStack {
    scopes: Vec<HashMap<String, ScopeEntry>>,
}

impl ScopeStack {
    pub fn new() -> Self {
        Self::default()
    }

    pub fn push_scope(&mut self) {
        self.scopes.push(HashMap::new());
    }

    pub fn pop_scope(&mut self) {
        self.scopes.pop();
    }

    pub fn bind(&mut self, name: &str, entry: ScopeEntry) {
        if let Some(scope) = self.scopes.last_mut() {
            scope.insert(name.to_string(), entry);
        }
    }

    pub fn lookup(&self, name: &str) -> Option<&ScopeEntry> {
        for scope in self.scopes.iter().rev() {
            if let Some(entry) = scope.get(name) {
                return Some(entry);
            }
        }
        None
    }

    pub fn lookup_mut(&mut self, name: &str) -> Option<&mut ScopeEntry> {
        for scope in self.scopes.iter_mut().rev() {
            if let Some(entry) = scope.get_mut(name) {
                return Some(entry);
            }
        }
        None
    }
}

```

---

## Type Analysis

Two-pass type checking and discovery.
pub mod registry;
pub mod discovery;
pub mod dependencies;
pub mod escape;
pub mod ownership;
pub mod policy;

pub use registry::{TypeRegistry, TypeDef};
pub use discovery::{DiscoveryPass, DiscoveryResult};
pub use dependencies::{scan_dependencies, Dependency};
pub use escape::{EscapeChecker, EscapeError, EscapeErrorKind};
pub use ownership::{OwnershipChecker, OwnershipError, OwnershipErrorKind, VarState};
pub use policy::{PolicyRegistry, PredicateDef, CapabilityDef, PolicyCondition};

#[cfg(not(target_arch = "wasm32"))]
pub use discovery::discover_with_imports;

```

---

use std::collections::HashMap;
use crate::intern::{Interner, Symbol};

/// Type reference for struct fields (avoids circular deps with ast::TypeExpr)
#[derive(Debug, Clone, PartialEq, Eq)]
pub enum FieldType {
    /// Primitive type name (Int, Nat, Text, Bool, etc.)
    Primitive(Symbol),
    /// User-defined type name
    Named(Symbol),
    /// Generic type with parameters (List of Int, Seq of Text)
    Generic { base: Symbol, params: Vec<FieldType> },
    /// Phase 34: Type parameter reference (T, U, etc.)
    TypeParam(Symbol),
}

/// Field definition within a struct
#[derive(Debug, Clone, PartialEq, Eq)]
pub struct FieldDef {
    pub name: Symbol,
    pub ty: FieldType,
    pub is_public: bool,
}

/// Phase 33: Variant definition for sum types
#[derive(Debug, Clone, PartialEq, Eq)]
pub struct VariantDef {
    pub name: Symbol,
    pub fields: Vec<FieldDef>,  // Empty for unit variants
}

#[derive(Debug, Clone, PartialEq, Eq)]
pub enum TypeDef {
    /// Primitive type (Nat, Int, Text, Bool)
    Primitive,
    /// Struct with named fields and visibility
    /// Phase 34: Now includes optional type parameters
    /// Phase 47: Added is_portable for serde derives
    /// Phase 49: Added is_shared for CRDT Merge impl
    Struct {
        fields: Vec<FieldDef>,
        generics: Vec<Symbol>,  // [T, U] for "A Pair of [T] and [U] has:"
        is_portable: bool,       // Phase 47: Derives Serialize/Deserialize
        is_shared: bool,         // Phase 49: Generates impl Merge
    },
    /// Phase 33: Enum with variants (unit or with payload)
    /// Phase 34: Now includes optional type parameters
    /// Phase 47: Added is_portable for serde derives
    /// Phase 49: Added is_shared for CRDT Merge impl
    Enum {
        variants: Vec<VariantDef>,
        generics: Vec<Symbol>,  // [T] for "A Maybe of [T] is either:"
        is_portable: bool,       // Phase 47: Derives Serialize/Deserialize
        is_shared: bool,         // Phase 49: Generates impl Merge
    },
    /// Built-in generic type (List, Option, Result)
    Generic { param_count: usize },
    /// Type alias
    Alias { target: Symbol },
}

#[derive(Debug, Default, Clone)]
pub struct TypeRegistry {
    types: HashMap<Symbol, TypeDef>,
}

impl TypeRegistry {
    pub fn new() -> Self {
        Self::default()
    }

    /// Register a type definition
    pub fn register(&mut self, name: Symbol, def: TypeDef) {
        self.types.insert(name, def);
    }

    /// Check if a symbol is a known type
    pub fn is_type(&self, name: Symbol) -> bool {
        self.types.contains_key(&name)
    }

    /// Check if a symbol is a generic type (takes parameters)
    pub fn is_generic(&self, name: Symbol) -> bool {
        match self.types.get(&name) {
            Some(TypeDef::Generic { .. }) => true,
            Some(TypeDef::Struct { generics, .. }) => !generics.is_empty(),
            Some(TypeDef::Enum { generics, .. }) => !generics.is_empty(),
            _ => false,
        }
    }

    /// Phase 34: Get type parameters for a user-defined generic type
    pub fn get_generics(&self, name: Symbol) -> Option<&[Symbol]> {
        match self.types.get(&name)? {
            TypeDef::Struct { generics, .. } => Some(generics),
            TypeDef::Enum { generics, .. } => Some(generics),
            _ => None,
        }
    }

    /// Get type definition
    pub fn get(&self, name: Symbol) -> Option<&TypeDef> {
        self.types.get(&name)
    }

    /// Iterate over all registered types (for codegen)
    pub fn iter_types(&self) -> impl Iterator<Item = (&Symbol, &TypeDef)> {
        self.types.iter()
    }

    /// Phase 33: Check if a symbol is a known enum variant
    /// Returns Some((enum_name, variant_def)) if found
    pub fn find_variant(&self, variant_name: Symbol) -> Option<(Symbol, &VariantDef)> {
        for (enum_name, type_def) in &self.types {
            if let TypeDef::Enum { variants, .. } = type_def {
                for variant in variants {
                    if variant.name == variant_name {
                        return Some((*enum_name, variant));
                    }
                }
            }
        }
        None
    }

    /// Phase 33: Check if a symbol is an enum variant
    pub fn is_variant(&self, name: Symbol) -> bool {
        self.find_variant(name).is_some()
    }

    /// Pre-register primitives and intrinsic generics
    pub fn with_primitives(interner: &mut Interner) -> Self {
        let mut reg = Self::new();

        // LOGOS Core Primitives
        reg.register(interner.intern("Nat"), TypeDef::Primitive);
        reg.register(interner.intern("Int"), TypeDef::Primitive);
        reg.register(interner.intern("Text"), TypeDef::Primitive);
        reg.register(interner.intern("Bool"), TypeDef::Primitive);
        reg.register(interner.intern("Boolean"), TypeDef::Primitive);
        reg.register(interner.intern("Unit"), TypeDef::Primitive);
        reg.register(interner.intern("Real"), TypeDef::Primitive);  // Floating point
        reg.register(interner.intern("Char"), TypeDef::Primitive);  // Character
        reg.register(interner.intern("Byte"), TypeDef::Primitive);  // 8-bit unsigned (0-255)

        // Intrinsic Generics
        reg.register(interner.intern("List"), TypeDef::Generic { param_count: 1 });
        reg.register(interner.intern("Seq"), TypeDef::Generic { param_count: 1 });  // Phase 30: Sequences
        reg.register(interner.intern("Map"), TypeDef::Generic { param_count: 2 });  // Phase 43D: Key-value maps
        reg.register(interner.intern("Set"), TypeDef::Generic { param_count: 1 });  // Set collection (HashSet)
        reg.register(interner.intern("Option"), TypeDef::Generic { param_count: 1 });
        reg.register(interner.intern("Result"), TypeDef::Generic { param_count: 2 });

        reg
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn registry_stores_and_retrieves() {
        let mut interner = Interner::new();
        let mut registry = TypeRegistry::new();
        let foo = interner.intern("Foo");
        registry.register(foo, TypeDef::Primitive);
        assert!(registry.is_type(foo));
        assert!(!registry.is_generic(foo));
    }
}

```

---

use crate::token::{Token, TokenType, BlockType};
use crate::intern::{Interner, Symbol};
use super::registry::{TypeRegistry, TypeDef, FieldDef, FieldType, VariantDef};
use super::policy::{PolicyRegistry, PredicateDef, CapabilityDef, PolicyCondition};
use super::dependencies::scan_dependencies;

#[cfg(not(target_arch = "wasm32"))]
use std::path::Path;
#[cfg(not(target_arch = "wasm32"))]
use crate::project::Loader;

/// Result of running the discovery pass
pub struct DiscoveryResult {
    pub types: TypeRegistry,
    pub policies: PolicyRegistry,
}

/// Discovery pass that scans tokens before main parsing to build a TypeRegistry.
///
/// This pass looks for type definitions in `## Definition` blocks:
/// - "A Stack is a generic collection." → Generic type
/// - "A User is a structure." → Struct type
/// - "A Shape is an enum." → Enum type
///
/// Phase 50: Also scans `## Policy` blocks for security predicates and capabilities.
pub struct DiscoveryPass<'a> {
    tokens: &'a [Token],
    pos: usize,
    interner: &'a mut Interner,
}

impl<'a> DiscoveryPass<'a> {
    pub fn new(tokens: &'a [Token], interner: &'a mut Interner) -> Self {
        Self { tokens, pos: 0, interner }
    }

    /// Run discovery pass, returning populated TypeRegistry
    /// (Backward compatible - returns only TypeRegistry)
    pub fn run(&mut self) -> TypeRegistry {
        self.run_full().types
    }

    /// Phase 50: Run discovery pass, returning both TypeRegistry and PolicyRegistry
    pub fn run_full(&mut self) -> DiscoveryResult {
        let mut type_registry = TypeRegistry::with_primitives(self.interner);
        let mut policy_registry = PolicyRegistry::new();

        while self.pos < self.tokens.len() {
            // Look for Definition blocks
            if self.check_block_header(BlockType::Definition) {
                self.advance(); // consume ## Definition
                self.scan_definition_block(&mut type_registry);
            } else if self.check_block_header(BlockType::TypeDef) {
                // Inline type definition: ## A Point has: or ## A Color is one of:
                // The article is part of the block header, so don't skip it
                self.advance(); // consume ## A/An
                self.parse_type_definition_inline(&mut type_registry);
            } else if self.check_block_header(BlockType::Policy) {
                // Phase 50: Security policy definitions
                self.advance(); // consume ## Policy
                self.scan_policy_block(&mut policy_registry);
            } else {
                self.advance();
            }
        }

        DiscoveryResult {
            types: type_registry,
            policies: policy_registry,
        }
    }

    fn check_block_header(&self, expected: BlockType) -> bool {
        matches!(
            self.tokens.get(self.pos),
            Some(Token { kind: TokenType::BlockHeader { block_type }, .. })
            if *block_type == expected
        )
    }

    fn scan_definition_block(&mut self, registry: &mut TypeRegistry) {
        // Scan until next block header or EOF
        while self.pos < self.tokens.len() {
            if matches!(self.peek(), Some(Token { kind: TokenType::BlockHeader { .. }, .. })) {
                break;
            }

            // Look for "A [Name] is a..." pattern
            if self.check_article() {
                self.try_parse_type_definition(registry);
            } else {
                self.advance();
            }
        }
    }

    /// Phase 50: Scan policy block for predicate and capability definitions
    /// Patterns:
    /// - "A User is admin if the user's role equals \"admin\"."
    /// - "A User can publish the Document if the user is admin OR the user equals the document's owner."
    fn scan_policy_block(&mut self, registry: &mut PolicyRegistry) {
        while self.pos < self.tokens.len() {
            if matches!(self.peek(), Some(Token { kind: TokenType::BlockHeader { .. }, .. })) {
                break;
            }

            // Skip newlines and indentation
            if self.check_newline() || self.check_indent() || self.check_dedent() {
                self.advance();
                continue;
            }

            // Look for "A [Type] is [predicate] if..." or "A [Type] can [action] ..."
            if self.check_article() {
                self.try_parse_policy_definition(registry);
            } else {
                self.advance();
            }
        }
    }

    /// Phase 50: Parse a policy definition
    fn try_parse_policy_definition(&mut self, registry: &mut PolicyRegistry) {
        self.advance(); // consume article

        // Get subject type name (e.g., "User")
        let subject_type = match self.consume_noun_or_proper() {
            Some(sym) => sym,
            None => return,
        };

        // Determine if predicate ("is admin") or capability ("can publish")
        if self.check_copula() {
            // "A User is admin if..."
            self.advance(); // consume "is"

            // Get predicate name (e.g., "admin")
            let predicate_name = match self.consume_noun_or_proper() {
                Some(sym) => sym,
                None => return,
            };

            // Expect "if"
            if !self.check_word("if") {
                self.skip_to_period();
                return;
            }
            self.advance(); // consume "if"

            // Handle multi-line condition (colon followed by indented lines)
            if self.check_colon() {
                self.advance();
            }
            if self.check_newline() {
                self.advance();
            }
            if self.check_indent() {
                self.advance();
            }

            // Parse condition
            let condition = self.parse_policy_condition(subject_type, None);

            registry.register_predicate(PredicateDef {
                subject_type,
                predicate_name,
                condition,
            });

            self.skip_to_period();
        } else if self.check_word("can") {
            // "A User can publish the Document if..."
            self.advance(); // consume "can"

            // Get action name (e.g., "publish")
            let action = match self.consume_noun_or_proper() {
                Some(sym) => sym,
                None => {
                    // Try verb token
                    if let Some(Token { kind: TokenType::Verb { lemma, .. }, .. }) = self.peek() {
                        let sym = *lemma;
                        self.advance();
                        sym
                    } else {
                        return;
                    }
                }
            };

            // Skip "the" article if present
            if self.check_article() {
                self.advance();
            }

            // Get object type (e.g., "Document")
            let object_type = match self.consume_noun_or_proper() {
                Some(sym) => sym,
                None => return,
            };

            // Expect "if"
            if !self.check_word("if") {
                self.skip_to_period();
                return;
            }
            self.advance(); // consume "if"

            // Parse condition (may include colon for multi-line)
            if self.check_colon() {
                self.advance();
            }
            if self.check_newline() {
                self.advance();
            }
            if self.check_indent() {
                self.advance();
            }

            let condition = self.parse_policy_condition(subject_type, Some(object_type));

            registry.register_capability(CapabilityDef {
                subject_type,
                action,
                object_type,
                condition,
            });

            // Skip to end of definition (may span multiple lines)
            self.skip_policy_definition();
        } else {
            self.skip_to_period();
        }
    }

    /// Phase 50: Parse a policy condition
    /// Handles: field comparisons, predicate references, and OR/AND combinators
    fn parse_policy_condition(&mut self, subject_type: Symbol, object_type: Option<Symbol>) -> PolicyCondition {
        let first = self.parse_atomic_condition(subject_type, object_type);

        // Check for OR/AND combinators
        loop {
            // Skip newlines between conditions
            while self.check_newline() {
                self.advance();
            }

            // Handle ", AND" or ", OR" patterns
            if self.check_comma() {
                self.advance(); // consume comma
                // Skip whitespace after comma
                while self.check_newline() {
                    self.advance();
                }
            }

            if self.check_word("AND") {
                self.advance();
                // Skip newlines after AND
                while self.check_newline() {
                    self.advance();
                }
                let right = self.parse_atomic_condition(subject_type, object_type);
                return PolicyCondition::And(Box::new(first), Box::new(right));
            } else if self.check_word("OR") {
                self.advance();
                // Skip newlines after OR
                while self.check_newline() {
                    self.advance();
                }
                let right = self.parse_atomic_condition(subject_type, object_type);
                return PolicyCondition::Or(Box::new(first), Box::new(right));
            } else {
                break;
            }
        }

        first
    }

    /// Phase 50: Parse an atomic condition
    fn parse_atomic_condition(&mut self, subject_type: Symbol, object_type: Option<Symbol>) -> PolicyCondition {
        // Skip "The" article if present
        if self.check_article() {
            self.advance();
        }

        // Get the subject reference (e.g., "user" or "user's role")
        let subject_ref = match self.consume_noun_or_proper() {
            Some(sym) => sym,
            None => return PolicyCondition::FieldEquals {
                field: self.interner.intern("unknown"),
                value: self.interner.intern("unknown"),
                is_string_literal: false,
            },
        };

        // Check if it's a field access ("'s role") or a predicate ("is admin")
        if self.check_possessive() {
            self.advance(); // consume "'s"

            // Get field name
            let field = match self.consume_noun_or_proper() {
                Some(sym) => sym,
                None => return PolicyCondition::FieldEquals {
                    field: self.interner.intern("unknown"),
                    value: self.interner.intern("unknown"),
                    is_string_literal: false,
                },
            };

            // Expect "equals"
            if self.check_word("equals") {
                self.advance();

                // Get value (string literal or identifier)
                let (value, is_string_literal) = self.consume_value();

                return PolicyCondition::FieldEquals { field, value, is_string_literal };
            }
        } else if self.check_copula() {
            // "user is admin"
            self.advance(); // consume "is"

            // Get predicate name
            let predicate = match self.consume_noun_or_proper() {
                Some(sym) => sym,
                None => return PolicyCondition::FieldEquals {
                    field: self.interner.intern("unknown"),
                    value: self.interner.intern("unknown"),
                    is_string_literal: false,
                },
            };

            return PolicyCondition::Predicate {
                subject: subject_ref,
                predicate,
            };
        } else if self.check_word("equals") {
            // "user equals the document's owner"
            self.advance(); // consume "equals"

            // Skip "the" if present
            if self.check_article() {
                self.advance();
            }

            // Check for object field reference: "document's owner"
            if let Some(obj_ref) = self.consume_noun_or_proper() {
                if self.check_possessive() {
                    self.advance(); // consume "'s"
                    if let Some(field) = self.consume_noun_or_proper() {
                        return PolicyCondition::ObjectFieldEquals {
                            subject: subject_ref,
                            object: obj_ref,
                            field,
                        };
                    }
                }
            }
        }

        // Fallback: unknown condition
        PolicyCondition::FieldEquals {
            field: self.interner.intern("unknown"),
            value: self.interner.intern("unknown"),
            is_string_literal: false,
        }
    }

    /// Consume a value (string literal or identifier), returning the symbol and whether it was a string literal
    fn consume_value(&mut self) -> (Symbol, bool) {
        if let Some(Token { kind: TokenType::StringLiteral(sym), .. }) = self.peek() {
            let s = *sym;
            self.advance();
            (s, true)
        } else if let Some(sym) = self.consume_noun_or_proper() {
            (sym, false)
        } else {
            (self.interner.intern("unknown"), false)
        }
    }

    /// Check for possessive marker ('s)
    fn check_possessive(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::Possessive, .. }))
    }

    /// Skip to end of a multi-line policy definition
    fn skip_policy_definition(&mut self) {
        let mut depth = 0;
        while self.pos < self.tokens.len() {
            if self.check_indent() {
                depth += 1;
            } else if self.check_dedent() {
                if depth == 0 {
                    break;
                }
                depth -= 1;
            }
            if self.check_period() && depth == 0 {
                self.advance();
                break;
            }
            if matches!(self.peek(), Some(Token { kind: TokenType::BlockHeader { .. }, .. })) {
                break;
            }
            self.advance();
        }
    }

    /// Parse inline type definition where article was part of block header (## A Point has:)
    fn parse_type_definition_inline(&mut self, registry: &mut TypeRegistry) {
        // Don't skip article - it was part of the block header
        self.parse_type_definition_body(registry);
    }

    fn try_parse_type_definition(&mut self, registry: &mut TypeRegistry) {
        self.advance(); // skip article
        self.parse_type_definition_body(registry);
    }

    fn parse_type_definition_body(&mut self, registry: &mut TypeRegistry) {
        if let Some(name_sym) = self.consume_noun_or_proper() {
            // Phase 34: Check for "of [T]" which indicates user-defined generic
            let type_params = if self.check_preposition("of") {
                self.advance(); // consume "of"
                self.parse_type_params()
            } else {
                vec![]
            };

            // Phase 47/49: Check for "is Portable/Shared and" pattern before "has:"
            let mut is_portable = false;
            let mut is_shared = false;
            if self.check_copula() {
                let copula_pos = self.pos;
                self.advance(); // consume is/are

                // Check for modifiers in any order (e.g., "is Shared and Portable and")
                loop {
                    if self.check_portable() {
                        self.advance(); // consume "Portable"
                        is_portable = true;
                        if self.check_word("and") {
                            self.advance(); // consume "and"
                        }
                    } else if self.check_shared() {
                        self.advance(); // consume "Shared"
                        is_shared = true;
                        if self.check_word("and") {
                            self.advance(); // consume "and"
                        }
                    } else {
                        break;
                    }
                }

                // If no modifiers were found, restore position
                if !is_portable && !is_shared {
                    self.pos = copula_pos;
                }
            }

            // Phase 31/34: Check for "has:" which indicates struct with fields
            // Pattern: "A Point has:" or "A Box of [T] has:" or "A Message is Portable and has:"
            if self.check_word("has") {
                self.advance(); // consume "has"
                if self.check_colon() {
                    self.advance(); // consume ":"
                    // Skip newline if present
                    if self.check_newline() {
                        self.advance();
                    }
                    if self.check_indent() {
                        self.advance(); // consume INDENT
                        let fields = self.parse_struct_fields_with_params(&type_params);
                        registry.register(name_sym, TypeDef::Struct { fields, generics: type_params, is_portable, is_shared });
                        return;
                    }
                }
            }

            // Check for "is either:" or "is one of:" pattern (Phase 33/34: Sum types with variants)
            if self.check_copula() {
                self.advance(); // consume is/are

                // Phase 33: Check for "either:" or "one of:" pattern
                let is_enum_pattern = if self.check_either() {
                    self.advance(); // consume "either"
                    true
                } else if self.check_word("one") {
                    self.advance(); // consume "one"
                    if self.check_word("of") {
                        self.advance(); // consume "of"
                        true
                    } else {
                        false
                    }
                } else {
                    false
                };

                if is_enum_pattern {
                    if self.check_colon() {
                        self.advance(); // consume ":"
                        // Skip newline if present
                        if self.check_newline() {
                            self.advance();
                        }
                        if self.check_indent() {
                            self.advance(); // consume INDENT
                            let variants = self.parse_enum_variants_with_params(&type_params);
                            registry.register(name_sym, TypeDef::Enum { variants, generics: type_params, is_portable, is_shared });
                            return;
                        }
                    }
                }

                if self.check_article() {
                    self.advance(); // consume a/an

                    // Look for type indicators
                    if self.check_word("generic") {
                        registry.register(name_sym, TypeDef::Generic { param_count: 1 });
                        self.skip_to_period();
                    } else if self.check_word("record") || self.check_word("struct") || self.check_word("structure") {
                        registry.register(name_sym, TypeDef::Struct { fields: vec![], generics: vec![], is_portable: false, is_shared: false });
                        self.skip_to_period();
                    } else if self.check_word("sum") || self.check_word("enum") || self.check_word("choice") {
                        registry.register(name_sym, TypeDef::Enum { variants: vec![], generics: vec![], is_portable: false, is_shared: false });
                        self.skip_to_period();
                    }
                }
            } else if !type_params.is_empty() {
                // "A Stack of [Things] is..." - old generic syntax, still supported
                registry.register(name_sym, TypeDef::Generic { param_count: type_params.len() });
                self.skip_to_period();
            }
        }
    }

    /// Phase 33/34: Parse enum variants in "is either:" block
    /// Each variant: "A VariantName." or "A VariantName with a field, which is Type."
    /// or concise: "A VariantName (field: Type)."
    fn parse_enum_variants_with_params(&mut self, type_params: &[Symbol]) -> Vec<VariantDef> {
        let mut variants = Vec::new();

        while self.pos < self.tokens.len() {
            // Exit on dedent or next block
            if self.check_dedent() {
                self.advance();
                break;
            }
            if matches!(self.peek(), Some(Token { kind: TokenType::BlockHeader { .. }, .. })) {
                break;
            }

            // Skip newlines between variants
            if self.check_newline() {
                self.advance();
                continue;
            }

            // Parse variant: "A VariantName [with fields | (field: Type)]." or bare "VariantName."
            // Optionally consume article (a/an) if present
            if self.check_article() {
                self.advance(); // consume "A"/"An"
            }

            // Try to parse variant name (noun or proper name)
            if let Some(variant_name) = self.consume_noun_or_proper() {
                // Check for payload fields
                let fields = if self.check_word("with") {
                    // Natural syntax: "A Circle with a radius, which is Int."
                    self.parse_variant_fields_natural_with_params(type_params)
                } else if self.check_lparen() {
                    // Concise syntax: "A Circle (radius: Int)."
                    self.parse_variant_fields_concise_with_params(type_params)
                } else {
                    // Unit variant: "A Point." or "Point."
                    vec![]
                };

                variants.push(VariantDef {
                    name: variant_name,
                    fields,
                });

                // Consume period
                if self.check_period() {
                    self.advance();
                }
            } else {
                self.advance(); // skip malformed token
            }
        }

        variants
    }

    /// Phase 33: Parse enum variants (backward compat wrapper)
    fn parse_enum_variants(&mut self) -> Vec<VariantDef> {
        self.parse_enum_variants_with_params(&[])
    }

    /// Parse variant fields in natural syntax.
    /// Supports multiple syntaxes:
    /// - "with a radius, which is Int." (verbose natural)
    /// - "with radius Int" (concise natural - no article/comma)
    fn parse_variant_fields_natural_with_params(&mut self, type_params: &[Symbol]) -> Vec<FieldDef> {
        let mut fields = Vec::new();

        // "with" has already been detected, consume it
        self.advance();

        loop {
            // Skip article (optional)
            if self.check_article() {
                self.advance();
            }

            // Get field name
            if let Some(field_name) = self.consume_noun_or_proper() {
                // Support multiple type annotation patterns:
                // 1. ", which is Type" (verbose)
                // 2. " Type" (concise - just a type name after field name)
                let ty = if self.check_comma() {
                    self.advance(); // consume ","
                    // Consume "which"
                    if self.check_word("which") {
                        self.advance();
                    }
                    // Consume "is"
                    if self.check_copula() {
                        self.advance();
                    }
                    self.consume_field_type_with_params(type_params)
                } else {
                    // Concise syntax: "radius Int" - type immediately follows field name
                    self.consume_field_type_with_params(type_params)
                };

                fields.push(FieldDef {
                    name: field_name,
                    ty,
                    is_public: true, // Variant fields are always public
                });

                // Check for "and" to continue: "and height Int"
                // May have comma before "and"
                if self.check_comma() {
                    self.advance(); // consume comma before "and"
                }
                if self.check_word("and") {
                    self.advance();
                    continue;
                }
            }
            break;
        }

        fields
    }

    /// Backward compat wrapper
    fn parse_variant_fields_natural(&mut self) -> Vec<FieldDef> {
        self.parse_variant_fields_natural_with_params(&[])
    }

    /// Parse variant fields in concise syntax: "(radius: Int)" or "(width: Int, height: Int)"
    fn parse_variant_fields_concise_with_params(&mut self, type_params: &[Symbol]) -> Vec<FieldDef> {
        let mut fields = Vec::new();

        // Consume "("
        self.advance();

        loop {
            // Get field name
            if let Some(field_name) = self.consume_noun_or_proper() {
                // Expect ": Type" pattern
                let ty = if self.check_colon() {
                    self.advance(); // consume ":"
                    self.consume_field_type_with_params(type_params)
                } else {
                    FieldType::Primitive(self.interner.intern("Unknown"))
                };

                fields.push(FieldDef {
                    name: field_name,
                    ty,
                    is_public: true, // Variant fields are always public
                });

                // Check for "," to continue
                if self.check_comma() {
                    self.advance();
                    continue;
                }
            }
            break;
        }

        // Consume ")"
        if self.check_rparen() {
            self.advance();
        }

        fields
    }

    /// Backward compat wrapper
    fn parse_variant_fields_concise(&mut self) -> Vec<FieldDef> {
        self.parse_variant_fields_concise_with_params(&[])
    }

    /// Parse struct fields in "has:" block
    /// Each field: "a [public] name, which is Type."
    fn parse_struct_fields_with_params(&mut self, type_params: &[Symbol]) -> Vec<FieldDef> {
        let mut fields = Vec::new();

        while self.pos < self.tokens.len() {
            // Exit on dedent or next block
            if self.check_dedent() {
                self.advance();
                break;
            }
            if matches!(self.peek(), Some(Token { kind: TokenType::BlockHeader { .. }, .. })) {
                break;
            }

            // Skip newlines between fields
            if self.check_newline() {
                self.advance();
                continue;
            }

            // Parse field: "a [public] name, which is Type." or "name: Type." (no article)
            // Check for article (optional for concise syntax)
            let has_article = self.check_article();
            if has_article {
                self.advance(); // consume "a"/"an"
            }

            // Check for "public" modifier
            let has_public_keyword = if self.check_word("public") {
                self.advance();
                true
            } else {
                false
            };
            // Visibility determined later based on syntax used
            let mut is_public = has_public_keyword;

            // Get field name - try to parse if we had article OR if next token looks like identifier
            if let Some(field_name) = self.consume_noun_or_proper() {
                // Support both syntaxes:
                // 1. "name: Type." (concise) - public by default
                // 2. "name, which is Type." (natural) - public by default
                let ty = if self.check_colon() {
                    // Concise syntax: "x: Int" - public by default
                    is_public = true;
                    self.advance(); // consume ":"
                    self.consume_field_type_with_params(type_params)
                } else if self.check_comma() {
                    // Natural syntax: "name, which is Type" - also public by default
                    is_public = true;
                    self.advance(); // consume ","
                    // Consume "which"
                    if self.check_word("which") {
                        self.advance();
                    }
                    // Consume "is"
                    if self.check_copula() {
                        self.advance();
                    }
                    self.consume_field_type_with_params(type_params)
                } else if !has_article {
                    // No colon and no article - this wasn't a field, skip
                    continue;
                } else {
                    // Fallback: unknown type
                    FieldType::Primitive(self.interner.intern("Unknown"))
                };

                fields.push(FieldDef {
                    name: field_name,
                    ty,
                    is_public,
                });

                // Consume period
                if self.check_period() {
                    self.advance();
                }
            } else if !has_article {
                // Didn't have article and couldn't get field name - skip this token
                self.advance();
            }
        }

        fields
    }

    /// Backward compat wrapper
    fn parse_struct_fields(&mut self) -> Vec<FieldDef> {
        self.parse_struct_fields_with_params(&[])
    }

    /// Parse a field type reference
    fn consume_field_type(&mut self) -> FieldType {
        // Skip article if present (e.g., "a Tally" -> "Tally")
        if self.check_article() {
            self.advance();
        }

        if let Some(name) = self.consume_noun_or_proper() {
            let name_str = self.interner.resolve(name);

            // Phase 49c: Check for bias/algorithm modifier on SharedSet: "SharedSet (AddWins) of T"
            let modified_name = if name_str == "SharedSet" || name_str == "ORSet" {
                if self.check_lparen() {
                    self.advance(); // consume "("
                    let modifier = if self.check_removewins() {
                        self.advance(); // consume "RemoveWins"
                        Some("SharedSet_RemoveWins")
                    } else if self.check_addwins() {
                        self.advance(); // consume "AddWins"
                        Some("SharedSet_AddWins")
                    } else {
                        None
                    };
                    if self.check_rparen() {
                        self.advance(); // consume ")"
                    }
                    modifier.map(|m| self.interner.intern(m))
                } else {
                    None
                }
            } else if name_str == "SharedSequence" {
                // Phase 49c: Check for algorithm modifier on SharedSequence: "SharedSequence (YATA) of T"
                if self.check_lparen() {
                    self.advance(); // consume "("
                    let modifier = if self.check_yata() {
                        self.advance(); // consume "YATA"
                        Some("SharedSequence_YATA")
                    } else {
                        None
                    };
                    if self.check_rparen() {
                        self.advance(); // consume ")"
                    }
                    modifier.map(|m| self.interner.intern(m))
                } else {
                    None
                }
            } else {
                None
            };

            // Use modified name if we found a modifier, otherwise use original
            let final_name = modified_name.unwrap_or(name);
            let final_name_str = self.interner.resolve(final_name);

            // Phase 49c: Handle "SharedMap from K to V" / "ORMap from K to V" syntax
            if (final_name_str == "SharedMap" || final_name_str == "ORMap") && self.check_from() {
                self.advance(); // consume "from"
                let key_type = self.consume_field_type();
                // Expect "to" (can be TokenType::To or preposition)
                if self.check_to() {
                    self.advance(); // consume "to"
                }
                let value_type = self.consume_field_type();
                return FieldType::Generic { base: final_name, params: vec![key_type, value_type] };
            }

            // Check for generic: "List of Int", "Seq of Text"
            if self.check_preposition("of") {
                self.advance();
                let param = self.consume_field_type();
                return FieldType::Generic { base: final_name, params: vec![param] };
            }

            // Phase 49b: "Divergent T" syntax (no "of" required)
            if final_name_str == "Divergent" {
                // Next token should be the inner type
                let param = self.consume_field_type();
                return FieldType::Generic { base: final_name, params: vec![param] };
            }

            // Check if primitive
            match final_name_str {
                "Int" | "Nat" | "Text" | "Bool" | "Real" | "Unit" => FieldType::Primitive(final_name),
                _ => FieldType::Named(final_name),
            }
        } else {
            FieldType::Primitive(self.interner.intern("Unknown"))
        }
    }

    // Helper methods
    fn peek(&self) -> Option<&Token> {
        self.tokens.get(self.pos)
    }

    fn advance(&mut self) {
        if self.pos < self.tokens.len() {
            self.pos += 1;
        }
    }

    fn check_article(&self) -> bool {
        match self.peek() {
            Some(Token { kind: TokenType::Article(_), .. }) => true,
            // Also accept ProperName("A") / ProperName("An") which can occur at line starts
            Some(Token { kind: TokenType::ProperName(sym), .. }) => {
                let text = self.interner.resolve(*sym);
                text.eq_ignore_ascii_case("a") || text.eq_ignore_ascii_case("an")
            }
            _ => false,
        }
    }

    fn check_copula(&self) -> bool {
        match self.peek() {
            Some(Token { kind: TokenType::Is | TokenType::Are, .. }) => true,
            // Also match "is" when tokenized as a verb (common in declarative mode)
            Some(Token { kind: TokenType::Verb { lemma, .. }, .. }) => {
                let word = self.interner.resolve(*lemma).to_lowercase();
                word == "is" || word == "are"
            }
            _ => false,
        }
    }

    fn check_preposition(&self, word: &str) -> bool {
        if let Some(Token { kind: TokenType::Preposition(sym), .. }) = self.peek() {
            self.interner.resolve(*sym) == word
        } else {
            false
        }
    }

    fn consume_noun_or_proper(&mut self) -> Option<Symbol> {
        let t = self.peek()?;
        match &t.kind {
            TokenType::Noun(s) | TokenType::ProperName(s) => {
                let sym = *s;
                self.advance();
                Some(sym)
            }
            // Phase 31: Also accept Adjective as identifier (for field names like "x")
            TokenType::Adjective(s) => {
                let sym = *s;
                self.advance();
                Some(sym)
            }
            // Phase 47: Accept Performative as type name (for agent messages like "Command")
            TokenType::Performative(s) => {
                let sym = *s;
                self.advance();
                Some(sym)
            }
            // Phase 34: Accept special tokens as identifiers using their lexeme
            TokenType::Items | TokenType::Some => {
                let sym = t.lexeme;
                self.advance();
                Some(sym)
            }
            // Phase 49/50: Accept Verb tokens as identifiers
            // - Uppercase verbs like "Setting" are type names
            // - Lowercase verbs like "trusted", "privileged" are predicate names
            // Use lexeme to preserve the original word (not lemma which strips suffixes)
            TokenType::Verb { .. } => {
                let sym = t.lexeme;
                self.advance();
                Some(sym)
            }
            // Phase 49b: Accept CRDT type tokens as type names
            TokenType::Tally => {
                self.advance();
                Some(self.interner.intern("Tally"))
            }
            TokenType::SharedSet => {
                self.advance();
                Some(self.interner.intern("SharedSet"))
            }
            TokenType::SharedSequence => {
                self.advance();
                Some(self.interner.intern("SharedSequence"))
            }
            TokenType::CollaborativeSequence => {
                self.advance();
                Some(self.interner.intern("CollaborativeSequence"))
            }
            TokenType::SharedMap => {
                self.advance();
                Some(self.interner.intern("SharedMap"))
            }
            TokenType::Divergent => {
                self.advance();
                Some(self.interner.intern("Divergent"))
            }
            // Phase 49: Accept Ambiguous tokens (e.g., "name" could be verb or noun)
            // Use lexeme to get the original word
            TokenType::Ambiguous { .. } => {
                let sym = t.lexeme;
                self.advance();
                Some(sym)
            }
            _ => None
        }
    }

    fn check_word(&self, word: &str) -> bool {
        if let Some(token) = self.peek() {
            // Check against the lexeme of the token
            self.interner.resolve(token.lexeme).eq_ignore_ascii_case(word)
        } else {
            false
        }
    }

    fn skip_to_period(&mut self) {
        while self.pos < self.tokens.len() {
            if matches!(self.peek(), Some(Token { kind: TokenType::Period, .. })) {
                self.advance();
                break;
            }
            self.advance();
        }
    }

    fn check_colon(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::Colon, .. }))
    }

    fn check_newline(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::Newline, .. }))
    }

    fn check_indent(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::Indent, .. }))
    }

    fn check_dedent(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::Dedent, .. }))
    }

    fn check_comma(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::Comma, .. }))
    }

    fn check_period(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::Period, .. }))
    }

    fn check_either(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::Either, .. }))
    }

    fn check_lparen(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::LParen, .. }))
    }

    fn check_rparen(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::RParen, .. }))
    }

    /// Phase 49c: Check for AddWins token
    fn check_addwins(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::AddWins, .. }))
    }

    /// Phase 49c: Check for RemoveWins token
    fn check_removewins(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::RemoveWins, .. }))
    }

    /// Phase 49c: Check for YATA token
    fn check_yata(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::YATA, .. }))
    }

    /// Phase 49c: Check for "to" (either TokenType::To or preposition "to")
    fn check_to(&self) -> bool {
        match self.peek() {
            Some(Token { kind: TokenType::To, .. }) => true,
            Some(Token { kind: TokenType::Preposition(sym), .. }) => {
                self.interner.resolve(*sym) == "to"
            }
            _ => false,
        }
    }

    /// Phase 49c: Check for "from" (either TokenType::From or preposition "from")
    fn check_from(&self) -> bool {
        match self.peek() {
            Some(Token { kind: TokenType::From, .. }) => true,
            Some(Token { kind: TokenType::Preposition(sym), .. }) => {
                self.interner.resolve(*sym) == "from"
            }
            _ => false,
        }
    }

    /// Phase 47: Check for Portable token
    fn check_portable(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::Portable, .. }))
    }

    /// Phase 49: Check for Shared token
    fn check_shared(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::Shared, .. }))
    }

    // Phase 34: Bracket checks for type parameters
    fn check_lbracket(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::LBracket, .. }))
    }

    fn check_rbracket(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::RBracket, .. }))
    }

    /// Phase 34: Parse type parameters in brackets: "[T]" or "[A] and [B]"
    fn parse_type_params(&mut self) -> Vec<Symbol> {
        let mut params = Vec::new();

        loop {
            if self.check_lbracket() {
                self.advance(); // consume [
                if let Some(param) = self.consume_noun_or_proper() {
                    params.push(param);
                }
                if self.check_rbracket() {
                    self.advance(); // consume ]
                }
            }

            // Check for "and" separator for multi-param generics
            if self.check_word("and") {
                self.advance();
                continue;
            }
            break;
        }
        params
    }

    /// Phase 34: Parse a field type reference, recognizing type parameters
    fn consume_field_type_with_params(&mut self, type_params: &[Symbol]) -> FieldType {
        // Phase 34: Single-letter type params like "A" may be tokenized as Article
        // Check for Article that matches a type param first
        if let Some(Token { kind: TokenType::Article(_), lexeme, .. }) = self.peek() {
            let text = self.interner.resolve(*lexeme);
            // Find matching type param by name (case-insensitive for single letters)
            for &param_sym in type_params {
                let param_name = self.interner.resolve(param_sym);
                if text.eq_ignore_ascii_case(param_name) {
                    self.advance(); // consume the article token
                    return FieldType::TypeParam(param_sym);
                }
            }
            // Article didn't match a type param, skip it (e.g., "a Tally" -> "Tally")
            self.advance();
        }

        if let Some(name) = self.consume_noun_or_proper() {
            // Check if this is a type parameter reference
            if type_params.contains(&name) {
                return FieldType::TypeParam(name);
            }

            let name_str = self.interner.resolve(name);

            // Phase 49c: Check for bias/algorithm modifier on SharedSet: "SharedSet (AddWins) of T"
            let modified_name = if name_str == "SharedSet" || name_str == "ORSet" {
                if self.check_lparen() {
                    self.advance(); // consume "("
                    let modifier = if self.check_removewins() {
                        self.advance(); // consume "RemoveWins"
                        Some("SharedSet_RemoveWins")
                    } else if self.check_addwins() {
                        self.advance(); // consume "AddWins"
                        Some("SharedSet_AddWins")
                    } else {
                        None
                    };
                    if self.check_rparen() {
                        self.advance(); // consume ")"
                    }
                    modifier.map(|m| self.interner.intern(m))
                } else {
                    None
                }
            } else if name_str == "SharedSequence" {
                // Phase 49c: Check for algorithm modifier on SharedSequence: "SharedSequence (YATA) of T"
                if self.check_lparen() {
                    self.advance(); // consume "("
                    let modifier = if self.check_yata() {
                        self.advance(); // consume "YATA"
                        Some("SharedSequence_YATA")
                    } else {
                        None
                    };
                    if self.check_rparen() {
                        self.advance(); // consume ")"
                    }
                    modifier.map(|m| self.interner.intern(m))
                } else {
                    None
                }
            } else {
                None
            };

            // Use modified name if we found a modifier, otherwise use original
            let final_name = modified_name.unwrap_or(name);
            let final_name_str = self.interner.resolve(final_name);

            // Phase 49c: Handle "SharedMap from K to V" / "ORMap from K to V" syntax
            if (final_name_str == "SharedMap" || final_name_str == "ORMap") && self.check_from() {
                self.advance(); // consume "from"
                let key_type = self.consume_field_type_with_params(type_params);
                // Expect "to" (can be TokenType::To or preposition)
                if self.check_to() {
                    self.advance(); // consume "to"
                }
                let value_type = self.consume_field_type_with_params(type_params);
                return FieldType::Generic { base: final_name, params: vec![key_type, value_type] };
            }

            // Check for generic: "List of Int", "Seq of Text", "List of T"
            if self.check_preposition("of") {
                self.advance();
                let param = self.consume_field_type_with_params(type_params);
                return FieldType::Generic { base: final_name, params: vec![param] };
            }

            // Phase 49b: "Divergent T" syntax (no "of" required)
            if final_name_str == "Divergent" {
                // Next token should be the inner type
                let param = self.consume_field_type_with_params(type_params);
                return FieldType::Generic { base: final_name, params: vec![param] };
            }

            // Check if primitive
            match final_name_str {
                "Int" | "Nat" | "Text" | "Bool" | "Real" | "Unit" => FieldType::Primitive(final_name),
                _ => FieldType::Named(final_name),
            }
        } else {
            FieldType::Primitive(self.interner.intern("Unknown"))
        }
    }
}

/// Phase 36: Recursive discovery with module imports.
///
/// This function scans a LOGOS source file for:
/// 1. Dependencies declared in the Abstract (Markdown links)
/// 2. Type definitions in ## Definition blocks
///
/// Dependencies are loaded recursively, and their types are merged into
/// the registry with namespace prefixes (e.g., "Geometry::Point").
#[cfg(not(target_arch = "wasm32"))]
pub fn discover_with_imports(
    file_path: &Path,
    source: &str,
    loader: &mut Loader,
    interner: &mut Interner,
) -> Result<TypeRegistry, String> {
    use crate::Lexer;
    use crate::mwe;

    let mut registry = TypeRegistry::with_primitives(interner);

    // 1. Scan for dependencies in the abstract
    let deps = scan_dependencies(source);

    // 2. For each dependency, recursively discover types
    for dep in deps {
        let module_source = loader.resolve(file_path, &dep.uri)?;
        let dep_content = module_source.content.clone();
        let dep_path = module_source.path.clone();

        // Recursively discover types in the dependency
        let dep_registry = discover_with_imports(
            &dep_path,
            &dep_content,
            loader,
            interner
        )?;

        // Merge with namespace prefix
        merge_registry(&mut registry, &dep.alias, dep_registry, interner);
    }

    // 3. Scan local definitions using existing DiscoveryPass
    let mut lexer = Lexer::new(source, interner);
    let tokens = lexer.tokenize();
    let mwe_trie = mwe::build_mwe_trie();
    let tokens = mwe::apply_mwe_pipeline(tokens, &mwe_trie, interner);

    let mut discovery = DiscoveryPass::new(&tokens, interner);
    let local_registry = discovery.run();

    // Merge local types (without namespace prefix)
    for (sym, def) in local_registry.iter_types() {
        // Skip primitives (already in registry)
        let name = interner.resolve(*sym);
        if !["Int", "Nat", "Text", "Bool", "Real", "Unit"].contains(&name) {
            registry.register(*sym, def.clone());
        }
    }

    Ok(registry)
}

/// Merges types from a dependency registry into the main registry with namespace prefix.
#[cfg(not(target_arch = "wasm32"))]
fn merge_registry(
    main: &mut TypeRegistry,
    namespace: &str,
    dep: TypeRegistry,
    interner: &mut Interner,
) {
    for (sym, def) in dep.iter_types() {
        let name = interner.resolve(*sym);
        // Skip primitives
        if ["Int", "Nat", "Text", "Bool", "Real", "Unit"].contains(&name) {
            continue;
        }
        // Create namespaced symbol: "Geometry::Point"
        let qualified = format!("{}::{}", namespace, name);
        let new_sym = interner.intern(&qualified);
        main.register(new_sym, def.clone());
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::Lexer;
    use crate::mwe;

    fn make_tokens(source: &str, interner: &mut Interner) -> Vec<Token> {
        let mut lexer = Lexer::new(source, interner);
        let tokens = lexer.tokenize();
        let mwe_trie = mwe::build_mwe_trie();
        mwe::apply_mwe_pipeline(tokens, &mwe_trie, interner)
    }

    #[test]
    fn discovery_finds_generic_in_definition_block() {
        let source = "## Definition\nA Stack is a generic collection.";
        let mut interner = Interner::new();
        let tokens = make_tokens(source, &mut interner);

        let mut discovery = DiscoveryPass::new(&tokens, &mut interner);
        let registry = discovery.run();

        let stack = interner.intern("Stack");
        assert!(registry.is_generic(stack), "Stack should be discovered as generic");
    }

    #[test]
    fn discovery_parses_struct_with_fields() {
        let source = r#"## Definition
A Point has:
    an x, which is Int.
    a y, which is Int.
"#;
        let mut interner = Interner::new();
        let tokens = make_tokens(source, &mut interner);

        let mut discovery = DiscoveryPass::new(&tokens, &mut interner);
        let registry = discovery.run();

        let point = interner.intern("Point");
        assert!(registry.is_type(point), "Point should be registered");

        if let Some(TypeDef::Struct { fields, generics, .. }) = registry.get(point) {
            assert_eq!(fields.len(), 2, "Point should have 2 fields, got {:?}", fields);
            assert_eq!(interner.resolve(fields[0].name), "x");
            assert_eq!(interner.resolve(fields[1].name), "y");
            assert!(generics.is_empty(), "Point should have no generics");
        } else {
            panic!("Point should be a struct with fields");
        }
    }

    #[test]
    fn discovery_works_with_markdown_header() {
        // Phase 36: LOGOS files have `# Header` before `## Definition`
        let source = r#"# Geometry

## Definition
A Point has:
    an x, which is Int.
"#;
        let mut interner = Interner::new();
        let tokens = make_tokens(source, &mut interner);

        // Debug: print tokens to see what we're getting
        for (i, tok) in tokens.iter().enumerate() {
            eprintln!("Token {}: {:?}", i, tok.kind);
        }

        let mut discovery = DiscoveryPass::new(&tokens, &mut interner);
        let registry = discovery.run();
        let point = interner.intern("Point");
        assert!(registry.is_type(point), "Point should be discovered even with # header");
    }

    #[test]
    fn discovery_parses_portable_enum() {
        let source = r#"## Definition
A Command is Portable and is either:
    a Start.
    a Stop.
    a Pause.
"#;
        let mut interner = Interner::new();
        let tokens = make_tokens(source, &mut interner);

        // Debug: print tokens to see what we're getting
        eprintln!("Tokens for portable enum:");
        for (i, tok) in tokens.iter().enumerate() {
            eprintln!("Token {}: {:?} ({})", i, tok.kind, interner.resolve(tok.lexeme));
        }

        let mut discovery = DiscoveryPass::new(&tokens, &mut interner);
        let registry = discovery.run();

        let command = interner.intern("Command");
        assert!(registry.is_type(command), "Command should be registered as type");

        if let Some(TypeDef::Enum { variants, is_portable, .. }) = registry.get(command) {
            eprintln!("Command is_portable: {}", is_portable);
            eprintln!("Variants: {:?}", variants.iter().map(|v| interner.resolve(v.name)).collect::<Vec<_>>());
            assert!(*is_portable, "Command should be portable");
            assert_eq!(variants.len(), 3, "Command should have 3 variants");
        } else {
            panic!("Command should be an enum, got: {:?}", registry.get(command));
        }
    }

    #[test]
    fn discovery_parses_lww_int_field() {
        let source = r#"## Definition
A Setting is Shared and has:
    a volume, which is LastWriteWins of Int.
"#;
        let mut interner = Interner::new();
        let tokens = make_tokens(source, &mut interner);

        // Debug: print tokens
        eprintln!("Tokens for LWW of Int:");
        for (i, tok) in tokens.iter().enumerate() {
            eprintln!("{:3}: {:?} ({})", i, tok.kind, interner.resolve(tok.lexeme));
        }

        let mut discovery = DiscoveryPass::new(&tokens, &mut interner);
        let registry = discovery.run();

        let setting = interner.intern("Setting");
        assert!(registry.is_type(setting), "Setting should be registered");

        if let Some(TypeDef::Struct { fields, is_shared, .. }) = registry.get(setting) {
            eprintln!("is_shared: {}", is_shared);
            eprintln!("Fields: {:?}", fields.len());
            for f in fields {
                eprintln!("  field: {} = {:?}", interner.resolve(f.name), f.ty);
            }
            assert!(*is_shared, "Setting should be shared");
            assert_eq!(fields.len(), 1, "Setting should have 1 field");
        } else {
            panic!("Setting should be a struct, got: {:?}", registry.get(setting));
        }
    }
}

```

---

## Logos Core Runtime

Standard library for compiled programs.
//! LOGOS Runtime Library

pub mod io;
pub mod types;
// Phase 53: Virtual File System (cross-platform)
pub mod fs;
// Phase 49: CRDT primitives (cross-platform)
pub mod crdt;
// Phase 55: Persistent storage (cross-platform, uses async-lock)
pub mod storage;
// Phase 56: Distributed<T> - unified persistence + network (cross-platform)
pub mod distributed;
// Phase 57: Polymorphic indexing (Vec + HashMap)
pub mod indexing;

// Native-only modules
#[cfg(not(target_arch = "wasm32"))]
pub mod file;
#[cfg(not(target_arch = "wasm32"))]
pub mod time;
#[cfg(not(target_arch = "wasm32"))]
pub mod random;
#[cfg(not(target_arch = "wasm32"))]
pub mod env;
#[cfg(not(target_arch = "wasm32"))]
pub mod memory;
#[cfg(not(target_arch = "wasm32"))]
pub mod network;
// Phase 54: Go-like concurrency primitives (native only)
#[cfg(not(target_arch = "wasm32"))]
pub mod concurrency;

// Phase 51: Re-export tokio for async main support (native only)
#[cfg(not(target_arch = "wasm32"))]
pub use tokio;

pub fn panic_with(reason: &str) -> ! {
    panic!("{}", reason);
}

pub mod fmt {
    pub fn format<T: std::fmt::Display>(x: T) -> String {
        format!("{}", x)
    }
}

pub mod prelude {
    pub use crate::io::{show, read_line, println, eprintln, print, Showable};
    pub use crate::types::{Nat, Int, Real, Text, Bool, Unit, Char, Byte, Seq, Map, Set, LogosContains, Value, Tuple};
    pub use crate::panic_with;
    pub use crate::fmt::format;
    // Phase 57: Polymorphic indexing traits
    pub use crate::indexing::{LogosIndex, LogosIndexMut};
    // Phase 49: CRDT primitives
    pub use crate::crdt::{GCounter, LWWRegister, Merge};
    // Phase 56: Distributed<T>
    pub use crate::distributed::Distributed;

    // Native-only prelude exports
    #[cfg(not(target_arch = "wasm32"))]
    pub use crate::file::{read, write};
    #[cfg(not(target_arch = "wasm32"))]
    pub use crate::time::{now, sleep};
    #[cfg(not(target_arch = "wasm32"))]
    pub use crate::random::{randomInt, randomFloat};
    #[cfg(not(target_arch = "wasm32"))]
    pub use crate::env::{get, args};
    #[cfg(not(target_arch = "wasm32"))]
    pub use crate::memory::Zone;
    #[cfg(not(target_arch = "wasm32"))]
    pub use crate::network::{FileSipper, FileManifest, FileChunk};
    // Phase 54: Go-like concurrency primitives
    #[cfg(not(target_arch = "wasm32"))]
    pub use crate::concurrency::{
        spawn, TaskHandle,
        Pipe, PipeSender, PipeReceiver,
        check_preemption, reset_preemption_timer,
    };
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_format() {
        assert_eq!(fmt::format(42), "42");
        assert_eq!(fmt::format("hello"), "hello");
    }

    #[test]
    fn test_type_aliases() {
        let _n: types::Nat = 42;
        let _i: types::Int = -42;
        let _r: types::Real = 3.14;
        let _t: types::Text = String::from("hello");
        let _b: types::Bool = true;
        let _u: types::Unit = ();
    }
}

```

---

//! Core Type Definitions (Spec 3.2)

use std::hash::Hash;

pub type Nat = u64;
pub type Int = i64;
pub type Real = f64;
pub type Text = String;
pub type Bool = bool;
pub type Unit = ();
pub type Char = char;
pub type Byte = u8;

// Phase 30: Collections
pub type Seq<T> = Vec<T>;

// Phase 57: Map type alias
pub type Map<K, V> = std::collections::HashMap<K, V>;

// Set collection type
pub type Set<T> = std::collections::HashSet<T>;

/// Unified contains trait for all collection types
pub trait LogosContains<T> {
    fn logos_contains(&self, value: &T) -> bool;
}

impl<T: PartialEq> LogosContains<T> for Vec<T> {
    fn logos_contains(&self, value: &T) -> bool {
        self.contains(value)
    }
}

impl<T: Eq + Hash> LogosContains<T> for std::collections::HashSet<T> {
    fn logos_contains(&self, value: &T) -> bool {
        self.contains(value)
    }
}

impl<K: Eq + Hash, V> LogosContains<K> for std::collections::HashMap<K, V> {
    fn logos_contains(&self, key: &K) -> bool {
        self.contains_key(key)
    }
}

impl LogosContains<&str> for String {
    fn logos_contains(&self, value: &&str) -> bool {
        self.contains(*value)
    }
}

impl LogosContains<char> for String {
    fn logos_contains(&self, value: &char) -> bool {
        self.contains(*value)
    }
}

// Phase 49b: LogosContains for CRDT ORSet
impl<T: Eq + Hash + Clone, B: crate::crdt::SetBias> LogosContains<T>
    for crate::crdt::ORSet<T, B>
{
    fn logos_contains(&self, value: &T) -> bool {
        self.contains(value)
    }
}

/// Dynamic value type for heterogeneous collections (tuples)
#[derive(Clone, Debug, PartialEq)]
pub enum Value {
    Int(i64),
    Float(f64),
    Bool(bool),
    Text(String),
    Char(char),
    Nothing,
}

impl std::fmt::Display for Value {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            Value::Int(n) => write!(f, "{}", n),
            Value::Float(n) => write!(f, "{}", n),
            Value::Bool(b) => write!(f, "{}", b),
            Value::Text(s) => write!(f, "{}", s),
            Value::Char(c) => write!(f, "{}", c),
            Value::Nothing => write!(f, "nothing"),
        }
    }
}

// Conversion traits for Value
impl From<i64> for Value {
    fn from(n: i64) -> Self { Value::Int(n) }
}

impl From<f64> for Value {
    fn from(n: f64) -> Self { Value::Float(n) }
}

impl From<bool> for Value {
    fn from(b: bool) -> Self { Value::Bool(b) }
}

impl From<String> for Value {
    fn from(s: String) -> Self { Value::Text(s) }
}

impl From<&str> for Value {
    fn from(s: &str) -> Self { Value::Text(s.to_string()) }
}

impl From<char> for Value {
    fn from(c: char) -> Self { Value::Char(c) }
}

/// Tuple type: Vec of heterogeneous Values (uses LogosIndex from indexing module)
pub type Tuple = Vec<Value>;

// Implement Showable for Value
impl crate::io::Showable for Value {
    fn format_show(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
        match self {
            Value::Int(n) => write!(f, "{}", n),
            Value::Float(n) => write!(f, "{}", n),
            Value::Bool(b) => write!(f, "{}", b),
            Value::Text(s) => write!(f, "{}", s),
            Value::Char(c) => write!(f, "{}", c),
            Value::Nothing => write!(f, "nothing"),
        }
    }
}

// Arithmetic operations for Value
impl std::ops::Add for Value {
    type Output = Value;

    fn add(self, other: Value) -> Value {
        match (self, other) {
            (Value::Int(a), Value::Int(b)) => Value::Int(a + b),
            (Value::Float(a), Value::Float(b)) => Value::Float(a + b),
            (Value::Int(a), Value::Float(b)) => Value::Float(a as f64 + b),
            (Value::Float(a), Value::Int(b)) => Value::Float(a + b as f64),
            (Value::Text(a), Value::Text(b)) => Value::Text(format!("{}{}", a, b)),
            _ => panic!("Cannot add these value types"),
        }
    }
}

impl std::ops::Sub for Value {
    type Output = Value;

    fn sub(self, other: Value) -> Value {
        match (self, other) {
            (Value::Int(a), Value::Int(b)) => Value::Int(a - b),
            (Value::Float(a), Value::Float(b)) => Value::Float(a - b),
            (Value::Int(a), Value::Float(b)) => Value::Float(a as f64 - b),
            (Value::Float(a), Value::Int(b)) => Value::Float(a - b as f64),
            _ => panic!("Cannot subtract these value types"),
        }
    }
}

impl std::ops::Mul for Value {
    type Output = Value;

    fn mul(self, other: Value) -> Value {
        match (self, other) {
            (Value::Int(a), Value::Int(b)) => Value::Int(a * b),
            (Value::Float(a), Value::Float(b)) => Value::Float(a * b),
            (Value::Int(a), Value::Float(b)) => Value::Float(a as f64 * b),
            (Value::Float(a), Value::Int(b)) => Value::Float(a * b as f64),
            _ => panic!("Cannot multiply these value types"),
        }
    }
}

impl std::ops::Div for Value {
    type Output = Value;

    fn div(self, other: Value) -> Value {
        match (self, other) {
            (Value::Int(a), Value::Int(b)) => Value::Int(a / b),
            (Value::Float(a), Value::Float(b)) => Value::Float(a / b),
            (Value::Int(a), Value::Float(b)) => Value::Float(a as f64 / b),
            (Value::Float(a), Value::Int(b)) => Value::Float(a / b as f64),
            _ => panic!("Cannot divide these value types"),
        }
    }
}

```

---

## Web Application

Dioxus frontend components.
//! LOGOS entry point
//!
//! Dispatches between CLI mode and web UI based on compile features.

#[cfg(all(not(target_arch = "wasm32"), feature = "cli"))]
fn main() {
    if let Err(e) = logos::cli::run_cli() {
        eprintln!("Error: {}", e);
        std::process::exit(1);
    }
}

#[cfg(any(target_arch = "wasm32", not(feature = "cli")))]
fn main() {
    dioxus::launch(logos::ui::App);
}

```

---

use dioxus::prelude::*;
use crate::ui::router::Route;
use crate::ui::state::{LicenseState, RegistryAuthState};
use crate::ui::theme;

const GLOBAL_STYLE: &str = r#"
:root {
    /* Primary colors */
    --color-primary-blue: #667eea;
    --color-primary-purple: #764ba2;
    --color-accent-blue: #60a5fa;
    --color-accent-purple: #a78bfa;

    /* Semantic colors */
    --color-success: #4ade80;
    --color-warning: #f59e0b;
    --color-error: #e06c75;
    --color-info: #60a5fa;

    /* Text colors - accessible grays (lighter for visibility) */
    --text-primary: #f0f0f0;
    --text-secondary: #b0b0b0;
    --text-tertiary: #909090;
    --text-muted: #a0a0a0;
    --text-placeholder: #808080;

    /* Font sizes - +2px for accessibility */
    --font-display-xl: 66px;
    --font-display-lg: 50px;
    --font-display-md: 34px;
    --font-heading-lg: 26px;
    --font-heading-md: 22px;
    --font-heading-sm: 20px;
    --font-body-lg: 18px;
    --font-body-md: 16px;
    --font-body-sm: 15px;
    --font-caption-lg: 14px;
    --font-caption-md: 13px;
    --font-caption-sm: 12px;

    /* Font families */
    --font-mono: 'SF Mono', 'Fira Code', 'Consolas', monospace;
    --font-sans: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif;

    /* Spacing */
    --spacing-xs: 4px;
    --spacing-sm: 8px;
    --spacing-md: 12px;
    --spacing-lg: 16px;
    --spacing-xl: 24px;
    --spacing-xxl: 32px;

    /* Border radius */
    --radius-sm: 4px;
    --radius-md: 8px;
    --radius-lg: 12px;
    --radius-xl: 16px;
    --radius-full: 9999px;
}

* {
    margin: 0;
    padding: 0;
    box-sizing: border-box;
}

html, body {
    height: 100%;
    background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
    color: var(--text-primary);
    font-family: var(--font-sans);
    font-size: var(--font-body-lg);
    overflow-x: hidden;
}

#main {
    min-height: 100vh;
}

a {
    color: inherit;
    text-decoration: none;
}

.chat-area {
    flex: 1;
    overflow-y: auto;
    padding: 30px;
    display: flex;
    flex-direction: column;
    gap: var(--spacing-lg);
}

.message {
    max-width: 75%;
    padding: 14px 20px;
    border-radius: var(--radius-xl);
    line-height: 1.6;
    animation: fadeIn 0.3s ease;
}

@keyframes fadeIn {
    from { opacity: 0; transform: translateY(10px); }
    to { opacity: 1; transform: translateY(0); }
}

.message.user {
    align-self: flex-end;
    background: linear-gradient(135deg, var(--color-primary-blue) 0%, var(--color-primary-purple) 100%);
    color: white;
    border-bottom-right-radius: var(--radius-sm);
    box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
}

.message.system {
    align-self: flex-start;
    background: rgba(255, 255, 255, 0.08);
    border: 1px solid rgba(255, 255, 255, 0.15);
    border-bottom-left-radius: var(--radius-sm);
    font-family: var(--font-mono);
    font-size: var(--font-heading-sm);
    color: #00d4ff;
    text-shadow: 0 0 20px rgba(0, 212, 255, 0.3);
}

.message.error {
    align-self: flex-start;
    background: linear-gradient(135deg, #ff6b6b 0%, #c92a2a 100%);
    color: white;
    border-bottom-left-radius: var(--radius-sm);
    font-style: italic;
    box-shadow: 0 4px 15px rgba(255, 107, 107, 0.3);
}

.input-area {
    background: rgba(0, 0, 0, 0.4);
    backdrop-filter: blur(10px);
    padding: 20px 30px;
    border-top: 1px solid rgba(255, 255, 255, 0.1);
}

.input-row {
    display: flex;
    gap: var(--spacing-md);
    align-items: center;
}

.input-row input {
    flex: 1;
    background: rgba(255, 255, 255, 0.08);
    border: 1px solid rgba(255, 255, 255, 0.2);
    border-radius: var(--radius-lg);
    padding: 14px 20px;
    font-size: var(--font-body-lg);
    color: white;
    outline: none;
    transition: all 0.2s ease;
}

.input-row input::placeholder {
    color: var(--text-placeholder);
}

.input-row input:focus {
    border-color: var(--color-primary-blue);
    box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.2);
}

.input-row button {
    background: linear-gradient(135deg, var(--color-primary-blue) 0%, var(--color-primary-purple) 100%);
    border: none;
    border-radius: var(--radius-lg);
    padding: 14px 28px;
    font-size: var(--font-body-lg);
    font-weight: 600;
    color: white;
    cursor: pointer;
    transition: all 0.2s ease;
    box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
}

.input-row button:hover {
    transform: translateY(-2px);
    box-shadow: 0 6px 20px rgba(102, 126, 234, 0.4);
}

.input-row button:active {
    transform: translateY(0);
}

/* Interactive reveal section */
.reveal-section {
    margin-top: var(--spacing-lg);
    padding-top: var(--spacing-lg);
    border-top: 1px solid rgba(255,255,255,0.06);
}

.reveal-buttons {
    display: flex;
    gap: var(--spacing-md);
    flex-wrap: wrap;
    margin-bottom: var(--spacing-lg);
}

.reveal-btn {
    padding: 10px 16px;
    border-radius: var(--radius-md);
    border: 1px solid rgba(255,255,255,0.15);
    background: rgba(255,255,255,0.05);
    color: var(--text-secondary);
    font-size: var(--font-body-sm);
    font-weight: 500;
    cursor: pointer;
    transition: all 0.2s ease;
    display: inline-flex;
    align-items: center;
    gap: 6px;
}

.reveal-btn:hover {
    background: rgba(255,255,255,0.10);
    color: var(--text-primary);
}

.reveal-btn.active {
    background: linear-gradient(135deg, rgba(96,165,250,0.2), rgba(167,139,250,0.2));
    border-color: rgba(167,139,250,0.4);
    color: var(--text-primary);
}

.revealed-content {
    padding: var(--spacing-lg);
    background: rgba(255,255,255,0.03);
    border: 1px solid rgba(255,255,255,0.08);
    border-radius: var(--radius-lg);
    margin-top: var(--spacing-md);
    animation: fadeIn 0.2s ease;
}

.revealed-label {
    font-size: var(--font-caption-sm);
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    color: var(--text-tertiary);
    margin-bottom: var(--spacing-sm);
}

.revealed-logic {
    font-family: var(--font-mono);
    font-size: var(--font-heading-sm);
    color: var(--color-accent-blue);
    padding: var(--spacing-md);
    background: rgba(96, 165, 250, 0.08);
    border-radius: var(--radius-md);
    margin: var(--spacing-md) 0;
}

/* Socratic hint box */
.socratic-hint-box {
    margin-top: var(--spacing-lg);
    padding: var(--spacing-lg);
    background: linear-gradient(135deg, rgba(167,139,250,0.08), rgba(96,165,250,0.08));
    border: 1px solid rgba(167,139,250,0.2);
    border-radius: var(--radius-lg);
    border-left: 4px solid var(--color-accent-purple);
}

.hint-header {
    display: flex;
    align-items: center;
    gap: var(--spacing-sm);
    margin-bottom: var(--spacing-sm);
    font-size: var(--font-caption-md);
    font-weight: 600;
    color: var(--color-accent-purple);
}

.hint-text {
    color: var(--text-secondary);
    line-height: 1.6;
}

/* Multiple choice options */
.multiple-choice-options {
    display: flex;
    flex-direction: column;
    gap: var(--spacing-sm);
    margin: var(--spacing-lg) 0;
}

.multiple-choice-options .reveal-btn {
    width: 100%;
    text-align: left;
    padding: var(--spacing-md) var(--spacing-lg);
    font-family: var(--font-mono);
}

.multiple-choice-options .reveal-btn.correct {
    background: rgba(74, 222, 128, 0.15);
    border-color: var(--color-success);
}

.multiple-choice-options .reveal-btn.incorrect {
    background: rgba(248, 113, 113, 0.15);
    border-color: var(--color-error);
}

/* Progress indicator */
.exercise-progress {
    display: flex;
    align-items: center;
    gap: var(--spacing-sm);
    font-size: var(--font-caption-md);
    color: var(--text-tertiary);
    margin-bottom: var(--spacing-md);
}

.progress-bar {
    flex: 1;
    height: 4px;
    background: rgba(255,255,255,0.1);
    border-radius: 2px;
    overflow: hidden;
}

.progress-fill {
    height: 100%;
    background: linear-gradient(90deg, var(--color-accent-blue), var(--color-accent-purple));
    border-radius: 2px;
    transition: width 0.3s ease;
}

.practice-score {
    font-weight: 600;
    color: var(--color-success);
}

/* Exercise mode badges */
.exercise-mode-badge {
    display: inline-flex;
    align-items: center;
    gap: 4px;
    padding: 4px 10px;
    border-radius: var(--radius-full);
    font-size: var(--font-caption-sm);
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    margin-right: var(--spacing-md);
}

.exercise-mode-badge.test {
    background: rgba(251, 191, 36, 0.15);
    color: #fbbf24;
}

.exercise-mode-badge.practice {
    background: rgba(74, 222, 128, 0.15);
    color: var(--color-success);
}
"#;

pub fn App() -> Element {
    let license_state = use_context_provider(LicenseState::new);
    let _registry_auth = use_context_provider(RegistryAuthState::new);

    use_effect(move || {
        let mut license_state = license_state.clone();
        spawn(async move {
            if license_state.has_license() && license_state.needs_revalidation() {
                license_state.validate().await;
            }
        });
    });

    rsx! {
        style { "{GLOBAL_STYLE}" }
        Router::<Route> {}
    }
}

```

---

## Problem Generator

Curriculum and exercise generation.
use include_dir::{include_dir, Dir};
use serde::Deserialize;
use std::collections::HashMap;

static CURRICULUM_DIR: Dir = include_dir!("$CARGO_MANIFEST_DIR/assets/curriculum");

#[derive(Debug, Clone, Deserialize)]
pub struct EraMeta {
    pub id: String,
    pub title: String,
    pub description: String,
    pub order: u32,
}

#[derive(Debug, Clone, Deserialize)]
pub struct ModuleMeta {
    pub id: String,
    pub title: String,
    pub pedagogy: String,
    pub order: u32,
}

#[derive(Debug, Clone, Deserialize)]
pub struct ExerciseConfig {
    pub id: String,
    #[serde(rename = "type")]
    pub exercise_type: ExerciseType,
    pub difficulty: u32,
    pub prompt: String,
    #[serde(default)]
    pub template: Option<String>,
    #[serde(default)]
    pub constraints: HashMap<String, Vec<String>>,
    #[serde(default)]
    pub hint: Option<String>,
    #[serde(default)]
    pub explanation: Option<String>,
    #[serde(default)]
    pub options: Option<Vec<String>>,
    #[serde(default)]
    pub correct: Option<usize>,
}

#[derive(Debug, Clone, Deserialize, PartialEq)]
#[serde(rename_all = "snake_case")]
pub enum ExerciseType {
    Translation,
    MultipleChoice,
    Ambiguity,
}

/// A symbol definition for the glossary
#[derive(Debug, Clone, Deserialize)]
pub struct SymbolDef {
    pub symbol: String,
    pub name: String,
    pub meaning: String,
    #[serde(default)]
    pub example: Option<String>,
}

/// A content block within a section (paragraph, definition, example, etc.)
#[derive(Debug, Clone, Deserialize)]
#[serde(tag = "type", rename_all = "snake_case")]
pub enum ContentBlock {
    Paragraph {
        text: String,
    },
    Definition {
        term: String,
        definition: String,
    },
    Example {
        title: String,
        #[serde(default)]
        premises: Vec<String>,
        #[serde(default)]
        conclusion: Option<String>,
        #[serde(default)]
        note: Option<String>,
    },
    /// Symbol glossary block - shows relevant symbols for this section
    Symbols {
        title: String,
        symbols: Vec<SymbolDef>,
    },
    /// Quiz question embedded in the lesson
    Quiz {
        question: String,
        options: Vec<String>,
        correct: usize,
        #[serde(default)]
        explanation: Option<String>,
    },
}

/// A lesson section with structured content
#[derive(Debug, Clone, Deserialize)]
pub struct Section {
    pub id: String,
    pub title: String,
    pub order: u32,
    #[serde(default)]
    pub content: Vec<ContentBlock>,
    #[serde(default)]
    pub key_symbols: Vec<String>,
}

#[derive(Debug, Clone)]
pub struct Module {
    pub meta: ModuleMeta,
    pub exercises: Vec<ExerciseConfig>,
    pub sections: Vec<Section>,
}

#[derive(Debug, Clone)]
pub struct Era {
    pub meta: EraMeta,
    pub modules: Vec<Module>,
}

#[derive(Debug, Clone)]
pub struct Curriculum {
    pub eras: Vec<Era>,
}

pub struct ContentEngine {
    pub curriculum: Curriculum,
}

impl ContentEngine {
    pub fn new() -> Self {
        let curriculum = Self::load_curriculum();
        Self { curriculum }
    }

    fn load_curriculum() -> Curriculum {
        let mut eras = Vec::new();

        for era_entry in CURRICULUM_DIR.dirs() {
            if let Some(era) = Self::load_era(era_entry) {
                eras.push(era);
            }
        }

        eras.sort_by_key(|e| e.meta.order);
        Curriculum { eras }
    }

    fn load_era(era_dir: &Dir) -> Option<Era> {
        // era_dir.path() returns "01_trivium", file paths are "01_trivium/meta.json"
        let era_path = era_dir.path().to_string_lossy();
        let meta_path = format!("{}/meta.json", era_path);
        let meta_file = era_dir.get_file(&meta_path)?;
        let meta_content = meta_file.contents_utf8()?;
        let meta: EraMeta = serde_json::from_str(meta_content).ok()?;

        let mut modules = Vec::new();
        for module_entry in era_dir.dirs() {
            if let Some(module) = Self::load_module(module_entry) {
                modules.push(module);
            }
        }

        modules.sort_by_key(|m| m.meta.order);
        Some(Era { meta, modules })
    }

    fn load_module(module_dir: &Dir) -> Option<Module> {
        // module_dir.path() returns "01_trivium/01_atomic"
        let module_path = module_dir.path().to_string_lossy();
        let meta_path = format!("{}/meta.json", module_path);
        let meta_file = module_dir.get_file(&meta_path)?;
        let meta_content = meta_file.contents_utf8()?;
        let meta: ModuleMeta = serde_json::from_str(meta_content).ok()?;

        let mut exercises = Vec::new();
        let mut sections = Vec::new();

        for file in module_dir.files() {
            if let Some(name) = file.path().file_name() {
                let name_str = name.to_string_lossy();
                if name_str.starts_with("ex_") && name_str.ends_with(".json") {
                    // Load exercise
                    if let Some(content) = file.contents_utf8() {
                        if let Ok(exercise) = serde_json::from_str::<ExerciseConfig>(content) {
                            exercises.push(exercise);
                        }
                    }
                } else if name_str.starts_with("sec_") && name_str.ends_with(".json") {
                    // Load section
                    if let Some(content) = file.contents_utf8() {
                        if let Ok(section) = serde_json::from_str::<Section>(content) {
                            sections.push(section);
                        }
                    }
                }
            }
        }

        exercises.sort_by(|a, b| a.id.cmp(&b.id));
        sections.sort_by_key(|s| s.order);
        Some(Module { meta, exercises, sections })
    }

    pub fn get_era(&self, era_id: &str) -> Option<&Era> {
        self.curriculum.eras.iter().find(|e| e.meta.id == era_id)
    }

    pub fn get_module(&self, era_id: &str, module_id: &str) -> Option<&Module> {
        self.get_era(era_id)?
            .modules
            .iter()
            .find(|m| m.meta.id == module_id)
    }

    pub fn get_exercise(&self, era_id: &str, module_id: &str, exercise_id: &str) -> Option<&ExerciseConfig> {
        self.get_module(era_id, module_id)?
            .exercises
            .iter()
            .find(|e| e.id == exercise_id)
    }

    pub fn eras(&self) -> &[Era] {
        &self.curriculum.eras
    }

    pub fn era_count(&self) -> usize {
        self.curriculum.eras.len()
    }

    pub fn module_count(&self, era_id: &str) -> usize {
        self.get_era(era_id).map(|e| e.modules.len()).unwrap_or(0)
    }

    pub fn exercise_count(&self, era_id: &str, module_id: &str) -> usize {
        self.get_module(era_id, module_id)
            .map(|m| m.exercises.len())
            .unwrap_or(0)
    }
}

impl Default for ContentEngine {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_dir_contents() {
        // Debug: print what's in the embedded directory
        println!("Files in CURRICULUM_DIR:");
        for f in CURRICULUM_DIR.files() {
            println!("  file: {:?}", f.path());
        }
        println!("Dirs in CURRICULUM_DIR:");
        for d in CURRICULUM_DIR.dirs() {
            println!("  era dir: {:?}", d.path());
            for f in d.files() {
                println!("    era file: {:?}", f.path());
            }
            for module_d in d.dirs() {
                println!("    module dir: {:?}", module_d.path());
                for f in module_d.files() {
                    println!("      module file: {:?}", f.path());
                }
            }
        }
        assert!(!CURRICULUM_DIR.dirs().collect::<Vec<_>>().is_empty(), "Should have embedded directories");
    }

    #[test]
    fn test_curriculum_loads() {
        let engine = ContentEngine::new();
        assert!(engine.era_count() >= 4, "Should have at least 4 eras (got {})", engine.era_count());
    }

    #[test]
    fn test_first_steps_era_exists() {
        let engine = ContentEngine::new();
        let era = engine.get_era("first-steps");
        assert!(era.is_some(), "First Steps era should exist");
        assert_eq!(era.unwrap().meta.title, "First Steps");
    }

    #[test]
    fn test_building_blocks_era_exists() {
        let engine = ContentEngine::new();
        let era = engine.get_era("building-blocks");
        assert!(era.is_some(), "Building Blocks era should exist");
        assert_eq!(era.unwrap().meta.title, "Building Blocks");
    }

    #[test]
    fn test_expanding_horizons_era_exists() {
        let engine = ContentEngine::new();
        let era = engine.get_era("expanding-horizons");
        assert!(era.is_some(), "Expanding Horizons era should exist");
        assert_eq!(era.unwrap().meta.title, "Expanding Horizons");
    }

    #[test]
    fn test_mastery_era_exists() {
        let engine = ContentEngine::new();
        let era = engine.get_era("mastery");
        assert!(era.is_some(), "Mastery era should exist");
        assert_eq!(era.unwrap().meta.title, "Mastery");
    }

    #[test]
    fn test_introduction_module_exists() {
        let engine = ContentEngine::new();
        let module = engine.get_module("first-steps", "introduction");
        assert!(module.is_some(), "Introduction module should exist");
        assert_eq!(module.unwrap().meta.title, "Introduction");
    }

    #[test]
    fn test_syllogistic_module_exists() {
        let engine = ContentEngine::new();
        let module = engine.get_module("first-steps", "syllogistic");
        assert!(module.is_some(), "Syllogistic module should exist");
        let m = module.unwrap();
        assert_eq!(m.meta.title, "Syllogistic Logic");
        assert!(m.exercises.len() >= 90, "Should have at least 90 exercises (got {})", m.exercises.len());
    }

    #[test]
    fn test_propositional_module_exists() {
        let engine = ContentEngine::new();
        let module = engine.get_module("building-blocks", "propositional");
        assert!(module.is_some(), "Propositional module should exist");
        let m = module.unwrap();
        assert_eq!(m.meta.title, "Basic Propositional Logic");
        assert!(m.exercises.len() >= 100, "Should have at least 100 exercises (got {})", m.exercises.len());
    }

    #[test]
    fn test_exercises_load() {
        let engine = ContentEngine::new();
        let count = engine.exercise_count("first-steps", "syllogistic");
        assert!(count >= 90, "Syllogistic module should have at least 90 exercises");
    }

    #[test]
    fn test_exercise_has_explanation() {
        let engine = ContentEngine::new();
        let ex = engine.get_exercise("first-steps", "syllogistic", "A_1.1");
        assert!(ex.is_some(), "Exercise A_1.1 should exist");
        let exercise = ex.unwrap();
        assert!(exercise.explanation.is_some(), "Exercise should have explanation");
        assert!(exercise.options.is_some(), "Exercise should have options");
        assert_eq!(exercise.exercise_type, ExerciseType::MultipleChoice);
    }

    #[test]
    fn test_all_eras_have_modules() {
        let engine = ContentEngine::new();

        // First Steps: 5 modules
        let first_steps_modules = ["introduction", "syllogistic", "definitions", "fallacies", "inductive"];
        for module in first_steps_modules {
            assert!(engine.get_module("first-steps", module).is_some(), "first-steps/{} should exist", module);
        }

        // Building Blocks: 2 modules
        let building_blocks_modules = ["propositional", "proofs"];
        for module in building_blocks_modules {
            assert!(engine.get_module("building-blocks", module).is_some(), "building-blocks/{} should exist", module);
        }

        // Expanding Horizons: 6 modules
        let expanding_modules = ["quantificational", "relations", "modal", "further_modal", "deontic", "belief"];
        for module in expanding_modules {
            assert!(engine.get_module("expanding-horizons", module).is_some(), "expanding-horizons/{} should exist", module);
        }

        // Mastery: 5 modules
        let mastery_modules = ["ethics", "metalogic", "history", "deviant", "philosophy"];
        for module in mastery_modules {
            assert!(engine.get_module("mastery", module).is_some(), "mastery/{} should exist", module);
        }
    }
}

```

---

use crate::content::{ExerciseConfig, ExerciseType};
use crate::runtime_lexicon::{LexiconIndex, pluralize, present_3s, past_tense, gerund};
use crate::compile;
use rand::Rng;
use rand::seq::SliceRandom;
use std::collections::HashMap;

pub struct Generator {
    lexicon: LexiconIndex,
}

#[derive(Debug, Clone)]
pub struct Challenge {
    pub exercise_id: String,
    pub prompt: String,
    pub sentence: String,
    pub answer: AnswerType,
    pub hint: Option<String>,
    pub explanation: Option<String>,
}

#[derive(Debug, Clone)]
pub enum AnswerType {
    FreeForm {
        golden_logic: String,
    },
    MultipleChoice {
        options: Vec<String>,
        correct_index: usize,
    },
    Ambiguity {
        readings: Vec<String>,
    },
}

impl Generator {
    pub fn new() -> Self {
        Self {
            lexicon: LexiconIndex::new(),
        }
    }

    pub fn generate(&self, exercise: &ExerciseConfig, rng: &mut impl Rng) -> Option<Challenge> {
        match exercise.exercise_type {
            ExerciseType::Translation => self.generate_translation(exercise, rng),
            ExerciseType::MultipleChoice => self.generate_multiple_choice(exercise, rng),
            ExerciseType::Ambiguity => self.generate_ambiguity(exercise, rng),
        }
    }

    fn generate_translation(&self, exercise: &ExerciseConfig, rng: &mut impl Rng) -> Option<Challenge> {
        let template = exercise.template.as_ref()?;
        let sentence = self.fill_template(template, &exercise.constraints, rng)?;

        let golden_logic = compile(&sentence).ok()?;

        Some(Challenge {
            exercise_id: exercise.id.clone(),
            prompt: exercise.prompt.clone(),
            sentence,
            answer: AnswerType::FreeForm { golden_logic },
            hint: exercise.hint.clone(),
            explanation: exercise.explanation.clone(),
        })
    }

    fn generate_multiple_choice(&self, exercise: &ExerciseConfig, rng: &mut impl Rng) -> Option<Challenge> {
        let options = exercise.options.clone()?;
        let correct_index = exercise.correct?;

        let sentence = if let Some(template) = &exercise.template {
            self.fill_template(template, &exercise.constraints, rng)?
        } else {
            exercise.prompt.clone()
        };

        Some(Challenge {
            exercise_id: exercise.id.clone(),
            prompt: exercise.prompt.clone(),
            sentence,
            answer: AnswerType::MultipleChoice { options, correct_index },
            hint: exercise.hint.clone(),
            explanation: exercise.explanation.clone(),
        })
    }

    fn generate_ambiguity(&self, exercise: &ExerciseConfig, rng: &mut impl Rng) -> Option<Challenge> {
        let template = exercise.template.as_ref()?;
        let sentence = self.fill_template(template, &exercise.constraints, rng)?;

        let readings = crate::compile_all_scopes(&sentence).ok()?;

        Some(Challenge {
            exercise_id: exercise.id.clone(),
            prompt: exercise.prompt.clone(),
            sentence,
            answer: AnswerType::Ambiguity { readings },
            hint: exercise.hint.clone(),
            explanation: exercise.explanation.clone(),
        })
    }

    fn fill_template(&self, template: &str, constraints: &HashMap<String, Vec<String>>, rng: &mut impl Rng) -> Option<String> {
        let mut result = template.to_string();
        let mut used_names: HashMap<String, String> = HashMap::new();

        while let Some(start) = result.find('{') {
            let end = result[start..].find('}')? + start;
            let slot = &result[start + 1..end];

            let (slot_type, modifier) = if let Some(colon_pos) = slot.find(':') {
                (&slot[..colon_pos], Some(&slot[colon_pos + 1..]))
            } else {
                (slot, None)
            };

            let slot_constraints = constraints.get(slot_type).map(|v| v.as_slice()).unwrap_or(&[]);
            let word = self.fill_slot(slot_type, slot_constraints, modifier, &mut used_names, rng)?;

            result = format!("{}{}{}", &result[..start], word, &result[end + 1..]);
        }

        Some(result)
    }

    fn fill_slot(
        &self,
        slot_type: &str,
        constraints: &[String],
        modifier: Option<&str>,
        used_names: &mut HashMap<String, String>,
        rng: &mut impl Rng,
    ) -> Option<String> {
        match slot_type {
            "ProperName" => {
                let key = format!("ProperName_{}", used_names.len());
                if let Some(existing) = used_names.get(&key) {
                    return Some(existing.clone());
                }

                let proper_nouns = self.lexicon.proper_nouns();
                let available: Vec<_> = proper_nouns
                    .iter()
                    .filter(|n| !used_names.values().any(|v| v == &n.lemma))
                    .copied()
                    .collect();

                let entry = if !available.is_empty() {
                    available.choose(rng)?
                } else {
                    proper_nouns.choose(rng)?
                };
                let name = entry.lemma.clone();
                used_names.insert(key, name.clone());
                Some(name)
            }
            "Noun" => {
                let nouns = if constraints.is_empty() {
                    self.lexicon.common_nouns()
                } else {
                    let mut filtered = Vec::new();
                    for constraint in constraints {
                        filtered.extend(self.lexicon.nouns_with_feature(constraint));
                    }
                    filtered
                };

                let entry = nouns.choose(rng)?;
                let word = entry.lemma.to_lowercase();

                match modifier {
                    Some("Plural") => Some(pluralize(entry)),
                    _ => Some(word),
                }
            }
            "Verb" => {
                let verbs = if constraints.contains(&"Intransitive".to_string()) {
                    self.lexicon.intransitive_verbs()
                } else if constraints.contains(&"Transitive".to_string()) {
                    self.lexicon.transitive_verbs()
                } else {
                    let mut result = Vec::new();
                    for constraint in constraints {
                        result.extend(self.lexicon.verbs_with_feature(constraint));
                    }
                    if result.is_empty() {
                        self.lexicon.intransitive_verbs()
                    } else {
                        result
                    }
                };

                let entry = verbs.choose(rng)?;

                match modifier {
                    Some("Past") => Some(past_tense(entry)),
                    Some("Gerund") => Some(gerund(entry)),
                    Some("Present3s") => Some(present_3s(entry)),
                    _ => Some(entry.lemma.to_lowercase()),
                }
            }
            "Adjective" => {
                let adjectives = if constraints.contains(&"Intersective".to_string()) {
                    self.lexicon.intersective_adjectives()
                } else if constraints.is_empty() {
                    self.lexicon.intersective_adjectives()
                } else {
                    let mut result = Vec::new();
                    for constraint in constraints {
                        result.extend(self.lexicon.adjectives_with_feature(constraint));
                    }
                    result
                };

                let entry = adjectives.choose(rng)?;
                Some(entry.lemma.to_lowercase())
            }
            _ => Some("thing".to_string()),
        }
    }
}

impl Default for Generator {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::content::ContentEngine;
    use rand::SeedableRng;
    use rand::rngs::StdRng;

    #[test]
    fn test_generate_translation_challenge() {
        let engine = ContentEngine::new();
        let generator = Generator::new();
        let mut rng = StdRng::seed_from_u64(42);

        // Use introduction module which has Translation exercises
        let exercise = engine.get_exercise("first-steps", "introduction", "I_1.1");
        assert!(exercise.is_some(), "Exercise first-steps/introduction/I_1.1 should exist");
        let exercise = exercise.unwrap();
        let challenge = generator.generate(exercise, &mut rng);

        assert!(challenge.is_some(), "Should generate a challenge");
        let challenge = challenge.unwrap();
        assert!(!challenge.sentence.is_empty(), "Sentence should not be empty");

        if let AnswerType::FreeForm { golden_logic } = &challenge.answer {
            assert!(!golden_logic.is_empty(), "Golden logic should not be empty");
        } else {
            panic!("Expected FreeForm answer type");
        }
    }

    #[test]
    fn test_generate_multiple_choice() {
        let engine = ContentEngine::new();
        let generator = Generator::new();
        let mut rng = StdRng::seed_from_u64(42);

        // Use syllogistic module which has MultipleChoice exercises
        let exercise = engine.get_exercise("first-steps", "syllogistic", "A_1.1");
        assert!(exercise.is_some(), "Exercise first-steps/syllogistic/A_1.1 should exist");
        let exercise = exercise.unwrap();
        let challenge = generator.generate(exercise, &mut rng);

        assert!(challenge.is_some(), "Should generate a challenge");
        let challenge = challenge.unwrap();

        if let AnswerType::MultipleChoice { options, correct_index } = &challenge.answer {
            assert_eq!(options.len(), 4, "Should have 4 options");
            assert!(*correct_index < options.len(), "Correct index should be within options range");
        } else {
            panic!("Expected MultipleChoice answer type");
        }
    }

    #[test]
    fn test_fill_template_proper_names() {
        let generator = Generator::new();
        let mut rng = StdRng::seed_from_u64(42);

        let constraints = HashMap::new();
        let result = generator.fill_template("{ProperName} runs.", &constraints, &mut rng);

        assert!(result.is_some());
        let sentence = result.unwrap();
        assert!(sentence.ends_with(" runs."), "Template should be filled: {}", sentence);
        assert!(!sentence.starts_with("{"), "Slot should be replaced");
    }

    #[test]
    fn test_fill_template_with_modifier() {
        let generator = Generator::new();
        let mut rng = StdRng::seed_from_u64(42);

        let constraints = HashMap::new();
        let result = generator.fill_template("All {Noun:Plural} run.", &constraints, &mut rng);

        assert!(result.is_some());
        let sentence = result.unwrap();
        assert!(!sentence.contains("{"), "All slots should be filled: {}", sentence);
    }

    #[test]
    fn test_deterministic_with_seed() {
        let generator = Generator::new();
        let mut rng1 = StdRng::seed_from_u64(12345);
        let mut rng2 = StdRng::seed_from_u64(12345);

        let constraints = HashMap::new();
        let result1 = generator.fill_template("{ProperName} is {Adjective}.", &constraints, &mut rng1);
        let result2 = generator.fill_template("{ProperName} is {Adjective}.", &constraints, &mut rng2);

        assert_eq!(result1, result2, "Same seed should produce same output");
    }

    #[test]
    fn test_all_introduction_exercises() {
        let engine = ContentEngine::new();
        let generator = Generator::new();

        let module = engine.get_module("first-steps", "introduction");
        assert!(module.is_some(), "Introduction module should exist");
        let module = module.unwrap();

        println!("Introduction module has {} exercises", module.exercises.len());

        for (i, exercise) in module.exercises.iter().enumerate() {
            let mut rng = StdRng::seed_from_u64(42 + i as u64);
            println!("Exercise {}: id={}, type={:?}", i, exercise.id, exercise.exercise_type);

            let challenge = generator.generate(exercise, &mut rng);
            if challenge.is_none() {
                println!("  FAILED to generate challenge!");
                if let Some(template) = &exercise.template {
                    println!("  Template: {}", template);
                    let filled = generator.fill_template(template, &exercise.constraints, &mut StdRng::seed_from_u64(42));
                    println!("  Filled template: {:?}", filled);
                    if let Some(sentence) = filled {
                        let compiled = crate::compile(&sentence);
                        println!("  Compile result: {:?}", compiled);
                    }
                }
            } else {
                println!("  OK: {:?}", challenge.as_ref().map(|c| &c.sentence));
            }
            assert!(challenge.is_some(), "Exercise {} ({}) should generate a challenge", i, exercise.id);
        }
    }

    #[test]
    fn test_all_exercises_across_all_modules() {
        let engine = ContentEngine::new();
        let generator = Generator::new();

        let mut total_exercises = 0;
        let mut successful = 0;
        let mut failed_exercises = Vec::new();

        for era in engine.eras() {
            for module in &era.modules {
                if let Some(m) = engine.get_module(&era.meta.id, &module.meta.id) {
                    for (i, exercise) in m.exercises.iter().enumerate() {
                        total_exercises += 1;
                        let mut rng = StdRng::seed_from_u64(42 + i as u64);

                        let challenge = generator.generate(exercise, &mut rng);
                        if challenge.is_some() {
                            successful += 1;
                        } else {
                            failed_exercises.push(format!("{}/{}/{}", era.meta.id, module.meta.id, exercise.id));
                        }
                    }
                }
            }
        }

        println!("Total exercises: {}", total_exercises);
        println!("Successful: {}", successful);
        println!("Failed: {}", failed_exercises.len());

        if !failed_exercises.is_empty() {
            println!("\nFailed exercises:");
            for ex in &failed_exercises {
                println!("  - {}", ex);
            }
        }

        // Allow some failures for now, but ensure most work
        let success_rate = successful as f64 / total_exercises as f64;
        assert!(success_rate >= 0.8, "At least 80% of exercises should generate (got {:.1}%)", success_rate * 100.0);
    }
}

```

---


#[derive(Debug, Clone)]
pub struct GradeResult {
    pub correct: bool,
    pub partial: bool,
    pub score: u32,
    pub feedback: String,
}

impl GradeResult {
    pub fn correct() -> Self {
        Self {
            correct: true,
            partial: false,
            score: 100,
            feedback: "Correct!".to_string(),
        }
    }

    pub fn partial(feedback: String, score: u32) -> Self {
        Self {
            correct: false,
            partial: true,
            score,
            feedback,
        }
    }

    pub fn incorrect(feedback: String) -> Self {
        Self {
            correct: false,
            partial: false,
            score: 0,
            feedback,
        }
    }
}

pub fn check_answer(user_input: &str, expected: &str) -> GradeResult {
    let user_normalized = normalize_logic(user_input);
    let expected_normalized = normalize_logic(expected);

    if user_normalized == expected_normalized {
        return GradeResult::correct();
    }

    let user_parsed = parse_to_normalized_ast(user_input);
    let expected_parsed = parse_to_normalized_ast(expected);

    match (user_parsed, expected_parsed) {
        (Some(user_ast), Some(expected_ast)) => {
            if structural_eq(&user_ast, &expected_ast) {
                return GradeResult::correct();
            }

            let similarity = structural_similarity(&user_ast, &expected_ast);
            if similarity > 0.7 {
                GradeResult::partial(
                    "Close! Check your quantifier or connective structure.".to_string(),
                    (similarity * 50.0) as u32,
                )
            } else if similarity > 0.4 {
                GradeResult::partial(
                    "Partially correct. Review the logical structure.".to_string(),
                    (similarity * 30.0) as u32,
                )
            } else {
                GradeResult::incorrect(
                    "Not quite. Consider the relationship between subject and predicate.".to_string(),
                )
            }
        }
        (None, _) => GradeResult::incorrect(
            "Could not parse your answer. Check syntax.".to_string(),
        ),
        (_, None) => GradeResult::incorrect(
            "Internal error: could not parse expected answer.".to_string(),
        ),
    }
}

fn normalize_logic(input: &str) -> String {
    let mut result = input.to_string();

    result = result.replace("\\forall", "∀");
    result = result.replace("\\exists", "∃");
    result = result.replace("\\neg", "¬");
    result = result.replace("\\land", "∧");
    result = result.replace("\\lor", "∨");
    result = result.replace("\\supset", "→");
    result = result.replace("\\equiv", "↔");
    result = result.replace("\\Box", "□");
    result = result.replace("\\Diamond", "◇");

    // Order matters: replace <-> before ->
    result = result.replace("<->", "↔");
    result = result.replace("->", "→");
    result = result.replace("&", "∧");
    result = result.replace("|", "∨");
    result = result.replace("~", "¬");
    result = result.replace("!", "¬");

    result = result.chars().filter(|c| !c.is_whitespace()).collect();

    result
}

#[derive(Debug, Clone)]
struct NormalizedExpr {
    kind: NormalizedKind,
}

#[derive(Debug, Clone)]
enum NormalizedKind {
    Predicate { name: String, arity: usize },
    Quantifier { kind: String, body: Box<NormalizedExpr> },
    Binary { op: String, left: Box<NormalizedExpr>, right: Box<NormalizedExpr> },
    Unary { op: String, operand: Box<NormalizedExpr> },
    Atom(String),
}

fn parse_to_normalized_ast(input: &str) -> Option<NormalizedExpr> {
    let normalized = normalize_logic(input);

    if normalized.starts_with('∀') || normalized.starts_with('∃') {
        let quantifier = if normalized.starts_with('∀') { "∀" } else { "∃" };
        let rest = &normalized[quantifier.len()..];

        if let Some(paren_start) = rest.find('(') {
            let body = &rest[paren_start..];
            if let Some(inner) = extract_balanced(body) {
                return Some(NormalizedExpr {
                    kind: NormalizedKind::Quantifier {
                        kind: quantifier.to_string(),
                        body: Box::new(parse_to_normalized_ast(&inner)?),
                    },
                });
            }
        }
    }

    if let Some(impl_pos) = find_main_connective(&normalized, "→") {
        let left = &normalized[..impl_pos];
        let right = &normalized[impl_pos + "→".len()..];
        return Some(NormalizedExpr {
            kind: NormalizedKind::Binary {
                op: "→".to_string(),
                left: Box::new(parse_to_normalized_ast(left)?),
                right: Box::new(parse_to_normalized_ast(right)?),
            },
        });
    }

    if let Some(and_pos) = find_main_connective(&normalized, "∧") {
        let left = &normalized[..and_pos];
        let right = &normalized[and_pos + "∧".len()..];
        return Some(NormalizedExpr {
            kind: NormalizedKind::Binary {
                op: "∧".to_string(),
                left: Box::new(parse_to_normalized_ast(left)?),
                right: Box::new(parse_to_normalized_ast(right)?),
            },
        });
    }

    if normalized.starts_with('¬') {
        let operand = &normalized["¬".len()..];
        return Some(NormalizedExpr {
            kind: NormalizedKind::Unary {
                op: "¬".to_string(),
                operand: Box::new(parse_to_normalized_ast(operand)?),
            },
        });
    }

    if let Some(paren_pos) = normalized.find('(') {
        let name = &normalized[..paren_pos];
        let args = &normalized[paren_pos..];
        let arity = args.matches(',').count() + 1;
        return Some(NormalizedExpr {
            kind: NormalizedKind::Predicate {
                name: name.to_string(),
                arity,
            },
        });
    }

    Some(NormalizedExpr {
        kind: NormalizedKind::Atom(normalized),
    })
}

fn extract_balanced(s: &str) -> Option<String> {
    if !s.starts_with('(') {
        return None;
    }

    let mut depth = 0;
    let mut end = 0;

    for (i, c) in s.chars().enumerate() {
        match c {
            '(' => depth += 1,
            ')' => {
                depth -= 1;
                if depth == 0 {
                    end = i;
                    break;
                }
            }
            _ => {}
        }
    }

    if depth == 0 && end > 0 {
        Some(s[1..end].to_string())
    } else {
        None
    }
}

fn find_main_connective(s: &str, connective: &str) -> Option<usize> {
    let mut depth = 0;
    let mut byte_idx = 0;

    for c in s.chars() {
        match c {
            '(' => depth += 1,
            ')' => depth -= 1,
            _ if depth == 0 && s[byte_idx..].starts_with(connective) => {
                return Some(byte_idx);
            }
            _ => {}
        }
        byte_idx += c.len_utf8();
    }

    None
}

fn structural_eq(a: &NormalizedExpr, b: &NormalizedExpr) -> bool {
    match (&a.kind, &b.kind) {
        (NormalizedKind::Predicate { name: n1, arity: a1 }, NormalizedKind::Predicate { name: n2, arity: a2 }) => {
            n1 == n2 && a1 == a2
        }
        (NormalizedKind::Quantifier { kind: k1, body: b1 }, NormalizedKind::Quantifier { kind: k2, body: b2 }) => {
            k1 == k2 && structural_eq(b1, b2)
        }
        (NormalizedKind::Binary { op: o1, left: l1, right: r1 }, NormalizedKind::Binary { op: o2, left: l2, right: r2 }) => {
            if o1 != o2 {
                return false;
            }
            if structural_eq(l1, l2) && structural_eq(r1, r2) {
                return true;
            }
            if o1 == "∧" || o1 == "∨" {
                structural_eq(l1, r2) && structural_eq(r1, l2)
            } else {
                false
            }
        }
        (NormalizedKind::Unary { op: o1, operand: op1 }, NormalizedKind::Unary { op: o2, operand: op2 }) => {
            o1 == o2 && structural_eq(op1, op2)
        }
        (NormalizedKind::Atom(a1), NormalizedKind::Atom(a2)) => a1 == a2,
        _ => false,
    }
}

fn structural_similarity(a: &NormalizedExpr, b: &NormalizedExpr) -> f64 {
    match (&a.kind, &b.kind) {
        (NormalizedKind::Predicate { name: n1, arity: a1 }, NormalizedKind::Predicate { name: n2, arity: a2 }) => {
            let name_match = if n1 == n2 { 0.7 } else { 0.0 };
            let arity_match = if a1 == a2 { 0.3 } else { 0.0 };
            name_match + arity_match
        }
        (NormalizedKind::Quantifier { kind: k1, body: b1 }, NormalizedKind::Quantifier { kind: k2, body: b2 }) => {
            let kind_match = if k1 == k2 { 0.4 } else { 0.0 };
            let body_sim = structural_similarity(b1, b2);
            kind_match + body_sim * 0.6
        }
        (NormalizedKind::Binary { op: o1, left: l1, right: r1 }, NormalizedKind::Binary { op: o2, left: l2, right: r2 }) => {
            let op_match = if o1 == o2 { 0.3 } else { 0.0 };
            let left_sim = structural_similarity(l1, l2);
            let right_sim = structural_similarity(r1, r2);
            op_match + (left_sim + right_sim) * 0.35
        }
        (NormalizedKind::Unary { op: o1, operand: op1 }, NormalizedKind::Unary { op: o2, operand: op2 }) => {
            let op_match = if o1 == o2 { 0.3 } else { 0.0 };
            op_match + structural_similarity(op1, op2) * 0.7
        }
        (NormalizedKind::Atom(a1), NormalizedKind::Atom(a2)) => {
            if a1 == a2 { 1.0 } else { 0.0 }
        }
        _ => 0.0,
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_exact_match() {
        let result = check_answer("∀x(D(x) → B(x))", "∀x(D(x) → B(x))");
        assert!(result.correct, "Exact match should be correct");
    }

    #[test]
    fn test_whitespace_normalization() {
        let result = check_answer("∀x( D(x) → B(x) )", "∀x(D(x)→B(x))");
        assert!(result.correct, "Whitespace should be normalized");
    }

    #[test]
    fn test_latex_to_unicode() {
        let result = check_answer("\\forall x(D(x) \\supset B(x))", "∀x(D(x) → B(x))");
        assert!(result.correct, "LaTeX should normalize to Unicode");
    }

    #[test]
    fn test_ascii_shortcuts() {
        let result = check_answer("D(x) & B(x)", "D(x) ∧ B(x)");
        assert!(result.correct, "ASCII & should match ∧");
    }

    #[test]
    fn test_commutative_conjunction() {
        let result = check_answer("∃x(B(x) ∧ D(x))", "∃x(D(x) ∧ B(x))");
        assert!(result.correct, "Conjunction should be commutative");
    }

    #[test]
    fn test_wrong_quantifier() {
        let result = check_answer("∃x(D(x) → B(x))", "∀x(D(x) → B(x))");
        assert!(!result.correct, "Wrong quantifier should not match");
        assert!(result.partial, "Should get partial credit");
    }

    #[test]
    fn test_wrong_connective() {
        let result = check_answer("∀x(D(x) ∧ B(x))", "∀x(D(x) → B(x))");
        assert!(!result.correct, "Wrong connective should not match");
        assert!(result.partial, "Should get partial credit for structure");
    }

    #[test]
    fn test_completely_wrong() {
        let result = check_answer("P(a)", "∀x(D(x) → B(x))");
        assert!(!result.correct);
        assert!(!result.partial);
    }

    #[test]
    fn test_normalize_arrow() {
        let normalized = normalize_logic("A -> B");
        assert_eq!(normalized, "A→B");
    }

    #[test]
    fn test_normalize_biconditional() {
        let normalized = normalize_logic("A <-> B");
        assert_eq!(normalized, "A↔B");
    }
}

```

---

## Integration Tests
#### Phase 1: Garden Path

**File:** 
tests/phase1_garden_path.rs

Structural ambiguity tests.

**Example:** The horse raced past the barn fell.

---

#### Phase 21: Imperative

**File:** 
tests/phase21_block_headers.rs

Imperative mode tests.

**Example:** ## Main

---

#### Phase 24: Codegen

**File:** 
tests/phase24_codegen.rs

Code generation tests.

**Example:** Let x be 5.

---


---

## Metadata

- **Generated:** Mon Jan  5 19:24:05 CST 2026
- **Repository:** /Users/tristen/logicaffeine/logicaffeine
- **Git Branch:** main
- **Git Commit:** 9a41ce1

---

**Note:** This documentation is auto-generated. Run 
./generate-docs.sh to regenerate.
