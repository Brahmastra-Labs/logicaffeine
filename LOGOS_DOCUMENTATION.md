# LOGICAFFEINE 1.0 - Complete Source Documentation

An English-to-First-Order-Logic transpiler with modal operators, temporal logic, and semantic analysis.

**Technology Stack:**
- Rust (core transpiler)
- Dioxus 0.6 (web UI with Router)
- Bumpalo (arena allocation)
- WASM (browser deployment)

---

## Acknowledgments & History

Logicaffeine stands on the shoulders of giants. This project draws deep inspiration from **LogiCola**, the legendary logic tutorial software created by **Harry J. Gensler** at John Carroll University. For decades, LogiCola helped students worldwide master symbolic logic through interactive exercises and immediate feedback.

The creator of Logicaffeine first encountered LogiCola as a college student, and it sparked a lasting passion for formal logic and natural language processing. The pedagogical brilliance of Gensler's approach—breaking complex logical concepts into digestible, interactive exercises—directly influenced Logicaffeine's curriculum design.

While early prototypes referenced LogiCola's exercise format (LogiCola 3.0), **Logicaffeine 1.0** is a complete reimagining: a modern English-to-First-Order-Logic transpiler built from the ground up in Rust, featuring Montague semantics, Neo-Davidsonian event structures, and parse forest ambiguity resolution. The programming language component is called **LOGOS**.

We honor LogiCola's legacy while charting a new course—extending beyond tutorial software into a full formal semantics engine capable of translating natural English into rigorous logical notation.

---

## Table of Contents

### Overview
1. [Architecture Overview](#architecture-overview)

### Grammar & Semantics
2. [Grammar Rules](#grammar-rules)
   - [Sentence Patterns](#sentence-patterns)
   - [Quantifiers & Scope](#quantifier-scope)
   - [Modal & Temporal Operators](#modal-operators)
   - [Linguistic Phenomena](#linguistic-phenomena)
   - [Output Examples](#output-examples)
3. [Glossary](#glossary)

### Test Coverage
4. [Integration Tests](#integration-tests)
    - [Phase 1: Garden Path](#phase-1-garden-path)
    - [Phase 2: Polarity Items](#phase-2-polarity-items)
    - [Phase 3: Tense & Aspect](#phase-3-tense--aspect)
    - [Phase 4: Movement & Reciprocals](#phase-4-movement--reciprocals)
    - [Phase 5: Wh-Movement](#phase-5-wh-movement)
    - [Phase 6: Complex Tense](#phase-6-complex-tense)
    - [Phase 7: Intensional Semantics](#phase-7-intensional-semantics)
    - [Phase 8: Degrees & Comparatives](#phase-8-degrees--comparatives)
    - [Phase 9: Noun/Verb Conversion](#phase-9-nounverb-conversion)
    - [Phase 10: Ellipsis & Sluicing](#phase-10-ellipsis--sluicing)
    - [Phase 11: Sorts & Metaphor](#phase-11-sorts--metaphor)
    - [Phase 12: Parse Forest](#phase-12-parse-forest)
    - [Phase 13: Multi-Word Expressions](#phase-13-mwe)
    - [Phase 14: Ontology & Bridging](#phase-14-ontology)
    - [Phase 15: Negation & Polarity](#phase-15-negation--polarity)
    - [Phase 16: Aspect Stack](#phase-16-aspect-stack)
    - [Phase 17: Comparatives & Superlatives](#phase-17-comparatives--superlatives)
    - [Phase 18: Plurality](#phase-18-plurality)
    - [Phase 19: Group Plurals](#phase-19-group-plurals)
    - [Phase 20: Axiom Layer](#phase-20-axiom-layer)
    - [Phase 21: Block Structure & Imperative](#phase-21-block-headers)
    - [Phase 22: Identity, Scope & Resolution](#phase-22-identity-scope)
    - [Phase 23: Type System & Statements](#phase-23-type-system)
    - [Phase 24: Code Generation](#phase-24-code-generation)
    - [Phase 25: Assertions & Smoke Tests](#phase-25-assertions)
    - [Phase 26: End-to-End Pipeline](#phase-26-end-to-end)
    - [Phase 27: Guards](#phase-27-guards)
    - [Phase 28: Precedence](#phase-28-precedence)
    - [Phase 29: Runtime Injection](#phase-29-runtime-injection)
    - [Phase 30: Collections & Iteration](#phase-30-collections--iteration)
    - [Phase 31: User-Defined Types](#phase-31-user-defined-types)
    - [Phase 32: Function Definitions & Inference](#phase-32-function-definitions--inference)
    - [Phase 33: Sum Types & Pattern Matching](#phase-33-sum-types--pattern-matching)
    - [Phase 34: User-Defined Generics](#phase-34-user-defined-generics)
5. [Statistics](#statistics)

### Source Code
6. [Lexicon Data](#lexicon-data)
7. [Lexer & Tokenization](#lexer--tokenization)
8. [Parser & AST](#parser--ast) (Dual-AST: logic.rs + stmt.rs)
9. [Transpilation](#transpilation)
10. [Semantic Analysis](#semantic-analysis)
11. [Type Analysis](#type-analysis) (analysis/ module)
12. [Code Generation](#code-generation) (codegen.rs, compile.rs, scope.rs)
13. [Public API](#public-api)
14. [Linguistic Data](#linguistic-data)
15. [Memory Management](#memory-management)
16. [Error Handling](#error-handling)
17. [Gamification](#gamification) (achievements, progress, SRS)
18. [Web Application](#web-application)
    - [Pages](#pages): Home, Workspace, Pricing, Learn, Lesson
    - [Components](#components): ChatDisplay, InputArea
    - [Router](#router): Client-side navigation
19. [Problem Generator](#problem-generator)
    - [Curriculum Structure](#curriculum-structure)
    - [Runtime Lexicon](#runtime-lexicon)
    - [Generator Engine](#generator-engine)
    - [Grader](#grader)
20. [Logos Core Runtime](#logos-core-runtime)

### Appendix
16. [Metadata](#metadata)

---

## Architecture Overview

LOGICAFFEINE implements a compiler pipeline for natural language to formal logic translation, with support for **structural ambiguity** via parse forests.

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                           LOGICAFFEINE 1.0 Pipeline                         │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   ┌─────────┐    ┌─────────┐    ┌─────────┐    ┌───────────┐    ┌───────┐  │
│   │  Input  │───▶│  Lexer  │───▶│ Parser  │───▶│ Transpile │───▶│Output │  │
│   │ English │    │         │    │         │    │           │    │ FOL   │  │
│   └─────────┘    └────┬────┘    └────┬────┘    └─────┬─────┘    └───────┘  │
│                       │              │               │                      │
│                       ▼              ▼               ▼                      │
│                  ┌─────────┐    ┌─────────┐    ┌───────────┐               │
│                  │ Tokens  │    │  Parse  │    │ Vec<AST>  │               │
│                  └─────────┘    │  Forest │    │ (multiple │               │
│                                 └─────────┘    │ readings) │               │
│                                      │         └───────────┘               │
│                                      ▼                                      │
│                              ┌───────────────┐                              │
│                              │    Lambda     │                              │
│                              │   Calculus    │                              │
│                              │  (Semantics)  │                              │
│                              └───────────────┘                              │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

**Data Flow:**
1. **Lexer** (`lexer.rs`, `token.rs`): Tokenizes English input using dictionary-based classification
2. **Parser** (`parser/`, `ast.rs`): Builds Arena-based AST via recursive descent; returns **parse forest** for ambiguous inputs
3. **Semantics** (`lambda.rs`, `context.rs`): Lambda calculus for compositional meaning
4. **Transpiler** (`transpile.rs`, `formatter.rs`): Generates Unicode or LaTeX logical notation

**Key Design Decisions:**
- **Arena allocation** (`bumpalo`) for zero-copy AST nodes with `Copy` semantics
- **Boxed AST variants** - Large variants boxed to reduce Expr size (112→32 bytes)
- **AstContext** - Unified arena access struct for ergonomic allocation
- **Visitor pattern** - walk_expr/walk_term for clean AST traversal
- **RAII checkpoints** - ParserCheckpoint for automatic backtracking cleanup
- **ParserGuard** - RAII guard with Deref/DerefMut for transparent parser access and automatic rollback
- **Fluent builders** - Type-safe expression construction with inline builders on AstContext
- **Semantic token sets** - Const arrays (WH_WORDS, MODALS) for declarative token matching via check_any()
- **Zero-alloc transpile** - write_to/write_logic methods avoid String allocation
- **Parse forest** output via `compile_ambiguous()` for structurally ambiguous sentences
- **Neo-Davidsonian event semantics** with thematic roles (Agent, Patient, Theme, etc.)
- **Control theory** (Chomsky) - raising verbs, control verbs, PRO binding
- **Generic quantifiers** (`Gen x`) for law-like generalizations ("Birds fly")
- **Mereology/Plurals** with Sigma operator (σ) and Distributive wrapper (*)
- **Presupposition & Focus** semantics (Strawson, Rooth)
- **Gapping/ellipsis** support via backtracking and verb recovery
- Symbol interning for efficient string comparisons
- Discourse context tracking for pronoun resolution
- Socratic error messages for educational feedback
- **Span tracking** - Source positions on tokens for rich error diagnostics with display_with_source()
- **Snapshot testing** - Golden master tests via assert_snapshot! macro (UPDATE_SNAPSHOTS=1 to regenerate)
- **Typo suggestions** - Zero-dependency Levenshtein distance for 'did you mean?' error messages
- **ANSI styling** - Compiler-style colored terminal output for errors
- **Reciprocals** - "each other" expands to bidirectional predicate conjunction
- **Polarity sensitivity** - Context-aware "any" interpretation (NPI vs free choice)
- **Garden path reanalysis** - Reduced relative clause detection with backtracking
- **Aspect chains** - Perfect/progressive/passive/modal stacking in verb groups
- **Voice operator** - Passive voice handling integrated with event semantics
- **Vendler classes (Aktionsart)** - Lexical aspect classification: State, Activity, Accomplishment, Achievement, Semelfactive
- **Zero-derivation** - Nouns dynamically coerced to verbs via morphological heuristics; consonant cluster recovery for silent-e lemmas
- **VP Ellipsis reconstruction** - EventTemplate stores verb + non-agent roles; try_parse_ellipsis() detects auxiliary + terminator pattern and rebuilds NeoEvent with new subject
- **Sluicing reconstruction** - Wh-word at sentence boundary triggers reconstruction from last_event_template; contraction expansion in lexer enables "don't know who" parsing
- **Verb-first classification** - Polysemous words (love, ring) classified as verbs first; parser accepts verbs in noun positions via consume_content_word()
- **Parse forest** - compile_forest() returns Vec<String> of all valid readings for ambiguous sentences
- **MAX_FOREST_READINGS** (12) - Limits parse forest size to prevent exponential blowup
- **noun_priority_mode** - Parser flag for lexical ambiguity forking; prefers noun interpretation for Ambiguous tokens
- **Sort system** - Ontological type hierarchy (Human⊂Animate⊂Physical) for semantic compatibility and metaphor detection
- **MWE Pipeline** - Post-tokenization trie-based collapsing of multi-word expressions (compound nouns, idioms, phrasal verbs)
- **Bridging Anaphora** - Part-whole inference for definite NPs without direct antecedent via ontology lookup
- **Copula Adjective Preference** - After copula, simple-aspect Verbs with Adjective alternatives prefer adjective reading
- **Content Word Classifiers** - Heuristic disambiguation via is_noun_like(), is_verb_like(), is_adjective_like()
- **NPI Licensing** - Negative Polarity Items (any, ever, anything) require licensing context; "no/nobody/nothing" are inherently negative quantifiers
- **Collective/Distributive ambiguity** - Mixed verbs (lift, carry) fork parse forest for plural subjects; collective verbs (gather, meet) force group reading; distributive verbs force individual reading
- **Distributive Expr** - Expr::Distributive wraps predicates for \`*\` operator transpilation
- **GroupQuantifier** - Expr::GroupQuantifier for cardinal indefinites with collective readings; outputs Group(g) ∧ Count(g, n) ∧ ∀x(Member(x, g) → R(x)) structure
- **Axiom Layer** - Post-parse AST transformation via apply_axioms(); expands predicates using meaning postulates from lexicon (analytic entailments, privatives, hypernyms, verb entailments)
- **Problem Generator** - Template-based exercise generation with {ProperName}, {Noun}, {Verb}, {Adjective} slots; runtime lexicon queries with constraint filtering; morphological modifiers (:Plural, :Past)
- **Semantic Grading** - Answer comparison via Unicode normalization, AST parsing, and structural equivalence; handles commutativity of ∧/∨; partial credit scoring
- **Curriculum Embedding** - Filesystem-based curriculum (assets/curriculum/) embedded at compile time via include_dir; JSON schemas for eras, modules, exercises
- **Catch-all 404 Route** - NotFound variant with /:..route pattern prevents router panics on invalid URLs

**Quantifier Kinds:**
| Kind | Symbol | Example | Meaning |
|------|--------|---------|---------|
| Universal | ∀ | "All birds fly" | Every individual |
| Existential | ∃ | "Some bird flies" | At least one |
| Generic | Gen | "Birds fly" | Characteristic/law-like |
| Negative | ¬∃ | "No birds swim" | None |
| Many | MANY | "Many dogs bark" | Significantly many |
| Most | MOST | "Most birds fly" | More than half |
| Few | FEW | "Few cats swim" | Small number |

**Scope Enumeration Complexity:**
| Scenario | Formula | Example |
|----------|---------|---------|
| Naive | n! | 3 quantifiers → 6 readings |
| With Islands | Π(k_i!) | 4 quantifiers (2+2) → 4 readings |
| + Intensionality | Π(k_i!) × 2^m | m opaque verbs add binary choice |

**Vendler Classes (Aktionsart):**
| Class | Features | Example Verbs | Meaning |
|-------|----------|---------------|---------|
| State | +static, +durative, -telic | know, love, exist | No change, extends in time |
| Activity | -static, +durative, -telic | run, swim, drive | Dynamic, no endpoint |
| Accomplishment | -static, +durative, +telic | build, draw, write | Dynamic with endpoint |
| Achievement | -static, -durative, +telic | win, find, die | Instantaneous change |
| Semelfactive | -static, -durative, -telic | knock, cough, blink | Single punctual event |

**Verb Plurality Classes:**
| Class | Example Verbs | Plural Subject Behavior |
|-------|---------------|------------------------|
| Collective | gather, meet, disperse | Group reading only |
| Distributive | sleep, run, die | Individual reading only |
| Mixed | lift, carry, surround | Ambiguous - forks readings |

**Word Classification Priority:**
| Word | In Verbs | In disambiguation_not_verbs | In Nouns | In Adjectives | Result |
|------|----------|----------------------------|----------|---------------|--------|
| love | ✓ | ✗ | ✓ | ✗ | Verb (parser handles noun positions) |
| ring | ✓ | ✓ | ✓ | ✗ | Noun (disambiguation + noun check) |
| bus  | ✓ | ✓ | ✓ | ✗ | Noun (disambiguation + noun check) |
| fake | ✓ | ✓ | ✗ | ✗ | Adjective (disambiguation, not noun) |
| open | ✓ | ✗ | ✗ | ✓ | Ambiguous{Verb, [Adj]} (copula prefers Adj) |

**Lexical Ambiguity (Phase 12):**
| Pattern | Example | Readings |
|---------|---------|----------|
| Noun/Verb | "I saw her duck" | duck=bird vs duck=action |
| Verb/Adjective | "The door is open" | open=Adj (copula preference) vs open=Verb |
| Possessive Pronoun | "her book" vs "saw her" | possessive determiner vs object pronoun |
| PP Attachment | "man with telescope" | VP attachment (instrument) vs NP attachment (modifier) |

**Sort Hierarchy (Phase 11):**
| Sort | Parent | Examples |
|------|--------|----------|
| Human | Animate | John, Mary, Juliet |
| Animate | Physical | dog, cat, bird |
| Celestial | - | Sun, Moon, stars |
| Abstract | - | Time, Justice, Love |
| Physical | - | Rock, Table, Book |
| Value | - | Money, Gold |

**Aspect Operators:**
| Operator | Symbol | Example | Meaning |
|----------|--------|---------|---------|
| Progressive | Prog | "is running" | Ongoing action |
| Perfect | Perf | "has eaten" | Completed with relevance |
| Habitual | HAB | "John runs" (present activity) | Characteristic behavior |
| Iterative | ITER | "kept knocking" | Repeated semelfactive |

**Plural Semantics (Link-style Mereology):**
| Feature | Syntax | Output | Meaning |
|---------|--------|--------|---------|
| Sigma operator | "The dogs" | σx.Dog(x) | Maximal sum of all dogs |
| Collective verb | "The dogs gathered" | P(G(σD)) | Group action |
| Distributive verb | "The dogs barked" | *P(B(σD)) | Each individual acted |
| Coordination | "John and Mary met" | P(M2(J ⊕ M)) | Sum of individuals |

**Event Semantics (Neo-Davidsonian):**
| Role | Example | Output |
|------|---------|--------|
| Agent | "John kicked the ball" | ∃e(Kick(e) ∧ Agent(e,j) ∧ Theme(e,b)) |
| Theme | "The ball was kicked" | ∃e(Kick(e) ∧ Theme(e,b)) |
| Recipient | "John gave Mary a book" | ∃e(Give(e) ∧ Agent(e,j) ∧ Recipient(e,m) ∧ Theme(e,b)) |
| Instrument | "with a hammer" | Instrument(e,h) |

**Ditransitive Verbs:**
| Verb | Example | Roles |
|------|---------|-------|
| give | "John gave Mary a book" | Agent, Recipient, Theme |
| send | "Mary sent John a letter" | Agent, Recipient, Theme |
| tell | "She told him a story" | Agent, Recipient, Theme |

**Causal Relations:**
| Type | Example | Output |
|------|---------|--------|
| Because | "John fell because he slipped" | Cause(Slip(j), Fall(j)) |

**Deixis (Demonstratives):**
| Type | Words | Predicate |
|------|-------|-----------|
| Proximal | this, these | Proximal(x) |
| Distal | that, those | Distal(x) |

**Gerunds:**
| Position | Example | Output |
|----------|---------|--------|
| Subject | "Running is healthy" | Healthy(Running) |
| Object | "John loves swimming" | Love(j, Swimming) |

**Mass Nouns:**
| Measure | Example | Output |
|---------|---------|--------|
| Much | "much water" | Measure(x, Much) ∧ Water(x) |
| Little | "little time" | Measure(x, Little) ∧ Time(x) |

**Control Theory (Chomsky):**
| Type | Example | Structure |
|------|---------|-----------|
| Subject Control | "John wants to leave" | Want(j, PRO_j leave) |
| Object Control | "John persuaded Mary to go" | Persuade(j, m, PRO_m go) |
| Raising | "John seems to be happy" | Seem(Happy(j)) |

**Adjective Types:**
| Type | Example | Output | Semantics |
|------|---------|--------|-----------|
| Intersective | "a red ball" | R(x) ∧ B(x) | Independent predicates |
| Subsective | "a small elephant" | S(x, ^E) ∧ E(x) | Relative to noun class |
| Non-Intersective | "a fake gun" | Fake(Gun) | Modifies concept |

**Measurement Semantics (Phase 8):**
| Dimension | Example | Output |
|-----------|---------|--------|
| Length | "5 meters long" | Value(5, meters, Length) |
| Temperature | "98.6 degrees" | Value(98.6, degrees, Temperature) |
| Cardinality | "aleph_0" | Value(aleph_0, ∅, Cardinality) |
| Comparative | "2 inches taller" | Taller(j, m, Value(2, inches)) |

**Compound Identifiers:**
| Pattern | Example | Output |
|---------|---------|--------|
| noun + label | "set A" | set_A |
| noun + proper | "King John" | King_John |
| noun + letter | "function F" | function_F |

**Zero-Derivation (Phase 9):**
| Pattern | Example | Output |
|---------|---------|--------|
| noun→verb (past) | "tabled the motion" | Table(committee, motion) |
| noun→verb (past) | "emailed him" | Email(she, him) |
| noun→verb (past) | "googled the answer" | Google(j, answer) |
| noun→verb (modal) | "should table" | Modal(Should, Table(x, motion)) |

**VP Ellipsis (Phase 10a):**
| Pattern | Example | Output |
|---------|---------|--------|
| does too | "John runs. Mary does too." | Run(j) ∧ Run(m) |
| modal too | "John can swim. Mary can too." | ◇Swim(j) ∧ ◇Swim(m) |
| does not | "John runs. Mary does not." | Run(j) ∧ ¬Run(m) |
| with object | "John eats an apple. Mary does too." | Eat(j,apple) ∧ Eat(m,apple) |

**Sluicing (Phase 10b):**
| Pattern | Example | Output |
|---------|---------|--------|
| who sluicing | "Someone left. I know who." | ∃x(Leave(x)) ∧ Know(I, ?y[Leave(y)]) |
| what sluicing | "John ate something. I know what." | ∃x(Eat(j,x)) ∧ Know(I, ?y[Eat(j,y)]) |
| negation | "Someone called. I don't know who." | ∃x(Call(x)) ∧ ¬Know(I, ?y[Call(y)]) |
| wonder | "Someone ran. I wonder who." | ∃x(Run(x)) ∧ Wonder(I, ?y[Run(y)]) |

---


## Grammar Rules

LOGICAFFEINE parses English sentences according to the following grammar patterns:

### Sentence Patterns

| Pattern | Example | Logic |
|---------|---------|-------|
| Universal | "All cats are mammals" | ∀x(Cat(x) → Mammal(x)) |
| Existential | "Some dogs bark" | ∃x(Dog(x) ∧ Bark(x)) |
| Generic | "Birds fly" | Gen x(Bird(x) → Fly(x)) |
| Singular | "Socrates is mortal" | Mortal(socrates) |
| Negative | "No fish fly" | ¬∃x(Fish(x) ∧ Fly(x)) |
| Conditional | "If it rains, the ground is wet" | Rain → Wet(ground) |
| Gapping | "John ate an apple, and Mary, a pear" | Ate(john, apple) ∧ Ate(mary, pear) |
| Plural Collective | "The dogs gathered" | P(G(σD)) |
| Plural Distributive | "The dogs barked" | *P(B(σD)) |
| Coordination | "John and Mary met" | P(M2(J ⊕ M)) |
| Subject Control | "John wants to leave" | Want(j, Leave(PRO_j)) |
| Object Control | "John persuaded Mary to go" | Persuade(j, m, Go(PRO_m)) |
| Raising | "John seems to be happy" | Seem(Happy(j)) |
| Focus | "Only John ran" | Only(j, Ran(j)) |
| Presupposition | "John stopped smoking" | Smoke(j)_presup ∧ ¬Smoke(j) |
| Counterfactual | "If John had run, he would have won" | □→(Run(j), Win(j)) |
| Comparative | "John is taller than Mary" | Taller(j, m) |
| Ditransitive | "John gave Mary a book" | ∃e(Give(e) ∧ Agent(e,j) ∧ Recipient(e,m) ∧ Theme(e,b)) |
| Causal | "John fell because he slipped" | Cause(Slip(j), Fall(j)) |
| Gerund Subject | "Running is healthy" | Healthy(Running) |
| Gerund Object | "John loves swimming" | Love(j, Swimming) |
| Deixis Proximal | "This cat meows" | ∃x(Proximal(x) ∧ Cat(x) ∧ Meow(x)) |
| Deixis Distal | "That dog barks" | ∃x(Distal(x) ∧ Dog(x) ∧ Bark(x)) |
| Mass Noun | "Much water flows" | ∃x(Measure(x, Much) ∧ Water(x) ∧ Flow(x)) |
| Reciprocal | "They love each other" | Love(x,y) ∧ Love(y,x) |
| NPI Any | "No one has any books" | ¬∃x∃y(Person(x) ∧ Book(y) ∧ Has(x,y)) |
| Free Choice Any | "Any book works" | ∀x(Book(x) → Works(x)) |
| Garden Path | "The horse raced past the barn fell" | ∃x(Horse(x) ∧ RacedPast(x,barn) ∧ Fell(x)) |
| Perfect Aspect | "John has eaten" | Perf(Eat(j)) |
| Progressive | "John is eating" | Prog(Eat(j)) |
| Passive Voice | "The ball was kicked" | ∃e(Kick(e) ∧ Theme(e,ball)) |
| Contact Clause | "The cat the dog chased ran" | ∃x(Cat(x) ∧ ∃y(Dog(y) ∧ Chase(y,x)) ∧ Run(x)) |
| Stacked Relatives | "Every book that John read that Mary wrote" | ∀x((Book(x) ∧ Read(j,x) ∧ Wrote(m,x)) → ...) |

### Quantifier Kinds

| Kind | Trigger | Symbol | Semantics |
|------|---------|--------|-----------|
| Universal | "all", "every", "each" | ∀ | True for every individual |
| Existential | "some", "a", "an" | ∃ | True for at least one |
| Generic | Bare plural ("birds") | Gen | Law-like/characteristic |
| Negative | "no", "none" | ¬∃ | True for none |

### Quantifier Scope

- Nested quantifiers resolve left-to-right by default
- "Every student read some book" → ∀x(Student(x) → ∃y(Book(y) ∧ Read(x,y)))
- Scope can be disambiguated via context

### Structural Ambiguity

Sentences with multiple valid parses return all readings via `compile_ambiguous()`:

| Sentence | Reading 1 | Reading 2 |
|----------|-----------|-----------|
| "I saw the man with the telescope" | See(i, man, with:telescope) | See(i, man) ∧ Has(man, telescope) |

**PP-Attachment:** Prepositional phrases can attach to VP (instrument) or NP (modifier).

### Modal Operators

| Operator | Symbol | Meaning |
|----------|--------|---------|
| Necessity | □ | "must", "necessarily" |
| Possibility | ◇ | "can", "possibly", "might" |
| Obligation | O | "ought", "should" |
| Permission | P | "may" (deontic) |

### Temporal Operators

| Operator | Symbol | Meaning |
|----------|--------|---------|
| Future | F | "will" |
| Past | P | "did", past tense |
| Always | G | "always" |
| Sometimes | F | "sometimes" |

### Linguistic Phenomena

LOGICAFFEINE supports the following linguistic constructs:

### Quantification
- Universal: "all", "every", "each", "any"
- Existential: "some", "a", "an", "there exists"
- Generic: bare plurals ("birds", "dogs") - law-like generalizations
- Negative: "no", "none", "not any"

### Plurals & Mereology (Link-style)
- Sigma operator (σ): maximal sum - "the dogs" → σx.Dog(x)
- Collective verbs: "gather", "meet", "assemble", "disperse" - no distributive wrapper
- Distributive verbs: most verbs - wrapped with * operator
- Group formation (⊕): "John and Mary" → J ⊕ M

### Event Semantics (Neo-Davidsonian)
- Event variables: ∃e(Kick(e) ∧ Agent(e,j) ∧ Theme(e,b))
- Thematic roles: Agent, Patient, Theme, Goal, Source, Recipient, Instrument, Location, Time, Manner
- Adverbial modification: Manner(e, quickly)

### Control Theory (Chomsky)
- Subject control: "want", "try", "promise" - PRO bound to subject
- Object control: "persuade", "force", "convince" - PRO bound to object
- Raising: "seem", "appear" - no PRO, subject raises

### Presupposition (Strawson)
- Factive triggers: "know", "regret", "realize"
- Aspectual triggers: "stop", "start", "continue" (require gerund complement)
  - "John stopped smoking." → presupposition: John was smoking
  - "John stopped." → no presupposition (simple past tense verb)
- Definite descriptions: presuppose existence

### Focus (Rooth)
- Focus particles: "only", "even", "just"
- Alternative semantics: focus introduces alternatives

### Connectives
- Conjunction: "and", "but", "yet"
- Disjunction: "or", "either...or"
- Implication: "if...then", "implies", "only if"
- Biconditional: "if and only if", "iff"

### Modality
- Alethic: "necessarily", "possibly", "must", "can"
- Deontic: "ought", "should", "may", "permitted"
- Epistemic: "knows", "believes"

### Anaphora
- Pronouns: "he", "she", "it", "they"
- Reflexives: "himself", "herself", "itself"
- Demonstratives: "this", "that"

### Relative Clauses
- Restrictive: "the man who runs"
- Non-restrictive: "John, who is tall"
- Stacked relatives: "the book that John read that Mary wrote" - multiple relative clauses on single head noun

### Presupposition Triggers
- Definite descriptions: "the king of France"
- Factive verbs: "knows that", "regrets that"
- Change of state: "stopped", "began" (gerund complement required)
  - Triggered: "stopped smoking" → presupposes was smoking
  - Not triggered: "stopped" alone → simple verb, no presupposition

### Ellipsis & Gapping
- Gapping: "John ate an apple, and Mary, a pear" (verb elided in second conjunct)
- VP Ellipsis: "John ran and Mary did too"
- Sluicing: "Someone left, but I don't know who"

### Structural Ambiguity
- PP-attachment: "I saw the man with the telescope" (VP vs NP attachment)
- Quantifier scope: "Every boy loves some girl" (wide vs narrow scope)
- Coordination: "old men and women" (old men + women vs old men + old women)

### Deixis (Demonstratives)
- Proximal: "this", "these" → Proximal(x) predicate
- Distal: "that", "those" → Distal(x) predicate
- Spatial reference relative to speaker position

### Ditransitive Verbs
- Double object construction: "give X Y", "send X Y", "tell X Y"
- Recipient thematic role for indirect object
- Three-argument event: Agent, Recipient, Theme

### Gerunds
- Gerund as subject: "Running is fun" → predicate applied to nominalized verb
- Gerund as object: "I love swimming" → verb as theme argument
- -ing form functioning as noun phrase

### Causal Connectives
- "because" introduces causal relation: Cause(antecedent, consequent)
- Antecedent is the cause, consequent is the effect
- Order: "X because Y" → Cause(Y, X)

### Mass Nouns
- "much" + noun → Measure(x, Much) ∧ Noun(x)
- "little" + noun → Measure(x, Little) ∧ Noun(x)
- Quantity expressions for uncountable nouns

### Reciprocals
- Pattern: "each other" with plural subject
- Expansion: P(x,y) ∧ P(y,x) for all pairs in the group
- Example: "John and Mary love each other" → Love(j,m) ∧ Love(m,j)

### Polarity Items
- NPI "any": Licensed by negation, questions, conditionals → existential
- Free choice "any": Universal interpretation in positive contexts
- Context tracking via negation depth in parser
- Example: "No one has any books" (NPI) vs "Any book will do" (free choice)

### Garden Path Sentences
- Reduced relative clauses: "The horse raced past the barn fell"
- Initially parsed as main verb, triggers reanalysis
- Backtracking to reduced relative interpretation
- Parser uses try_reduced_relative_interpretation()

### Vendler Classes (Aktionsart)
- State: +static, +durative, -telic (know, love) - no progressive allowed
- Activity: -static, +durative, -telic (run, swim) - present tense → Habitual
- Accomplishment: -static, +durative, +telic (build, write) - present tense → Habitual
- Achievement: -static, -durative, +telic (win, die) - present tense → Habitual
- Semelfactive: -static, -durative, -telic (knock, blink) - progressive → Iterative

### Aspect System
- Progressive: -ing form (is/was running) → Prog(φ)
- Perfect: have/has/had + past participle → Perf(φ)
- Habitual: present tense non-stative → HAB(φ)
- Iterative: semelfactive + progressive → ITER(φ)
- Passive: been + past participle → Voice(Passive, φ)
- Chains: Modal + Perfect + Passive + Progressive stacking
- Example: "would have been being eaten" → chains all four

### Contact Clauses
- Reduced relatives without overt relativizer: "The cat the dog chased ran"
- Pattern: NP + NP + Verb triggers contact clause interpretation
- Equivalent to: "The cat [that] the dog chased ran"
- Parser uses is_contact_clause_pattern() lookahead

### Intensionality (De Re / De Dicto)
- De Re: Object exists in actual world, quantifier scopes wide
- De Dicto: Object described intensionally, quantifier scopes narrow
- Opaque verbs: "seek", "want", "believe", "need", "fear"
- Montague up-arrow (^): Marks intension of predicate
- Example: "John seeks a unicorn"
  - De Re: ∃x(Unicorn(x) ∧ Seek(j, x)) - specific unicorn exists
  - De Dicto: Seek(j, ^Unicorn) - seeking unicorn-concept

### Scope Islands
- Island boundaries: conjunctions (if/and/or), relative clauses
- Quantifiers cannot scope out of their island
- Reduces exponential scope ambiguity to manageable product of factorials
- Example: "Every man runs AND some dog barks" → 1! × 1! = 1 reading (no cross-island scoping)

### Adjective Semantics
- Intersective: Property independent of noun - "red ball" → R(x) ∧ B(x)
- Subsective: Property relative to noun class - "small elephant" → S(x, ^E) ∧ E(x)
- Non-Intersective: Modifies concept - "fake gun" → Fake(Gun)
- Gradable: Allows comparison - "taller", "tallest"
- Montague up-arrow (^): Marks intension of noun for subsective context

### Generalized Quantifiers
- Beyond ∀/∃: MANY, MOST, FEW with cardinality semantics
- MANY x(P(x) ∧ Q(x)) - significantly many P's are Q's
- MOST x(P(x) → Q(x)) - more than half of P's are Q's
- FEW x(P(x) ∧ Q(x)) - small number of P's are Q's

### Zero-Derivation (Noun→Verb Conversion)
- English allows nouns to be used as verbs without morphological marking
- Pattern detection: Past tense "-ed" suffix on non-lexicon words
- Morphological recovery: Silent-e restoration via consonant cluster heuristics
- Example: "table" (noun) → "tabled" (verb) → "Table(x, y)"
- Handles: tabled, emailed, googled, skyped, friended, texted, etc.

### VP Ellipsis (Anaphoric Reconstruction)
- Elided VP reconstructed from discourse antecedent
- Pattern: Subject + Auxiliary + (not)? + Terminator (too/also/.)
- Template stores: verb + non-agent thematic roles + modifiers
- Reconstruction: New subject as Agent, preserve Theme/Goal/etc.
- Modal preservation: "can too" → same modal on reconstructed VP
- Negation: "does not" → negated reconstruction
- Examples: "John runs. Mary does too." → Run(j) ∧ Run(m)

### Sluicing (Wh-Ellipsis)
- Elided wh-clause reconstructed from discourse antecedent
- Pattern: Embedding verb + wh-word + terminator (period/comma/EOF)
- Template stores: verb + thematic roles from antecedent clause
- Reconstruction: wh-variable fills Agent (who) or Theme (what) slot
- Negation support: "I don't know who" via contraction expansion
- Embedding verbs: know, wonder (Opaque feature)
- Examples: "Someone left. I know who." → ∃x(Leave(x)) ∧ Know(I, ?y[Leave(y)])

### Degree Semantics (Phase 8)
- Comparative with measure: "2 inches taller" → Taller(j, m, 2 inches)
- Absolute measurement: "5 meters long" → Long(rope, 5 meters)
- Symbolic numbers: aleph_0, omega for infinite cardinals
- Dimension tracking: Length, Time, Weight, Temperature, Cardinality
- NumberKind types: Real(f64), Integer(i64), Symbolic(Symbol)
- Term::Value stores numeric value with optional unit and dimension

### Topicalization (Object Fronting)
- Pattern: "NP, Subject Verb" → fronted NP is object (Theme)
- Example: "The apple, John ate." → Eat(j, apple)
- Adjective preservation: "The red apple, John ate." keeps Red(x) ∧ Apple(x)
- Pronoun subject handling: "The book, he read."
- Implementation: parser/mod.rs lines 401-473, uses wrap_with_definiteness_full()

### Long-Distance Dependencies (Wh-Movement)
- Filler-Gap binding across clause boundaries
- Example: "Who did John say Mary loves?" → λx.Say(j, Loves(m, x))
- Parser field: filler_gap: Option<Symbol> in Parser struct
- Persists through recursive clause parsing for embedded extractions
- Pied-piping: "To whom did John give the book?" fronts P+wh together

### Sentential Complements (Embedded Clauses)
- Verbs like "say", "believe", "think" take clausal arguments
- Represented as Term::Proposition wrapping the embedded Expr
- Example: "John said Mary runs" → Say(j, [Run(m)])
- Bracket notation [expr] distinguishes from conjunction
- Supports wh-extraction across clause boundaries
- Communication verbs: say, tell, report, announce
- Propositional attitude verbs: believe, think, know, doubt

### Reichenbach Temporal Semantics
- Three-point temporal model: Event (E), Reference (R), Speech (S)
- Past: R < S (reference before speech)
- Future: S < R (speech before reference)
- Perfect: E < R (event before reference)
- Past Perfect: E < R < S ("had run")
- Future Perfect: E < R, S < R ("will have run")
- Present Perfect: E < R, R = S ("has run")
- Output uses Precedes(x, y) predicates for explicit temporal ordering

### Multi-Word Expressions (Phase 13)
- Compound nouns: "fire engine" → FireEngine (merged single token)
- Idioms: "kicked the bucket" → Die (semantic replacement)
- Phrasal verbs: "gave up" → Surrender
- Trie-based pattern matching for efficient MWE detection
- Tense inheritance: "kicked the bucket" inherits past tense from "kicked"
- Post-tokenization pipeline: apply_mwe_pipeline() collapses multi-token sequences

### Bridging Anaphora (Phase 14)
- Part-whole inference for definite NPs without direct antecedent
- Example: "I bought a car. The engine smoked." → PartOf(engine, car)
- Ontology lookup: find_bridging_wholes() returns possible whole objects
- Ambiguous bridging handled via parse forest forking
- Sort compatibility checking for semantic validation

### Metaphor Detection (Phase 14)
- Sort violations trigger Metaphor wrapper
- Example: "The rock was happy" → Metaphor(Happy(rock))
- Predicate sort requirements checked via ontology module
- Compatible sorts pass without Metaphor wrapping
- Example: "John was happy" → Happy(j) (no metaphor - Human compatible with mental predicates)

### Negation & Polarity Items (Phase 15)
- Free choice "any": "Any cat hunts" → ∀x(Cat(x) → Hunt(x))
- NPI "any" with negation: "did not see any X" → ¬∃x(X(x) ∧ See(...,x))
- Negative quantifiers: nobody, nothing, no one → ∀x(R(x) → ¬P(x))
- Scope: "Not all birds fly" → ¬∀ (negation scopes over universal)
- Temporal NPIs: "never" → inherent negation, "ever" → requires licensor
- NPI licensing by "no": "No dog saw anything" licenses existential in object

### Output Examples

#### Unicode Output

**Input:** "All humans are mortal"
**Output:** `∀x(Human(x) → Mortal(x))`

**Input:** "Birds fly" (Generic)
**Output:** `Gen x(Bird(x) → Fly(x))`

**Input:** "Socrates is human and Socrates is mortal"
**Output:** `Human(socrates) ∧ Mortal(socrates)`

**Input:** "John ate an apple, and Mary, a pear" (Gapping)
**Output:** `Ate(john, apple) ∧ Ate(mary, pear)`

**Input:** "Necessarily, if something is a bachelor then it is unmarried"
**Output:** `□∀x(Bachelor(x) → Unmarried(x))`

### Plural Output (Mereology)

**Input:** "The dogs gathered" (Collective)
**Output:** `P(G(σD))`

**Input:** "The dogs barked" (Distributive)
**Output:** `*P(B(σD))`

**Input:** "John and Mary met" (Coordination)
**Output:** `P(M2(J ⊕ M))`

### Event Semantics Output

**Input:** "John kicked the ball"
**Output:** `∃e(Kick(e) ∧ Agent(e,j) ∧ Theme(e,b))`

### Control Output

**Input:** "John wants to leave"
**Output:** `Want(j, Leave(PRO_j))`

**Input:** "John seems to be happy"
**Output:** `Seem(Happy(j))`

### Focus & Presupposition Output

**Input:** "Only John ran"
**Output:** `Only(j, Ran(j))`

**Input:** "John stopped smoking"
**Output:** `Stop(j, Smoke(j))` with presupposition: `Smoke(j)`

### Ambiguous Output (compile_ambiguous)

**Input:** "I saw the man with the telescope"
**Output (Reading 1 - VP attachment):** `See(i, man, with:telescope)`
**Output (Reading 2 - NP attachment):** `See(i, man) ∧ Has(man, telescope)`

### LaTeX Output

**Input:** "All humans are mortal"
**Output:** `\forall x(Human(x) \rightarrow Mortal(x))`

**Input:** "Birds fly" (Generic)
**Output:** `\text{Gen } x(Bird(x) \rightarrow Fly(x))`

**Input:** "Some cat loves every dog"
**Output:** `\exists x(Cat(x) \land \forall y(Dog(y) \rightarrow Loves(x,y)))`

### Ditransitive Output

**Input:** "John gave Mary a book"
**Output:** `∃e(Give(e) ∧ Agent(e, j) ∧ Recipient(e, m) ∧ Theme(e, b))`

**Input:** "She sent him a letter"
**Output:** `∃e(Send(e) ∧ Agent(e, s) ∧ Recipient(e, h) ∧ Theme(e, l))`

### Causal Output

**Input:** "John fell because he slipped"
**Output:** `Cause(Slip(j), Fall(j))`

**Input:** "The plant died because it lacked water"
**Output:** `Cause(Lack(p, w), Die(p))`

### Gerund Output

**Input:** "Running is healthy"
**Output:** `Healthy(Running)`

**Input:** "John loves swimming"
**Output:** `Love(j, Swimming)`

### Deixis Output

**Input:** "This dog barks"
**Output:** `∃x(Proximal(x) ∧ Dog(x) ∧ Bark(x))`

**Input:** "Those cats meow"
**Output:** `∃x(Distal(x) ∧ Cat(x) ∧ Meow(x))`

### Mass Noun Output

**Input:** "Much water flows"
**Output:** `∃x(Measure(x, Much) ∧ Water(x) ∧ Flow(x))`

**Input:** "Little time remains"
**Output:** `∃x(Measure(x, Little) ∧ Time(x) ∧ Remain(x))`

### Reciprocal Output

**Input:** "John and Mary love each other"
**Output:** `Love(j, m) ∧ Love(m, j)`

**Input:** "They saw each other"
**Output:** `See(x, y) ∧ See(y, x)`

### Polarity Output

**Input:** "No one has any books" (NPI)
**Output:** `¬∃x(Person(x) ∧ ∃y(Book(y) ∧ Has(x, y)))`

**Input:** "Any book works" (Free Choice)
**Output:** `∀x(Book(x) → Works(x))`

### Garden Path Output

**Input:** "The horse raced past the barn fell"
**Output:** `∃x(Horse(x) ∧ RacedPast(x, barn) ∧ Fell(x))`

### Aspect Output

**Input:** "John is running" (Progressive)
**Output:** `Prog(∃e(Run(e) ∧ Agent(e, j)))`

**Input:** "John has eaten" (Perfect)
**Output:** `Perf(∃e(Eat(e) ∧ Agent(e, j)))`

**Input:** "The ball was kicked" (Passive)
**Output:** `∃e(Kick(e) ∧ Theme(e, ball))`

**Input:** "John was running" (Past Progressive)
**Output:** `Past(Prog(∃e(Run(e) ∧ Agent(e, j))))`

### Vendler/Aktionsart Output

**Input:** "John runs" (Activity, Present)
**Output:** `HAB(∃e(Run(e) ∧ Agent(e, j)))`

**Input:** "John knows Mary" (State, Present)
**Output:** `∃e(Know(e) ∧ Agent(e, j) ∧ Theme(e, m))` (no Habitual wrapper)

**Input:** "John is knocking" (Semelfactive, Progressive)
**Output:** `ITER(∃e(Knock(e) ∧ Agent(e, j)))`

**Input:** "John built a house" (Accomplishment, Past)
**Output:** `Past(∃e(Build(e) ∧ Agent(e, j) ∧ Theme(e, h)))`

**Input:** "John won" (Achievement, Past)
**Output:** `Past(∃e(Win(e) ∧ Agent(e, j)))`

### Intensional Readings (De Re / De Dicto)

**Input:** "John seeks a unicorn"
**Output (De Re):** `∃x(Unicorn(x) ∧ ∃e(Seek(e) ∧ Agent(e, j) ∧ Theme(e, x)))`
**Output (De Dicto):** `∃e(Seek(e) ∧ Agent(e, j) ∧ Theme(e, ^Unicorn))`

**Input:** "Mary needs a doctor"
**Output (De Re):** `∃x(Doctor(x) ∧ Need(m, x))` - specific doctor
**Output (De Dicto):** `Need(m, ^Doctor)` - any doctor

**Input:** "John believes a spy exists"
**Output (De Re):** `∃x(Spy(x) ∧ Believe(j, Exists(x)))` - specific spy
**Output (De Dicto):** `Believe(j, ∃x(Spy(x)))` - belief in existence

### Adjective Output

**Input:** "A small elephant ran." (Subsective)
**Output:** `∃x(S(x, ^E) ∧ E(x) ∧ ∃e(Run(e) ∧ Agent(e, x)))`

**Input:** "A red ball rolled." (Intersective)
**Output:** `∃x(R(x) ∧ B(x) ∧ ∃e(Roll(e) ∧ Agent(e, x)))`

**Input:** "A large mouse ran." (Subsective)
**Output:** `∃x(L(x, ^M) ∧ M(x) ∧ ∃e(Run(e) ∧ Agent(e, x)))`

### Generalized Quantifier Output

**Input:** "Many dogs bark."
**Output:** `MANY x(D(x) ∧ B(x))`

**Input:** "Most birds fly."
**Output:** `MOST x(B(x) ∧ F(x))`

**Input:** "Few cats swim."
**Output:** `FEW x(C(x) ∧ S(x))`

### Measurement Output (Phase 8)

**Input:** "John is 2 inches taller than Mary."
**Output:** `Taller(j, m, 2 inches)`

**Input:** "The rope is 5 meters long."
**Output:** `Long(rope, 5 meters)`

**Input:** "Set A has cardinality aleph_0."
**Output:** `Cardinality(A, aleph_0)`

**Input:** "The temperature is 98.6 degrees."
**Output:** `Temperature(t, 98.6 degrees)`

### Zero-Derivation Output (Phase 9)

**Input:** "The committee tabled the discussion."
**Output:** `∃e(Table(e) ∧ Agent(e, committee) ∧ Theme(e, discussion))`

**Input:** "She emailed him."
**Output:** `∃e(Email(e) ∧ Agent(e, she) ∧ Theme(e, him))`

**Input:** "John googled the answer."
**Output:** `∃e(Google(e) ∧ Agent(e, j) ∧ Theme(e, answer))`

### VP Ellipsis Output (Phase 10a)

**Input:** "John runs. Mary does too."
**Output:** `Run(j) ∧ Run(m)`

**Input:** "John can swim. Mary can too."
**Output:** `◇Swim(j) ∧ ◇Swim(m)`

**Input:** "John runs. Mary does not."
**Output:** `Run(j) ∧ ¬Run(m)`

**Input:** "John eats an apple. Mary does too."
**Output:** `∃e(Eat(e) ∧ Agent(e,j) ∧ Theme(e,apple)) ∧ ∃e(Eat(e) ∧ Agent(e,m) ∧ Theme(e,apple))`

### Sluicing Output (Phase 10b)

**Input:** "Someone left. I know who."
**Output:** `∃x(Leave(x)) ∧ Know(I, Question(y, Leave(y)))`

**Input:** "John ate something. I know what."
**Output:** `∃x(Eat(j,x)) ∧ Know(I, Question(y, Eat(j,y)))`

**Input:** "Someone called. I don't know who."
**Output:** `∃x(Call(x)) ∧ ¬Know(I, Question(y, Call(y)))`

**Input:** "Someone ran. I wonder who."
**Output:** `∃x(Run(x)) ∧ Wonder(I, Question(y, Run(y)))`

### Topicalization Output

**Input:** "The apple, John ate."
**Output:** `∃x(((Apple(x) ∧ ∀y((Apple(y) → y = x))) ∧ Eat(J, x)))`

**Input:** "The red apple, John ate."
**Output:** `∃x(((Red(x) ∧ Apple(x) ∧ ∀y((...) → y = x))) ∧ Eat(J, x)))`

**Input:** "A book, Mary read."
**Output:** `∃x((Book(x) ∧ Read(M, x)))` - indefinite topic

### Long-Distance Wh-Movement Output

**Input:** "Who did John say Mary loves?"
**Output:** `λx.Say(J, Love(M, x))` - gap filled in embedded clause

**Input:** "To whom did John give the book?"
**Output:** `λx.Give(J, book, x)` - pied-piped preposition

### Embedded Clause (Sentential Complement) Output

**Input:** "John said Mary runs."
**Output:** `Say(J, [Run(M)])` - embedded clause as argument with bracket notation

**Input:** "Who did John say Mary loves?"
**Output:** `λx.Past(Say(J, [Love(M, x)]))` - gap filled in embedded Proposition

**Input:** "John believes Mary won."
**Output:** `Believe(J, [Past(Win(M))])` - propositional attitude with clause argument

### Reichenbach Temporal Output

**Input:** "John had run." (Past Perfect)
**Output:** `Precedes(e, r) ∧ Precedes(r, S) ∧ Run(e, j)` - E < R < S

**Input:** "John will have run." (Future Perfect)
**Output:** `Precedes(S, r) ∧ Precedes(e, r) ∧ Run(e, j)` - S < R, E < R

**Input:** "John has run." (Present Perfect)
**Output:** `Precedes(e, r) ∧ Run(e, j)` - E < R (R = S implicit)

---

## Glossary

### First-Order Logic Terms

| Term | Definition |
|------|------------|
| **Predicate** | A property or relation: P(x), Loves(x,y) |
| **Quantifier** | Binds variables: ∀ (universal), ∃ (existential), Gen (generic) |
| **Generic Quantifier** | Law-like generalization over a kind: "Birds fly" → Gen x(Bird(x) → Fly(x)) |
| **Variable** | A placeholder: x, y, z |
| **Constant** | A named individual: socrates, fido |
| **Connective** | Logical operators: ∧ (and), ∨ (or), → (implies), ↔ (iff), ¬ (not) |
| **Formula** | A well-formed logical expression |
| **Scope** | The extent of a quantifier's binding |
| **Free Variable** | A variable not bound by any quantifier |
| **Bound Variable** | A variable within a quantifier's scope |

### Modal Logic Terms

| Term | Definition |
|------|------------|
| **Necessity (□)** | True in all possible worlds |
| **Possibility (◇)** | True in at least one possible world |
| **Alethic** | Concerning truth and necessity |
| **Deontic** | Concerning obligation and permission |
| **Epistemic** | Concerning knowledge and belief |

### Linguistic Terms

| Term | Definition |
|------|------------|
| **Noun Phrase** | A noun with modifiers: "the tall man" |
| **Verb Phrase** | A verb with complements: "loves Mary" |
| **Relative Clause** | A clause modifying a noun: "who runs" |
| **Anaphora** | Reference to a previous expression |
| **Definiteness** | Whether a noun is specific: "the" vs "a" |
| **Aspect** | Temporal structure of events |
| **Thematic Role** | Semantic role: agent, patient, theme |
| **Gapping** | Ellipsis of a verb in coordination: "John ate an apple, and Mary, a pear" |
| **PP-Attachment** | Where a prepositional phrase attaches: VP (instrument) or NP (modifier) |
| **Bare Plural** | Plural noun without determiner: "birds" (triggers generic reading) |
| **Collective Verb** | Verb requiring group action: "gather", "meet", "disperse" |
| **Distributive Verb** | Verb applying to each individual: "bark", "run", "sleep" |
| **Mereology** | Theory of parts and wholes; used for plural semantics |
| **Thematic Role** | Semantic role in event: Agent, Patient, Theme, Goal, etc. |
| **Control Verb** | Verb where embedded subject is controlled: "want", "try" |
| **Raising Verb** | Verb where subject raises from embedded clause: "seem" |
| **PRO** | Silent pronoun in infinitival clauses bound by controller |
| **Presupposition** | Background assumption triggered by certain expressions |
| **Focus Particle** | Word highlighting alternatives: "only", "even", "just" |
| **Counterfactual** | Conditional contrary to fact: "if...had...would" |
| **Deixis** | Contextual reference: "this/that" (proximal/distal), "here/there", "now/then" |
| **Ditransitive Verb** | Verb taking two objects: "give", "send", "tell" (Agent, Recipient, Theme) |
| **Gerund** | Verb form functioning as noun: "Running is fun", "I love swimming" |
| **Causal Connective** | Word linking cause to effect: "because" → Cause(antecedent, consequent) |
| **Mass Noun** | Uncountable noun: "water", "rice", "information" (quantified by "much"/"little") |
| **Reciprocal** | Bidirectional relation with "each other": P(x,y) ∧ P(y,x) |
| **NPI (Negative Polarity Item)** | Words like "any" requiring negative context for existential reading |
| **Free Choice Any** | Universal "any" in positive contexts: ∀x |
| **Garden Path** | Sentence requiring structural reanalysis due to initial misparse |
| **Reduced Relative** | Relative clause without "who/that": "the man seen" = "the man who was seen" |
| **Perfect Aspect** | Completed action with current relevance: "has eaten" → Perf(φ) |
| **Progressive Aspect** | Ongoing action: "is eating" → Prog(φ) |
| **Habitual Aspect** | Present tense activity/accomplishment/achievement interpretation: "runs" → HAB(Run(x)) |
| **Iterative Aspect** | Progressive semelfactive producing repeated event: "is knocking" → ITER(Knock) |
| **Aspect Chain** | Stacked aspect operators: modal + perfect + passive + progressive |
| **Contact Clause** | Relative clause without overt "who/that": "the man I saw" = "the man that I saw" |
| **Vendler Class** | Lexical aspect category: State, Activity, Accomplishment, Achievement, Semelfactive |
| **Stative** | Verb class feature (+static): no change over time (know, love, exist) |
| **Durative** | Verb class feature (+durative): extends over time (run, build) vs punctual (win, knock) |
| **Telic** | Verb class feature (+telic): has natural endpoint (build, win) vs atelic (run, know) |
| **Semelfactive** | Punctual, atelic verb class: single events (knock, blink, cough) |
| **Aktionsart** | German term for lexical aspect; verb-inherent temporal properties (synonym: Vendler class) |
| **Subsective Adjective** | Adjective whose meaning depends on noun class: "small" relative to elephants vs mice |
| **Intersective Adjective** | Adjective forming independent predicate: "red" applies regardless of noun |
| **Non-Intersective Adjective** | Adjective modifying the noun concept itself: "fake gun" |
| **Generalized Quantifier** | Quantifiers beyond ∀/∃: MANY, MOST, FEW with cardinality semantics |
| **Degree Phrase** | Measure expression modifying comparison: "2 inches" in "2 inches taller" |
| **Absolute Measurement** | Direct dimension attribution: "5 meters long" |
| **Symbolic Number** | Mathematical constant: aleph_0, omega for infinite cardinals |
| **Compound Identifier** | Noun followed by proper name or single letter label: "set A" → set_A |
| **Zero-Derivation** | Conversion of a word from one category to another without morphological change: "table" (noun) → "table" (verb) |
| **VP Ellipsis** | Omission of a verb phrase that is recoverable from context: "John runs. Mary does too." = Mary runs |
| **Sluicing** | Ellipsis of a wh-clause recoverable from context: "Someone left. I know who." = I know who left |

### Implementation Terms

| Term | Definition |
|------|------------|
| **Token** | A classified unit from the lexer |
| **Lexeme** | The actual text of a token |
| **AST** | Abstract Syntax Tree (arena-allocated with Copy semantics) |
| **Parse Forest** | Multiple AST trees for ambiguous sentences; returned by compile_ambiguous() |
| **Recursive Descent** | Top-down parsing strategy with backtracking for ellipsis |
| **Precedence** | Operator binding strength |
| **Interning** | Storing strings once, referencing by ID |
| **Arena Allocation** | Batch memory allocation via bumpalo; enables Copy AST nodes |
| **Beta Reduction** | Lambda calculus substitution |
| **Backtracking** | Parser technique for handling gapping by rewinding and retrying |
| **Sigma (σ)** | Term constructor for maximal sum of a predicate: σx.Dog(x) |
| **Distributive (*)** | Expression wrapper for distributive readings over plurals |
| **Group (⊕)** | Term constructor for sum of individuals: J ⊕ M |
| **NeoEvent** | Expression with event variable and thematic role assignments |
| **Control** | Expression for control/raising verb structures |
| **ThematicRole** | Enum: Agent, Patient, Theme, Goal, Source, Recipient, Instrument, Location, Time, Manner |
| **Recipient** | Thematic role for indirect object in ditransitive verbs |
| **Causal** | Expression variant representing cause-effect relationships: Cause(antecedent, consequent) |
| **MeasureKind** | Enum for quantity expressions: Much, Little (used with mass nouns) |
| **AstContext** | Unified struct holding all arena allocators for AST construction |
| **ParserCheckpoint** | RAII struct for parser backtracking with automatic restore |
| **ParserGuard** | RAII struct with Deref for transparent parser access; auto-restores on drop unless commit() called |
| **Visitor** | Trait for traversing AST nodes without manual recursion |
| **Fluent builders** | Inline methods on AstContext (binary, unary, quantifier, temporal, aspectual, modal) for ergonomic AST construction |
| **Semantic token sets** | Const arrays (WH_WORDS, MODALS) grouping related tokens for check_any() matching |
| **Zero-alloc transpile** | Output methods using Write trait to avoid String allocation |
| **Span** | Byte range (start, end) for source location tracking on tokens |
| **display_with_source()** | Renders ParseError with line numbers and underline markers pointing to error location |
| **assert_snapshot!** | Macro for golden master testing; compares output against stored snapshots in tests/snapshots/ |
| **Levenshtein distance** | Edit distance algorithm for finding similar words; used for 'did you mean?' suggestions |
| **find_similar()** | Finds closest vocabulary match within threshold for typo correction |
| **Style** | ANSI color wrapper with red(), blue(), cyan(), green(), bold_red() methods |
| **VoiceOperator** | Enum for voice handling in AST: Passive variant |
| **VerbClass** | Enum for Vendler categories: State, Activity, Accomplishment, Achievement, Semelfactive |
| **VerbEntry** | Struct with lemma, time, aspect, and class fields for verb dictionary entries |
| **is_stative()** | VerbClass method returning true for State class |
| **is_durative()** | VerbClass method returning true for State, Activity, Accomplishment |
| **is_telic()** | VerbClass method returning true for Accomplishment, Achievement |
| **is_negative_context()** | Parser method tracking negation depth for NPI licensing |
| **is_followed_by_gerund()** | Parser helper checking if presupposition trigger is followed by gerund; prevents false presupposition on bare "stopped" |
| **parse_aspect_chain()** | Parser method handling complex verb group stacking |
| **parse_aspect_chain_with_term()** | Parser method for aspect chains with variable subjects (used in relative clause + modal combinations) |
| **Stacked Relatives** | Multiple relative clauses modifying same head noun: "the book that X read that Y wrote" |
| **try_reduced_relative_interpretation()** | Parser method for garden path reanalysis |
| **is_contact_clause_pattern()** | Parser lookahead for NP+NP+Verb contact clause detection |
| **Island** | Scope boundary preventing quantifier extraction: if/and/or clauses |
| **island_id** | u32 field on Quantifier identifying its scope island |
| **enumerate_scopings()** | Function returning ScopeIterator over all quantifier scope readings |
| **ScopeIterator** | Lazy iterator implementing ExactSizeIterator for scope readings |
| **group_by_island()** | Groups quantifiers by island_id to constrain permutations |
| **De Re** | "Of the thing" - object exists, quantifier scopes wide |
| **De Dicto** | "Of the word" - intensional reading, quantifier scopes narrow |
| **Opaque Verb** | Verb creating intensional context: seek, want, believe, need, fear |
| **is_opaque_verb()** | Function checking if a verb creates an opaque context |
| **Intension (^)** | Montague up-arrow marking concept/property vs individual |
| **Term::Intension** | Term variant for intensional predicates: ^Unicorn |
| **Expr::Intensional** | Expression wrapper for opaque verb contexts |
| **substitute_respecting_opacity()** | Substitution that blocks inside intensional contexts |
| **enumerate_intensional_readings()** | Generates de re and de dicto readings for opaque verb sentences |
| **IntensionalContext** | Struct tracking opaque verb, quantifier variable, and restrictor |
| **compile_all_scopes()** | Public API returning all scope + intensionality readings |
| **Topicalization** | Object fronting with comma intonation break: "NP, Subject Verb" pattern |
| **filler_gap** | Parser field (Option<Symbol>) tracking wh-filler for long-distance dependencies |
| **Long-Distance Dependency** | Extraction across clause boundaries: "Who did John say Mary loves?" |
| **Pied-Piping** | P+wh fronting: "To whom" instead of "Who...to" |
| **wrap_with_definiteness_full()** | NounPhrase wrapper preserving adjectives during topicalization |
| **Phase 4 Movement Tests** | tests/phase4_movement.rs: topicalization, adjective preservation, pronoun subjects |
| **Term::Proposition** | Term variant wrapping embedded Expr for sentential complements |
| **Sentential Complement** | Clause serving as argument: "John said [Mary runs]" |
| **Bracket Notation [expr]** | Transpilation format for embedded clauses to distinguish from conjunction |
| **Phase 5 Wh-Movement Tests** | tests/phase5_wh_movement.rs: long-distance extraction, embedded clauses, double embedding |
| **Reichenbach Semantics** | Three-point temporal model with E (event), R (reference), S (speech) |
| **Event Point (E)** | When the event occurs in Reichenbach model |
| **Reference Point (R)** | Temporal vantage point for viewing event |
| **Speech Point (S)** | Time of utterance |
| **Precedes(x, y)** | Temporal ordering predicate: x before y |
| **Phase 6 Complex Tense Tests** | tests/phase6_complex_tense.rs: Reichenbach E/R/S temporal constraints |
| **is_subsective()** | Generated function checking if adjective is subsective (relative to class) |
| **QuantifierKind::Many** | AST variant for generalized "many" quantifier |
| **QuantifierKind::Most** | AST variant for generalized "most" quantifier |
| **QuantifierKind::Few** | AST variant for generalized "few" quantifier |
| **Term::Intension** | Term variant for Montague up-arrow notation (^Noun) in subsective contexts |
| **Dimension** | Enum for measurement categories: Length, Time, Weight, Temperature, Cardinality |
| **NumberKind** | Enum for numeric types: Real(f64), Integer(i64), Symbolic(Symbol) |
| **Term::Value** | Term variant storing numeric value with optional unit Symbol and Dimension |
| **Comparative.difference** | Optional field for measure phrase in comparative expressions |
| **TokenType::Number** | Token variant storing numeric literal as interned Symbol |
| **parse_measure()** | Parser method for measure phrase expressions |
| **Phase 8 Degree Tests** | tests/phase8_degrees.rs: numeric measurement and degree semantics |
| **check_proper_name_or_label()** | Parser helper detecting proper names or single uppercase letter labels for compound identifier parsing |
| **Passive Agent Extraction** | Pattern matching "by X" after passive "been" to identify the semantic agent in passive constructions |
| **Consonant Cluster Heuristic** | Morphological rule: vowel + consonant + l/r at word end suggests silent-e lemma recovery (tabl → table) |
| **Phase 9 Zero-Derivation Tests** | tests/phase9_conversion.rs: noun→verb conversion with silent-e recovery |
| **EventTemplate** | Struct storing verb + non-agent thematic roles + modifiers for VP ellipsis reconstruction |
| **Phase 10a VP Ellipsis Tests** | tests/phase10_ellipsis.rs: VP ellipsis with does too, modal too, negation, and objects |
| **Contraction Expansion** | Lexer splits negative contractions: don't→do+not, won't→will+not, can't→cannot |
| **Phase 10b Sluicing Tests** | tests/phase10b_sluicing.rs: sluicing with who/what, negation, embedding verbs |
| **Verb-First Priority** | Classification order: verbs checked before nouns in lexer. Parser safety net via consume_content_word() accepts Verb tokens in noun positions. |
| **disambiguation_not_verbs** | Lexicon list of words that should NOT be classified as verbs despite having verb forms (ring, bus). Returns Noun if also in nouns list. |
| **Polysemy Resolution** | Handling words with multiple parts of speech. Verb-first + parser safety net enables "I love you" and "Love is real" from same token type. |
| **compile_forest()** | Phase 12 API returning Vec<String> of all valid parse readings for ambiguous sentences. |
| **MAX_FOREST_READINGS** | Constant (12) limiting parse forest size to prevent exponential blowup. |
| **noun_priority_mode** | Parser flag that prefers noun interpretation for Ambiguous tokens; used for lexical ambiguity forking. |
| **TokenType::Ambiguous** | Token variant with primary interpretation and alternatives Vec for polysemous words (duck, bear, love). |
| **Sort** | Phase 11 ontological type category: Human, Animate, Celestial, Abstract, Physical, Value. |
| **lookup_sort()** | Returns Sort for proper names; used for semantic type checking. |
| **is_compatible_with()** | Sort method checking type subsumption (Human⊂Animate⊂Physical). |
| **Lexical Ambiguity** | Words with multiple parts of speech requiring parse forest (e.g., "duck" as Noun or Verb). |
| **Structural Ambiguity** | Syntactic attachment ambiguity (PP attachment, coordination scope) handled via pp_attachment_mode. |
| **MweTrie** | Trie data structure for multi-word expression pattern storage and efficient longest-match lookup. |
| **apply_mwe_pipeline()** | Post-tokenization function that collapses multi-token MWE sequences into single tokens. |
| **build_mwe_trie()** | Creates default MWE vocabulary trie with compound nouns, idioms, and phrasal verbs. |
| **find_bridging_wholes()** | Ontology function returning possible whole objects for a given part noun (e.g., "engine" → ["car", "plane"]). |
| **check_sort_compatibility()** | Validates predicate-subject sort match; returns true if compatible or no requirement exists. |
| **PartOf** | Term relation representing part-whole relationship in bridging anaphora (e.g., PartOf(engine, car)). |
| **Bridging Anaphora** | Pragmatic inference linking a definite NP to an antecedent's part (e.g., "a car... the engine" → engine is part of car). |
| **Copula Adjective Preference** | Parser heuristic: after copula (is/was), simple-aspect Verbs with Adjective alternative prefer Adjective reading. |
| **is_adjective_like()** | Lexer heuristic checking if word could be an adjective for ambiguity detection. |
| **is_noun_like()** | Lexer heuristic checking if word could be a noun for ambiguity detection. |
| **is_verb_like()** | Lexer heuristic checking if word could be a verb for disambiguation. |
| **NPI (Negative Polarity Item)** | Words like "any", "ever", "anything" that require negative context for existential interpretation. |
| **Free Choice Any** | "Any" in affirmative contexts producing universal quantification: "Any cat hunts" → ∀x. |
| **Negative Quantifier** | Inherently negative quantifiers (nobody, nothing, no one) that produce ∀x(R(x) → ¬P(x)). |
| **NPI Licensing** | Process by which negative context triggers existential interpretation of NPIs. |

---

## Integration Tests

Comprehensive test suite validating parsing and transpilation across 15 linguistic phases.

**Location:** `tests/`

#### Phase 1: Garden Path

**File:** `tests/phase1_garden_path.rs`

Garden path sentences requiring structural reanalysis. Parser detects reduced relatives via backtracking when initial parse leaves unparsed tokens.

**Example:** "The horse raced past the barn fell." → ∃x(Horse(x) ∧ RacedPast(x, barn) ∧ Fell(x))

---

#### Phase 2: Polarity Items

**File:** `tests/phase2_polarity.rs`

Negative Polarity Items (NPIs). 'any' is existential in negative/conditional contexts, universal in positive contexts. Parser tracks negative_depth for NPI licensing.

**Example:** "Not any dogs run." → ¬∃x(D(x) ∧ R(x)) vs "Any dog runs." → ∀x(D(x) → R(x))

---

#### Phase 3: Temporal Logic

**File:** `tests/phase3_time.rs`

Reichenbach temporal semantics with Event (E), Reference (R), and Speech (S) points. Tests simple tense, perfect aspect, and temporal anchoring.

**Example:** "John had run." (past perfect) → Precedes(e, r) ∧ Precedes(r, S)

---

#### Phase 3: Aspect & Aktionsart

**File:** `tests/phase3_aspect.rs`

Vendler aspectual classes (State/Activity/Accomplishment/Achievement/Semelfactive) and grammatical aspect interaction. Habitual for present-tense activities.

**Example:** "John is knocking." (semelfactive+prog) → ITER(Knock(j))

---

#### Phase 4: Topicalization

**File:** `tests/phase4_movement.rs`

Filler-gap dependencies and object fronting. Tests NP-fronting with adjective preservation and pronoun subjects.

**Example:** "The apple, John ate." → Eat(J, apple) with fronted Theme

---

#### Phase 4: Reciprocals

**File:** `tests/phase4_reciprocals.rs`

Reciprocal 'each other' expands to bidirectional predicate conjunction for plural subjects.

**Example:** "John and Mary love each other." → Love(j,m) ∧ Love(m,j)

---

#### Phase 5: Wh-Movement

**File:** `tests/phase5_wh_movement.rs`

Long-distance wh-dependencies across embedded clauses. Filler-gap binding through subordinate clauses with Term::Proposition wrapping.

**Example:** "Who did John say Mary loves?" → λx.Say(J, [Love(M, x)])

---

#### Phase 6: Complex Tense

**File:** `tests/phase6_complex_tense.rs`

Reichenbach temporal constraints with explicit E/R/S point relations. Verifies Precedes() predicate output.

**Example:** Past perfect: E < R < S; Future perfect: S < R, E < R

---

#### Phase 7: Intensional Semantics

**File:** `tests/phase7_semantics.rs`

Subsective adjectives (S(x, ^E) format) and generalized quantifiers (MANY, MOST, FEW with cardinality semantics).

**Example:** "A small elephant ran." → ∃x(S(x, ^E) ∧ E(x) ∧ Run(x))

---

#### Phase 7: De Re/De Dicto

**File:** `tests/intensionality_tests.rs`

Intensional ambiguity with opaque verbs. Tests both readings for sentences with seek, want, believe, need, fear.

**Example:** "John seeks a unicorn." → De Re: ∃x(U(x) ∧ Seek(j,x)) vs De Dicto: Seek(j, ^Unicorn)

---

#### Phase 8: Degrees & Comparatives

**File:** `tests/phase8_degrees.rs`

Numeric measurements and degree semantics. Tests comparatives with measure phrases, absolute measurements, and symbolic cardinality.

**Example:** "John is 2 inches taller than Mary." → Taller(j, m, 2 inches)

---

#### Phase 9: Noun/Verb Conversion

**File:** `tests/phase9_conversion.rs`

Zero-derivation (noun→verb): tabled, emailed, googled. Morphological heuristics for silent-e lemma recovery.

**Example:** "The committee tabled the motion." → Table(committee, motion)

---

#### Phase 10a: VP Ellipsis

**File:** `tests/phase10_ellipsis.rs`

VP ellipsis reconstruction via EventTemplate. Handles 'does too', modal ellipsis, negative ellipsis, and ellipsis with objects.

**Example:** "John runs. Mary does too." → Run(j) ∧ Run(m)

---

#### Phase 10b: Sluicing

**File:** `tests/phase10b_sluicing.rs`

Sluicing reconstruction: wh-words at sentence boundary after embedding verbs. Handles contractions (don't know who).

**Example:** "Someone left. I know who." → ∃x(Leave(x)) ∧ Know(I, ?y[Leave(y)])

---

#### Phase 11: Ontological Sorts

**File:** `tests/phase11_sorts.rs`

Sort system with type hierarchy (Human⊂Animate⊂Physical). Sort compatibility checking for semantic validation.

**Example:** Sort::Human.is_compatible_with(Sort::Animate) → true

---

#### Phase 11: Metaphor Detection

**File:** `tests/phase11_metaphor.rs`

Metaphor detection via sort violations. Distinguishes literal copula from metaphorical assertions.

**Example:** "The king is bald." → literal; "Juliet is the sun." → sort violation → metaphor

---

#### Phase 12: Parse Forest

**File:** `tests/phase12_ambiguity.rs`

Lexical and structural ambiguity handling. compile_forest() returns Vec of all valid readings for ambiguous sentences.

**Example:** "I saw her duck." → 2 readings (duck=Noun vs duck=Verb)

---

#### Phase 13: Multi-Word Expressions

**File:** `tests/phase13_mwe.rs`

MWE processing: compound nouns (fire engine → FireEngine), idioms (kicked the bucket → Die), phrasal verbs (gave up → Surrender). Trie-based pipeline collapses multi-token sequences into single semantic units.

**Example:** "John kicked the bucket." → Die(j)

---

#### Phase 14: Ontology & Bridging

**File:** `tests/phase14_ontology.rs`

Bridging anaphora for part-whole inference (PartOf relation). Metaphor detection via sort violations. Sort compatibility checking for predicates.

**Example:** "I bought a car. The engine smoked." → PartOf(engine, car)

---

#### Phase 15: Negation & Polarity

**File:** `tests/phase15_negation.rs`

NPI processing: free choice 'any' (universal), NPI 'any' with negation (existential), negative quantifiers (nobody/nothing/no one), temporal NPIs (never/ever), scope interactions. Licensing determines existential vs universal interpretation.

**Example:** "Any cat hunts." → ∀x(Cat(x) → Hunt(x)); "John did not see any cat." → ¬∃x(Cat(x) ∧ See(j,x))

---

#### Phase 16: Aspect Stack

**File:** `tests/phase16_aspect.rs`

Complex aspect operator combinations: Perfect+Progressive, Perfect+Passive, Modal+Perfect+Progressive. Tests proper operator nesting without conflation (e.g., Perfect+Progressive should NOT imply Passive).

**Example:** "John has been eating apples." → Perf(Prog(Eat(j, apples)))

---

#### Phase 17: Comparatives & Superlatives

**File:** `tests/phase17_degrees.rs`

Extended degree semantics: comparatives with measure phrases, clausal comparative ellipsis, and superlatives with domain restriction. Superlatives expand to universal quantification over the comparison class.

**Example:** "John climbed the highest mountain." → ∀x((Mountain(x) ∧ x ≠ m) → Higher(m, x))

---

#### Phase 18: Plurality

**File:** `tests/phase18_plurality.rs`

Collective vs distributive verb semantics. Mixed verbs fork readings for plural subjects (lifted → collective OR distributive). Collective verbs (gathered) force group reading. Distributive verbs (slept) force individual reading.

**Example:** "The boys lifted the piano." → Collective: Lift(σB, piano) OR Distributive: *Lift(σB, piano)

---

#### Phase 19: Group Plurals

**File:** `tests/phase19_group_plurals.rs`

Group existential quantification for cardinal indefinites with collective readings. Cardinal + mixed verb forks into distributive (∃=n) and collective (Group/Count/Member) readings. Collective verbs force group reading.

**Example:** "Two boys lifted a rock." → Collective: ∃g(Group(g) ∧ Count(g, 2) ∧ ∀x(Member(x, g) → B(x)) ∧ Lift(g, rock))

---

#### Phase 20: Axiom Layer

**File:** `tests/phase20_axioms.rs`

Semantic axiom expansion for meaning postulates. Bachelor→Unmarried∧Male∧Adult, privative adjectives (fake→¬N∧Resembles(^N)), verb entailments (murder→kill), and hypernym chains (dog→animal→mammal). Pipeline position: Parser→Axioms→Pragmatics.

**Example:** "John is a bachelor." → B(J) ∧ Unmarried(J) ∧ Male(J) ∧ Adult(J)

---

#### Phase 21: Block Headers

**File:** `tests/phase21_block_headers.rs`

Parsing ## Main and other block headers that trigger imperative mode. Block headers mark the transition from declarative logic to executable code.

**Example:** "## Main" triggers imperative parsing mode

---

#### Phase 21: Imperative Verbs

**File:** `tests/phase21_imperative_verbs.rs`

Let/Set/Return statement parsing in imperative blocks. Let binds values, Set mutates, Return exits functions.

**Example:** "Let x be 5." → let x = 5;

---

#### Phase 21: Ownership

**File:** `tests/phase21_ownership.rs`

Rust-style ownership semantics via natural language verbs. Give performs moves, Show performs immutable borrows. Tracks owned/moved/borrowed states.

**Example:** "Give x to f." → f(x) // x is moved

---

#### Phase 22: Equality

**File:** `tests/phase22_equals.rs`

Identity predicates and equality relations. Handles 'is equal to', 'is identical to', and numeric equality.

**Example:** "x is equal to y" → x = y

---

#### Phase 22: Indexing

**File:** `tests/phase22_index.rs`

Array and collection indexing operations. Supports numeric indices and slice syntax.

**Example:** "the third element of xs" → xs[2]

---

#### Phase 22: Is-Rejection

**File:** `tests/phase22_is_rejection.rs`

Filtering non-predicate uses of 'is' copula in imperative context. Distinguishes identity from predication.

**Example:** "x is large" vs "x is 5"

---

#### Phase 22: Resolution

**File:** `tests/phase22_resolution.rs`

Anaphora and reference resolution in imperative blocks. Resolves pronouns and definite descriptions to bound variables.

**Example:** "Let x be 5. Return it." → it resolves to x

---

#### Phase 22: Scope

**File:** `tests/phase22_scope.rs`

Variable scope and quantifier interactions in imperative code. Handles block scoping and shadowing.

**Example:** Block-level variable scoping

---

#### Phase 23: Blocks

**File:** `tests/phase23_blocks.rs`

Indentation-based block structure parsing. Python-style significant whitespace with Colon/Indent/Dedent tokens.

**Example:** Indent → block body → Dedent

---

#### Phase 23: Parsing

**File:** `tests/phase23_parsing.rs`

Parser internals and mode switching between declarative and imperative modes. Tests ParserMode enum.

**Example:** Declarative mode ↔ Imperative mode

---

#### Phase 23: Statements

**File:** `tests/phase23_stmt.rs`

Stmt enum variants: Let, Set, Call, If, While, Return, Assert, Give, Show. The imperative AST types.

**Example:** Stmt::Let { name, value }

---

#### Phase 23: Tokens

**File:** `tests/phase23_tokens.rs`

Token type verification for imperative constructs. Tests Give, Show, Let, Set, Return, Assert token recognition.

**Example:** TokenType::Give, TokenType::Show

---

#### Phase 23: Types

**File:** `tests/phase23_types.rs`

TypeRegistry and DiscoveryPass for two-pass compilation. First pass discovers type definitions, second pass resolves references.

**Example:** ## Definition blocks → TypeRegistry

---

#### Phase 24: Code Generation

**File:** `tests/phase24_codegen.rs`

Rust code emission for literals and expressions. Converts imperative AST to valid Rust source code.

**Example:** Stmt → fn main() { ... }

---

#### Phase 24: Pipeline Wiring

**File:** `tests/phase24_wired_types.rs`

Two-pass compilation pipeline integration. DiscoveryPass runs before parser to build TypeRegistry. Parser uses registry for type vs predicate disambiguation.

**Example:** Stack of Integers → Generic type when Stack is defined

---

#### Phase 25: Type Expressions

**File:** `tests/phase25_type_expr.rs`

Type annotations for Let statements. Supports primitives (Int→i64, Nat→u64, Text→String), generics (List of Int→Vec<i64>), multi-param generics (Result of Int and Text), nested generics, and mutable bindings.

**Example:** Let x: Int be 5. → let x: i64 = 5;

---

#### Phase 25: Assertions

**File:** `tests/phase25_assertions.rs`

Logic kernel assertions via Assert statements. Bridges imperative code to declarative verification using debug_assert! macros.

**Example:** "Assert that x is positive." → debug_assert!(x > 0)

---

#### Phase 25: Smoke Tests

**File:** `tests/phase25_smoke_tests.rs`

Aspirational tests for advanced linguistic phenomena. Covers scopal adverbs (almost/barely wrapping events), negation scope ambiguity, donkey anaphora, intensional identity, performatives, distanced phrasal verbs, and double focus operators. Some tests expected to fail until features implemented.

**Example:** "John almost killed Mary." → Almost(∃e(Kill(e) ∧ Agent(e, J) ∧ Theme(e, M)))

---

#### Phase 26: End-to-End

**File:** `tests/phase26_e2e.rs`

Full pipeline tests: English → AST → Rust code. Tests compile_to_rust output for complete programs.

**Example:** English source → executable Rust

---

#### Phase 27: Guards

**File:** `tests/phase27_guards.rs`

Guard clauses and conditional patterns. Handles 'if' conditions and pattern guards in function definitions.

**Example:** "If x is negative, return 0." → guard clause

---

#### Phase 28: Precedence

**File:** `tests/phase28_precedence.rs`

Operator precedence and associativity. Ensures correct parsing of complex expressions with mixed operators.

**Example:** a + b * c → a + (b * c)

---

#### Phase 29: Runtime Injection

**File:** `tests/phase29_runtime.rs`

Embeds logos_core/ runtime into compiled programs. Type aliases (Nat, Int, Real, Text, Bool, Unit) and IO functions (show, read_line) per Spec §10.5 and §10.6.1.

**Example:** use logos_core::prelude::*; // Auto-injected

---

#### Phase 30: Collections & Iteration

**File:** `tests/phase30_iteration.rs`

Seq<T> generic type, list literals [1, 2, 3], repeat loops (for x in list:), range syntax (from N to M), and Showable trait. Mode-dependent 'in' keyword handling.

**Example:** Repeat for x in [1, 2, 3]: → for x in vec![1, 2, 3]

---

#### Phase 31: User-Defined Types

**File:** `tests/phase31_structs.rs`

Struct definitions with encapsulation. Syntax: 'A TypeName has: a [public] field, which is Type.' Constructor generation (new Type), field access (var's field), field mutations (Set var's field to value), and visibility modifiers (pub/private fields).

**Example:** A Point has: a public x, which is Int.

---

#### Phase 32: Function Definitions & Inference

**File:** `tests/phase32_functions.rs`

User-defined functions with ## To [verb] syntax. Call expression syntax f(x, y) for use in expressions, return type inference from body, and dual call syntax (Call f with x. for statements, f(x) for expressions).

**Example:** ## To add (a: Int) and (b: Int): → fn add(a: i64, b: i64) -> i64

---

#### Phase 33: Sum Types & Pattern Matching

**File:** `tests/phase33_enums.rs`

Algebraic data types with 'A Type is either:' syntax. Variant constructors with optional payloads (A Circle with radius value.), pattern matching via 'Inspect expr:' with match arms, and field bindings in patterns (When Circle (radius: r):).

**Example:** A Shape is either: A Circle with a radius, which is Int.

---

#### Phase 34: User-Defined Generics

**File:** `tests/phase34_generics.rs`

Generic type parameters with 'of [T]' syntax. Single-param (A Box of [T] has:), multi-param (A Pair of [A] and [B] has:), generic enums (A Maybe of [T] is either:), and turbofish instantiation (new Box of Int → Box::<i64>::default()).

**Example:** A Box of [T] has: a value, which is T.

---

#### Aktionsart/Vendler Classes

**File:** `tests/aktionsart_tests.rs`

Tests for Vendler's lexical aspect classes and their interaction with aspectual operators.

**Example:** State (know), Activity (run), Accomplishment (build), Achievement (win), Semelfactive (knock)

---

#### Complex Operator Chains

**File:** `tests/complex_combinations.rs`

Tests for complex modal + aspect + tense chains with proper operator nesting.

**Example:** Perfect + Passive + Progressive stacking

---

#### Parser Stress Tests

**File:** `tests/torture_tests.rs`

Edge case stress tests: deeply nested structures, unusual word orders, boundary conditions.

**Example:** Deeply nested relative clauses and coordinations

---

#### Core Integration Tests

**File:** `tests/integration_tests.rs`

Comprehensive tests covering quantifiers, modals, temporal logic, relative clauses, and basic parsing.

**Example:** Universal, existential, and generic quantification patterns

---

## Statistics

### By Compiler Stage
```
Lexer (token.rs, lexer.rs):           1691 lines
Parser (ast/, parser/):               10375 lines
Transpilation:                        1030 lines
Code Generation:                      986 lines
Semantics (lambda, context, view):    2880 lines
Type Analysis (analysis/):            809 lines
Support Infrastructure:               4133 lines
Desktop UI:                               8841 lines
Entry Point:                                 3 lines
```

### Totals
```
Source lines:        34306
Test lines:           9028
Total Rust lines: 43334
```

### File Counts
```
Source files: 85
Test files:   64
```
## Lexicon Data

The lexicon defines all vocabulary entries that drive the lexer and parser behavior.

**File:** `assets/lexicon.json`

**Contents:**
- **Keywords** (44 entries): quantifiers, connectives, modals
- **Pronouns** (9 entries): with gender/number/case features
- **Verbs** (252 entries): lemma, Vendler class, irregular forms, features (Ditransitive, SubjectControl, ObjectControl, Raising, Opaque, Factive, Performative, Collective)
- **Nouns** (113 entries): lemma, plural forms, features (Proper, Masculine, Feminine)
- **Adjectives** (65 entries): lemma, features (Intersective, NonIntersective, Gradable)
- **Closed classes**: prepositions, adverbs, scopal/temporal adverbs
- **Morphology rules**: needs_e_ing, needs_e_ed, stemming_exceptions

```json
{
  "keywords": {
    "all": "All",
    "every": "All",
    "no": "No",
    "some": "Some",
    "any": "Any",
    "most": "Most",
    "few": "Few",
    "many": "Many",
    "and": "And",
    "but": "And",
    "or": "Or",
    "if": "If",
    "then": "Then",
    "not": "Not",
    "is": "Is",
    "are": "Are",
    "was": "Was",
    "were": "Were",
    "that": "That",
    "who": "Who",
    "whom": "Who",
    "what": "What",
    "where": "Where",
    "when": "When",
    "why": "Why",
    "does": "Does",
    "do": "Do",
    "must": "Must",
    "shall": "Shall",
    "should": "Should",
    "can": "Can",
    "may": "May",
    "cannot": "Cannot",
    "would": "Would",
    "could": "Could",
    "had": "Had",
    "than": "Than",
    "itself": "Reflexive",
    "himself": "Reflexive",
    "herself": "Reflexive",
    "themselves": "Reflexive",
    "because": "Because",
    "anything": "Anything",
    "anyone": "Anyone",
    "anybody": "Anyone",
    "nothing": "Nothing",
    "nobody": "Nobody",
    "nowhere": "Nowhere",
    "ever": "Ever",
    "never": "Never",
    "repeat": "Repeat",
    "for": "For",
    "from": "From",
    "trust": "Trust"
  },
  "pronouns": [
    { "word": "i", "gender": "Unknown", "number": "Singular", "case": "Subject" },
    { "word": "he", "gender": "Male", "number": "Singular", "case": "Subject" },
    { "word": "she", "gender": "Female", "number": "Singular", "case": "Subject" },
    { "word": "it", "gender": "Neuter", "number": "Singular", "case": "Subject" },
    { "word": "they", "gender": "Unknown", "number": "Plural", "case": "Subject" },
    { "word": "you", "gender": "Unknown", "number": "Singular", "case": "Subject" },
    { "word": "him", "gender": "Male", "number": "Singular", "case": "Object" },
    { "word": "her", "gender": "Female", "number": "Singular", "case": "Object" },
    { "word": "her", "gender": "Female", "number": "Singular", "case": "Possessive" },
    { "word": "his", "gender": "Male", "number": "Singular", "case": "Possessive" },
    { "word": "my", "gender": "Unknown", "number": "Singular", "case": "Possessive" },
    { "word": "their", "gender": "Unknown", "number": "Plural", "case": "Possessive" },
    { "word": "them", "gender": "Unknown", "number": "Plural", "case": "Object" }
  ],
  "articles": {
    "the": "Definite",
    "a": "Indefinite",
    "an": "Indefinite",
    "this": "Proximal",
    "these": "Proximal",
    "those": "Distal"
  },
  "auxiliaries": {
    "will": "Future",
    "did": "Past"
  },
  "presupposition_triggers": {
    "stop": "Stop",
    "start": "Start",
    "begin": "Start",
    "regret": "Regret",
    "continue": "Continue",
    "realize": "Realize",
    "realise": "Realize",
    "know": "Know"
  },
  "number_words": {
    "one": 1, "two": 2, "three": 3, "four": 4, "five": 5,
    "six": 6, "seven": 7, "eight": 8, "nine": 9, "ten": 10
  },
  "verbs": [
    { "lemma": "Be", "class": "State", "forms": { "past": "was", "participle": "been", "gerund": "being" } },
    { "lemma": "Have", "class": "State", "forms": { "present3s": "has", "past": "had", "participle": "had", "gerund": "having" } },
    { "lemma": "Run", "class": "Activity", "forms": { "past": "ran", "gerund": "running" } },
    { "lemma": "See", "class": "State", "forms": { "past": "saw", "participle": "seen", "gerund": "seeing" } },
    { "lemma": "Give", "class": "Achievement", "forms": { "past": "gave", "participle": "given", "gerund": "giving" }, "features": ["Ditransitive"] },
    { "lemma": "Take", "class": "Achievement", "forms": { "past": "took", "participle": "taken", "gerund": "taking" } },
    { "lemma": "Go", "class": "Activity", "forms": { "past": "went", "participle": "gone", "gerund": "going" } },
    { "lemma": "Come", "class": "Achievement", "forms": { "past": "came", "participle": "come", "gerund": "coming" } },
    { "lemma": "Make", "class": "Accomplishment", "forms": { "past": "made", "gerund": "making" } },
    { "lemma": "Say", "class": "Activity", "forms": { "past": "said", "gerund": "saying" } },
    { "lemma": "Know", "class": "State", "forms": { "past": "knew", "participle": "known", "gerund": "knowing" }, "features": ["Opaque", "Factive"] },
    { "lemma": "Wonder", "class": "State", "forms": { "past": "wondered", "gerund": "wondering" }, "features": ["Opaque"] },
    { "lemma": "Think", "class": "State", "forms": { "past": "thought", "gerund": "thinking" }, "features": ["Opaque"] },
    { "lemma": "Tell", "class": "Activity", "forms": { "past": "told", "gerund": "telling" }, "features": ["Ditransitive", "ObjectControl"] },
    { "lemma": "Find", "class": "Achievement", "forms": { "past": "found", "gerund": "finding" } },
    { "lemma": "Put", "class": "Achievement", "forms": { "past": "put", "gerund": "putting" } },
    { "lemma": "Leave", "class": "Achievement", "forms": { "past": "left", "gerund": "leaving" } },
    { "lemma": "Bring", "class": "Activity", "forms": { "past": "brought", "gerund": "bringing" }, "features": ["Ditransitive"] },
    { "lemma": "Send", "class": "Achievement", "forms": { "past": "sent", "gerund": "sending" }, "features": ["Ditransitive"] },
    { "lemma": "Build", "class": "Accomplishment", "forms": { "past": "built", "gerund": "building" } },
    { "lemma": "Speak", "class": "Activity", "forms": { "past": "spoke", "participle": "spoken", "gerund": "speaking" } },
    { "lemma": "Write", "class": "Accomplishment", "forms": { "past": "wrote", "participle": "written", "gerund": "writing" } },
    { "lemma": "Hold", "class": "Activity", "forms": { "past": "held", "gerund": "holding" } },
    { "lemma": "Meet", "class": "Achievement", "forms": { "past": "met", "gerund": "meeting" }, "features": ["Collective"] },
    { "lemma": "Read", "class": "Activity", "forms": { "past": "read", "gerund": "reading" } },
    { "lemma": "Keep", "class": "State", "forms": { "past": "kept", "gerund": "keeping" } },
    { "lemma": "Set", "class": "Achievement", "forms": { "past": "set", "gerund": "setting" } },
    { "lemma": "Hear", "class": "State", "forms": { "past": "heard", "gerund": "hearing" } },
    { "lemma": "Mean", "class": "State", "forms": { "past": "meant", "gerund": "meaning" } },
    { "lemma": "Show", "class": "Achievement", "forms": { "past": "shown", "gerund": "showing" }, "features": ["Ditransitive"] },
    { "lemma": "Eat", "class": "Activity", "forms": { "past": "ate", "participle": "eaten", "gerund": "eating" } },
    { "lemma": "Sleep", "class": "Activity", "forms": { "past": "slept", "gerund": "sleeping" } },
    { "lemma": "Drink", "class": "Activity", "forms": { "past": "drank", "participle": "drunk", "gerund": "drinking" } },
    { "lemma": "Die", "class": "Achievement", "forms": { "past": "died", "gerund": "dying" } },
    { "lemma": "Grow", "class": "Accomplishment", "forms": { "past": "grew", "participle": "grown", "gerund": "growing" } },
    { "lemma": "Blow", "class": "Activity", "forms": { "past": "blew", "participle": "blown", "gerund": "blowing" } },
    { "lemma": "Throw", "class": "Activity", "forms": { "past": "threw", "participle": "thrown", "gerund": "throwing" } },
    { "lemma": "Draw", "class": "Accomplishment", "forms": { "past": "drew", "participle": "drawn", "gerund": "drawing" } },
    { "lemma": "Drive", "class": "Activity", "forms": { "past": "drove", "participle": "driven", "gerund": "driving" } },
    { "lemma": "Fight", "class": "Activity", "forms": { "past": "fought", "gerund": "fighting" } },
    { "lemma": "Hide", "class": "Achievement", "forms": { "past": "hid", "participle": "hidden", "gerund": "hiding" } },
    { "lemma": "Ride", "class": "Activity", "forms": { "past": "rode", "participle": "ridden", "gerund": "riding" } },
    { "lemma": "Rise", "class": "Achievement", "forms": { "past": "rose", "participle": "risen", "gerund": "rising" } },
    { "lemma": "Shake", "class": "Activity", "forms": { "past": "shook", "participle": "shaken", "gerund": "shaking" } },
    { "lemma": "Steal", "class": "Achievement", "forms": { "past": "stole", "participle": "stolen", "gerund": "stealing" } },
    { "lemma": "Wake", "class": "Achievement", "forms": { "past": "woke", "participle": "woken", "gerund": "waking" } },
    { "lemma": "Wear", "class": "Activity", "forms": { "past": "wore", "participle": "worn", "gerund": "wearing" } },
    { "lemma": "Break", "class": "Achievement", "forms": { "past": "broke", "participle": "broken", "gerund": "breaking" } },
    { "lemma": "Choose", "class": "Achievement", "forms": { "past": "chose", "participle": "chosen", "gerund": "choosing" } },
    { "lemma": "Freeze", "class": "Accomplishment", "forms": { "past": "froze", "participle": "frozen", "gerund": "freezing" } },
    { "lemma": "Bite", "class": "Semelfactive", "forms": { "past": "bit", "participle": "bitten", "gerund": "biting" } },
    { "lemma": "Begin", "class": "Achievement", "forms": { "past": "began", "participle": "begun", "gerund": "beginning" }, "features": ["SubjectControl"] },
    { "lemma": "Sing", "class": "Activity", "forms": { "past": "sang", "participle": "sung", "gerund": "singing" } },
    { "lemma": "Swim", "class": "Activity", "forms": { "past": "swam", "participle": "swum", "gerund": "swimming" } },
    { "lemma": "Fly", "class": "Activity", "forms": { "past": "flew", "participle": "flown", "gerund": "flying" } },
    { "lemma": "Get", "class": "Achievement", "forms": { "past": "got", "participle": "gotten", "gerund": "getting" } },
    { "lemma": "Fall", "class": "Achievement", "forms": { "past": "fell", "participle": "fallen", "gerund": "falling" } },
    { "lemma": "Feel", "class": "State", "forms": { "past": "felt", "gerund": "feeling" } },
    { "lemma": "Sit", "class": "Activity", "forms": { "past": "sat", "gerund": "sitting" } },
    { "lemma": "Stand", "class": "Activity", "forms": { "past": "stood", "gerund": "standing" } },
    { "lemma": "Lose", "class": "Achievement", "forms": { "past": "lost", "gerund": "losing" } },
    { "lemma": "Win", "class": "Achievement", "forms": { "past": "won", "gerund": "winning" } },
    { "lemma": "Catch", "class": "Achievement", "forms": { "past": "caught", "gerund": "catching" } },
    { "lemma": "Teach", "class": "Accomplishment", "forms": { "past": "taught", "gerund": "teaching" }, "features": ["Ditransitive", "ObjectControl"] },
    { "lemma": "Buy", "class": "Achievement", "forms": { "past": "bought", "gerund": "buying" } },
    { "lemma": "Sell", "class": "Achievement", "forms": { "past": "sold", "gerund": "selling" } },
    { "lemma": "Pay", "class": "Achievement", "forms": { "past": "paid", "gerund": "paying" }, "features": ["Ditransitive"] },
    { "lemma": "Cut", "class": "Achievement", "forms": { "past": "cut", "gerund": "cutting" } },
    { "lemma": "Hit", "class": "Semelfactive", "forms": { "past": "hit", "gerund": "hitting" } },
    { "lemma": "Let", "class": "Achievement", "forms": { "past": "let", "gerund": "letting" } },
    { "lemma": "Shut", "class": "Achievement", "forms": { "past": "shut", "gerund": "shutting" } },
    { "lemma": "Cost", "class": "State", "forms": { "past": "cost", "gerund": "costing" } },
    { "lemma": "Hurt", "class": "Achievement", "forms": { "past": "hurt", "gerund": "hurting" } },
    { "lemma": "Chase", "class": "Activity", "forms": { "past": "chased", "gerund": "chasing" } },
    { "lemma": "Wag", "class": "Semelfactive", "forms": { "past": "wagged", "gerund": "wagging" } },
    { "lemma": "Push", "class": "Semelfactive", "forms": { "past": "pushed", "gerund": "pushing" } },
    { "lemma": "Stop", "class": "Achievement", "forms": { "past": "stopped", "gerund": "stopping" } },
    { "lemma": "Smoke", "class": "Activity", "forms": { "past": "smoked", "gerund": "smoking" } },
    { "lemma": "Open", "class": "Achievement", "forms": { "past": "opened", "gerund": "opening" } },
    { "lemma": "Gather", "class": "Activity", "regular": true, "features": ["Collective"] },
    { "lemma": "Assemble", "class": "Accomplishment", "regular": true, "features": ["Collective"] },
    { "lemma": "Convene", "class": "Activity", "regular": true, "features": ["Collective"] },
    { "lemma": "Want", "class": "State", "regular": true, "features": ["SubjectControl", "Opaque"] },
    { "lemma": "Hope", "class": "State", "regular": true, "features": ["SubjectControl", "Opaque"] },
    { "lemma": "Decide", "class": "Activity", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Try", "class": "Activity", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Intend", "class": "State", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Refuse", "class": "Activity", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Agree", "class": "Activity", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Threaten", "class": "Activity", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Prefer", "class": "State", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Manage", "class": "Accomplishment", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Fail", "class": "Achievement", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Tend", "class": "State", "regular": true, "features": ["SubjectControl", "Raising"] },
    { "lemma": "Continue", "class": "Activity", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Start", "class": "Achievement", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Promise", "class": "Activity", "regular": true, "features": ["SubjectControl", "Performative"] },
    { "lemma": "Swear", "class": "Activity", "regular": true, "features": ["SubjectControl", "Performative"] },
    { "lemma": "Vow", "class": "Activity", "regular": true, "features": ["SubjectControl", "Performative"] },
    { "lemma": "Expect", "class": "State", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Plan", "class": "Activity", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Seem", "class": "State", "regular": true, "features": ["Raising"] },
    { "lemma": "Appear", "class": "State", "regular": true, "features": ["Raising"] },
    { "lemma": "Happen", "class": "Achievement", "regular": true, "features": ["Raising"] },
    { "lemma": "Turn", "class": "Activity", "regular": true, "features": ["Raising"] },
    { "lemma": "Persuade", "class": "Accomplishment", "regular": true, "features": ["ObjectControl"] },
    { "lemma": "Convince", "class": "Accomplishment", "regular": true, "features": ["ObjectControl"] },
    { "lemma": "Force", "class": "Accomplishment", "regular": true, "features": ["ObjectControl"] },
    { "lemma": "Order", "class": "Activity", "regular": true, "features": ["ObjectControl", "Performative"] },
    { "lemma": "Command", "class": "Activity", "regular": true, "features": ["ObjectControl", "Performative"] },
    { "lemma": "Ask", "class": "Activity", "regular": true, "features": ["ObjectControl"] },
    { "lemma": "Advise", "class": "Activity", "regular": true, "features": ["ObjectControl", "Performative"] },
    { "lemma": "Encourage", "class": "Activity", "regular": true, "features": ["ObjectControl"] },
    { "lemma": "Allow", "class": "State", "regular": true, "features": ["ObjectControl"] },
    { "lemma": "Permit", "class": "State", "regular": true, "features": ["ObjectControl"] },
    { "lemma": "Forbid", "class": "State", "regular": true, "features": ["ObjectControl", "Performative"] },
    { "lemma": "Cause", "class": "Accomplishment", "regular": true, "features": ["ObjectControl"] },
    { "lemma": "Help", "class": "Activity", "regular": true, "features": ["ObjectControl"] },
    { "lemma": "Invite", "class": "Activity", "regular": true, "features": ["ObjectControl"] },
    { "lemma": "Remind", "class": "Activity", "regular": true, "features": ["ObjectControl"] },
    { "lemma": "Warn", "class": "Activity", "regular": true, "features": ["ObjectControl", "Performative"] },
    { "lemma": "Believe", "class": "State", "regular": true, "features": ["Opaque"] },
    { "lemma": "Wish", "class": "State", "regular": true, "features": ["Opaque"] },
    { "lemma": "Seek", "class": "State", "forms": {"past": "sought", "participle": "sought"}, "features": ["Opaque"] },
    { "lemma": "Fear", "class": "State", "regular": true, "features": ["Opaque"] },
    { "lemma": "Imagine", "class": "State", "regular": true, "features": ["Opaque"] },
    { "lemma": "Dream", "class": "Activity", "regular": true, "features": ["Opaque"] },
    { "lemma": "Pretend", "class": "Activity", "regular": true, "features": ["Opaque"] },
    { "lemma": "Bark", "class": "Activity", "regular": true },
    { "lemma": "Hunt", "class": "Activity", "regular": true },
    { "lemma": "Happen", "class": "Achievement", "regular": true },
    { "lemma": "Flow", "class": "Activity", "regular": true },
    { "lemma": "Remain", "class": "State", "regular": true },
    { "lemma": "Examine", "class": "Activity", "regular": true },
    { "lemma": "Walk", "class": "Activity", "regular": true },
    { "lemma": "Talk", "class": "Activity", "regular": true },
    { "lemma": "Jump", "class": "Activity", "regular": true },
    { "lemma": "Duck", "class": "Activity", "regular": true },
    { "lemma": "Love", "class": "State", "regular": true },
    { "lemma": "Hate", "class": "State", "regular": true },
    { "lemma": "Like", "class": "State", "regular": true },
    { "lemma": "Need", "class": "State", "regular": true, "features": ["Opaque"] },
    { "lemma": "Touch", "class": "Activity", "regular": true },
    { "lemma": "Smell", "class": "State", "regular": true },
    { "lemma": "Look", "class": "Activity", "regular": true },
    { "lemma": "Own", "class": "State", "regular": true },
    { "lemma": "Lack", "class": "State", "regular": true },
    { "lemma": "Enter", "class": "Activity", "regular": true },
    { "lemma": "Trigger", "class": "Achievement", "regular": true },
    { "lemma": "Beat", "class": "Activity", "regular": true },
    { "lemma": "Marry", "class": "Achievement", "regular": true },
    { "lemma": "Kill", "class": "Achievement", "regular": true },
    { "lemma": "Stay", "class": "Activity", "regular": true },
    { "lemma": "Work", "class": "Activity", "regular": true },
    { "lemma": "Play", "class": "Activity", "regular": true },
    { "lemma": "Pass", "class": "Activity", "regular": true, "features": ["Ditransitive"] },
    { "lemma": "Hand", "class": "Activity", "regular": true, "features": ["Ditransitive"] },
    { "lemma": "Carry", "class": "Activity", "regular": true, "features": ["Mixed"] },
    { "lemma": "Lift", "class": "Activity", "regular": true, "features": ["Mixed"] },
    { "lemma": "Move", "class": "Activity", "regular": true, "features": ["Mixed"] },
    { "lemma": "Push", "class": "Activity", "regular": true, "features": ["Mixed"] },
    { "lemma": "Pull", "class": "Activity", "regular": true, "features": ["Mixed"] },
    { "lemma": "Deliver", "class": "Accomplishment", "regular": true },
    { "lemma": "Exist", "class": "State", "regular": true },
    { "lemma": "Knock", "class": "Semelfactive", "regular": true },
    { "lemma": "Kick", "class": "Semelfactive", "regular": true },
    { "lemma": "Tap", "class": "Semelfactive", "regular": true },
    { "lemma": "Cough", "class": "Semelfactive", "regular": true },
    { "lemma": "Blink", "class": "Semelfactive", "regular": true },
    { "lemma": "Sneeze", "class": "Semelfactive", "regular": true },
    { "lemma": "Hiccup", "class": "Semelfactive", "regular": true },
    { "lemma": "Flash", "class": "Semelfactive", "regular": true },
    { "lemma": "Click", "class": "Semelfactive", "regular": true },
    { "lemma": "Beep", "class": "Semelfactive", "regular": true },
    { "lemma": "Honk", "class": "Semelfactive", "regular": true },
    { "lemma": "Slap", "class": "Semelfactive", "regular": true },
    { "lemma": "Punch", "class": "Semelfactive", "regular": true },
    { "lemma": "Poke", "class": "Semelfactive", "regular": true },
    { "lemma": "Flap", "class": "Semelfactive", "regular": true },
    { "lemma": "Nod", "class": "Semelfactive", "regular": true },
    { "lemma": "Wink", "class": "Semelfactive", "regular": true },
    { "lemma": "Create", "class": "Accomplishment", "regular": true },
    { "lemma": "Construct", "class": "Accomplishment", "regular": true },
    { "lemma": "Paint", "class": "Accomplishment", "regular": true },
    { "lemma": "Repair", "class": "Accomplishment", "regular": true },
    { "lemma": "Fix", "class": "Accomplishment", "regular": true },
    { "lemma": "Melt", "class": "Accomplishment", "regular": true },
    { "lemma": "Destroy", "class": "Accomplishment", "regular": true },
    { "lemma": "Demolish", "class": "Accomplishment", "regular": true },
    { "lemma": "Dissolve", "class": "Accomplishment", "regular": true },
    { "lemma": "Recover", "class": "Accomplishment", "regular": true },
    { "lemma": "Heal", "class": "Accomplishment", "regular": true },
    { "lemma": "Cross", "class": "Accomplishment", "regular": true },
    { "lemma": "Fill", "class": "Accomplishment", "regular": true },
    { "lemma": "Empty", "class": "Accomplishment", "regular": true },
    { "lemma": "Arrive", "class": "Achievement", "regular": true },
    { "lemma": "Notice", "class": "Achievement", "regular": true },
    { "lemma": "Recognize", "class": "Achievement", "regular": true },
    { "lemma": "Realize", "class": "Achievement", "regular": true },
    { "lemma": "Discover", "class": "Achievement", "regular": true },
    { "lemma": "Reach", "class": "Achievement", "regular": true },
    { "lemma": "Born", "class": "Achievement", "regular": true },
    { "lemma": "Divorce", "class": "Achievement", "regular": true },
    { "lemma": "Graduate", "class": "Achievement", "regular": true },
    { "lemma": "Finish", "class": "Achievement", "regular": true },
    { "lemma": "Complete", "class": "Achievement", "regular": true },
    { "lemma": "Understand", "class": "State", "regular": true },
    { "lemma": "Remember", "class": "State", "regular": true },
    { "lemma": "Forget", "class": "State", "regular": true },
    { "lemma": "Deserve", "class": "State", "regular": true },
    { "lemma": "Contain", "class": "State", "regular": true },
    { "lemma": "Consist", "class": "State", "regular": true },
    { "lemma": "Belong", "class": "State", "regular": true },
    { "lemma": "Matter", "class": "State", "regular": true },
    { "lemma": "Resemble", "class": "State", "regular": true },
    { "lemma": "Dance", "class": "Activity", "regular": true },
    { "lemma": "Study", "class": "Activity", "regular": true },
    { "lemma": "Search", "class": "Activity", "regular": true },
    { "lemma": "Listen", "class": "Activity", "regular": true },
    { "lemma": "Watch", "class": "Activity", "regular": true },
    { "lemma": "Wait", "class": "Activity", "regular": true },
    { "lemma": "Lie", "class": "Activity", "regular": true },
    { "lemma": "Live", "class": "Activity", "regular": true },
    { "lemma": "Travel", "class": "Activity", "regular": true },
    { "lemma": "Move", "class": "Activity", "regular": true },
    { "lemma": "Climb", "class": "Activity", "regular": true },
    { "lemma": "Crawl", "class": "Activity", "regular": true },
    { "lemma": "Roll", "class": "Activity", "regular": true },
    { "lemma": "Spin", "class": "Activity", "regular": true },
    { "lemma": "Turn", "class": "Activity", "regular": true },
    { "lemma": "Pull", "class": "Activity", "regular": true },
    { "lemma": "Drag", "class": "Activity", "regular": true },
    { "lemma": "Lend", "class": "Activity", "regular": true, "features": ["Ditransitive"] },
    { "lemma": "Owe", "class": "Activity", "regular": true, "features": ["Ditransitive"] },
    { "lemma": "Award", "class": "Activity", "regular": true, "features": ["Ditransitive"] },
    { "lemma": "Grant", "class": "Activity", "regular": true, "features": ["Ditransitive"] },
    { "lemma": "Offer", "class": "Activity", "regular": true, "features": ["Ditransitive"] },
    { "lemma": "Bet", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Guarantee", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Pledge", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Declare", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Pronounce", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Announce", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Proclaim", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Request", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Demand", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Apologize", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Thank", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Congratulate", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Welcome", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Suggest", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Recommend", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Surround", "class": "Activity", "regular": true, "features": ["Collective"] },
    { "lemma": "Disperse", "class": "Achievement", "regular": true, "features": ["Collective"] },
    { "lemma": "Scatter", "class": "Achievement", "regular": true, "features": ["Collective"] },
    { "lemma": "Congregate", "class": "Activity", "regular": true, "features": ["Collective"] },
    { "lemma": "Unite", "class": "Achievement", "regular": true, "features": ["Collective"] },
    { "lemma": "Merge", "class": "Achievement", "regular": true, "features": ["Collective"] },
    { "lemma": "Combine", "class": "Achievement", "regular": true, "features": ["Collective"] },
    { "lemma": "Collaborate", "class": "Activity", "regular": true, "features": ["Collective"] },
    { "lemma": "Cooperate", "class": "Activity", "regular": true, "features": ["Collective"] },
    { "lemma": "Conspire", "class": "Activity", "regular": true, "features": ["Collective"] }
  ],
  "nouns": [
    { "lemma": "Man", "forms": { "plural": "men" }, "features": ["Masculine"], "sort": "Human" },
    { "lemma": "Woman", "forms": { "plural": "women" }, "features": ["Feminine"], "sort": "Human" },
    { "lemma": "Child", "forms": { "plural": "children" }, "sort": "Human" },
    { "lemma": "Person", "forms": { "plural": "people" }, "sort": "Human" },
    { "lemma": "Mouse", "forms": { "plural": "mice" } },
    { "lemma": "Tooth", "forms": { "plural": "teeth" } },
    { "lemma": "Foot", "forms": { "plural": "feet" } },
    { "lemma": "Goose", "forms": { "plural": "geese" } },
    { "lemma": "Fish", "forms": { "plural": "fish" } },
    { "lemma": "Deer", "forms": { "plural": "deer" } },
    { "lemma": "Sheep", "forms": { "plural": "sheep" } },
    { "lemma": "Species", "forms": { "plural": "species" } },
    { "lemma": "Series", "forms": { "plural": "series" } },
    { "lemma": "Car", "sort": "Physical" },
    { "lemma": "Engine", "sort": "Physical" },
    { "lemma": "Wheel", "sort": "Physical" },
    { "lemma": "Door", "sort": "Physical" },
    { "lemma": "Alarm", "sort": "Physical" },
    { "lemma": "Window", "sort": "Physical" },
    { "lemma": "Tire", "sort": "Physical" },
    { "lemma": "House", "sort": "Physical" },
    { "lemma": "Roof", "sort": "Physical" },
    { "lemma": "Room", "sort": "Physical" },
    { "lemma": "Wall", "sort": "Physical" },
    { "lemma": "Floor", "sort": "Physical" },
    { "lemma": "Ceiling", "sort": "Physical" },
    { "lemma": "Bike", "sort": "Physical" },
    { "lemma": "Pedal", "sort": "Physical" },
    { "lemma": "Chain", "sort": "Physical" },
    { "lemma": "Seat", "sort": "Physical" },
    { "lemma": "Rock", "sort": "Physical", "features": ["Inanimate"] },
    { "lemma": "Stone", "sort": "Physical", "features": ["Inanimate"] },
    { "lemma": "John", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "James", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Bob", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Bill", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Tom", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Mike", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "David", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Peter", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Paul", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Jack", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Joe", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Jim", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Steve", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Mark", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Chris", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Dan", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Sam", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Alex", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Romeo", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Mary", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Jane", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Susan", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Sarah", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Alice", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Lisa", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Anna", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Emily", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Emma", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Kate", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Amy", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Lucy", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Rachel", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Laura", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Helen", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Nancy", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Betty", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Juliet", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Boy", "features": ["Masculine"], "sort": "Human" },
    { "lemma": "King", "features": ["Masculine"], "sort": "Human" },
    { "lemma": "Prince", "features": ["Masculine"], "sort": "Human" },
    { "lemma": "Father", "features": ["Masculine"], "sort": "Human" },
    { "lemma": "Brother", "features": ["Masculine"], "sort": "Human" },
    { "lemma": "Son", "features": ["Masculine"], "sort": "Human" },
    { "lemma": "Husband", "features": ["Masculine"], "sort": "Human" },
    { "lemma": "Actor", "features": ["Masculine"], "sort": "Human" },
    { "lemma": "Waiter", "features": ["Masculine"], "sort": "Human" },
    { "lemma": "Girl", "features": ["Feminine"], "sort": "Human" },
    { "lemma": "Queen", "features": ["Feminine"], "sort": "Human" },
    { "lemma": "Princess", "features": ["Feminine"], "sort": "Human" },
    { "lemma": "Mother", "features": ["Feminine"], "sort": "Human" },
    { "lemma": "Sister", "features": ["Feminine"], "sort": "Human" },
    { "lemma": "Daughter", "features": ["Feminine"], "sort": "Human" },
    { "lemma": "Wife", "features": ["Feminine"], "sort": "Human" },
    { "lemma": "Actress", "features": ["Feminine"], "sort": "Human" },
    { "lemma": "Waitress", "features": ["Feminine"], "sort": "Human" },
    { "lemma": "Ring" }, { "lemma": "Thing" }, { "lemma": "Spring" }, { "lemma": "String" },
    { "lemma": "Swing" }, { "lemma": "Wing" }, { "lemma": "Bus" }, { "lemma": "Gas" },
    { "lemma": "Focus" }, { "lemma": "Campus" }, { "lemma": "Status" }, { "lemma": "Bonus" },
    { "lemma": "Set", "forms": { "plural": "sets" } },
    { "lemma": "Cardinality" },
    { "lemma": "Dog", "sort": "Animate" }, { "lemma": "Cat", "sort": "Animate" }, { "lemma": "Bird", "sort": "Animate" }, { "lemma": "Student", "sort": "Human" },
    { "lemma": "Hunter", "sort": "Human" }, { "lemma": "Book", "sort": "Information" }, { "lemma": "House", "sort": "Physical" }, { "lemma": "Code" },
    { "lemma": "User", "sort": "Human" }, { "lemma": "Logic", "sort": "Abstract" }, { "lemma": "Time", "sort": "Abstract" }, { "lemma": "Letter" },
    { "lemma": "Logician", "sort": "Human" }, { "lemma": "Philosopher", "sort": "Human" }, { "lemma": "Teacher", "sort": "Human" }, { "lemma": "Writer", "sort": "Human" },
    { "lemma": "Athlete", "sort": "Human" }, { "lemma": "World" }, { "lemma": "Unicorn", "sort": "Animate" }, { "lemma": "Toast", "sort": "Physical" },
    { "lemma": "Bathroom", "sort": "Place" }, { "lemma": "Knife", "sort": "Physical" }, { "lemma": "Gun", "sort": "Physical" }, { "lemma": "Thief", "sort": "Human" },
    { "lemma": "Senator", "sort": "Human" }, { "lemma": "Ball", "sort": "Physical" }, { "lemma": "President", "sort": "Human" }, { "lemma": "Hero", "sort": "Human" },
    { "lemma": "Friend", "sort": "Human" }, { "lemma": "Story", "sort": "Information" }, { "lemma": "Horse", "sort": "Animate" }, { "lemma": "Water", "sort": "Physical" },
    { "lemma": "Money", "sort": "Value" }, { "lemma": "Apple", "sort": "Physical" }, { "lemma": "Rat", "sort": "Animate" }, { "lemma": "Tail", "sort": "Physical" },
    { "lemma": "Door", "sort": "Physical" }, { "lemma": "Key", "sort": "Physical" }, { "lemma": "Glass", "sort": "Physical" }, { "lemma": "Ice", "sort": "Physical" },
    { "lemma": "Sun", "sort": "Celestial" }, { "lemma": "Moon", "sort": "Celestial" }, { "lemma": "Star", "sort": "Celestial" },
    { "lemma": "Rock", "sort": "Physical" }, { "lemma": "Justice", "sort": "Abstract" }, { "lemma": "Love", "sort": "Abstract" },
    { "lemma": "Team", "features": ["Collective"], "sort": "Group" }, { "lemma": "Army", "features": ["Collective"], "sort": "Group" },
    { "lemma": "Animal", "sort": "Animate" },
    { "lemma": "Duck", "sort": "Animate" }
  ],
  "adjectives": [
    { "lemma": "Red", "regular": true, "features": ["Intersective"] },
    { "lemma": "Blue", "regular": true, "features": ["Intersective"] },
    { "lemma": "Green", "regular": true, "features": ["Intersective"] },
    { "lemma": "Black", "regular": true, "features": ["Intersective"] },
    { "lemma": "White", "regular": true, "features": ["Intersective"] },
    { "lemma": "Happy", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Sad", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Great", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Dangerous", "regular": true, "features": ["Intersective"] },
    { "lemma": "Open", "regular": true, "features": ["Intersective"] },
    { "lemma": "Closed", "regular": true, "features": ["Intersective"] },
    { "lemma": "Flat", "regular": true, "features": ["Intersective"] },
    { "lemma": "Fake", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Former", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Alleged", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Counterfeit", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Would-Be", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Putative", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Supposed", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "So-Called", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Pseudo", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Quasi", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Potential", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Possible", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Future", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Imaginary", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Fictional", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Tall", "regular": true, "features": ["Subsective", "Gradable"] },
    { "lemma": "Short", "regular": true, "features": ["Subsective", "Gradable"] },
    { "lemma": "Big", "regular": true, "features": ["Subsective", "Gradable"] },
    { "lemma": "Large", "regular": true, "features": ["Subsective", "Gradable"] },
    { "lemma": "Small", "regular": true, "features": ["Subsective", "Gradable"] },
    { "lemma": "Fast", "regular": true, "features": ["Subsective", "Gradable"] },
    { "lemma": "Slow", "regular": true, "features": ["Subsective", "Gradable"] },
    { "lemma": "Old", "regular": true, "features": ["Subsective", "Gradable"] },
    { "lemma": "Young", "regular": true, "features": ["Subsective", "Gradable"] },
    { "lemma": "Strong", "regular": true, "features": ["Subsective", "Gradable"] },
    { "lemma": "Weak", "regular": true, "features": ["Subsective", "Gradable"] },
    { "lemma": "Loud", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Quiet", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Smart", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Dumb", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Rich", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Poor", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "High", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Low", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Long", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Wide", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Deep", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Thick", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Thin", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Hot", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Cold", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Warm", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Cool", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Hard", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Soft", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Dark", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Light", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Clean", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Dirty", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Dry", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Wet", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "New", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Bright", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Sweet", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Sour", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Good", "regular": true, "features": ["Subsective"] },
    { "lemma": "Bad", "regular": true, "features": ["Subsective"] }
  ],
  "prepositions": [
    "from", "with", "for", "by", "of", "in", "on", "at", "into", "onto",
    "under", "over", "through", "about", "around", "between", "among",
    "behind", "before", "after", "near", "beside", "beneath", "above",
    "below", "inside", "outside", "within", "without", "against",
    "toward", "towards", "across", "along", "during", "until", "upon", "past"
  ],
  "adverbs": [
    "quickly", "slowly", "loudly", "quietly", "happily", "sadly",
    "carefully", "carelessly", "easily", "hardly", "barely",
    "passionately", "angrily", "gently", "roughly", "softly",
    "suddenly", "gradually", "immediately", "finally", "eventually",
    "really", "truly", "certainly", "probably", "possibly",
    "always", "never", "often", "sometimes", "rarely", "usually",
    "please"
  ],
  "scopal_adverbs": [
    "almost", "nearly", "barely", "hardly", "just",
    "merely", "still", "already",
    "allegedly", "probably", "possibly", "certainly"
  ],
  "temporal_adverbs": ["yesterday", "today", "tomorrow", "now"],
  "particles": ["up", "down", "out", "in", "off", "on", "away", "over", "back", "through", "apart", "about", "around", "along", "by"],
  "phrasal_verbs": {
    "give_up": { "lemma": "Surrender", "class": "Activity" },
    "break_down": { "lemma": "Malfunction", "class": "Achievement" },
    "pick_up": { "lemma": "Collect", "class": "Achievement" },
    "put_down": { "lemma": "Place", "class": "Activity" },
    "take_off": { "lemma": "Remove", "class": "Achievement" },
    "turn_on": { "lemma": "Activate", "class": "Achievement" },
    "turn_off": { "lemma": "Deactivate", "class": "Achievement" },
    "carry_out": { "lemma": "Execute", "class": "Activity" },
    "figure_out": { "lemma": "Understand", "class": "Achievement" },
    "find_out": { "lemma": "Discover", "class": "Achievement" },
    "give_away": { "lemma": "Donate", "class": "Activity" },
    "throw_away": { "lemma": "Discard", "class": "Activity" },
    "bring_up": { "lemma": "Mention", "class": "Activity" },
    "call_off": { "lemma": "Cancel", "class": "Achievement" },
    "make_up": { "lemma": "Fabricate", "class": "Activity" },
    "set_up": { "lemma": "Arrange", "class": "Activity" },
    "shut_down": { "lemma": "Close", "class": "Achievement" }
  },
  "not_adverbs": [
    "friendly", "lovely", "ugly", "silly", "holy", "lonely", "deadly",
    "likely", "costly", "early", "only", "daily", "weekly", "monthly",
    "yearly", "orderly", "timely", "lively", "elderly", "brotherly",
    "fatherly", "motherly", "sisterly", "beastly", "ghostly", "princely"
  ],
  "noun_patterns": [
    "dog", "cat", "man", "bird", "book", "house", "person", "thing",
    "dogs", "cats", "men", "birds", "books", "houses", "persons", "things"
  ],
  "disambiguation_not_verbs": [
    "ring", "king", "thing", "spring", "string", "swing", "wing", "bring", "sing",
    "bus", "plus", "gas", "us", "thus", "focus", "campus", "status", "bonus",
    "red", "bed", "led", "shed", "sled", "wed",
    "tired", "bored", "excited", "interested", "blessed", "wicked",
    "mortal", "happy", "friendly", "loud", "black", "old", "wise", "bald",
    "tall", "short", "big", "small", "fast", "slow", "good", "bad", "lazy",
    "dangerous", "blue", "green", "yellow", "white", "free"
  ],
  "morphology": {
    "needs_e_ing": [
      "tak", "mak", "giv", "hav", "lov", "liv", "mov", "sav",
      "writ", "rid", "hid", "bit", "driv", "shak", "wak",
      "hat", "lik", "nam", "shar", "hop", "danc", "chas"
    ],
    "needs_e_ed": [
      "persuad", "forc", "convinc", "reduc", "produc", "induc",
      "lov", "mov", "sav", "liv", "giv", "hav", "mak", "tak",
      "chas", "danc", "hop", "lik", "hat", "nam", "shar",
      "chang", "manag", "arrang", "enclos", "clos", "rais",
      "prais", "paus", "caus", "us", "refus", "excus", "abus",
      "accus", "amus", "confus", "advis", "devis", "revis",
      "promis", "compromis", "exercis", "practis", "realis",
      "organis", "recognis", "surpris", "disguis",
      "decid", "provid", "divid", "guid", "resid", "collid",
      "examin"
    ],
    "stemming_exceptions": [
      "themselves", "ourselves", "yourselves", "himself", "herself",
      "itself", "myself", "yourself", "this", "thus", "plus", "minus",
      "always", "sometimes", "perhaps", "yes", "is", "as", "was", "has",
      "does", "his", "hers", "its", "ours", "yours", "theirs", "us"
    ]
  },
  "units": {
    "inch": "Length",
    "inches": "Length",
    "meter": "Length",
    "meters": "Length",
    "foot": "Length",
    "feet": "Length",
    "yard": "Length",
    "yards": "Length",
    "mile": "Length",
    "miles": "Length",
    "second": "Time",
    "seconds": "Time",
    "minute": "Time",
    "minutes": "Time",
    "hour": "Time",
    "hours": "Time",
    "day": "Time",
    "days": "Time",
    "year": "Time",
    "years": "Time",
    "pound": "Weight",
    "pounds": "Weight",
    "kilogram": "Weight",
    "kilograms": "Weight",
    "gram": "Weight",
    "grams": "Weight",
    "ounce": "Weight",
    "ounces": "Weight",
    "degree": "Temperature",
    "degrees": "Temperature",
    "child": "Cardinality",
    "children": "Cardinality",
    "item": "Cardinality",
    "items": "Cardinality"
  },
  "multi_word_expressions": [
    { "pattern": ["fire", "engine"], "lemma": "FireEngine", "pos": "Noun" },
    { "pattern": ["ice", "cream"], "lemma": "IceCream", "pos": "Noun" },
    { "pattern": ["credit", "card"], "lemma": "CreditCard", "pos": "Noun" },
    { "pattern": ["black", "hole"], "lemma": "BlackHole", "pos": "Noun" },
    { "pattern": ["high", "school"], "lemma": "HighSchool", "pos": "Noun" },
    { "pattern": ["new", "york"], "lemma": "NewYork", "pos": "Noun", "features": ["Proper"] },
    { "pattern": ["united", "states"], "lemma": "UnitedStates", "pos": "Noun", "features": ["Proper"] },
    { "pattern": ["san", "francisco"], "lemma": "SanFrancisco", "pos": "Noun", "features": ["Proper"] },
    { "pattern": ["kick", "the", "bucket"], "lemma": "Die", "pos": "Verb", "class": "Achievement" },
    { "pattern": ["give", "up"], "lemma": "Surrender", "pos": "Verb", "class": "Activity" },
    { "pattern": ["break", "down"], "lemma": "Malfunction", "pos": "Verb", "class": "Achievement" },
    { "pattern": ["in", "front", "of"], "lemma": "InFrontOf", "pos": "Preposition" },
    { "pattern": ["as", "well", "as"], "lemma": "And", "pos": "Conjunction" },
    { "pattern": ["no", "one"], "lemma": "NoOne", "pos": "Quantifier" }
  ],
  "ontology": {
    "part_whole": [
      { "whole": "Car", "parts": ["Engine", "Wheel", "Door", "Window", "Tire"] },
      { "whole": "Bike", "parts": ["Wheel", "Pedal", "Chain", "Seat"] },
      { "whole": "House", "parts": ["Door", "Window", "Roof", "Room", "Wall"] },
      { "whole": "Body", "parts": ["Head", "Arm", "Leg", "Hand", "Foot"] },
      { "whole": "Computer", "parts": ["Screen", "Keyboard", "Mouse"] },
      { "whole": "Book", "parts": ["Page", "Cover", "Chapter"] },
      { "whole": "Tree", "parts": ["Branch", "Leaf", "Root"] },
      { "whole": "Room", "parts": ["Floor", "Ceiling", "Wall"] },
      { "whole": "Paper", "parts": ["Author", "Abstract", "Conclusion"] }
    ],
    "predicate_sorts": {
      "happy": "Animate",
      "sad": "Animate",
      "angry": "Animate",
      "hungry": "Animate",
      "tired": "Animate",
      "alive": "Animate",
      "dead": "Animate",
      "think": "Animate",
      "believe": "Animate",
      "remember": "Animate",
      "know": "Animate",
      "want": "Animate",
      "hope": "Animate",
      "fear": "Animate"
    }
  },
  "axioms": {
    "nouns": {
      "bachelor": { "entails": ["Unmarried", "Male", "Adult"] },
      "spinster": { "entails": ["Unmarried", "Female", "Adult"] },
      "widow": { "entails": ["Female", "WasMarried"] },
      "widower": { "entails": ["Male", "WasMarried"] },
      "orphan": { "entails": ["Child", "ParentsDeceased"] },
      "dog": { "hypernyms": ["Animal", "Mammal"] },
      "cat": { "hypernyms": ["Animal", "Mammal"] },
      "bird": { "hypernyms": ["Animal"] },
      "sparrow": { "hypernyms": ["Bird", "Animal"] },
      "eagle": { "hypernyms": ["Bird", "Animal"] },
      "fish": { "hypernyms": ["Animal"] },
      "salmon": { "hypernyms": ["Fish", "Animal"] },
      "human": { "hypernyms": ["Animal", "Mammal"] },
      "car": { "hypernyms": ["Vehicle"] },
      "truck": { "hypernyms": ["Vehicle"] },
      "bicycle": { "hypernyms": ["Vehicle"] }
    },
    "adjectives": {
      "fake": { "type": "Privative" },
      "counterfeit": { "type": "Privative" },
      "former": { "type": "Privative" },
      "alleged": { "type": "Privative" },
      "would-be": { "type": "Privative" },
      "imaginary": { "type": "Privative" },
      "fictional": { "type": "Privative" }
    },
    "verbs": {
      "murder": { "entails": "Kill", "manner": ["Intentional"] },
      "assassinate": { "entails": "Kill", "manner": ["Intentional", "Political"] },
      "slaughter": { "entails": "Kill", "manner": ["Violent"] },
      "execute": { "entails": "Kill", "manner": ["Legal", "Intentional"] }
    }
  }
}
```

---

## Lexer & Tokenization

The lexer transforms English text into a stream of classified tokens using dictionary lookups and heuristic fallbacks for unknown words.

**Location:** `src/token.rs`, `src/lexer.rs`

### Token Definitions

**File:** `src/token.rs`

Token type taxonomy including quantifiers, modal operators, connectives (Because for causal), pronouns, prepositions, demonstratives (This/That/These/Those), Reciprocal (each other), and performatives. Supports presupposition triggers, focus particles, and measure words (MeasureKind: Much/Little). Number(Symbol) stores numeric literals as interned strings for prover-ready symbolic math. Includes semantic token sets (WH_WORDS, MODALS) as const arrays for pattern matching. Span struct (start/end byte positions) for source location tracking. **Phase 12:** TokenType::Ambiguous { primary: Box<TokenType>, alternatives: Vec<TokenType> } for polysemous words that have multiple valid interpretations (e.g., 'duck' as Noun or Verb).

```rust
use crate::context::{Case, Gender, Number};
use crate::intern::Symbol;
use crate::lexicon::{Aspect, Definiteness, Time, VerbClass};

#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
pub struct Span {
    pub start: usize,
    pub end: usize,
}

impl Span {
    pub fn new(start: usize, end: usize) -> Self {
        Self { start, end }
    }
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum PresupKind {
    Stop,
    Start,
    Regret,
    Continue,
    Realize,
    Know,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum FocusKind {
    Only,
    Even,
    Just,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum MeasureKind {
    Much,
    Little,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum BlockType {
    Theorem,
    Main,
    Definition,
    Proof,
    Example,
    Logic,
    Note,
    Function,  // Phase 32: ## To blocks
}

#[derive(Debug, Clone, PartialEq, Eq)]
pub enum TokenType {
    // Document Structure
    BlockHeader { block_type: BlockType },

    // Quantifiers
    All,
    No,
    Some,
    Any,
    Most,
    Few,
    Many,
    Cardinal(u32),
    AtLeast(u32),
    AtMost(u32),

    // Negative Polarity Items (NPIs)
    Anything,
    Anyone,
    Nothing,
    Nobody,
    NoOne,
    Nowhere,
    Ever,
    Never,

    // Logical Connectives
    And,
    Or,
    If,
    Then,
    Not,
    Iff,
    Because,

    // Modal Operators
    Must,
    Shall,
    Should,
    Can,
    May,
    Cannot,
    Would,
    Could,
    Had,

    // Imperative Statement Keywords
    Let,
    Set,
    Return,
    Be,
    While,
    Repeat,
    For,
    In,
    From,
    Assert,
    Trust,    // Phase 35: Documented assertion with justification
    Otherwise,
    Call,
    New,      // Phase 31: Constructor keyword
    Either,   // Phase 33: Sum type definition
    Inspect,  // Phase 33: Pattern matching

    // Ownership Keywords (Move/Borrow Semantics)
    Give,  // Move ownership: "Give x to processor"
    Show,  // Immutable borrow: "Show x to console"

    // Block Scoping
    Colon,
    Indent,
    Dedent,
    Newline,

    // Content Words
    Noun(Symbol),
    Adjective(Symbol),
    NonIntersectiveAdjective(Symbol),
    Adverb(Symbol),
    ScopalAdverb(Symbol),
    TemporalAdverb(Symbol),
    Verb {
        lemma: Symbol,
        time: Time,
        aspect: Aspect,
        class: VerbClass,
    },
    ProperName(Symbol),

    // Lexical Ambiguity (Phase 12: Parse Forest)
    Ambiguous {
        primary: Box<TokenType>,
        alternatives: Vec<TokenType>,
    },

    // Speech Acts (Performatives)
    Performative(Symbol),
    Exclamation,

    // Articles (Definiteness)
    Article(Definiteness),

    // Temporal Auxiliaries
    Auxiliary(Time),

    // Copula & Functional
    Is,
    Are,
    Was,
    Were,
    That,
    Who,
    What,
    Where,
    When,
    Why,
    Does,
    Do,

    // Identity & Reflexive (FOL)
    Identity,
    Equals,
    Reflexive,
    Reciprocal,

    // Pronouns (Discourse)
    Pronoun {
        gender: Gender,
        number: Number,
        case: Case,
    },

    // Prepositions (for N-ary relations)
    Preposition(Symbol),

    // Phrasal Verb Particles (up, down, out, in, off, on, away)
    Particle(Symbol),

    // Comparatives & Superlatives (Pillar 3 - Degree Semantics)
    Comparative(Symbol),
    Superlative(Symbol),
    Than,

    // Control Verbs (Chomsky's Control Theory)
    To,

    // Presupposition Triggers (Austin/Strawson)
    PresupTrigger(PresupKind),

    // Focus Particles (Rooth)
    Focus(FocusKind),

    // Mass Noun Measure
    Measure(MeasureKind),

    // Numeric Literals (prover-ready: stores raw string for symbolic math)
    Number(Symbol),

    // Phase 33: String literals "hello world"
    StringLiteral(Symbol),

    // Index Access (1-indexed)
    Item,
    Items,

    // Possession (Genitive Case)
    Possessive,

    // Punctuation
    LParen,
    RParen,
    LBracket,
    RBracket,
    Comma,
    Period,

    // Arithmetic Operators
    Plus,
    Minus,
    Star,
    Slash,

    EOF,
}

#[derive(Debug, Clone)]
pub struct Token {
    pub kind: TokenType,
    pub lexeme: Symbol,
    pub span: Span,
}

impl Token {
    pub fn new(kind: TokenType, lexeme: Symbol, span: Span) -> Self {
        Token { kind, lexeme, span }
    }
}

impl TokenType {
    pub const WH_WORDS: &'static [TokenType] = &[
        TokenType::Who,
        TokenType::What,
        TokenType::Where,
        TokenType::When,
        TokenType::Why,
    ];

    pub const MODALS: &'static [TokenType] = &[
        TokenType::Must,
        TokenType::Shall,
        TokenType::Should,
        TokenType::Can,
        TokenType::May,
        TokenType::Cannot,
    ];
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn span_new_stores_positions() {
        let span = Span::new(5, 10);
        assert_eq!(span.start, 5);
        assert_eq!(span.end, 10);
    }

    #[test]
    fn span_default_is_zero() {
        let span = Span::default();
        assert_eq!(span.start, 0);
        assert_eq!(span.end, 0);
    }

    #[test]
    fn token_has_span_field() {
        use crate::intern::Interner;
        let mut interner = Interner::new();
        let lexeme = interner.intern("test");
        let token = Token::new(TokenType::Noun(lexeme), lexeme, Span::new(0, 4));
        assert_eq!(token.span.start, 0);
        assert_eq!(token.span.end, 4);
    }

    #[test]
    fn wh_words_contains_all_wh_tokens() {
        assert_eq!(TokenType::WH_WORDS.len(), 5);
        assert!(TokenType::WH_WORDS.contains(&TokenType::Who));
        assert!(TokenType::WH_WORDS.contains(&TokenType::What));
        assert!(TokenType::WH_WORDS.contains(&TokenType::Where));
        assert!(TokenType::WH_WORDS.contains(&TokenType::When));
        assert!(TokenType::WH_WORDS.contains(&TokenType::Why));
    }

    #[test]
    fn modals_contains_all_modal_tokens() {
        assert_eq!(TokenType::MODALS.len(), 6);
        assert!(TokenType::MODALS.contains(&TokenType::Must));
        assert!(TokenType::MODALS.contains(&TokenType::Shall));
        assert!(TokenType::MODALS.contains(&TokenType::Should));
        assert!(TokenType::MODALS.contains(&TokenType::Can));
        assert!(TokenType::MODALS.contains(&TokenType::May));
        assert!(TokenType::MODALS.contains(&TokenType::Cannot));
    }
}

```

---

### Lexer Implementation

**File:** `src/lexer.rs`

Dictionary-based tokenization with heuristic word classification. **Verb-First Priority:** Word classification checks verbs before nouns (lines 573-594), enabling the parser safety net where consume_content_word() accepts Verb tokens in noun positions. Disambiguation: words in disambiguation_not_verbs that are also common nouns return Noun; otherwise Adjective. **Verb/Adjective Ambiguity:** Extended ambiguity detection to include Verb AND Adjective overlap (e.g., 'open'); returns TokenType::Ambiguous{Verb, [Adj]} for words that can be either. **Content Word Classifiers:** Heuristic helpers is_noun_like(), is_verb_like(), is_adjective_like() for disambiguating unknown words. **Capitalized Article Disambiguation:** Sentence-initial 'A'/'An' uses lookahead heuristics: followed by logical keyword (if, and, or) → ProperName; followed by verb (not gerund) → ProperName; followed by noun/adjective or lowercase word → Article(Indefinite). Examples: 'A dog ran.' → Article; 'A if B.' → ProperName; 'A red ball.' → Article. Handles contractions, punctuation, unknown word fallbacks, gerund detection (-ing forms as nouns), and mass noun quantifiers (much/little). Enhanced number recognition with word_to_number() for spelled-out numerals and lookahead for compound numbers (twenty five, two and a half). Returns Number(Symbol) tokens for prover-ready symbolic math. UTF-8 safe byte position tracking via char_indices() for span generation. **Contraction Expansion:** Negative contractions split to separate tokens: don't→do+not, doesn't→does+not, didn't→did+not, won't→will+not, can't→cannot. Uses skip_count for character skipping after expansion.

```rust
use crate::intern::Interner;
use crate::lexicon::{self, Aspect, Definiteness, Lexicon, Time};
use crate::token::{BlockType, FocusKind, MeasureKind, Span, Token, TokenType};

#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
pub enum LexerMode {
    #[default]
    Declarative, // Logic, Theorems, Definitions
    Imperative,  // Main, Functions, Code
}

pub struct Lexer<'a> {
    words: Vec<WordItem>,
    pos: usize,
    lexicon: Lexicon,
    interner: &'a mut Interner,
    input_len: usize,
    in_let_context: bool,
    mode: LexerMode,
    source: String,
}

struct WordItem {
    word: String,
    trailing_punct: Option<char>,
    start: usize,
    end: usize,
    punct_pos: Option<usize>,
}

impl<'a> Lexer<'a> {
    pub fn new(input: &str, interner: &'a mut Interner) -> Self {
        let words = Self::split_into_words(input);
        let input_len = input.len();

        Lexer {
            words,
            pos: 0,
            lexicon: Lexicon::new(),
            interner,
            input_len,
            in_let_context: false,
            mode: LexerMode::Declarative,
            source: input.to_string(),
        }
    }

    fn split_into_words(input: &str) -> Vec<WordItem> {
        let mut items = Vec::new();
        let mut current_word = String::new();
        let mut word_start = 0;
        let chars: Vec<char> = input.chars().collect();
        let mut char_idx = 0;
        let mut skip_count = 0;

        for (i, c) in input.char_indices() {
            if skip_count > 0 {
                skip_count -= 1;
                char_idx += 1;
                continue;
            }
            let next_pos = i + c.len_utf8();
            match c {
                ' ' | '\t' | '\n' | '\r' => {
                    if !current_word.is_empty() {
                        items.push(WordItem {
                            word: std::mem::take(&mut current_word),
                            trailing_punct: None,
                            start: word_start,
                            end: i,
                            punct_pos: None,
                        });
                    }
                    word_start = next_pos;
                }
                '.' => {
                    // Check if this is a decimal point (digit before and after)
                    let prev_is_digit = !current_word.is_empty()
                        && current_word.chars().last().map_or(false, |ch| ch.is_ascii_digit());
                    let next_is_digit = char_idx + 1 < chars.len()
                        && chars[char_idx + 1].is_ascii_digit();

                    if prev_is_digit && next_is_digit {
                        // This is a decimal point, include it in the current word
                        current_word.push(c);
                    } else {
                        // This is a sentence period
                        if !current_word.is_empty() {
                            items.push(WordItem {
                                word: std::mem::take(&mut current_word),
                                trailing_punct: Some(c),
                                start: word_start,
                                end: i,
                                punct_pos: Some(i),
                            });
                        } else {
                            items.push(WordItem {
                                word: String::new(),
                                trailing_punct: Some(c),
                                start: i,
                                end: next_pos,
                                punct_pos: Some(i),
                            });
                        }
                        word_start = next_pos;
                    }
                }
                '#' => {
                    // Check for ## block header (markdown-style)
                    if char_idx + 1 < chars.len() && chars[char_idx + 1] == '#' {
                        // This is a ## block header
                        // Skip the second # and capture the next word as a block header
                        if !current_word.is_empty() {
                            items.push(WordItem {
                                word: std::mem::take(&mut current_word),
                                trailing_punct: None,
                                start: word_start,
                                end: i,
                                punct_pos: None,
                            });
                        }
                        // Skip whitespace after ##
                        let header_start = i;
                        let mut j = char_idx + 2;
                        while j < chars.len() && (chars[j] == ' ' || chars[j] == '\t') {
                            j += 1;
                        }
                        // Capture the block type word
                        let mut block_word = String::from("##");
                        while j < chars.len() && chars[j].is_alphabetic() {
                            block_word.push(chars[j]);
                            j += 1;
                        }
                        if block_word.len() > 2 {
                            items.push(WordItem {
                                word: block_word,
                                trailing_punct: None,
                                start: header_start,
                                end: header_start + (j - char_idx),
                                punct_pos: None,
                            });
                        }
                        skip_count = j - char_idx - 1;
                        word_start = header_start + (j - char_idx);
                    } else {
                        // Single # - treat as comment, skip to end of line
                        while char_idx + 1 < chars.len() && chars[char_idx + 1] != '\n' {
                            skip_count += 1;
                            char_idx += 1;
                        }
                        if !current_word.is_empty() {
                            items.push(WordItem {
                                word: std::mem::take(&mut current_word),
                                trailing_punct: None,
                                start: word_start,
                                end: i,
                                punct_pos: None,
                            });
                        }
                        word_start = next_pos;
                    }
                }
                // Phase 33: String literals "hello world"
                '"' => {
                    // Push any pending word
                    if !current_word.is_empty() {
                        items.push(WordItem {
                            word: std::mem::take(&mut current_word),
                            trailing_punct: None,
                            start: word_start,
                            end: i,
                            punct_pos: None,
                        });
                    }

                    // Scan until closing quote
                    let string_start = i;
                    let mut j = char_idx + 1;
                    let mut string_content = String::new();
                    while j < chars.len() && chars[j] != '"' {
                        if chars[j] == '\\' && j + 1 < chars.len() {
                            // Escape sequence - skip backslash, include next char
                            j += 1;
                            if j < chars.len() {
                                string_content.push(chars[j]);
                            }
                        } else {
                            string_content.push(chars[j]);
                        }
                        j += 1;
                    }

                    // Create a special marker for string literals
                    // We prefix with a special character to identify in tokenize()
                    items.push(WordItem {
                        word: format!("\x00STR:{}", string_content),
                        trailing_punct: None,
                        start: string_start,
                        end: if j < chars.len() { j + 1 } else { j },
                        punct_pos: None,
                    });

                    // Skip past the closing quote
                    if j < chars.len() {
                        skip_count = j - char_idx;
                    } else {
                        skip_count = j - char_idx - 1;
                    }
                    word_start = if j < chars.len() { j + 1 } else { j };
                }
                '(' | ')' | '[' | ']' | ',' | '?' | '!' | ':' | '+' | '-' | '*' | '/' => {
                    if !current_word.is_empty() {
                        items.push(WordItem {
                            word: std::mem::take(&mut current_word),
                            trailing_punct: Some(c),
                            start: word_start,
                            end: i,
                            punct_pos: Some(i),
                        });
                    } else {
                        items.push(WordItem {
                            word: String::new(),
                            trailing_punct: Some(c),
                            start: i,
                            end: next_pos,
                            punct_pos: Some(i),
                        });
                    }
                    word_start = next_pos;
                }
                '\'' => {
                    // Handle contractions: expand "don't" → "do" + "not", etc.
                    let remaining: String = chars[char_idx + 1..].iter().collect();
                    let remaining_lower = remaining.to_lowercase();

                    if remaining_lower.starts_with("t ") || remaining_lower.starts_with("t.") ||
                       remaining_lower.starts_with("t,") || remaining_lower == "t" ||
                       (char_idx + 1 < chars.len() && chars[char_idx + 1] == 't' &&
                        (char_idx + 2 >= chars.len() || !chars[char_idx + 2].is_alphabetic())) {
                        // This is a contraction ending in 't (don't, doesn't, won't, can't, etc.)
                        let word_lower = current_word.to_lowercase();
                        if word_lower == "don" || word_lower == "doesn" || word_lower == "didn" {
                            // do/does/did + not
                            let base = if word_lower == "don" { "do" }
                                      else if word_lower == "doesn" { "does" }
                                      else { "did" };
                            items.push(WordItem {
                                word: base.to_string(),
                                trailing_punct: None,
                                start: word_start,
                                end: i,
                                punct_pos: None,
                            });
                            items.push(WordItem {
                                word: "not".to_string(),
                                trailing_punct: None,
                                start: i,
                                end: i + 2,
                                punct_pos: None,
                            });
                            current_word.clear();
                            word_start = next_pos + 1;
                            skip_count = 1;
                        } else if word_lower == "won" {
                            // will + not
                            items.push(WordItem {
                                word: "will".to_string(),
                                trailing_punct: None,
                                start: word_start,
                                end: i,
                                punct_pos: None,
                            });
                            items.push(WordItem {
                                word: "not".to_string(),
                                trailing_punct: None,
                                start: i,
                                end: i + 2,
                                punct_pos: None,
                            });
                            current_word.clear();
                            word_start = next_pos + 1;
                            skip_count = 1;
                        } else if word_lower == "can" {
                            // cannot
                            items.push(WordItem {
                                word: "cannot".to_string(),
                                trailing_punct: None,
                                start: word_start,
                                end: i + 2,
                                punct_pos: None,
                            });
                            current_word.clear();
                            word_start = next_pos + 1;
                            skip_count = 1;
                        } else {
                            // Unknown contraction, split normally
                            if !current_word.is_empty() {
                                items.push(WordItem {
                                    word: std::mem::take(&mut current_word),
                                    trailing_punct: Some('\''),
                                    start: word_start,
                                    end: i,
                                    punct_pos: Some(i),
                                });
                            }
                            word_start = next_pos;
                        }
                    } else {
                        // Not a 't contraction, handle normally
                        if !current_word.is_empty() {
                            items.push(WordItem {
                                word: std::mem::take(&mut current_word),
                                trailing_punct: Some('\''),
                                start: word_start,
                                end: i,
                                punct_pos: Some(i),
                            });
                        }
                        word_start = next_pos;
                    }
                }
                c if c.is_alphabetic() || c.is_ascii_digit() || (c == '.' && !current_word.is_empty() && current_word.chars().all(|ch| ch.is_ascii_digit())) || c == '_' => {
                    if current_word.is_empty() {
                        word_start = i;
                    }
                    current_word.push(c);
                }
                _ => {
                    word_start = next_pos;
                }
            }
            char_idx += 1;
        }

        if !current_word.is_empty() {
            items.push(WordItem {
                word: current_word,
                trailing_punct: None,
                start: word_start,
                end: input.len(),
                punct_pos: None,
            });
        }

        items
    }

    fn peek_word(&self, offset: usize) -> Option<&str> {
        self.words.get(self.pos + offset).map(|w| w.word.as_str())
    }

    fn peek_sequence(&self, expected: &[&str]) -> bool {
        for (i, &exp) in expected.iter().enumerate() {
            match self.peek_word(i + 1) {
                Some(w) if w.to_lowercase() == exp => continue,
                _ => return false,
            }
        }
        true
    }

    fn consume_words(&mut self, count: usize) {
        self.pos += count;
    }

    pub fn tokenize(&mut self) -> Vec<Token> {
        let mut tokens = Vec::new();

        while self.pos < self.words.len() {
            let item = &self.words[self.pos];
            let word = item.word.clone();
            let trailing_punct = item.trailing_punct;
            let word_start = item.start;
            let word_end = item.end;
            let punct_pos = item.punct_pos;

            if word.is_empty() {
                if let Some(punct) = trailing_punct {
                    let kind = match punct {
                        '(' => TokenType::LParen,
                        ')' => TokenType::RParen,
                        '[' => TokenType::LBracket,
                        ']' => TokenType::RBracket,
                        ',' => TokenType::Comma,
                        ':' => TokenType::Colon,
                        '.' | '?' => {
                            self.in_let_context = false;
                            TokenType::Period
                        }
                        '!' => TokenType::Exclamation,
                        '+' => TokenType::Plus,
                        '-' => TokenType::Minus,
                        '*' => TokenType::Star,
                        '/' => TokenType::Slash,
                        _ => {
                            self.pos += 1;
                            continue;
                        }
                    };
                    let lexeme = self.interner.intern(&punct.to_string());
                    let span = Span::new(word_start, word_end);
                    tokens.push(Token::new(kind, lexeme, span));
                }
                self.pos += 1;
                continue;
            }

            // Phase 33: Check for string literal marker
            if word.starts_with("\x00STR:") {
                let content = &word[5..]; // Skip the marker prefix
                let sym = self.interner.intern(content);
                let span = Span::new(word_start, word_end);
                tokens.push(Token::new(TokenType::StringLiteral(sym), sym, span));
                self.pos += 1;
                continue;
            }

            let kind = self.classify_with_lookahead(&word);
            let lexeme = self.interner.intern(&word);
            let span = Span::new(word_start, word_end);
            tokens.push(Token::new(kind, lexeme, span));

            if let Some(punct) = trailing_punct {
                if punct == '\'' {
                    if let Some(next_item) = self.words.get(self.pos + 1) {
                        if next_item.word.to_lowercase() == "s" {
                            let poss_lexeme = self.interner.intern("'s");
                            let poss_start = punct_pos.unwrap_or(word_end);
                            let poss_end = next_item.end;
                            tokens.push(Token::new(TokenType::Possessive, poss_lexeme, Span::new(poss_start, poss_end)));
                            self.pos += 1;
                            if let Some(s_punct) = next_item.trailing_punct {
                                let kind = match s_punct {
                                    '(' => TokenType::LParen,
                                    ')' => TokenType::RParen,
                                    '[' => TokenType::LBracket,
                                    ']' => TokenType::RBracket,
                                    ',' => TokenType::Comma,
                                    ':' => TokenType::Colon,
                                    '.' | '?' => TokenType::Period,
                                    '!' => TokenType::Exclamation,
                                    '+' => TokenType::Plus,
                                    '-' => TokenType::Minus,
                                    '*' => TokenType::Star,
                                    '/' => TokenType::Slash,
                                    _ => {
                                        self.pos += 1;
                                        continue;
                                    }
                                };
                                let s_punct_pos = next_item.punct_pos.unwrap_or(next_item.end);
                                let lexeme = self.interner.intern(&s_punct.to_string());
                                tokens.push(Token::new(kind, lexeme, Span::new(s_punct_pos, s_punct_pos + 1)));
                            }
                            self.pos += 1;
                            continue;
                        }
                    }
                    self.pos += 1;
                    continue;
                }

                let kind = match punct {
                    '(' => TokenType::LParen,
                    ')' => TokenType::RParen,
                    '[' => TokenType::LBracket,
                    ']' => TokenType::RBracket,
                    ',' => TokenType::Comma,
                    ':' => TokenType::Colon,
                    '.' | '?' => {
                        self.in_let_context = false;
                        TokenType::Period
                    }
                    '!' => TokenType::Exclamation,
                    '+' => TokenType::Plus,
                    '-' => TokenType::Minus,
                    '*' => TokenType::Star,
                    '/' => TokenType::Slash,
                    _ => {
                        self.pos += 1;
                        continue;
                    }
                };
                let p_start = punct_pos.unwrap_or(word_end);
                let lexeme = self.interner.intern(&punct.to_string());
                tokens.push(Token::new(kind, lexeme, Span::new(p_start, p_start + 1)));
            }

            self.pos += 1;
        }

        let eof_lexeme = self.interner.intern("");
        let eof_span = Span::new(self.input_len, self.input_len);
        tokens.push(Token::new(TokenType::EOF, eof_lexeme, eof_span));

        self.insert_indentation_tokens(tokens)
    }

    fn insert_indentation_tokens(&mut self, tokens: Vec<Token>) -> Vec<Token> {
        let mut result = Vec::new();
        let mut indent_stack: Vec<usize> = vec![0];
        let empty_sym = self.interner.intern("");

        for (i, token) in tokens.iter().enumerate() {
            result.push(token.clone());

            if token.kind == TokenType::Colon {
                let colon_pos = token.span.end;
                // Only insert Indent if colon is at end of line (followed by newline)
                if self.is_end_of_line(colon_pos) {
                    if let Some(indent) = self.measure_next_line_indent(colon_pos) {
                        let current_indent = *indent_stack.last().unwrap_or(&0);
                        if indent > current_indent {
                            indent_stack.push(indent);
                            let span = Span::new(colon_pos, colon_pos);
                            result.push(Token::new(TokenType::Indent, empty_sym, span));
                        }
                    }
                }
            }

            if token.kind == TokenType::Period {
                let period_pos = token.span.end;
                if let Some(next_indent) = self.measure_next_line_indent(period_pos) {
                    while indent_stack.len() > 1 {
                        let current_indent = *indent_stack.last().unwrap();
                        if next_indent < current_indent {
                            indent_stack.pop();
                            let span = Span::new(period_pos, period_pos);
                            result.push(Token::new(TokenType::Dedent, empty_sym, span));
                        } else {
                            break;
                        }
                    }
                }
            }
        }

        while indent_stack.len() > 1 {
            indent_stack.pop();
            let span = Span::new(self.input_len, self.input_len);
            result.push(Token::new(TokenType::Dedent, empty_sym, span));
        }

        let eof_pos = result.iter().position(|t| t.kind == TokenType::EOF);
        if let Some(pos) = eof_pos {
            let eof = result.remove(pos);
            result.push(eof);
        }

        result
    }

    /// Check if position is at end of line (only whitespace until newline)
    fn is_end_of_line(&self, from_pos: usize) -> bool {
        let bytes = self.source.as_bytes();
        let mut pos = from_pos;
        while pos < bytes.len() {
            match bytes[pos] {
                b' ' | b'\t' => pos += 1,
                b'\n' => return true,
                _ => return false,
            }
        }
        true // End of input is also end of line
    }

    fn measure_next_line_indent(&self, from_pos: usize) -> Option<usize> {
        let bytes = self.source.as_bytes();
        let mut pos = from_pos;

        while pos < bytes.len() && bytes[pos] != b'\n' {
            pos += 1;
        }

        if pos >= bytes.len() {
            return None;
        }

        pos += 1;

        let mut indent = 0;
        while pos < bytes.len() {
            match bytes[pos] {
                b' ' => indent += 1,
                b'\t' => indent += 4,
                b'\n' => {
                    indent = 0;
                }
                _ => break,
            }
            pos += 1;
        }

        if pos >= bytes.len() {
            return None;
        }

        Some(indent)
    }

    fn word_to_number(word: &str) -> Option<u32> {
        lexicon::word_to_number(&word.to_lowercase())
    }

    fn is_numeric_literal(word: &str) -> bool {
        if word.is_empty() {
            return false;
        }
        let chars: Vec<char> = word.chars().collect();
        let first = chars[0];
        if first.is_ascii_digit() {
            return true;
        }
        if word.contains('_') && chars.iter().any(|c| c.is_alphabetic()) {
            return true;
        }
        false
    }

    fn classify_with_lookahead(&mut self, word: &str) -> TokenType {
        // Handle block headers (##Theorem, ##Main, etc.)
        if word.starts_with("##") {
            let block_name = &word[2..];
            let block_type = match block_name.to_lowercase().as_str() {
                "theorem" => BlockType::Theorem,
                "main" => BlockType::Main,
                "definition" => BlockType::Definition,
                "proof" => BlockType::Proof,
                "example" => BlockType::Example,
                "logic" => BlockType::Logic,
                "note" => BlockType::Note,
                "to" => BlockType::Function,  // Phase 32: ## To blocks
                _ => BlockType::Note, // Default unknown block types to Note
            };

            // Update lexer mode based on block type
            self.mode = match block_type {
                BlockType::Main | BlockType::Function => LexerMode::Imperative,
                _ => LexerMode::Declarative,
            };

            return TokenType::BlockHeader { block_type };
        }

        let lower = word.to_lowercase();

        if lower == "each" && self.peek_sequence(&["other"]) {
            self.consume_words(1);
            return TokenType::Reciprocal;
        }

        if lower == "to" {
            if let Some(next) = self.peek_word(1) {
                if self.is_verb_like(next) {
                    return TokenType::To;
                }
            }
            let sym = self.interner.intern("to");
            return TokenType::Preposition(sym);
        }

        if lower == "at" {
            if let Some(next) = self.peek_word(1) {
                let next_lower = next.to_lowercase();
                if next_lower == "least" {
                    if let Some(num_word) = self.peek_word(2) {
                        if let Some(n) = Self::word_to_number(num_word) {
                            self.consume_words(2);
                            return TokenType::AtLeast(n);
                        }
                    }
                }
                if next_lower == "most" {
                    if let Some(num_word) = self.peek_word(2) {
                        if let Some(n) = Self::word_to_number(num_word) {
                            self.consume_words(2);
                            return TokenType::AtMost(n);
                        }
                    }
                }
            }
        }

        if let Some(n) = Self::word_to_number(&lower) {
            return TokenType::Cardinal(n);
        }

        if Self::is_numeric_literal(word) {
            let sym = self.interner.intern(word);
            return TokenType::Number(sym);
        }

        if lower == "if" && self.peek_sequence(&["and", "only", "if"]) {
            self.consume_words(3);
            return TokenType::Iff;
        }

        if lower == "is" {
            if self.peek_sequence(&["equal", "to"]) {
                self.consume_words(2);
                return TokenType::Identity;
            }
            if self.peek_sequence(&["identical", "to"]) {
                self.consume_words(2);
                return TokenType::Identity;
            }
        }

        if (lower == "a" || lower == "an") && word.chars().next().unwrap().is_uppercase() {
            // Capitalized "A" or "An" - disambiguate article vs proper name
            // Heuristic: articles are followed by nouns/adjectives, not verbs or keywords
            if let Some(next) = self.peek_word(1) {
                let next_lower = next.to_lowercase();
                let next_starts_lowercase = next.chars().next().map(|c| c.is_lowercase()).unwrap_or(false);

                // If followed by logical keyword, treat as proper name (propositional variable)
                if matches!(next_lower.as_str(), "if" | "and" | "or" | "implies" | "iff") {
                    let sym = self.interner.intern(word);
                    return TokenType::ProperName(sym);
                }

                // If next word is a verb (like "has", "is", "ran"), A is likely a name
                // Exception: gerunds (like "running") can follow articles
                // Exception: words in disambiguation_not_verbs (like "red") are not verbs
                let is_verb = self.lexicon.lookup_verb(&next_lower).is_some()
                    && !lexicon::is_disambiguation_not_verb(&next_lower);
                let is_gerund = next_lower.ends_with("ing");
                if is_verb && !is_gerund {
                    let sym = self.interner.intern(word);
                    return TokenType::ProperName(sym);
                }

                // Definition pattern: "A [TypeName] is a..." or "A [TypeName] has:" - treat A as article
                // even when TypeName is capitalized and unknown
                if let Some(third) = self.peek_word(2) {
                    let third_lower = third.to_lowercase();
                    // Phase 31: Added "has" for struct definitions
                    if third_lower == "is" || third_lower == "are" || third_lower == "has" {
                        return TokenType::Article(Definiteness::Indefinite);
                    }
                }

                // It's an article if next word is:
                // - A known noun or adjective, or
                // - Lowercase (likely a common word we don't recognize)
                let is_content_word = self.is_noun_like(&next_lower) || self.is_adjective_like(&next_lower);
                if is_content_word || next_starts_lowercase {
                    return TokenType::Article(Definiteness::Indefinite);
                }
            }
            let sym = self.interner.intern(word);
            return TokenType::ProperName(sym);
        }

        self.classify_word(word)
    }

    fn is_noun_like(&self, word: &str) -> bool {
        if lexicon::is_noun_pattern(word) || lexicon::is_common_noun(word) {
            return true;
        }
        if word.ends_with("er") || word.ends_with("ian") || word.ends_with("ist") {
            return true;
        }
        false
    }

    fn is_adjective_like(&self, word: &str) -> bool {
        lexicon::is_adjective(word) || lexicon::is_non_intersective(word)
    }

    fn classify_word(&mut self, word: &str) -> TokenType {
        let lower = word.to_lowercase();
        let first_char = word.chars().next().unwrap();

        // Disambiguate "that" as determiner vs complementizer
        // "that dog" → Article(Distal), "I know that he ran" → That (complementizer)
        if lower == "that" {
            if let Some(next) = self.peek_word(1) {
                let next_lower = next.to_lowercase();
                if self.is_noun_like(&next_lower) || self.is_adjective_like(&next_lower) {
                    return TokenType::Article(Definiteness::Distal);
                }
            }
        }

        if let Some(kind) = lexicon::lookup_keyword(&lower) {
            return kind;
        }

        if let Some(kind) = lexicon::lookup_pronoun(&lower) {
            return kind;
        }

        if let Some(def) = lexicon::lookup_article(&lower) {
            return TokenType::Article(def);
        }

        if let Some(time) = lexicon::lookup_auxiliary(&lower) {
            return TokenType::Auxiliary(time);
        }

        // Handle imperative keywords that might conflict with prepositions
        match lower.as_str() {
            "call" => return TokenType::Call,
            "in" if self.mode == LexerMode::Imperative => return TokenType::In,
            _ => {}
        }

        if lexicon::is_preposition(&lower) {
            let sym = self.interner.intern(&lower);
            return TokenType::Preposition(sym);
        }

        match lower.as_str() {
            "equals" => return TokenType::Equals,
            "item" => return TokenType::Item,
            "items" => return TokenType::Items,
            "let" => {
                self.in_let_context = true;
                return TokenType::Let;
            }
            "set" => {
                // In Imperative mode, treat "set" as the keyword
                // In Declarative mode, check if followed by identifier + "to" to disambiguate from noun "set"
                if self.mode == LexerMode::Imperative {
                    return TokenType::Set;
                }
                // Phase 31: Also check positions 3, 4, 5 for "to" (handles field access like "set p's x to")
                for offset in 2..=5 {
                    if self.peek_word(offset).map_or(false, |w| w.to_lowercase() == "to") {
                        return TokenType::Set;
                    }
                }
            }
            "return" => return TokenType::Return,
            "be" if self.in_let_context => {
                self.in_let_context = false;
                return TokenType::Be;
            }
            "while" => return TokenType::While,
            "assert" => return TokenType::Assert,
            "trust" => return TokenType::Trust,  // Phase 35: Trust statement
            "otherwise" => return TokenType::Otherwise,
            // Phase 33: Sum type definition (after "is")
            "either" => return TokenType::Either,
            // Phase 33: Pattern matching statement
            "inspect" if self.mode == LexerMode::Imperative => return TokenType::Inspect,
            // Phase 31: Constructor keyword (Imperative mode only)
            "new" if self.mode == LexerMode::Imperative => return TokenType::New,
            // Only emit Give/Show as keywords in Imperative mode
            // In Declarative mode, they fall through to lexicon lookup as verbs
            "give" if self.mode == LexerMode::Imperative => return TokenType::Give,
            "show" if self.mode == LexerMode::Imperative => return TokenType::Show,
            "if" => return TokenType::If,
            "only" => return TokenType::Focus(FocusKind::Only),
            "even" => return TokenType::Focus(FocusKind::Even),
            "just" if self.peek_word(1).map_or(false, |w| {
                !self.is_verb_like(w) || w.to_lowercase() == "john" || w.chars().next().map_or(false, |c| c.is_uppercase())
            }) => return TokenType::Focus(FocusKind::Just),
            "much" => return TokenType::Measure(MeasureKind::Much),
            "little" => return TokenType::Measure(MeasureKind::Little),
            _ => {}
        }

        if lexicon::is_scopal_adverb(&lower) {
            let sym = self.interner.intern(&Self::capitalize(&lower));
            return TokenType::ScopalAdverb(sym);
        }

        if lexicon::is_temporal_adverb(&lower) {
            let sym = self.interner.intern(&Self::capitalize(&lower));
            return TokenType::TemporalAdverb(sym);
        }

        if lexicon::is_non_intersective(&lower) {
            let sym = self.interner.intern(&Self::capitalize(&lower));
            return TokenType::NonIntersectiveAdjective(sym);
        }

        if lexicon::is_adverb(&lower) {
            let sym = self.interner.intern(&Self::capitalize(&lower));
            return TokenType::Adverb(sym);
        }
        if lower.ends_with("ly") && !lexicon::is_not_adverb(&lower) && lower.len() > 4 {
            let sym = self.interner.intern(&Self::capitalize(&lower));
            return TokenType::Adverb(sym);
        }

        if let Some(base) = self.try_parse_superlative(&lower) {
            let sym = self.interner.intern(&base);
            return TokenType::Superlative(sym);
        }

        // Phase 35: Handle irregular comparatives (less, more, better, worse)
        let irregular_comparative = match lower.as_str() {
            "less" => Some("Little"),
            "more" => Some("Much"),
            "better" => Some("Good"),
            "worse" => Some("Bad"),
            _ => None,
        };
        if let Some(base) = irregular_comparative {
            let sym = self.interner.intern(base);
            return TokenType::Comparative(sym);
        }

        if let Some(base) = self.try_parse_comparative(&lower) {
            let sym = self.interner.intern(&base);
            return TokenType::Comparative(sym);
        }

        if lexicon::is_performative(&lower) {
            let sym = self.interner.intern(&Self::capitalize(&lower));
            return TokenType::Performative(sym);
        }

        if lexicon::is_base_verb_early(&lower) {
            let sym = self.interner.intern(&Self::capitalize(&lower));
            let class = lexicon::lookup_verb_class(&lower);
            return TokenType::Verb {
                lemma: sym,
                time: Time::Present,
                aspect: Aspect::Simple,
                class,
            };
        }

        // Check for gerunds/progressive verbs BEFORE ProperName check
        // "Running" at start of sentence should be Verb, not ProperName
        if lower.ends_with("ing") && lower.len() > 4 {
            if let Some(entry) = self.lexicon.lookup_verb(&lower) {
                let sym = self.interner.intern(&entry.lemma);
                return TokenType::Verb {
                    lemma: sym,
                    time: entry.time,
                    aspect: entry.aspect,
                    class: entry.class,
                };
            }
        }

        if first_char.is_uppercase() {
            let sym = self.interner.intern(word);
            return TokenType::ProperName(sym);
        }

        let verb_entry = self.lexicon.lookup_verb(&lower);
        let is_noun = lexicon::is_common_noun(&lower);
        let is_adj = self.is_adjective_like(&lower);
        let is_disambiguated = lexicon::is_disambiguation_not_verb(&lower);

        // Ambiguous: word is Verb AND (Noun OR Adjective), not disambiguated
        if verb_entry.is_some() && (is_noun || is_adj) && !is_disambiguated {
            let entry = verb_entry.unwrap();
            let verb_token = TokenType::Verb {
                lemma: self.interner.intern(&entry.lemma),
                time: entry.time,
                aspect: entry.aspect,
                class: entry.class,
            };

            let mut alternatives = Vec::new();
            if is_noun {
                alternatives.push(TokenType::Noun(self.interner.intern(word)));
            }
            if is_adj {
                alternatives.push(TokenType::Adjective(self.interner.intern(word)));
            }

            return TokenType::Ambiguous {
                primary: Box::new(verb_token),
                alternatives,
            };
        }

        // Disambiguated to noun/adjective (not verb)
        if let Some(_) = &verb_entry {
            if is_disambiguated {
                let sym = self.interner.intern(word);
                if is_noun {
                    return TokenType::Noun(sym);
                }
                return TokenType::Adjective(sym);
            }
        }

        // Pure verb
        if let Some(entry) = verb_entry {
            let sym = self.interner.intern(&entry.lemma);
            return TokenType::Verb {
                lemma: sym,
                time: entry.time,
                aspect: entry.aspect,
                class: entry.class,
            };
        }

        // Pure noun
        if is_noun {
            let sym = self.interner.intern(word);
            return TokenType::Noun(sym);
        }

        if lexicon::is_base_verb(&lower) {
            let sym = self.interner.intern(&Self::capitalize(&lower));
            let class = lexicon::lookup_verb_class(&lower);
            return TokenType::Verb {
                lemma: sym,
                time: Time::Present,
                aspect: Aspect::Simple,
                class,
            };
        }

        if lower.ends_with("ian")
            || lower.ends_with("er")
            || lower == "logic"
            || lower == "time"
            || lower == "men"
            || lower == "book"
            || lower == "house"
            || lower == "code"
            || lower == "user"
        {
            let sym = self.interner.intern(word);
            return TokenType::Noun(sym);
        }

        if lexicon::is_particle(&lower) {
            let sym = self.interner.intern(&lower);
            return TokenType::Particle(sym);
        }

        let sym = self.interner.intern(word);
        TokenType::Adjective(sym)
    }

    fn capitalize(s: &str) -> String {
        let mut chars = s.chars();
        match chars.next() {
            None => String::new(),
            Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
        }
    }

    pub fn is_collective_verb(lemma: &str) -> bool {
        lexicon::is_collective_verb(&lemma.to_lowercase())
    }

    pub fn is_mixed_verb(lemma: &str) -> bool {
        lexicon::is_mixed_verb(&lemma.to_lowercase())
    }

    pub fn is_ditransitive_verb(lemma: &str) -> bool {
        lexicon::is_ditransitive_verb(&lemma.to_lowercase())
    }

    fn is_verb_like(&self, word: &str) -> bool {
        let lower = word.to_lowercase();
        if lexicon::is_infinitive_verb(&lower) {
            return true;
        }
        if let Some(entry) = self.lexicon.lookup_verb(&lower) {
            return entry.lemma.len() > 0;
        }
        false
    }

    pub fn is_subject_control_verb(lemma: &str) -> bool {
        lexicon::is_subject_control_verb(&lemma.to_lowercase())
    }

    pub fn is_raising_verb(lemma: &str) -> bool {
        lexicon::is_raising_verb(&lemma.to_lowercase())
    }

    pub fn is_object_control_verb(lemma: &str) -> bool {
        lexicon::is_object_control_verb(&lemma.to_lowercase())
    }

    fn try_parse_superlative(&self, word: &str) -> Option<String> {
        if !word.ends_with("est") || word.len() < 5 {
            return None;
        }

        let base = &word[..word.len() - 3];

        if base.len() >= 2 {
            let chars: Vec<char> = base.chars().collect();
            let last = chars[chars.len() - 1];
            let second_last = chars[chars.len() - 2];
            if last == second_last && !"aeiou".contains(last) {
                let stem = &base[..base.len() - 1];
                if lexicon::is_gradable_adjective(stem) {
                    return Some(Self::capitalize(stem));
                }
            }
        }

        if base.ends_with("i") {
            let stem = format!("{}y", &base[..base.len() - 1]);
            if lexicon::is_gradable_adjective(&stem) {
                return Some(Self::capitalize(&stem));
            }
        }

        if lexicon::is_gradable_adjective(base) {
            return Some(Self::capitalize(base));
        }

        None
    }

    fn try_parse_comparative(&self, word: &str) -> Option<String> {
        if !word.ends_with("er") || word.len() < 4 {
            return None;
        }

        let base = &word[..word.len() - 2];

        if base.len() >= 2 {
            let chars: Vec<char> = base.chars().collect();
            let last = chars[chars.len() - 1];
            let second_last = chars[chars.len() - 2];
            if last == second_last && !"aeiou".contains(last) {
                let stem = &base[..base.len() - 1];
                if lexicon::is_gradable_adjective(stem) {
                    return Some(Self::capitalize(stem));
                }
            }
        }

        if base.ends_with("i") {
            let stem = format!("{}y", &base[..base.len() - 1]);
            if lexicon::is_gradable_adjective(&stem) {
                return Some(Self::capitalize(&stem));
            }
        }

        if lexicon::is_gradable_adjective(base) {
            return Some(Self::capitalize(base));
        }

        None
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn lexer_handles_apostrophe() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("it's raining", &mut interner);
        let tokens = lexer.tokenize();
        assert!(!tokens.is_empty());
    }

    #[test]
    fn lexer_handles_question_mark() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("Is it raining?", &mut interner);
        let tokens = lexer.tokenize();
        assert!(!tokens.is_empty());
    }

    #[test]
    fn ring_is_not_verb() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("ring", &mut interner);
        let tokens = lexer.tokenize();
        assert!(matches!(tokens[0].kind, TokenType::Noun(_)));
    }

    #[test]
    fn debug_that_token() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("The cat that runs", &mut interner);
        let tokens = lexer.tokenize();
        for (i, t) in tokens.iter().enumerate() {
            let lex = interner.resolve(t.lexeme);
            eprintln!("Token[{}]: {:?} -> {:?}", i, lex, t.kind);
        }
        let that_token = tokens.iter().find(|t| interner.resolve(t.lexeme) == "that");
        if let Some(t) = that_token {
            // Verify discriminant comparison works
            let check = std::mem::discriminant(&t.kind) == std::mem::discriminant(&TokenType::That);
            eprintln!("Discriminant check for That: {}", check);
            assert!(matches!(t.kind, TokenType::That), "'that' should be TokenType::That, got {:?}", t.kind);
        } else {
            panic!("No 'that' token found");
        }
    }

    #[test]
    fn bus_is_not_verb() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("bus", &mut interner);
        let tokens = lexer.tokenize();
        assert!(matches!(tokens[0].kind, TokenType::Noun(_)));
    }

    #[test]
    fn lowercase_a_is_article() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("a car", &mut interner);
        let tokens = lexer.tokenize();
        for (i, t) in tokens.iter().enumerate() {
            let lex = interner.resolve(t.lexeme);
            eprintln!("Token[{}]: {:?} -> {:?}", i, lex, t.kind);
        }
        assert_eq!(tokens[0].kind, TokenType::Article(Definiteness::Indefinite));
        assert!(matches!(tokens[1].kind, TokenType::Noun(_)), "Expected Noun, got {:?}", tokens[1].kind);
    }

    #[test]
    fn open_is_ambiguous() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("open", &mut interner);
        let tokens = lexer.tokenize();

        if let TokenType::Ambiguous { primary, alternatives } = &tokens[0].kind {
            assert!(matches!(**primary, TokenType::Verb { .. }), "Primary should be Verb");
            assert!(alternatives.iter().any(|t| matches!(t, TokenType::Adjective(_))),
                "Should have Adjective alternative");
        } else {
            panic!("Expected Ambiguous token for 'open', got {:?}", tokens[0].kind);
        }
    }

    #[test]
    fn basic_tokenization() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("All men are mortal.", &mut interner);
        let tokens = lexer.tokenize();
        assert_eq!(tokens[0].kind, TokenType::All);
        assert!(matches!(tokens[1].kind, TokenType::Noun(_)));
        assert_eq!(tokens[2].kind, TokenType::Are);
    }

    #[test]
    fn iff_tokenizes_as_single_token() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("A if and only if B", &mut interner);
        let tokens = lexer.tokenize();
        assert!(
            tokens.iter().any(|t| t.kind == TokenType::Iff),
            "should contain Iff token: got {:?}",
            tokens
        );
    }

    #[test]
    fn is_equal_to_tokenizes_as_identity() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("Socrates is equal to Socrates", &mut interner);
        let tokens = lexer.tokenize();
        assert!(
            tokens.iter().any(|t| t.kind == TokenType::Identity),
            "should contain Identity token: got {:?}",
            tokens
        );
    }

    #[test]
    fn is_identical_to_tokenizes_as_identity() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("Clark is identical to Superman", &mut interner);
        let tokens = lexer.tokenize();
        assert!(
            tokens.iter().any(|t| t.kind == TokenType::Identity),
            "should contain Identity token: got {:?}",
            tokens
        );
    }

    #[test]
    fn itself_tokenizes_as_reflexive() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("John loves itself", &mut interner);
        let tokens = lexer.tokenize();
        assert!(
            tokens.iter().any(|t| t.kind == TokenType::Reflexive),
            "should contain Reflexive token: got {:?}",
            tokens
        );
    }

    #[test]
    fn himself_tokenizes_as_reflexive() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("John sees himself", &mut interner);
        let tokens = lexer.tokenize();
        assert!(
            tokens.iter().any(|t| t.kind == TokenType::Reflexive),
            "should contain Reflexive token: got {:?}",
            tokens
        );
    }

    #[test]
    fn to_stay_tokenizes_correctly() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("to stay", &mut interner);
        let tokens = lexer.tokenize();
        assert!(
            tokens.iter().any(|t| t.kind == TokenType::To),
            "should contain To token: got {:?}",
            tokens
        );
        assert!(
            tokens.iter().any(|t| matches!(t.kind, TokenType::Verb { .. })),
            "should contain Verb token for stay: got {:?}",
            tokens
        );
    }

    #[test]
    fn possessive_apostrophe_s() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("John's dog", &mut interner);
        let tokens = lexer.tokenize();
        assert!(
            tokens.iter().any(|t| t.kind == TokenType::Possessive),
            "should contain Possessive token: got {:?}",
            tokens
        );
        assert!(
            tokens.iter().any(|t| matches!(&t.kind, TokenType::ProperName(_))),
            "should have John as proper name: got {:?}",
            tokens
        );
    }

    #[test]
    fn lexer_produces_valid_spans() {
        let input = "All men are mortal.";
        let mut interner = Interner::new();
        let mut lexer = Lexer::new(input, &mut interner);
        let tokens = lexer.tokenize();

        // "All" at 0..3
        assert_eq!(tokens[0].span.start, 0);
        assert_eq!(tokens[0].span.end, 3);
        assert_eq!(&input[tokens[0].span.start..tokens[0].span.end], "All");

        // "men" at 4..7
        assert_eq!(tokens[1].span.start, 4);
        assert_eq!(tokens[1].span.end, 7);
        assert_eq!(&input[tokens[1].span.start..tokens[1].span.end], "men");

        // "are" at 8..11
        assert_eq!(tokens[2].span.start, 8);
        assert_eq!(tokens[2].span.end, 11);
        assert_eq!(&input[tokens[2].span.start..tokens[2].span.end], "are");

        // "mortal" at 12..18
        assert_eq!(tokens[3].span.start, 12);
        assert_eq!(tokens[3].span.end, 18);
        assert_eq!(&input[tokens[3].span.start..tokens[3].span.end], "mortal");

        // "." at 18..19
        assert_eq!(tokens[4].span.start, 18);
        assert_eq!(tokens[4].span.end, 19);

        // EOF at end
        assert_eq!(tokens[5].span.start, input.len());
        assert_eq!(tokens[5].kind, TokenType::EOF);
    }
}

```

---

## Parser & AST

The parser builds an Abstract Syntax Tree from the token stream using recursive descent with operator precedence handling. The AST is split into two modules: declarative logic expressions and imperative statements.

**Location:** `src/ast/` (module), `src/parser/`

### AST Module

**File:** `src/ast/mod.rs`

Module exports for the dual-AST architecture. Re-exports logic.rs (declarative) and stmt.rs (imperative) types.

```rust
pub mod logic;
pub mod stmt;

pub use logic::*;
pub use stmt::{Stmt, Expr, Literal, Block, BinaryOpKind, TypeExpr, MatchArm};

```

---

### Logic AST (Declarative)

**File:** `src/ast/logic.rs`

Arena-allocated AST with Copy semantics for first-order logic. Boxed large variants (CategoricalData, RelationData, NeoEventData) reduce Expr size from 112 to 32 bytes. Includes compile-time size assertions. **Expression types:** Predicate, Identity, Quantifier (with Generic and island_id for scope constraints), Modal, Temporal, Aspectual, NeoEvent (thematic roles), Event, Control (raising/control verbs), Presupposition, Focus, SpeechAct, Imperative, Comparative (with difference field for measure phrases), Superlative, Counterfactual, Distributive, Scopal, TemporalAnchor, Causal, Intensional (opaque verb wrapper). **Term types:** Constants, Variables, Functions, Sigma, Group, Possessed, Intension (Montague up-arrow ^P for de dicto), Proposition (sentential complement), Value (numeric with kind/unit/dimension). **Intensionality Support:** Term::Intension(Symbol) for de dicto readings; Expr::Intensional { operator, content } for opaque verb contexts. **Sentential Complements:** Term::Proposition(&Expr) wraps embedded clauses as term arguments for verbs like 'say', 'believe', 'think'. Transpiles to bracket notation [expr]. **Scope Tracking:** Expr::Quantifier.island_id: u32 identifies scope boundaries for constraining quantifier movement. **Degree Semantics (Phase 8):** Dimension enum (Length, Time, Weight, Temperature, Cardinality) for measurement categories. NumberKind enum (Real, Integer, Symbolic) for prover-ready numeric types. Term::Value stores numeric value with optional unit Symbol and Dimension. Expr::Comparative.difference field holds optional measure phrase ('2 inches' in 'taller'). ThematicRole enum: Agent, Patient, Theme, Goal, Source, Recipient, Instrument, Location, Time, Manner. VoiceOperator enum (Passive) for voice handling. AspectOperator enum (Progressive, Perfect, Habitual, Iterative) for grammatical aspect. Habitual for present-tense non-stative verbs; Iterative for progressive semelfactives.

```rust
use crate::arena::Arena;
use crate::intern::Symbol;
use crate::lexicon::Definiteness;
use crate::token::TokenType;

// ═══════════════════════════════════════════════════════════════════
// Semantic Types (Montague Grammar)
// ═══════════════════════════════════════════════════════════════════

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum LogicalType {
    Entity,      // e (individuals: John, the ball)
    TruthValue,  // t (propositions)
    Property,    // <e,t> (predicates: Unicorn, Water)
    Quantifier,  // <<e,t>,t> (every man, a woman)
}

// ═══════════════════════════════════════════════════════════════════
// Degree Semantics (Prover-Ready Number System)
// ═══════════════════════════════════════════════════════════════════

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum Dimension {
    Length,
    Time,
    Weight,
    Temperature,
    Cardinality,
}

#[derive(Debug, Clone, Copy, PartialEq)]
pub enum NumberKind {
    Real(f64),
    Integer(i64),
    Symbolic(Symbol),
}

// ═══════════════════════════════════════════════════════════════════
// First-Order Logic Types (FOL Upgrade)
// ═══════════════════════════════════════════════════════════════════

#[derive(Debug, Clone, Copy)]
pub enum Term<'a> {
    Constant(Symbol),
    Variable(Symbol),
    Function(Symbol, &'a [Term<'a>]),
    Group(&'a [Term<'a>]),
    Possessed { possessor: &'a Term<'a>, possessed: Symbol },
    Sigma(Symbol),
    Intension(Symbol),  // ^Predicate (Montague up-arrow for de dicto)
    Proposition(&'a LogicExpr<'a>),  // Sentential complement (embedded clause)
    Value {
        kind: NumberKind,
        unit: Option<Symbol>,
        dimension: Option<Dimension>,
    },
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum QuantifierKind {
    Universal,
    Existential,
    Most,
    Few,
    Many,
    Cardinal(u32),
    AtLeast(u32),
    AtMost(u32),
    Generic,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum BinaryOpKind {
    And,
    Or,
    Implies,
    Iff,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum UnaryOpKind {
    Not,
}

// ═══════════════════════════════════════════════════════════════════
// Temporal & Aspect Operators (Arthur Prior's Tense Logic)
// ═══════════════════════════════════════════════════════════════════

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum TemporalOperator {
    Past,
    Future,
}

// ═══════════════════════════════════════════════════════════════════
// Event Semantics (Neo-Davidsonian)
// ═══════════════════════════════════════════════════════════════════

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum ThematicRole {
    Agent,
    Patient,
    Theme,
    Recipient,
    Goal,
    Source,
    Instrument,
    Location,
    Time,
    Manner,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum AspectOperator {
    Progressive,
    Perfect,
    Habitual,
    Iterative,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum VoiceOperator {
    Passive,
}

// ═══════════════════════════════════════════════════════════════════
// Legacy Types (kept during transition)
// ═══════════════════════════════════════════════════════════════════

#[derive(Debug)]
pub struct NounPhrase<'a> {
    pub definiteness: Option<Definiteness>,
    pub adjectives: &'a [Symbol],
    pub noun: Symbol,
    pub possessor: Option<&'a NounPhrase<'a>>,
    pub pps: &'a [&'a LogicExpr<'a>],
    pub superlative: Option<Symbol>,
}

// ═══════════════════════════════════════════════════════════════════
// Boxed Variant Data (keeps LogicExpr enum small)
// ═══════════════════════════════════════════════════════════════════

#[derive(Debug)]
pub struct CategoricalData<'a> {
    pub quantifier: TokenType,
    pub subject: NounPhrase<'a>,
    pub copula_negative: bool,
    pub predicate: NounPhrase<'a>,
}

#[derive(Debug)]
pub struct RelationData<'a> {
    pub subject: NounPhrase<'a>,
    pub verb: Symbol,
    pub object: NounPhrase<'a>,
}

#[derive(Debug)]
pub struct NeoEventData<'a> {
    pub event_var: Symbol,
    pub verb: Symbol,
    pub roles: &'a [(ThematicRole, Term<'a>)],
    pub modifiers: &'a [Symbol],
}

impl<'a> NounPhrase<'a> {
    pub fn simple(noun: Symbol) -> Self {
        NounPhrase {
            definiteness: None,
            adjectives: &[],
            noun,
            possessor: None,
            pps: &[],
            superlative: None,
        }
    }

    pub fn with_definiteness(definiteness: Definiteness, noun: Symbol) -> Self {
        NounPhrase {
            definiteness: Some(definiteness),
            adjectives: &[],
            noun,
            possessor: None,
            pps: &[],
            superlative: None,
        }
    }
}

#[derive(Debug, Clone, Copy, PartialEq)]
pub enum ModalDomain {
    Alethic,
    Deontic,
}

#[derive(Debug, Clone, Copy, PartialEq)]
pub struct ModalVector {
    pub domain: ModalDomain,
    pub force: f32,
}

// ═══════════════════════════════════════════════════════════════════
// Expression Enum (hybrid: old + new variants)
// ═══════════════════════════════════════════════════════════════════

#[derive(Debug)]
pub enum LogicExpr<'a> {
    Predicate {
        name: Symbol,
        args: &'a [Term<'a>],
    },

    Identity {
        left: &'a Term<'a>,
        right: &'a Term<'a>,
    },

    Metaphor {
        tenor: &'a Term<'a>,
        vehicle: &'a Term<'a>,
    },

    Quantifier {
        kind: QuantifierKind,
        variable: Symbol,
        body: &'a LogicExpr<'a>,
        island_id: u32,
    },

    Categorical(Box<CategoricalData<'a>>),

    Relation(Box<RelationData<'a>>),

    Modal {
        vector: ModalVector,
        operand: &'a LogicExpr<'a>,
    },

    Temporal {
        operator: TemporalOperator,
        body: &'a LogicExpr<'a>,
    },

    Aspectual {
        operator: AspectOperator,
        body: &'a LogicExpr<'a>,
    },

    Voice {
        operator: VoiceOperator,
        body: &'a LogicExpr<'a>,
    },

    BinaryOp {
        left: &'a LogicExpr<'a>,
        op: TokenType,
        right: &'a LogicExpr<'a>,
    },

    UnaryOp {
        op: TokenType,
        operand: &'a LogicExpr<'a>,
    },

    Question {
        wh_variable: Symbol,
        body: &'a LogicExpr<'a>,
    },

    YesNoQuestion {
        body: &'a LogicExpr<'a>,
    },

    Atom(Symbol),

    Lambda {
        variable: Symbol,
        body: &'a LogicExpr<'a>,
    },

    App {
        function: &'a LogicExpr<'a>,
        argument: &'a LogicExpr<'a>,
    },

    Intensional {
        operator: Symbol,
        content: &'a LogicExpr<'a>,
    },

    Event {
        predicate: &'a LogicExpr<'a>,
        adverbs: &'a [Symbol],
    },

    NeoEvent(Box<NeoEventData<'a>>),

    Imperative {
        action: &'a LogicExpr<'a>,
    },

    SpeechAct {
        performer: Symbol,
        act_type: Symbol,
        content: &'a LogicExpr<'a>,
    },

    Counterfactual {
        antecedent: &'a LogicExpr<'a>,
        consequent: &'a LogicExpr<'a>,
    },

    Causal {
        effect: &'a LogicExpr<'a>,
        cause: &'a LogicExpr<'a>,
    },

    Comparative {
        adjective: Symbol,
        subject: &'a Term<'a>,
        object: &'a Term<'a>,
        difference: Option<&'a Term<'a>>,
    },

    Superlative {
        adjective: Symbol,
        subject: &'a Term<'a>,
        domain: Symbol,
    },

    Scopal {
        operator: Symbol,
        body: &'a LogicExpr<'a>,
    },

    Control {
        verb: Symbol,
        subject: &'a Term<'a>,
        object: Option<&'a Term<'a>>,
        infinitive: &'a LogicExpr<'a>,
    },

    Presupposition {
        assertion: &'a LogicExpr<'a>,
        presupposition: &'a LogicExpr<'a>,
    },

    Focus {
        kind: crate::token::FocusKind,
        focused: &'a Term<'a>,
        scope: &'a LogicExpr<'a>,
    },

    TemporalAnchor {
        anchor: Symbol,
        body: &'a LogicExpr<'a>,
    },

    Distributive {
        predicate: &'a LogicExpr<'a>,
    },

    /// Group existential for collective readings of cardinals
    /// ∃g(Group(g) ∧ Count(g,n) ∧ ∀x(Member(x,g) → Restriction(x)) ∧ Body(g))
    GroupQuantifier {
        group_var: Symbol,
        count: u32,
        member_var: Symbol,
        restriction: &'a LogicExpr<'a>,
        body: &'a LogicExpr<'a>,
    },
}

impl<'a> LogicExpr<'a> {
    pub fn lambda(var: Symbol, body: &'a LogicExpr<'a>, arena: &'a Arena<LogicExpr<'a>>) -> &'a LogicExpr<'a> {
        arena.alloc(LogicExpr::Lambda {
            variable: var,
            body,
        })
    }

    pub fn app(func: &'a LogicExpr<'a>, arg: &'a LogicExpr<'a>, arena: &'a Arena<LogicExpr<'a>>) -> &'a LogicExpr<'a> {
        arena.alloc(LogicExpr::App {
            function: func,
            argument: arg,
        })
    }
}

#[cfg(test)]
mod size_tests {
    use super::*;
    use std::mem::size_of;

    #[test]
    fn test_ast_node_sizes() {
        println!("LogicExpr size: {} bytes", size_of::<LogicExpr>());
        println!("Term size: {} bytes", size_of::<Term>());
        println!("NounPhrase size: {} bytes", size_of::<NounPhrase>());

        assert!(
            size_of::<LogicExpr>() <= 48,
            "LogicExpr is {} bytes - consider boxing large variants",
            size_of::<LogicExpr>()
        );
        assert!(
            size_of::<Term>() <= 32,
            "Term is {} bytes",
            size_of::<Term>()
        );
    }
}

```

---

### Statement AST (Imperative)

**File:** `src/ast/stmt.rs`

Imperative AST for executable code blocks. **Stmt enum variants:** Let (variable binding), Set (mutation), Call (function invocation), If (conditional with then/else blocks), While (loops), Return (with optional value), Assert (bridge to logic kernel - embeds Expr for verification), Give (ownership transfer/move semantics), Show (immutable borrow). **Expr enum (imperative):** Literal (Number, Text, Boolean, Nothing), Identifier, BinaryOp (arithmetic and comparison), Call, Index, Slice. **BinaryOpKind:** Add, Subtract, Multiply, Divide, Eq, NotEq, Lt, Gt, LtEq, GtEq. The Assert statement connects imperative code to the declarative logic kernel, enabling runtime verification via debug_assert! macros in generated Rust.

```rust
use super::logic::LogicExpr;
use crate::intern::Symbol;

/// Type expression for explicit type annotations.
///
/// Represents type syntax like:
/// - `Int` → Primitive(Int)
/// - `User` → Named(User)
/// - `List of Int` → Generic { base: List, params: [Primitive(Int)] }
/// - `List of List of Int` → Generic { base: List, params: [Generic { base: List, params: [Primitive(Int)] }] }
/// - `Result of Int and Text` → Generic { base: Result, params: [Primitive(Int), Primitive(Text)] }
#[derive(Debug, Clone, PartialEq, Eq)]
pub enum TypeExpr<'a> {
    /// Primitive type: Int, Nat, Text, Bool
    Primitive(Symbol),
    /// Named type (user-defined): User, Point
    Named(Symbol),
    /// Generic type: List of Int, Option of Text, Result of Int and Text
    Generic {
        base: Symbol,
        params: &'a [TypeExpr<'a>],
    },
    /// Function type: fn(A, B) -> C (for higher-order functions)
    Function {
        inputs: &'a [TypeExpr<'a>],
        output: &'a TypeExpr<'a>,
    },
}

/// Binary operation kinds for imperative expressions.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum BinaryOpKind {
    Add,
    Subtract,
    Multiply,
    Divide,
    Eq,
    NotEq,
    Lt,
    Gt,
    LtEq,
    GtEq,
}

/// Block is a sequence of statements.
pub type Block<'a> = &'a [Stmt<'a>];

/// Phase 33: Match arm for Inspect statement
#[derive(Debug)]
pub struct MatchArm<'a> {
    pub enum_name: Option<Symbol>,          // The enum type (e.g., Shape)
    pub variant: Option<Symbol>,            // None = Otherwise (wildcard)
    pub bindings: Vec<(Symbol, Symbol)>,    // (field_name, binding_name)
    pub body: Block<'a>,
}

/// Imperative statement AST (LOGOS §15.0.0).
///
/// Stmt is the primary AST node for imperative code blocks like `## Main`
/// and function bodies. The Assert variant bridges to the Logic Kernel.
#[derive(Debug)]
pub enum Stmt<'a> {
    /// Variable binding: `Let x be 5.` or `Let x: Int be 5.`
    Let {
        var: Symbol,
        ty: Option<&'a TypeExpr<'a>>,
        value: &'a Expr<'a>,
        mutable: bool,
    },

    /// Mutation: `Set x to 10.`
    Set {
        target: Symbol,
        value: &'a Expr<'a>,
    },

    /// Function call as statement: `Call process with data.`
    Call {
        function: Symbol,
        args: Vec<&'a Expr<'a>>,
    },

    /// Conditional: `If condition: ... Otherwise: ...`
    If {
        cond: &'a Expr<'a>,
        then_block: Block<'a>,
        else_block: Option<Block<'a>>,
    },

    /// Loop: `While condition: ...`
    While {
        cond: &'a Expr<'a>,
        body: Block<'a>,
    },

    /// Iteration: `Repeat for x in list: ...` or `Repeat for i from 1 to 10: ...`
    Repeat {
        var: Symbol,
        iterable: &'a Expr<'a>,
        body: Block<'a>,
    },

    /// Return: `Return x.` or `Return.`
    Return {
        value: Option<&'a Expr<'a>>,
    },

    /// Bridge to Logic Kernel: `Assert that P.`
    Assert {
        proposition: &'a LogicExpr<'a>,
    },

    /// Phase 35: Documented assertion with justification
    /// `Trust that P because "reason".`
    /// Semantics: Documented runtime check that could be verified statically.
    Trust {
        proposition: &'a LogicExpr<'a>,
        justification: Symbol,
    },

    /// Ownership transfer (move): `Give x to processor.`
    /// Semantics: Move ownership of `object` to `recipient`.
    Give {
        object: &'a Expr<'a>,
        recipient: &'a Expr<'a>,
    },

    /// Immutable borrow: `Show x to console.`
    /// Semantics: Immutable borrow of `object` passed to `recipient`.
    Show {
        object: &'a Expr<'a>,
        recipient: &'a Expr<'a>,
    },

    /// Phase 31: Field mutation: `Set p's x to 10.`
    SetField {
        object: &'a Expr<'a>,
        field: Symbol,
        value: &'a Expr<'a>,
    },

    /// Phase 31: Struct definition for codegen
    StructDef {
        name: Symbol,
        fields: Vec<(Symbol, Symbol, bool)>, // (name, type_name, is_public)
    },

    /// Phase 32: Function definition
    FunctionDef {
        name: Symbol,
        params: Vec<(Symbol, Symbol)>, // (param_name, type_name)
        body: Block<'a>,
        return_type: Option<Symbol>,   // Inferred if None
    },

    /// Phase 33: Pattern matching on sum types
    Inspect {
        target: &'a Expr<'a>,
        arms: Vec<MatchArm<'a>>,
        has_otherwise: bool,            // For exhaustiveness tracking
    },
}

/// Shared expression type for pure computations (LOGOS §15.0.0).
///
/// Expr is used by both LogicExpr (as terms) and Stmt (as values).
/// These are pure computations without side effects.
#[derive(Debug)]
pub enum Expr<'a> {
    /// Literal value: 42, "hello", true, nothing
    Literal(Literal),

    /// Variable reference: x
    Identifier(Symbol),

    /// Binary operation: x plus y
    BinaryOp {
        op: BinaryOpKind,
        left: &'a Expr<'a>,
        right: &'a Expr<'a>,
    },

    /// Function call as expression: f(x, y)
    Call {
        function: Symbol,
        args: Vec<&'a Expr<'a>>,
    },

    /// Index access: item 1 of list (1-indexed)
    Index {
        collection: &'a Expr<'a>,
        index: usize,
    },

    /// Slice access: items 2 through 5 of list (1-indexed, inclusive)
    Slice {
        collection: &'a Expr<'a>,
        start: usize,
        end: usize,
    },

    /// List literal: [1, 2, 3]
    List(Vec<&'a Expr<'a>>),

    /// Range: 1 to 10 (inclusive)
    Range {
        start: &'a Expr<'a>,
        end: &'a Expr<'a>,
    },

    /// Phase 31: Field access: `p's x` or `the x of p`
    FieldAccess {
        object: &'a Expr<'a>,
        field: Symbol,
    },

    /// Phase 31: Constructor: `a new Point`
    /// Phase 34: Extended for generics: `a new Box of Int`
    New {
        type_name: Symbol,
        type_args: Vec<Symbol>,  // Empty for non-generic types
    },

    /// Phase 33: Enum variant constructor: `a new Circle with radius 10`
    NewVariant {
        enum_name: Symbol,                      // Shape (resolved from registry)
        variant: Symbol,                        // Circle
        fields: Vec<(Symbol, &'a Expr<'a>)>,    // [(radius, 10)]
    },
}

/// Literal values in LOGOS.
#[derive(Debug, Clone, PartialEq)]
pub enum Literal {
    /// Integer literal
    Number(i64),
    /// Text literal
    Text(Symbol),
    /// Boolean literal
    Boolean(bool),
    /// The nothing literal (unit type)
    Nothing,
}

```

---

### Parser Core

**File:** `src/parser/mod.rs`

Core Parser struct with token stream, cursor, and context management. **Topicalization:** Detects 'NP + Comma' pattern at sentence start (lines 401-473), stores fronted NP, injects as object with adjective preservation via wrap_with_definiteness_full(). Handles pronoun subjects ('The book, he read.') and full NP subjects ('The apple, John ate.'). **Filler-Gap:** filler_gap: Option<Symbol> field tracks wh-fillers across clause boundaries for long-distance dependencies in relative clauses and wh-questions. **Garden Path Optimization:** Skips reanalysis when auxiliary is present (pending_time.is_some()) since auxiliaries disambiguate structure. ParserGuard RAII struct with guard()/commit() pattern and Deref for transparent parser access with automatic rollback. Entry point for recursive descent parsing. **VP Ellipsis Support:** EventTemplate struct stores verb + non-agent thematic roles + modifiers. capture_event_template() extracts template at NeoEvent creation. last_event_template field persists template for cross-sentence reconstruction. **Phase 12 Parse Forest:** noun_priority_mode: bool field enables lexical ambiguity forking. set_noun_priority_mode() toggles noun-first interpretation for Ambiguous tokens. check_pronoun() respects noun_priority_mode for possessive pronoun handling ('her' as determiner vs object). **Copula Adjective Preference:** After copula (is/was/are/were), simple-aspect Verbs with Adjective alternative prefer Adjective reading via prefer_adjective check (lines 870-884). E.g., 'The door is open' → Adjective(open) rather than Verb. **NPI Handling (Phase 15):** check_npi_quantifier() detects anything/anyone/nobody/nothing; check_npi_object() handles NPI objects in negative contexts; check_temporal_npi() handles ever/never; parse_npi_quantified() produces appropriate quantifier structure based on licensing.

```rust
mod clause;
mod common;
mod modal;
mod noun;
mod pragmatics;
mod quantifier;
mod question;
mod verb;

#[cfg(test)]
mod tests;

pub use clause::ClauseParsing;
pub use modal::ModalParsing;
pub use noun::NounParsing;
pub use pragmatics::PragmaticsParsing;
pub use quantifier::QuantifierParsing;
pub use question::QuestionParsing;
pub use verb::{LogicVerbParsing, ImperativeVerbParsing};

use crate::analysis::TypeRegistry;
use crate::arena_ctx::AstContext;
use crate::ast::{AspectOperator, LogicExpr, NeoEventData, QuantifierKind, TemporalOperator, Term, ThematicRole, Stmt, Expr, Literal, TypeExpr, BinaryOpKind, MatchArm};
use crate::context::{Case, DiscourseContext, Entity, Gender, Number};
use crate::error::{ParseError, ParseErrorKind};
use crate::intern::{Interner, Symbol, SymbolEq};
use crate::lexer::Lexer;
use crate::lexicon::{self, Aspect, Definiteness, Time, VerbClass};
use crate::token::{BlockType, FocusKind, Token, TokenType};

pub(super) type ParseResult<T> = Result<T, ParseError>;

use std::ops::{Deref, DerefMut};

/// Determines how the parser interprets sentences.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
pub enum ParserMode {
    /// Logicaffeine mode: propositions, NeoEvents, ambiguity allowed.
    #[default]
    Declarative,
    /// LOGOS mode: statements, strict scoping, deterministic.
    Imperative,
}

#[derive(Clone)]
struct ParserCheckpoint {
    pos: usize,
    var_counter: usize,
    bindings_len: usize,
    island: u32,
    time: Option<Time>,
    negative_depth: u32,
}

pub struct ParserGuard<'p, 'a, 'ctx, 'int> {
    parser: &'p mut Parser<'a, 'ctx, 'int>,
    checkpoint: ParserCheckpoint,
    committed: bool,
}

impl<'p, 'a, 'ctx, 'int> ParserGuard<'p, 'a, 'ctx, 'int> {
    pub fn commit(mut self) {
        self.committed = true;
    }
}

impl<'p, 'a, 'ctx, 'int> Drop for ParserGuard<'p, 'a, 'ctx, 'int> {
    fn drop(&mut self) {
        if !self.committed {
            self.parser.restore(self.checkpoint.clone());
        }
    }
}

impl<'p, 'a, 'ctx, 'int> Deref for ParserGuard<'p, 'a, 'ctx, 'int> {
    type Target = Parser<'a, 'ctx, 'int>;
    fn deref(&self) -> &Self::Target {
        self.parser
    }
}

impl<'p, 'a, 'ctx, 'int> DerefMut for ParserGuard<'p, 'a, 'ctx, 'int> {
    fn deref_mut(&mut self) -> &mut Self::Target {
        self.parser
    }
}

#[derive(Clone, Debug)]
pub struct EventTemplate<'a> {
    pub verb: Symbol,
    pub non_agent_roles: Vec<(ThematicRole, Term<'a>)>,
    pub modifiers: Vec<Symbol>,
}

pub struct Parser<'a, 'ctx, 'int> {
    pub(super) tokens: Vec<Token>,
    pub(super) current: usize,
    pub(super) var_counter: usize,
    pub(super) pending_time: Option<Time>,
    pub(super) context: Option<&'ctx mut DiscourseContext>,
    pub(super) donkey_bindings: Vec<(Symbol, Symbol, bool)>,
    pub(super) interner: &'int mut Interner,
    pub(super) ctx: AstContext<'a>,
    pub(super) current_island: u32,
    pub(super) pp_attach_to_noun: bool,
    pub(super) filler_gap: Option<Symbol>,
    pub(super) negative_depth: u32,
    pub(super) discourse_event_var: Option<Symbol>,
    pub(super) last_event_template: Option<EventTemplate<'a>>,
    pub(super) noun_priority_mode: bool,
    pub(super) collective_mode: bool,
    pub(super) pending_cardinal: Option<u32>,
    pub(super) mode: ParserMode,
    pub(super) type_registry: Option<TypeRegistry>,
}

impl<'a, 'ctx, 'int> Parser<'a, 'ctx, 'int> {
    pub fn new(
        tokens: Vec<Token>,
        interner: &'int mut Interner,
        ctx: AstContext<'a>,
    ) -> Self {
        Parser {
            tokens,
            current: 0,
            var_counter: 0,
            pending_time: None,
            context: None,
            donkey_bindings: Vec::new(),
            interner,
            ctx,
            current_island: 0,
            pp_attach_to_noun: false,
            filler_gap: None,
            negative_depth: 0,
            discourse_event_var: None,
            last_event_template: None,
            noun_priority_mode: false,
            collective_mode: false,
            pending_cardinal: None,
            mode: ParserMode::Declarative,
            type_registry: None,
        }
    }

    pub fn set_noun_priority_mode(&mut self, mode: bool) {
        self.noun_priority_mode = mode;
    }

    pub fn set_collective_mode(&mut self, mode: bool) {
        self.collective_mode = mode;
    }

    pub fn with_context(
        tokens: Vec<Token>,
        context: &'ctx mut DiscourseContext,
        interner: &'int mut Interner,
        ctx: AstContext<'a>,
    ) -> Self {
        Parser {
            tokens,
            current: 0,
            var_counter: 0,
            pending_time: None,
            context: Some(context),
            donkey_bindings: Vec::new(),
            interner,
            ctx,
            current_island: 0,
            pp_attach_to_noun: false,
            filler_gap: None,
            negative_depth: 0,
            discourse_event_var: None,
            last_event_template: None,
            noun_priority_mode: false,
            collective_mode: false,
            pending_cardinal: None,
            mode: ParserMode::Declarative,
            type_registry: None,
        }
    }

    /// Create a parser with type registry for two-pass compilation.
    /// The type registry enables disambiguation of "Stack of Integers" (generic)
    /// vs "Owner of House" (possessive).
    pub fn with_types(
        tokens: Vec<Token>,
        context: &'ctx mut DiscourseContext,
        interner: &'int mut Interner,
        ctx: AstContext<'a>,
        types: TypeRegistry,
    ) -> Self {
        Parser {
            tokens,
            current: 0,
            var_counter: 0,
            pending_time: None,
            context: Some(context),
            donkey_bindings: Vec::new(),
            interner,
            ctx,
            current_island: 0,
            pp_attach_to_noun: false,
            filler_gap: None,
            negative_depth: 0,
            discourse_event_var: None,
            last_event_template: None,
            noun_priority_mode: false,
            collective_mode: false,
            pending_cardinal: None,
            mode: ParserMode::Declarative,
            type_registry: Some(types),
        }
    }

    pub fn set_discourse_event_var(&mut self, var: Symbol) {
        self.discourse_event_var = Some(var);
    }

    pub fn mode(&self) -> ParserMode {
        self.mode
    }

    /// Check if a symbol is a known type in the registry.
    /// Used to disambiguate "Stack of Integers" (generic type) vs "Owner of House" (possessive).
    pub fn is_known_type(&self, sym: Symbol) -> bool {
        self.type_registry
            .as_ref()
            .map(|r| r.is_type(sym))
            .unwrap_or(false)
    }

    /// Check if a symbol is a known generic type (takes type parameters).
    /// Used to parse "Stack of Integers" as generic instantiation.
    pub fn is_generic_type(&self, sym: Symbol) -> bool {
        self.type_registry
            .as_ref()
            .map(|r| r.is_generic(sym))
            .unwrap_or(false)
    }

    /// Get the parameter count for a generic type.
    fn get_generic_param_count(&self, sym: Symbol) -> Option<usize> {
        use crate::analysis::TypeDef;
        self.type_registry.as_ref().and_then(|r| {
            match r.get(sym) {
                Some(TypeDef::Generic { param_count }) => Some(*param_count),
                _ => None,
            }
        })
    }

    /// Phase 33: Check if a symbol is a known enum variant and return the enum name.
    fn find_variant(&self, sym: Symbol) -> Option<Symbol> {
        self.type_registry
            .as_ref()
            .and_then(|r| r.find_variant(sym).map(|(enum_name, _)| enum_name))
    }

    /// Consume a type name token (doesn't check entity registration).
    fn consume_type_name(&mut self) -> ParseResult<Symbol> {
        let t = self.advance().clone();
        match t.kind {
            TokenType::Noun(s) | TokenType::Adjective(s) => Ok(s),
            TokenType::ProperName(s) => Ok(s),
            other => Err(ParseError {
                kind: ParseErrorKind::ExpectedContentWord { found: other },
                span: self.current_span(),
            }),
        }
    }

    /// Parse a type expression: Int, Text, List of Int, Result of Int and Text.
    /// Uses TypeRegistry to distinguish primitives from generics.
    fn parse_type_expression(&mut self) -> ParseResult<TypeExpr<'a>> {
        use noun::NounParsing;

        // Get the base type name (must be a noun or proper name - type names bypass entity check)
        let base = self.consume_type_name()?;

        // Check if it's a known generic type
        if let Some(param_count) = self.get_generic_param_count(base) {
            // Check for "of" or "from" separator
            if self.check_of_preposition() || self.check_preposition_is("from") {
                self.advance(); // consume "of" or "from"

                let mut params = Vec::new();
                for i in 0..param_count {
                    if i > 0 {
                        // Expect separator for params > 1: "and", "to", or ","
                        if self.check(&TokenType::And) || self.check_to_preposition() || self.check(&TokenType::Comma) {
                            self.advance();
                        }
                    }
                    let param = self.parse_type_expression()?;
                    params.push(param);
                }

                let params_slice = self.ctx.alloc_type_exprs(params);
                return Ok(TypeExpr::Generic { base, params: params_slice });
            }
        }

        // Check if it's a known primitive type
        if self.type_registry.as_ref().map(|r| r.is_type(base)).unwrap_or(false) {
            return Ok(TypeExpr::Primitive(base));
        }

        // User-defined or unknown type
        Ok(TypeExpr::Named(base))
    }

    pub fn process_block_headers(&mut self) {
        use crate::token::BlockType;

        while self.current < self.tokens.len() {
            if let TokenType::BlockHeader { block_type } = &self.tokens[self.current].kind {
                self.mode = match block_type {
                    BlockType::Main | BlockType::Function => ParserMode::Imperative,
                    BlockType::Theorem | BlockType::Definition | BlockType::Proof |
                    BlockType::Example | BlockType::Logic | BlockType::Note => ParserMode::Declarative,
                };
                self.current += 1;
            } else {
                break;
            }
        }
    }

    pub fn get_event_var(&mut self) -> Symbol {
        self.discourse_event_var.unwrap_or_else(|| self.interner.intern("e"))
    }

    pub fn capture_event_template(&mut self, verb: Symbol, roles: &[(ThematicRole, Term<'a>)], modifiers: &[Symbol]) {
        let non_agent_roles: Vec<_> = roles.iter()
            .filter(|(role, _)| *role != ThematicRole::Agent)
            .cloned()
            .collect();
        self.last_event_template = Some(EventTemplate {
            verb,
            non_agent_roles,
            modifiers: modifiers.to_vec(),
        });
    }

    fn parse_embedded_wh_clause(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        // Parse embedded question body: "who runs", "what John ate"
        let var_name = self.interner.intern("x");
        let var_term = Term::Variable(var_name);

        if self.check_verb() {
            // "who runs" pattern
            let verb = self.consume_verb();
            let body = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice([var_term]),
            });
            return Ok(body);
        }

        if self.check_content_word() || self.check_article() {
            // "what John ate" pattern
            let subject = self.parse_noun_phrase(true)?;
            if self.check_verb() {
                let verb = self.consume_verb();
                let body = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb,
                    args: self.ctx.terms.alloc_slice([
                        Term::Constant(subject.noun),
                        var_term,
                    ]),
                });
                return Ok(body);
            }
        }

        // Fallback: just the wh-variable
        Ok(self.ctx.exprs.alloc(LogicExpr::Atom(var_name)))
    }

    pub fn set_pp_attachment_mode(&mut self, attach_to_noun: bool) {
        self.pp_attach_to_noun = attach_to_noun;
    }

    fn checkpoint(&self) -> ParserCheckpoint {
        ParserCheckpoint {
            pos: self.current,
            var_counter: self.var_counter,
            bindings_len: self.donkey_bindings.len(),
            island: self.current_island,
            time: self.pending_time,
            negative_depth: self.negative_depth,
        }
    }

    fn restore(&mut self, cp: ParserCheckpoint) {
        self.current = cp.pos;
        self.var_counter = cp.var_counter;
        self.donkey_bindings.truncate(cp.bindings_len);
        self.current_island = cp.island;
        self.pending_time = cp.time;
        self.negative_depth = cp.negative_depth;
    }

    fn is_negative_context(&self) -> bool {
        self.negative_depth % 2 == 1
    }

    pub fn guard(&mut self) -> ParserGuard<'_, 'a, 'ctx, 'int> {
        ParserGuard {
            checkpoint: self.checkpoint(),
            parser: self,
            committed: false,
        }
    }

    pub(super) fn try_parse<F, T>(&mut self, op: F) -> Option<T>
    where
        F: FnOnce(&mut Self) -> ParseResult<T>,
    {
        let cp = self.checkpoint();
        match op(self) {
            Ok(res) => Some(res),
            Err(_) => {
                self.restore(cp);
                None
            }
        }
    }

    fn register_entity(&mut self, symbol: &str, noun_class: &str, gender: Gender, number: Number) {
        use crate::context::OwnershipState;
        if let Some(ref mut ctx) = self.context {
            ctx.register(Entity {
                symbol: symbol.to_string(),
                gender,
                number,
                noun_class: noun_class.to_string(),
                ownership: OwnershipState::Owned,
            });
        }
    }

    fn resolve_pronoun(&mut self, gender: Gender, number: Number) -> Option<Symbol> {
        self.context
            .as_ref()
            .and_then(|ctx| ctx.resolve_pronoun(gender, number))
            .map(|e| e.symbol.clone())
            .map(|s| self.interner.intern(&s))
    }

    fn resolve_donkey_pronoun(&mut self, gender: Gender) -> Option<Symbol> {
        for (noun_class, var_name, used) in self.donkey_bindings.iter_mut().rev() {
            let noun_str = self.interner.resolve(*noun_class);
            let noun_gender = Self::infer_noun_gender(noun_str);
            if noun_gender == gender || gender == Gender::Neuter || noun_gender == Gender::Unknown {
                *used = true; // Mark as used by a pronoun (donkey anaphor)
                return Some(*var_name);
            }
        }
        None
    }

    fn infer_noun_gender(noun: &str) -> Gender {
        let lower = noun.to_lowercase();
        if lexicon::is_female_noun(&lower) {
            Gender::Female
        } else if lexicon::is_male_noun(&lower) {
            Gender::Male
        } else {
            Gender::Unknown
        }
    }

    fn is_plural_noun(noun: &str) -> bool {
        let lower = noun.to_lowercase();
        if lexicon::is_irregular_plural(&lower) {
            return true;
        }
        lower.ends_with('s') && !lower.ends_with("ss") && lower.len() > 2
    }

    fn singularize_noun(noun: &str) -> String {
        let lower = noun.to_lowercase();
        if let Some(singular) = lexicon::singularize(&lower) {
            return singular.to_string();
        }
        if lower.ends_with('s') && !lower.ends_with("ss") && lower.len() > 2 {
            let base = &lower[..lower.len() - 1];
            let mut chars: Vec<char> = base.chars().collect();
            if !chars.is_empty() {
                chars[0] = chars[0].to_uppercase().next().unwrap();
            }
            return chars.into_iter().collect();
        }
        let mut chars: Vec<char> = lower.chars().collect();
        if !chars.is_empty() {
            chars[0] = chars[0].to_uppercase().next().unwrap();
        }
        chars.into_iter().collect()
    }

    fn infer_gender(name: &str) -> Gender {
        let lower = name.to_lowercase();
        if lexicon::is_male_name(&lower) {
            Gender::Male
        } else if lexicon::is_female_name(&lower) {
            Gender::Female
        } else {
            Gender::Unknown
        }
    }


    fn next_var_name(&mut self) -> Symbol {
        const VARS: &[&str] = &["x", "y", "z", "w", "v", "u"];
        let idx = self.var_counter;
        self.var_counter += 1;
        if idx < VARS.len() {
            self.interner.intern(VARS[idx])
        } else {
            let name = format!("x{}", idx - VARS.len() + 1);
            self.interner.intern(&name)
        }
    }

    pub fn parse(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let first = self.parse_sentence()?;

        // Only continue to second sentence if there was a period separator
        // AND there are more tokens after the period
        if self.check(&TokenType::Period) {
            self.advance();

            if !self.is_at_end() {
                let second = self.parse_sentence()?;
                return Ok(self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: first,
                    op: TokenType::And,
                    right: second,
                }));
            }
        }

        Ok(first)
    }

    pub fn parse_program(&mut self) -> ParseResult<Vec<Stmt<'a>>> {
        let mut statements = Vec::new();
        let mut in_definition_block = false;

        // Check if we started in a Definition block (from process_block_headers)
        if self.mode == ParserMode::Declarative {
            // Check if the previous token was a Definition header
            // For now, assume Definition blocks should be skipped
            // We'll detect them by checking the content pattern
        }

        while !self.is_at_end() {
            // Handle block headers
            if let Some(Token { kind: TokenType::BlockHeader { block_type }, .. }) = self.tokens.get(self.current) {
                match block_type {
                    BlockType::Definition => {
                        in_definition_block = true;
                        self.mode = ParserMode::Declarative;
                        self.advance();
                        continue;
                    }
                    BlockType::Main => {
                        in_definition_block = false;
                        self.mode = ParserMode::Imperative;
                        self.advance();
                        continue;
                    }
                    BlockType::Function => {
                        in_definition_block = false;
                        self.mode = ParserMode::Imperative;
                        self.advance();
                        // Parse function definition
                        let func_def = self.parse_function_def()?;
                        statements.push(func_def);
                        continue;
                    }
                    _ => {
                        in_definition_block = false;
                        self.mode = ParserMode::Declarative;
                        self.advance();
                        continue;
                    }
                }
            }

            // Skip Definition block content - handled by DiscoveryPass
            if in_definition_block {
                self.advance();
                continue;
            }

            // Skip indent/dedent/newline tokens at program level
            if self.check(&TokenType::Indent) || self.check(&TokenType::Dedent) || self.check(&TokenType::Newline) {
                self.advance();
                continue;
            }

            // In imperative mode, parse statements
            if self.mode == ParserMode::Imperative {
                let stmt = self.parse_statement()?;
                statements.push(stmt);

                if self.check(&TokenType::Period) {
                    self.advance();
                }
            } else {
                // In declarative mode (Theorem, etc.), skip for now
                self.advance();
            }
        }

        Ok(statements)
    }

    fn parse_statement(&mut self) -> ParseResult<Stmt<'a>> {
        if self.check(&TokenType::Let) {
            return self.parse_let_statement();
        }
        if self.check(&TokenType::Set) {
            return self.parse_set_statement();
        }
        if self.check(&TokenType::Return) {
            return self.parse_return_statement();
        }
        if self.check(&TokenType::If) {
            return self.parse_if_statement();
        }
        if self.check(&TokenType::Assert) {
            return self.parse_assert_statement();
        }
        // Phase 35: Trust statement
        if self.check(&TokenType::Trust) {
            return self.parse_trust_statement();
        }
        if self.check(&TokenType::While) {
            return self.parse_while_statement();
        }
        if self.check(&TokenType::Repeat) {
            return self.parse_repeat_statement();
        }
        if self.check(&TokenType::Call) {
            return self.parse_call_statement();
        }
        if self.check(&TokenType::Give) {
            return self.parse_give_statement();
        }
        if self.check(&TokenType::Show) {
            return self.parse_show_statement();
        }
        // Phase 33: Pattern matching on sum types
        if self.check(&TokenType::Inspect) {
            return self.parse_inspect_statement();
        }

        Err(ParseError {
            kind: ParseErrorKind::ExpectedStatement,
            span: self.current_span(),
        })
    }

    fn parse_if_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "If"

        // Parse condition expression (simple: identifier equals value)
        let cond = self.parse_condition()?;

        // Expect colon
        if !self.check(&TokenType::Colon) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume ":"

        // Expect indent
        if !self.check(&TokenType::Indent) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedStatement,
                span: self.current_span(),
            });
        }
        self.advance(); // consume Indent

        // Parse then block
        let mut then_stmts = Vec::new();
        while !self.check(&TokenType::Dedent) && !self.is_at_end() {
            let stmt = self.parse_statement()?;
            then_stmts.push(stmt);
            if self.check(&TokenType::Period) {
                self.advance();
            }
        }

        // Consume dedent
        if self.check(&TokenType::Dedent) {
            self.advance();
        }

        // Allocate then_block in arena
        let then_block = self.ctx.stmts.expect("imperative arenas not initialized")
            .alloc_slice(then_stmts.into_iter());

        // Check for Otherwise: block
        let else_block = if self.check(&TokenType::Otherwise) {
            self.advance(); // consume "Otherwise"

            if !self.check(&TokenType::Colon) {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance(); // consume ":"

            if !self.check(&TokenType::Indent) {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedStatement,
                    span: self.current_span(),
                });
            }
            self.advance(); // consume Indent

            let mut else_stmts = Vec::new();
            while !self.check(&TokenType::Dedent) && !self.is_at_end() {
                let stmt = self.parse_statement()?;
                else_stmts.push(stmt);
                if self.check(&TokenType::Period) {
                    self.advance();
                }
            }

            if self.check(&TokenType::Dedent) {
                self.advance();
            }

            Some(self.ctx.stmts.expect("imperative arenas not initialized")
                .alloc_slice(else_stmts.into_iter()))
        } else {
            None
        };

        Ok(Stmt::If {
            cond,
            then_block,
            else_block,
        })
    }

    fn parse_while_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "While"

        let cond = self.parse_condition()?;

        if !self.check(&TokenType::Colon) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume ":"

        if !self.check(&TokenType::Indent) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedStatement,
                span: self.current_span(),
            });
        }
        self.advance(); // consume Indent

        let mut body_stmts = Vec::new();
        while !self.check(&TokenType::Dedent) && !self.is_at_end() {
            let stmt = self.parse_statement()?;
            body_stmts.push(stmt);
            if self.check(&TokenType::Period) {
                self.advance();
            }
        }

        if self.check(&TokenType::Dedent) {
            self.advance();
        }

        let body = self.ctx.stmts.expect("imperative arenas not initialized")
            .alloc_slice(body_stmts.into_iter());

        Ok(Stmt::While { cond, body })
    }

    fn parse_repeat_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Repeat"

        // Optional "for"
        if self.check(&TokenType::For) {
            self.advance();
        }

        // Parse loop variable (using context-aware identifier parsing)
        let var = self.expect_identifier()?;

        // Determine iteration type: "in" for collection, "from" for range
        let iterable = if self.check(&TokenType::From) || self.check_preposition_is("from") {
            self.advance(); // consume "from"
            let start = self.parse_imperative_expr()?;

            // Expect "to" (can be keyword or preposition)
            if !self.check(&TokenType::To) && !self.check_preposition_is("to") {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: "to".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance();

            let end = self.parse_imperative_expr()?;
            self.ctx.alloc_imperative_expr(Expr::Range { start, end })
        } else if self.check(&TokenType::In) || self.check_preposition_is("in") {
            self.advance(); // consume "in"
            self.parse_imperative_expr()?
        } else {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "in or from".to_string() },
                span: self.current_span(),
            });
        };

        // Expect colon
        if !self.check(&TokenType::Colon) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                span: self.current_span(),
            });
        }
        self.advance();

        // Expect indent
        if !self.check(&TokenType::Indent) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedStatement,
                span: self.current_span(),
            });
        }
        self.advance();

        // Parse body statements
        let mut body_stmts = Vec::new();
        while !self.check(&TokenType::Dedent) && !self.is_at_end() {
            let stmt = self.parse_statement()?;
            body_stmts.push(stmt);
            if self.check(&TokenType::Period) {
                self.advance();
            }
        }

        if self.check(&TokenType::Dedent) {
            self.advance();
        }

        let body = self.ctx.stmts.expect("imperative arenas not initialized")
            .alloc_slice(body_stmts.into_iter());

        Ok(Stmt::Repeat { var, iterable, body })
    }

    fn parse_call_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Call"

        // Parse function name (identifier)
        let function = match &self.peek().kind {
            TokenType::Noun(sym) | TokenType::Adjective(sym) => {
                let s = *sym;
                self.advance();
                s
            }
            _ => {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedIdentifier,
                    span: self.current_span(),
                });
            }
        };

        // Expect "with" followed by arguments
        let args = if self.check_preposition_is("with") {
            self.advance(); // consume "with"
            self.parse_call_arguments()?
        } else {
            Vec::new()
        };

        Ok(Stmt::Call { function, args })
    }

    fn parse_call_arguments(&mut self) -> ParseResult<Vec<&'a Expr<'a>>> {
        let mut args = Vec::new();

        // Parse first argument
        let arg = self.parse_imperative_expr()?;
        args.push(arg);

        // Parse additional comma-separated arguments
        while self.check(&TokenType::Comma) {
            self.advance(); // consume ","
            let arg = self.parse_imperative_expr()?;
            args.push(arg);
        }

        Ok(args)
    }

    fn parse_condition(&mut self) -> ParseResult<&'a Expr<'a>> {
        use crate::ast::stmt::BinaryOpKind as ImperativeBinOp;

        // Parse left side (identifier)
        let left = self.parse_imperative_expr()?;

        // Check for "equals"
        if self.check(&TokenType::Equals) {
            self.advance();
            let right = self.parse_imperative_expr()?;
            Ok(self.ctx.alloc_imperative_expr(Expr::BinaryOp {
                op: ImperativeBinOp::Eq,
                left,
                right,
            }))
        } else {
            // Just return the expression as the condition
            Ok(left)
        }
    }

    fn parse_let_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Let"

        // Check for "mutable" keyword
        let mutable = if self.check_mutable_keyword() {
            self.advance();
            true
        } else {
            false
        };

        // Get identifier
        let var = self.expect_identifier()?;

        // Check for optional type annotation: `: Type`
        let ty = if self.check(&TokenType::Colon) {
            self.advance(); // consume ":"
            let type_expr = self.parse_type_expression()?;
            Some(self.ctx.alloc_type_expr(type_expr))
        } else {
            None
        };

        // Expect "be"
        if !self.check(&TokenType::Be) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "be".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "be"

        // Parse expression value (simple: just a number for now)
        let value = self.parse_imperative_expr()?;

        // Bind in ScopeStack if context available
        if let Some(ctx) = self.context.as_mut() {
            use crate::context::{Entity, Gender, Number, OwnershipState};
            let var_name = self.interner.resolve(var).to_string();
            ctx.register(Entity {
                symbol: var_name.clone(),
                gender: Gender::Neuter,
                number: Number::Singular,
                noun_class: var_name,
                ownership: OwnershipState::Owned,
            });
        }

        Ok(Stmt::Let { var, ty, value, mutable })
    }

    fn check_mutable_keyword(&self) -> bool {
        if let TokenType::Noun(sym) | TokenType::Adjective(sym) = self.peek().kind {
            self.interner.resolve(sym).eq_ignore_ascii_case("mutable")
        } else {
            false
        }
    }

    fn parse_set_statement(&mut self) -> ParseResult<Stmt<'a>> {
        use crate::ast::Expr;
        self.advance(); // consume "Set"

        // Parse target - can be identifier or field access expression
        let target_expr = self.parse_imperative_expr()?;

        // Expect "to" - can be TokenType::To or Preposition("to")
        let is_to = self.check(&TokenType::To) || matches!(
            &self.peek().kind,
            TokenType::Preposition(sym) if self.interner.resolve(*sym) == "to"
        );
        if !is_to {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "to".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "to"

        // Parse expression value
        let value = self.parse_imperative_expr()?;

        // Phase 31: Handle field access targets
        match target_expr {
            Expr::FieldAccess { object, field } => {
                Ok(Stmt::SetField { object, field: *field, value })
            }
            Expr::Identifier(target) => {
                Ok(Stmt::Set { target: *target, value })
            }
            _ => Err(ParseError {
                kind: ParseErrorKind::ExpectedIdentifier,
                span: self.current_span(),
            })
        }
    }

    fn parse_return_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Return"

        // Check if there's a value or just "Return."
        if self.check(&TokenType::Period) || self.is_at_end() {
            return Ok(Stmt::Return { value: None });
        }

        let value = self.parse_imperative_expr()?;
        Ok(Stmt::Return { value: Some(value) })
    }

    fn parse_assert_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Assert"

        // Optionally consume "that"
        if self.check(&TokenType::That) {
            self.advance();
        }

        // Save current mode and switch to declarative for proposition parsing
        let saved_mode = self.mode;
        self.mode = ParserMode::Declarative;

        // Parse the proposition using the Logic Kernel
        let proposition = self.parse()?;

        // Restore mode
        self.mode = saved_mode;

        Ok(Stmt::Assert { proposition })
    }

    /// Phase 35: Parse Trust statement
    /// Syntax: Trust [that] [proposition] because [justification].
    fn parse_trust_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Trust"

        // Optionally consume "that"
        if self.check(&TokenType::That) {
            self.advance();
        }

        // Save current mode and switch to declarative for proposition parsing
        let saved_mode = self.mode;
        self.mode = ParserMode::Declarative;

        // Parse the proposition using the Logic Kernel
        let proposition = self.parse()?;

        // Restore mode
        self.mode = saved_mode;

        // Expect "because"
        if !self.check(&TokenType::Because) {
            return Err(ParseError {
                kind: ParseErrorKind::UnexpectedToken {
                    expected: TokenType::Because,
                    found: self.peek().kind.clone(),
                },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "because"

        // Parse justification (string literal)
        let justification = match &self.peek().kind {
            TokenType::StringLiteral(sym) => {
                let s = *sym;
                self.advance();
                s
            }
            _ => {
                return Err(ParseError {
                    kind: ParseErrorKind::UnexpectedToken {
                        expected: TokenType::StringLiteral(self.interner.intern("")),
                        found: self.peek().kind.clone(),
                    },
                    span: self.current_span(),
                });
            }
        };

        Ok(Stmt::Trust { proposition, justification })
    }

    fn parse_give_statement(&mut self) -> ParseResult<Stmt<'a>> {
        use crate::context::OwnershipState;

        self.advance(); // consume "Give"

        // Parse the object being given: "x" or "the data"
        let object = self.parse_imperative_expr()?;

        // Expect "to" preposition
        if !self.check_preposition_is("to") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "to".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "to"

        // Parse the recipient: "processor" or "the console"
        let recipient = self.parse_imperative_expr()?;

        // CRITICAL: Mark the object as Moved in the ownership tracker
        if let Expr::Identifier(sym) = *object {
            if let Some(ctx) = self.context.as_mut() {
                let name = self.interner.resolve(sym);
                ctx.set_ownership(name, OwnershipState::Moved);
            }
        }

        Ok(Stmt::Give { object, recipient })
    }

    fn parse_show_statement(&mut self) -> ParseResult<Stmt<'a>> {
        use crate::context::OwnershipState;

        self.advance(); // consume "Show"

        // Parse the object being shown: "x" or "the data"
        let object = self.parse_imperative_expr()?;

        // Optional "to" preposition - if not present, default to "show" function
        let recipient = if self.check_preposition_is("to") {
            self.advance(); // consume "to"
            // Parse the recipient: "console" or "the user"
            self.parse_imperative_expr()?
        } else {
            // Default recipient: the runtime "show" function
            let show_sym = self.interner.intern("show");
            self.ctx.alloc_imperative_expr(Expr::Identifier(show_sym))
        };

        // Mark the object as Borrowed (NOT Moved - still accessible)
        if let Expr::Identifier(sym) = *object {
            if let Some(ctx) = self.context.as_mut() {
                let name = self.interner.resolve(sym);
                ctx.set_ownership(name, OwnershipState::Borrowed);
            }
        }

        Ok(Stmt::Show { object, recipient })
    }

    /// Phase 33: Parse Inspect statement for pattern matching
    /// Syntax: Inspect target:
    ///             If it is a Variant [(bindings)]:
    ///                 body...
    ///             Otherwise:
    ///                 body...
    fn parse_inspect_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Inspect"

        // Parse target expression
        let target = self.parse_imperative_expr()?;

        // Expect colon
        if !self.check(&TokenType::Colon) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume ":"

        // Expect indent
        if !self.check(&TokenType::Indent) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedStatement,
                span: self.current_span(),
            });
        }
        self.advance(); // consume Indent

        let mut arms = Vec::new();
        let mut has_otherwise = false;

        // Parse match arms until dedent
        while !self.check(&TokenType::Dedent) && !self.is_at_end() {
            if self.check(&TokenType::Otherwise) {
                // Parse "Otherwise:" default arm
                self.advance(); // consume "Otherwise"

                if !self.check(&TokenType::Colon) {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                        span: self.current_span(),
                    });
                }
                self.advance(); // consume ":"

                if !self.check(&TokenType::Indent) {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedStatement,
                        span: self.current_span(),
                    });
                }
                self.advance(); // consume Indent

                // Parse body statements
                let mut body_stmts = Vec::new();
                while !self.check(&TokenType::Dedent) && !self.is_at_end() {
                    let stmt = self.parse_statement()?;
                    body_stmts.push(stmt);
                    if self.check(&TokenType::Period) {
                        self.advance();
                    }
                }

                // Consume dedent
                if self.check(&TokenType::Dedent) {
                    self.advance();
                }

                let body = self.ctx.stmts.expect("imperative arenas not initialized")
                    .alloc_slice(body_stmts.into_iter());

                arms.push(MatchArm { enum_name: None, variant: None, bindings: vec![], body });
                has_otherwise = true;
                break;
            }

            if self.check(&TokenType::If) {
                // Parse "If it is a VariantName [(bindings)]:"
                let arm = self.parse_match_arm()?;
                arms.push(arm);
            } else {
                // Skip unexpected tokens
                self.advance();
            }
        }

        // Consume final dedent
        if self.check(&TokenType::Dedent) {
            self.advance();
        }

        Ok(Stmt::Inspect { target, arms, has_otherwise })
    }

    /// Parse a single match arm: "If it is a Variant [(field: binding)]:"
    fn parse_match_arm(&mut self) -> ParseResult<MatchArm<'a>> {
        self.advance(); // consume "If"

        // Expect "it"
        if !self.check_word("it") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "it".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "it"

        // Expect "is"
        if !self.check(&TokenType::Is) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "is".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "is"

        // Consume article "a" or "an"
        if self.check_article() {
            self.advance();
        }

        // Get variant name
        let variant = self.expect_identifier()?;

        // Look up the enum name for this variant
        let enum_name = self.find_variant(variant);

        // Optional: "(field)" or "(field: binding)" or "(f1, f2: b2)"
        let bindings = if self.check(&TokenType::LParen) {
            self.parse_pattern_bindings()?
        } else {
            vec![]
        };

        // Expect colon
        if !self.check(&TokenType::Colon) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume ":"

        // Expect indent
        if !self.check(&TokenType::Indent) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedStatement,
                span: self.current_span(),
            });
        }
        self.advance(); // consume Indent

        // Parse body statements
        let mut body_stmts = Vec::new();
        while !self.check(&TokenType::Dedent) && !self.is_at_end() {
            let stmt = self.parse_statement()?;
            body_stmts.push(stmt);
            if self.check(&TokenType::Period) {
                self.advance();
            }
        }

        // Consume dedent
        if self.check(&TokenType::Dedent) {
            self.advance();
        }

        let body = self.ctx.stmts.expect("imperative arenas not initialized")
            .alloc_slice(body_stmts.into_iter());

        Ok(MatchArm { enum_name, variant: Some(variant), bindings, body })
    }

    /// Parse pattern bindings: "(field)" or "(field: binding)" or "(f1, f2: b2)"
    fn parse_pattern_bindings(&mut self) -> ParseResult<Vec<(Symbol, Symbol)>> {
        self.advance(); // consume '('
        let mut bindings = Vec::new();

        loop {
            let field = self.expect_identifier()?;
            let binding = if self.check(&TokenType::Colon) {
                self.advance(); // consume ":"
                self.expect_identifier()?
            } else {
                field // field name = binding name
            };
            bindings.push((field, binding));

            if !self.check(&TokenType::Comma) {
                break;
            }
            self.advance(); // consume ','
        }

        if !self.check(&TokenType::RParen) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ")".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume ')'

        Ok(bindings)
    }

    /// Phase 33: Parse variant constructor fields: "with field1 value1 [and field2 value2]..."
    /// Example: "with radius 10" or "with width 10 and height 20"
    fn parse_variant_constructor_fields(&mut self) -> ParseResult<Vec<(Symbol, &'a Expr<'a>)>> {
        use crate::ast::Expr;
        let mut fields = Vec::new();

        // Consume "with"
        self.advance();

        loop {
            // Parse field name
            let field_name = self.expect_identifier()?;

            // Parse field value expression
            let value = self.parse_imperative_expr()?;

            fields.push((field_name, value));

            // Check for "and" to continue
            if self.check(&TokenType::And) {
                self.advance(); // consume "and"
                continue;
            }
            break;
        }

        Ok(fields)
    }

    /// Phase 34: Parse generic type arguments for constructor instantiation
    /// Parses "of Int" or "of Int and Text" after a generic type name
    /// Returns empty Vec for non-generic types
    fn parse_generic_type_args(&mut self, type_name: Symbol) -> ParseResult<Vec<Symbol>> {
        // Only parse type args if the type is a known generic
        if !self.is_generic_type(type_name) {
            return Ok(vec![]);
        }

        // Expect "of" preposition
        if !self.check_preposition_is("of") {
            return Ok(vec![]);  // Generic type without arguments - will use defaults
        }
        self.advance(); // consume "of"

        let mut type_args = Vec::new();
        loop {
            // Parse type argument (e.g., "Int", "Text", "User")
            let type_arg = self.expect_identifier()?;
            type_args.push(type_arg);

            // Check for "and" to continue (for multi-param generics like "Result of Int and Text")
            if self.check(&TokenType::And) {
                self.advance(); // consume "and"
                continue;
            }
            break;
        }

        Ok(type_args)
    }

    /// Phase 32: Parse function definition after `## To` header
    /// Syntax: add (a: Int) and (b: Int)
    ///             body statements...
    fn parse_function_def(&mut self) -> ParseResult<Stmt<'a>> {
        // Parse function name (first identifier after ## To)
        let name = self.expect_identifier()?;

        // Parse parameters: (name: Type) groups separated by "and"
        let mut params = Vec::new();
        while self.check(&TokenType::LParen) {
            self.advance(); // consume (

            let param_name = self.expect_identifier()?;

            // Expect colon
            if !self.check(&TokenType::Colon) {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance(); // consume :

            let param_type = self.expect_identifier()?;

            // Expect )
            if !self.check(&TokenType::RParen) {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: ")".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance(); // consume )

            params.push((param_name, param_type));

            // Check for "and" between parameters
            if self.check_word("and") {
                self.advance();
            }
        }

        // Expect colon after parameter list
        if !self.check(&TokenType::Colon) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume :

        // Expect indent for function body
        if !self.check(&TokenType::Indent) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedStatement,
                span: self.current_span(),
            });
        }
        self.advance(); // consume Indent

        // Parse body statements
        let mut body_stmts = Vec::new();
        while !self.check(&TokenType::Dedent) && !self.is_at_end() {
            // Skip newlines between statements
            if self.check(&TokenType::Newline) {
                self.advance();
                continue;
            }
            // Stop if we hit another block header
            if matches!(self.peek().kind, TokenType::BlockHeader { .. }) {
                break;
            }
            let stmt = self.parse_statement()?;
            body_stmts.push(stmt);
            if self.check(&TokenType::Period) {
                self.advance();
            }
        }

        // Consume dedent if present
        if self.check(&TokenType::Dedent) {
            self.advance();
        }

        // Allocate body in arena
        let body = self.ctx.stmts.expect("imperative arenas not initialized")
            .alloc_slice(body_stmts.into_iter());

        Ok(Stmt::FunctionDef {
            name,
            params,
            body,
            return_type: None, // Will be inferred later
        })
    }

    /// Parse a primary expression (literal, identifier, index, slice, list, etc.)
    fn parse_primary_expr(&mut self) -> ParseResult<&'a Expr<'a>> {
        use crate::ast::{Expr, Literal};

        let token = self.peek().clone();
        match &token.kind {
            // Phase 31: Constructor expression "new TypeName" or "a new TypeName"
            // Phase 33: Extended for variant constructors "new Circle with radius 10"
            // Phase 34: Extended for generic instantiation "new Box of Int"
            TokenType::New => {
                self.advance(); // consume "new"
                let type_name = self.expect_identifier()?;

                // Phase 33: Check if this is a variant constructor
                if let Some(enum_name) = self.find_variant(type_name) {
                    // Parse optional "with field value" pairs
                    let fields = if self.check_word("with") {
                        self.parse_variant_constructor_fields()?
                    } else {
                        vec![]
                    };
                    let base = self.ctx.alloc_imperative_expr(Expr::NewVariant {
                        enum_name,
                        variant: type_name,
                        fields,
                    });
                    return self.parse_field_access_chain(base);
                }

                // Phase 34: Parse generic type arguments "of Int" or "of Int and Text"
                let type_args = self.parse_generic_type_args(type_name)?;
                let base = self.ctx.alloc_imperative_expr(Expr::New { type_name, type_args });
                return self.parse_field_access_chain(base);
            }

            // Phase 31: Handle "a new TypeName" pattern OR single-letter identifier
            // Phase 33: Extended for variant constructors "a new Circle with radius 10"
            // Phase 34: Extended for generic instantiation "a new Box of Int"
            TokenType::Article(_) => {
                // Check if followed by New token
                if let Some(next) = self.tokens.get(self.current + 1) {
                    if matches!(next.kind, TokenType::New) {
                        self.advance(); // consume article "a"/"an"
                        self.advance(); // consume "new"
                        let type_name = self.expect_identifier()?;

                        // Phase 33: Check if this is a variant constructor
                        if let Some(enum_name) = self.find_variant(type_name) {
                            // Parse optional "with field value" pairs
                            let fields = if self.check_word("with") {
                                self.parse_variant_constructor_fields()?
                            } else {
                                vec![]
                            };
                            let base = self.ctx.alloc_imperative_expr(Expr::NewVariant {
                                enum_name,
                                variant: type_name,
                                fields,
                            });
                            return self.parse_field_access_chain(base);
                        }

                        // Phase 34: Parse generic type arguments "of Int" or "of Int and Text"
                        let type_args = self.parse_generic_type_args(type_name)?;
                        let base = self.ctx.alloc_imperative_expr(Expr::New { type_name, type_args });
                        return self.parse_field_access_chain(base);
                    }
                }
                // Phase 32: Treat as identifier (single-letter var like "a", "b")
                let sym = token.lexeme;
                self.advance();
                let base = self.ctx.alloc_imperative_expr(Expr::Identifier(sym));
                return self.parse_field_access_chain(base);
            }

            // Index access: "item N of collection"
            TokenType::Item => {
                self.advance(); // consume "item"

                // Parse index (must be a number)
                let index = if let TokenType::Number(sym) = &self.peek().kind {
                    let sym = *sym;
                    self.advance();
                    let num_str = self.interner.resolve(sym);
                    num_str.parse::<usize>().unwrap_or(0)
                } else {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedExpression,
                        span: self.current_span(),
                    });
                };

                // Index 0 Guard: LOGOS uses 1-based indexing
                if index == 0 {
                    return Err(ParseError {
                        kind: ParseErrorKind::ZeroIndex,
                        span: self.current_span(),
                    });
                }

                // Expect "of"
                if !self.check_preposition_is("of") {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedKeyword { keyword: "of".to_string() },
                        span: self.current_span(),
                    });
                }
                self.advance(); // consume "of"

                // Parse collection
                let collection = self.parse_imperative_expr()?;

                Ok(self.ctx.alloc_imperative_expr(Expr::Index {
                    collection,
                    index,
                }))
            }

            // Slice access: "items N through M of collection"
            // OR variable named "items" - disambiguate by checking if next token is a number
            TokenType::Items => {
                // Peek ahead to determine if this is slice syntax or variable usage
                // If next token is not a number, treat "items" as a variable identifier
                if let Some(next) = self.tokens.get(self.current + 1) {
                    if !matches!(next.kind, TokenType::Number(_)) {
                        // Treat "items" as a variable identifier
                        let sym = token.lexeme;
                        self.advance();
                        return Ok(self.ctx.alloc_imperative_expr(Expr::Identifier(sym)));
                    }
                }

                self.advance(); // consume "items"

                // Parse start index (must be a number)
                let start = if let TokenType::Number(sym) = &self.peek().kind {
                    let sym = *sym;
                    self.advance();
                    let num_str = self.interner.resolve(sym);
                    num_str.parse::<usize>().unwrap_or(0)
                } else {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedNumber,
                        span: self.current_span(),
                    });
                };

                // Index 0 Guard for start
                if start == 0 {
                    return Err(ParseError {
                        kind: ParseErrorKind::ZeroIndex,
                        span: self.current_span(),
                    });
                }

                // Expect "through"
                if !self.check_preposition_is("through") {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedKeyword { keyword: "through".to_string() },
                        span: self.current_span(),
                    });
                }
                self.advance(); // consume "through"

                // Parse end index (must be a number)
                let end = if let TokenType::Number(sym) = &self.peek().kind {
                    let sym = *sym;
                    self.advance();
                    let num_str = self.interner.resolve(sym);
                    num_str.parse::<usize>().unwrap_or(0)
                } else {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedNumber,
                        span: self.current_span(),
                    });
                };

                // Index 0 Guard for end
                if end == 0 {
                    return Err(ParseError {
                        kind: ParseErrorKind::ZeroIndex,
                        span: self.current_span(),
                    });
                }

                // Expect "of"
                if !self.check_preposition_is("of") {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedKeyword { keyword: "of".to_string() },
                        span: self.current_span(),
                    });
                }
                self.advance(); // consume "of"

                // Parse collection
                let collection = self.parse_imperative_expr()?;

                Ok(self.ctx.alloc_imperative_expr(Expr::Slice {
                    collection,
                    start,
                    end,
                }))
            }

            // List literal: [1, 2, 3]
            TokenType::LBracket => {
                self.advance(); // consume "["

                let mut items = Vec::new();
                if !self.check(&TokenType::RBracket) {
                    loop {
                        items.push(self.parse_imperative_expr()?);
                        if !self.check(&TokenType::Comma) {
                            break;
                        }
                        self.advance(); // consume ","
                    }
                }

                if !self.check(&TokenType::RBracket) {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedKeyword { keyword: "]".to_string() },
                        span: self.current_span(),
                    });
                }
                self.advance(); // consume "]"

                Ok(self.ctx.alloc_imperative_expr(Expr::List(items)))
            }

            TokenType::Number(sym) => {
                self.advance();
                let num_str = self.interner.resolve(*sym);
                let num = num_str.parse::<i64>().unwrap_or(0);
                Ok(self.ctx.alloc_imperative_expr(Expr::Literal(Literal::Number(num))))
            }

            // Phase 33: String literals
            TokenType::StringLiteral(sym) => {
                self.advance();
                Ok(self.ctx.alloc_imperative_expr(Expr::Literal(Literal::Text(*sym))))
            }

            // Handle 'nothing' literal
            TokenType::Nothing => {
                self.advance();
                Ok(self.ctx.alloc_imperative_expr(Expr::Literal(Literal::Nothing)))
            }

            // Handle 'empty' when tokenized as a verb (lexicon includes "empty" as verb)
            TokenType::Verb { lemma, .. } => {
                let word = self.interner.resolve(*lemma).to_lowercase();
                if word == "empty" {
                    self.advance();
                    return Ok(self.ctx.alloc_imperative_expr(Expr::Literal(Literal::Nothing)));
                }
                // Other verbs aren't valid expressions in imperative context
                Err(ParseError {
                    kind: ParseErrorKind::ExpectedExpression,
                    span: self.current_span(),
                })
            }

            // Unified identifier handling - all identifier-like tokens get verified
            // First check for boolean/special literals before treating as variable
            TokenType::Noun(sym) | TokenType::ProperName(sym) | TokenType::Adjective(sym) => {
                let sym = *sym;
                let word = self.interner.resolve(sym);

                // Check for boolean literals
                if word == "true" {
                    self.advance();
                    return Ok(self.ctx.alloc_imperative_expr(Expr::Literal(Literal::Boolean(true))));
                }
                if word == "false" {
                    self.advance();
                    return Ok(self.ctx.alloc_imperative_expr(Expr::Literal(Literal::Boolean(false))));
                }

                // Check for 'empty' - treat as unit value for collections
                if word == "empty" {
                    self.advance();
                    return Ok(self.ctx.alloc_imperative_expr(Expr::Literal(Literal::Nothing)));
                }

                // Don't verify as variable - might be a function call
                self.advance();

                // Phase 32: Check for function call: identifier(args)
                if self.check(&TokenType::LParen) {
                    return self.parse_call_expr(sym);
                }

                // Centralized verification for undefined/moved checks (only for variables)
                self.verify_identifier_access(sym)?;
                let base = self.ctx.alloc_imperative_expr(Expr::Identifier(sym));
                // Phase 31: Check for field access via possessive
                self.parse_field_access_chain(base)
            }

            // Pronouns can be variable names in code context ("i", "it")
            TokenType::Pronoun { .. } => {
                let sym = token.lexeme;
                self.advance();
                let base = self.ctx.alloc_imperative_expr(Expr::Identifier(sym));
                // Phase 31: Check for field access via possessive
                self.parse_field_access_chain(base)
            }

            // Handle ambiguous tokens that might be identifiers
            TokenType::Ambiguous { primary, alternatives } => {
                let sym = match &**primary {
                    TokenType::Noun(s) | TokenType::Adjective(s) | TokenType::ProperName(s) => Some(*s),
                    _ => alternatives.iter().find_map(|t| match t {
                        TokenType::Noun(s) | TokenType::Adjective(s) | TokenType::ProperName(s) => Some(*s),
                        _ => None
                    })
                };

                if let Some(s) = sym {
                    self.verify_identifier_access(s)?;
                    self.advance();
                    let base = self.ctx.alloc_imperative_expr(Expr::Identifier(s));
                    // Phase 31: Check for field access via possessive
                    self.parse_field_access_chain(base)
                } else {
                    Err(ParseError {
                        kind: ParseErrorKind::ExpectedExpression,
                        span: self.current_span(),
                    })
                }
            }

            _ => {
                Err(ParseError {
                    kind: ParseErrorKind::ExpectedExpression,
                    span: self.current_span(),
                })
            }
        }
    }

    /// Parse a complete imperative expression including binary operators.
    fn parse_imperative_expr(&mut self) -> ParseResult<&'a Expr<'a>> {
        let left = self.parse_primary_expr()?;

        // Check for binary operator
        if let Some(op) = self.try_parse_binary_op() {
            let right = self.parse_imperative_expr()?;
            return Ok(self.ctx.alloc_imperative_expr(Expr::BinaryOp {
                op,
                left,
                right,
            }));
        }

        Ok(left)
    }

    /// Try to parse a binary operator (+, -, *, /)
    fn try_parse_binary_op(&mut self) -> Option<BinaryOpKind> {
        match &self.peek().kind {
            TokenType::Plus => {
                self.advance();
                Some(BinaryOpKind::Add)
            }
            TokenType::Minus => {
                self.advance();
                Some(BinaryOpKind::Subtract)
            }
            TokenType::Star => {
                self.advance();
                Some(BinaryOpKind::Multiply)
            }
            TokenType::Slash => {
                self.advance();
                Some(BinaryOpKind::Divide)
            }
            _ => None,
        }
    }

    /// Phase 32: Parse function call expression: f(x, y, ...)
    fn parse_call_expr(&mut self, function: Symbol) -> ParseResult<&'a Expr<'a>> {
        use crate::ast::Expr;

        self.advance(); // consume '('

        let mut args = Vec::new();
        if !self.check(&TokenType::RParen) {
            loop {
                args.push(self.parse_imperative_expr()?);
                if !self.check(&TokenType::Comma) {
                    break;
                }
                self.advance(); // consume ','
            }
        }

        if !self.check(&TokenType::RParen) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ")".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume ')'

        Ok(self.ctx.alloc_imperative_expr(Expr::Call { function, args }))
    }

    /// Phase 31: Parse field access chain via possessive ('s)
    /// Handles patterns like: p's x, p's x's y
    fn parse_field_access_chain(&mut self, base: &'a Expr<'a>) -> ParseResult<&'a Expr<'a>> {
        use crate::ast::Expr;

        let mut result = base;

        // Keep parsing field accesses while we see possessive tokens
        while self.check(&TokenType::Possessive) {
            self.advance(); // consume "'s"
            let field = self.expect_identifier()?;
            result = self.ctx.alloc_imperative_expr(Expr::FieldAccess {
                object: result,
                field,
            });
        }

        Ok(result)
    }

    /// Centralized verification for identifier access in imperative mode.
    /// Checks for use-after-move errors on known variables.
    fn verify_identifier_access(&self, sym: Symbol) -> ParseResult<()> {
        if self.mode != ParserMode::Imperative {
            return Ok(());
        }

        use crate::context::OwnershipState;
        let name = self.interner.resolve(sym);

        // Check for Use-After-Move on variables we're tracking
        let ownership = self.context.as_ref()
            .and_then(|ctx| ctx.get_ownership(name));

        if ownership == Some(OwnershipState::Moved) {
            return Err(ParseError {
                kind: ParseErrorKind::UseAfterMove { name: name.to_string() },
                span: self.current_span(),
            });
        }

        Ok(())
    }

    fn expect_identifier(&mut self) -> ParseResult<Symbol> {
        let token = self.peek().clone();
        match &token.kind {
            // Standard identifiers
            TokenType::Noun(sym) | TokenType::ProperName(sym) | TokenType::Adjective(sym) => {
                self.advance();
                Ok(*sym)
            }
            // Verbs can be variable names in code context ("empty", "run", etc.)
            // Use raw lexeme to preserve original casing
            TokenType::Verb { .. } => {
                let sym = token.lexeme;
                self.advance();
                Ok(sym)
            }
            // Phase 32: Articles can be single-letter identifiers (a, an)
            TokenType::Article(_) => {
                let sym = token.lexeme;
                self.advance();
                Ok(sym)
            }
            // Overloaded tokens that are valid identifiers in code context
            TokenType::Pronoun { .. } |  // "i", "it"
            TokenType::Items |           // "items"
            TokenType::Item |            // "item"
            TokenType::Nothing => {      // "nothing"
                // Use the raw lexeme (interned string) as the symbol
                let sym = token.lexeme;
                self.advance();
                Ok(sym)
            }
            TokenType::Ambiguous { primary, .. } => {
                // For ambiguous tokens, extract symbol from primary
                let sym = match &**primary {
                    TokenType::Noun(s) | TokenType::Adjective(s) | TokenType::ProperName(s) => *s,
                    TokenType::Verb { lemma, .. } => *lemma,
                    _ => token.lexeme,
                };
                self.advance();
                Ok(sym)
            }
            _ => Err(ParseError {
                kind: ParseErrorKind::ExpectedIdentifier,
                span: self.current_span(),
            }),
        }
    }

    fn consume_content_word_for_relative(&mut self) -> ParseResult<Symbol> {
        let t = self.advance().clone();
        match t.kind {
            TokenType::Noun(s) | TokenType::Adjective(s) => Ok(s),
            TokenType::ProperName(s) => Ok(s),
            TokenType::Verb { lemma, .. } => Ok(lemma),
            other => Err(ParseError {
                kind: ParseErrorKind::ExpectedContentWord { found: other },
                span: self.current_span(),
            }),
        }
    }

    fn check_modal(&self) -> bool {
        matches!(
            self.peek().kind,
            TokenType::Must
                | TokenType::Shall
                | TokenType::Should
                | TokenType::Can
                | TokenType::May
                | TokenType::Cannot
                | TokenType::Could
                | TokenType::Would
        )
    }

    fn check_pronoun(&self) -> bool {
        match &self.peek().kind {
            TokenType::Pronoun { case, .. } => {
                // In noun_priority_mode, possessive pronouns start NPs, not standalone objects
                if self.noun_priority_mode && matches!(case, Case::Possessive) {
                    return false;
                }
                true
            }
            TokenType::Ambiguous { primary, alternatives } => {
                // In noun_priority_mode, if there's a possessive alternative, prefer noun path
                if self.noun_priority_mode {
                    let has_possessive = matches!(**primary, TokenType::Pronoun { case: Case::Possessive, .. })
                        || alternatives.iter().any(|t| matches!(t, TokenType::Pronoun { case: Case::Possessive, .. }));
                    if has_possessive {
                        return false;
                    }
                }
                matches!(**primary, TokenType::Pronoun { .. })
                    || alternatives.iter().any(|t| matches!(t, TokenType::Pronoun { .. }))
            }
            _ => false,
        }
    }

    fn parse_atom(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        // Handle Focus particles: "Only John loves Mary", "Even John ran"
        if self.check_focus() {
            return self.parse_focus();
        }

        // Handle mass noun measure: "Much water flows", "Little time remains"
        if self.check_measure() {
            return self.parse_measure();
        }

        if self.check_quantifier() {
            self.advance();
            return self.parse_quantified();
        }

        if self.check_npi_quantifier() {
            return self.parse_npi_quantified();
        }

        if self.check_temporal_npi() {
            return self.parse_temporal_npi();
        }

        if self.match_token(&[TokenType::LParen]) {
            let expr = self.parse_sentence()?;
            self.consume(TokenType::RParen)?;
            return Ok(expr);
        }

        // Handle pronoun as subject
        if self.check_pronoun() {
            let token = self.advance().clone();
            let (gender, number) = match &token.kind {
                TokenType::Pronoun { gender, number, .. } => (*gender, *number),
                TokenType::Ambiguous { primary, alternatives } => {
                    if let TokenType::Pronoun { gender, number, .. } = **primary {
                        (gender, number)
                    } else {
                        alternatives.iter().find_map(|t| {
                            if let TokenType::Pronoun { gender, number, .. } = t {
                                Some((*gender, *number))
                            } else {
                                None
                            }
                        }).unwrap_or((Gender::Unknown, Number::Singular))
                    }
                }
                _ => (Gender::Unknown, Number::Singular),
            };

            let token_text = self.interner.resolve(token.lexeme);

            // Handle deictic pronouns that don't need discourse resolution
            let resolved = if token_text.eq_ignore_ascii_case("i") {
                self.interner.intern("Speaker")
            } else if token_text.eq_ignore_ascii_case("you") {
                self.interner.intern("Addressee")
            } else {
                // Try discourse resolution for anaphoric pronouns
                let unknown = self.interner.intern("?");
                self.resolve_pronoun(gender, number).unwrap_or(unknown)
            };

            // Check for performative: "I promise that..." or "I promise to..."
            if self.check_performative() {
                if let TokenType::Performative(act) = self.advance().kind.clone() {
                    // Check for infinitive complement: "I promise to come"
                    if self.check(&TokenType::To) {
                        self.advance(); // consume "to"

                        if self.check_verb() {
                            let infinitive_verb = self.consume_verb();

                            let content = self.ctx.exprs.alloc(LogicExpr::Predicate {
                                name: infinitive_verb,
                                args: self.ctx.terms.alloc_slice([Term::Constant(resolved)]),
                            });

                            return Ok(self.ctx.exprs.alloc(LogicExpr::SpeechAct {
                                performer: resolved,
                                act_type: act,
                                content,
                            }));
                        }
                    }

                    // Skip "that" if present
                    if self.check(&TokenType::That) {
                        self.advance();
                    }
                    let content = self.parse_sentence()?;
                    return Ok(self.ctx.exprs.alloc(LogicExpr::SpeechAct {
                        performer: resolved,
                        act_type: act,
                        content,
                    }));
                }
            }

            // Continue parsing verb phrase with resolved subject
            return self.parse_predicate_with_subject(resolved);
        }

        let subject = self.parse_noun_phrase(true)?;

        // Handle plural subjects: "John and Mary verb"
        if self.check(&TokenType::And) {
            if let Some(result) = self.try_parse_plural_subject(&subject) {
                return Ok(result);
            }
        }

        // Handle scopal adverbs: "John almost died"
        if self.check_scopal_adverb() {
            return self.parse_scopal_adverb(&subject);
        }

        // Handle topicalization: "The cake, John ate." - first NP is object, not subject
        if self.check(&TokenType::Comma) {
            let saved_pos = self.current;
            self.advance(); // consume comma

            // Check if followed by pronoun subject (e.g., "The book, he read.")
            if self.check_pronoun() {
                let topic_attempt = self.try_parse(|p| {
                    let token = p.peek().clone();
                    let pronoun_features = match &token.kind {
                        TokenType::Pronoun { gender, number, .. } => Some((*gender, *number)),
                        TokenType::Ambiguous { primary, alternatives } => {
                            if let TokenType::Pronoun { gender, number, .. } = **primary {
                                Some((gender, number))
                            } else {
                                alternatives.iter().find_map(|t| {
                                    if let TokenType::Pronoun { gender, number, .. } = t {
                                        Some((*gender, *number))
                                    } else {
                                        None
                                    }
                                })
                            }
                        }
                        _ => None,
                    };

                    if let Some((gender, number)) = pronoun_features {
                        p.advance(); // consume pronoun
                        let unknown = p.interner.intern("?");
                        let resolved = p.resolve_pronoun(gender, number).unwrap_or(unknown);

                        if p.check_verb() {
                            let verb = p.consume_verb();
                            let predicate = p.ctx.exprs.alloc(LogicExpr::Predicate {
                                name: verb,
                                args: p.ctx.terms.alloc_slice([
                                    Term::Constant(resolved),
                                    Term::Constant(subject.noun),
                                ]),
                            });
                            p.wrap_with_definiteness_full(&subject, predicate)
                        } else {
                            Err(ParseError {
                                kind: ParseErrorKind::ExpectedVerb { found: p.peek().kind.clone() },
                                span: p.current_span(),
                            })
                        }
                    } else {
                        Err(ParseError {
                            kind: ParseErrorKind::ExpectedContentWord { found: token.kind },
                            span: p.current_span(),
                        })
                    }
                });

                if let Some(result) = topic_attempt {
                    return Ok(result);
                }
            }

            // Check if followed by another NP and then a verb (topicalization pattern)
            if self.check_content_word() {
                let topic_attempt = self.try_parse(|p| {
                    let real_subject = p.parse_noun_phrase(true)?;
                    if p.check_verb() {
                        let verb = p.consume_verb();
                        let predicate = p.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: verb,
                            args: p.ctx.terms.alloc_slice([
                                Term::Constant(real_subject.noun),
                                Term::Constant(subject.noun),
                            ]),
                        });
                        p.wrap_with_definiteness_full(&subject, predicate)
                    } else {
                        Err(ParseError {
                            kind: ParseErrorKind::ExpectedVerb { found: p.peek().kind.clone() },
                            span: p.current_span(),
                        })
                    }
                });

                if let Some(result) = topic_attempt {
                    return Ok(result);
                }
            }

            // Restore position if topicalization didn't match
            self.current = saved_pos;
        }

        // Handle relative clause after subject: "The cat that the dog chased ran."
        let mut relative_clause: Option<(Symbol, &'a LogicExpr<'a>)> = None;
        if self.check(&TokenType::That) || self.check(&TokenType::Who) {
            self.advance();
            let var_name = self.next_var_name();
            let rel_pred = self.parse_relative_clause(var_name)?;
            relative_clause = Some((var_name, rel_pred));
        } else if matches!(self.peek().kind, TokenType::Article(_)) && self.is_contact_clause_pattern() {
            // Contact clause (reduced relative): "The cat the dog chased ran."
            // NP + NP + Verb pattern indicates embedded relative without explicit "that"
            let var_name = self.next_var_name();
            let rel_pred = self.parse_relative_clause(var_name)?;
            relative_clause = Some((var_name, rel_pred));
        }

        // Handle main verb after relative clause: "The cat that the dog chased ran."
        if let Some((var_name, rel_clause)) = relative_clause {
            if self.check_verb() {
                let (verb, verb_time, _, _) = self.consume_verb_with_metadata();
                let var_term = Term::Variable(var_name);

                let event_var = self.get_event_var();
                let mut modifiers = vec![];
                if verb_time == Time::Past {
                    modifiers.push(self.interner.intern("Past"));
                }
                let main_pred = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                    event_var,
                    verb,
                    roles: self.ctx.roles.alloc_slice(vec![
                        (ThematicRole::Agent, var_term),
                    ]),
                    modifiers: self.ctx.syms.alloc_slice(modifiers),
                })));

                let type_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: subject.noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                });

                let inner = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: type_pred,
                    op: TokenType::And,
                    right: rel_clause,
                });

                let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: inner,
                    op: TokenType::And,
                    right: main_pred,
                });

                return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: var_name,
                    body,
                    island_id: self.current_island,
                }));
            }

            // No main verb - just the relative clause: "The cat that runs" as a complete NP
            // Build: ∃x(Cat(x) ∧ Runs(x) ∧ ∀y(Cat(y) → y=x))
            if self.is_at_end() || self.check(&TokenType::Period) || self.check(&TokenType::Comma) {
                let type_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: subject.noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                });

                let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: type_pred,
                    op: TokenType::And,
                    right: rel_clause,
                });

                // Add uniqueness for definite description
                let uniqueness_body = if subject.definiteness == Some(Definiteness::Definite) {
                    let y_var = self.next_var_name();
                    let type_pred_y = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: subject.noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(y_var)]),
                    });
                    let identity = self.ctx.exprs.alloc(LogicExpr::Identity {
                        left: self.ctx.terms.alloc(Term::Variable(y_var)),
                        right: self.ctx.terms.alloc(Term::Variable(var_name)),
                    });
                    let uniqueness_cond = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: type_pred_y,
                        op: TokenType::If,
                        right: identity,
                    });
                    let uniqueness = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                        kind: QuantifierKind::Universal,
                        variable: y_var,
                        body: uniqueness_cond,
                        island_id: self.current_island,
                    });
                    self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: body,
                        op: TokenType::And,
                        right: uniqueness,
                    })
                } else {
                    body
                };

                return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: var_name,
                    body: uniqueness_body,
                    island_id: self.current_island,
                }));
            }

            // Re-store for copula handling below
            relative_clause = Some((var_name, rel_clause));
        }

        // Identity check: "Clark is equal to Superman"
        if self.check(&TokenType::Identity) {
            self.advance();
            let right = self.consume_content_word()?;
            return Ok(self.ctx.exprs.alloc(LogicExpr::Identity {
                left: self.ctx.terms.alloc(Term::Constant(subject.noun)),
                right: self.ctx.terms.alloc(Term::Constant(right)),
            }));
        }

        if self.check_modal() {
            if let Some((var_name, rel_clause)) = relative_clause {
                let modal_pred = self.parse_aspect_chain_with_term(Term::Variable(var_name))?;

                let type_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: subject.noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                });

                let inner = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: type_pred,
                    op: TokenType::And,
                    right: rel_clause,
                });

                let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: inner,
                    op: TokenType::And,
                    right: modal_pred,
                });

                return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: var_name,
                    body,
                    island_id: self.current_island,
                }));
            }

            let modal_pred = self.parse_aspect_chain(subject.noun)?;
            return self.wrap_with_definiteness_full(&subject, modal_pred);
        }

        if self.check(&TokenType::Is) || self.check(&TokenType::Are)
            || self.check(&TokenType::Was) || self.check(&TokenType::Were)
        {
            let copula_time = if self.check(&TokenType::Was) || self.check(&TokenType::Were) {
                Time::Past
            } else {
                Time::Present
            };
            self.advance();

            // Check for Number token (measure phrase) before comparative or adjective
            // "John is 2 inches taller than Mary" or "The rope is 5 meters long"
            if self.check_number() {
                let measure = self.parse_measure_phrase()?;

                // Check if followed by comparative: "2 inches taller than"
                if self.check_comparative() {
                    return self.parse_comparative(&subject, copula_time, Some(measure));
                }

                // Check for dimensional adjective: "5 meters long"
                if self.check_content_word() {
                    let adj = self.consume_content_word()?;
                    let result = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: adj,
                        args: self.ctx.terms.alloc_slice([
                            Term::Constant(subject.noun),
                            *measure,
                        ]),
                    });
                    return self.wrap_with_definiteness_full(&subject, result);
                }

                // Bare measure phrase: "The temperature is 98.6 degrees."
                // Output: Identity(subject, measure)
                if self.check(&TokenType::Period) || self.is_at_end() {
                    // In imperative mode, reject "x is 5" - suggest "x equals 5"
                    if self.mode == ParserMode::Imperative {
                        let variable = self.interner.resolve(subject.noun).to_string();
                        let value = if let Term::Value { kind, .. } = measure {
                            format!("{:?}", kind)
                        } else {
                            "value".to_string()
                        };
                        return Err(ParseError {
                            kind: ParseErrorKind::IsValueEquality { variable, value },
                            span: self.current_span(),
                        });
                    }
                    let result = self.ctx.exprs.alloc(LogicExpr::Identity {
                        left: self.ctx.terms.alloc(Term::Constant(subject.noun)),
                        right: measure,
                    });
                    return self.wrap_with_definiteness_full(&subject, result);
                }
            }

            // Check for comparative: "is taller than"
            if self.check_comparative() {
                return self.parse_comparative(&subject, copula_time, None);
            }

            // Check for existential "is": "God is." - bare copula followed by period/EOF
            if self.check(&TokenType::Period) || self.is_at_end() {
                let var = self.next_var_name();
                let body = self.ctx.exprs.alloc(LogicExpr::Identity {
                    left: self.ctx.terms.alloc(Term::Variable(var)),
                    right: self.ctx.terms.alloc(Term::Constant(subject.noun)),
                });
                return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: var,
                    body,
                    island_id: self.current_island,
                }));
            }

            // Check for superlative: "is the tallest man"
            if self.check(&TokenType::Article(Definiteness::Definite)) {
                let saved_pos = self.current;
                self.advance();
                if self.check_superlative() {
                    return self.parse_superlative(&subject);
                }
                self.current = saved_pos;
            }

            // Check for predicate NP: "Juliet is the sun" or "John is a man"
            if self.check_article() {
                let predicate_np = self.parse_noun_phrase(true)?;
                let predicate_noun = predicate_np.noun;

                let subject_sort = lexicon::lookup_sort(self.interner.resolve(subject.noun));
                let predicate_sort = lexicon::lookup_sort(self.interner.resolve(predicate_noun));

                if let (Some(s_sort), Some(p_sort)) = (subject_sort, predicate_sort) {
                    if !s_sort.is_compatible_with(p_sort) && !p_sort.is_compatible_with(s_sort) {
                        let metaphor = self.ctx.exprs.alloc(LogicExpr::Metaphor {
                            tenor: self.ctx.terms.alloc(Term::Constant(subject.noun)),
                            vehicle: self.ctx.terms.alloc(Term::Constant(predicate_noun)),
                        });
                        return self.wrap_with_definiteness(subject.definiteness, subject.noun, metaphor);
                    }
                }

                let predicate = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: predicate_noun,
                    args: self.ctx.terms.alloc_slice([Term::Constant(subject.noun)]),
                });
                return self.wrap_with_definiteness(subject.definiteness, subject.noun, predicate);
            }

            // After copula, prefer Adjective over simple-aspect Verb for ambiguous tokens
            // "is open" (Adj: state) is standard; "is open" (Verb: habitual) is ungrammatical here
            let prefer_adjective = if let TokenType::Ambiguous { primary, alternatives } = &self.peek().kind {
                let is_simple_verb = if let TokenType::Verb { aspect, .. } = **primary {
                    aspect == Aspect::Simple
                } else {
                    false
                };
                let has_adj_alt = alternatives.iter().any(|t| matches!(t, TokenType::Adjective(_)));
                is_simple_verb && has_adj_alt
            } else {
                false
            };

            if !prefer_adjective && self.check_verb() {
                let (verb, _verb_time, verb_aspect, verb_class) = self.consume_verb_with_metadata();

                // Stative verbs cannot be progressive
                if verb_class.is_stative() && verb_aspect == Aspect::Progressive {
                    return Err(ParseError {
                        kind: ParseErrorKind::StativeProgressiveConflict,
                        span: self.current_span(),
                    });
                }

                // Collect any prepositional phrases before "by" (for ditransitives)
                // "given to Mary by John" → goal = Mary, then agent = John
                let mut goal_args: Vec<Term<'a>> = Vec::new();
                while self.check_to_preposition() {
                    self.advance(); // consume "to"
                    let goal = self.parse_noun_phrase(true)?;
                    goal_args.push(self.noun_phrase_to_term(&goal));
                }

                // Check for passive: "was loved by John" or "was given to Mary by John"
                if self.check_by_preposition() {
                    self.advance(); // consume "by"
                    let agent = self.parse_noun_phrase(true)?;

                    // Build args: agent, theme (subject), then any goals
                    let mut args = vec![
                        self.noun_phrase_to_term(&agent),
                        self.noun_phrase_to_term(&subject),
                    ];
                    args.extend(goal_args);

                    let predicate = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: verb,
                        args: self.ctx.terms.alloc_slice(args),
                    });

                    let with_time = if copula_time == Time::Past {
                        self.ctx.exprs.alloc(LogicExpr::Temporal {
                            operator: TemporalOperator::Past,
                            body: predicate,
                        })
                    } else {
                        predicate
                    };

                    return self.wrap_with_definiteness(subject.definiteness, subject.noun, with_time);
                }

                // Agentless passive: "The book was read" → ∃x.Read(x, Book)
                if copula_time == Time::Past && verb_aspect == Aspect::Simple {
                    // Could be agentless passive - treat as existential
                    let var_name = self.next_var_name();
                    let predicate = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: verb,
                        args: self.ctx.terms.alloc_slice([
                            Term::Variable(var_name),
                            Term::Constant(subject.noun),
                        ]),
                    });

                    let type_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: subject.noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                    });

                    let temporal = self.ctx.exprs.alloc(LogicExpr::Temporal {
                        operator: TemporalOperator::Past,
                        body: predicate,
                    });

                    let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: type_pred,
                        op: TokenType::And,
                        right: temporal,
                    });

                    return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                        kind: QuantifierKind::Existential,
                        variable: var_name,
                        body,
                        island_id: self.current_island,
                    }));
                }

                let predicate = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb,
                    args: self.ctx.terms.alloc_slice([Term::Constant(subject.noun)]),
                });

                let with_aspect = if verb_aspect == Aspect::Progressive {
                    // Semelfactive + Progressive → Iterative
                    let operator = if verb_class == VerbClass::Semelfactive {
                        AspectOperator::Iterative
                    } else {
                        AspectOperator::Progressive
                    };
                    self.ctx.exprs.alloc(LogicExpr::Aspectual {
                        operator,
                        body: predicate,
                    })
                } else {
                    predicate
                };

                let with_time = if copula_time == Time::Past {
                    self.ctx.exprs.alloc(LogicExpr::Temporal {
                        operator: TemporalOperator::Past,
                        body: with_aspect,
                    })
                } else {
                    with_aspect
                };

                return self.wrap_with_definiteness(subject.definiteness, subject.noun, with_time);
            }

            // Handle relative clause with copula: "The book that John read is good."
            if let Some((var_name, rel_clause)) = relative_clause {
                let var_term = Term::Variable(var_name);
                let pred_word = self.consume_content_word()?;

                let main_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: pred_word,
                    args: self.ctx.terms.alloc_slice([var_term]),
                });

                let type_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: subject.noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                });

                let inner = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: type_pred,
                    op: TokenType::And,
                    right: rel_clause,
                });

                let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: inner,
                    op: TokenType::And,
                    right: main_pred,
                });

                return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: var_name,
                    body,
                    island_id: self.current_island,
                }));
            }

            // Handle "The king is bald" - NP copula ADJ/NOUN
            // Also handles bare noun predicates like "Time is money"
            let predicate_name = self.consume_content_word()?;

            // Check for sort violation (metaphor detection)
            let subject_sort = lexicon::lookup_sort(self.interner.resolve(subject.noun));
            let predicate_str = self.interner.resolve(predicate_name);

            // Check ontology's predicate sort requirements (for adjectives like "happy")
            if let Some(s_sort) = subject_sort {
                if !crate::ontology::check_sort_compatibility(predicate_str, s_sort) {
                    let metaphor = self.ctx.exprs.alloc(LogicExpr::Metaphor {
                        tenor: self.ctx.terms.alloc(Term::Constant(subject.noun)),
                        vehicle: self.ctx.terms.alloc(Term::Constant(predicate_name)),
                    });
                    return self.wrap_with_definiteness(subject.definiteness, subject.noun, metaphor);
                }
            }

            // Check copular NP predicate sort compatibility (for "Time is money")
            let predicate_sort = lexicon::lookup_sort(predicate_str);
            if let (Some(s_sort), Some(p_sort)) = (subject_sort, predicate_sort) {
                if s_sort != p_sort && !s_sort.is_compatible_with(p_sort) && !p_sort.is_compatible_with(s_sort) {
                    let metaphor = self.ctx.exprs.alloc(LogicExpr::Metaphor {
                        tenor: self.ctx.terms.alloc(Term::Constant(subject.noun)),
                        vehicle: self.ctx.terms.alloc(Term::Constant(predicate_name)),
                    });
                    return self.wrap_with_definiteness(subject.definiteness, subject.noun, metaphor);
                }
            }

            let predicate = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: predicate_name,
                args: self.ctx.terms.alloc_slice([Term::Constant(subject.noun)]),
            });
            return self.wrap_with_definiteness(subject.definiteness, subject.noun, predicate);
        }

        // Handle auxiliary: set pending_time, handle negation
        if self.check_auxiliary() {
            let aux_time = if let TokenType::Auxiliary(time) = self.advance().kind {
                time
            } else {
                Time::None
            };
            self.pending_time = Some(aux_time);

            // Handle negation: "John did not see dogs"
            if self.match_token(&[TokenType::Not]) {
                self.negative_depth += 1;

                // Skip "ever" if present: "John did not ever run"
                if self.check(&TokenType::Ever) {
                    self.advance();
                }

                if self.check_verb() {
                    let verb = self.consume_verb();
                    let subject_term = self.noun_phrase_to_term(&subject);

                    // Check for NPI object first: "John did not see anything"
                    if self.check_npi_object() {
                        let npi_token = self.advance().kind.clone();
                        let obj_var = self.next_var_name();

                        let restriction_name = match npi_token {
                            TokenType::Anything => "Thing",
                            TokenType::Anyone => "Person",
                            _ => "Thing",
                        };

                        let restriction_sym = self.interner.intern(restriction_name);
                        let obj_restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: restriction_sym,
                            args: self.ctx.terms.alloc_slice([Term::Variable(obj_var)]),
                        });

                        let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: verb,
                            args: self.ctx.terms.alloc_slice([subject_term.clone(), Term::Variable(obj_var)]),
                        });

                        let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: obj_restriction,
                            op: TokenType::And,
                            right: verb_pred,
                        });

                        let quantified = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                            kind: QuantifierKind::Existential,
                            variable: obj_var,
                            body,
                            island_id: self.current_island,
                        });

                        let effective_time = self.pending_time.take().unwrap_or(Time::None);
                        let with_time = match effective_time {
                            Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                                operator: TemporalOperator::Past,
                                body: quantified,
                            }),
                            Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                                operator: TemporalOperator::Future,
                                body: quantified,
                            }),
                            _ => quantified,
                        };

                        self.negative_depth -= 1;
                        return Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                            op: TokenType::Not,
                            operand: with_time,
                        }));
                    }

                    // Check for quantifier object: "John did not see any dogs"
                    if self.check_quantifier() {
                        let quantifier_token = self.advance().kind.clone();
                        let object_np = self.parse_noun_phrase(false)?;
                        let obj_var = self.next_var_name();

                        let obj_restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: object_np.noun,
                            args: self.ctx.terms.alloc_slice([Term::Variable(obj_var)]),
                        });

                        let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: verb,
                            args: self.ctx.terms.alloc_slice([subject_term.clone(), Term::Variable(obj_var)]),
                        });

                        let (kind, body) = match quantifier_token {
                            TokenType::Any => {
                                if self.is_negative_context() {
                                    (
                                        QuantifierKind::Existential,
                                        self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                            left: obj_restriction,
                                            op: TokenType::And,
                                            right: verb_pred,
                                        }),
                                    )
                                } else {
                                    (
                                        QuantifierKind::Universal,
                                        self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                            left: obj_restriction,
                                            op: TokenType::If,
                                            right: verb_pred,
                                        }),
                                    )
                                }
                            }
                            TokenType::Some => (
                                QuantifierKind::Existential,
                                self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                    left: obj_restriction,
                                    op: TokenType::And,
                                    right: verb_pred,
                                }),
                            ),
                            TokenType::All => (
                                QuantifierKind::Universal,
                                self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                    left: obj_restriction,
                                    op: TokenType::If,
                                    right: verb_pred,
                                }),
                            ),
                            _ => (
                                QuantifierKind::Existential,
                                self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                    left: obj_restriction,
                                    op: TokenType::And,
                                    right: verb_pred,
                                }),
                            ),
                        };

                        let quantified = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                            kind,
                            variable: obj_var,
                            body,
                            island_id: self.current_island,
                        });

                        let effective_time = self.pending_time.take().unwrap_or(Time::None);
                        let with_time = match effective_time {
                            Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                                operator: TemporalOperator::Past,
                                body: quantified,
                            }),
                            Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                                operator: TemporalOperator::Future,
                                body: quantified,
                            }),
                            _ => quantified,
                        };

                        self.negative_depth -= 1;
                        return Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                            op: TokenType::Not,
                            operand: with_time,
                        }));
                    }

                    let mut roles: Vec<(ThematicRole, Term<'a>)> = vec![(ThematicRole::Agent, subject_term)];

                    // Add temporal modifier from pending_time
                    let effective_time = self.pending_time.take().unwrap_or(Time::None);
                    let mut modifiers: Vec<Symbol> = vec![];
                    match effective_time {
                        Time::Past => modifiers.push(self.interner.intern("Past")),
                        Time::Future => modifiers.push(self.interner.intern("Future")),
                        _ => {}
                    }

                    // Check for object
                    if self.check_content_word() || self.check_article() {
                        let object = self.parse_noun_phrase(false)?;
                        let object_term = self.noun_phrase_to_term(&object);
                        roles.push((ThematicRole::Theme, object_term));
                    }

                    let event_var = self.get_event_var();
                    let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                        event_var,
                        verb,
                        roles: self.ctx.roles.alloc_slice(roles),
                        modifiers: self.ctx.syms.alloc_slice(modifiers),
                    })));

                    self.negative_depth -= 1;
                    return Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                        op: TokenType::Not,
                        operand: neo_event,
                    }));
                }

                self.negative_depth -= 1;
            }
            // Non-negated auxiliary: pending_time is set, fall through to normal verb handling
        }

        // Check for presupposition triggers: "stopped", "started", "regrets", "knows"
        // Factive verbs like "know" only trigger presupposition with clausal complements
        // "John knows that..." → presupposition, "John knows Mary" → regular verb
        // Only trigger presupposition if followed by a gerund (e.g., "stopped smoking")
        // "John stopped." alone should parse as intransitive verb, not presupposition
        if self.check_presup_trigger() && !self.is_followed_by_np_object() && self.is_followed_by_gerund() {
            let presup_kind = match self.advance().kind {
                TokenType::PresupTrigger(kind) => kind,
                TokenType::Verb { lemma, .. } => {
                    let s = self.interner.resolve(lemma).to_lowercase();
                    crate::lexicon::lookup_presup_trigger(&s)
                        .expect("Lexicon mismatch: Verb flagged as trigger but lookup failed")
                }
                _ => panic!("Expected presupposition trigger"),
            };
            return self.parse_presupposition(&subject, presup_kind);
        }

        // Handle bare plurals: "Birds fly." → Gen x. Bird(x) → Fly(x)
        let noun_str = self.interner.resolve(subject.noun);
        let is_bare_plural = subject.definiteness.is_none()
            && subject.possessor.is_none()
            && Self::is_plural_noun(noun_str)
            && self.check_verb();

        if is_bare_plural {
            let var_name = self.next_var_name();
            let (verb, verb_time, verb_aspect, _) = self.consume_verb_with_metadata();

            let type_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: subject.noun,
                args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
            });

            let mut args = vec![Term::Variable(var_name)];
            if self.check_content_word() {
                let object = self.parse_noun_phrase(false)?;
                args.push(self.noun_phrase_to_term(&object));
            }

            let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice(args),
            });

            let effective_time = self.pending_time.take().unwrap_or(verb_time);
            let with_time = match effective_time {
                Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                    operator: TemporalOperator::Past,
                    body: verb_pred,
                }),
                Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                    operator: TemporalOperator::Future,
                    body: verb_pred,
                }),
                _ => verb_pred,
            };

            let with_aspect = if verb_aspect == Aspect::Progressive {
                self.ctx.exprs.alloc(LogicExpr::Aspectual {
                    operator: AspectOperator::Progressive,
                    body: with_time,
                })
            } else {
                with_time
            };

            let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: type_pred,
                op: TokenType::If,
                right: with_aspect,
            });

            return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                kind: QuantifierKind::Generic,
                variable: var_name,
                body,
                island_id: self.current_island,
            }));
        }

        // Handle do-support: "John does not exist" or "John does run"
        if self.check(&TokenType::Does) || self.check(&TokenType::Do) {
            self.advance(); // consume does/do
            let is_negated = self.match_token(&[TokenType::Not]);

            if self.check_verb() {
                let verb = self.consume_verb();
                let verb_lemma = self.interner.resolve(verb).to_lowercase();

                // Check for embedded wh-clause with negation: "I don't know who"
                if self.check_wh_word() {
                    let wh_token = self.advance().kind.clone();
                    let is_who = matches!(wh_token, TokenType::Who);
                    let is_what = matches!(wh_token, TokenType::What);

                    let is_sluicing = self.is_at_end() ||
                        self.check(&TokenType::Period) ||
                        self.check(&TokenType::Comma);

                    if is_sluicing {
                        if let Some(template) = self.last_event_template.clone() {
                            let wh_var = self.next_var_name();
                            let subject_term = self.noun_phrase_to_term(&subject);

                            let roles: Vec<_> = if is_who {
                                std::iter::once((ThematicRole::Agent, Term::Variable(wh_var)))
                                    .chain(template.non_agent_roles.iter().cloned())
                                    .collect()
                            } else if is_what {
                                vec![
                                    (ThematicRole::Agent, subject_term.clone()),
                                    (ThematicRole::Theme, Term::Variable(wh_var)),
                                ]
                            } else {
                                std::iter::once((ThematicRole::Agent, Term::Variable(wh_var)))
                                    .chain(template.non_agent_roles.iter().cloned())
                                    .collect()
                            };

                            let event_var = self.get_event_var();
                            let reconstructed = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                                event_var,
                                verb: template.verb,
                                roles: self.ctx.roles.alloc_slice(roles),
                                modifiers: self.ctx.syms.alloc_slice(template.modifiers.clone()),
                            })));

                            let question = self.ctx.exprs.alloc(LogicExpr::Question {
                                wh_variable: wh_var,
                                body: reconstructed,
                            });

                            let know_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                                event_var: self.get_event_var(),
                                verb,
                                roles: self.ctx.roles.alloc_slice(vec![
                                    (ThematicRole::Agent, subject_term),
                                    (ThematicRole::Theme, Term::Proposition(question)),
                                ]),
                                modifiers: self.ctx.syms.alloc_slice(vec![]),
                            })));

                            let result = if is_negated {
                                self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                                    op: TokenType::Not,
                                    operand: know_event,
                                })
                            } else {
                                know_event
                            };

                            return self.wrap_with_definiteness_full(&subject, result);
                        }
                    }
                }

                // Special handling for "exist" with negation
                if verb_lemma == "exist" && is_negated {
                    // "The King of France does not exist" -> ¬∃x(KingOfFrance(x))
                    let var_name = self.next_var_name();
                    let restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: subject.noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                    });
                    let exists = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                        kind: QuantifierKind::Existential,
                        variable: var_name,
                        body: restriction,
                        island_id: self.current_island,
                    });
                    return Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                        op: TokenType::Not,
                        operand: exists,
                    }));
                }

                // Regular do-support: "John does run" or "John does not run"
                let subject_term = self.noun_phrase_to_term(&subject);
                let roles: Vec<(ThematicRole, Term<'a>)> = vec![(ThematicRole::Agent, subject_term)];
                let modifiers: Vec<Symbol> = vec![];
                let event_var = self.get_event_var();

                let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                    event_var,
                    verb,
                    roles: self.ctx.roles.alloc_slice(roles),
                    modifiers: self.ctx.syms.alloc_slice(modifiers),
                })));

                if is_negated {
                    return Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                        op: TokenType::Not,
                        operand: neo_event,
                    }));
                }
                return Ok(neo_event);
            }
        }

        // Garden path detection: "The horse raced past the barn fell."
        // If we have a definite NP + past verb + more content + another verb,
        // try reduced relative interpretation
        // Skip if pending_time is set (auxiliary like "will" was just consumed)
        // Skip if verb is has/have/had (perfect aspect, not reduced relative)
        let is_perfect_aux = if self.check_verb() {
            let word = self.interner.resolve(self.peek().lexeme).to_lowercase();
            word == "has" || word == "have" || word == "had"
        } else {
            false
        };
        if subject.definiteness == Some(Definiteness::Definite) && self.check_verb() && self.pending_time.is_none() && !is_perfect_aux {
            let saved_pos = self.current;

            // Try parsing as reduced relative: first verb is modifier, look for main verb after
            if let Some(garden_path_result) = self.try_parse(|p| {
                let (modifier_verb, _modifier_time, _, _) = p.consume_verb_with_metadata();

                // Collect any PP modifiers on the reduced relative
                let mut pp_mods: Vec<&'a LogicExpr<'a>> = Vec::new();
                while p.check_preposition() {
                    let prep = if let TokenType::Preposition(prep) = p.advance().kind {
                        prep
                    } else {
                        break;
                    };
                    if p.check_article() || p.check_content_word() {
                        let pp_obj = p.parse_noun_phrase(false)?;
                        let pp_pred = p.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: prep,
                            args: p.ctx.terms.alloc_slice([Term::Variable(p.interner.intern("x")), Term::Constant(pp_obj.noun)]),
                        });
                        pp_mods.push(pp_pred);
                    }
                }

                // Now check if there's ANOTHER verb (the real main verb)
                if !p.check_verb() {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedVerb { found: p.peek().kind.clone() },
                        span: p.current_span(),
                    });
                }

                let (main_verb, main_time, _, _) = p.consume_verb_with_metadata();

                // Build: ∃x((Horse(x) ∧ ∀y(Horse(y) → y=x)) ∧ Raced(x) ∧ Past(x, Barn) ∧ Fell(x))
                let var = p.interner.intern("x");

                // Type predicate
                let type_pred = p.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: subject.noun,
                    args: p.ctx.terms.alloc_slice([Term::Variable(var)]),
                });

                // Modifier verb predicate (reduced relative)
                let mod_pred = p.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: modifier_verb,
                    args: p.ctx.terms.alloc_slice([Term::Variable(var)]),
                });

                // Main verb predicate
                let main_pred = p.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: main_verb,
                    args: p.ctx.terms.alloc_slice([Term::Variable(var)]),
                });

                // Combine type + modifier
                let mut body = p.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: type_pred,
                    op: TokenType::And,
                    right: mod_pred,
                });

                // Add PP modifiers
                for pp in pp_mods {
                    body = p.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: body,
                        op: TokenType::And,
                        right: pp,
                    });
                }

                // Add main predicate
                body = p.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: body,
                    op: TokenType::And,
                    right: main_pred,
                });

                // Wrap with temporal if needed
                let with_time = match main_time {
                    Time::Past => p.ctx.exprs.alloc(LogicExpr::Temporal {
                        operator: TemporalOperator::Past,
                        body,
                    }),
                    Time::Future => p.ctx.exprs.alloc(LogicExpr::Temporal {
                        operator: TemporalOperator::Future,
                        body,
                    }),
                    _ => body,
                };

                // Wrap in existential quantifier for definite
                Ok(p.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: var,
                    body: with_time,
                    island_id: p.current_island,
                }))
            }) {
                return Ok(garden_path_result);
            }

            // Restore position if garden path didn't work
            self.current = saved_pos;
        }

        if self.check_modal() {
            return self.parse_aspect_chain(subject.noun);
        }

        // Handle "has/have/had" perfect aspect: "John has run"
        if self.check_content_word() {
            let word = self.interner.resolve(self.peek().lexeme).to_lowercase();
            if word == "has" || word == "have" || word == "had" {
                // Lookahead to distinguish perfect aspect ("has eaten") from possession ("has 3 children")
                let is_perfect_aspect = if self.current + 1 < self.tokens.len() {
                    let next_token = &self.tokens[self.current + 1].kind;
                    matches!(
                        next_token,
                        TokenType::Verb { .. } | TokenType::Not
                    ) && !matches!(next_token, TokenType::Number(_))
                } else {
                    false
                };
                if is_perfect_aspect {
                    return self.parse_aspect_chain(subject.noun);
                }
                // Otherwise fall through to verb parsing below
            }
        }

        // Handle TokenType::Had for past perfect: "John had run"
        if self.check(&TokenType::Had) {
            return self.parse_aspect_chain(subject.noun);
        }

        // Handle "never" temporal negation: "John never runs"
        if self.check(&TokenType::Never) {
            self.advance();
            let verb = self.consume_verb();
            let subject_term = self.noun_phrase_to_term(&subject);
            let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice([subject_term]),
            });
            let result = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                op: TokenType::Not,
                operand: verb_pred,
            });
            return self.wrap_with_definiteness_full(&subject, result);
        }

        if self.check_verb() {
            let (mut verb, verb_time, verb_aspect, verb_class) = self.consume_verb_with_metadata();

            // Check for verb sort violation (metaphor detection)
            let subject_sort = lexicon::lookup_sort(self.interner.resolve(subject.noun));
            let verb_str = self.interner.resolve(verb);
            if let Some(s_sort) = subject_sort {
                if !crate::ontology::check_sort_compatibility(verb_str, s_sort) {
                    let metaphor = self.ctx.exprs.alloc(LogicExpr::Metaphor {
                        tenor: self.ctx.terms.alloc(Term::Constant(subject.noun)),
                        vehicle: self.ctx.terms.alloc(Term::Constant(verb)),
                    });
                    return self.wrap_with_definiteness(subject.definiteness, subject.noun, metaphor);
                }
            }

            // Check for control verb + infinitive
            if self.is_control_verb(verb) {
                return self.parse_control_structure(&subject, verb, verb_time);
            }

            // If we have a relative clause, use variable binding
            if let Some((var_name, rel_clause)) = relative_clause {
                let main_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                });

                let effective_time = self.pending_time.take().unwrap_or(verb_time);
                let with_time = match effective_time {
                    Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                        operator: TemporalOperator::Past,
                        body: main_pred,
                    }),
                    Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                        operator: TemporalOperator::Future,
                        body: main_pred,
                    }),
                    _ => main_pred,
                };

                // Build: ∃x(Type(x) ∧ RelClause(x) ∧ MainPred(x))
                let type_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: subject.noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                });

                let inner = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: type_pred,
                    op: TokenType::And,
                    right: rel_clause,
                });

                let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: inner,
                    op: TokenType::And,
                    right: with_time,
                });

                return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: var_name,
                    body,
                    island_id: self.current_island,
                }));
            }

            let subject_term = self.noun_phrase_to_term(&subject);
            let mut args = vec![subject_term.clone()];

            let unknown = self.interner.intern("?");

            // Check for embedded wh-clause: "I know who/what"
            if self.check_wh_word() {
                let wh_token = self.advance().kind.clone();

                // Determine wh-type for slot matching
                let is_who = matches!(wh_token, TokenType::Who);
                let is_what = matches!(wh_token, TokenType::What);

                // Check for sluicing: wh-word followed by terminator
                let is_sluicing = self.is_at_end() ||
                    self.check(&TokenType::Period) ||
                    self.check(&TokenType::Comma);

                if is_sluicing {
                    // Reconstruct from template
                    if let Some(template) = self.last_event_template.clone() {
                        let wh_var = self.next_var_name();

                        // Build roles with wh-variable in appropriate slot
                        let roles: Vec<_> = if is_who {
                            // "who" replaces Agent
                            std::iter::once((ThematicRole::Agent, Term::Variable(wh_var)))
                                .chain(template.non_agent_roles.iter().cloned())
                                .collect()
                        } else if is_what {
                            // "what" replaces Theme - use Agent from context, Theme is variable
                            vec![
                                (ThematicRole::Agent, subject_term.clone()),
                                (ThematicRole::Theme, Term::Variable(wh_var)),
                            ]
                        } else {
                            // Default: wh-variable as Agent
                            std::iter::once((ThematicRole::Agent, Term::Variable(wh_var)))
                                .chain(template.non_agent_roles.iter().cloned())
                                .collect()
                        };

                        let event_var = self.get_event_var();
                        let reconstructed = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                            event_var,
                            verb: template.verb,
                            roles: self.ctx.roles.alloc_slice(roles),
                            modifiers: self.ctx.syms.alloc_slice(template.modifiers.clone()),
                        })));

                        let question = self.ctx.exprs.alloc(LogicExpr::Question {
                            wh_variable: wh_var,
                            body: reconstructed,
                        });

                        // Build: Know(subject, question)
                        let know_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                            event_var: self.get_event_var(),
                            verb,
                            roles: self.ctx.roles.alloc_slice(vec![
                                (ThematicRole::Agent, subject_term),
                                (ThematicRole::Theme, Term::Proposition(question)),
                            ]),
                            modifiers: self.ctx.syms.alloc_slice(vec![]),
                        })));

                        return self.wrap_with_definiteness_full(&subject, know_event);
                    }
                }

                // Non-sluicing embedded question: "I know who runs"
                let embedded = self.parse_embedded_wh_clause()?;
                let question = self.ctx.exprs.alloc(LogicExpr::Question {
                    wh_variable: self.interner.intern("x"),
                    body: embedded,
                });

                // Build: Know(subject, question)
                let know_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                    event_var: self.get_event_var(),
                    verb,
                    roles: self.ctx.roles.alloc_slice(vec![
                        (ThematicRole::Agent, subject_term),
                        (ThematicRole::Theme, Term::Proposition(question)),
                    ]),
                    modifiers: self.ctx.syms.alloc_slice(vec![]),
                })));

                return self.wrap_with_definiteness_full(&subject, know_event);
            }

            let mut object_term: Option<Term<'a>> = None;
            let mut second_object_term: Option<Term<'a>> = None;
            let mut object_superlative: Option<(Symbol, Symbol)> = None; // (adjective, noun)
            if self.check(&TokenType::Reflexive) {
                self.advance();
                let term = self.noun_phrase_to_term(&subject);
                object_term = Some(term.clone());
                args.push(term);

                // Check for distanced phrasal verb particle: "gave himself up"
                if let TokenType::Particle(particle_sym) = self.peek().kind {
                    let verb_str = self.interner.resolve(verb).to_lowercase();
                    let particle_str = self.interner.resolve(particle_sym).to_lowercase();
                    if let Some((phrasal_lemma, _class)) = crate::lexicon::lookup_phrasal_verb(&verb_str, &particle_str) {
                        self.advance();
                        verb = self.interner.intern(phrasal_lemma);
                    }
                }
            } else if self.check_pronoun() {
                let token = self.advance().clone();
                if let TokenType::Pronoun { gender, number, .. } = token.kind {
                    let resolved = self.resolve_pronoun(gender, number)
                        .unwrap_or(unknown);
                    let term = Term::Constant(resolved);
                    object_term = Some(term.clone());
                    args.push(term);

                    // Check for distanced phrasal verb particle: "gave it up"
                    if let TokenType::Particle(particle_sym) = self.peek().kind {
                        let verb_str = self.interner.resolve(verb).to_lowercase();
                        let particle_str = self.interner.resolve(particle_sym).to_lowercase();
                        if let Some((phrasal_lemma, _class)) = crate::lexicon::lookup_phrasal_verb(&verb_str, &particle_str) {
                            self.advance();
                            verb = self.interner.intern(phrasal_lemma);
                        }
                    }
                }
            } else if self.check_quantifier() || self.check_article() {
                // Quantified object: "John loves every woman" or "John saw a dog"
                let obj_quantifier = if self.check_quantifier() {
                    Some(self.advance().kind.clone())
                } else {
                    let art = self.advance().kind.clone();
                    if let TokenType::Article(def) = art {
                        if def == Definiteness::Indefinite {
                            Some(TokenType::Some)
                        } else {
                            None
                        }
                    } else {
                        None
                    }
                };

                let object_np = self.parse_noun_phrase(false)?;

                // Capture superlative info for constraint generation
                if let Some(adj) = object_np.superlative {
                    object_superlative = Some((adj, object_np.noun));
                }

                // Check for distanced phrasal verb particle: "gave the book up"
                if let TokenType::Particle(particle_sym) = self.peek().kind {
                    let verb_str = self.interner.resolve(verb).to_lowercase();
                    let particle_str = self.interner.resolve(particle_sym).to_lowercase();
                    if let Some((phrasal_lemma, _class)) = crate::lexicon::lookup_phrasal_verb(&verb_str, &particle_str) {
                        self.advance(); // consume the particle
                        verb = self.interner.intern(phrasal_lemma);
                    }
                }

                if let Some(obj_q) = obj_quantifier {
                    // Check for opaque verb with indefinite object (de dicto reading)
                    // For verbs like "seek", "want", "believe" with indefinite objects,
                    // use Term::Intension to represent the intensional (concept) reading
                    let verb_str = self.interner.resolve(verb).to_lowercase();
                    let is_opaque = lexicon::lookup_verb_db(&verb_str)
                        .map(|meta| meta.features.contains(&lexicon::Feature::Opaque))
                        .unwrap_or(false);

                    if is_opaque && matches!(obj_q, TokenType::Some) {
                        // De dicto reading: use Term::Intension for the theme
                        let intension_term = Term::Intension(object_np.noun);

                        // Register intensional entity for anaphora resolution
                        let noun_str = self.interner.resolve(object_np.noun).to_string();
                        let first_char = noun_str.chars().next().unwrap_or('X');
                        if first_char.is_alphabetic() {
                            let symbol = format!("^{}", first_char.to_uppercase());
                            self.register_entity(&symbol, &noun_str, Gender::Neuter, Number::Singular);
                        }

                        let event_var = self.get_event_var();
                        let mut modifiers = self.collect_adverbs();
                        let effective_time = self.pending_time.take().unwrap_or(verb_time);
                        match effective_time {
                            Time::Past => modifiers.push(self.interner.intern("Past")),
                            Time::Future => modifiers.push(self.interner.intern("Future")),
                            _ => {}
                        }

                        let subject_term_for_event = self.noun_phrase_to_term(&subject);
                        let roles = vec![
                            (ThematicRole::Agent, subject_term_for_event),
                            (ThematicRole::Theme, intension_term),
                        ];

                        let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                            event_var,
                            verb,
                            roles: self.ctx.roles.alloc_slice(roles),
                            modifiers: self.ctx.syms.alloc_slice(modifiers),
                        })));

                        return self.wrap_with_definiteness_full(&subject, neo_event);
                    }

                    let obj_var = self.next_var_name();
                    let type_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: object_np.noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(obj_var)]),
                    });

                    let obj_restriction = if self.check(&TokenType::That) || self.check(&TokenType::Who) {
                        self.advance();
                        let rel_clause = self.parse_relative_clause(obj_var)?;
                        self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: type_pred,
                            op: TokenType::And,
                            right: rel_clause,
                        })
                    } else {
                        type_pred
                    };

                    let event_var = self.get_event_var();
                    let mut modifiers = self.collect_adverbs();
                    let effective_time = self.pending_time.take().unwrap_or(verb_time);
                    match effective_time {
                        Time::Past => modifiers.push(self.interner.intern("Past")),
                        Time::Future => modifiers.push(self.interner.intern("Future")),
                        _ => {}
                    }

                    let subject_term_for_event = self.noun_phrase_to_term(&subject);
                    let roles = vec![
                        (ThematicRole::Agent, subject_term_for_event),
                        (ThematicRole::Theme, Term::Variable(obj_var)),
                    ];

                    // Capture template with object type for ellipsis reconstruction
                    // Use the object noun type instead of variable for reconstruction
                    let template_roles = vec![
                        (ThematicRole::Agent, subject_term_for_event),
                        (ThematicRole::Theme, Term::Constant(object_np.noun)),
                    ];
                    self.capture_event_template(verb, &template_roles, &modifiers);

                    let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                        event_var,
                        verb,
                        roles: self.ctx.roles.alloc_slice(roles),
                        modifiers: self.ctx.syms.alloc_slice(modifiers),
                    })));

                    let obj_kind = match obj_q {
                        TokenType::All => QuantifierKind::Universal,
                        TokenType::Some => QuantifierKind::Existential,
                        TokenType::No => QuantifierKind::Universal,
                        TokenType::Most => QuantifierKind::Most,
                        TokenType::Few => QuantifierKind::Few,
                        TokenType::Many => QuantifierKind::Many,
                        TokenType::Cardinal(n) => QuantifierKind::Cardinal(n),
                        TokenType::AtLeast(n) => QuantifierKind::AtLeast(n),
                        TokenType::AtMost(n) => QuantifierKind::AtMost(n),
                        _ => QuantifierKind::Existential,
                    };

                    let obj_body = match obj_q {
                        TokenType::All => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: obj_restriction,
                            op: TokenType::If,
                            right: neo_event,
                        }),
                        TokenType::No => {
                            let neg = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                                op: TokenType::Not,
                                operand: neo_event,
                            });
                            self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                left: obj_restriction,
                                op: TokenType::If,
                                right: neg,
                            })
                        }
                        _ => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: obj_restriction,
                            op: TokenType::And,
                            right: neo_event,
                        }),
                    };

                    return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                        kind: obj_kind,
                        variable: obj_var,
                        body: obj_body,
                        island_id: self.current_island,
                    }));
                } else {
                    let term = self.noun_phrase_to_term(&object_np);
                    object_term = Some(term.clone());
                    args.push(term);
                }
            } else if self.check_focus() {
                let focus_kind = if let TokenType::Focus(k) = self.advance().kind {
                    k
                } else {
                    FocusKind::Only
                };

                let event_var = self.get_event_var();
                let mut modifiers = self.collect_adverbs();
                let effective_time = self.pending_time.take().unwrap_or(verb_time);
                match effective_time {
                    Time::Past => modifiers.push(self.interner.intern("Past")),
                    Time::Future => modifiers.push(self.interner.intern("Future")),
                    _ => {}
                }

                let subject_term_for_event = self.noun_phrase_to_term(&subject);

                if self.check_preposition() {
                    let prep_token = self.advance().clone();
                    let prep_name = if let TokenType::Preposition(sym) = prep_token.kind {
                        sym
                    } else {
                        self.interner.intern("to")
                    };
                    let pp_obj = self.parse_noun_phrase(false)?;
                    let pp_obj_term = Term::Constant(pp_obj.noun);

                    let roles = vec![(ThematicRole::Agent, subject_term_for_event)];
                    let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                        event_var,
                        verb,
                        roles: self.ctx.roles.alloc_slice(roles),
                        modifiers: self.ctx.syms.alloc_slice(modifiers),
                    })));

                    let pp_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: prep_name,
                        args: self.ctx.terms.alloc_slice([Term::Variable(event_var), pp_obj_term]),
                    });

                    let with_pp = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: neo_event,
                        op: TokenType::And,
                        right: pp_pred,
                    });

                    let focused_ref = self.ctx.terms.alloc(pp_obj_term);
                    return Ok(self.ctx.exprs.alloc(LogicExpr::Focus {
                        kind: focus_kind,
                        focused: focused_ref,
                        scope: with_pp,
                    }));
                }

                let focused_np = self.parse_noun_phrase(false)?;
                let focused_term = self.noun_phrase_to_term(&focused_np);
                args.push(focused_term.clone());

                let roles = vec![
                    (ThematicRole::Agent, subject_term_for_event),
                    (ThematicRole::Theme, focused_term.clone()),
                ];

                let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                    event_var,
                    verb,
                    roles: self.ctx.roles.alloc_slice(roles),
                    modifiers: self.ctx.syms.alloc_slice(modifiers),
                })));

                let focused_ref = self.ctx.terms.alloc(focused_term);
                return Ok(self.ctx.exprs.alloc(LogicExpr::Focus {
                    kind: focus_kind,
                    focused: focused_ref,
                    scope: neo_event,
                }));
            } else if self.check_number() {
                // Handle "has 3 children" or "has cardinality aleph_0"
                let measure = self.parse_measure_phrase()?;

                // If there's a noun after the measure (for "3 children" where children wasn't a unit)
                if self.check_content_word() {
                    let noun_sym = self.consume_content_word()?;
                    // Build: Has(Subject, 3, Children) where 3 is the count
                    let count_term = *measure;
                    object_term = Some(count_term.clone());
                    args.push(count_term);
                    second_object_term = Some(Term::Constant(noun_sym));
                    args.push(Term::Constant(noun_sym));
                } else {
                    // Just the measure: "has cardinality 5"
                    object_term = Some(*measure);
                    args.push(*measure);
                }
            } else if self.check_content_word() || self.check_article() {
                let object = self.parse_noun_phrase(false)?;
                if let Some(adj) = object.superlative {
                    object_superlative = Some((adj, object.noun));
                }
                let term = self.noun_phrase_to_term(&object);
                object_term = Some(term.clone());
                args.push(term);

                // Check for distanced phrasal verb particle: "gave the book up"
                if let TokenType::Particle(particle_sym) = self.peek().kind {
                    let verb_str = self.interner.resolve(verb).to_lowercase();
                    let particle_str = self.interner.resolve(particle_sym).to_lowercase();
                    if let Some((phrasal_lemma, _class)) = crate::lexicon::lookup_phrasal_verb(&verb_str, &particle_str) {
                        self.advance(); // consume the particle
                        verb = self.interner.intern(phrasal_lemma);
                    }
                }

                // Check for "has cardinality aleph_0" pattern: noun followed by number
                if self.check_number() {
                    let measure = self.parse_measure_phrase()?;
                    second_object_term = Some(*measure);
                    args.push(*measure);
                }
                // Check for ditransitive: "John gave Mary a book"
                else {
                    let verb_str = self.interner.resolve(verb);
                    if Lexer::is_ditransitive_verb(verb_str) && (self.check_content_word() || self.check_article()) {
                        let second_np = self.parse_noun_phrase(false)?;
                        let second_term = self.noun_phrase_to_term(&second_np);
                        second_object_term = Some(second_term.clone());
                        args.push(second_term);
                    }
                }
            }

            let mut pp_predicates: Vec<&'a LogicExpr<'a>> = Vec::new();
            while self.check_preposition() || self.check_to() {
                let prep_token = self.advance().clone();
                let prep_name = if let TokenType::Preposition(sym) = prep_token.kind {
                    sym
                } else if matches!(prep_token.kind, TokenType::To) {
                    self.interner.intern("To")
                } else {
                    continue;
                };

                let pp_obj_term = if self.check(&TokenType::Reflexive) {
                    self.advance();
                    self.noun_phrase_to_term(&subject)
                } else if self.check_pronoun() {
                    let token = self.advance().clone();
                    if let TokenType::Pronoun { gender, number, .. } = token.kind {
                        let resolved = self.resolve_pronoun(gender, number)
                            .unwrap_or(unknown);
                        Term::Constant(resolved)
                    } else {
                        continue;
                    }
                } else if self.check_content_word() || self.check_article() {
                    let prep_obj = self.parse_noun_phrase(false)?;
                    self.noun_phrase_to_term(&prep_obj)
                } else {
                    continue;
                };

                if self.pp_attach_to_noun {
                    if let Some(ref obj) = object_term {
                        // NP-attachment: PP modifies the object noun
                        let pp_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: prep_name,
                            args: self.ctx.terms.alloc_slice([obj.clone(), pp_obj_term]),
                        });
                        pp_predicates.push(pp_pred);
                    } else {
                        args.push(pp_obj_term);
                    }
                } else {
                    // VP-attachment: PP modifies the event (instrument/manner)
                    let event_sym = self.get_event_var();
                    let pp_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: prep_name,
                        args: self.ctx.terms.alloc_slice([Term::Variable(event_sym), pp_obj_term]),
                    });
                    pp_predicates.push(pp_pred);
                }
            }

            // Check for trailing relative clause on object NP: "the girl with the telescope that laughed"
            if self.check(&TokenType::That) || self.check(&TokenType::Who) {
                self.advance();
                let rel_var = self.next_var_name();
                let rel_pred = self.parse_relative_clause(rel_var)?;
                pp_predicates.push(rel_pred);
            }

            // Collect any trailing adverbs FIRST (before building NeoEvent)
            let mut modifiers = self.collect_adverbs();

            // Add temporal modifier as part of event semantics
            let effective_time = self.pending_time.take().unwrap_or(verb_time);
            match effective_time {
                Time::Past => modifiers.push(self.interner.intern("Past")),
                Time::Future => modifiers.push(self.interner.intern("Future")),
                _ => {}
            }

            // Add aspect modifier if applicable
            if verb_aspect == Aspect::Progressive {
                modifiers.push(self.interner.intern("Progressive"));
            } else if verb_aspect == Aspect::Perfect {
                modifiers.push(self.interner.intern("Perfect"));
            }

            // Build thematic roles for Neo-Davidsonian event semantics
            let mut roles: Vec<(ThematicRole, Term<'a>)> = Vec::new();
            roles.push((ThematicRole::Agent, subject_term));
            if let Some(second_obj) = second_object_term {
                // Ditransitive: first object is Recipient, second is Theme
                if let Some(first_obj) = object_term {
                    roles.push((ThematicRole::Recipient, first_obj));
                }
                roles.push((ThematicRole::Theme, second_obj));
            } else if let Some(obj) = object_term {
                // Normal transitive: object is Theme
                roles.push((ThematicRole::Theme, obj));
            }

            // Create event variable
            let event_var = self.get_event_var();

            // Capture template for ellipsis reconstruction before consuming roles
            self.capture_event_template(verb, &roles, &modifiers);

            // Create NeoEvent structure with all modifiers including time/aspect
            let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                event_var,
                verb,
                roles: self.ctx.roles.alloc_slice(roles),
                modifiers: self.ctx.syms.alloc_slice(modifiers),
            })));

            // Combine with PP predicates if any
            let with_pps = if pp_predicates.is_empty() {
                neo_event
            } else {
                let mut combined = neo_event;
                for pp in pp_predicates {
                    combined = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: combined,
                        op: TokenType::And,
                        right: pp,
                    });
                }
                combined
            };

            // Apply aspectual operators based on verb class
            let with_aspect = if verb_aspect == Aspect::Progressive {
                // Semelfactive + Progressive → Iterative
                if verb_class == crate::lexicon::VerbClass::Semelfactive {
                    self.ctx.exprs.alloc(LogicExpr::Aspectual {
                        operator: AspectOperator::Iterative,
                        body: with_pps,
                    })
                } else {
                    // Other verbs + Progressive → Progressive
                    self.ctx.exprs.alloc(LogicExpr::Aspectual {
                        operator: AspectOperator::Progressive,
                        body: with_pps,
                    })
                }
            } else if verb_aspect == Aspect::Perfect {
                self.ctx.exprs.alloc(LogicExpr::Aspectual {
                    operator: AspectOperator::Perfect,
                    body: with_pps,
                })
            } else if effective_time == Time::Present && verb_aspect == Aspect::Simple {
                // Non-state verbs in simple present get Habitual reading
                if !verb_class.is_stative() {
                    self.ctx.exprs.alloc(LogicExpr::Aspectual {
                        operator: AspectOperator::Habitual,
                        body: with_pps,
                    })
                } else {
                    // State verbs in present: direct predication
                    with_pps
                }
            } else {
                with_pps
            };

            let with_adverbs = with_aspect;

            // Check for temporal anchor adverb at end of sentence
            let with_temporal = if self.check_temporal_adverb() {
                let anchor = if let TokenType::TemporalAdverb(adv) = self.advance().kind.clone() {
                    adv
                } else {
                    panic!("Expected temporal adverb");
                };
                self.ctx.exprs.alloc(LogicExpr::TemporalAnchor {
                    anchor,
                    body: with_adverbs,
                })
            } else {
                with_adverbs
            };

            let wrapped = self.wrap_with_definiteness_full(&subject, with_temporal)?;

            // Add superlative constraint for object NP if applicable
            if let Some((adj, noun)) = object_superlative {
                let superlative_expr = self.ctx.exprs.alloc(LogicExpr::Superlative {
                    adjective: adj,
                    subject: self.ctx.terms.alloc(Term::Constant(noun)),
                    domain: noun,
                });
                return Ok(self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: wrapped,
                    op: TokenType::And,
                    right: superlative_expr,
                }));
            }

            return Ok(wrapped);
        }

        Ok(self.ctx.exprs.alloc(LogicExpr::Atom(subject.noun)))
    }

    fn check_preposition(&self) -> bool {
        matches!(self.peek().kind, TokenType::Preposition(_))
    }

    fn check_by_preposition(&self) -> bool {
        if let TokenType::Preposition(p) = self.peek().kind {
            p.is(self.interner, "by")
        } else {
            false
        }
    }

    fn check_preposition_is(&self, word: &str) -> bool {
        if let TokenType::Preposition(p) = self.peek().kind {
            p.is(self.interner, word)
        } else {
            false
        }
    }

    /// Check if current token is a word (noun/adj/verb lexeme) matching the given string
    fn check_word(&self, word: &str) -> bool {
        let token = self.peek();
        let lexeme = self.interner.resolve(token.lexeme);
        lexeme.eq_ignore_ascii_case(word)
    }

    fn check_to_preposition(&self) -> bool {
        if let TokenType::Preposition(p) = self.peek().kind {
            p.is(self.interner, "to")
        } else {
            false
        }
    }

    fn check_content_word(&self) -> bool {
        match &self.peek().kind {
            TokenType::Noun(_)
            | TokenType::Adjective(_)
            | TokenType::NonIntersectiveAdjective(_)
            | TokenType::Verb { .. }
            | TokenType::ProperName(_)
            | TokenType::Article(_) => true,
            TokenType::Ambiguous { primary, alternatives } => {
                Self::is_content_word_type(primary)
                    || alternatives.iter().any(Self::is_content_word_type)
            }
            _ => false,
        }
    }

    fn is_content_word_type(t: &TokenType) -> bool {
        matches!(
            t,
            TokenType::Noun(_)
                | TokenType::Adjective(_)
                | TokenType::NonIntersectiveAdjective(_)
                | TokenType::Verb { .. }
                | TokenType::ProperName(_)
                | TokenType::Article(_)
        )
    }

    fn check_verb(&self) -> bool {
        match &self.peek().kind {
            TokenType::Verb { .. } => true,
            TokenType::Ambiguous { primary, alternatives } => {
                if self.noun_priority_mode {
                    return false;
                }
                matches!(**primary, TokenType::Verb { .. })
                    || alternatives.iter().any(|t| matches!(t, TokenType::Verb { .. }))
            }
            _ => false,
        }
    }

    fn check_adverb(&self) -> bool {
        matches!(self.peek().kind, TokenType::Adverb(_))
    }

    fn check_performative(&self) -> bool {
        matches!(self.peek().kind, TokenType::Performative(_))
    }

    fn collect_adverbs(&mut self) -> Vec<Symbol> {
        let mut adverbs = Vec::new();
        while self.check_adverb() {
            if let TokenType::Adverb(adv) = self.advance().kind.clone() {
                adverbs.push(adv);
            }
            // Skip "and" between adverbs
            if self.check(&TokenType::And) {
                self.advance();
            }
        }
        adverbs
    }

    fn check_auxiliary(&self) -> bool {
        matches!(self.peek().kind, TokenType::Auxiliary(_))
    }

    fn check_to(&self) -> bool {
        matches!(self.peek().kind, TokenType::To)
    }


    fn consume_verb(&mut self) -> Symbol {
        let t = self.advance().clone();
        match t.kind {
            TokenType::Verb { lemma, .. } => lemma,
            TokenType::Ambiguous { primary, .. } => match *primary {
                TokenType::Verb { lemma, .. } => lemma,
                _ => panic!("Expected verb in Ambiguous primary, got {:?}", primary),
            },
            _ => panic!("Expected verb, got {:?}", t.kind),
        }
    }

    fn consume_verb_with_metadata(&mut self) -> (Symbol, Time, Aspect, VerbClass) {
        let t = self.advance().clone();
        match t.kind {
            TokenType::Verb { lemma, time, aspect, class } => (lemma, time, aspect, class),
            TokenType::Ambiguous { primary, .. } => match *primary {
                TokenType::Verb { lemma, time, aspect, class } => (lemma, time, aspect, class),
                _ => panic!("Expected verb in Ambiguous primary, got {:?}", primary),
            },
            _ => panic!("Expected verb, got {:?}", t.kind),
        }
    }

    fn match_token(&mut self, types: &[TokenType]) -> bool {
        for t in types {
            if self.check(t) {
                self.advance();
                return true;
            }
        }
        false
    }

    fn check_quantifier(&self) -> bool {
        matches!(
            self.peek().kind,
            TokenType::All
                | TokenType::No
                | TokenType::Some
                | TokenType::Any
                | TokenType::Most
                | TokenType::Few
                | TokenType::Many
                | TokenType::Cardinal(_)
                | TokenType::AtLeast(_)
                | TokenType::AtMost(_)
        )
    }

    fn check_npi_quantifier(&self) -> bool {
        matches!(
            self.peek().kind,
            TokenType::Nobody | TokenType::Nothing | TokenType::NoOne
        )
    }

    fn check_npi_object(&self) -> bool {
        matches!(
            self.peek().kind,
            TokenType::Anything | TokenType::Anyone
        )
    }

    fn check_temporal_npi(&self) -> bool {
        matches!(
            self.peek().kind,
            TokenType::Ever | TokenType::Never
        )
    }

    fn parse_npi_quantified(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let npi_token = self.advance().kind.clone();
        let var_name = self.next_var_name();

        let (restriction_name, is_person) = match npi_token {
            TokenType::Nobody | TokenType::NoOne => ("Person", true),
            TokenType::Nothing => ("Thing", false),
            _ => ("Thing", false),
        };

        let restriction_sym = self.interner.intern(restriction_name);
        let subject_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
            name: restriction_sym,
            args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
        });

        self.negative_depth += 1;

        let verb = self.consume_verb();

        if self.check_npi_object() {
            let obj_npi_token = self.advance().kind.clone();
            let obj_var = self.next_var_name();

            let obj_restriction_name = match obj_npi_token {
                TokenType::Anything => "Thing",
                TokenType::Anyone => "Person",
                _ => "Thing",
            };

            let obj_restriction_sym = self.interner.intern(obj_restriction_name);
            let obj_restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: obj_restriction_sym,
                args: self.ctx.terms.alloc_slice([Term::Variable(obj_var)]),
            });

            let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice([Term::Variable(var_name), Term::Variable(obj_var)]),
            });

            let verb_and_obj = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: obj_restriction,
                op: TokenType::And,
                right: verb_pred,
            });

            let inner_existential = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                kind: crate::ast::QuantifierKind::Existential,
                variable: obj_var,
                body: verb_and_obj,
                island_id: self.current_island,
            });

            self.negative_depth -= 1;

            let negated = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                op: TokenType::Not,
                operand: inner_existential,
            });

            let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: subject_pred,
                op: TokenType::If,
                right: negated,
            });

            return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                kind: crate::ast::QuantifierKind::Universal,
                variable: var_name,
                body,
                island_id: self.current_island,
            }));
        }

        let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
            name: verb,
            args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
        });

        self.negative_depth -= 1;

        let negated_verb = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
            op: TokenType::Not,
            operand: verb_pred,
        });

        let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
            left: subject_pred,
            op: TokenType::If,
            right: negated_verb,
        });

        Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
            kind: crate::ast::QuantifierKind::Universal,
            variable: var_name,
            body,
            island_id: self.current_island,
        }))
    }

    fn parse_temporal_npi(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let npi_token = self.advance().kind.clone();
        let is_never = matches!(npi_token, TokenType::Never);

        let subject = self.parse_noun_phrase(true)?;

        if is_never {
            self.negative_depth += 1;
        }

        let verb = self.consume_verb();
        let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
            name: verb,
            args: self.ctx.terms.alloc_slice([Term::Constant(subject.noun)]),
        });

        if is_never {
            self.negative_depth -= 1;
            Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                op: TokenType::Not,
                operand: verb_pred,
            }))
        } else {
            Ok(verb_pred)
        }
    }

    fn check(&self, kind: &TokenType) -> bool {
        if self.is_at_end() {
            return false;
        }
        std::mem::discriminant(&self.peek().kind) == std::mem::discriminant(kind)
    }

    fn check_any(&self, kinds: &[TokenType]) -> bool {
        if self.is_at_end() {
            return false;
        }
        let current = std::mem::discriminant(&self.peek().kind);
        kinds.iter().any(|k| std::mem::discriminant(k) == current)
    }

    fn check_article(&self) -> bool {
        matches!(self.peek().kind, TokenType::Article(_))
    }

    fn advance(&mut self) -> &Token {
        if !self.is_at_end() {
            self.current += 1;
        }
        self.previous()
    }

    fn is_at_end(&self) -> bool {
        self.peek().kind == TokenType::EOF
    }

    fn peek(&self) -> &Token {
        &self.tokens[self.current]
    }

    /// Phase 35: Check if the next token (after current) is a string literal.
    /// Used to distinguish causal `because` from Trust's `because "reason"`.
    fn peek_next_is_string_literal(&self) -> bool {
        self.tokens.get(self.current + 1)
            .map(|t| matches!(t.kind, TokenType::StringLiteral(_)))
            .unwrap_or(false)
    }

    fn previous(&self) -> &Token {
        &self.tokens[self.current - 1]
    }

    fn current_span(&self) -> crate::token::Span {
        self.peek().span
    }

    fn consume(&mut self, kind: TokenType) -> ParseResult<&Token> {
        if self.check(&kind) {
            Ok(self.advance())
        } else {
            Err(ParseError {
                kind: ParseErrorKind::UnexpectedToken {
                    expected: kind,
                    found: self.peek().kind.clone(),
                },
                span: self.current_span(),
            })
        }
    }

    fn consume_content_word(&mut self) -> ParseResult<Symbol> {
        let t = self.advance().clone();
        match t.kind {
            TokenType::Noun(s) | TokenType::Adjective(s) | TokenType::NonIntersectiveAdjective(s) => Ok(s),
            // Phase 35: Allow single-letter articles (a, an) to be used as variable names
            TokenType::Article(_) => Ok(t.lexeme),
            // Phase 35: Allow numeric literals as content words (e.g., "equal to 42")
            TokenType::Number(s) => Ok(s),
            TokenType::ProperName(s) => {
                let s_str = self.interner.resolve(s);

                // In imperative mode, reject unknown or moved entities
                if self.mode == ParserMode::Imperative {
                    use crate::context::OwnershipState;

                    let is_known = self.context.as_ref()
                        .map(|ctx| ctx.has_entity_by_noun_class(s_str))
                        .unwrap_or(false);

                    if !is_known {
                        return Err(ParseError {
                            kind: ParseErrorKind::UndefinedVariable { name: s_str.to_string() },
                            span: self.current_span(),
                        });
                    }

                    // Check for use-after-move
                    let ownership = self.context.as_ref()
                        .and_then(|ctx| ctx.get_ownership(s_str));

                    if ownership == Some(OwnershipState::Moved) {
                        return Err(ParseError {
                            kind: ParseErrorKind::UseAfterMove { name: s_str.to_string() },
                            span: self.current_span(),
                        });
                    }
                }

                let gender = Self::infer_gender(s_str);
                let symbol_str = s_str.chars().next().unwrap().to_string();
                let noun_class = s_str.to_string();
                self.register_entity(&symbol_str, &noun_class, gender, Number::Singular);
                Ok(s)
            }
            TokenType::Verb { lemma, .. } => Ok(lemma),
            TokenType::Ambiguous { primary, .. } => {
                match *primary {
                    TokenType::Noun(s) | TokenType::Adjective(s) | TokenType::NonIntersectiveAdjective(s) => Ok(s),
                    TokenType::Verb { lemma, .. } => Ok(lemma),
                    TokenType::ProperName(s) => Ok(s),
                    _ => Err(ParseError {
                        kind: ParseErrorKind::ExpectedContentWord { found: *primary },
                        span: self.current_span(),
                    }),
                }
            }
            other => Err(ParseError {
                kind: ParseErrorKind::ExpectedContentWord { found: other },
                span: self.current_span(),
            }),
        }
    }

    fn consume_copula(&mut self) -> ParseResult<()> {
        if self.match_token(&[TokenType::Is, TokenType::Are, TokenType::Was, TokenType::Were]) {
            Ok(())
        } else {
            Err(ParseError {
                kind: ParseErrorKind::ExpectedCopula,
                span: self.current_span(),
            })
        }
    }

    fn check_comparative(&self) -> bool {
        matches!(self.peek().kind, TokenType::Comparative(_))
    }

    fn is_contact_clause_pattern(&self) -> bool {
        // Detect "The cat [the dog chased] ran" pattern
        // Also handles nested: "The rat [the cat [the dog chased] ate] died"
        let mut pos = self.current;

        // Skip the article we're at
        if pos < self.tokens.len() && matches!(self.tokens[pos].kind, TokenType::Article(_)) {
            pos += 1;
        } else {
            return false;
        }

        // Skip adjectives
        while pos < self.tokens.len() && matches!(self.tokens[pos].kind, TokenType::Adjective(_)) {
            pos += 1;
        }

        // Must have noun/proper name (embedded subject)
        if pos < self.tokens.len() && matches!(self.tokens[pos].kind, TokenType::Noun(_) | TokenType::ProperName(_) | TokenType::Adjective(_)) {
            pos += 1;
        } else {
            return false;
        }

        // Must have verb OR another article (nested contact clause) after
        pos < self.tokens.len() && matches!(self.tokens[pos].kind, TokenType::Verb { .. } | TokenType::Article(_))
    }

    fn check_superlative(&self) -> bool {
        matches!(self.peek().kind, TokenType::Superlative(_))
    }

    fn check_scopal_adverb(&self) -> bool {
        matches!(self.peek().kind, TokenType::ScopalAdverb(_))
    }

    fn check_temporal_adverb(&self) -> bool {
        matches!(self.peek().kind, TokenType::TemporalAdverb(_))
    }

    fn check_non_intersective_adjective(&self) -> bool {
        matches!(self.peek().kind, TokenType::NonIntersectiveAdjective(_))
    }

    fn check_focus(&self) -> bool {
        matches!(self.peek().kind, TokenType::Focus(_))
    }

    fn check_measure(&self) -> bool {
        matches!(self.peek().kind, TokenType::Measure(_))
    }

    fn check_presup_trigger(&self) -> bool {
        match &self.peek().kind {
            TokenType::PresupTrigger(_) => true,
            TokenType::Verb { lemma, .. } => {
                let s = self.interner.resolve(*lemma).to_lowercase();
                crate::lexicon::lookup_presup_trigger(&s).is_some()
            }
            _ => false,
        }
    }

    fn is_followed_by_np_object(&self) -> bool {
        if self.current + 1 >= self.tokens.len() {
            return false;
        }
        let next = &self.tokens[self.current + 1].kind;
        matches!(next,
            TokenType::ProperName(_) |
            TokenType::Article(_) |
            TokenType::Noun(_) |
            TokenType::Pronoun { .. } |
            TokenType::Reflexive |
            TokenType::Who |
            TokenType::What |
            TokenType::Where |
            TokenType::When |
            TokenType::Why
        )
    }

    fn is_followed_by_gerund(&self) -> bool {
        if self.current + 1 >= self.tokens.len() {
            return false;
        }
        matches!(self.tokens[self.current + 1].kind, TokenType::Verb { .. })
    }

}


```

---

### ClauseParsing Trait

**File:** `src/parser/clause.rs`

Extension trait for sentence-level parsing: conditionals (if/then), conjunctions (and/or/but), relative clauses (who/that/which), gapped clauses (ellipsis via verb borrowing), counterfactual antecedents/consequents. Handles complete clause detection and verb extraction. **VP Ellipsis:** try_parse_ellipsis() detects pattern: Subject + Auxiliary (does/do/can/could/would/may/must/should) + (not)? + Terminator (too/also/period/EOF). Reconstructs NeoEvent with new Agent but preserves verb and non-agent roles from last_event_template. Applies modal wrapper and negation as needed.

```rust
use super::modal::ModalParsing;
use super::noun::NounParsing;
use super::pragmatics::PragmaticsParsing;
use super::quantifier::QuantifierParsing;
use super::question::QuestionParsing;
use super::verb::LogicVerbParsing;
use super::{ParseResult, Parser};
use crate::ast::{LogicExpr, NeoEventData, NounPhrase, Term, ThematicRole};
use crate::error::{ParseError, ParseErrorKind};
use crate::intern::Symbol;
use crate::token::TokenType;

pub trait ClauseParsing<'a, 'ctx, 'int> {
    fn parse_sentence(&mut self) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_conditional(&mut self) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_disjunction(&mut self) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_conjunction(&mut self) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_relative_clause(&mut self, gap_var: Symbol) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_gapped_clause(&mut self, borrowed_verb: Symbol) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_counterfactual_antecedent(&mut self) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_counterfactual_consequent(&mut self) -> ParseResult<&'a LogicExpr<'a>>;
    fn check_wh_word(&self) -> bool;
    fn is_counterfactual_context(&self) -> bool;
    fn is_complete_clause(&self, expr: &LogicExpr<'a>) -> bool;
    fn extract_verb_from_expr(&self, expr: &LogicExpr<'a>) -> Option<Symbol>;
    fn try_parse_ellipsis(&mut self) -> Option<ParseResult<&'a LogicExpr<'a>>>;
    fn check_ellipsis_auxiliary(&self) -> bool;
    fn check_ellipsis_terminator(&self) -> bool;
}

impl<'a, 'ctx, 'int> ClauseParsing<'a, 'ctx, 'int> for Parser<'a, 'ctx, 'int> {
    fn parse_sentence(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        // Check for ellipsis pattern: "Mary does too." / "Mary can too."
        if let Some(result) = self.try_parse_ellipsis() {
            return result;
        }

        if self.check_verb() {
            let verb_pos = self.current;
            let mut temp_pos = self.current + 1;
            while temp_pos < self.tokens.len() {
                if matches!(self.tokens[temp_pos].kind, TokenType::Exclamation) {
                    self.current = verb_pos;
                    let verb = self.consume_verb();
                    while !matches!(self.peek().kind, TokenType::Exclamation | TokenType::EOF) {
                        self.advance();
                    }
                    if self.check(&TokenType::Exclamation) {
                        self.advance();
                    }
                    let addressee = self.interner.intern("addressee");
                    let action = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: verb,
                        args: self.ctx.terms.alloc_slice([Term::Variable(addressee)]),
                    });
                    return Ok(self.ctx.exprs.alloc(LogicExpr::Imperative { action }));
                }
                if matches!(self.tokens[temp_pos].kind, TokenType::Period | TokenType::EOF) {
                    break;
                }
                temp_pos += 1;
            }
        }

        if self.check_wh_word() {
            return self.parse_wh_question();
        }

        if self.check(&TokenType::Does)
            || self.check(&TokenType::Do)
            || self.check(&TokenType::Is)
            || self.check(&TokenType::Are)
            || self.check(&TokenType::Was)
            || self.check(&TokenType::Were)
            || self.check(&TokenType::Would)
            || self.check(&TokenType::Could)
            || self.check(&TokenType::Can)
        {
            return self.parse_yes_no_question();
        }

        if self.match_token(&[TokenType::If]) {
            return self.parse_conditional();
        }

        if self.check_modal() {
            self.advance();
            return self.parse_modal();
        }

        if self.match_token(&[TokenType::Not]) {
            self.negative_depth += 1;
            let inner = self.parse_sentence()?;
            self.negative_depth -= 1;
            return Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                op: TokenType::Not,
                operand: inner,
            }));
        }

        self.parse_disjunction()
    }

    fn check_wh_word(&self) -> bool {
        if matches!(
            self.peek().kind,
            TokenType::Who
                | TokenType::What
                | TokenType::Where
                | TokenType::When
                | TokenType::Why
        ) {
            return true;
        }
        if self.check_preposition() && self.current + 1 < self.tokens.len() {
            matches!(
                self.tokens[self.current + 1].kind,
                TokenType::Who
                    | TokenType::What
                    | TokenType::Where
                    | TokenType::When
                    | TokenType::Why
            )
        } else {
            false
        }
    }

    fn parse_conditional(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let is_counterfactual = self.is_counterfactual_context();

        let antecedent = self.parse_counterfactual_antecedent()?;

        if self.check(&TokenType::Comma) {
            self.advance();
        }

        if self.check(&TokenType::Then) {
            self.advance();
        }

        let consequent = self.parse_counterfactual_consequent()?;

        Ok(if is_counterfactual {
            self.ctx.exprs.alloc(LogicExpr::Counterfactual {
                antecedent,
                consequent,
            })
        } else {
            self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: antecedent,
                op: TokenType::If,
                right: consequent,
            })
        })
    }

    fn is_counterfactual_context(&self) -> bool {
        for i in 0..5 {
            if self.current + i >= self.tokens.len() {
                break;
            }
            let token = &self.tokens[self.current + i];
            if matches!(token.kind, TokenType::Were | TokenType::Had) {
                return true;
            }
            if matches!(token.kind, TokenType::Comma | TokenType::Period) {
                break;
            }
        }
        false
    }

    fn parse_counterfactual_antecedent(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let unknown = self.interner.intern("?");
        if self.check_content_word() || self.check_pronoun() {
            let subject = if self.check_pronoun() {
                let token = self.advance().clone();
                if let TokenType::Pronoun { gender, number, .. } = token.kind {
                    self.resolve_pronoun(gender, number).unwrap_or(unknown)
                } else {
                    unknown
                }
            } else {
                self.parse_noun_phrase(true)?.noun
            };

            // Handle presupposition triggers in antecedent: "If John stopped smoking, ..."
            // Only trigger if followed by gerund complement
            if self.check_presup_trigger() && self.is_followed_by_gerund() {
                let presup_kind = match self.advance().kind {
                    TokenType::PresupTrigger(kind) => kind,
                    TokenType::Verb { lemma, .. } => {
                        let s = self.interner.resolve(lemma).to_lowercase();
                        crate::lexicon::lookup_presup_trigger(&s)
                            .expect("Lexicon mismatch: Verb flagged as trigger but lookup failed")
                    }
                    _ => panic!("Expected presupposition trigger"),
                };
                let np = NounPhrase {
                    noun: subject,
                    definiteness: None,
                    adjectives: &[],
                    possessor: None,
                    pps: &[],
                    superlative: None,
                };
                return self.parse_presupposition(&np, presup_kind);
            }

            if self.check(&TokenType::Were) {
                self.advance();
                let predicate = if self.check_pronoun() {
                    let token = self.advance().clone();
                    if let TokenType::Pronoun { gender, number, .. } = token.kind {
                        let token_text = self.interner.resolve(token.lexeme);
                        if token_text.eq_ignore_ascii_case("i") {
                            self.interner.intern("Speaker")
                        } else if token_text.eq_ignore_ascii_case("you") {
                            self.interner.intern("Addressee")
                        } else {
                            self.resolve_pronoun(gender, number).unwrap_or(unknown)
                        }
                    } else {
                        unknown
                    }
                } else {
                    self.consume_content_word()?
                };
                let be = self.interner.intern("Be");
                return Ok(self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: be,
                    args: self.ctx.terms.alloc_slice([
                        Term::Constant(subject),
                        Term::Constant(predicate),
                    ]),
                }));
            }

            if self.check(&TokenType::Had) {
                self.advance();
                let verb = self.consume_content_word()?;
                let main_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb,
                    args: self.ctx.terms.alloc_slice([Term::Constant(subject)]),
                });

                // Handle "because" causal clause in antecedent
                // Phase 35: Do NOT consume if followed by string literal (Trust justification)
                if self.check(&TokenType::Because) && !self.peek_next_is_string_literal() {
                    self.advance();
                    let cause = self.parse_atom()?;
                    return Ok(self.ctx.exprs.alloc(LogicExpr::Causal {
                        effect: main_pred,
                        cause,
                    }));
                }

                return Ok(main_pred);
            }

            return self.parse_predicate_with_subject(subject);
        }

        self.parse_sentence()
    }

    fn parse_counterfactual_consequent(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let unknown = self.interner.intern("?");
        if self.check_content_word() || self.check_pronoun() {
            let subject = if self.check_pronoun() {
                let token = self.advance().clone();
                if let TokenType::Pronoun { gender, number, .. } = token.kind {
                    self.resolve_pronoun(gender, number).unwrap_or(unknown)
                } else {
                    unknown
                }
            } else {
                self.parse_noun_phrase(true)?.noun
            };

            if self.check(&TokenType::Would) {
                self.advance();
                if self.check_content_word() {
                    let next_word = self.interner.resolve(self.peek().lexeme).to_lowercase();
                    if next_word == "have" {
                        self.advance();
                    }
                }
                let verb = self.consume_content_word()?;
                return Ok(self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb,
                    args: self.ctx.terms.alloc_slice([Term::Constant(subject)]),
                }));
            }

            return self.parse_predicate_with_subject(subject);
        }

        self.parse_sentence()
    }

    fn extract_verb_from_expr(&self, expr: &LogicExpr<'a>) -> Option<Symbol> {
        match expr {
            LogicExpr::Predicate { name, .. } => Some(*name),
            LogicExpr::NeoEvent(data) => Some(data.verb),
            LogicExpr::BinaryOp { right, .. } => self.extract_verb_from_expr(right),
            LogicExpr::Modal { operand, .. } => self.extract_verb_from_expr(operand),
            LogicExpr::Presupposition { assertion, .. } => self.extract_verb_from_expr(assertion),
            LogicExpr::Control { verb, .. } => Some(*verb),
            LogicExpr::Temporal { body, .. } => self.extract_verb_from_expr(body),
            LogicExpr::TemporalAnchor { body, .. } => self.extract_verb_from_expr(body),
            LogicExpr::Aspectual { body, .. } => self.extract_verb_from_expr(body),
            LogicExpr::Quantifier { body, .. } => self.extract_verb_from_expr(body),
            _ => None,
        }
    }

    fn parse_gapped_clause(&mut self, borrowed_verb: Symbol) -> ParseResult<&'a LogicExpr<'a>> {
        let subject = self.parse_noun_phrase(true)?;

        if self.check(&TokenType::Comma) {
            self.advance();
        }

        let subject_term = self.noun_phrase_to_term(&subject);
        let event_var = self.get_event_var();

        // Check if next token is temporal adverb (gapping with adjunct only)
        if self.check_temporal_adverb() {
            let adv_sym = if let TokenType::TemporalAdverb(sym) = self.advance().kind {
                sym
            } else {
                self.interner.intern("?")
            };

            return Ok(self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                event_var,
                verb: borrowed_verb,
                roles: self.ctx.roles.alloc_slice(vec![
                    (ThematicRole::Agent, subject_term),
                ]),
                modifiers: self.ctx.syms.alloc_slice(vec![adv_sym]),
            }))));
        }

        // Standard gapping: subject + object
        let object = self.parse_noun_phrase(false)?;
        let object_term = self.noun_phrase_to_term(&object);

        let roles = vec![
            (ThematicRole::Agent, subject_term),
            (ThematicRole::Theme, object_term),
        ];

        Ok(self
            .ctx
            .exprs
            .alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                event_var,
                verb: borrowed_verb,
                roles: self.ctx.roles.alloc_slice(roles),
                modifiers: self.ctx.syms.alloc_slice(vec![]),
            }))))
    }

    fn is_complete_clause(&self, expr: &LogicExpr<'a>) -> bool {
        match expr {
            LogicExpr::Atom(_) => false,
            LogicExpr::Predicate { .. } => true,
            LogicExpr::Quantifier { .. } => true,
            LogicExpr::Modal { .. } => true,
            LogicExpr::Temporal { .. } => true,
            LogicExpr::Aspectual { .. } => true,
            LogicExpr::BinaryOp { .. } => true,
            LogicExpr::UnaryOp { .. } => true,
            LogicExpr::Control { .. } => true,
            LogicExpr::Presupposition { .. } => true,
            LogicExpr::Categorical(_) => true,
            LogicExpr::Relation(_) => true,
            _ => true,
        }
    }

    /// Parse disjunction (Or/Iff) - lowest precedence logical connectives.
    /// Calls parse_conjunction for operands to ensure And binds tighter.
    fn parse_disjunction(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let mut expr = self.parse_conjunction()?;

        while self.check(&TokenType::Comma)
            || self.check(&TokenType::Or)
            || self.check(&TokenType::Iff)
        {
            if self.check(&TokenType::Comma) {
                self.advance();
            }
            if !self.match_token(&[TokenType::Or, TokenType::Iff]) {
                break;
            }
            let operator = self.previous().kind.clone();
            self.current_island += 1;

            let saved_pos = self.current;
            let standard_attempt = self.try_parse(|p| p.parse_conjunction());

            let use_gapping = match &standard_attempt {
                Some(right) => {
                    !self.is_complete_clause(right)
                        && (self.check(&TokenType::Comma) || self.check_content_word())
                }
                None => true,
            };

            if !use_gapping {
                if let Some(right) = standard_attempt {
                    expr = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: expr,
                        op: operator,
                        right,
                    });
                }
            } else {
                self.current = saved_pos;

                let borrowed_verb = self.extract_verb_from_expr(expr).ok_or(ParseError {
                    kind: ParseErrorKind::GappingResolutionFailed,
                    span: self.current_span(),
                })?;

                let right = self.parse_gapped_clause(borrowed_verb)?;

                expr = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: expr,
                    op: operator,
                    right,
                });
            }
        }

        Ok(expr)
    }

    /// Parse conjunction (And) - higher precedence than Or.
    /// Calls parse_atom for operands.
    fn parse_conjunction(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let mut expr = self.parse_atom()?;

        // Handle causal "because" at conjunction level
        // Phase 35: Do NOT consume if followed by string literal (Trust justification)
        if self.check(&TokenType::Because) && !self.peek_next_is_string_literal() {
            self.advance();
            let cause = self.parse_atom()?;
            return Ok(self.ctx.exprs.alloc(LogicExpr::Causal {
                effect: expr,
                cause,
            }));
        }

        while self.check(&TokenType::Comma) || self.check(&TokenType::And) {
            if self.check(&TokenType::Comma) {
                self.advance();
            }
            if !self.match_token(&[TokenType::And]) {
                break;
            }
            let operator = self.previous().kind.clone();
            self.current_island += 1;

            let saved_pos = self.current;
            let standard_attempt = self.try_parse(|p| p.parse_atom());

            let use_gapping = match &standard_attempt {
                Some(right) => {
                    !self.is_complete_clause(right)
                        && (self.check(&TokenType::Comma) || self.check_content_word())
                }
                None => true,
            };

            if !use_gapping {
                if let Some(right) = standard_attempt {
                    expr = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: expr,
                        op: operator,
                        right,
                    });
                }
            } else {
                self.current = saved_pos;

                let borrowed_verb = self.extract_verb_from_expr(expr).ok_or(ParseError {
                    kind: ParseErrorKind::GappingResolutionFailed,
                    span: self.current_span(),
                })?;

                let right = self.parse_gapped_clause(borrowed_verb)?;

                expr = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: expr,
                    op: operator,
                    right,
                });
            }
        }

        Ok(expr)
    }

    fn parse_relative_clause(&mut self, gap_var: Symbol) -> ParseResult<&'a LogicExpr<'a>> {
        if self.check_verb() {
            return self.parse_verb_phrase_for_restriction(gap_var);
        }

        if self.check_content_word() || self.check_article() {
            let rel_subject = self.parse_noun_phrase_for_relative()?;

            let nested_relative = if matches!(self.peek().kind, TokenType::Article(_)) {
                let nested_var = self.next_var_name();
                Some((nested_var, self.parse_relative_clause(nested_var)?))
            } else {
                None
            };

            if self.check_verb() {
                let verb = self.consume_verb();

                let mut roles: Vec<(ThematicRole, Term<'a>)> = vec![
                    (ThematicRole::Agent, Term::Constant(rel_subject.noun)),
                    (ThematicRole::Theme, Term::Variable(gap_var)),
                ];

                while self.check_to_preposition() {
                    self.advance();
                    if self.check_content_word() || self.check_article() {
                        let recipient = self.parse_noun_phrase(false)?;
                        roles.push((ThematicRole::Recipient, Term::Constant(recipient.noun)));
                    }
                }

                let event_var = self.get_event_var();
                let this_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                    event_var,
                    verb,
                    roles: self.ctx.roles.alloc_slice(roles),
                    modifiers: self.ctx.syms.alloc_slice(vec![]),
                })));

                if let Some((nested_var, nested_clause)) = nested_relative {
                    let type_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: rel_subject.noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(nested_var)]),
                    });

                    let inner = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: type_pred,
                        op: TokenType::And,
                        right: nested_clause,
                    });

                    let combined = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: inner,
                        op: TokenType::And,
                        right: this_event,
                    });

                    return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                        kind: crate::ast::QuantifierKind::Existential,
                        variable: nested_var,
                        body: combined,
                        island_id: self.current_island,
                    }));
                }

                return Ok(this_event);
            }
        }

        if self.check_verb() {
            return self.parse_verb_phrase_for_restriction(gap_var);
        }

        let unknown = self.interner.intern("?");
        Ok(self.ctx.exprs.alloc(LogicExpr::Atom(unknown)))
    }

    fn check_ellipsis_auxiliary(&self) -> bool {
        matches!(
            self.peek().kind,
            TokenType::Does | TokenType::Do |
            TokenType::Can | TokenType::Could | TokenType::Would |
            TokenType::May | TokenType::Must | TokenType::Should
        )
    }

    fn check_ellipsis_terminator(&self) -> bool {
        if self.is_at_end() || self.check(&TokenType::Period) {
            return true;
        }
        if self.check_content_word() {
            let word = self.interner.resolve(self.peek().lexeme).to_lowercase();
            return word == "too" || word == "also";
        }
        false
    }

    fn try_parse_ellipsis(&mut self) -> Option<ParseResult<&'a LogicExpr<'a>>> {
        // Need a stored template to reconstruct from
        if self.last_event_template.is_none() {
            return None;
        }

        let saved_pos = self.current;

        // Pattern: Subject + Auxiliary + (not)? + Terminator
        // Subject must be proper name or pronoun
        let subject_sym = if matches!(self.peek().kind, TokenType::ProperName(_)) {
            if let TokenType::ProperName(sym) = self.advance().kind {
                sym
            } else {
                self.current = saved_pos;
                return None;
            }
        } else if self.check_pronoun() {
            let token = self.advance().clone();
            if let TokenType::Pronoun { gender, number, .. } = token.kind {
                self.resolve_pronoun(gender, number)
                    .unwrap_or_else(|| self.interner.intern("?"))
            } else {
                self.current = saved_pos;
                return None;
            }
        } else {
            return None;
        };

        // Must be followed by ellipsis auxiliary
        if !self.check_ellipsis_auxiliary() {
            self.current = saved_pos;
            return None;
        }
        let aux_token = self.advance().kind.clone();

        // Check for negation
        let is_negated = self.match_token(&[TokenType::Not]);

        // Must end with terminator
        if !self.check_ellipsis_terminator() {
            self.current = saved_pos;
            return None;
        }

        // Consume "too"/"also" if present
        if self.check_content_word() {
            let word = self.interner.resolve(self.peek().lexeme).to_lowercase();
            if word == "too" || word == "also" {
                self.advance();
            }
        }

        // Reconstruct from template
        let template = self.last_event_template.clone().unwrap();
        let event_var = self.get_event_var();

        // Build roles with new subject as Agent
        let mut roles: Vec<(ThematicRole, Term<'a>)> = vec![
            (ThematicRole::Agent, Term::Constant(subject_sym))
        ];
        roles.extend(template.non_agent_roles.iter().cloned());

        let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
            event_var,
            verb: template.verb,
            roles: self.ctx.roles.alloc_slice(roles),
            modifiers: self.ctx.syms.alloc_slice(template.modifiers.clone()),
        })));

        // Apply modal if auxiliary is modal
        let with_modal = match aux_token {
            TokenType::Can | TokenType::Could => {
                let vector = self.token_to_vector(&aux_token);
                self.ctx.modal(vector, neo_event)
            }
            TokenType::Would | TokenType::May | TokenType::Must | TokenType::Should => {
                let vector = self.token_to_vector(&aux_token);
                self.ctx.modal(vector, neo_event)
            }
            _ => neo_event,
        };

        // Apply negation if present
        let result = if is_negated {
            self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                op: TokenType::Not,
                operand: with_modal,
            })
        } else {
            with_modal
        };

        Some(Ok(result))
    }
}

```

---

### QuantifierParsing Trait

**File:** `src/parser/quantifier.rs`

Extension trait for quantified expressions: universal (all/every/each), existential (some/a/an), generic (bare plurals), negative (no/none). Handles restrictions, verb phrase parsing for restrictions, definiteness wrapping (with adjectives and PPs), donkey anaphora binding, PP placeholder substitution, and stacked relative clauses ('the book that John read that Mary wrote').

```rust
use super::clause::ClauseParsing;
use super::modal::ModalParsing;
use super::noun::NounParsing;
use super::{ParseResult, Parser};
use crate::ast::{LogicExpr, NounPhrase, QuantifierKind, Term};
use crate::context::Number;
use crate::error::{ParseError, ParseErrorKind};
use crate::intern::Symbol;
use crate::lexer::Lexer;
use crate::lexicon::{is_subsective, Definiteness, Time};
use crate::token::{PresupKind, TokenType};

pub trait QuantifierParsing<'a, 'ctx, 'int> {
    fn parse_quantified(&mut self) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_restriction(&mut self, var_name: Symbol) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_verb_phrase_for_restriction(&mut self, var_name: Symbol) -> ParseResult<&'a LogicExpr<'a>>;
    fn combine_with_and(&self, exprs: Vec<&'a LogicExpr<'a>>) -> ParseResult<&'a LogicExpr<'a>>;
    fn wrap_with_definiteness_full(
        &mut self,
        np: &NounPhrase<'a>,
        predicate: &'a LogicExpr<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>>;
    fn wrap_with_definiteness(
        &mut self,
        definiteness: Option<Definiteness>,
        noun: Symbol,
        predicate: &'a LogicExpr<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>>;
    fn wrap_with_definiteness_and_adjectives(
        &mut self,
        definiteness: Option<Definiteness>,
        noun: Symbol,
        adjectives: &[Symbol],
        predicate: &'a LogicExpr<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>>;
    fn wrap_with_definiteness_and_adjectives_and_pps(
        &mut self,
        definiteness: Option<Definiteness>,
        noun: Symbol,
        adjectives: &[Symbol],
        pps: &[&'a LogicExpr<'a>],
        predicate: &'a LogicExpr<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>>;
    fn wrap_with_definiteness_for_object(
        &mut self,
        definiteness: Option<Definiteness>,
        noun: Symbol,
        predicate: &'a LogicExpr<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>>;
    fn substitute_pp_placeholder(&mut self, pp: &'a LogicExpr<'a>, var: Symbol) -> &'a LogicExpr<'a>;
    fn substitute_constant_with_var(
        &self,
        expr: &'a LogicExpr<'a>,
        constant_name: Symbol,
        var_name: Symbol,
    ) -> ParseResult<&'a LogicExpr<'a>>;
    fn substitute_constant_with_var_sym(
        &self,
        expr: &'a LogicExpr<'a>,
        constant_name: Symbol,
        var_name: Symbol,
    ) -> ParseResult<&'a LogicExpr<'a>>;
    fn substitute_constant_with_sigma(
        &self,
        expr: &'a LogicExpr<'a>,
        constant_name: Symbol,
        sigma_term: Term<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>>;
    fn find_main_verb_name(&self, expr: &LogicExpr<'a>) -> Option<Symbol>;
    fn transform_cardinal_to_group(&mut self, expr: &'a LogicExpr<'a>) -> ParseResult<&'a LogicExpr<'a>>;
}

impl<'a, 'ctx, 'int> QuantifierParsing<'a, 'ctx, 'int> for Parser<'a, 'ctx, 'int> {
    fn parse_quantified(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let quantifier_token = self.previous().kind.clone();
        let var_name = self.next_var_name();

        let subject_pred = self.parse_restriction(var_name)?;

        if self.check_modal() {
            self.advance();
            let vector = self.token_to_vector(&self.previous().kind.clone());
            let verb = self.consume_content_word()?;

            let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
            });

            let body = match quantifier_token {
                TokenType::All => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: subject_pred,
                    op: TokenType::If,
                    right: verb_pred,
                }),
                TokenType::Any => {
                    if self.is_negative_context() {
                        self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: subject_pred,
                            op: TokenType::And,
                            right: verb_pred,
                        })
                    } else {
                        self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: subject_pred,
                            op: TokenType::If,
                            right: verb_pred,
                        })
                    }
                }
                TokenType::Some
                | TokenType::Most
                | TokenType::Few
                | TokenType::Many
                | TokenType::Cardinal(_)
                | TokenType::AtLeast(_)
                | TokenType::AtMost(_) => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: subject_pred,
                    op: TokenType::And,
                    right: verb_pred,
                }),
                TokenType::No => {
                    let neg = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                        op: TokenType::Not,
                        operand: verb_pred,
                    });
                    self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: subject_pred,
                        op: TokenType::If,
                        right: neg,
                    })
                }
                _ => {
                    return Err(ParseError {
                        kind: ParseErrorKind::UnknownQuantifier {
                            found: quantifier_token.clone(),
                        },
                        span: self.current_span(),
                    })
                }
            };

            let kind = match quantifier_token {
                TokenType::All | TokenType::No => QuantifierKind::Universal,
                TokenType::Any => {
                    if self.is_negative_context() {
                        QuantifierKind::Existential
                    } else {
                        QuantifierKind::Universal
                    }
                }
                TokenType::Some => QuantifierKind::Existential,
                TokenType::Most => QuantifierKind::Most,
                TokenType::Few => QuantifierKind::Few,
                TokenType::Many => QuantifierKind::Many,
                TokenType::Cardinal(n) => QuantifierKind::Cardinal(n),
                TokenType::AtLeast(n) => QuantifierKind::AtLeast(n),
                TokenType::AtMost(n) => QuantifierKind::AtMost(n),
                _ => {
                    return Err(ParseError {
                        kind: ParseErrorKind::UnknownQuantifier {
                            found: quantifier_token.clone(),
                        },
                        span: self.current_span(),
                    })
                }
            };

            let quantified = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                kind,
                variable: var_name,
                body,
                island_id: self.current_island,
            });

            return Ok(self.ctx.exprs.alloc(LogicExpr::Modal {
                vector,
                operand: quantified,
            }));
        }

        if self.check_auxiliary() {
            let aux_token = self.advance();
            let aux_time = if let TokenType::Auxiliary(time) = aux_token.kind.clone() {
                time
            } else {
                Time::None
            };
            self.pending_time = Some(aux_time);

            let is_negated = self.match_token(&[TokenType::Not]);
            if is_negated {
                self.negative_depth += 1;
            }

            if self.check_verb() {
                let verb = self.consume_verb();
                let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                });

                let maybe_negated = if is_negated {
                    self.negative_depth -= 1;
                    self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                        op: TokenType::Not,
                        operand: verb_pred,
                    })
                } else {
                    verb_pred
                };

                let body = match quantifier_token {
                    TokenType::All | TokenType::Any => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: subject_pred,
                        op: TokenType::If,
                        right: maybe_negated,
                    }),
                    _ => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: subject_pred,
                        op: TokenType::And,
                        right: maybe_negated,
                    }),
                };

                let kind = match quantifier_token {
                    TokenType::All | TokenType::No => QuantifierKind::Universal,
                    TokenType::Some => QuantifierKind::Existential,
                    TokenType::Most => QuantifierKind::Most,
                    TokenType::Few => QuantifierKind::Few,
                    TokenType::Cardinal(n) => QuantifierKind::Cardinal(n),
                    TokenType::AtLeast(n) => QuantifierKind::AtLeast(n),
                    TokenType::AtMost(n) => QuantifierKind::AtMost(n),
                    _ => QuantifierKind::Universal,
                };

                return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind,
                    variable: var_name,
                    body,
                    island_id: self.current_island,
                }));
            }
        }

        // Only trigger presupposition if followed by gerund complement
        if self.check_presup_trigger() && self.is_followed_by_gerund() {
            let presup_kind = match self.advance().kind {
                TokenType::PresupTrigger(kind) => kind,
                TokenType::Verb { lemma, .. } => {
                    let s = self.interner.resolve(lemma).to_lowercase();
                    crate::lexicon::lookup_presup_trigger(&s)
                        .expect("Lexicon mismatch: Verb flagged as trigger but lookup failed")
                }
                _ => panic!("Expected presupposition trigger"),
            };

            let complement = if self.check_verb() {
                let verb = self.consume_verb();
                self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                })
            } else {
                let unknown = self.interner.intern("?");
                self.ctx.exprs.alloc(LogicExpr::Atom(unknown))
            };

            let verb_pred = match presup_kind {
                PresupKind::Stop => self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                    op: TokenType::Not,
                    operand: complement,
                }),
                PresupKind::Start | PresupKind::Continue => complement,
                PresupKind::Regret | PresupKind::Realize | PresupKind::Know => complement,
            };

            let body = match quantifier_token {
                TokenType::All | TokenType::Any => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: subject_pred,
                    op: TokenType::If,
                    right: verb_pred,
                }),
                _ => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: subject_pred,
                    op: TokenType::And,
                    right: verb_pred,
                }),
            };

            let kind = match quantifier_token {
                TokenType::All | TokenType::No => QuantifierKind::Universal,
                TokenType::Some => QuantifierKind::Existential,
                TokenType::Most => QuantifierKind::Most,
                TokenType::Few => QuantifierKind::Few,
                TokenType::Many => QuantifierKind::Many,
                TokenType::Cardinal(n) => QuantifierKind::Cardinal(n),
                TokenType::AtLeast(n) => QuantifierKind::AtLeast(n),
                TokenType::AtMost(n) => QuantifierKind::AtMost(n),
                _ => QuantifierKind::Universal,
            };

            return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                kind,
                variable: var_name,
                body,
                island_id: self.current_island,
            }));
        }

        if self.check_verb() {
            let verb = self.consume_verb();
            let mut args = vec![Term::Variable(var_name)];

            if self.check_pronoun() {
                let token = self.peek().clone();
                if let TokenType::Pronoun { gender, .. } = token.kind {
                    self.advance();
                    if let Some(donkey_var) = self.resolve_donkey_pronoun(gender) {
                        args.push(Term::Variable(donkey_var));
                    } else {
                        let unknown = self.interner.intern("?");
                        let resolved = self
                            .resolve_pronoun(gender, Number::Singular)
                            .unwrap_or(unknown);
                        args.push(Term::Constant(resolved));
                    }
                }
            } else if self.check_npi_object() {
                let npi_token = self.advance().kind.clone();
                let obj_var = self.next_var_name();

                let restriction_name = match npi_token {
                    TokenType::Anything => "Thing",
                    TokenType::Anyone => "Person",
                    _ => "Thing",
                };

                let restriction_sym = self.interner.intern(restriction_name);
                let obj_restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: restriction_sym,
                    args: self.ctx.terms.alloc_slice([Term::Variable(obj_var)]),
                });

                let verb_with_obj = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb,
                    args: self.ctx.terms.alloc_slice([
                        Term::Variable(var_name),
                        Term::Variable(obj_var),
                    ]),
                });

                let npi_body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: obj_restriction,
                    op: TokenType::And,
                    right: verb_with_obj,
                });

                let npi_quantified = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: obj_var,
                    body: npi_body,
                    island_id: self.current_island,
                });

                let negated_npi = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                    op: TokenType::Not,
                    operand: npi_quantified,
                });

                let body = match quantifier_token {
                    TokenType::All | TokenType::No => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: subject_pred,
                        op: TokenType::If,
                        right: negated_npi,
                    }),
                    _ => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: subject_pred,
                        op: TokenType::And,
                        right: negated_npi,
                    }),
                };

                let kind = match quantifier_token {
                    TokenType::All | TokenType::No => QuantifierKind::Universal,
                    TokenType::Some => QuantifierKind::Existential,
                    TokenType::Most => QuantifierKind::Most,
                    TokenType::Few => QuantifierKind::Few,
                    TokenType::Many => QuantifierKind::Many,
                    TokenType::Cardinal(n) => QuantifierKind::Cardinal(n),
                    TokenType::AtLeast(n) => QuantifierKind::AtLeast(n),
                    TokenType::AtMost(n) => QuantifierKind::AtMost(n),
                    _ => QuantifierKind::Universal,
                };

                return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind,
                    variable: var_name,
                    body,
                    island_id: self.current_island,
                }));
            } else if self.check_quantifier() || self.check_article() {
                let obj_quantifier = if self.check_quantifier() {
                    Some(self.advance().kind.clone())
                } else {
                    let art = self.advance().kind.clone();
                    if let TokenType::Article(def) = art {
                        if def == Definiteness::Indefinite {
                            Some(TokenType::Some)
                        } else {
                            None
                        }
                    } else {
                        None
                    }
                };

                let object = self.parse_noun_phrase(false)?;

                if let Some(obj_q) = obj_quantifier {
                    let obj_var = self.next_var_name();
                    let obj_restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: object.noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(obj_var)]),
                    });

                    let verb_with_obj = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: verb,
                        args: self.ctx.terms.alloc_slice([
                            Term::Variable(var_name),
                            Term::Variable(obj_var),
                        ]),
                    });

                    let obj_kind = match obj_q {
                        TokenType::All => QuantifierKind::Universal,
                        TokenType::Some => QuantifierKind::Existential,
                        TokenType::No => QuantifierKind::Universal,
                        TokenType::Most => QuantifierKind::Most,
                        TokenType::Few => QuantifierKind::Few,
                        TokenType::Many => QuantifierKind::Many,
                        TokenType::Cardinal(n) => QuantifierKind::Cardinal(n),
                        TokenType::AtLeast(n) => QuantifierKind::AtLeast(n),
                        TokenType::AtMost(n) => QuantifierKind::AtMost(n),
                        _ => QuantifierKind::Existential,
                    };

                    let obj_body = match obj_q {
                        TokenType::All => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: obj_restriction,
                            op: TokenType::If,
                            right: verb_with_obj,
                        }),
                        TokenType::No => {
                            let neg = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                                op: TokenType::Not,
                                operand: verb_with_obj,
                            });
                            self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                left: obj_restriction,
                                op: TokenType::If,
                                right: neg,
                            })
                        }
                        _ => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: obj_restriction,
                            op: TokenType::And,
                            right: verb_with_obj,
                        }),
                    };

                    let obj_quantified = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                        kind: obj_kind,
                        variable: obj_var,
                        body: obj_body,
                        island_id: self.current_island,
                    });

                    let subj_kind = match quantifier_token {
                        TokenType::All | TokenType::No => QuantifierKind::Universal,
                        TokenType::Any => {
                            if self.is_negative_context() {
                                QuantifierKind::Existential
                            } else {
                                QuantifierKind::Universal
                            }
                        }
                        TokenType::Some => QuantifierKind::Existential,
                        TokenType::Most => QuantifierKind::Most,
                        TokenType::Few => QuantifierKind::Few,
                        TokenType::Many => QuantifierKind::Many,
                        TokenType::Cardinal(n) => QuantifierKind::Cardinal(n),
                        TokenType::AtLeast(n) => QuantifierKind::AtLeast(n),
                        TokenType::AtMost(n) => QuantifierKind::AtMost(n),
                        _ => QuantifierKind::Universal,
                    };

                    let subj_body = match quantifier_token {
                        TokenType::All => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: subject_pred,
                            op: TokenType::If,
                            right: obj_quantified,
                        }),
                        TokenType::No => {
                            let neg = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                                op: TokenType::Not,
                                operand: obj_quantified,
                            });
                            self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                left: subject_pred,
                                op: TokenType::If,
                                right: neg,
                            })
                        }
                        _ => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: subject_pred,
                            op: TokenType::And,
                            right: obj_quantified,
                        }),
                    };

                    return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                        kind: subj_kind,
                        variable: var_name,
                        body: subj_body,
                        island_id: self.current_island,
                    }));
                } else {
                    args.push(Term::Constant(object.noun));
                }
            } else if self.check_content_word() {
                let object = self.parse_noun_phrase(false)?;
                args.push(Term::Constant(object.noun));
            }

            let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice(args),
            });

            let body = match quantifier_token {
                TokenType::All => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: subject_pred,
                    op: TokenType::If,
                    right: verb_pred,
                }),
                TokenType::Any => {
                    if self.is_negative_context() {
                        self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: subject_pred,
                            op: TokenType::And,
                            right: verb_pred,
                        })
                    } else {
                        self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: subject_pred,
                            op: TokenType::If,
                            right: verb_pred,
                        })
                    }
                }
                TokenType::Some
                | TokenType::Most
                | TokenType::Few
                | TokenType::Many
                | TokenType::Cardinal(_)
                | TokenType::AtLeast(_)
                | TokenType::AtMost(_) => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: subject_pred,
                    op: TokenType::And,
                    right: verb_pred,
                }),
                TokenType::No => {
                    let neg = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                        op: TokenType::Not,
                        operand: verb_pred,
                    });
                    self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: subject_pred,
                        op: TokenType::If,
                        right: neg,
                    })
                }
                _ => {
                    return Err(ParseError {
                        kind: ParseErrorKind::UnknownQuantifier {
                            found: quantifier_token.clone(),
                        },
                        span: self.current_span(),
                    })
                }
            };

            let kind = match quantifier_token {
                TokenType::All | TokenType::No => QuantifierKind::Universal,
                TokenType::Any => {
                    if self.is_negative_context() {
                        QuantifierKind::Existential
                    } else {
                        QuantifierKind::Universal
                    }
                }
                TokenType::Some => QuantifierKind::Existential,
                TokenType::Most => QuantifierKind::Most,
                TokenType::Few => QuantifierKind::Few,
                TokenType::Many => QuantifierKind::Many,
                TokenType::Cardinal(n) => QuantifierKind::Cardinal(n),
                TokenType::AtLeast(n) => QuantifierKind::AtLeast(n),
                TokenType::AtMost(n) => QuantifierKind::AtMost(n),
                _ => {
                    return Err(ParseError {
                        kind: ParseErrorKind::UnknownQuantifier {
                            found: quantifier_token.clone(),
                        },
                        span: self.current_span(),
                    })
                }
            };

            let mut result = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                kind,
                variable: var_name,
                body,
                island_id: self.current_island,
            });

            for (_noun, donkey_var, used) in self.donkey_bindings.iter().rev() {
                let kind = if *used {
                    QuantifierKind::Universal
                } else {
                    QuantifierKind::Existential
                };
                result = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind,
                    variable: *donkey_var,
                    body: result,
                    island_id: self.current_island,
                });
            }
            self.donkey_bindings.clear();

            return Ok(result);
        }

        self.consume_copula()?;

        let negative = self.match_token(&[TokenType::Not]);
        let predicate_np = self.parse_noun_phrase(true)?;

        let predicate_expr = self.ctx.exprs.alloc(LogicExpr::Predicate {
            name: predicate_np.noun,
            args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
        });

        let final_predicate = if negative {
            self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                op: TokenType::Not,
                operand: predicate_expr,
            })
        } else {
            predicate_expr
        };

        let body = match quantifier_token {
            TokenType::All => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: subject_pred,
                op: TokenType::If,
                right: final_predicate,
            }),
            TokenType::Any => {
                if self.is_negative_context() {
                    self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: subject_pred,
                        op: TokenType::And,
                        right: final_predicate,
                    })
                } else {
                    self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: subject_pred,
                        op: TokenType::If,
                        right: final_predicate,
                    })
                }
            }
            TokenType::Some
            | TokenType::Most
            | TokenType::Few
            | TokenType::Many
            | TokenType::Cardinal(_)
            | TokenType::AtLeast(_)
            | TokenType::AtMost(_) => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: subject_pred,
                op: TokenType::And,
                right: final_predicate,
            }),
            TokenType::No => {
                let neg_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: predicate_np.noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                });
                let neg = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                    op: TokenType::Not,
                    operand: neg_pred,
                });
                self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: subject_pred,
                    op: TokenType::If,
                    right: neg,
                })
            }
            _ => {
                return Err(ParseError {
                    kind: ParseErrorKind::UnknownQuantifier {
                        found: quantifier_token.clone(),
                    },
                    span: self.current_span(),
                })
            }
        };

        let kind = match quantifier_token {
            TokenType::All | TokenType::No => QuantifierKind::Universal,
            TokenType::Any => {
                if self.is_negative_context() {
                    QuantifierKind::Existential
                } else {
                    QuantifierKind::Universal
                }
            }
            TokenType::Some => QuantifierKind::Existential,
            TokenType::Most => QuantifierKind::Most,
            TokenType::Few => QuantifierKind::Few,
            TokenType::Many => QuantifierKind::Many,
            TokenType::Cardinal(n) => QuantifierKind::Cardinal(n),
            TokenType::AtLeast(n) => QuantifierKind::AtLeast(n),
            TokenType::AtMost(n) => QuantifierKind::AtMost(n),
            _ => {
                return Err(ParseError {
                    kind: ParseErrorKind::UnknownQuantifier {
                        found: quantifier_token.clone(),
                    },
                    span: self.current_span(),
                })
            }
        };

        let mut result = self.ctx.exprs.alloc(LogicExpr::Quantifier {
            kind,
            variable: var_name,
            body,
            island_id: self.current_island,
        });

        for (_noun, donkey_var, used) in self.donkey_bindings.iter().rev() {
            let donkey_kind = if *used {
                QuantifierKind::Universal
            } else {
                QuantifierKind::Existential
            };
            result = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                kind: donkey_kind,
                variable: *donkey_var,
                body: result,
                island_id: self.current_island,
            });
        }
        self.donkey_bindings.clear();

        Ok(result)
    }

    fn parse_restriction(&mut self, var_name: Symbol) -> ParseResult<&'a LogicExpr<'a>> {
        let mut conditions: Vec<&'a LogicExpr<'a>> = Vec::new();

        loop {
            if self.is_at_end() {
                break;
            }

            let is_adjective = matches!(self.peek().kind, TokenType::Adjective(_));
            if !is_adjective {
                break;
            }

            let next_is_content = if self.current + 1 < self.tokens.len() {
                matches!(
                    self.tokens[self.current + 1].kind,
                    TokenType::Noun(_) | TokenType::Adjective(_) | TokenType::ProperName(_)
                )
            } else {
                false
            };

            if next_is_content {
                if let TokenType::Adjective(adj) = self.advance().kind.clone() {
                    conditions.push(self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: adj,
                        args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                    }));
                }
            } else {
                break;
            }
        }

        let noun = self.consume_content_word()?;
        conditions.push(self.ctx.exprs.alloc(LogicExpr::Predicate {
            name: noun,
            args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
        }));

        while self.check(&TokenType::That) || self.check(&TokenType::Who) {
            self.advance();
            let clause_pred = self.parse_relative_clause(var_name)?;
            conditions.push(clause_pred);
        }

        self.combine_with_and(conditions)
    }

    fn parse_verb_phrase_for_restriction(&mut self, var_name: Symbol) -> ParseResult<&'a LogicExpr<'a>> {
        let var_term = Term::Variable(var_name);
        let verb = self.consume_verb();
        let verb_str = self.interner.resolve(verb);

        if Lexer::is_raising_verb(verb_str) && self.check_to() {
            self.advance();
            if self.check_verb() {
                let inf_verb = self.consume_verb();
                let inf_verb_str = self.interner.resolve(inf_verb).to_lowercase();

                if inf_verb_str == "be" && self.check_content_word() {
                    let adj = self.consume_content_word()?;
                    let embedded = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: adj,
                        args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                    });
                    return Ok(self.ctx.exprs.alloc(LogicExpr::Scopal {
                        operator: verb,
                        body: embedded,
                    }));
                }

                let embedded = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: inf_verb,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                });
                return Ok(self.ctx.exprs.alloc(LogicExpr::Scopal {
                    operator: verb,
                    body: embedded,
                }));
            } else if self.check(&TokenType::Is) || self.check(&TokenType::Are) {
                self.advance();
                if self.check_content_word() {
                    let adj = self.consume_content_word()?;
                    let embedded = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: adj,
                        args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                    });
                    return Ok(self.ctx.exprs.alloc(LogicExpr::Scopal {
                        operator: verb,
                        body: embedded,
                    }));
                }
            }
        }

        let mut args = vec![var_term];
        let mut extra_conditions: Vec<&'a LogicExpr<'a>> = Vec::new();

        if self.check(&TokenType::Reflexive) {
            self.advance();
            args.push(Term::Variable(var_name));
        } else if (self.check_content_word() || self.check_article()) && !self.check_verb() {
            if matches!(
                self.peek().kind,
                TokenType::Article(Definiteness::Indefinite)
            ) {
                self.advance();
                let noun = self.consume_content_word()?;
                let donkey_var = self.next_var_name();

                self.donkey_bindings.push((noun, donkey_var, false));

                extra_conditions.push(self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(donkey_var)]),
                }));

                args.push(Term::Variable(donkey_var));
            } else {
                let object = self.parse_noun_phrase(false)?;

                if self.check(&TokenType::That) || self.check(&TokenType::Who) {
                    self.advance();
                    let nested_var = self.next_var_name();
                    let nested_rel = self.parse_relative_clause(nested_var)?;

                    extra_conditions.push(self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: object.noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(nested_var)]),
                    }));
                    extra_conditions.push(nested_rel);
                    args.push(Term::Variable(nested_var));
                } else {
                    args.push(Term::Constant(object.noun));
                }
            }
        }

        while self.check_preposition() {
            self.advance();
            if self.check(&TokenType::Reflexive) {
                self.advance();
                args.push(Term::Variable(var_name));
            } else if self.check_content_word() || self.check_article() {
                let object = self.parse_noun_phrase(false)?;

                if self.check(&TokenType::That) || self.check(&TokenType::Who) {
                    self.advance();
                    let nested_var = self.next_var_name();
                    let nested_rel = self.parse_relative_clause(nested_var)?;
                    extra_conditions.push(self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: object.noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(nested_var)]),
                    }));
                    extra_conditions.push(nested_rel);
                    args.push(Term::Variable(nested_var));
                } else {
                    args.push(Term::Constant(object.noun));
                }
            }
        }

        let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
            name: verb,
            args: self.ctx.terms.alloc_slice(args),
        });

        if extra_conditions.is_empty() {
            Ok(verb_pred)
        } else {
            extra_conditions.push(verb_pred);
            self.combine_with_and(extra_conditions)
        }
    }

    fn combine_with_and(&self, mut exprs: Vec<&'a LogicExpr<'a>>) -> ParseResult<&'a LogicExpr<'a>> {
        if exprs.is_empty() {
            return Err(ParseError {
                kind: ParseErrorKind::EmptyRestriction,
                span: self.current_span(),
            });
        }
        if exprs.len() == 1 {
            return Ok(exprs.remove(0));
        }
        let mut root = exprs.remove(0);
        for expr in exprs {
            root = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: root,
                op: TokenType::And,
                right: expr,
            });
        }
        Ok(root)
    }

    fn wrap_with_definiteness_full(
        &mut self,
        np: &NounPhrase<'a>,
        predicate: &'a LogicExpr<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        let result = self.wrap_with_definiteness_and_adjectives_and_pps(
            np.definiteness,
            np.noun,
            np.adjectives,
            np.pps,
            predicate,
        )?;

        // If NP has a superlative, add the superlative constraint
        if let Some(adj) = np.superlative {
            let superlative_expr = self.ctx.exprs.alloc(LogicExpr::Superlative {
                adjective: adj,
                subject: self.ctx.terms.alloc(Term::Constant(np.noun)),
                domain: np.noun,
            });
            Ok(self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: result,
                op: TokenType::And,
                right: superlative_expr,
            }))
        } else {
            Ok(result)
        }
    }

    fn wrap_with_definiteness(
        &mut self,
        definiteness: Option<Definiteness>,
        noun: Symbol,
        predicate: &'a LogicExpr<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        self.wrap_with_definiteness_and_adjectives_and_pps(definiteness, noun, &[], &[], predicate)
    }

    fn wrap_with_definiteness_and_adjectives(
        &mut self,
        definiteness: Option<Definiteness>,
        noun: Symbol,
        adjectives: &[Symbol],
        predicate: &'a LogicExpr<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        self.wrap_with_definiteness_and_adjectives_and_pps(
            definiteness,
            noun,
            adjectives,
            &[],
            predicate,
        )
    }

    fn wrap_with_definiteness_and_adjectives_and_pps(
        &mut self,
        definiteness: Option<Definiteness>,
        noun: Symbol,
        adjectives: &[Symbol],
        pps: &[&'a LogicExpr<'a>],
        predicate: &'a LogicExpr<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        match definiteness {
            Some(Definiteness::Indefinite) => {
                let var = self.next_var_name();

                let mut restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var)]),
                });

                for adj in adjectives {
                    let adj_str = self.interner.resolve(*adj).to_lowercase();
                    let adj_pred = if is_subsective(&adj_str) {
                        self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: *adj,
                            args: self.ctx.terms.alloc_slice([
                                Term::Variable(var),
                                Term::Intension(noun),
                            ]),
                        })
                    } else {
                        self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: *adj,
                            args: self.ctx.terms.alloc_slice([Term::Variable(var)]),
                        })
                    };
                    restriction = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: restriction,
                        op: TokenType::And,
                        right: adj_pred,
                    });
                }

                for pp in pps {
                    let substituted_pp = self.substitute_pp_placeholder(pp, var);
                    restriction = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: restriction,
                        op: TokenType::And,
                        right: substituted_pp,
                    });
                }

                let substituted = self.substitute_constant_with_var_sym(predicate, noun, var)?;
                let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: restriction,
                    op: TokenType::And,
                    right: substituted,
                });
                Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: var,
                    body,
                    island_id: self.current_island,
                }))
            }
            Some(Definiteness::Definite) => {
                let noun_str = self.interner.resolve(noun).to_string();

                if Self::is_plural_noun(&noun_str) {
                    let singular = Self::singularize_noun(&noun_str);
                    let singular_sym = self.interner.intern(&singular);
                    let sigma_term = Term::Sigma(singular_sym);

                    let substituted =
                        self.substitute_constant_with_sigma(predicate, noun, sigma_term)?;

                    let verb_name = self.find_main_verb_name(predicate);
                    let is_collective = verb_name
                        .map(|v| {
                            let lemma = self.interner.resolve(v);
                            Lexer::is_collective_verb(lemma)
                                || (Lexer::is_mixed_verb(lemma) && self.collective_mode)
                        })
                        .unwrap_or(false);

                    if is_collective {
                        Ok(substituted)
                    } else {
                        Ok(self.ctx.exprs.alloc(LogicExpr::Distributive {
                            predicate: substituted,
                        }))
                    }
                } else {
                    let x = self.next_var_name();
                    let y = self.next_var_name();

                    let mut restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(x)]),
                    });

                    for adj in adjectives {
                        let adj_str = self.interner.resolve(*adj).to_lowercase();
                        let adj_pred = if is_subsective(&adj_str) {
                            self.ctx.exprs.alloc(LogicExpr::Predicate {
                                name: *adj,
                                args: self.ctx.terms.alloc_slice([
                                    Term::Variable(x),
                                    Term::Intension(noun),
                                ]),
                            })
                        } else {
                            self.ctx.exprs.alloc(LogicExpr::Predicate {
                                name: *adj,
                                args: self.ctx.terms.alloc_slice([Term::Variable(x)]),
                            })
                        };
                        restriction = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: restriction,
                            op: TokenType::And,
                            right: adj_pred,
                        });
                    }

                    for pp in pps {
                        let substituted_pp = self.substitute_pp_placeholder(pp, x);
                        restriction = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: restriction,
                            op: TokenType::And,
                            right: substituted_pp,
                        });
                    }

                    // Bridging anaphora: check if this noun is a part of a previously mentioned whole
                    if let Some(ref mut ctx) = self.context {
                        let our_symbol = noun_str.chars().next().unwrap().to_uppercase().to_string();
                        let has_prior_antecedent = ctx.resolve_definite(&noun_str)
                            .map(|e| e.symbol != our_symbol)
                            .unwrap_or(false);

                        if !has_prior_antecedent {
                            let bridging_matches = ctx.resolve_bridging(&noun_str);
                            if let Some((entity, _whole_name)) = bridging_matches.first() {
                                let whole_sym = self.interner.intern(&entity.symbol);
                                let part_of_sym = self.interner.intern("PartOf");
                                let part_of_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                                    name: part_of_sym,
                                    args: self.ctx.terms.alloc_slice([
                                        Term::Variable(x),
                                        Term::Constant(whole_sym),
                                    ]),
                                });
                                restriction = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                    left: restriction,
                                    op: TokenType::And,
                                    right: part_of_pred,
                                });
                            }
                        }
                    }

                    let mut y_restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(y)]),
                    });
                    for adj in adjectives {
                        let adj_str = self.interner.resolve(*adj).to_lowercase();
                        let adj_pred = if is_subsective(&adj_str) {
                            self.ctx.exprs.alloc(LogicExpr::Predicate {
                                name: *adj,
                                args: self.ctx.terms.alloc_slice([
                                    Term::Variable(y),
                                    Term::Intension(noun),
                                ]),
                            })
                        } else {
                            self.ctx.exprs.alloc(LogicExpr::Predicate {
                                name: *adj,
                                args: self.ctx.terms.alloc_slice([Term::Variable(y)]),
                            })
                        };
                        y_restriction = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: y_restriction,
                            op: TokenType::And,
                            right: adj_pred,
                        });
                    }

                    for pp in pps {
                        let substituted_pp = self.substitute_pp_placeholder(pp, y);
                        y_restriction = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: y_restriction,
                            op: TokenType::And,
                            right: substituted_pp,
                        });
                    }

                    let identity = self.ctx.exprs.alloc(LogicExpr::Identity {
                        left: self.ctx.terms.alloc(Term::Variable(y)),
                        right: self.ctx.terms.alloc(Term::Variable(x)),
                    });
                    let uniqueness_body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: y_restriction,
                        op: TokenType::If,
                        right: identity,
                    });
                    let uniqueness = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                        kind: QuantifierKind::Universal,
                        variable: y,
                        body: uniqueness_body,
                        island_id: self.current_island,
                    });

                    let main_pred = self.substitute_constant_with_var_sym(predicate, noun, x)?;

                    let inner = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: restriction,
                        op: TokenType::And,
                        right: uniqueness,
                    });
                    let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: inner,
                        op: TokenType::And,
                        right: main_pred,
                    });

                    Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                        kind: QuantifierKind::Existential,
                        variable: x,
                        body,
                        island_id: self.current_island,
                    }))
                }
            }
            Some(Definiteness::Proximal) | Some(Definiteness::Distal) => {
                let var = self.next_var_name();

                let mut restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var)]),
                });

                let deictic_name = if matches!(definiteness, Some(Definiteness::Proximal)) {
                    self.interner.intern("Proximal")
                } else {
                    self.interner.intern("Distal")
                };
                let deictic_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: deictic_name,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var)]),
                });
                restriction = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: restriction,
                    op: TokenType::And,
                    right: deictic_pred,
                });

                for adj in adjectives {
                    let adj_str = self.interner.resolve(*adj).to_lowercase();
                    let adj_pred = if is_subsective(&adj_str) {
                        self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: *adj,
                            args: self.ctx.terms.alloc_slice([
                                Term::Variable(var),
                                Term::Intension(noun),
                            ]),
                        })
                    } else {
                        self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: *adj,
                            args: self.ctx.terms.alloc_slice([Term::Variable(var)]),
                        })
                    };
                    restriction = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: restriction,
                        op: TokenType::And,
                        right: adj_pred,
                    });
                }

                for pp in pps {
                    let substituted_pp = self.substitute_pp_placeholder(pp, var);
                    restriction = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: restriction,
                        op: TokenType::And,
                        right: substituted_pp,
                    });
                }

                let substituted = self.substitute_constant_with_var_sym(predicate, noun, var)?;
                let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: restriction,
                    op: TokenType::And,
                    right: substituted,
                });
                Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: var,
                    body,
                    island_id: self.current_island,
                }))
            }
            None => Ok(predicate),
        }
    }

    fn wrap_with_definiteness_for_object(
        &mut self,
        definiteness: Option<Definiteness>,
        noun: Symbol,
        predicate: &'a LogicExpr<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        match definiteness {
            Some(Definiteness::Indefinite) => {
                let var = self.next_var_name();
                let type_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var)]),
                });
                let substituted = self.substitute_constant_with_var(predicate, noun, var)?;
                let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: type_pred,
                    op: TokenType::And,
                    right: substituted,
                });
                Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: var,
                    body,
                    island_id: self.current_island,
                }))
            }
            Some(Definiteness::Definite) => {
                let x = self.next_var_name();
                let y = self.next_var_name();

                let type_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(x)]),
                });

                let identity = self.ctx.exprs.alloc(LogicExpr::Identity {
                    left: self.ctx.terms.alloc(Term::Variable(y)),
                    right: self.ctx.terms.alloc(Term::Variable(x)),
                });
                let inner_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(y)]),
                });
                let uniqueness_body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: inner_pred,
                    op: TokenType::If,
                    right: identity,
                });
                let uniqueness = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Universal,
                    variable: y,
                    body: uniqueness_body,
                    island_id: self.current_island,
                });

                let main_pred = self.substitute_constant_with_var(predicate, noun, x)?;

                let type_and_unique = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: type_pred,
                    op: TokenType::And,
                    right: uniqueness,
                });
                let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: type_and_unique,
                    op: TokenType::And,
                    right: main_pred,
                });

                Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: x,
                    body,
                    island_id: self.current_island,
                }))
            }
            Some(Definiteness::Proximal) | Some(Definiteness::Distal) => {
                let var = self.next_var_name();

                let mut restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var)]),
                });

                let deictic_name = if matches!(definiteness, Some(Definiteness::Proximal)) {
                    self.interner.intern("Proximal")
                } else {
                    self.interner.intern("Distal")
                };
                let deictic_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: deictic_name,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var)]),
                });
                restriction = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: restriction,
                    op: TokenType::And,
                    right: deictic_pred,
                });

                let substituted = self.substitute_constant_with_var(predicate, noun, var)?;
                let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: restriction,
                    op: TokenType::And,
                    right: substituted,
                });
                Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: var,
                    body,
                    island_id: self.current_island,
                }))
            }
            None => Ok(predicate),
        }
    }

    fn substitute_pp_placeholder(&mut self, pp: &'a LogicExpr<'a>, var: Symbol) -> &'a LogicExpr<'a> {
        let placeholder = self.interner.intern("_PP_SELF_");
        match pp {
            LogicExpr::Predicate { name, args } => {
                let new_args: Vec<Term<'a>> = args
                    .iter()
                    .map(|arg| match arg {
                        Term::Variable(v) if *v == placeholder => Term::Variable(var),
                        other => *other,
                    })
                    .collect();
                self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: *name,
                    args: self.ctx.terms.alloc_slice(new_args),
                })
            }
            _ => pp,
        }
    }

    fn substitute_constant_with_var(
        &self,
        expr: &'a LogicExpr<'a>,
        constant_name: Symbol,
        var_name: Symbol,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        match expr {
            LogicExpr::Predicate { name, args } => {
                let new_args: Vec<Term<'a>> = args
                    .iter()
                    .map(|arg| match arg {
                        Term::Constant(c) if *c == constant_name => Term::Variable(var_name),
                        Term::Constant(c) => Term::Constant(*c),
                        Term::Variable(v) => Term::Variable(*v),
                        Term::Function(n, a) => Term::Function(*n, *a),
                        Term::Group(m) => Term::Group(*m),
                        Term::Possessed { possessor, possessed } => Term::Possessed {
                            possessor: *possessor,
                            possessed: *possessed,
                        },
                        Term::Sigma(p) => Term::Sigma(*p),
                        Term::Intension(p) => Term::Intension(*p),
                        Term::Proposition(e) => Term::Proposition(*e),
                        Term::Value { kind, unit, dimension } => Term::Value {
                            kind: *kind,
                            unit: *unit,
                            dimension: *dimension,
                        },
                    })
                    .collect();
                Ok(self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: *name,
                    args: self.ctx.terms.alloc_slice(new_args),
                }))
            }
            LogicExpr::Temporal { operator, body } => Ok(self.ctx.exprs.alloc(LogicExpr::Temporal {
                operator: *operator,
                body: self.substitute_constant_with_var(body, constant_name, var_name)?,
            })),
            LogicExpr::Aspectual { operator, body } => Ok(self.ctx.exprs.alloc(LogicExpr::Aspectual {
                operator: *operator,
                body: self.substitute_constant_with_var(body, constant_name, var_name)?,
            })),
            LogicExpr::UnaryOp { op, operand } => Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                op: op.clone(),
                operand: self.substitute_constant_with_var(operand, constant_name, var_name)?,
            })),
            LogicExpr::BinaryOp { left, op, right } => Ok(self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: self.substitute_constant_with_var(left, constant_name, var_name)?,
                op: op.clone(),
                right: self.substitute_constant_with_var(right, constant_name, var_name)?,
            })),
            LogicExpr::Event { predicate, adverbs } => Ok(self.ctx.exprs.alloc(LogicExpr::Event {
                predicate: self.substitute_constant_with_var(predicate, constant_name, var_name)?,
                adverbs: *adverbs,
            })),
            LogicExpr::TemporalAnchor { anchor, body } => {
                Ok(self.ctx.exprs.alloc(LogicExpr::TemporalAnchor {
                    anchor: *anchor,
                    body: self.substitute_constant_with_var(body, constant_name, var_name)?,
                }))
            }
            _ => Ok(expr),
        }
    }

    fn substitute_constant_with_var_sym(
        &self,
        expr: &'a LogicExpr<'a>,
        constant_name: Symbol,
        var_name: Symbol,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        self.substitute_constant_with_var(expr, constant_name, var_name)
    }

    fn substitute_constant_with_sigma(
        &self,
        expr: &'a LogicExpr<'a>,
        constant_name: Symbol,
        sigma_term: Term<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        match expr {
            LogicExpr::Predicate { name, args } => {
                let new_args: Vec<Term<'a>> = args
                    .iter()
                    .map(|arg| match arg {
                        Term::Constant(c) if *c == constant_name => sigma_term.clone(),
                        Term::Constant(c) => Term::Constant(*c),
                        Term::Variable(v) => Term::Variable(*v),
                        Term::Function(n, a) => Term::Function(*n, *a),
                        Term::Group(m) => Term::Group(*m),
                        Term::Possessed { possessor, possessed } => Term::Possessed {
                            possessor: *possessor,
                            possessed: *possessed,
                        },
                        Term::Sigma(p) => Term::Sigma(*p),
                        Term::Intension(p) => Term::Intension(*p),
                        Term::Proposition(e) => Term::Proposition(*e),
                        Term::Value { kind, unit, dimension } => Term::Value {
                            kind: *kind,
                            unit: *unit,
                            dimension: *dimension,
                        },
                    })
                    .collect();
                Ok(self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: *name,
                    args: self.ctx.terms.alloc_slice(new_args),
                }))
            }
            LogicExpr::Temporal { operator, body } => Ok(self.ctx.exprs.alloc(LogicExpr::Temporal {
                operator: *operator,
                body: self.substitute_constant_with_sigma(body, constant_name, sigma_term)?,
            })),
            LogicExpr::Aspectual { operator, body } => Ok(self.ctx.exprs.alloc(LogicExpr::Aspectual {
                operator: *operator,
                body: self.substitute_constant_with_sigma(body, constant_name, sigma_term)?,
            })),
            LogicExpr::UnaryOp { op, operand } => Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                op: op.clone(),
                operand: self.substitute_constant_with_sigma(operand, constant_name, sigma_term)?,
            })),
            LogicExpr::BinaryOp { left, op, right } => Ok(self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: self.substitute_constant_with_sigma(
                    left,
                    constant_name,
                    sigma_term.clone(),
                )?,
                op: op.clone(),
                right: self.substitute_constant_with_sigma(right, constant_name, sigma_term)?,
            })),
            LogicExpr::Event { predicate, adverbs } => Ok(self.ctx.exprs.alloc(LogicExpr::Event {
                predicate: self.substitute_constant_with_sigma(
                    predicate,
                    constant_name,
                    sigma_term,
                )?,
                adverbs: *adverbs,
            })),
            LogicExpr::TemporalAnchor { anchor, body } => {
                Ok(self.ctx.exprs.alloc(LogicExpr::TemporalAnchor {
                    anchor: *anchor,
                    body: self.substitute_constant_with_sigma(body, constant_name, sigma_term)?,
                }))
            }
            LogicExpr::NeoEvent(data) => {
                let new_roles: Vec<(crate::ast::ThematicRole, Term<'a>)> = data
                    .roles
                    .iter()
                    .map(|(role, term)| {
                        let new_term = match term {
                            Term::Constant(c) if *c == constant_name => sigma_term.clone(),
                            Term::Constant(c) => Term::Constant(*c),
                            Term::Variable(v) => Term::Variable(*v),
                            Term::Function(n, a) => Term::Function(*n, *a),
                            Term::Group(m) => Term::Group(*m),
                            Term::Possessed { possessor, possessed } => Term::Possessed {
                                possessor: *possessor,
                                possessed: *possessed,
                            },
                            Term::Sigma(p) => Term::Sigma(*p),
                            Term::Intension(p) => Term::Intension(*p),
                            Term::Proposition(e) => Term::Proposition(*e),
                            Term::Value { kind, unit, dimension } => Term::Value {
                                kind: *kind,
                                unit: *unit,
                                dimension: *dimension,
                            },
                        };
                        (*role, new_term)
                    })
                    .collect();
                Ok(self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(crate::ast::NeoEventData {
                    event_var: data.event_var,
                    verb: data.verb,
                    roles: self.ctx.roles.alloc_slice(new_roles),
                    modifiers: data.modifiers,
                }))))
            }
            LogicExpr::Distributive { predicate } => Ok(self.ctx.exprs.alloc(LogicExpr::Distributive {
                predicate: self.substitute_constant_with_sigma(predicate, constant_name, sigma_term)?,
            })),
            _ => Ok(expr),
        }
    }

    fn find_main_verb_name(&self, expr: &LogicExpr<'a>) -> Option<Symbol> {
        match expr {
            LogicExpr::Predicate { name, .. } => Some(*name),
            LogicExpr::NeoEvent(data) => Some(data.verb),
            LogicExpr::Temporal { body, .. } => self.find_main_verb_name(body),
            LogicExpr::Aspectual { body, .. } => self.find_main_verb_name(body),
            LogicExpr::Event { predicate, .. } => self.find_main_verb_name(predicate),
            LogicExpr::TemporalAnchor { body, .. } => self.find_main_verb_name(body),
            LogicExpr::UnaryOp { operand, .. } => self.find_main_verb_name(operand),
            LogicExpr::BinaryOp { left, .. } => self.find_main_verb_name(left),
            _ => None,
        }
    }

    fn transform_cardinal_to_group(&mut self, expr: &'a LogicExpr<'a>) -> ParseResult<&'a LogicExpr<'a>> {
        match expr {
            LogicExpr::Quantifier { kind: QuantifierKind::Cardinal(n), variable, body, .. } => {
                let group_var = self.interner.intern("g");
                let member_var = *variable;

                // Extract the restriction (first conjunct) and the body (rest)
                // The structure is: restriction ∧ body_rest
                let (restriction, body_rest) = match body {
                    LogicExpr::BinaryOp { left, op: TokenType::And, right } => (*left, *right),
                    _ => return Ok(expr),
                };

                // Substitute the member variable with the group variable in the body
                let transformed_body = self.substitute_constant_with_var_sym(body_rest, member_var, group_var)?;

                Ok(self.ctx.exprs.alloc(LogicExpr::GroupQuantifier {
                    group_var,
                    count: *n,
                    member_var,
                    restriction,
                    body: transformed_body,
                }))
            }
            // Recursively transform nested expressions
            LogicExpr::Temporal { operator, body } => {
                let transformed = self.transform_cardinal_to_group(body)?;
                Ok(self.ctx.exprs.alloc(LogicExpr::Temporal {
                    operator: *operator,
                    body: transformed,
                }))
            }
            LogicExpr::Aspectual { operator, body } => {
                let transformed = self.transform_cardinal_to_group(body)?;
                Ok(self.ctx.exprs.alloc(LogicExpr::Aspectual {
                    operator: *operator,
                    body: transformed,
                }))
            }
            LogicExpr::UnaryOp { op, operand } => {
                let transformed = self.transform_cardinal_to_group(operand)?;
                Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                    op: op.clone(),
                    operand: transformed,
                }))
            }
            LogicExpr::BinaryOp { left, op, right } => {
                let transformed_left = self.transform_cardinal_to_group(left)?;
                let transformed_right = self.transform_cardinal_to_group(right)?;
                Ok(self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: transformed_left,
                    op: op.clone(),
                    right: transformed_right,
                }))
            }
            LogicExpr::Distributive { predicate } => {
                let transformed = self.transform_cardinal_to_group(predicate)?;
                Ok(self.ctx.exprs.alloc(LogicExpr::Distributive {
                    predicate: transformed,
                }))
            }
            LogicExpr::Quantifier { kind, variable, body, island_id } => {
                let transformed = self.transform_cardinal_to_group(body)?;
                Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: kind.clone(),
                    variable: *variable,
                    body: transformed,
                    island_id: *island_id,
                }))
            }
            _ => Ok(expr),
        }
    }
}

```

---

### VerbParsing Trait

**File:** `src/parser/verb.rs`

Extension trait for predicate parsing: subject-verb agreement, aspect chains (progressive/perfect/passive), control structures (want to, try to, seem to), plural subject coordination, thematic role assignment for Neo-Davidsonian events, ditransitive verbs (give/send/tell with Recipient role). **Embedded Clauses:** When filler_gap is set and a verb follows a noun phrase, wraps subordinate clause in Term::Proposition and passes as argument. Enables 'Who did John say Mary loves?' with structure Say(J, [Love(M, x)]). **Do-Support:** Handles do/does/did + (not)? + verb patterns for emphasis and negation. **Sluicing:** Detects wh-word at sentence boundary after embedding verbs (know, wonder); reconstructs event from last_event_template with wh-variable as Agent (who) or Theme (what); wraps in Expr::Question.

```rust
use super::clause::ClauseParsing;
use super::modal::ModalParsing;
use super::noun::NounParsing;
use super::pragmatics::PragmaticsParsing;
use super::{ParseResult, Parser};
use crate::ast::{
    AspectOperator, LogicExpr, NeoEventData, NounPhrase, QuantifierKind, TemporalOperator, Term,
    ThematicRole,
};
use crate::context::{Gender, Number};
use crate::intern::Symbol;
use crate::lexer::Lexer;
use crate::lexicon::{Aspect, Definiteness, Time};
use crate::token::{FocusKind, TokenType};

use crate::ast::Stmt;

pub trait LogicVerbParsing<'a, 'ctx, 'int> {
    fn parse_predicate_with_subject(&mut self, subject_symbol: Symbol)
        -> ParseResult<&'a LogicExpr<'a>>;
    fn try_parse_plural_subject(&mut self, first_subject: &NounPhrase<'a>)
        -> Option<&'a LogicExpr<'a>>;
    fn parse_control_structure(
        &mut self,
        subject: &NounPhrase<'a>,
        verb: Symbol,
        verb_time: Time,
    ) -> ParseResult<&'a LogicExpr<'a>>;
    fn is_control_verb(&self, verb: Symbol) -> bool;
}

pub trait ImperativeVerbParsing<'a, 'ctx, 'int> {
    fn parse_statement_with_subject(&mut self, subject_symbol: Symbol)
        -> ParseResult<Stmt<'a>>;
}

impl<'a, 'ctx, 'int> LogicVerbParsing<'a, 'ctx, 'int> for Parser<'a, 'ctx, 'int> {
    fn parse_predicate_with_subject(
        &mut self,
        subject_symbol: Symbol,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        let subject_term = Term::Constant(subject_symbol);

        if self.check(&TokenType::Never) {
            self.advance();
            let verb = self.consume_verb();
            let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice([subject_term]),
            });
            return Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                op: TokenType::Not,
                operand: verb_pred,
            }));
        }

        if self.check_modal() {
            return self.parse_aspect_chain(subject_symbol);
        }

        if self.check_content_word() {
            let next_word = self.interner.resolve(self.peek().lexeme).to_lowercase();
            if next_word == "has" || next_word == "have" || next_word == "had" {
                // Look ahead to distinguish perfect aspect ("has eaten") from possession ("has 3 children")
                // Perfect aspect: has/have/had + verb
                // Possession: has/have/had + number/noun
                let is_perfect_aspect = if self.current + 1 < self.tokens.len() {
                    let next_token = &self.tokens[self.current + 1].kind;
                    matches!(
                        next_token,
                        TokenType::Verb { .. } | TokenType::Not
                    ) && !matches!(next_token, TokenType::Number(_))
                } else {
                    false
                };
                if is_perfect_aspect {
                    return self.parse_aspect_chain(subject_symbol);
                }
                // Otherwise, treat "has" as a main verb (possession) and continue below
            }
        }

        if self.check(&TokenType::Had) {
            return self.parse_aspect_chain(subject_symbol);
        }

        // Handle do-support: "I do/don't know who"
        if self.check(&TokenType::Does) || self.check(&TokenType::Do) {
            self.advance();
            let is_negated = self.match_token(&[TokenType::Not]);

            if self.check(&TokenType::Ever) {
                self.advance();
            }

            if self.check_verb() {
                let verb = self.consume_verb();

                // Check for embedded wh-clause with sluicing: "I don't know who"
                if self.check_wh_word() {
                    let wh_token = self.advance().kind.clone();
                    let is_who = matches!(wh_token, TokenType::Who);
                    let is_what = matches!(wh_token, TokenType::What);

                    let is_sluicing = self.is_at_end() ||
                        self.check(&TokenType::Period) ||
                        self.check(&TokenType::Comma);

                    if is_sluicing {
                        if let Some(template) = self.last_event_template.clone() {
                            let wh_var = self.next_var_name();

                            let roles: Vec<_> = if is_who {
                                std::iter::once((ThematicRole::Agent, Term::Variable(wh_var)))
                                    .chain(template.non_agent_roles.iter().cloned())
                                    .collect()
                            } else if is_what {
                                vec![
                                    (ThematicRole::Agent, subject_term.clone()),
                                    (ThematicRole::Theme, Term::Variable(wh_var)),
                                ]
                            } else {
                                std::iter::once((ThematicRole::Agent, Term::Variable(wh_var)))
                                    .chain(template.non_agent_roles.iter().cloned())
                                    .collect()
                            };

                            let event_var = self.get_event_var();
                            let reconstructed = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                                event_var,
                                verb: template.verb,
                                roles: self.ctx.roles.alloc_slice(roles),
                                modifiers: self.ctx.syms.alloc_slice(template.modifiers.clone()),
                            })));

                            let question = self.ctx.exprs.alloc(LogicExpr::Question {
                                wh_variable: wh_var,
                                body: reconstructed,
                            });

                            let know_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                                event_var: self.get_event_var(),
                                verb,
                                roles: self.ctx.roles.alloc_slice(vec![
                                    (ThematicRole::Agent, subject_term.clone()),
                                    (ThematicRole::Theme, Term::Proposition(question)),
                                ]),
                                modifiers: self.ctx.syms.alloc_slice(vec![]),
                            })));

                            let result = if is_negated {
                                self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                                    op: TokenType::Not,
                                    operand: know_event,
                                })
                            } else {
                                know_event
                            };

                            return Ok(result);
                        }
                    }
                }

                // Regular do-support: "I do run" or "I don't run"
                let roles: Vec<(ThematicRole, Term<'a>)> = vec![(ThematicRole::Agent, subject_term.clone())];
                let modifiers: Vec<Symbol> = vec![];
                let event_var = self.get_event_var();

                let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                    event_var,
                    verb,
                    roles: self.ctx.roles.alloc_slice(roles),
                    modifiers: self.ctx.syms.alloc_slice(modifiers),
                })));

                if is_negated {
                    return Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                        op: TokenType::Not,
                        operand: neo_event,
                    }));
                }
                return Ok(neo_event);
            }
        }

        if self.check_auxiliary() {
            let aux_time = if let TokenType::Auxiliary(time) = self.advance().kind {
                time
            } else {
                Time::None
            };
            self.pending_time = Some(aux_time);

            if self.match_token(&[TokenType::Not]) {
                self.negative_depth += 1;

                if self.check_verb() {
                    let verb = self.consume_verb();

                    if self.check_quantifier() {
                        let quantifier_token = self.advance().kind.clone();
                        let object_np = self.parse_noun_phrase(false)?;
                        let obj_var = self.next_var_name();

                        let obj_restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: object_np.noun,
                            args: self.ctx.terms.alloc_slice([Term::Variable(obj_var)]),
                        });

                        let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: verb,
                            args: self
                                .ctx
                                .terms
                                .alloc_slice([subject_term, Term::Variable(obj_var)]),
                        });

                        let (kind, body) = match quantifier_token {
                            TokenType::Any => {
                                if self.is_negative_context() {
                                    (
                                        QuantifierKind::Existential,
                                        self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                            left: obj_restriction,
                                            op: TokenType::And,
                                            right: verb_pred,
                                        }),
                                    )
                                } else {
                                    (
                                        QuantifierKind::Universal,
                                        self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                            left: obj_restriction,
                                            op: TokenType::If,
                                            right: verb_pred,
                                        }),
                                    )
                                }
                            }
                            TokenType::Some => (
                                QuantifierKind::Existential,
                                self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                    left: obj_restriction,
                                    op: TokenType::And,
                                    right: verb_pred,
                                }),
                            ),
                            TokenType::All => (
                                QuantifierKind::Universal,
                                self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                    left: obj_restriction,
                                    op: TokenType::If,
                                    right: verb_pred,
                                }),
                            ),
                            _ => (
                                QuantifierKind::Existential,
                                self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                    left: obj_restriction,
                                    op: TokenType::And,
                                    right: verb_pred,
                                }),
                            ),
                        };

                        let quantified = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                            kind,
                            variable: obj_var,
                            body,
                            island_id: self.current_island,
                        });

                        let effective_time = self.pending_time.take().unwrap_or(Time::None);
                        let with_time = match effective_time {
                            Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                                operator: TemporalOperator::Past,
                                body: quantified,
                            }),
                            Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                                operator: TemporalOperator::Future,
                                body: quantified,
                            }),
                            _ => quantified,
                        };

                        self.negative_depth -= 1;
                        return Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                            op: TokenType::Not,
                            operand: with_time,
                        }));
                    }

                    if self.check_npi_object() {
                        let npi_token = self.advance().kind.clone();
                        let obj_var = self.next_var_name();

                        let restriction_name = match npi_token {
                            TokenType::Anything => "Thing",
                            TokenType::Anyone => "Person",
                            _ => "Thing",
                        };

                        let restriction_sym = self.interner.intern(restriction_name);
                        let obj_restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: restriction_sym,
                            args: self.ctx.terms.alloc_slice([Term::Variable(obj_var)]),
                        });

                        let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: verb,
                            args: self.ctx.terms.alloc_slice([subject_term, Term::Variable(obj_var)]),
                        });

                        let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: obj_restriction,
                            op: TokenType::And,
                            right: verb_pred,
                        });

                        let quantified = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                            kind: QuantifierKind::Existential,
                            variable: obj_var,
                            body,
                            island_id: self.current_island,
                        });

                        let effective_time = self.pending_time.take().unwrap_or(Time::None);
                        let with_time = match effective_time {
                            Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                                operator: TemporalOperator::Past,
                                body: quantified,
                            }),
                            Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                                operator: TemporalOperator::Future,
                                body: quantified,
                            }),
                            _ => quantified,
                        };

                        self.negative_depth -= 1;
                        return Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                            op: TokenType::Not,
                            operand: with_time,
                        }));
                    }

                    let mut roles: Vec<(ThematicRole, Term<'a>)> =
                        vec![(ThematicRole::Agent, subject_term)];

                    if self.check_content_word() || self.check_article() {
                        let object = self.parse_noun_phrase(false)?;
                        let object_term = self.noun_phrase_to_term(&object);
                        roles.push((ThematicRole::Theme, object_term));
                    }

                    let event_var = self.get_event_var();
                    let effective_time = self.pending_time.take().unwrap_or(Time::None);
                    let mut modifiers = Vec::new();
                    match effective_time {
                        Time::Past => modifiers.push(self.interner.intern("Past")),
                        Time::Future => modifiers.push(self.interner.intern("Future")),
                        _ => {}
                    }

                    let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                        event_var,
                        verb,
                        roles: self.ctx.roles.alloc_slice(roles),
                        modifiers: self.ctx.syms.alloc_slice(modifiers),
                    })));

                    self.negative_depth -= 1;
                    return Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                        op: TokenType::Not,
                        operand: neo_event,
                    }));
                }

                self.negative_depth -= 1;
            }
        }

        if self.check(&TokenType::Is)
            || self.check(&TokenType::Are)
            || self.check(&TokenType::Was)
            || self.check(&TokenType::Were)
        {
            let copula_time = if self.check(&TokenType::Was) || self.check(&TokenType::Were) {
                Time::Past
            } else {
                Time::Present
            };
            self.advance();

            if self.check_verb() {
                let (verb, _verb_time, verb_aspect, verb_class) = self.consume_verb_with_metadata();

                // Stative verbs cannot be progressive
                if verb_class.is_stative() && verb_aspect == Aspect::Progressive {
                    return Err(crate::error::ParseError {
                        kind: crate::error::ParseErrorKind::StativeProgressiveConflict,
                        span: self.current_span(),
                    });
                }

                let predicate = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb,
                    args: self.ctx.terms.alloc_slice([subject_term]),
                });

                let with_aspect = if verb_aspect == Aspect::Progressive {
                    // Semelfactive + Progressive → Iterative
                    let operator = if verb_class == crate::lexicon::VerbClass::Semelfactive {
                        AspectOperator::Iterative
                    } else {
                        AspectOperator::Progressive
                    };
                    self.ctx.exprs.alloc(LogicExpr::Aspectual {
                        operator,
                        body: predicate,
                    })
                } else {
                    predicate
                };

                return Ok(if copula_time == Time::Past {
                    self.ctx.exprs.alloc(LogicExpr::Temporal {
                        operator: TemporalOperator::Past,
                        body: with_aspect,
                    })
                } else {
                    with_aspect
                });
            }

            let predicate = self.consume_content_word()?;
            return Ok(self.ctx.exprs.alloc(LogicExpr::Atom(predicate)));
        }

        if self.check_verb() {
            let (mut verb, verb_time, verb_aspect, verb_class) = self.consume_verb_with_metadata();
            let mut args = vec![subject_term.clone()];

            // Check for embedded wh-clause: "I know who/what"
            if self.check_wh_word() {
                let wh_token = self.advance().kind.clone();

                let is_who = matches!(wh_token, TokenType::Who);
                let is_what = matches!(wh_token, TokenType::What);

                // Check for sluicing: wh-word followed by terminator
                let is_sluicing = self.is_at_end() ||
                    self.check(&TokenType::Period) ||
                    self.check(&TokenType::Comma);

                if is_sluicing {
                    if let Some(template) = self.last_event_template.clone() {
                        let wh_var = self.next_var_name();

                        let roles: Vec<_> = if is_who {
                            std::iter::once((ThematicRole::Agent, Term::Variable(wh_var)))
                                .chain(template.non_agent_roles.iter().cloned())
                                .collect()
                        } else if is_what {
                            vec![
                                (ThematicRole::Agent, subject_term.clone()),
                                (ThematicRole::Theme, Term::Variable(wh_var)),
                            ]
                        } else {
                            std::iter::once((ThematicRole::Agent, Term::Variable(wh_var)))
                                .chain(template.non_agent_roles.iter().cloned())
                                .collect()
                        };

                        let event_var = self.get_event_var();
                        let reconstructed = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                            event_var,
                            verb: template.verb,
                            roles: self.ctx.roles.alloc_slice(roles),
                            modifiers: self.ctx.syms.alloc_slice(template.modifiers.clone()),
                        })));

                        let question = self.ctx.exprs.alloc(LogicExpr::Question {
                            wh_variable: wh_var,
                            body: reconstructed,
                        });

                        let know_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                            event_var: self.get_event_var(),
                            verb,
                            roles: self.ctx.roles.alloc_slice(vec![
                                (ThematicRole::Agent, subject_term),
                                (ThematicRole::Theme, Term::Proposition(question)),
                            ]),
                            modifiers: self.ctx.syms.alloc_slice(vec![]),
                        })));

                        return Ok(know_event);
                    }
                }

                // Non-sluicing: "I know who runs"
                let embedded = self.parse_embedded_wh_clause()?;
                let question = self.ctx.exprs.alloc(LogicExpr::Question {
                    wh_variable: self.interner.intern("x"),
                    body: embedded,
                });

                let know_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                    event_var: self.get_event_var(),
                    verb,
                    roles: self.ctx.roles.alloc_slice(vec![
                        (ThematicRole::Agent, subject_term),
                        (ThematicRole::Theme, Term::Proposition(question)),
                    ]),
                    modifiers: self.ctx.syms.alloc_slice(vec![]),
                })));

                return Ok(know_event);
            }

            let mut object_term: Option<Term<'a>> = None;
            let mut second_object_term: Option<Term<'a>> = None;
            if self.check(&TokenType::Reflexive) {
                self.advance();
                let term = Term::Constant(subject_symbol);
                object_term = Some(term);
                args.push(term);
            } else if self.check_pronoun() {
                let token = self.advance().clone();
                let (gender, number) = match &token.kind {
                    TokenType::Pronoun { gender, number, .. } => (*gender, *number),
                    TokenType::Ambiguous { primary, alternatives } => {
                        if let TokenType::Pronoun { gender, number, .. } = **primary {
                            (gender, number)
                        } else {
                            alternatives.iter().find_map(|t| {
                                if let TokenType::Pronoun { gender, number, .. } = t {
                                    Some((*gender, *number))
                                } else {
                                    None
                                }
                            }).unwrap_or((Gender::Unknown, Number::Singular))
                        }
                    }
                    _ => (Gender::Unknown, Number::Singular),
                };

                let resolved = self
                    .resolve_pronoun(gender, number)
                    .unwrap_or_else(|| self.interner.intern("?"));
                let term = Term::Constant(resolved);
                object_term = Some(term);
                args.push(term);

                let verb_str = self.interner.resolve(verb);
                if Lexer::is_ditransitive_verb(verb_str)
                    && (self.check_content_word() || self.check_article())
                {
                    let second_np = self.parse_noun_phrase(false)?;
                    let second_term = Term::Constant(second_np.noun);
                    second_object_term = Some(second_term);
                    args.push(second_term);
                }
            } else if self.check_quantifier() || self.check_article() {
                let obj_quantifier = if self.check_quantifier() {
                    Some(self.advance().kind.clone())
                } else {
                    let art = self.advance().kind.clone();
                    if let TokenType::Article(def) = art {
                        if def == Definiteness::Indefinite {
                            Some(TokenType::Some)
                        } else {
                            None
                        }
                    } else {
                        None
                    }
                };

                let object_np = self.parse_noun_phrase(false)?;

                if let Some(obj_q) = obj_quantifier {
                    let obj_var = self.next_var_name();
                    let obj_restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: object_np.noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(obj_var)]),
                    });

                    let event_var = self.get_event_var();
                    let mut modifiers = self.collect_adverbs();
                    let effective_time = self.pending_time.take().unwrap_or(verb_time);
                    match effective_time {
                        Time::Past => modifiers.push(self.interner.intern("Past")),
                        Time::Future => modifiers.push(self.interner.intern("Future")),
                        _ => {}
                    }

                    let roles = vec![
                        (ThematicRole::Agent, subject_term),
                        (ThematicRole::Theme, Term::Variable(obj_var)),
                    ];

                    let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                        event_var,
                        verb,
                        roles: self.ctx.roles.alloc_slice(roles),
                        modifiers: self.ctx.syms.alloc_slice(modifiers),
                    })));

                    let obj_kind = match obj_q {
                        TokenType::All => QuantifierKind::Universal,
                        TokenType::Some => QuantifierKind::Existential,
                        TokenType::No => QuantifierKind::Universal,
                        TokenType::Most => QuantifierKind::Most,
                        TokenType::Few => QuantifierKind::Few,
                        TokenType::Many => QuantifierKind::Many,
                        TokenType::Cardinal(n) => QuantifierKind::Cardinal(n),
                        TokenType::AtLeast(n) => QuantifierKind::AtLeast(n),
                        TokenType::AtMost(n) => QuantifierKind::AtMost(n),
                        _ => QuantifierKind::Existential,
                    };

                    let obj_body = match obj_q {
                        TokenType::All => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: obj_restriction,
                            op: TokenType::If,
                            right: neo_event,
                        }),
                        TokenType::No => {
                            let neg = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                                op: TokenType::Not,
                                operand: neo_event,
                            });
                            self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                left: obj_restriction,
                                op: TokenType::If,
                                right: neg,
                            })
                        }
                        _ => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: obj_restriction,
                            op: TokenType::And,
                            right: neo_event,
                        }),
                    };

                    return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                        kind: obj_kind,
                        variable: obj_var,
                        body: obj_body,
                        island_id: self.current_island,
                    }));
                } else {
                    let term = Term::Constant(object_np.noun);
                    object_term = Some(term);
                    args.push(term);
                }
            } else if self.check_focus() {
                let focus_kind = if let TokenType::Focus(k) = self.advance().kind {
                    k
                } else {
                    FocusKind::Only
                };

                let event_var = self.get_event_var();
                let mut modifiers = self.collect_adverbs();
                let effective_time = self.pending_time.take().unwrap_or(verb_time);
                match effective_time {
                    Time::Past => modifiers.push(self.interner.intern("Past")),
                    Time::Future => modifiers.push(self.interner.intern("Future")),
                    _ => {}
                }

                if self.check_preposition() {
                    let prep_token = self.advance().clone();
                    let prep_name = if let TokenType::Preposition(sym) = prep_token.kind {
                        sym
                    } else {
                        self.interner.intern("to")
                    };
                    let pp_obj = self.parse_noun_phrase(false)?;
                    let pp_obj_term = Term::Constant(pp_obj.noun);

                    let roles = vec![(ThematicRole::Agent, subject_term)];
                    let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                        event_var,
                        verb,
                        roles: self.ctx.roles.alloc_slice(roles),
                        modifiers: self.ctx.syms.alloc_slice(modifiers),
                    })));

                    let pp_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: prep_name,
                        args: self.ctx.terms.alloc_slice([Term::Variable(event_var), pp_obj_term]),
                    });

                    let with_pp = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: neo_event,
                        op: TokenType::And,
                        right: pp_pred,
                    });

                    let focused_ref = self.ctx.terms.alloc(pp_obj_term);
                    return Ok(self.ctx.exprs.alloc(LogicExpr::Focus {
                        kind: focus_kind,
                        focused: focused_ref,
                        scope: with_pp,
                    }));
                }

                let focused_np = self.parse_noun_phrase(false)?;
                let focused_term = Term::Constant(focused_np.noun);
                args.push(focused_term);

                let roles = vec![
                    (ThematicRole::Agent, subject_term),
                    (ThematicRole::Theme, focused_term),
                ];

                let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                    event_var,
                    verb,
                    roles: self.ctx.roles.alloc_slice(roles),
                    modifiers: self.ctx.syms.alloc_slice(modifiers),
                })));

                let focused_ref = self.ctx.terms.alloc(focused_term);
                return Ok(self.ctx.exprs.alloc(LogicExpr::Focus {
                    kind: focus_kind,
                    focused: focused_ref,
                    scope: neo_event,
                }));
            } else if self.check_number() {
                let measure = self.parse_measure_phrase()?;
                if self.check_content_word() {
                    let noun_sym = self.consume_content_word()?;
                    args.push(*measure);
                    args.push(Term::Constant(noun_sym));
                } else {
                    args.push(*measure);
                }
            } else if self.check_content_word() {
                let potential_object = self.parse_noun_phrase(false)?;

                if self.check_verb() && self.filler_gap.is_some() {
                    let embedded_subject = potential_object.noun;
                    let embedded_pred = self.parse_predicate_with_subject(embedded_subject)?;

                    let embedded_term = Term::Proposition(embedded_pred);
                    let main_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: verb,
                        args: self.ctx.terms.alloc_slice([subject_term, embedded_term]),
                    });

                    let effective_time = self.pending_time.take().unwrap_or(verb_time);
                    return Ok(if effective_time == Time::Past {
                        self.ctx.exprs.alloc(LogicExpr::Temporal {
                            operator: TemporalOperator::Past,
                            body: main_pred,
                        })
                    } else {
                        main_pred
                    });
                }

                let term = Term::Constant(potential_object.noun);
                object_term = Some(term);
                args.push(term);

                let verb_str = self.interner.resolve(verb);
                if Lexer::is_ditransitive_verb(verb_str)
                    && (self.check_content_word() || self.check_article())
                {
                    let second_np = self.parse_noun_phrase(false)?;
                    let second_term = Term::Constant(second_np.noun);
                    second_object_term = Some(second_term);
                    args.push(second_term);
                }
            } else if self.filler_gap.is_some() && !self.check_content_word() && !self.check_pronoun()
            {
                let gap_var = self.filler_gap.take().unwrap();
                let term = Term::Variable(gap_var);
                object_term = Some(term);
                args.push(term);
            }

            // Check for distanced phrasal verb particle: "gave the book up"
            if let TokenType::Particle(particle_sym) = self.peek().kind {
                let verb_str = self.interner.resolve(verb).to_lowercase();
                let particle_str = self.interner.resolve(particle_sym).to_lowercase();
                if let Some((phrasal_lemma, _class)) = crate::lexicon::lookup_phrasal_verb(&verb_str, &particle_str) {
                    self.advance(); // consume the particle
                    verb = self.interner.intern(phrasal_lemma);
                }
            }

            let unknown = self.interner.intern("?");
            let mut pp_predicates: Vec<&'a LogicExpr<'a>> = Vec::new();
            while self.check_preposition() || self.check_to() {
                let prep_token = self.advance().clone();
                let prep_name = if let TokenType::Preposition(sym) = prep_token.kind {
                    sym
                } else if matches!(prep_token.kind, TokenType::To) {
                    self.interner.intern("To")
                } else {
                    continue;
                };

                let pp_obj_term = if self.check(&TokenType::Reflexive) {
                    self.advance();
                    Term::Constant(subject_symbol)
                } else if self.check_pronoun() {
                    let token = self.advance().clone();
                    let (gender, number) = match &token.kind {
                        TokenType::Pronoun { gender, number, .. } => (*gender, *number),
                        TokenType::Ambiguous { primary, alternatives } => {
                            if let TokenType::Pronoun { gender, number, .. } = **primary {
                                (gender, number)
                            } else {
                                alternatives.iter().find_map(|t| {
                                    if let TokenType::Pronoun { gender, number, .. } = t {
                                        Some((*gender, *number))
                                    } else {
                                        None
                                    }
                                }).unwrap_or((Gender::Unknown, Number::Singular))
                            }
                        }
                        _ => (Gender::Unknown, Number::Singular),
                    };
                    let resolved = self.resolve_pronoun(gender, number).unwrap_or(unknown);
                    Term::Constant(resolved)
                } else if self.check_content_word() || self.check_article() {
                    let prep_obj = self.parse_noun_phrase(false)?;
                    Term::Constant(prep_obj.noun)
                } else {
                    continue;
                };

                if self.pp_attach_to_noun {
                    if let Some(obj) = object_term {
                        let pp_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: prep_name,
                            args: self.ctx.terms.alloc_slice([obj, pp_obj_term]),
                        });
                        pp_predicates.push(pp_pred);
                    } else {
                        args.push(pp_obj_term);
                    }
                } else {
                    let event_sym = self.get_event_var();
                    let pp_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: prep_name,
                        args: self
                            .ctx
                            .terms
                            .alloc_slice([Term::Variable(event_sym), pp_obj_term]),
                    });
                    pp_predicates.push(pp_pred);
                }
            }

            if self.check(&TokenType::That) || self.check(&TokenType::Who) {
                self.advance();
                let rel_var = self.next_var_name();
                let rel_pred = self.parse_relative_clause(rel_var)?;
                pp_predicates.push(rel_pred);
            }

            let mut modifiers = self.collect_adverbs();

            let effective_time = self.pending_time.take().unwrap_or(verb_time);
            match effective_time {
                Time::Past => modifiers.push(self.interner.intern("Past")),
                Time::Future => modifiers.push(self.interner.intern("Future")),
                _ => {}
            }

            if verb_aspect == Aspect::Progressive {
                modifiers.push(self.interner.intern("Progressive"));
            } else if verb_aspect == Aspect::Perfect {
                modifiers.push(self.interner.intern("Perfect"));
            }

            let mut roles: Vec<(ThematicRole, Term<'a>)> = Vec::new();
            roles.push((ThematicRole::Agent, subject_term));
            if let Some(second_obj) = second_object_term {
                if let Some(first_obj) = object_term {
                    roles.push((ThematicRole::Recipient, first_obj));
                }
                roles.push((ThematicRole::Theme, second_obj));
            } else if let Some(obj) = object_term {
                roles.push((ThematicRole::Theme, obj));
            }

            let event_var = self.get_event_var();
            let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                event_var,
                verb,
                roles: self.ctx.roles.alloc_slice(roles.clone()),
                modifiers: self.ctx.syms.alloc_slice(modifiers.clone()),
            })));

            // Capture template for ellipsis reconstruction
            self.capture_event_template(verb, &roles, &modifiers);

            let with_pps = if pp_predicates.is_empty() {
                neo_event
            } else {
                let mut combined = neo_event;
                for pp in pp_predicates {
                    combined = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: combined,
                        op: TokenType::And,
                        right: pp,
                    });
                }
                combined
            };

            // Apply aspectual operators based on verb class
            let with_aspect = if verb_aspect == Aspect::Simple && effective_time == Time::Present {
                // Non-state verbs in simple present get Habitual reading
                if !verb_class.is_stative() {
                    self.ctx.exprs.alloc(LogicExpr::Aspectual {
                        operator: AspectOperator::Habitual,
                        body: with_pps,
                    })
                } else {
                    with_pps
                }
            } else if verb_aspect == Aspect::Progressive {
                // Semelfactive + Progressive → Iterative
                if verb_class == crate::lexicon::VerbClass::Semelfactive {
                    self.ctx.exprs.alloc(LogicExpr::Aspectual {
                        operator: AspectOperator::Iterative,
                        body: with_pps,
                    })
                } else {
                    with_pps
                }
            } else {
                with_pps
            };

            Ok(with_aspect)
        } else {
            Ok(self.ctx.exprs.alloc(LogicExpr::Atom(subject_symbol)))
        }
    }

    fn try_parse_plural_subject(
        &mut self,
        first_subject: &NounPhrase<'a>,
    ) -> Option<&'a LogicExpr<'a>> {
        let saved_pos = self.current;

        self.advance();

        if !self.check_content_word() {
            self.current = saved_pos;
            return None;
        }

        let second_subject = self.parse_noun_phrase(true).ok()?;

        if !self.check_verb() {
            self.current = saved_pos;
            return None;
        }

        let (verb, verb_time, _verb_aspect, _) = self.consume_verb_with_metadata();

        if self.check(&TokenType::Reciprocal) {
            self.advance();
            let pred1 = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice([
                    Term::Constant(first_subject.noun),
                    Term::Constant(second_subject.noun),
                ]),
            });
            let pred2 = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice([
                    Term::Constant(second_subject.noun),
                    Term::Constant(first_subject.noun),
                ]),
            });
            let expr = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: pred1,
                op: TokenType::And,
                right: pred2,
            });

            let with_time = match verb_time {
                Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                    operator: TemporalOperator::Past,
                    body: expr,
                }),
                Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                    operator: TemporalOperator::Future,
                    body: expr,
                }),
                _ => expr,
            };
            return Some(with_time);
        }

        let first_sym = self.interner.resolve(first_subject.noun);
        let second_sym = self.interner.resolve(second_subject.noun);
        let group_name = format!("{}⊕{}", first_sym, second_sym);
        self.register_entity(&group_name, "group", Gender::Unknown, Number::Plural);

        let group_members = self.ctx.terms.alloc_slice([
            Term::Constant(first_subject.noun),
            Term::Constant(second_subject.noun),
        ]);
        let expr = self.ctx.exprs.alloc(LogicExpr::Predicate {
            name: verb,
            args: self.ctx.terms.alloc_slice([Term::Group(group_members)]),
        });

        let with_time = match verb_time {
            Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                operator: TemporalOperator::Past,
                body: expr,
            }),
            Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                operator: TemporalOperator::Future,
                body: expr,
            }),
            _ => expr,
        };

        Some(with_time)
    }

    fn parse_control_structure(
        &mut self,
        subject: &NounPhrase<'a>,
        verb: Symbol,
        verb_time: Time,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        let subject_sym = subject.noun;
        let verb_str = self.interner.resolve(verb);

        if Lexer::is_raising_verb(verb_str) {
            if !self.check_to() {
                return Ok(self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb,
                    args: self.ctx.terms.alloc_slice([Term::Constant(subject_sym)]),
                }));
            }
            self.advance();

            if !self.check_verb() {
                return Ok(self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb,
                    args: self.ctx.terms.alloc_slice([Term::Constant(subject_sym)]),
                }));
            }

            let inf_verb = self.consume_verb();

            let embedded = if self.is_control_verb(inf_verb) {
                let raised_np = NounPhrase {
                    noun: subject_sym,
                    definiteness: None,
                    adjectives: &[],
                    possessor: None,
                    pps: &[],
                    superlative: None,
                };
                self.parse_control_structure(&raised_np, inf_verb, Time::None)?
            } else {
                self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: inf_verb,
                    args: self.ctx.terms.alloc_slice([Term::Constant(subject_sym)]),
                })
            };

            let result = self.ctx.exprs.alloc(LogicExpr::Scopal {
                operator: verb,
                body: embedded,
            });

            return Ok(match verb_time {
                Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                    operator: TemporalOperator::Past,
                    body: result,
                }),
                Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                    operator: TemporalOperator::Future,
                    body: result,
                }),
                _ => result,
            });
        }

        let is_object_control = Lexer::is_object_control_verb(self.interner.resolve(verb));
        let (object_term, pro_controller_sym) = if self.check_to() {
            (None, subject_sym)
        } else if self.check_content_word() {
            let object_np = self.parse_noun_phrase(false)?;
            let obj_sym = object_np.noun;

            let controller = if is_object_control {
                obj_sym
            } else {
                subject_sym
            };
            (
                Some(self.ctx.terms.alloc(Term::Constant(obj_sym))),
                controller,
            )
        } else {
            (None, subject_sym)
        };

        if !self.check_to() {
            return Ok(self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: match object_term {
                    Some(obj) => self.ctx.terms.alloc_slice([
                        Term::Constant(subject_sym),
                        Term::Constant(match obj {
                            Term::Constant(s) => *s,
                            _ => subject_sym,
                        }),
                    ]),
                    None => self.ctx.terms.alloc_slice([Term::Constant(subject_sym)]),
                },
            }));
        }
        self.advance();

        if !self.check_verb() {
            return Ok(self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice([Term::Constant(subject_sym)]),
            }));
        }

        let inf_verb = self.consume_verb();
        let inf_verb_str = self.interner.resolve(inf_verb).to_lowercase();

        let infinitive = if inf_verb_str == "be" && self.check_verb() {
            let passive_verb = self.consume_verb();
            let passive_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: passive_verb,
                args: self
                    .ctx
                    .terms
                    .alloc_slice([Term::Constant(pro_controller_sym)]),
            });
            self.ctx.voice(crate::ast::VoiceOperator::Passive, passive_pred)
        } else if self.is_control_verb(inf_verb) {
            let controller_np = NounPhrase {
                noun: pro_controller_sym,
                definiteness: None,
                adjectives: &[],
                possessor: None,
                pps: &[],
                superlative: None,
            };
            self.parse_control_structure(&controller_np, inf_verb, Time::None)?
        } else {
            self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: inf_verb,
                args: self
                    .ctx
                    .terms
                    .alloc_slice([Term::Constant(pro_controller_sym)]),
            })
        };

        let control = self.ctx.exprs.alloc(LogicExpr::Control {
            verb,
            subject: self.ctx.terms.alloc(Term::Constant(subject_sym)),
            object: object_term,
            infinitive,
        });

        Ok(match verb_time {
            Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                operator: TemporalOperator::Past,
                body: control,
            }),
            Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                operator: TemporalOperator::Future,
                body: control,
            }),
            _ => control,
        })
    }

    fn is_control_verb(&self, verb: Symbol) -> bool {
        let lemma = self.interner.resolve(verb);
        Lexer::is_subject_control_verb(lemma)
            || Lexer::is_object_control_verb(lemma)
            || Lexer::is_raising_verb(lemma)
    }
}

```

---

### NounParsing Trait

**File:** `src/parser/noun.rs`

Extension trait for noun phrase parsing: articles, intersective/non-intersective adjectives (with compound interning), proper names, possessives ('s and 'of' forms), and PP attachment. Includes check_proper_name_or_label() for compound identifiers (set_A, function_F). Registers definite NPs for anaphora with gender/number inference. Provides parse_noun_phrase_for_relative() for relative clause contexts. Converts NounPhrase to Term for predicate arguments.

```rust
use super::clause::ClauseParsing;
use super::{ParseResult, Parser};
use crate::ast::{LogicExpr, NounPhrase, Term};
use crate::context::{Case, Gender, Number};
use crate::intern::SymbolEq;
use crate::lexicon::Definiteness;
use crate::token::TokenType;

pub trait NounParsing<'a, 'ctx, 'int> {
    fn parse_noun_phrase(&mut self, greedy: bool) -> ParseResult<NounPhrase<'a>>;
    fn parse_noun_phrase_for_relative(&mut self) -> ParseResult<NounPhrase<'a>>;
    fn noun_phrase_to_term(&self, np: &NounPhrase<'a>) -> Term<'a>;
    fn check_possessive(&self) -> bool;
    fn check_of_preposition(&self) -> bool;
    fn check_proper_name_or_label(&self) -> bool;
    fn check_possessive_pronoun(&self) -> bool;
}

impl<'a, 'ctx, 'int> NounParsing<'a, 'ctx, 'int> for Parser<'a, 'ctx, 'int> {
    fn parse_noun_phrase(&mut self, greedy: bool) -> ParseResult<NounPhrase<'a>> {
        let mut definiteness = None;
        let mut adjectives = Vec::new();
        let mut non_intersective_prefix: Option<crate::intern::Symbol> = None;
        let mut possessor_from_pronoun: Option<&'a NounPhrase<'a>> = None;
        let mut superlative_adj: Option<crate::intern::Symbol> = None;

        // Phase 35: Support numeric literals as noun phrases (e.g., "equal to 42")
        if let TokenType::Number(sym) = self.peek().kind {
            self.advance();
            return Ok(NounPhrase {
                definiteness: None,
                adjectives: &[],
                noun: sym,
                possessor: None,
                pps: &[],
                superlative: None,
            });
        }

        if self.check_possessive_pronoun() {
            let token = self.advance().clone();
            let (gender, number) = match &token.kind {
                TokenType::Pronoun { gender, number, case: Case::Possessive } => (*gender, *number),
                TokenType::Ambiguous { primary, alternatives } => {
                    let mut found = None;
                    if let TokenType::Pronoun { gender, number, case: Case::Possessive } = **primary {
                        found = Some((gender, number));
                    }
                    if found.is_none() {
                        for alt in alternatives {
                            if let TokenType::Pronoun { gender, number, case: Case::Possessive } = alt {
                                found = Some((*gender, *number));
                                break;
                            }
                        }
                    }
                    found.unwrap_or((Gender::Unknown, Number::Singular))
                }
                _ => (Gender::Unknown, Number::Singular),
            };

            let resolved = self.resolve_pronoun(gender, number)
                .unwrap_or_else(|| self.interner.intern("?"));

            let possessor_np = NounPhrase {
                definiteness: None,
                adjectives: &[],
                noun: resolved,
                possessor: None,
                pps: &[],
                superlative: None,
            };
            possessor_from_pronoun = Some(self.ctx.nps.alloc(possessor_np));
            definiteness = Some(Definiteness::Definite);
        } else if let TokenType::Article(def) = self.peek().kind {
            // Phase 35: Disambiguate "a" as variable vs article
            // If "a" or "an" is followed by a verb/copula/modal, it's a variable name, not an article
            let is_variable_a = {
                let lexeme = self.interner.resolve(self.peek().lexeme).to_lowercase();
                if lexeme == "a" || lexeme == "an" {
                    if let Some(next) = self.tokens.get(self.current + 1) {
                        matches!(next.kind,
                            TokenType::Is | TokenType::Are | TokenType::Was | TokenType::Were | // Copula
                            TokenType::Verb { .. } | // Main verb
                            TokenType::Auxiliary(_) | // will, did
                            TokenType::Must | TokenType::Can | TokenType::Should | TokenType::May | // Modals
                            TokenType::Could | TokenType::Would | TokenType::Shall |
                            TokenType::Identity | TokenType::Equals // "a = b"
                        )
                    } else {
                        false
                    }
                } else {
                    false
                }
            };

            if !is_variable_a {
                definiteness = Some(def);
                self.advance();
            }
        }

        if self.check_superlative() {
            if let TokenType::Superlative(adj) = self.advance().kind {
                superlative_adj = Some(adj);
            }
        }

        if self.check_non_intersective_adjective() {
            if let TokenType::NonIntersectiveAdjective(adj) = self.advance().kind {
                non_intersective_prefix = Some(adj);
            }
        }

        loop {
            if self.is_at_end() {
                break;
            }

            let is_adjective = matches!(self.peek().kind, TokenType::Adjective(_));
            if !is_adjective {
                break;
            }

            let next_is_content = if self.current + 1 < self.tokens.len() {
                matches!(
                    self.tokens[self.current + 1].kind,
                    TokenType::Noun(_)
                        | TokenType::Adjective(_)
                        | TokenType::ProperName(_)
                )
            } else {
                false
            };

            if next_is_content {
                if let TokenType::Adjective(adj) = self.advance().kind {
                    adjectives.push(adj);
                }
            } else {
                break;
            }
        }

        let base_noun = self.consume_content_word()?;

        let noun = if let Some(prefix) = non_intersective_prefix {
            let prefix_str = self.interner.resolve(prefix);
            let base_str = self.interner.resolve(base_noun);
            let compound = format!("{}-{}", prefix_str, base_str);
            self.interner.intern(&compound)
        } else {
            base_noun
        };

        let noun = if self.check_proper_name_or_label() {
            let label = self.consume_content_word()?;
            let label_str = self.interner.resolve(label);
            let base_str = self.interner.resolve(noun);
            let compound = format!("{}_{}", base_str, label_str);
            self.interner.intern(&compound)
        } else {
            noun
        };

        if self.check_possessive() {
            self.advance();

            let possessor = self.ctx.nps.alloc(NounPhrase {
                definiteness,
                adjectives: self.ctx.syms.alloc_slice(adjectives.clone()),
                noun,
                possessor: None,
                pps: &[],
                superlative: superlative_adj,
            });

            let possessed_noun = self.consume_content_word()?;

            return Ok(NounPhrase {
                definiteness: None,
                adjectives: &[],
                noun: possessed_noun,
                possessor: Some(possessor),
                pps: &[],
                superlative: None,
            });
        }

        let should_attach_pps = greedy || self.pp_attach_to_noun;

        let mut pps: Vec<&'a LogicExpr<'a>> = Vec::new();
        if should_attach_pps {
            while self.check_preposition() && !self.check_of_preposition() {
                let prep_token = self.advance().clone();
                let prep_name = if let TokenType::Preposition(sym) = prep_token.kind {
                    sym
                } else {
                    break;
                };

                if self.check_content_word() || matches!(self.peek().kind, TokenType::Article(_)) {
                    let pp_object = self.parse_noun_phrase(true)?;
                    let placeholder_var = self.interner.intern("_PP_SELF_");
                    let pp_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: prep_name,
                        args: self.ctx.terms.alloc_slice([
                            Term::Variable(placeholder_var),
                            Term::Constant(pp_object.noun),
                        ]),
                    });
                    pps.push(pp_pred);
                }
            }
        }
        let pps_slice = self.ctx.pps.alloc_slice(pps);

        if self.check_of_preposition() {
            // Two-Pass Type Disambiguation:
            // If the noun is a known generic type (e.g., "Stack", "List"),
            // then "X of Y" is a type instantiation, not a possessive.
            // For now, we still parse it as possessive structurally, but
            // the type_registry enables future AST extensions for type annotations.
            let is_generic = self.is_generic_type(noun);

            if !is_generic {
                // Standard possessive: "owner of house" → possessor relationship
                self.advance();

                let possessor_np = self.parse_noun_phrase(true)?;
                let possessor = self.ctx.nps.alloc(possessor_np);

                return Ok(NounPhrase {
                    definiteness,
                    adjectives: self.ctx.syms.alloc_slice(adjectives),
                    noun,
                    possessor: Some(possessor),
                    pps: pps_slice,
                    superlative: superlative_adj,
                });
            }
            // If generic type, fall through to regular noun phrase handling.
            // The "of [Type]" will be left unparsed for now.
            // Future: Parse as GenericType { base: noun, params: [...] }
        }

        // Register ALL noun phrases as discourse entities, not just definite ones.
        // This is needed for bridging anaphora: "I bought a car. The engine smoked."
        // The indefinite "a car" must be in discourse history for "the engine" to link to it.
        let noun_str = self.interner.resolve(noun);
        let first_char = noun_str.chars().next().unwrap_or('X');
        if first_char.is_alphabetic() {
            let symbol = first_char.to_uppercase().to_string();
            let number = if noun_str.ends_with('s') && !noun_str.ends_with("ss") {
                Number::Plural
            } else {
                Number::Singular
            };
            let noun_class = noun_str.to_string();
            self.register_entity(&symbol, &noun_class, Gender::Neuter, number);
        }

        Ok(NounPhrase {
            definiteness,
            adjectives: self.ctx.syms.alloc_slice(adjectives),
            noun,
            possessor: possessor_from_pronoun,
            pps: pps_slice,
            superlative: superlative_adj,
        })
    }

    fn parse_noun_phrase_for_relative(&mut self) -> ParseResult<NounPhrase<'a>> {
        let mut definiteness = None;
        let mut adjectives = Vec::new();

        if let TokenType::Article(def) = self.peek().kind {
            definiteness = Some(def);
            self.advance();
        }

        loop {
            if self.is_at_end() {
                break;
            }

            let is_adjective = matches!(self.peek().kind, TokenType::Adjective(_));
            if !is_adjective {
                break;
            }

            let next_is_content = if self.current + 1 < self.tokens.len() {
                matches!(
                    self.tokens[self.current + 1].kind,
                    TokenType::Noun(_)
                        | TokenType::Adjective(_)
                        | TokenType::Verb { .. }
                        | TokenType::ProperName(_)
                )
            } else {
                false
            };

            if next_is_content {
                if let TokenType::Adjective(adj) = self.advance().kind.clone() {
                    adjectives.push(adj);
                }
            } else {
                break;
            }
        }

        let noun = self.consume_content_word_for_relative()?;

        if self.check(&TokenType::That) || self.check(&TokenType::Who) {
            self.advance();
            let var_name = self.interner.intern(&format!("r{}", self.var_counter));
            self.var_counter += 1;
            let _nested_clause = self.parse_relative_clause(var_name)?;
        }

        Ok(NounPhrase {
            definiteness,
            adjectives: self.ctx.syms.alloc_slice(adjectives),
            noun,
            possessor: None,
            pps: &[],
            superlative: None,
        })
    }

    fn noun_phrase_to_term(&self, np: &NounPhrase<'a>) -> Term<'a> {
        if let Some(possessor) = np.possessor {
            let possessor_term = self.noun_phrase_to_term(possessor);
            Term::Possessed {
                possessor: self.ctx.terms.alloc(possessor_term),
                possessed: np.noun,
            }
        } else {
            Term::Constant(np.noun)
        }
    }

    fn check_possessive(&self) -> bool {
        matches!(self.peek().kind, TokenType::Possessive)
    }

    fn check_of_preposition(&self) -> bool {
        if let TokenType::Preposition(p) = self.peek().kind {
            p.is(self.interner, "of")
        } else {
            false
        }
    }

    fn check_proper_name_or_label(&self) -> bool {
        match &self.peek().kind {
            TokenType::ProperName(_) => true,
            TokenType::Noun(s) => {
                let str_val = self.interner.resolve(*s);
                str_val.len() == 1 && str_val.chars().next().unwrap().is_uppercase()
            }
            _ => false,
        }
    }

    fn check_possessive_pronoun(&self) -> bool {
        match &self.peek().kind {
            TokenType::Pronoun { case: Case::Possessive, .. } => true,
            TokenType::Ambiguous { primary, alternatives } => {
                if self.noun_priority_mode {
                    if let TokenType::Pronoun { case: Case::Possessive, .. } = **primary {
                        return true;
                    }
                    for alt in alternatives {
                        if let TokenType::Pronoun { case: Case::Possessive, .. } = alt {
                            return true;
                        }
                    }
                }
                false
            }
            _ => false,
        }
    }
}

```

---

### QuestionParsing Trait

**File:** `src/parser/question.rs`

Extension trait for interrogatives: wh-questions (who/what/where/when/why/how), pied-piping prepositions, yes/no questions with auxiliary inversion, modal-to-vector conversion for question semantics.

```rust
use super::noun::NounParsing;
use super::quantifier::QuantifierParsing;
use super::verb::LogicVerbParsing;
use super::{ParseResult, Parser};
use crate::ast::{AspectOperator, LogicExpr, ModalDomain, ModalVector, TemporalOperator, Term};
use crate::lexicon::{Aspect, Time};
use crate::token::TokenType;

pub trait QuestionParsing<'a, 'ctx, 'int> {
    fn parse_wh_question(&mut self) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_yes_no_question(&mut self) -> ParseResult<&'a LogicExpr<'a>>;
    fn aux_token_to_modal_vector(&self, token: &TokenType) -> ModalVector;
}

impl<'a, 'ctx, 'int> QuestionParsing<'a, 'ctx, 'int> for Parser<'a, 'ctx, 'int> {
    fn parse_wh_question(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let pied_piping_prep = if self.check_preposition() {
            let prep = self.advance().kind.clone();
            Some(prep)
        } else {
            None
        };

        let wh_token = self.advance().kind.clone();
        let var_name = self.interner.intern("x");
        let var_term = Term::Variable(var_name);

        if pied_piping_prep.is_some() && self.check_auxiliary() {
            let aux_token = self.advance().clone();
            if let TokenType::Auxiliary(time) = aux_token.kind {
                self.pending_time = Some(time);
            }

            let subject = self.parse_noun_phrase(true)?;
            let verb = self.consume_verb();

            let mut args = vec![Term::Constant(subject.noun)];
            if self.check_content_word() || self.check_article() {
                let object = self.parse_noun_phrase(false)?;
                args.push(Term::Constant(object.noun));
            }
            args.push(var_term);

            let body = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice(args),
            });
            return Ok(self.ctx.exprs.alloc(LogicExpr::Question {
                wh_variable: var_name,
                body,
            }));
        }

        if self.check_verb() {
            let verb = self.consume_verb();
            let mut args = vec![var_term];

            if self.check_content_word() {
                let object = self.parse_noun_phrase(false)?;
                args.push(Term::Constant(object.noun));
            }

            let body = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice(args),
            });
            return Ok(self.ctx.exprs.alloc(LogicExpr::Question {
                wh_variable: var_name,
                body,
            }));
        }

        if self.check(&TokenType::Does) || self.check(&TokenType::Do) {
            self.advance();
            let subject = self.parse_noun_phrase(true)?;
            let verb = self.consume_verb();

            let body = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice([Term::Constant(subject.noun), var_term]),
            });
            return Ok(self.ctx.exprs.alloc(LogicExpr::Question {
                wh_variable: var_name,
                body,
            }));
        }

        if self.check_auxiliary() {
            let aux_token = self.advance().clone();
            if let TokenType::Auxiliary(time) = aux_token.kind {
                self.pending_time = Some(time);
            }

            self.filler_gap = Some(var_name);

            let subject = self.parse_noun_phrase(true)?;
            let body = self.parse_predicate_with_subject(subject.noun)?;

            self.filler_gap = None;

            return Ok(self.ctx.exprs.alloc(LogicExpr::Question {
                wh_variable: var_name,
                body,
            }));
        }

        let unknown = self.interner.intern(&format!("{:?}", wh_token));
        Ok(self.ctx.exprs.alloc(LogicExpr::Atom(unknown)))
    }

    fn parse_yes_no_question(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let aux_token = self.advance().kind.clone();

        let is_modal = matches!(aux_token, TokenType::Can | TokenType::Could | TokenType::Would | TokenType::May | TokenType::Must | TokenType::Should);
        let is_copula = matches!(aux_token, TokenType::Is | TokenType::Are | TokenType::Was | TokenType::Were);
        let copula_time = if matches!(aux_token, TokenType::Was | TokenType::Were) {
            Time::Past
        } else {
            Time::Present
        };

        if self.check_quantifier() {
            self.advance();
            let quantified = self.parse_quantified()?;
            let wrapped = if is_modal {
                let vector = self.aux_token_to_modal_vector(&aux_token);
                self.ctx.exprs.alloc(LogicExpr::Modal {
                    vector,
                    operand: quantified,
                })
            } else {
                quantified
            };
            return Ok(self.ctx.exprs.alloc(LogicExpr::YesNoQuestion { body: wrapped }));
        }

        let subject_symbol = if self.check_pronoun() {
            let token = self.advance().clone();
            if let TokenType::Pronoun { gender, number, .. } = token.kind {
                let token_text = self.interner.resolve(token.lexeme);
                if token_text.eq_ignore_ascii_case("you") {
                    self.interner.intern("Addressee")
                } else {
                    self.resolve_pronoun(gender, number)
                        .unwrap_or_else(|| self.interner.intern("?"))
                }
            } else {
                self.interner.intern("?")
            }
        } else {
            self.parse_noun_phrase(true)?.noun
        };

        let please_sym = self.interner.intern("please");
        self.match_token(&[TokenType::Adverb(please_sym)]);

        if is_copula {
            let body = if self.check_verb() {
                let (verb, _, verb_aspect, _) = self.consume_verb_with_metadata();
                let predicate = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb,
                    args: self.ctx.terms.alloc_slice([Term::Constant(subject_symbol)]),
                });
                let with_aspect = if verb_aspect == Aspect::Progressive {
                    self.ctx.exprs.alloc(LogicExpr::Aspectual {
                        operator: AspectOperator::Progressive,
                        body: predicate,
                    })
                } else {
                    predicate
                };
                if copula_time == Time::Past {
                    self.ctx.exprs.alloc(LogicExpr::Temporal {
                        operator: TemporalOperator::Past,
                        body: with_aspect,
                    })
                } else {
                    with_aspect
                }
            } else if self.check_content_word() {
                let adj = self.consume_content_word()?;
                self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: adj,
                    args: self.ctx.terms.alloc_slice([Term::Constant(subject_symbol)]),
                })
            } else {
                self.ctx.exprs.alloc(LogicExpr::Atom(subject_symbol))
            };
            return Ok(self.ctx.exprs.alloc(LogicExpr::YesNoQuestion { body }));
        }

        let body = self.parse_predicate_with_subject(subject_symbol)?;

        let wrapped_body = if is_modal {
            let vector = self.aux_token_to_modal_vector(&aux_token);
            self.ctx.exprs.alloc(LogicExpr::Modal {
                vector,
                operand: body,
            })
        } else {
            body
        };

        Ok(self.ctx.exprs.alloc(LogicExpr::YesNoQuestion { body: wrapped_body }))
    }

    fn aux_token_to_modal_vector(&self, token: &TokenType) -> ModalVector {
        match token {
            TokenType::Can => ModalVector {
                domain: ModalDomain::Alethic,
                force: 0.5,
            },
            TokenType::Could => ModalVector {
                domain: ModalDomain::Alethic,
                force: 0.4,
            },
            TokenType::Would => ModalVector {
                domain: ModalDomain::Alethic,
                force: 0.6,
            },
            TokenType::May => ModalVector {
                domain: ModalDomain::Deontic,
                force: 0.5,
            },
            TokenType::Must => ModalVector {
                domain: ModalDomain::Alethic,
                force: 1.0,
            },
            TokenType::Should => ModalVector {
                domain: ModalDomain::Deontic,
                force: 0.6,
            },
            _ => ModalVector {
                domain: ModalDomain::Alethic,
                force: 0.5,
            },
        }
    }
}

```

---

### ModalParsing Trait

**File:** `src/parser/modal.rs`

Extension trait for modal expressions: necessity/possibility (must/can/might/would/should/cannot), aspect chains (parse_aspect_chain() and parse_aspect_chain_with_term() for perfect/progressive/passive/modal stacking with constant or variable subjects), modal vector construction (domain + force). **Passive Agent Extraction:** Detects 'by X' after passive 'been' to extract agent argument for proper thematic role assignment. **NeoEvent Output:** Creates Expr::NeoEvent with thematic roles for consistent event semantics; adds tense modifiers from pending_time. All modals route through aspect chain parsing for uniform handling of negation and auxiliaries.

```rust
use super::clause::ClauseParsing;
use super::noun::NounParsing;
use super::{ParseResult, Parser};
use crate::ast::{AspectOperator, LogicExpr, ModalDomain, ModalVector, NeoEventData, ThematicRole, VoiceOperator, Term};
use crate::context::TimeRelation;
use crate::error::{ParseError, ParseErrorKind};
use crate::intern::Symbol;
use crate::lexicon::{Time, Aspect};
use crate::token::TokenType;

pub trait ModalParsing<'a, 'ctx, 'int> {
    fn parse_modal(&mut self) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_aspect_chain(&mut self, subject_symbol: Symbol) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_aspect_chain_with_term(&mut self, subject_term: Term<'a>) -> ParseResult<&'a LogicExpr<'a>>;
    fn token_to_vector(&self, token: &TokenType) -> ModalVector;
}

impl<'a, 'ctx, 'int> ModalParsing<'a, 'ctx, 'int> for Parser<'a, 'ctx, 'int> {
    fn parse_modal(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let vector = self.token_to_vector(&self.previous().kind.clone());

        if self.check(&TokenType::That) {
            self.advance();
        }

        let content = self.parse_sentence()?;

        Ok(self.ctx.exprs.alloc(LogicExpr::Modal {
            vector,
            operand: content,
        }))
    }

    fn parse_aspect_chain(&mut self, subject_symbol: Symbol) -> ParseResult<&'a LogicExpr<'a>> {
        self.parse_aspect_chain_with_term(Term::Constant(subject_symbol))
    }

    fn parse_aspect_chain_with_term(&mut self, subject_term: Term<'a>) -> ParseResult<&'a LogicExpr<'a>> {
        let mut has_modal = false;
        let mut modal_vector = None;
        let mut has_negation = false;
        let mut has_perfect = false;
        let mut has_passive = false;
        let mut has_progressive = false;

        if self.check(&TokenType::Would) || self.check(&TokenType::Could)
            || self.check(&TokenType::Must) || self.check(&TokenType::Can)
            || self.check(&TokenType::Should) || self.check(&TokenType::May)
            || self.check(&TokenType::Cannot) {
            let modal_token = self.peek().kind.clone();
            self.advance();
            has_modal = true;
            modal_vector = Some(self.token_to_vector(&modal_token));
        }

        if self.check(&TokenType::Not) {
            self.advance();
            has_negation = true;
        }

        if self.check_content_word() {
            let word = self.interner.resolve(self.peek().lexeme).to_lowercase();
            if word == "have" || word == "has" || word == "had" {
                self.advance();
                has_perfect = true;
            }
        }

        if self.check(&TokenType::Had) {
            self.advance();
            has_perfect = true;
            // "had" = past perfect: R < S (past reference time)
            if let Some(ref mut context) = self.context {
                let r_var = context.next_reference_time();
                context.add_time_constraint(r_var, TimeRelation::Precedes, "S".to_string());
            }
        }

        if self.check_content_word() {
            let word = self.interner.resolve(self.peek().lexeme).to_lowercase();
            if word == "been" {
                self.advance();

                if self.check_verb() {
                    match &self.peek().kind {
                        TokenType::Verb { aspect: Aspect::Progressive, .. } => {
                            has_progressive = true;
                        }
                        TokenType::Verb { .. } => {
                            let next_word = self.interner.resolve(self.peek().lexeme);
                            if next_word.ends_with("ing") {
                                has_progressive = true;
                            } else {
                                has_passive = true;
                            }
                        }
                        _ => {
                            has_passive = true;
                        }
                    }
                }
            }
        }

        if self.check_content_word() {
            let word = self.interner.resolve(self.peek().lexeme).to_lowercase();
            if word == "being" {
                self.advance();
                has_progressive = true;
            }
        }

        let verb = if self.check_verb() {
            self.consume_verb()
        } else if self.check_content_word() {
            self.consume_content_word()?
        } else {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedContentWord { found: self.peek().kind.clone() },
                span: self.peek().span.clone(),
            });
        };

        let subject_role = if has_passive {
            ThematicRole::Theme
        } else {
            ThematicRole::Agent
        };
        let mut roles: Vec<(ThematicRole, Term<'a>)> = vec![(subject_role, subject_term)];

        if has_passive && self.check_preposition() {
            if let TokenType::Preposition(sym) = self.peek().kind {
                if self.interner.resolve(sym) == "by" {
                    self.advance();
                    let agent_np = self.parse_noun_phrase(true)?;
                    let agent_term = self.noun_phrase_to_term(&agent_np);
                    roles.push((ThematicRole::Agent, agent_term));
                }
            }
        } else if !has_passive && (self.check_content_word() || self.check_article()) {
            let obj_np = self.parse_noun_phrase(false)?;
            let obj_term = self.noun_phrase_to_term(&obj_np);
            roles.push((ThematicRole::Theme, obj_term));
        }

        let event_var = self.get_event_var();
        let mut modifiers: Vec<Symbol> = Vec::new();
        if let Some(pending) = self.pending_time {
            match pending {
                Time::Past => modifiers.push(self.interner.intern("Past")),
                Time::Future => modifiers.push(self.interner.intern("Future")),
                _ => {}
            }
        }
        let base_pred = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
            event_var,
            verb,
            roles: self.ctx.roles.alloc_slice(roles.clone()),
            modifiers: self.ctx.syms.alloc_slice(modifiers.clone()),
        })));

        // Capture template for ellipsis reconstruction
        self.capture_event_template(verb, &roles, &modifiers);

        let mut result: &'a LogicExpr<'a> = base_pred;

        if has_progressive {
            result = self.ctx.aspectual(AspectOperator::Progressive, result);
        }

        if has_passive {
            result = self.ctx.voice(VoiceOperator::Passive, result);
        }

        if has_perfect {
            result = self.ctx.aspectual(AspectOperator::Perfect, result);
            if let Some(ref mut context) = self.context {
                // Check pending_time to set up reference time for tense
                if let Some(pending) = self.pending_time.take() {
                    match pending {
                        Time::Future => {
                            let r_var = context.next_reference_time();
                            context.add_time_constraint("S".to_string(), TimeRelation::Precedes, r_var);
                        }
                        Time::Past => {
                            // Past tense with perfect (should be handled by "had" already, but as fallback)
                            if context.current_reference_time() == "S" {
                                let r_var = context.next_reference_time();
                                context.add_time_constraint(r_var, TimeRelation::Precedes, "S".to_string());
                            }
                        }
                        _ => {}
                    }
                }
                // Perfect: E < R
                let e_var = format!("e{}", context.event_history().len().max(1));
                let r_var = context.current_reference_time();
                context.add_time_constraint(e_var, TimeRelation::Precedes, r_var);
            }
        }

        if has_negation {
            result = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                op: TokenType::Not,
                operand: result,
            });
        }

        if has_modal {
            if let Some(vector) = modal_vector {
                result = self.ctx.modal(vector, result);
            }
        }

        Ok(result)
    }

    fn token_to_vector(&self, token: &TokenType) -> ModalVector {
        match token {
            TokenType::Must => ModalVector {
                domain: ModalDomain::Alethic,
                force: 1.0,
            },
            TokenType::Cannot => ModalVector {
                domain: ModalDomain::Alethic,
                force: 0.0,
            },
            TokenType::Can => ModalVector {
                domain: ModalDomain::Alethic,
                force: 0.5,
            },
            TokenType::Could => ModalVector {
                domain: ModalDomain::Alethic,
                force: 0.5,
            },
            TokenType::Would => ModalVector {
                domain: ModalDomain::Alethic,
                force: 0.5,
            },
            TokenType::Shall => ModalVector {
                domain: ModalDomain::Deontic,
                force: 0.9,
            },
            TokenType::Should => ModalVector {
                domain: ModalDomain::Deontic,
                force: 0.6,
            },
            TokenType::May => ModalVector {
                domain: ModalDomain::Deontic,
                force: 0.5,
            },
            _ => panic!("Unknown modal token: {:?}", token),
        }
    }
}

```

---

### PragmaticsParsing Trait

**File:** `src/parser/pragmatics.rs`

Extension trait for pragmatic phenomena: focus particles (only/even/just), measure expressions (much/little), presupposition triggers (factive verbs, aspectual verbs with gerund complement check via is_followed_by_gerund()), scopal adverbs, comparatives (taller than with optional difference measure phrase), superlatives (tallest). parse_measure() handles numeric measurement phrases and routes to comparative parsing when degree expressions are detected.

```rust
use super::noun::NounParsing;
use super::quantifier::QuantifierParsing;
use super::{ParseResult, Parser};
use crate::ast::{LogicExpr, NounPhrase, NumberKind, QuantifierKind, TemporalOperator, Term};
use crate::error::{ParseError, ParseErrorKind};
use crate::lexicon::{self, Time};
use crate::token::{MeasureKind, PresupKind, TokenType};

pub trait PragmaticsParsing<'a, 'ctx, 'int> {
    fn parse_focus(&mut self) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_measure(&mut self) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_presupposition(
        &mut self,
        subject: &NounPhrase<'a>,
        presup_kind: PresupKind,
    ) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_predicate_for_subject(&mut self, subject: &NounPhrase<'a>)
        -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_scopal_adverb(&mut self, subject: &NounPhrase<'a>) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_superlative(&mut self, subject: &NounPhrase<'a>) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_comparative(
        &mut self,
        subject: &NounPhrase<'a>,
        copula_time: Time,
        difference: Option<&'a Term<'a>>,
    ) -> ParseResult<&'a LogicExpr<'a>>;
    fn check_number(&self) -> bool;
    fn parse_measure_phrase(&mut self) -> ParseResult<&'a Term<'a>>;
}

impl<'a, 'ctx, 'int> PragmaticsParsing<'a, 'ctx, 'int> for Parser<'a, 'ctx, 'int> {
    fn parse_focus(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let kind = if let TokenType::Focus(k) = self.advance().kind {
            k
        } else {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedFocusParticle,
                span: self.current_span(),
            });
        };

        if self.check_quantifier() {
            self.advance();
            let quantified = self.parse_quantified()?;
            let focus_var = self.interner.intern("focus");
            let focused = self.ctx.terms.alloc(Term::Variable(focus_var));
            return Ok(self.ctx.exprs.alloc(LogicExpr::Focus {
                kind,
                focused,
                scope: quantified,
            }));
        }

        let focused_np = self.parse_noun_phrase(true)?;
        let focused = self.ctx.terms.alloc(Term::Constant(focused_np.noun));

        let scope = self.parse_predicate_for_subject(&focused_np)?;

        Ok(self.ctx.exprs.alloc(LogicExpr::Focus {
            kind,
            focused,
            scope,
        }))
    }

    fn parse_measure(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let kind = if let TokenType::Measure(k) = self.advance().kind {
            k
        } else {
            return Err(ParseError {
                kind: ParseErrorKind::UnexpectedToken {
                    expected: TokenType::Measure(MeasureKind::Much),
                    found: self.peek().kind.clone(),
                },
                span: self.current_span(),
            });
        };

        let np = self.parse_noun_phrase(true)?;
        let var = self.next_var_name();

        let noun_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
            name: np.noun,
            args: self.ctx.terms.alloc_slice([Term::Variable(var)]),
        });

        let measure_sym = self.interner.intern("Measure");
        let kind_sym = self.interner.intern(match kind {
            MeasureKind::Much => "Much",
            MeasureKind::Little => "Little",
        });
        let measure_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
            name: measure_sym,
            args: self
                .ctx
                .terms
                .alloc_slice([Term::Variable(var), Term::Constant(kind_sym)]),
        });

        let (pred_expr, verb_time) = if self.check(&TokenType::Is) {
            let copula_time = if let TokenType::Is = self.advance().kind {
                Time::Present
            } else {
                Time::Present
            };

            // Check for comparative: "is colder than"
            if self.check_comparative() {
                let subj_np = NounPhrase {
                    noun: np.noun,
                    definiteness: None,
                    adjectives: &[],
                    possessor: None,
                    pps: &[],
                    superlative: None,
                };
                let comp_expr = self.parse_comparative(&subj_np, copula_time, None)?;

                let combined = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: noun_pred,
                    op: TokenType::And,
                    right: self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: measure_pred,
                        op: TokenType::And,
                        right: comp_expr,
                    }),
                });

                return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: var,
                    body: combined,
                    island_id: self.current_island,
                }));
            }

            let adj = self.consume_content_word()?;
            let adj_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: adj,
                args: self.ctx.terms.alloc_slice([Term::Variable(var)]),
            });
            (adj_pred, copula_time)
        } else {
            let (verb, verb_time, _, _) = self.consume_verb_with_metadata();
            let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice([Term::Variable(var)]),
            });
            (verb_pred, verb_time)
        };

        let combined = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
            left: noun_pred,
            op: TokenType::And,
            right: self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: measure_pred,
                op: TokenType::And,
                right: pred_expr,
            }),
        });

        let with_time = match verb_time {
            Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                operator: TemporalOperator::Past,
                body: combined,
            }),
            Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                operator: TemporalOperator::Future,
                body: combined,
            }),
            _ => combined,
        };

        Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Existential,
            variable: var,
            body: with_time,
            island_id: self.current_island,
        }))
    }

    fn parse_presupposition(
        &mut self,
        subject: &NounPhrase<'a>,
        presup_kind: PresupKind,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        let subject_noun = subject.noun;

        let unknown = self.interner.intern("?");
        let complement = if self.check_verb() {
            let verb = self.consume_verb();
            self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice([Term::Constant(subject_noun)]),
            })
        } else {
            self.ctx.exprs.alloc(LogicExpr::Atom(unknown))
        };

        let (assertion, presupposition) = match presup_kind {
            PresupKind::Stop => {
                let neg = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                    op: TokenType::Not,
                    operand: complement,
                });
                let past = self.ctx.exprs.alloc(LogicExpr::Temporal {
                    operator: TemporalOperator::Past,
                    body: complement,
                });
                (neg, past)
            }
            PresupKind::Start => {
                let past = self.ctx.exprs.alloc(LogicExpr::Temporal {
                    operator: TemporalOperator::Past,
                    body: complement,
                });
                let neg_past = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                    op: TokenType::Not,
                    operand: past,
                });
                (complement, neg_past)
            }
            PresupKind::Regret => {
                let regret_sym = self.interner.intern("Regret");
                let regret = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: regret_sym,
                    args: self.ctx.terms.alloc_slice([Term::Constant(subject_noun)]),
                });
                let past = self.ctx.exprs.alloc(LogicExpr::Temporal {
                    operator: TemporalOperator::Past,
                    body: complement,
                });
                (regret, past)
            }
            PresupKind::Continue | PresupKind::Realize | PresupKind::Know => {
                let verb_name = match presup_kind {
                    PresupKind::Continue => self.interner.intern("Continue"),
                    PresupKind::Realize => self.interner.intern("Realize"),
                    PresupKind::Know => self.interner.intern("Know"),
                    _ => unknown,
                };
                let main = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb_name,
                    args: self.ctx.terms.alloc_slice([Term::Constant(subject_noun)]),
                });
                (main, complement)
            }
        };

        Ok(self.ctx.exprs.alloc(LogicExpr::Presupposition {
            assertion,
            presupposition,
        }))
    }

    fn parse_predicate_for_subject(
        &mut self,
        subject: &NounPhrase<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        if self.check_verb() {
            let verb = self.consume_verb();

            // Check for focused object: "eats only rice"
            if self.check_focus() {
                let focus_kind = if let TokenType::Focus(k) = self.advance().kind {
                    k
                } else {
                    crate::token::FocusKind::Only
                };

                let object_np = self.parse_noun_phrase(false)?;
                let object_term = Term::Constant(object_np.noun);

                let predicate = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb,
                    args: self.ctx.terms.alloc_slice([
                        Term::Constant(subject.noun),
                        object_term.clone(),
                    ]),
                });

                return Ok(self.ctx.exprs.alloc(LogicExpr::Focus {
                    kind: focus_kind,
                    focused: self.ctx.terms.alloc(object_term),
                    scope: predicate,
                }));
            }

            let mut args = vec![Term::Constant(subject.noun)];

            if self.check_content_word() || self.check_article() {
                let object = self.parse_noun_phrase(false)?;
                args.push(Term::Constant(object.noun));
            }

            Ok(self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice(args),
            }))
        } else {
            Ok(self.ctx.exprs.alloc(LogicExpr::Atom(subject.noun)))
        }
    }

    fn parse_scopal_adverb(&mut self, subject: &NounPhrase<'a>) -> ParseResult<&'a LogicExpr<'a>> {
        let operator = if let TokenType::ScopalAdverb(adv) = self.advance().kind.clone() {
            adv
        } else {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedScopalAdverb,
                span: self.current_span(),
            });
        };

        if !self.check_verb() {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedVerb {
                    found: self.peek().kind.clone(),
                },
                span: self.current_span(),
            });
        }

        let (verb, verb_time, _verb_aspect, _) = self.consume_verb_with_metadata();

        let predicate = self.ctx.exprs.alloc(LogicExpr::Predicate {
            name: verb,
            args: self.ctx.terms.alloc_slice([Term::Constant(subject.noun)]),
        });

        let with_time = match verb_time {
            Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                operator: TemporalOperator::Past,
                body: predicate,
            }),
            Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                operator: TemporalOperator::Future,
                body: predicate,
            }),
            _ => predicate,
        };

        Ok(self.ctx.exprs.alloc(LogicExpr::Scopal {
            operator,
            body: with_time,
        }))
    }

    fn parse_superlative(&mut self, subject: &NounPhrase<'a>) -> ParseResult<&'a LogicExpr<'a>> {
        let adj = if let TokenType::Superlative(adj) = self.advance().kind.clone() {
            adj
        } else {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedSuperlativeAdjective,
                span: self.current_span(),
            });
        };

        let domain = self.consume_content_word()?;

        Ok(self.ctx.exprs.alloc(LogicExpr::Superlative {
            adjective: adj,
            subject: self.ctx.terms.alloc(Term::Constant(subject.noun)),
            domain,
        }))
    }

    fn parse_comparative(
        &mut self,
        subject: &NounPhrase<'a>,
        _copula_time: Time,
        difference: Option<&'a Term<'a>>,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        let adj = if let TokenType::Comparative(adj) = self.advance().kind.clone() {
            adj
        } else {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedComparativeAdjective,
                span: self.current_span(),
            });
        };

        if !self.check(&TokenType::Than) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedThan,
                span: self.current_span(),
            });
        }
        self.advance();

        // Check if the comparison target is a number (e.g., "greater than 0")
        let object_term = if self.check_number() {
            // Parse number as the comparison target
            let num_sym = if let TokenType::Number(sym) = self.advance().kind {
                sym
            } else {
                unreachable!()
            };
            let num_str = self.interner.resolve(num_sym);
            let num_val = num_str.parse::<i64>().unwrap_or(0);
            self.ctx.terms.alloc(Term::Value {
                kind: crate::ast::logic::NumberKind::Integer(num_val),
                unit: None,
                dimension: None,
            })
        } else {
            // Parse noun phrase as the comparison target
            let object = self.parse_noun_phrase(false)?;
            let obj_term = self.ctx.terms.alloc(Term::Constant(object.noun));

            let result = self.ctx.exprs.alloc(LogicExpr::Comparative {
                adjective: adj,
                subject: self.ctx.terms.alloc(Term::Constant(subject.noun)),
                object: obj_term,
                difference,
            });

            let result = self.wrap_with_definiteness(subject.definiteness, subject.noun, result)?;
            return self.wrap_with_definiteness_for_object(object.definiteness, object.noun, result);
        };

        // For number comparisons, create a simple Comparative expression
        Ok(self.ctx.exprs.alloc(LogicExpr::Comparative {
            adjective: adj,
            subject: self.ctx.terms.alloc(Term::Constant(subject.noun)),
            object: object_term,
            difference,
        }))
    }

    fn check_number(&self) -> bool {
        matches!(self.peek().kind, TokenType::Number(_))
    }

    fn parse_measure_phrase(&mut self) -> ParseResult<&'a Term<'a>> {
        let num_sym = if let TokenType::Number(sym) = self.advance().kind {
            sym
        } else {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedNumber,
                span: self.current_span(),
            });
        };

        let num_str = self.interner.resolve(num_sym);
        let kind = parse_number_kind(num_str, num_sym);

        let (unit, dimension) = if self.check_content_word() {
            let unit_word = self.consume_content_word()?;
            let unit_str = self.interner.resolve(unit_word).to_lowercase();
            let dim = lexicon::lookup_unit_dimension(&unit_str);
            (Some(unit_word), dim)
        } else {
            (None, None)
        };

        Ok(self.ctx.terms.alloc(Term::Value { kind, unit, dimension }))
    }
}

fn parse_number_kind(s: &str, sym: crate::intern::Symbol) -> NumberKind {
    if s.contains('.') {
        NumberKind::Real(s.parse().unwrap_or(0.0))
    } else if s.chars().all(|c| c.is_ascii_digit() || c == '-') {
        NumberKind::Integer(s.parse().unwrap_or(0))
    } else {
        NumberKind::Symbolic(sym)
    }
}

```

---

### Parser Constants

**File:** `src/parser/common.rs`

Shared constants for parser modules. COPULAS array defines copular verbs (is/are/was/were) for pattern matching.

```rust
use crate::token::TokenType;

pub const COPULAS: &[TokenType] = &[
    TokenType::Is,
    TokenType::Are,
    TokenType::Was,
    TokenType::Were,
];

```

---

### Parser Unit Tests

**File:** `src/parser/tests.rs`

Unit tests for parser internals: ParserGuard RAII behavior (guard_restores_all_fields_on_drop), check_any() semantic token matching. Tests verify checkpoint/restore mechanics and token set operations.

```rust
use super::*;
use crate::arena::Arena;
use crate::ast::NounPhrase;

#[test]
fn guard_restores_all_fields_on_drop() {
    let mut interner = Interner::new();
    let expr_arena: Arena<LogicExpr> = Arena::new();
    let term_arena: Arena<Term> = Arena::new();
    let np_arena: Arena<NounPhrase> = Arena::new();
    let sym_arena: Arena<Symbol> = Arena::new();
    let role_arena: Arena<(ThematicRole, Term)> = Arena::new();
    let pp_arena: Arena<&LogicExpr> = Arena::new();

    let ctx = AstContext::new(
        &expr_arena, &term_arena, &np_arena, &sym_arena, &role_arena, &pp_arena,
    );

    let mut lexer = Lexer::new("a b c d e", &mut interner);
    let tokens = lexer.tokenize();
    let mut parser = Parser::new(tokens, &mut interner, ctx);

    let initial_pos = parser.current;
    let initial_var_counter = parser.var_counter;
    let initial_bindings_len = parser.donkey_bindings.len();
    let initial_island = parser.current_island;
    let initial_time = parser.pending_time;

    {
        let mut guard = parser.guard();
        guard.current = 3;
        guard.var_counter = 99;
        guard.donkey_bindings.push((Symbol::EMPTY, Symbol::EMPTY, false));
        guard.current_island = 42;
        guard.pending_time = Some(Time::Past);
    }

    assert_eq!(parser.current, initial_pos, "position not restored");
    assert_eq!(parser.var_counter, initial_var_counter, "var_counter not restored");
    assert_eq!(parser.donkey_bindings.len(), initial_bindings_len, "bindings not restored");
    assert_eq!(parser.current_island, initial_island, "island not restored");
    assert_eq!(parser.pending_time, initial_time, "time not restored");
}

#[test]
fn guard_preserves_state_on_commit() {
    let mut interner = Interner::new();
    let expr_arena: Arena<LogicExpr> = Arena::new();
    let term_arena: Arena<Term> = Arena::new();
    let np_arena: Arena<NounPhrase> = Arena::new();
    let sym_arena: Arena<Symbol> = Arena::new();
    let role_arena: Arena<(ThematicRole, Term)> = Arena::new();
    let pp_arena: Arena<&LogicExpr> = Arena::new();

    let ctx = AstContext::new(
        &expr_arena, &term_arena, &np_arena, &sym_arena, &role_arena, &pp_arena,
    );

    let mut lexer = Lexer::new("a b c", &mut interner);
    let tokens = lexer.tokenize();
    let mut parser = Parser::new(tokens, &mut interner, ctx);

    {
        let mut guard = parser.guard();
        guard.current = 2;
        guard.var_counter = 50;
        guard.commit();
    }

    assert_eq!(parser.current, 2, "position should be preserved after commit");
    assert_eq!(parser.var_counter, 50, "var_counter should be preserved after commit");
}

#[test]
fn check_any_matches_wh_words() {
    let mut interner = Interner::new();
    let expr_arena: Arena<LogicExpr> = Arena::new();
    let term_arena: Arena<Term> = Arena::new();
    let np_arena: Arena<NounPhrase> = Arena::new();
    let sym_arena: Arena<Symbol> = Arena::new();
    let role_arena: Arena<(ThematicRole, Term)> = Arena::new();
    let pp_arena: Arena<&LogicExpr> = Arena::new();

    let ctx = AstContext::new(
        &expr_arena, &term_arena, &np_arena, &sym_arena, &role_arena, &pp_arena,
    );

    let mut lexer = Lexer::new("who what where", &mut interner);
    let tokens = lexer.tokenize();
    let mut parser = Parser::new(tokens, &mut interner, ctx);

    assert!(parser.check_any(TokenType::WH_WORDS));
    parser.current = 1;
    assert!(parser.check_any(TokenType::WH_WORDS));
    parser.current = 2;
    assert!(parser.check_any(TokenType::WH_WORDS));
}

#[test]
fn check_any_rejects_non_matching() {
    let mut interner = Interner::new();
    let expr_arena: Arena<LogicExpr> = Arena::new();
    let term_arena: Arena<Term> = Arena::new();
    let np_arena: Arena<NounPhrase> = Arena::new();
    let sym_arena: Arena<Symbol> = Arena::new();
    let role_arena: Arena<(ThematicRole, Term)> = Arena::new();
    let pp_arena: Arena<&LogicExpr> = Arena::new();

    let ctx = AstContext::new(
        &expr_arena, &term_arena, &np_arena, &sym_arena, &role_arena, &pp_arena,
    );

    let mut lexer = Lexer::new("if then", &mut interner);
    let tokens = lexer.tokenize();
    let parser = Parser::new(tokens, &mut interner, ctx);

    assert!(!parser.check_any(TokenType::WH_WORDS));
    assert!(!parser.check_any(TokenType::MODALS));
}

```

---

## Transpilation

The transpiler converts the AST into formal logical notation, supporting both Unicode mathematical symbols and LaTeX output.

**Location:** `src/transpile.rs`, `src/formatter.rs`, `src/registry.rs`

### Code Generation

**File:** `src/transpile.rs`

Converts AST to logical notation. Implements symbolic substitution, quantifier formatting, output mode selection (Unicode/LaTeX), Recipient thematic role rendering, and Causal expression transpilation. Term::Value output formats numeric values (Real/Integer/Symbolic) with optional unit strings. Comparative.difference renders measure phrases in degree expressions. Includes write_to() and write_logic() methods for zero-allocation output to any std::fmt::Write target.

```rust
use std::fmt::Write;

use crate::ast::{LogicExpr, NounPhrase, Term};
use crate::formatter::{LatexFormatter, LogicFormatter, SimpleFOLFormatter, UnicodeFormatter};
use crate::intern::Interner;
use crate::registry::SymbolRegistry;
use crate::token::TokenType;
use crate::{OutputFormat, TranspileContext};

fn capitalize_first(s: &str) -> String {
    let mut chars = s.chars();
    match chars.next() {
        None => String::new(),
        Some(c) => c.to_uppercase().collect::<String>() + chars.as_str(),
    }
}

fn write_capitalized<W: Write>(w: &mut W, s: &str) -> std::fmt::Result {
    let mut chars = s.chars();
    match chars.next() {
        None => Ok(()),
        Some(c) => {
            for uc in c.to_uppercase() {
                write!(w, "{}", uc)?;
            }
            write!(w, "{}", chars.as_str())
        }
    }
}

impl<'a> NounPhrase<'a> {
    pub fn to_symbol(&self, registry: &mut SymbolRegistry, interner: &Interner) -> String {
        registry.get_symbol(self.noun, interner)
    }
}

impl<'a> Term<'a> {
    pub fn write_to<W: Write>(
        &self,
        w: &mut W,
        registry: &mut SymbolRegistry,
        interner: &Interner,
    ) -> std::fmt::Result {
        self.write_to_inner(w, registry, interner, false)
    }

    pub fn write_to_full<W: Write>(
        &self,
        w: &mut W,
        registry: &mut SymbolRegistry,
        interner: &Interner,
    ) -> std::fmt::Result {
        self.write_to_inner(w, registry, interner, true)
    }

    fn write_to_inner<W: Write>(
        &self,
        w: &mut W,
        registry: &mut SymbolRegistry,
        interner: &Interner,
        use_full_names: bool,
    ) -> std::fmt::Result {
        match self {
            Term::Constant(name) => {
                if use_full_names {
                    write!(w, "{}", registry.get_symbol_full(*name, interner))
                } else {
                    write!(w, "{}", registry.get_symbol(*name, interner))
                }
            }
            Term::Variable(name) => write!(w, "{}", interner.resolve(*name)),
            Term::Function(name, args) => {
                let fn_name = if use_full_names {
                    registry.get_symbol_full(*name, interner)
                } else {
                    registry.get_symbol(*name, interner)
                };
                write!(w, "{}(", fn_name)?;
                for (i, arg) in args.iter().enumerate() {
                    if i > 0 {
                        write!(w, ", ")?;
                    }
                    arg.write_to_inner(w, registry, interner, use_full_names)?;
                }
                write!(w, ")")
            }
            Term::Group(members) => {
                for (i, m) in members.iter().enumerate() {
                    if i > 0 {
                        write!(w, " ⊕ ")?;
                    }
                    m.write_to_inner(w, registry, interner, use_full_names)?;
                }
                Ok(())
            }
            Term::Possessed { possessor, possessed } => {
                let poss_name = if use_full_names {
                    registry.get_symbol_full(*possessed, interner)
                } else {
                    registry.get_symbol(*possessed, interner)
                };
                write!(w, "Poss(")?;
                possessor.write_to_inner(w, registry, interner, use_full_names)?;
                write!(w, ", {})", poss_name)
            }
            Term::Sigma(predicate) => {
                let pred_name = if use_full_names {
                    registry.get_symbol_full(*predicate, interner)
                } else {
                    registry.get_symbol(*predicate, interner)
                };
                write!(w, "σ{}", pred_name)
            }
            Term::Intension(predicate) => {
                // Use full word for intensional terms, not abbreviated symbol
                let word = interner.resolve(*predicate);
                let capitalized = word.chars().next()
                    .map(|c| c.to_uppercase().collect::<String>() + &word[1..])
                    .unwrap_or_default();
                write!(w, "^{}", capitalized)
            }
            Term::Proposition(expr) => {
                write!(w, "[")?;
                expr.write_logic(w, registry, interner, &UnicodeFormatter)?;
                write!(w, "]")
            }
            Term::Value { kind, unit, dimension: _ } => {
                use crate::ast::NumberKind;
                match kind {
                    NumberKind::Real(r) => write!(w, "{}", r)?,
                    NumberKind::Integer(i) => write!(w, "{}", i)?,
                    NumberKind::Symbolic(s) => write!(w, "{}", interner.resolve(*s))?,
                }
                if let Some(u) = unit {
                    write!(w, " {}", interner.resolve(*u))?;
                }
                Ok(())
            }
        }
    }

    pub fn transpile(&self, registry: &mut SymbolRegistry, interner: &Interner) -> String {
        let mut buf = String::new();
        let _ = self.write_to(&mut buf, registry, interner);
        buf
    }
}

impl<'a> LogicExpr<'a> {
    pub fn write_logic<W: Write, F: LogicFormatter>(
        &self,
        w: &mut W,
        registry: &mut SymbolRegistry,
        interner: &Interner,
        fmt: &F,
    ) -> std::fmt::Result {
        match self {
            LogicExpr::Predicate { name, args } => {
                let pred_name = if fmt.use_full_names() {
                    registry.get_symbol_full(*name, interner)
                } else {
                    registry.get_symbol(*name, interner)
                };
                write!(w, "{}(", fmt.sanitize(&pred_name))?;
                for (i, arg) in args.iter().enumerate() {
                    if i > 0 {
                        write!(w, ", ")?;
                    }
                    if fmt.use_full_names() {
                        arg.write_to_full(w, registry, interner)?;
                    } else {
                        arg.write_to(w, registry, interner)?;
                    }
                }
                write!(w, ")")
            }

            LogicExpr::Identity { left, right } => {
                left.write_to(w, registry, interner)?;
                write!(w, " = ")?;
                right.write_to(w, registry, interner)
            }

            LogicExpr::Metaphor { tenor, vehicle } => {
                write!(w, "Metaphor(")?;
                tenor.write_to(w, registry, interner)?;
                write!(w, ", ")?;
                vehicle.write_to(w, registry, interner)?;
                write!(w, ")")
            }

            LogicExpr::Quantifier { kind, variable, body, .. } => {
                let var_str = interner.resolve(*variable);
                let mut body_buf = String::new();
                body.write_logic(&mut body_buf, registry, interner, fmt)?;
                write!(w, "{}", fmt.quantifier(kind, var_str, &body_buf))
            }

            LogicExpr::Categorical(data) => {
                let s = fmt.sanitize(&data.subject.to_symbol(registry, interner));
                let p = fmt.sanitize(&data.predicate.to_symbol(registry, interner));
                match (&data.quantifier, data.copula_negative) {
                    (TokenType::All, false) => write!(w, "{} {} is {}", fmt.categorical_all(), s, p),
                    (TokenType::No, false) => write!(w, "{} {} is {}", fmt.categorical_no(), s, p),
                    (TokenType::Some, false) => write!(w, "{} {} is {}", fmt.categorical_some(), s, p),
                    (TokenType::Some, true) => write!(w, "{} {} is {} {}", fmt.categorical_some(), s, fmt.categorical_not(), p),
                    (TokenType::All, true) => write!(w, "{} {} is {} {}", fmt.categorical_some(), s, fmt.categorical_not(), p),
                    _ => write!(w, "Invalid Syllogism"),
                }
            }

            LogicExpr::Relation(data) => {
                let s = data.subject.to_symbol(registry, interner);
                let v = fmt.sanitize(&registry.get_symbol(data.verb, interner));
                let o = data.object.to_symbol(registry, interner);
                write!(w, "{}({}, {})", v, s, o)
            }

            LogicExpr::Modal { vector, operand } => {
                let mut o = String::new();
                operand.write_logic(&mut o, registry, interner, fmt)?;
                write!(w, "{}", fmt.modal(vector.domain, vector.force, &o))
            }

            LogicExpr::BinaryOp { left, op, right } => {
                let mut l = String::new();
                let mut r = String::new();
                left.write_logic(&mut l, registry, interner, fmt)?;
                right.write_logic(&mut r, registry, interner, fmt)?;
                write!(w, "{}", fmt.binary_op(op, &l, &r))
            }

            LogicExpr::UnaryOp { op, operand } => {
                let mut o = String::new();
                operand.write_logic(&mut o, registry, interner, fmt)?;
                write!(w, "{}", fmt.unary_op(op, &o))
            }

            LogicExpr::Temporal { operator, body } => {
                let mut inner = String::new();
                body.write_logic(&mut inner, registry, interner, fmt)?;
                write!(w, "{}", fmt.temporal(operator, &inner))
            }

            LogicExpr::Aspectual { operator, body } => {
                let mut inner = String::new();
                body.write_logic(&mut inner, registry, interner, fmt)?;
                write!(w, "{}", fmt.aspectual(operator, &inner))
            }

            LogicExpr::Voice { operator, body } => {
                let mut inner = String::new();
                body.write_logic(&mut inner, registry, interner, fmt)?;
                write!(w, "{}", fmt.voice(operator, &inner))
            }

            LogicExpr::Question { wh_variable, body } => {
                let mut body_str = String::new();
                body.write_logic(&mut body_str, registry, interner, fmt)?;
                write!(w, "{}", fmt.lambda(interner.resolve(*wh_variable), &body_str))
            }

            LogicExpr::YesNoQuestion { body } => {
                write!(w, "?")?;
                body.write_logic(w, registry, interner, fmt)
            }

            LogicExpr::Atom(s) => write!(w, "{}", fmt.sanitize(&registry.get_symbol(*s, interner))),

            LogicExpr::Lambda { variable, body } => {
                let mut b = String::new();
                body.write_logic(&mut b, registry, interner, fmt)?;
                write!(w, "{}", fmt.lambda(interner.resolve(*variable), &b))
            }

            LogicExpr::App { function, argument } => {
                write!(w, "(")?;
                function.write_logic(w, registry, interner, fmt)?;
                write!(w, ")(")?;
                argument.write_logic(w, registry, interner, fmt)?;
                write!(w, ")")
            }

            LogicExpr::Intensional { operator, content } => {
                write!(w, "{}[", fmt.sanitize(&registry.get_symbol(*operator, interner)))?;
                content.write_logic(w, registry, interner, fmt)?;
                write!(w, "]")
            }

            LogicExpr::Event { predicate, adverbs } => {
                let mut pred_str = String::new();
                predicate.write_logic(&mut pred_str, registry, interner, fmt)?;
                let adverb_preds: Vec<String> = adverbs
                    .iter()
                    .map(|a| format!("{}(e)", fmt.sanitize(&registry.get_symbol(*a, interner))))
                    .collect();
                write!(w, "{}", fmt.event_quantifier(&pred_str, &adverb_preds))
            }

            LogicExpr::NeoEvent(data) => {
                use crate::ast::{QuantifierKind, ThematicRole};

                if fmt.use_simple_events() {
                    write!(w, "{}", registry.get_symbol_full(data.verb, interner))?;
                    write!(w, "(")?;
                    let mut first = true;
                    for (role, term) in data.roles.iter() {
                        if matches!(role, ThematicRole::Agent | ThematicRole::Patient | ThematicRole::Theme) {
                            if !first {
                                write!(w, ", ")?;
                            }
                            first = false;
                            term.write_to_full(w, registry, interner)?;
                        }
                    }
                    write!(w, ")")
                } else {
                    let e = interner.resolve(data.event_var);
                    let mut body = String::new();
                    write_capitalized(&mut body, interner.resolve(data.verb))?;
                    write!(body, "({})", e)?;
                    for (role, term) in data.roles.iter() {
                        let role_str = match role {
                            ThematicRole::Agent => "Agent",
                            ThematicRole::Patient => "Patient",
                            ThematicRole::Theme => "Theme",
                            ThematicRole::Recipient => "Recipient",
                            ThematicRole::Goal => "Goal",
                            ThematicRole::Source => "Source",
                            ThematicRole::Instrument => "Instrument",
                            ThematicRole::Location => "Location",
                            ThematicRole::Time => "Time",
                            ThematicRole::Manner => "Manner",
                        };
                        write!(body, " {} {}({}, ", fmt.and(), role_str, e)?;
                        term.write_to(&mut body, registry, interner)?;
                        write!(body, ")")?;
                    }
                    for mod_sym in data.modifiers.iter() {
                        write!(body, " {} ", fmt.and())?;
                        write_capitalized(&mut body, interner.resolve(*mod_sym))?;
                        write!(body, "({})", e)?;
                    }
                    write!(w, "{}", fmt.quantifier(&QuantifierKind::Existential, e, &body))
                }
            }

            LogicExpr::Imperative { action } => {
                write!(w, "!")?;
                action.write_logic(w, registry, interner, fmt)
            }

            LogicExpr::SpeechAct { performer, act_type, content } => {
                write!(w, "SpeechAct({}, {}, ", interner.resolve(*act_type), fmt.sanitize(&registry.get_symbol(*performer, interner)))?;
                content.write_logic(w, registry, interner, fmt)?;
                write!(w, ")")
            }

            LogicExpr::Counterfactual { antecedent, consequent } => {
                let mut a = String::new();
                let mut c = String::new();
                antecedent.write_logic(&mut a, registry, interner, fmt)?;
                consequent.write_logic(&mut c, registry, interner, fmt)?;
                write!(w, "{}", fmt.counterfactual(&a, &c))
            }

            LogicExpr::Causal { effect, cause } => {
                write!(w, "Cause(")?;
                cause.write_logic(w, registry, interner, fmt)?;
                write!(w, ", ")?;
                effect.write_logic(w, registry, interner, fmt)?;
                write!(w, ")")
            }

            LogicExpr::Comparative { adjective, subject, object, difference } => {
                write!(w, "{}er(", interner.resolve(*adjective))?;
                subject.write_to(w, registry, interner)?;
                write!(w, ", ")?;
                object.write_to(w, registry, interner)?;
                if let Some(diff) = difference {
                    write!(w, ", ")?;
                    diff.write_to(w, registry, interner)?;
                }
                write!(w, ")")
            }

            LogicExpr::Superlative { adjective, subject, domain } => {
                let mut s = String::new();
                subject.write_to(&mut s, registry, interner)?;
                let mut d = String::new();
                write_capitalized(&mut d, interner.resolve(*domain))?;
                let comp = format!("{}er", interner.resolve(*adjective));
                write!(w, "{}", fmt.superlative(&comp, &d, &s))
            }

            LogicExpr::Scopal { operator, body } => {
                write!(w, "{}(", interner.resolve(*operator))?;
                body.write_logic(w, registry, interner, fmt)?;
                write!(w, ")")
            }

            LogicExpr::TemporalAnchor { anchor, body } => {
                write!(w, "{}(", interner.resolve(*anchor))?;
                body.write_logic(w, registry, interner, fmt)?;
                write!(w, ")")
            }

            LogicExpr::Control { verb, subject, object, infinitive } => {
                write!(w, "{}(", fmt.sanitize(&registry.get_symbol(*verb, interner)))?;
                subject.write_to(w, registry, interner)?;
                if let Some(obj) = object {
                    write!(w, ", ")?;
                    obj.write_to(w, registry, interner)?;
                }
                write!(w, ", ")?;
                infinitive.write_logic(w, registry, interner, fmt)?;
                write!(w, ")")
            }

            LogicExpr::Presupposition { assertion, presupposition } => {
                assertion.write_logic(w, registry, interner, fmt)?;
                write!(w, " [Presup: ")?;
                presupposition.write_logic(w, registry, interner, fmt)?;
                write!(w, "]")
            }

            LogicExpr::Focus { kind, focused, scope } => {
                use crate::token::FocusKind;
                let prefix = match kind {
                    FocusKind::Only => "Only",
                    FocusKind::Even => "Even",
                    FocusKind::Just => "Just",
                };
                write!(w, "{}(", prefix)?;
                focused.write_to(w, registry, interner)?;
                write!(w, ", ")?;
                scope.write_logic(w, registry, interner, fmt)?;
                write!(w, ")")
            }

            LogicExpr::Distributive { predicate } => {
                write!(w, "*")?;
                predicate.write_logic(w, registry, interner, fmt)
            }

            LogicExpr::GroupQuantifier { group_var, count, member_var, restriction, body } => {
                let g = interner.resolve(*group_var);
                let x = interner.resolve(*member_var);

                // ∃g(Group(g) ∧ Count(g,n) ∧ ∀x(Member(x,g) → restriction) ∧ body)
                write!(w, "{}{}(Group({}) {} Count({}, {}) {} {}{}(Member({}, {}) {} ",
                    fmt.existential(), g, g,
                    fmt.and(), g, count,
                    fmt.and(), fmt.universal(), x, x, g, fmt.implies())?;

                restriction.write_logic(w, registry, interner, fmt)?;

                write!(w, ") {} ", fmt.and())?;

                body.write_logic(w, registry, interner, fmt)?;

                write!(w, ")")
            }
        }
    }

    pub fn transpile_with<F: LogicFormatter>(
        &self,
        registry: &mut SymbolRegistry,
        interner: &Interner,
        fmt: &F,
    ) -> String {
        let mut buf = String::new();
        let _ = self.write_logic(&mut buf, registry, interner, fmt);
        buf
    }

    pub fn transpile(
        &self,
        registry: &mut SymbolRegistry,
        interner: &Interner,
        format: OutputFormat,
    ) -> String {
        match format {
            OutputFormat::Unicode => self.transpile_with(registry, interner, &UnicodeFormatter),
            OutputFormat::LaTeX => self.transpile_with(registry, interner, &LatexFormatter),
            OutputFormat::SimpleFOL => self.transpile_with(registry, interner, &SimpleFOLFormatter),
        }
    }

    pub fn transpile_ctx<F: LogicFormatter>(
        &self,
        ctx: &mut TranspileContext<'_>,
        fmt: &F,
    ) -> String {
        self.transpile_with(ctx.registry, ctx.interner, fmt)
    }

    pub fn transpile_ctx_unicode(&self, ctx: &mut TranspileContext<'_>) -> String {
        self.transpile_ctx(ctx, &UnicodeFormatter)
    }

    pub fn transpile_ctx_latex(&self, ctx: &mut TranspileContext<'_>) -> String {
        self.transpile_ctx(ctx, &LatexFormatter)
    }
}

```

---

### Output Formatting

**File:** `src/formatter.rs`

LatexFormatter, UnicodeFormatter, and LogicFormatter traits. Handles symbol sanitization and operator rendering for clean output.

```rust
use crate::ast::{AspectOperator, ModalDomain, QuantifierKind, TemporalOperator, VoiceOperator};
use crate::token::TokenType;

pub trait LogicFormatter {
    // Quantifiers
    fn quantifier(&self, kind: &QuantifierKind, var: &str, body: &str) -> String {
        let sym = match kind {
            QuantifierKind::Universal => self.universal(),
            QuantifierKind::Existential => self.existential(),
            QuantifierKind::Most => "MOST ".to_string(),
            QuantifierKind::Few => "FEW ".to_string(),
            QuantifierKind::Many => "MANY ".to_string(),
            QuantifierKind::Cardinal(n) => self.cardinal(*n),
            QuantifierKind::AtLeast(n) => self.at_least(*n),
            QuantifierKind::AtMost(n) => self.at_most(*n),
            QuantifierKind::Generic => "Gen ".to_string(),
        };
        format!("{}{}({})", sym, var, body)
    }

    fn universal(&self) -> String;
    fn existential(&self) -> String;
    fn cardinal(&self, n: u32) -> String;
    fn at_least(&self, n: u32) -> String;
    fn at_most(&self, n: u32) -> String;

    // Binary operators
    fn binary_op(&self, op: &TokenType, left: &str, right: &str) -> String {
        match op {
            TokenType::And => format!("({} {} {})", left, self.and(), right),
            TokenType::Or => format!("({} {} {})", left, self.or(), right),
            TokenType::If => format!("({} {} {})", left, self.implies(), right),
            TokenType::Iff => format!("({} {} {})", left, self.iff(), right),
            _ => String::new(),
        }
    }

    fn and(&self) -> &'static str;
    fn or(&self) -> &'static str;
    fn implies(&self) -> &'static str;
    fn iff(&self) -> &'static str;

    // Unary operators
    fn unary_op(&self, op: &TokenType, operand: &str) -> String {
        match op {
            TokenType::Not => format!("{}{}", self.not(), operand),
            _ => String::new(),
        }
    }

    fn not(&self) -> &'static str;

    // Modal operators
    fn modal(&self, domain: ModalDomain, force: f32, body: &str) -> String {
        let sym = match domain {
            ModalDomain::Alethic if force > 0.0 && force <= 0.5 => self.possibility(),
            ModalDomain::Alethic => self.necessity(),
            ModalDomain::Deontic if force <= 0.5 => "P",
            ModalDomain::Deontic => "O",
        };
        format!("{}_{{{:.1}}} {}", sym, force, body)
    }

    fn necessity(&self) -> &'static str;
    fn possibility(&self) -> &'static str;

    // Temporal operators
    fn temporal(&self, op: &TemporalOperator, body: &str) -> String {
        let sym = match op {
            TemporalOperator::Past => self.past(),
            TemporalOperator::Future => self.future(),
        };
        format!("{}({})", sym, body)
    }

    fn past(&self) -> &'static str;
    fn future(&self) -> &'static str;

    // Aspectual operators
    fn aspectual(&self, op: &AspectOperator, body: &str) -> String {
        let sym = match op {
            AspectOperator::Progressive => self.progressive(),
            AspectOperator::Perfect => self.perfect(),
            AspectOperator::Habitual => self.habitual(),
            AspectOperator::Iterative => self.iterative(),
        };
        format!("{}({})", sym, body)
    }

    fn progressive(&self) -> &'static str;
    fn perfect(&self) -> &'static str;
    fn habitual(&self) -> &'static str;
    fn iterative(&self) -> &'static str;

    // Voice operators
    fn voice(&self, op: &VoiceOperator, body: &str) -> String {
        let sym = match op {
            VoiceOperator::Passive => self.passive(),
        };
        format!("{}({})", sym, body)
    }

    fn passive(&self) -> &'static str;

    // Lambda
    fn lambda(&self, var: &str, body: &str) -> String;

    // Counterfactual
    fn counterfactual(&self, antecedent: &str, consequent: &str) -> String;

    // Superlative expansion
    fn superlative(&self, comp: &str, domain: &str, subject: &str) -> String;

    // Event quantification (uses existential + and)
    fn event_quantifier(&self, pred: &str, adverbs: &[String]) -> String {
        if adverbs.is_empty() {
            format!("{}e({})", self.existential(), pred)
        } else {
            let conj = self.and();
            format!(
                "{}e({} {} {})",
                self.existential(),
                pred,
                conj,
                adverbs.join(&format!(" {} ", conj))
            )
        }
    }

    // Categorical (legacy)
    fn categorical_all(&self) -> &'static str;
    fn categorical_no(&self) -> &'static str;
    fn categorical_some(&self) -> &'static str;
    fn categorical_not(&self) -> &'static str;

    // Sanitization hook for LaTeX special characters
    fn sanitize(&self, s: &str) -> String {
        s.to_string()
    }

    // Whether to use simple predicate form instead of event semantics
    fn use_simple_events(&self) -> bool {
        false
    }

    // Whether to use full predicate names instead of abbreviations
    fn use_full_names(&self) -> bool {
        false
    }
}

pub struct UnicodeFormatter;

impl LogicFormatter for UnicodeFormatter {
    fn universal(&self) -> String { "∀".to_string() }
    fn existential(&self) -> String { "∃".to_string() }
    fn cardinal(&self, n: u32) -> String { format!("∃={}.", n) }
    fn at_least(&self, n: u32) -> String { format!("∃≥{}", n) }
    fn at_most(&self, n: u32) -> String { format!("∃≤{}", n) }

    fn and(&self) -> &'static str { "∧" }
    fn or(&self) -> &'static str { "∨" }
    fn implies(&self) -> &'static str { "→" }
    fn iff(&self) -> &'static str { "↔" }
    fn not(&self) -> &'static str { "¬" }

    fn necessity(&self) -> &'static str { "□" }
    fn possibility(&self) -> &'static str { "◇" }

    fn past(&self) -> &'static str { "P" }
    fn future(&self) -> &'static str { "F" }

    fn progressive(&self) -> &'static str { "Prog" }
    fn perfect(&self) -> &'static str { "Perf" }
    fn habitual(&self) -> &'static str { "HAB" }
    fn iterative(&self) -> &'static str { "ITER" }
    fn passive(&self) -> &'static str { "Pass" }

    fn lambda(&self, var: &str, body: &str) -> String {
        format!("λ{}.{}", var, body)
    }

    fn counterfactual(&self, antecedent: &str, consequent: &str) -> String {
        format!("({} □→ {})", antecedent, consequent)
    }

    fn superlative(&self, comp: &str, domain: &str, subject: &str) -> String {
        format!(
            "∀x(({}(x) ∧ x ≠ {}) → {}({}, x))",
            domain, subject, comp, subject
        )
    }

    fn categorical_all(&self) -> &'static str { "∀" }
    fn categorical_no(&self) -> &'static str { "∀¬" }
    fn categorical_some(&self) -> &'static str { "∃" }
    fn categorical_not(&self) -> &'static str { "¬" }
}

pub struct LatexFormatter;

impl LogicFormatter for LatexFormatter {
    fn universal(&self) -> String { "\\forall ".to_string() }
    fn existential(&self) -> String { "\\exists ".to_string() }
    fn cardinal(&self, n: u32) -> String { format!("\\exists_{{={}}} ", n) }
    fn at_least(&self, n: u32) -> String { format!("\\exists_{{\\geq {}}} ", n) }
    fn at_most(&self, n: u32) -> String { format!("\\exists_{{\\leq {}}} ", n) }

    fn and(&self) -> &'static str { "\\cdot" }
    fn or(&self) -> &'static str { "\\vee" }
    fn implies(&self) -> &'static str { "\\supset" }
    fn iff(&self) -> &'static str { "\\equiv" }
    fn not(&self) -> &'static str { "\\sim " }

    fn necessity(&self) -> &'static str { "\\Box" }
    fn possibility(&self) -> &'static str { "\\Diamond" }

    fn past(&self) -> &'static str { "\\mathsf{P}" }
    fn future(&self) -> &'static str { "\\mathsf{F}" }

    fn progressive(&self) -> &'static str { "\\mathsf{Prog}" }
    fn perfect(&self) -> &'static str { "\\mathsf{Perf}" }
    fn habitual(&self) -> &'static str { "\\mathsf{HAB}" }
    fn iterative(&self) -> &'static str { "\\mathsf{ITER}" }
    fn passive(&self) -> &'static str { "\\mathsf{Pass}" }

    fn lambda(&self, var: &str, body: &str) -> String {
        format!("\\lambda {}.{}", var, body)
    }

    fn counterfactual(&self, antecedent: &str, consequent: &str) -> String {
        format!("({} \\boxright {})", antecedent, consequent)
    }

    fn superlative(&self, comp: &str, domain: &str, subject: &str) -> String {
        format!(
            "\\forall x(({}(x) \\land x \\neq {}) \\supset {}({}, x))",
            domain, subject, comp, subject
        )
    }

    fn categorical_all(&self) -> &'static str { "All" }
    fn categorical_no(&self) -> &'static str { "No" }
    fn categorical_some(&self) -> &'static str { "Some" }
    fn categorical_not(&self) -> &'static str { "not" }

    fn sanitize(&self, s: &str) -> String {
        s.replace('_', r"\_")
            .replace('^', r"\^{}")
            .replace('&', r"\&")
            .replace('%', r"\%")
            .replace('#', r"\#")
            .replace('$', r"\$")
    }
}

pub struct SimpleFOLFormatter;

impl LogicFormatter for SimpleFOLFormatter {
    fn universal(&self) -> String { "∀".to_string() }
    fn existential(&self) -> String { "∃".to_string() }
    fn cardinal(&self, n: u32) -> String { format!("∃={}", n) }
    fn at_least(&self, n: u32) -> String { format!("∃≥{}", n) }
    fn at_most(&self, n: u32) -> String { format!("∃≤{}", n) }

    fn and(&self) -> &'static str { "∧" }
    fn or(&self) -> &'static str { "∨" }
    fn implies(&self) -> &'static str { "→" }
    fn iff(&self) -> &'static str { "↔" }
    fn not(&self) -> &'static str { "¬" }

    fn necessity(&self) -> &'static str { "□" }
    fn possibility(&self) -> &'static str { "◇" }

    fn past(&self) -> &'static str { "Past" }
    fn future(&self) -> &'static str { "Future" }

    fn progressive(&self) -> &'static str { "" }
    fn perfect(&self) -> &'static str { "" }
    fn habitual(&self) -> &'static str { "" }
    fn iterative(&self) -> &'static str { "" }
    fn passive(&self) -> &'static str { "" }

    fn lambda(&self, var: &str, body: &str) -> String {
        format!("λ{}.{}", var, body)
    }

    fn counterfactual(&self, antecedent: &str, consequent: &str) -> String {
        format!("({} □→ {})", antecedent, consequent)
    }

    fn superlative(&self, comp: &str, domain: &str, subject: &str) -> String {
        format!(
            "∀x(({}(x) ∧ x ≠ {}) → {}({}, x))",
            domain, subject, comp, subject
        )
    }

    fn categorical_all(&self) -> &'static str { "∀" }
    fn categorical_no(&self) -> &'static str { "∀¬" }
    fn categorical_some(&self) -> &'static str { "∃" }
    fn categorical_not(&self) -> &'static str { "¬" }

    fn modal(&self, _domain: ModalDomain, _force: f32, body: &str) -> String {
        body.to_string()
    }

    fn aspectual(&self, _op: &AspectOperator, body: &str) -> String {
        body.to_string()
    }

    fn use_simple_events(&self) -> bool {
        true
    }

    fn use_full_names(&self) -> bool {
        true
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn unicode_binary_operators() {
        let f = UnicodeFormatter;
        assert_eq!(f.binary_op(&TokenType::And, "P", "Q"), "(P ∧ Q)");
        assert_eq!(f.binary_op(&TokenType::Or, "P", "Q"), "(P ∨ Q)");
        assert_eq!(f.binary_op(&TokenType::If, "P", "Q"), "(P → Q)");
        assert_eq!(f.binary_op(&TokenType::Iff, "P", "Q"), "(P ↔ Q)");
    }

    #[test]
    fn latex_binary_operators() {
        let f = LatexFormatter;
        assert_eq!(f.binary_op(&TokenType::And, "P", "Q"), r"(P \cdot Q)");
        assert_eq!(f.binary_op(&TokenType::Or, "P", "Q"), r"(P \vee Q)");
        assert_eq!(f.binary_op(&TokenType::If, "P", "Q"), r"(P \supset Q)");
        assert_eq!(f.binary_op(&TokenType::Iff, "P", "Q"), r"(P \equiv Q)");
    }

    #[test]
    fn unicode_quantifiers() {
        let f = UnicodeFormatter;
        assert_eq!(f.quantifier(&QuantifierKind::Universal, "x", "P(x)"), "∀x(P(x))");
        assert_eq!(f.quantifier(&QuantifierKind::Existential, "x", "P(x)"), "∃x(P(x))");
        assert_eq!(f.quantifier(&QuantifierKind::Cardinal(3), "x", "P(x)"), "∃=3.x(P(x))");
    }

    #[test]
    fn latex_quantifiers() {
        let f = LatexFormatter;
        assert_eq!(f.quantifier(&QuantifierKind::Universal, "x", "P(x)"), "\\forall x(P(x))");
        assert_eq!(f.quantifier(&QuantifierKind::Existential, "x", "P(x)"), "\\exists x(P(x))");
    }

    #[test]
    fn latex_sanitization() {
        let f = LatexFormatter;
        assert_eq!(f.sanitize("foo_bar"), r"foo\_bar");
        assert_eq!(f.sanitize("x^2"), r"x\^{}2");
        assert_eq!(f.sanitize("a&b"), r"a\&b");
    }

    #[test]
    fn unicode_no_sanitization() {
        let f = UnicodeFormatter;
        assert_eq!(f.sanitize("foo_bar"), "foo_bar");
    }

    #[test]
    fn unicode_lambda() {
        let f = UnicodeFormatter;
        assert_eq!(f.lambda("x", "P(x)"), "λx.P(x)");
    }

    #[test]
    fn latex_lambda() {
        let f = LatexFormatter;
        assert_eq!(f.lambda("x", "P(x)"), "\\lambda x.P(x)");
    }

    #[test]
    fn unicode_counterfactual() {
        let f = UnicodeFormatter;
        assert_eq!(f.counterfactual("P", "Q"), "(P □→ Q)");
    }

    #[test]
    fn latex_counterfactual() {
        let f = LatexFormatter;
        assert_eq!(f.counterfactual("P", "Q"), r"(P \boxright Q)");
    }
}

```

---

### Symbol Registry

**File:** `src/registry.rs`

Maps interned symbols to readable output strings. Manages predicate and constant naming conventions.

```rust
use std::collections::HashMap;
use crate::intern::{Interner, Symbol};

pub struct SymbolRegistry {
    mapping: HashMap<String, String>,
    counters: HashMap<char, usize>,
}

impl SymbolRegistry {
    pub fn new() -> Self {
        SymbolRegistry {
            mapping: HashMap::new(),
            counters: HashMap::new(),
        }
    }

    pub fn get_symbol_full(&self, sym: Symbol, interner: &Interner) -> String {
        let word = interner.resolve(sym);
        let mut chars = word.chars();
        match chars.next() {
            Some(c) => c.to_uppercase().collect::<String>() + chars.as_str(),
            None => String::new(),
        }
    }

    pub fn get_symbol(&mut self, sym: Symbol, interner: &Interner) -> String {
        let word = interner.resolve(sym);
        let normalized = word.to_lowercase();

        if let Some(sym) = self.mapping.get(&normalized) {
            return sym.clone();
        }

        // For hyphenated compounds (non-intersective adjectives), return full form
        // "fake-gun" → "Fake-Gun" (not "F")
        if word.contains('-') {
            let compound: String = word
                .split('-')
                .map(|part| {
                    let mut chars = part.chars();
                    match chars.next() {
                        Some(c) => c.to_uppercase().collect::<String>() + chars.as_str(),
                        None => String::new(),
                    }
                })
                .collect::<Vec<_>>()
                .join("-");
            self.mapping.insert(normalized, compound.clone());
            return compound;
        }

        // Preserve specific relational terms (bridging markers)
        const PRESERVED_TERMS: &[&str] = &["PartOf"];
        if PRESERVED_TERMS.iter().any(|t| t.eq_ignore_ascii_case(word)) {
            self.mapping.insert(normalized, word.to_string());
            return word.to_string();
        }

        let first = normalized
            .chars()
            .next()
            .unwrap()
            .to_uppercase()
            .next()
            .unwrap();

        let counter = self.counters.entry(first).or_insert(0);
        *counter += 1;

        let symbol = if *counter == 1 {
            first.to_string()
        } else {
            format!("{}{}", first, counter)
        };

        self.mapping.insert(normalized, symbol.clone());
        symbol
    }
}

impl Default for SymbolRegistry {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn first_word_gets_single_letter() {
        let mut interner = Interner::new();
        let mut reg = SymbolRegistry::new();
        let dog = interner.intern("dog");
        assert_eq!(reg.get_symbol(dog, &interner), "D");
    }

    #[test]
    fn second_word_same_letter_gets_numbered() {
        let mut interner = Interner::new();
        let mut reg = SymbolRegistry::new();
        let dog = interner.intern("dog");
        let dangerous = interner.intern("dangerous");
        reg.get_symbol(dog, &interner);
        assert_eq!(reg.get_symbol(dangerous, &interner), "D2");
    }

    #[test]
    fn same_word_returns_same_symbol() {
        let mut interner = Interner::new();
        let mut reg = SymbolRegistry::new();
        let cat = interner.intern("cat");
        let first = reg.get_symbol(cat, &interner);
        let second = reg.get_symbol(cat, &interner);
        assert_eq!(first, second);
    }

    #[test]
    fn case_insensitive() {
        let mut interner = Interner::new();
        let mut reg = SymbolRegistry::new();
        let dog = interner.intern("dog");
        let dog_upper = interner.intern("DOG");
        let lower = reg.get_symbol(dog, &interner);
        let upper = reg.get_symbol(dog_upper, &interner);
        assert_eq!(lower, upper);
    }
}

```

---

## Semantic Analysis

Advanced semantic computation using lambda calculus for compositional meaning construction.

**Location:** `src/lambda.rs`, `src/context.rs`, `src/view.rs`

### Lambda Calculus

**File:** `src/lambda.rs`

Lambda calculus core with Montague-style compositional semantics. Features: Lambda abstraction, application, and beta reduction. **Quantifier Scope Enumeration** via enumerate_scopings() returning lazy ScopeIterator. **Complexity:** Factorial O(n!) worst-case, optimized by Island constraints to Π(k_i!). **Island Constraints:** Scope boundaries (if/and/or) prevent cross-island quantifier movement. **Intensionality (De Re/De Dicto):** enumerate_intensional_readings() for opaque verbs (seek, want, believe, need, fear). **Opacity-Respecting Substitution:** substitute_respecting_opacity() blocks substitution inside intensional contexts. **Montague Up-Arrow:** Term::Intension(^P) for de dicto readings.

```rust
use crate::arena::Arena;
use crate::ast::{LogicExpr, QuantifierKind, Term};
use crate::intern::{Interner, Symbol};
use crate::lexicon;
use crate::token::TokenType;

fn clone_term<'a>(term: &Term<'a>, arena: &'a Arena<Term<'a>>) -> Term<'a> {
    match term {
        Term::Constant(s) => Term::Constant(*s),
        Term::Variable(s) => Term::Variable(*s),
        Term::Function(name, args) => {
            let cloned_args: Vec<Term<'a>> = args.iter().map(|t| clone_term(t, arena)).collect();
            Term::Function(*name, arena.alloc_slice(cloned_args))
        }
        Term::Group(members) => {
            let cloned: Vec<Term<'a>> = members.iter().map(|t| clone_term(t, arena)).collect();
            Term::Group(arena.alloc_slice(cloned))
        }
        Term::Possessed { possessor, possessed } => Term::Possessed {
            possessor: arena.alloc(clone_term(possessor, arena)),
            possessed: *possessed,
        },
        Term::Sigma(predicate) => Term::Sigma(*predicate),
        Term::Intension(predicate) => Term::Intension(*predicate),
        Term::Proposition(expr) => Term::Proposition(*expr),
        Term::Value { kind, unit, dimension } => Term::Value {
            kind: *kind,
            unit: *unit,
            dimension: *dimension,
        },
    }
}

pub fn is_opaque_verb(verb: Symbol, interner: &Interner) -> bool {
    let verb_str = interner.resolve(verb);
    let lower = verb_str.to_lowercase();
    lexicon::is_opaque_verb(&lower)
}

pub fn make_intensional<'a>(
    operator: Symbol,
    content: &'a LogicExpr<'a>,
    arena: &'a Arena<LogicExpr<'a>>,
) -> &'a LogicExpr<'a> {
    arena.alloc(LogicExpr::Intensional { operator, content })
}

pub fn substitute_respecting_opacity<'a>(
    expr: &'a LogicExpr<'a>,
    var: Symbol,
    replacement: &'a LogicExpr<'a>,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
) -> &'a LogicExpr<'a> {
    match expr {
        LogicExpr::Intensional { operator, content } => {
            expr_arena.alloc(LogicExpr::Intensional {
                operator: *operator,
                content: *content,
            })
        }

        LogicExpr::Predicate { name, args } => {
            let new_args: Vec<Term<'a>> = args
                .iter()
                .map(|arg| substitute_term_for_opacity(arg, var, replacement, term_arena))
                .collect();
            expr_arena.alloc(LogicExpr::Predicate {
                name: *name,
                args: term_arena.alloc_slice(new_args),
            })
        }

        LogicExpr::BinaryOp { left, op, right } => expr_arena.alloc(LogicExpr::BinaryOp {
            left: substitute_respecting_opacity(left, var, replacement, expr_arena, term_arena),
            op: op.clone(),
            right: substitute_respecting_opacity(right, var, replacement, expr_arena, term_arena),
        }),

        LogicExpr::UnaryOp { op, operand } => expr_arena.alloc(LogicExpr::UnaryOp {
            op: op.clone(),
            operand: substitute_respecting_opacity(operand, var, replacement, expr_arena, term_arena),
        }),

        LogicExpr::Quantifier { kind, variable, body, island_id } => {
            if *variable == var {
                expr
            } else {
                expr_arena.alloc(LogicExpr::Quantifier {
                    kind: *kind,
                    variable: *variable,
                    body: substitute_respecting_opacity(body, var, replacement, expr_arena, term_arena),
                    island_id: *island_id,
                })
            }
        }

        LogicExpr::Lambda { variable, body } => {
            if *variable == var {
                expr
            } else {
                expr_arena.alloc(LogicExpr::Lambda {
                    variable: *variable,
                    body: substitute_respecting_opacity(body, var, replacement, expr_arena, term_arena),
                })
            }
        }

        LogicExpr::App { function, argument } => expr_arena.alloc(LogicExpr::App {
            function: substitute_respecting_opacity(function, var, replacement, expr_arena, term_arena),
            argument: substitute_respecting_opacity(argument, var, replacement, expr_arena, term_arena),
        }),

        LogicExpr::Atom(s) => {
            if *s == var {
                replacement
            } else {
                expr
            }
        }

        _ => expr,
    }
}

fn substitute_term_for_opacity<'a>(
    term: &Term<'a>,
    var: Symbol,
    replacement: &LogicExpr<'a>,
    arena: &'a Arena<Term<'a>>,
) -> Term<'a> {
    match term {
        Term::Constant(c) if *c == var => {
            match replacement {
                LogicExpr::Atom(s) => Term::Constant(*s),
                _ => clone_term(term, arena),
            }
        }
        Term::Variable(v) if *v == var => {
            match replacement {
                LogicExpr::Atom(s) => Term::Constant(*s),
                _ => clone_term(term, arena),
            }
        }
        _ => clone_term(term, arena),
    }
}

pub fn to_event_semantics<'a>(
    expr: &'a LogicExpr<'a>,
    interner: &mut Interner,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
) -> &'a LogicExpr<'a> {
    match expr {
        LogicExpr::Predicate { name, args } => {
            let e_sym = interner.intern("e");
            let _event_var = term_arena.alloc(Term::Variable(e_sym));

            let event_pred = expr_arena.alloc(LogicExpr::Predicate {
                name: *name,
                args: term_arena.alloc_slice([Term::Variable(e_sym)]),
            });

            let mut body = event_pred;

            if !args.is_empty() {
                let agent_args = term_arena.alloc_slice([Term::Variable(e_sym), clone_term(&args[0], term_arena)]);
                let agent_pred = expr_arena.alloc(LogicExpr::Predicate {
                    name: interner.intern("Agent"),
                    args: agent_args,
                });
                body = expr_arena.alloc(LogicExpr::BinaryOp {
                    left: body,
                    op: TokenType::And,
                    right: agent_pred,
                });
            }

            if args.len() > 1 {
                let theme_args = term_arena.alloc_slice([Term::Variable(e_sym), clone_term(&args[1], term_arena)]);
                let theme_pred = expr_arena.alloc(LogicExpr::Predicate {
                    name: interner.intern("Theme"),
                    args: theme_args,
                });
                body = expr_arena.alloc(LogicExpr::BinaryOp {
                    left: body,
                    op: TokenType::And,
                    right: theme_pred,
                });
            }

            if args.len() > 2 {
                let goal_args = term_arena.alloc_slice([Term::Variable(e_sym), clone_term(&args[2], term_arena)]);
                let goal_pred = expr_arena.alloc(LogicExpr::Predicate {
                    name: interner.intern("Goal"),
                    args: goal_args,
                });
                body = expr_arena.alloc(LogicExpr::BinaryOp {
                    left: body,
                    op: TokenType::And,
                    right: goal_pred,
                });
            }

            expr_arena.alloc(LogicExpr::Quantifier {
                kind: QuantifierKind::Existential,
                variable: e_sym,
                body,
                island_id: 0,
            })
        }
        _ => expr,
    }
}

pub fn apply_adverb<'a>(
    expr: &'a LogicExpr<'a>,
    adverb: Symbol,
    interner: &mut Interner,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
) -> &'a LogicExpr<'a> {
    let e_sym = interner.intern("e");
    match expr {
        LogicExpr::Quantifier { kind, variable, body, island_id } if *variable == e_sym => {
            let adverb_str = interner.resolve(adverb);
            let capitalized = capitalize(adverb_str);
            let adverb_pred = expr_arena.alloc(LogicExpr::Predicate {
                name: interner.intern(&capitalized),
                args: term_arena.alloc_slice([Term::Variable(*variable)]),
            });

            let new_body = expr_arena.alloc(LogicExpr::BinaryOp {
                left: *body,
                op: TokenType::And,
                right: adverb_pred,
            });

            expr_arena.alloc(LogicExpr::Quantifier {
                kind: *kind,
                variable: *variable,
                body: new_body,
                island_id: *island_id,
            })
        }
        _ => expr,
    }
}

fn capitalize(s: &str) -> String {
    let mut chars = s.chars();
    match chars.next() {
        None => String::new(),
        Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
    }
}

fn factorial(n: usize) -> u64 {
    (1..=n as u64).product()
}

pub struct ScopeIterator<'a> {
    expr_arena: &'a Arena<LogicExpr<'a>>,
    islands: Vec<Vec<ScopalElement<'a>>>,
    core: &'a LogicExpr<'a>,
    current_index: u64,
    total: u64,
    single_result: Option<&'a LogicExpr<'a>>,
    returned_single: bool,
}

impl<'a> ScopeIterator<'a> {
    fn nth_island_aware_permutation(&self, n: u64) -> Vec<ScopalElement<'a>> {
        let mut result = Vec::new();
        let mut remainder = n;

        for island in &self.islands {
            let island_perms = factorial(island.len());
            let island_index = remainder % island_perms;
            remainder /= island_perms;

            let perm = nth_permutation_of_slice(island, island_index);
            result.extend(perm);
        }

        result
    }
}

fn nth_permutation_of_slice<T: Clone>(items: &[T], n: u64) -> Vec<T> {
    let len = items.len();
    let mut available: Vec<usize> = (0..len).collect();
    let mut result = Vec::with_capacity(len);
    let mut remainder = n;

    for i in 0..len {
        let divisor = factorial(len - i - 1);
        let index = (remainder / divisor) as usize;
        remainder %= divisor;
        result.push(items[available.remove(index)].clone());
    }
    result
}

impl<'a> Iterator for ScopeIterator<'a> {
    type Item = &'a LogicExpr<'a>;

    fn next(&mut self) -> Option<Self::Item> {
        if let Some(single) = self.single_result {
            if self.returned_single {
                return None;
            }
            self.returned_single = true;
            return Some(single);
        }

        if self.current_index >= self.total {
            return None;
        }
        let ordered = self.nth_island_aware_permutation(self.current_index);
        self.current_index += 1;
        Some(rebuild_with_scopal_elements(&ordered, self.core, self.expr_arena))
    }

    fn size_hint(&self) -> (usize, Option<usize>) {
        if self.single_result.is_some() {
            let remaining = if self.returned_single { 0 } else { 1 };
            return (remaining, Some(remaining));
        }
        let remaining = (self.total - self.current_index) as usize;
        (remaining, Some(remaining))
    }
}

impl<'a> ExactSizeIterator for ScopeIterator<'a> {}

#[derive(Clone, Debug)]
struct QuantifierInfo<'a> {
    kind: QuantifierKind,
    variable: Symbol,
    restrictor: &'a LogicExpr<'a>,
    island_id: u32,
}

#[derive(Clone, Debug)]
enum ScopalElement<'a> {
    Quantifier(QuantifierInfo<'a>),
    Negation { island_id: u32 },
}

impl<'a> ScopalElement<'a> {
    fn island_id(&self) -> u32 {
        match self {
            ScopalElement::Quantifier(q) => q.island_id,
            ScopalElement::Negation { island_id } => *island_id,
        }
    }
}

pub fn enumerate_scopings<'a>(
    expr: &'a LogicExpr<'a>,
    interner: &mut Interner,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    _term_arena: &'a Arena<Term<'a>>,
) -> ScopeIterator<'a> {
    let mut elements = Vec::new();
    let core = extract_scopal_elements(expr, &mut elements, interner, expr_arena);

    if elements.is_empty() || elements.len() == 1 {
        return ScopeIterator {
            expr_arena,
            islands: Vec::new(),
            core,
            current_index: 0,
            total: 0,
            single_result: Some(expr),
            returned_single: false,
        };
    }

    let islands = group_scopal_by_island(elements);
    let total: u64 = islands.iter().map(|island| factorial(island.len())).product();

    ScopeIterator {
        expr_arena,
        islands,
        core,
        current_index: 0,
        total,
        single_result: None,
        returned_single: false,
    }
}

fn group_by_island<'a>(quantifiers: Vec<QuantifierInfo<'a>>) -> Vec<Vec<QuantifierInfo<'a>>> {
    use std::collections::BTreeMap;

    let mut by_island: BTreeMap<u32, Vec<QuantifierInfo<'a>>> = BTreeMap::new();
    for q in quantifiers {
        by_island.entry(q.island_id).or_default().push(q);
    }

    by_island.into_values().collect()
}

fn group_scopal_by_island<'a>(elements: Vec<ScopalElement<'a>>) -> Vec<Vec<ScopalElement<'a>>> {
    use std::collections::BTreeMap;

    let mut by_island: BTreeMap<u32, Vec<ScopalElement<'a>>> = BTreeMap::new();
    for elem in elements {
        by_island.entry(elem.island_id()).or_default().push(elem);
    }

    by_island.into_values().collect()
}

fn extract_scopal_elements<'a>(
    expr: &'a LogicExpr<'a>,
    elements: &mut Vec<ScopalElement<'a>>,
    interner: &mut Interner,
    expr_arena: &'a Arena<LogicExpr<'a>>,
) -> &'a LogicExpr<'a> {
    match expr {
        LogicExpr::Quantifier { kind, variable, body, island_id } => {
            if let LogicExpr::BinaryOp { left, op, right } = body {
                if matches!(op, TokenType::If | TokenType::And) {
                    // Check if right side has a negation at the top level
                    if let LogicExpr::UnaryOp { op: TokenType::Not, operand } = right {
                        // Pattern: ∀x(R(x) → ¬P(x)) or ∃x(R(x) ∧ ¬P(x))
                        // Extract both quantifier and negation
                        elements.push(ScopalElement::Quantifier(QuantifierInfo {
                            kind: *kind,
                            variable: *variable,
                            restrictor: *left,
                            island_id: *island_id,
                        }));
                        elements.push(ScopalElement::Negation { island_id: *island_id });
                        return extract_scopal_elements(operand, elements, interner, expr_arena);
                    }
                    // No negation in right side, just extract quantifier
                    elements.push(ScopalElement::Quantifier(QuantifierInfo {
                        kind: *kind,
                        variable: *variable,
                        restrictor: *left,
                        island_id: *island_id,
                    }));
                    return extract_scopal_elements(right, elements, interner, expr_arena);
                }
            }
            // No binary op body, use a true restrictor
            elements.push(ScopalElement::Quantifier(QuantifierInfo {
                kind: *kind,
                variable: *variable,
                restrictor: expr_arena.alloc(LogicExpr::Atom(interner.intern("T"))),
                island_id: *island_id,
            }));
            extract_scopal_elements(body, elements, interner, expr_arena)
        }
        LogicExpr::UnaryOp { op: TokenType::Not, operand } => {
            // Standalone negation (not inside a quantifier body)
            elements.push(ScopalElement::Negation { island_id: 0 });
            extract_scopal_elements(operand, elements, interner, expr_arena)
        }
        _ => expr,
    }
}

fn rebuild_with_scopal_elements<'a>(
    elements: &[ScopalElement<'a>],
    core: &'a LogicExpr<'a>,
    arena: &'a Arena<LogicExpr<'a>>,
) -> &'a LogicExpr<'a> {
    let mut result = core;

    for elem in elements.iter().rev() {
        match elem {
            ScopalElement::Quantifier(q) => {
                let connective = match q.kind {
                    QuantifierKind::Universal => TokenType::If,
                    _ => TokenType::And,
                };

                let body = arena.alloc(LogicExpr::BinaryOp {
                    left: q.restrictor,
                    op: connective,
                    right: result,
                });

                result = arena.alloc(LogicExpr::Quantifier {
                    kind: q.kind,
                    variable: q.variable,
                    body,
                    island_id: q.island_id,
                });
            }
            ScopalElement::Negation { .. } => {
                result = arena.alloc(LogicExpr::UnaryOp {
                    op: TokenType::Not,
                    operand: result,
                });
            }
        }
    }

    result
}

fn extract_quantifiers<'a>(
    expr: &'a LogicExpr<'a>,
    quantifiers: &mut Vec<QuantifierInfo<'a>>,
    interner: &mut Interner,
    expr_arena: &'a Arena<LogicExpr<'a>>,
) -> &'a LogicExpr<'a> {
    match expr {
        LogicExpr::Quantifier { kind, variable, body, island_id } => {
            if let LogicExpr::BinaryOp { left, op, right } = body {
                if matches!(op, TokenType::If | TokenType::And) {
                    quantifiers.push(QuantifierInfo {
                        kind: *kind,
                        variable: *variable,
                        restrictor: *left,
                        island_id: *island_id,
                    });
                    return extract_quantifiers(right, quantifiers, interner, expr_arena);
                }
            }
            quantifiers.push(QuantifierInfo {
                kind: *kind,
                variable: *variable,
                restrictor: expr_arena.alloc(LogicExpr::Atom(interner.intern("T"))),
                island_id: *island_id,
            });
            extract_quantifiers(body, quantifiers, interner, expr_arena)
        }
        _ => expr,
    }
}

fn rebuild_with_scope_order<'a>(
    quantifiers: &[QuantifierInfo<'a>],
    core: &'a LogicExpr<'a>,
    arena: &'a Arena<LogicExpr<'a>>,
) -> &'a LogicExpr<'a> {
    let mut result = core;

    for q in quantifiers.iter().rev() {
        let connective = match q.kind {
            QuantifierKind::Universal => TokenType::If,
            _ => TokenType::And,
        };

        let body = arena.alloc(LogicExpr::BinaryOp {
            left: q.restrictor,
            op: connective,
            right: result,
        });

        result = arena.alloc(LogicExpr::Quantifier {
            kind: q.kind,
            variable: q.variable,
            body,
            island_id: q.island_id,
        });
    }

    result
}

pub fn lift_proper_name<'a>(
    name: Symbol,
    interner: &mut Interner,
    arena: &'a Arena<LogicExpr<'a>>,
) -> &'a LogicExpr<'a> {
    let p_sym = interner.intern("P");
    let inner_app = arena.alloc(LogicExpr::App {
        function: arena.alloc(LogicExpr::Atom(p_sym)),
        argument: arena.alloc(LogicExpr::Atom(name)),
    });
    arena.alloc(LogicExpr::Lambda {
        variable: p_sym,
        body: inner_app,
    })
}

pub fn lift_quantifier<'a>(
    kind: QuantifierKind,
    restrictor: Symbol,
    interner: &mut Interner,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
) -> &'a LogicExpr<'a> {
    let x_sym = interner.intern("x");
    let q_sym = interner.intern("Q");

    let restrictor_pred = expr_arena.alloc(LogicExpr::Predicate {
        name: restrictor,
        args: term_arena.alloc_slice([Term::Variable(x_sym)]),
    });

    let q_of_x = expr_arena.alloc(LogicExpr::App {
        function: expr_arena.alloc(LogicExpr::Atom(q_sym)),
        argument: expr_arena.alloc(LogicExpr::Atom(x_sym)),
    });

    let connective = match kind {
        QuantifierKind::Universal => TokenType::If,
        _ => TokenType::And,
    };

    let body = expr_arena.alloc(LogicExpr::BinaryOp {
        left: restrictor_pred,
        op: connective,
        right: q_of_x,
    });

    let quantifier = expr_arena.alloc(LogicExpr::Quantifier {
        kind,
        variable: x_sym,
        body,
        island_id: 0,
    });

    expr_arena.alloc(LogicExpr::Lambda {
        variable: q_sym,
        body: quantifier,
    })
}

pub fn beta_reduce<'a>(
    expr: &'a LogicExpr<'a>,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
) -> &'a LogicExpr<'a> {
    match expr {
        LogicExpr::App { function, argument } => {
            if let LogicExpr::Lambda { variable, body } = function {
                substitute(body, *variable, argument, expr_arena, term_arena)
            } else {
                expr_arena.alloc(LogicExpr::App {
                    function: beta_reduce(function, expr_arena, term_arena),
                    argument: beta_reduce(argument, expr_arena, term_arena),
                })
            }
        }
        LogicExpr::Lambda { variable, body } => expr_arena.alloc(LogicExpr::Lambda {
            variable: *variable,
            body: beta_reduce(body, expr_arena, term_arena),
        }),
        _ => expr,
    }
}

fn substitute<'a>(
    expr: &'a LogicExpr<'a>,
    var: Symbol,
    replacement: &'a LogicExpr<'a>,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
) -> &'a LogicExpr<'a> {
    match expr {
        LogicExpr::Predicate { name, args } => {
            let new_args: Vec<Term<'a>> = args
                .iter()
                .map(|arg| substitute_term(arg, var, replacement, term_arena))
                .collect();
            expr_arena.alloc(LogicExpr::Predicate {
                name: *name,
                args: term_arena.alloc_slice(new_args),
            })
        }

        LogicExpr::Lambda { variable, body } => {
            if *variable == var {
                expr
            } else {
                expr_arena.alloc(LogicExpr::Lambda {
                    variable: *variable,
                    body: substitute(body, var, replacement, expr_arena, term_arena),
                })
            }
        }

        LogicExpr::App { function, argument } => expr_arena.alloc(LogicExpr::App {
            function: substitute(function, var, replacement, expr_arena, term_arena),
            argument: substitute(argument, var, replacement, expr_arena, term_arena),
        }),

        LogicExpr::BinaryOp { left, op, right } => expr_arena.alloc(LogicExpr::BinaryOp {
            left: substitute(left, var, replacement, expr_arena, term_arena),
            op: op.clone(),
            right: substitute(right, var, replacement, expr_arena, term_arena),
        }),

        LogicExpr::UnaryOp { op, operand } => expr_arena.alloc(LogicExpr::UnaryOp {
            op: op.clone(),
            operand: substitute(operand, var, replacement, expr_arena, term_arena),
        }),

        LogicExpr::Quantifier { kind, variable, body, island_id } => {
            if *variable == var {
                expr
            } else {
                expr_arena.alloc(LogicExpr::Quantifier {
                    kind: *kind,
                    variable: *variable,
                    body: substitute(body, var, replacement, expr_arena, term_arena),
                    island_id: *island_id,
                })
            }
        }

        LogicExpr::Atom(s) => {
            if *s == var {
                replacement
            } else {
                expr
            }
        }

        _ => expr,
    }
}

fn substitute_term<'a>(
    term: &Term<'a>,
    var: Symbol,
    replacement: &LogicExpr<'a>,
    term_arena: &'a Arena<Term<'a>>,
) -> Term<'a> {
    match term {
        Term::Variable(v) if *v == var => {
            match replacement {
                LogicExpr::Atom(s) => Term::Constant(*s),
                LogicExpr::Predicate { name, .. } => Term::Constant(*name),
                _ => clone_term(term, term_arena),
            }
        }
        _ => clone_term(term, term_arena),
    }
}

// ═══════════════════════════════════════════════════════════════════
// Intensional Reading Generation (De Re / De Dicto)
// ═══════════════════════════════════════════════════════════════════

#[derive(Debug)]
struct IntensionalContext {
    verb: Symbol,
    quantifier_var: Symbol,
    restrictor: Symbol,
}

fn find_opaque_verb_context<'a>(
    expr: &'a LogicExpr<'a>,
    interner: &Interner,
) -> Option<IntensionalContext> {
    match expr {
        LogicExpr::Quantifier { kind: QuantifierKind::Existential, variable, body, .. } => {
            if let LogicExpr::BinaryOp { left, op: TokenType::And, right } = body {
                if let LogicExpr::Predicate { name: restrictor, args } = left {
                    if args.len() == 1 {
                        if let Term::Variable(v) = &args[0] {
                            if *v == *variable {
                                if let Some(verb) = find_opaque_verb_in_scope(right, *variable, interner) {
                                    return Some(IntensionalContext {
                                        verb,
                                        quantifier_var: *variable,
                                        restrictor: *restrictor,
                                    });
                                }
                            }
                        }
                    }
                }
            }
            None
        }
        _ => None,
    }
}

fn find_opaque_verb_in_scope<'a>(
    expr: &'a LogicExpr<'a>,
    theme_var: Symbol,
    interner: &Interner,
) -> Option<Symbol> {
    match expr {
        LogicExpr::Quantifier { body, .. } => find_opaque_verb_in_scope(body, theme_var, interner),
        LogicExpr::BinaryOp { left, right, .. } => {
            find_opaque_verb_in_scope(left, theme_var, interner)
                .or_else(|| find_opaque_verb_in_scope(right, theme_var, interner))
        }
        LogicExpr::NeoEvent(data) => {
            if is_opaque_verb(data.verb, interner) {
                for (role, term) in data.roles.iter() {
                    if matches!(role, crate::ast::ThematicRole::Theme) {
                        if let Term::Variable(v) = term {
                            if *v == theme_var {
                                return Some(data.verb);
                            }
                        }
                    }
                }
            }
            None
        }
        LogicExpr::Predicate { name, args } => {
            if is_opaque_verb(*name, interner) && args.len() >= 2 {
                if let Term::Variable(v) = &args[1] {
                    if *v == theme_var {
                        return Some(*name);
                    }
                }
            }
            None
        }
        _ => None,
    }
}

fn build_de_dicto_reading<'a>(
    expr: &'a LogicExpr<'a>,
    ctx: &IntensionalContext,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
    role_arena: &'a Arena<(crate::ast::ThematicRole, Term<'a>)>,
) -> &'a LogicExpr<'a> {
    match expr {
        LogicExpr::Quantifier { kind: QuantifierKind::Existential, variable, body, .. }
            if *variable == ctx.quantifier_var =>
        {
            if let LogicExpr::BinaryOp { right, .. } = body {
                replace_theme_with_intension(right, ctx, expr_arena, term_arena, role_arena)
            } else {
                expr
            }
        }
        _ => expr,
    }
}

fn replace_theme_with_intension<'a>(
    expr: &'a LogicExpr<'a>,
    ctx: &IntensionalContext,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
    role_arena: &'a Arena<(crate::ast::ThematicRole, Term<'a>)>,
) -> &'a LogicExpr<'a> {
    match expr {
        LogicExpr::Quantifier { kind, variable, body, island_id } => {
            let new_body = replace_theme_with_intension(body, ctx, expr_arena, term_arena, role_arena);
            expr_arena.alloc(LogicExpr::Quantifier {
                kind: *kind,
                variable: *variable,
                body: new_body,
                island_id: *island_id,
            })
        }
        LogicExpr::BinaryOp { left, op, right } => {
            let new_left = replace_theme_with_intension(left, ctx, expr_arena, term_arena, role_arena);
            let new_right = replace_theme_with_intension(right, ctx, expr_arena, term_arena, role_arena);
            expr_arena.alloc(LogicExpr::BinaryOp {
                left: new_left,
                op: op.clone(),
                right: new_right,
            })
        }
        LogicExpr::NeoEvent(data) => {
            let new_roles: Vec<_> = data.roles.iter().map(|(role, term)| {
                if matches!(role, crate::ast::ThematicRole::Theme) {
                    if let Term::Variable(v) = term {
                        if *v == ctx.quantifier_var {
                            return (*role, Term::Intension(ctx.restrictor));
                        }
                    }
                }
                (*role, clone_term(term, term_arena))
            }).collect();

            expr_arena.alloc(LogicExpr::NeoEvent(Box::new(crate::ast::NeoEventData {
                event_var: data.event_var,
                verb: data.verb,
                roles: role_arena.alloc_slice(new_roles),
                modifiers: data.modifiers,
            })))
        }
        LogicExpr::Predicate { name, args } => {
            let new_args: Vec<_> = args.iter().map(|arg| {
                if let Term::Variable(v) = arg {
                    if *v == ctx.quantifier_var {
                        return Term::Intension(ctx.restrictor);
                    }
                }
                clone_term(arg, term_arena)
            }).collect();

            expr_arena.alloc(LogicExpr::Predicate {
                name: *name,
                args: term_arena.alloc_slice(new_args),
            })
        }
        _ => expr,
    }
}

pub fn enumerate_intensional_readings<'a>(
    expr: &'a LogicExpr<'a>,
    interner: &mut Interner,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
    role_arena: &'a Arena<(crate::ast::ThematicRole, Term<'a>)>,
) -> Vec<&'a LogicExpr<'a>> {
    // Check if expression already has intensional terms (de dicto from parser)
    if let Some(de_re) = build_de_re_from_de_dicto(expr, interner, expr_arena, term_arena, role_arena) {
        // Return both: de re first (existential), de dicto second (intension)
        return vec![de_re, expr];
    }

    // Original logic: check for de re that can be converted to de dicto
    if let Some(ctx) = find_opaque_verb_context(expr, interner) {
        let de_dicto = build_de_dicto_reading(expr, &ctx, expr_arena, term_arena, role_arena);
        vec![expr, de_dicto]
    } else {
        vec![expr]
    }
}

fn build_de_re_from_de_dicto<'a>(
    expr: &'a LogicExpr<'a>,
    interner: &mut Interner,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
    role_arena: &'a Arena<(crate::ast::ThematicRole, Term<'a>)>,
) -> Option<&'a LogicExpr<'a>> {
    // Find Term::Intension in NeoEvent themes and expand to existential
    match expr {
        LogicExpr::NeoEvent(data) => {
            // Check if any role has an Intension term
            for (role, term) in data.roles.iter() {
                if matches!(role, crate::ast::ThematicRole::Theme) {
                    if let Term::Intension(noun) = term {
                        // Build de re: ∃x(Noun(x) ∧ Event[Theme=x])
                        let var = interner.intern("x");

                        // Build noun predicate: Noun(x)
                        let noun_pred = expr_arena.alloc(LogicExpr::Predicate {
                            name: *noun,
                            args: term_arena.alloc_slice([Term::Variable(var)]),
                        });

                        // Build new roles with variable instead of intension
                        let new_roles: Vec<_> = data.roles.iter().map(|(r, t)| {
                            if matches!(r, crate::ast::ThematicRole::Theme) {
                                (*r, Term::Variable(var))
                            } else {
                                (*r, t.clone())
                            }
                        }).collect();

                        let new_event = expr_arena.alloc(LogicExpr::NeoEvent(Box::new(crate::ast::NeoEventData {
                            event_var: data.event_var,
                            verb: data.verb,
                            roles: role_arena.alloc_slice(new_roles),
                            modifiers: data.modifiers,
                        })));

                        // Build: ∃x(Noun(x) ∧ Event)
                        let body = expr_arena.alloc(LogicExpr::BinaryOp {
                            left: noun_pred,
                            op: crate::token::TokenType::And,
                            right: new_event,
                        });

                        return Some(expr_arena.alloc(LogicExpr::Quantifier {
                            kind: crate::ast::QuantifierKind::Existential,
                            variable: var,
                            body,
                            island_id: 0,
                        }));
                    }
                }
            }
            None
        }
        _ => None,
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::ast::{LogicExpr, Term};
    use crate::intern::Interner;
    use crate::registry::SymbolRegistry;
    use crate::OutputFormat;

    #[test]
    fn test_lambda_formatting_unicode() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let sleep = interner.intern("Sleep");

        let body = expr_arena.alloc(LogicExpr::Predicate {
            name: sleep,
            args: term_arena.alloc_slice([Term::Variable(x)]),
        });
        let lambda = expr_arena.alloc(LogicExpr::Lambda { variable: x, body });

        let mut registry = SymbolRegistry::new();
        let output = lambda.transpile(&mut registry, &interner, OutputFormat::Unicode);
        assert!(output.contains("λx"), "Unicode should use λ: {}", output);
    }

    #[test]
    fn test_lambda_formatting_latex() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let sleep = interner.intern("Sleep");

        let body = expr_arena.alloc(LogicExpr::Predicate {
            name: sleep,
            args: term_arena.alloc_slice([Term::Variable(x)]),
        });
        let lambda = expr_arena.alloc(LogicExpr::Lambda { variable: x, body });

        let mut registry = SymbolRegistry::new();
        let output = lambda.transpile(&mut registry, &interner, OutputFormat::LaTeX);
        assert!(output.contains("\\lambda"), "LaTeX should use \\lambda: {}", output);
    }

    #[test]
    fn test_application_formatting() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();

        let p = interner.intern("P");
        let j = interner.intern("j");

        let func = expr_arena.alloc(LogicExpr::Atom(p));
        let arg = expr_arena.alloc(LogicExpr::Atom(j));
        let app = expr_arena.alloc(LogicExpr::App { function: func, argument: arg });

        let mut registry = SymbolRegistry::new();
        let output = app.transpile(&mut registry, &interner, OutputFormat::Unicode);
        assert!(output.contains("(") && output.contains(")"), "App should have parens: {}", output);
    }

    #[test]
    fn test_nested_lambda() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();

        let x = interner.intern("x");
        let y = interner.intern("y");

        let inner_body = expr_arena.alloc(LogicExpr::Atom(x));
        let inner_lambda = expr_arena.alloc(LogicExpr::Lambda { variable: y, body: inner_body });
        let outer_lambda = expr_arena.alloc(LogicExpr::Lambda { variable: x, body: inner_lambda });

        let mut registry = SymbolRegistry::new();
        let output = outer_lambda.transpile(&mut registry, &interner, OutputFormat::Unicode);
        assert!(output.contains("λx") && output.contains("λy"), "Nested lambdas: {}", output);
    }

    #[test]
    fn test_lambda_app_helper_functions() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let _term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let p = interner.intern("P");

        let body = expr_arena.alloc(LogicExpr::Atom(x));
        let lambda = LogicExpr::lambda(x, body, &expr_arena);

        let arg = expr_arena.alloc(LogicExpr::Atom(p));
        let app = LogicExpr::app(lambda, arg, &expr_arena);

        assert!(matches!(app, LogicExpr::App { .. }));
    }

    #[test]
    fn lift_proper_name_returns_lambda() {
        let mut interner = Interner::new();
        let arena: Arena<LogicExpr> = Arena::new();

        let john = interner.intern("John");
        let lifted = lift_proper_name(john, &mut interner, &arena);

        assert!(matches!(lifted, LogicExpr::Lambda { .. }), "Should return Lambda");
    }

    #[test]
    fn lift_proper_name_applies_predicate() {
        let mut interner = Interner::new();
        let arena: Arena<LogicExpr> = Arena::new();

        let john = interner.intern("John");
        let lifted = lift_proper_name(john, &mut interner, &arena);

        if let LogicExpr::Lambda { body, .. } = lifted {
            assert!(matches!(body, LogicExpr::App { .. }), "Body should be App");
        } else {
            panic!("Expected Lambda");
        }
    }

    #[test]
    fn lift_quantifier_universal_returns_lambda() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let woman = interner.intern("woman");
        let lifted = lift_quantifier(QuantifierKind::Universal, woman, &mut interner, &expr_arena, &term_arena);

        assert!(matches!(lifted, LogicExpr::Lambda { .. }), "Should return Lambda");
    }

    #[test]
    fn lift_quantifier_universal_structure() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let woman = interner.intern("woman");
        let lifted = lift_quantifier(QuantifierKind::Universal, woman, &mut interner, &expr_arena, &term_arena);

        if let LogicExpr::Lambda { body, .. } = lifted {
            assert!(
                matches!(body, LogicExpr::Quantifier { kind: QuantifierKind::Universal, .. }),
                "Body should contain ∀, got {:?}",
                body
            );
        } else {
            panic!("Expected Lambda, got {:?}", lifted);
        }
    }

    #[test]
    fn lift_quantifier_existential_returns_lambda() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let man = interner.intern("man");
        let lifted = lift_quantifier(QuantifierKind::Existential, man, &mut interner, &expr_arena, &term_arena);

        assert!(matches!(lifted, LogicExpr::Lambda { .. }), "Should return Lambda");
    }

    #[test]
    fn lift_quantifier_existential_structure() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let man = interner.intern("man");
        let lifted = lift_quantifier(QuantifierKind::Existential, man, &mut interner, &expr_arena, &term_arena);

        if let LogicExpr::Lambda { body, .. } = lifted {
            assert!(
                matches!(body, LogicExpr::Quantifier { kind: QuantifierKind::Existential, .. }),
                "Body should contain ∃, got {:?}",
                body
            );
        } else {
            panic!("Expected Lambda, got {:?}", lifted);
        }
    }

    #[test]
    fn beta_reduce_simple_predicate() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let john = interner.intern("John");
        let run = interner.intern("Run");

        let body = expr_arena.alloc(LogicExpr::Predicate {
            name: run,
            args: term_arena.alloc_slice([Term::Variable(x)]),
        });
        let lambda = expr_arena.alloc(LogicExpr::Lambda { variable: x, body });
        let arg = expr_arena.alloc(LogicExpr::Atom(john));
        let app = expr_arena.alloc(LogicExpr::App { function: lambda, argument: arg });

        let reduced = beta_reduce(app, &expr_arena, &term_arena);

        let mut registry = SymbolRegistry::new();
        let output = reduced.transpile(&mut registry, &interner, OutputFormat::Unicode);
        assert!(output.contains("R(J)") || output.contains("Run(John)"), "Should substitute: {}", output);
    }

    #[test]
    fn beta_reduce_with_constant() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let c = interner.intern("c");

        let body = expr_arena.alloc(LogicExpr::Atom(c));
        let lambda = expr_arena.alloc(LogicExpr::Lambda { variable: x, body });
        let arg = expr_arena.alloc(LogicExpr::Atom(interner.intern("anything")));
        let app = expr_arena.alloc(LogicExpr::App { function: lambda, argument: arg });

        let reduced = beta_reduce(app, &expr_arena, &term_arena);
        assert!(matches!(reduced, LogicExpr::Atom(s) if *s == c), "Constant should remain");
    }

    #[test]
    fn beta_reduce_nested_lambda() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let y = interner.intern("y");

        let inner_body = expr_arena.alloc(LogicExpr::Atom(x));
        let inner_lambda = expr_arena.alloc(LogicExpr::Lambda { variable: y, body: inner_body });
        let outer_lambda = expr_arena.alloc(LogicExpr::Lambda { variable: x, body: inner_lambda });

        let reduced = beta_reduce(outer_lambda, &expr_arena, &term_arena);
        assert!(matches!(reduced, LogicExpr::Lambda { .. }), "Should still be lambda");
    }

    #[test]
    fn beta_reduce_non_application_unchanged() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let p = interner.intern("P");
        let atom = expr_arena.alloc(LogicExpr::Atom(p));

        let reduced = beta_reduce(atom, &expr_arena, &term_arena);
        assert!(matches!(reduced, LogicExpr::Atom(s) if *s == p), "Atom unchanged");
    }

    #[test]
    fn beta_reduce_preserves_unbound_variables() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let y = interner.intern("y");
        let john = interner.intern("John");
        let loves = interner.intern("Loves");

        let body = expr_arena.alloc(LogicExpr::Predicate {
            name: loves,
            args: term_arena.alloc_slice([Term::Variable(x), Term::Variable(y)]),
        });
        let lambda = expr_arena.alloc(LogicExpr::Lambda { variable: x, body });
        let arg = expr_arena.alloc(LogicExpr::Atom(john));
        let app = expr_arena.alloc(LogicExpr::App { function: lambda, argument: arg });

        let reduced = beta_reduce(app, &expr_arena, &term_arena);

        let mut registry = SymbolRegistry::new();
        let output = reduced.transpile(&mut registry, &interner, OutputFormat::Unicode);
        assert!(output.contains("y"), "y should remain unbound: {}", output);
    }

    #[test]
    fn enumerate_scopings_single_quantifier() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let dog = interner.intern("Dog");
        let bark = interner.intern("Bark");

        let left = expr_arena.alloc(LogicExpr::Predicate {
            name: dog,
            args: term_arena.alloc_slice([Term::Variable(x)]),
        });
        let right = expr_arena.alloc(LogicExpr::Predicate {
            name: bark,
            args: term_arena.alloc_slice([Term::Variable(x)]),
        });
        let body = expr_arena.alloc(LogicExpr::BinaryOp {
            left,
            op: TokenType::If,
            right,
        });
        let expr = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Universal,
            variable: x,
            body,
            island_id: 0,
        });

        let scopings = enumerate_scopings(expr, &mut interner, &expr_arena, &term_arena);
        assert_eq!(scopings.len(), 1, "Single quantifier should have 1 reading");
    }

    #[test]
    fn enumerate_scopings_no_quantifier() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let run = interner.intern("Run");
        let john = interner.intern("John");

        let expr = expr_arena.alloc(LogicExpr::Predicate {
            name: run,
            args: term_arena.alloc_slice([Term::Constant(john)]),
        });

        let scopings = enumerate_scopings(expr, &mut interner, &expr_arena, &term_arena);
        assert_eq!(scopings.len(), 1, "No quantifiers should have 1 reading");
    }

    #[test]
    fn is_opaque_verb_believes() {
        let mut interner = Interner::new();
        let believes = interner.intern("believes");
        let believes_cap = interner.intern("Believes");
        assert!(is_opaque_verb(believes, &interner), "believes should be opaque");
        assert!(is_opaque_verb(believes_cap, &interner), "Believes should be opaque");
    }

    #[test]
    fn is_opaque_verb_seeks() {
        let mut interner = Interner::new();
        let seeks = interner.intern("seeks");
        let wants = interner.intern("wants");
        assert!(is_opaque_verb(seeks, &interner), "seeks should be opaque");
        assert!(is_opaque_verb(wants, &interner), "wants should be opaque");
    }

    #[test]
    fn is_opaque_verb_normal_verbs() {
        let mut interner = Interner::new();
        let runs = interner.intern("runs");
        let loves = interner.intern("loves");
        assert!(!is_opaque_verb(runs, &interner), "runs should NOT be opaque");
        assert!(!is_opaque_verb(loves, &interner), "loves should NOT be opaque");
    }

    #[test]
    fn make_intensional_creates_wrapper() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let weak = interner.intern("Weak");
        let clark = interner.intern("Clark");
        let believes = interner.intern("believes");

        let content = expr_arena.alloc(LogicExpr::Predicate {
            name: weak,
            args: term_arena.alloc_slice([Term::Constant(clark)]),
        });

        let intensional = make_intensional(believes, content, &expr_arena);

        assert!(
            matches!(intensional, LogicExpr::Intensional { operator, .. } if *operator == believes),
            "Should create Intensional wrapper, got {:?}",
            intensional
        );
    }

    #[test]
    fn intensional_transpiles_with_brackets() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let weak = interner.intern("Weak");
        let clark = interner.intern("Clark");
        let believes = interner.intern("Believes");

        let content = expr_arena.alloc(LogicExpr::Predicate {
            name: weak,
            args: term_arena.alloc_slice([Term::Constant(clark)]),
        });

        let intensional = expr_arena.alloc(LogicExpr::Intensional {
            operator: believes,
            content,
        });

        let mut registry = SymbolRegistry::new();
        let output = intensional.transpile(&mut registry, &interner, OutputFormat::Unicode);

        assert!(
            output.contains("[") && output.contains("]"),
            "Intensional should use brackets: got {}",
            output
        );
    }

    #[test]
    fn substitute_respecting_opacity_blocks_inside_intensional() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let weak = interner.intern("Weak");
        let clark = interner.intern("Clark");
        let believes = interner.intern("Believes");
        let superman = interner.intern("Superman");

        let inner = expr_arena.alloc(LogicExpr::Predicate {
            name: weak,
            args: term_arena.alloc_slice([Term::Constant(clark)]),
        });
        let expr = expr_arena.alloc(LogicExpr::Intensional {
            operator: believes,
            content: inner,
        });

        let replacement = expr_arena.alloc(LogicExpr::Atom(superman));
        let result = substitute_respecting_opacity(expr, clark, replacement, &expr_arena, &term_arena);

        let mut registry = SymbolRegistry::new();
        let output = result.transpile(&mut registry, &interner, OutputFormat::Unicode);

        assert!(
            output.contains("C") && !output.contains("S"),
            "Should NOT substitute inside intensional context: got {}",
            output
        );
    }

    #[test]
    fn substitute_respecting_opacity_allows_outside() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let weak = interner.intern("Weak");
        let clark = interner.intern("Clark");
        let superman = interner.intern("Superman");

        let expr = expr_arena.alloc(LogicExpr::Predicate {
            name: weak,
            args: term_arena.alloc_slice([Term::Constant(clark)]),
        });

        let replacement = expr_arena.alloc(LogicExpr::Atom(superman));
        let result = substitute_respecting_opacity(expr, clark, replacement, &expr_arena, &term_arena);

        let mut registry = SymbolRegistry::new();
        let output = result.transpile(&mut registry, &interner, OutputFormat::Unicode);

        assert!(
            output.contains("S"),
            "Should substitute outside intensional context: got {}",
            output
        );
    }

    #[test]
    fn factorial_basic() {
        assert_eq!(factorial(0), 1);
        assert_eq!(factorial(1), 1);
        assert_eq!(factorial(2), 2);
        assert_eq!(factorial(3), 6);
        assert_eq!(factorial(4), 24);
        assert_eq!(factorial(5), 120);
    }

    #[test]
    fn scope_iterator_two_quantifiers_yields_two() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let y = interner.intern("y");
        let man = interner.intern("Man");
        let woman = interner.intern("Woman");
        let loves = interner.intern("Loves");

        let man_x = expr_arena.alloc(LogicExpr::Predicate {
            name: man,
            args: term_arena.alloc_slice([Term::Variable(x)]),
        });
        let woman_y = expr_arena.alloc(LogicExpr::Predicate {
            name: woman,
            args: term_arena.alloc_slice([Term::Variable(y)]),
        });
        let loves_xy = expr_arena.alloc(LogicExpr::Predicate {
            name: loves,
            args: term_arena.alloc_slice([Term::Variable(x), Term::Variable(y)]),
        });

        let inner = expr_arena.alloc(LogicExpr::BinaryOp {
            left: woman_y,
            op: TokenType::And,
            right: loves_xy,
        });
        let inner_q = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Existential,
            variable: y,
            body: inner,
            island_id: 0,
        });

        let outer = expr_arena.alloc(LogicExpr::BinaryOp {
            left: man_x,
            op: TokenType::If,
            right: inner_q,
        });
        let expr = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Universal,
            variable: x,
            body: outer,
            island_id: 0,
        });

        let scopings: Vec<_> = enumerate_scopings(expr, &mut interner, &expr_arena, &term_arena).collect();
        assert_eq!(scopings.len(), 2, "Two quantifiers should have 2! = 2 readings");
    }

    #[test]
    fn scope_iterator_three_quantifiers_yields_six() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let y = interner.intern("y");
        let z = interner.intern("z");
        let man = interner.intern("Man");
        let woman = interner.intern("Woman");
        let book = interner.intern("Book");
        let gives = interner.intern("Gives");

        let man_x = expr_arena.alloc(LogicExpr::Predicate {
            name: man,
            args: term_arena.alloc_slice([Term::Variable(x)]),
        });
        let woman_y = expr_arena.alloc(LogicExpr::Predicate {
            name: woman,
            args: term_arena.alloc_slice([Term::Variable(y)]),
        });
        let book_z = expr_arena.alloc(LogicExpr::Predicate {
            name: book,
            args: term_arena.alloc_slice([Term::Variable(z)]),
        });
        let gives_xyz = expr_arena.alloc(LogicExpr::Predicate {
            name: gives,
            args: term_arena.alloc_slice([Term::Variable(x), Term::Variable(y), Term::Variable(z)]),
        });

        let inner_z = expr_arena.alloc(LogicExpr::BinaryOp {
            left: book_z,
            op: TokenType::And,
            right: gives_xyz,
        });
        let q_z = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Existential,
            variable: z,
            body: inner_z,
            island_id: 0,
        });

        let inner_y = expr_arena.alloc(LogicExpr::BinaryOp {
            left: woman_y,
            op: TokenType::And,
            right: q_z,
        });
        let q_y = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Existential,
            variable: y,
            body: inner_y,
            island_id: 0,
        });

        let outer = expr_arena.alloc(LogicExpr::BinaryOp {
            left: man_x,
            op: TokenType::If,
            right: q_y,
        });
        let expr = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Universal,
            variable: x,
            body: outer,
            island_id: 0,
        });

        let scopings: Vec<_> = enumerate_scopings(expr, &mut interner, &expr_arena, &term_arena).collect();
        assert_eq!(scopings.len(), 6, "Three quantifiers should have 3! = 6 readings");
    }

    #[test]
    fn scope_iterator_no_duplicates() {
        use std::collections::HashSet;

        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let y = interner.intern("y");
        let man = interner.intern("Man");
        let woman = interner.intern("Woman");
        let loves = interner.intern("Loves");

        let man_x = expr_arena.alloc(LogicExpr::Predicate {
            name: man,
            args: term_arena.alloc_slice([Term::Variable(x)]),
        });
        let woman_y = expr_arena.alloc(LogicExpr::Predicate {
            name: woman,
            args: term_arena.alloc_slice([Term::Variable(y)]),
        });
        let loves_xy = expr_arena.alloc(LogicExpr::Predicate {
            name: loves,
            args: term_arena.alloc_slice([Term::Variable(x), Term::Variable(y)]),
        });

        let inner = expr_arena.alloc(LogicExpr::BinaryOp {
            left: woman_y,
            op: TokenType::And,
            right: loves_xy,
        });
        let inner_q = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Existential,
            variable: y,
            body: inner,
            island_id: 0,
        });

        let outer = expr_arena.alloc(LogicExpr::BinaryOp {
            left: man_x,
            op: TokenType::If,
            right: inner_q,
        });
        let expr = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Universal,
            variable: x,
            body: outer,
            island_id: 0,
        });

        let mut registry = SymbolRegistry::new();
        let outputs: HashSet<String> = enumerate_scopings(expr, &mut interner, &expr_arena, &term_arena)
            .map(|e| e.transpile(&mut registry, &interner, OutputFormat::Unicode))
            .collect();

        assert_eq!(outputs.len(), 2, "All scopings should be unique");
    }

    #[test]
    fn scope_iterator_exact_size() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let y = interner.intern("y");
        let man = interner.intern("Man");
        let woman = interner.intern("Woman");
        let loves = interner.intern("Loves");

        let man_x = expr_arena.alloc(LogicExpr::Predicate {
            name: man,
            args: term_arena.alloc_slice([Term::Variable(x)]),
        });
        let woman_y = expr_arena.alloc(LogicExpr::Predicate {
            name: woman,
            args: term_arena.alloc_slice([Term::Variable(y)]),
        });
        let loves_xy = expr_arena.alloc(LogicExpr::Predicate {
            name: loves,
            args: term_arena.alloc_slice([Term::Variable(x), Term::Variable(y)]),
        });

        let inner = expr_arena.alloc(LogicExpr::BinaryOp {
            left: woman_y,
            op: TokenType::And,
            right: loves_xy,
        });
        let inner_q = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Existential,
            variable: y,
            body: inner,
            island_id: 0,
        });

        let outer = expr_arena.alloc(LogicExpr::BinaryOp {
            left: man_x,
            op: TokenType::If,
            right: inner_q,
        });
        let expr = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Universal,
            variable: x,
            body: outer,
            island_id: 0,
        });

        let mut iter = enumerate_scopings(expr, &mut interner, &expr_arena, &term_arena);
        assert_eq!(iter.len(), 2);
        iter.next();
        assert_eq!(iter.len(), 1);
        iter.next();
        assert_eq!(iter.len(), 0);
    }

    #[test]
    fn island_constraints_reduce_permutations() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let y = interner.intern("y");
        let man = interner.intern("Man");
        let woman = interner.intern("Woman");
        let loves = interner.intern("Loves");

        let man_x = expr_arena.alloc(LogicExpr::Predicate {
            name: man,
            args: term_arena.alloc_slice([Term::Variable(x)]),
        });
        let woman_y = expr_arena.alloc(LogicExpr::Predicate {
            name: woman,
            args: term_arena.alloc_slice([Term::Variable(y)]),
        });
        let loves_xy = expr_arena.alloc(LogicExpr::Predicate {
            name: loves,
            args: term_arena.alloc_slice([Term::Variable(x), Term::Variable(y)]),
        });

        let inner = expr_arena.alloc(LogicExpr::BinaryOp {
            left: woman_y,
            op: TokenType::And,
            right: loves_xy,
        });
        let inner_q = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Existential,
            variable: y,
            body: inner,
            island_id: 1,
        });

        let outer = expr_arena.alloc(LogicExpr::BinaryOp {
            left: man_x,
            op: TokenType::If,
            right: inner_q,
        });
        let expr = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Universal,
            variable: x,
            body: outer,
            island_id: 0,
        });

        let scopings = enumerate_scopings(expr, &mut interner, &expr_arena, &term_arena);
        assert_eq!(
            scopings.len(),
            1,
            "Two quantifiers in different islands: 1! × 1! = 1 reading (no cross-island scoping)"
        );
    }

    #[test]
    fn multiple_quantifiers_per_island() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let y = interner.intern("y");
        let z = interner.intern("z");
        let w = interner.intern("w");
        let pred = interner.intern("P");

        let core = expr_arena.alloc(LogicExpr::Predicate {
            name: pred,
            args: term_arena.alloc_slice([
                Term::Variable(x),
                Term::Variable(y),
                Term::Variable(z),
                Term::Variable(w),
            ]),
        });

        let true_sym = interner.intern("T");
        let t = expr_arena.alloc(LogicExpr::Atom(true_sym));

        let q_w = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Existential,
            variable: w,
            body: expr_arena.alloc(LogicExpr::BinaryOp { left: t, op: TokenType::And, right: core }),
            island_id: 1,
        });
        let q_z = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Existential,
            variable: z,
            body: expr_arena.alloc(LogicExpr::BinaryOp { left: t, op: TokenType::And, right: q_w }),
            island_id: 1,
        });
        let q_y = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Existential,
            variable: y,
            body: expr_arena.alloc(LogicExpr::BinaryOp { left: t, op: TokenType::And, right: q_z }),
            island_id: 0,
        });
        let expr = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Universal,
            variable: x,
            body: expr_arena.alloc(LogicExpr::BinaryOp { left: t, op: TokenType::If, right: q_y }),
            island_id: 0,
        });

        let scopings = enumerate_scopings(expr, &mut interner, &expr_arena, &term_arena);
        assert_eq!(
            scopings.len(),
            4,
            "4 quantifiers split 2+2 across islands: 2! × 2! = 4 (not 4! = 24)"
        );
    }
}

```

---

### Discourse Context

**File:** `src/context.rs`

Entity registration and resolution for anaphora. Tracks gender, number, and case attributes for pronoun binding.

```rust
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum TimeRelation {
    Precedes,
    Equals,
}

#[derive(Debug, Clone)]
pub struct TimeConstraint {
    pub left: String,
    pub relation: TimeRelation,
    pub right: String,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum Gender {
    Male,
    Female,
    Neuter,
    Unknown,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum Number {
    Singular,
    Plural,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum Case {
    Subject,
    Object,
    Possessive,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
pub enum OwnershipState {
    #[default]
    Owned,
    Moved,
    Borrowed,
}

#[derive(Debug, Clone)]
pub struct Entity {
    pub symbol: String,
    pub gender: Gender,
    pub number: Number,
    pub noun_class: String,
    pub ownership: OwnershipState,
}

#[derive(Debug, Clone, Default)]
pub struct DiscourseContext {
    history: Vec<Entity>,
    event_counter: usize,
    event_history: Vec<String>,
    reference_time_counter: usize,
    current_reference_time: Option<String>,
    time_constraints: Vec<TimeConstraint>,
}

impl DiscourseContext {
    pub fn new() -> Self {
        Self {
            history: Vec::new(),
            event_counter: 0,
            event_history: Vec::new(),
            reference_time_counter: 0,
            current_reference_time: None,
            time_constraints: Vec::new(),
        }
    }

    pub fn next_reference_time(&mut self) -> String {
        self.reference_time_counter += 1;
        let var = format!("r{}", self.reference_time_counter);
        self.current_reference_time = Some(var.clone());
        var
    }

    pub fn current_reference_time(&self) -> String {
        self.current_reference_time.clone().unwrap_or_else(|| "S".to_string())
    }

    pub fn add_time_constraint(&mut self, left: String, relation: TimeRelation, right: String) {
        self.time_constraints.push(TimeConstraint { left, relation, right });
    }

    pub fn time_constraints(&self) -> &[TimeConstraint] {
        &self.time_constraints
    }

    pub fn clear_time_constraints(&mut self) {
        self.time_constraints.clear();
        self.reference_time_counter = 0;
        self.current_reference_time = None;
    }

    pub fn next_event_var(&mut self) -> String {
        self.event_counter += 1;
        let var = format!("e{}", self.event_counter);
        self.event_history.push(var.clone());
        var
    }

    pub fn event_history(&self) -> &[String] {
        &self.event_history
    }

    pub fn register(&mut self, entity: Entity) {
        self.history.push(entity);
    }

    pub fn resolve_pronoun(&self, gender: Gender, number: Number) -> Option<&Entity> {
        self.history
            .iter()
            .rev()
            .find(|e| {
                let gender_match = gender == Gender::Unknown
                    || e.gender == Gender::Unknown
                    || e.gender == gender;
                let number_match = e.number == number;
                gender_match && number_match
            })
    }

    pub fn resolve_definite(&self, noun_class: &str) -> Option<&Entity> {
        self.history
            .iter()
            .rev()
            .find(|e| e.noun_class.to_lowercase() == noun_class.to_lowercase())
    }

    pub fn has_entity_by_noun_class(&self, noun_class: &str) -> bool {
        self.history
            .iter()
            .any(|e| e.noun_class.to_lowercase() == noun_class.to_lowercase())
    }

    /// Resolve bridging anaphora by finding entities whose type contains the noun as a part.
    /// Returns all matching entities for ambiguity handling (parse forest).
    pub fn resolve_bridging(&self, noun_class: &str) -> Vec<(&Entity, &'static str)> {
        use crate::ontology::find_bridging_wholes;

        let Some(wholes) = find_bridging_wholes(noun_class) else {
            return Vec::new();
        };

        let mut matches = Vec::new();
        for whole in wholes {
            for entity in self.history.iter().rev() {
                if entity.noun_class.to_lowercase() == whole.to_lowercase() {
                    matches.push((entity, *whole));
                }
            }
        }
        matches
    }

    pub fn set_ownership(&mut self, noun_class: &str, state: OwnershipState) {
        for entity in self.history.iter_mut() {
            if entity.noun_class.to_lowercase() == noun_class.to_lowercase() {
                entity.ownership = state;
                return;
            }
        }
    }

    pub fn get_ownership(&self, noun_class: &str) -> Option<OwnershipState> {
        self.history
            .iter()
            .find(|e| e.noun_class.to_lowercase() == noun_class.to_lowercase())
            .map(|e| e.ownership)
    }

    pub fn clear(&mut self) {
        self.history.clear();
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn register_and_resolve_male() {
        let mut ctx = DiscourseContext::new();
        ctx.register(Entity {
            symbol: "J".into(),
            gender: Gender::Male,
            number: Number::Singular,
            noun_class: "John".into(),
            ownership: OwnershipState::Owned,
        });
        let resolved = ctx.resolve_pronoun(Gender::Male, Number::Singular);
        assert!(resolved.is_some());
        assert_eq!(resolved.unwrap().symbol, "J");
    }

    #[test]
    fn resolve_female_pronoun() {
        let mut ctx = DiscourseContext::new();
        ctx.register(Entity {
            symbol: "M".into(),
            gender: Gender::Female,
            number: Number::Singular,
            noun_class: "Mary".into(),
            ownership: OwnershipState::Owned,
        });
        let resolved = ctx.resolve_pronoun(Gender::Female, Number::Singular);
        assert!(resolved.is_some());
        assert_eq!(resolved.unwrap().symbol, "M");
    }

    #[test]
    fn resolve_most_recent() {
        let mut ctx = DiscourseContext::new();
        ctx.register(Entity {
            symbol: "J".into(),
            gender: Gender::Male,
            number: Number::Singular,
            noun_class: "John".into(),
            ownership: OwnershipState::Owned,
        });
        ctx.register(Entity {
            symbol: "B".into(),
            gender: Gender::Male,
            number: Number::Singular,
            noun_class: "Bob".into(),
            ownership: OwnershipState::Owned,
        });
        let resolved = ctx.resolve_pronoun(Gender::Male, Number::Singular);
        assert_eq!(resolved.unwrap().symbol, "B");
    }

    #[test]
    fn resolve_definite_by_class() {
        let mut ctx = DiscourseContext::new();
        ctx.register(Entity {
            symbol: "D".into(),
            gender: Gender::Neuter,
            number: Number::Singular,
            noun_class: "Dog".into(),
            ownership: OwnershipState::Owned,
        });
        let resolved = ctx.resolve_definite("dog");
        assert!(resolved.is_some());
        assert_eq!(resolved.unwrap().symbol, "D");
    }

    #[test]
    fn gender_filtering() {
        let mut ctx = DiscourseContext::new();
        ctx.register(Entity {
            symbol: "J".into(),
            gender: Gender::Male,
            number: Number::Singular,
            noun_class: "John".into(),
            ownership: OwnershipState::Owned,
        });
        ctx.register(Entity {
            symbol: "M".into(),
            gender: Gender::Female,
            number: Number::Singular,
            noun_class: "Mary".into(),
            ownership: OwnershipState::Owned,
        });
        let he = ctx.resolve_pronoun(Gender::Male, Number::Singular);
        let she = ctx.resolve_pronoun(Gender::Female, Number::Singular);
        assert_eq!(he.unwrap().symbol, "J");
        assert_eq!(she.unwrap().symbol, "M");
    }
}

```

---

### AST Views & Resolution

**File:** `src/view.rs`

ExprView (including Causal variant), TermView, NounPhraseView types for AST traversal. Symbol resolution and display utilities.

```rust
use crate::ast::{
    AspectOperator, LogicExpr, ModalVector, NounPhrase, QuantifierKind, TemporalOperator, VoiceOperator, Term,
    ThematicRole,
};
use crate::intern::Interner;
use crate::lexicon::Definiteness;
use crate::token::{FocusKind, TokenType};

#[derive(Debug, Clone, PartialEq)]
pub enum TermView<'a> {
    Constant(&'a str),
    Variable(&'a str),
    Function(&'a str, Vec<TermView<'a>>),
    Group(Vec<TermView<'a>>),
    Possessed {
        possessor: Box<TermView<'a>>,
        possessed: &'a str,
    },
    Sigma(&'a str),
    Intension(&'a str),
    Proposition(Box<ExprView<'a>>),
    Value {
        kind: NumberKindView<'a>,
        unit: Option<&'a str>,
        dimension: Option<crate::ast::Dimension>,
    },
}

#[derive(Debug, Clone, PartialEq)]
pub enum NumberKindView<'a> {
    Real(f64),
    Integer(i64),
    Symbolic(&'a str),
}

#[derive(Debug, Clone, PartialEq)]
pub struct NounPhraseView<'a> {
    pub definiteness: Option<Definiteness>,
    pub adjectives: Vec<&'a str>,
    pub noun: &'a str,
    pub possessor: Option<Box<NounPhraseView<'a>>>,
    pub pps: Vec<Box<ExprView<'a>>>,
    pub superlative: Option<&'a str>,
}

#[derive(Debug, Clone, PartialEq)]
pub enum ExprView<'a> {
    Predicate {
        name: &'a str,
        args: Vec<TermView<'a>>,
    },
    Identity {
        left: TermView<'a>,
        right: TermView<'a>,
    },
    Metaphor {
        tenor: TermView<'a>,
        vehicle: TermView<'a>,
    },
    Quantifier {
        kind: QuantifierKind,
        variable: &'a str,
        body: Box<ExprView<'a>>,
    },
    Categorical {
        quantifier: TokenType,
        subject: NounPhraseView<'a>,
        copula_negative: bool,
        predicate: NounPhraseView<'a>,
    },
    Relation {
        subject: NounPhraseView<'a>,
        verb: &'a str,
        object: NounPhraseView<'a>,
    },
    Modal {
        vector: ModalVector,
        operand: Box<ExprView<'a>>,
    },
    Temporal {
        operator: TemporalOperator,
        body: Box<ExprView<'a>>,
    },
    Aspectual {
        operator: AspectOperator,
        body: Box<ExprView<'a>>,
    },
    Voice {
        operator: VoiceOperator,
        body: Box<ExprView<'a>>,
    },
    BinaryOp {
        left: Box<ExprView<'a>>,
        op: TokenType,
        right: Box<ExprView<'a>>,
    },
    UnaryOp {
        op: TokenType,
        operand: Box<ExprView<'a>>,
    },
    Question {
        wh_variable: &'a str,
        body: Box<ExprView<'a>>,
    },
    YesNoQuestion {
        body: Box<ExprView<'a>>,
    },
    Atom(&'a str),
    Lambda {
        variable: &'a str,
        body: Box<ExprView<'a>>,
    },
    App {
        function: Box<ExprView<'a>>,
        argument: Box<ExprView<'a>>,
    },
    Intensional {
        operator: &'a str,
        content: Box<ExprView<'a>>,
    },
    Event {
        predicate: Box<ExprView<'a>>,
        adverbs: Vec<&'a str>,
    },
    NeoEvent {
        event_var: &'a str,
        verb: &'a str,
        roles: Vec<(ThematicRole, TermView<'a>)>,
        modifiers: Vec<&'a str>,
    },
    Imperative {
        action: Box<ExprView<'a>>,
    },
    SpeechAct {
        performer: &'a str,
        act_type: &'a str,
        content: Box<ExprView<'a>>,
    },
    Counterfactual {
        antecedent: Box<ExprView<'a>>,
        consequent: Box<ExprView<'a>>,
    },
    Causal {
        effect: Box<ExprView<'a>>,
        cause: Box<ExprView<'a>>,
    },
    Comparative {
        adjective: &'a str,
        subject: TermView<'a>,
        object: TermView<'a>,
        difference: Option<Box<TermView<'a>>>,
    },
    Superlative {
        adjective: &'a str,
        subject: TermView<'a>,
        domain: &'a str,
    },
    Scopal {
        operator: &'a str,
        body: Box<ExprView<'a>>,
    },
    Control {
        verb: &'a str,
        subject: TermView<'a>,
        object: Option<TermView<'a>>,
        infinitive: Box<ExprView<'a>>,
    },
    Presupposition {
        assertion: Box<ExprView<'a>>,
        presupposition: Box<ExprView<'a>>,
    },
    Focus {
        kind: FocusKind,
        focused: TermView<'a>,
        scope: Box<ExprView<'a>>,
    },
    TemporalAnchor {
        anchor: &'a str,
        body: Box<ExprView<'a>>,
    },
    Distributive {
        predicate: Box<ExprView<'a>>,
    },
    GroupQuantifier {
        group_var: &'a str,
        count: u32,
        member_var: &'a str,
        restriction: Box<ExprView<'a>>,
        body: Box<ExprView<'a>>,
    },
}

pub trait Resolve<'a> {
    type Output;
    fn resolve(&self, interner: &'a Interner) -> Self::Output;
}

impl<'a, 'b> Resolve<'a> for Term<'b> {
    type Output = TermView<'a>;

    fn resolve(&self, interner: &'a Interner) -> TermView<'a> {
        match self {
            Term::Constant(s) => TermView::Constant(interner.resolve(*s)),
            Term::Variable(s) => TermView::Variable(interner.resolve(*s)),
            Term::Function(name, args) => TermView::Function(
                interner.resolve(*name),
                args.iter().map(|a| a.resolve(interner)).collect(),
            ),
            Term::Group(members) => {
                TermView::Group(members.iter().map(|m| m.resolve(interner)).collect())
            }
            Term::Possessed {
                possessor,
                possessed,
            } => TermView::Possessed {
                possessor: Box::new(possessor.resolve(interner)),
                possessed: interner.resolve(*possessed),
            },
            Term::Sigma(predicate) => TermView::Sigma(interner.resolve(*predicate)),
            Term::Intension(predicate) => TermView::Intension(interner.resolve(*predicate)),
            Term::Proposition(expr) => {
                TermView::Proposition(Box::new(expr.resolve(interner)))
            }
            Term::Value { kind, unit, dimension } => {
                use crate::ast::NumberKind;
                let kind_view = match kind {
                    NumberKind::Real(r) => NumberKindView::Real(*r),
                    NumberKind::Integer(i) => NumberKindView::Integer(*i),
                    NumberKind::Symbolic(s) => NumberKindView::Symbolic(interner.resolve(*s)),
                };
                TermView::Value {
                    kind: kind_view,
                    unit: unit.map(|u| interner.resolve(u)),
                    dimension: *dimension,
                }
            }
        }
    }
}

impl<'a, 'b> Resolve<'a> for NounPhrase<'b> {
    type Output = NounPhraseView<'a>;

    fn resolve(&self, interner: &'a Interner) -> NounPhraseView<'a> {
        NounPhraseView {
            definiteness: self.definiteness,
            adjectives: self.adjectives.iter().map(|s| interner.resolve(*s)).collect(),
            noun: interner.resolve(self.noun),
            possessor: self.possessor.map(|p| Box::new(p.resolve(interner))),
            pps: self.pps.iter().map(|pp| Box::new(pp.resolve(interner))).collect(),
            superlative: self.superlative.map(|s| interner.resolve(s)),
        }
    }
}

impl<'a, 'b> Resolve<'a> for LogicExpr<'b> {
    type Output = ExprView<'a>;

    fn resolve(&self, interner: &'a Interner) -> ExprView<'a> {
        match self {
            LogicExpr::Predicate { name, args } => ExprView::Predicate {
                name: interner.resolve(*name),
                args: args.iter().map(|a| a.resolve(interner)).collect(),
            },
            LogicExpr::Identity { left, right } => ExprView::Identity {
                left: left.resolve(interner),
                right: right.resolve(interner),
            },
            LogicExpr::Metaphor { tenor, vehicle } => ExprView::Metaphor {
                tenor: tenor.resolve(interner),
                vehicle: vehicle.resolve(interner),
            },
            LogicExpr::Quantifier { kind, variable, body, .. } => ExprView::Quantifier {
                kind: *kind,
                variable: interner.resolve(*variable),
                body: Box::new(body.resolve(interner)),
            },
            LogicExpr::Categorical(data) => ExprView::Categorical {
                quantifier: data.quantifier.clone(),
                subject: data.subject.resolve(interner),
                copula_negative: data.copula_negative,
                predicate: data.predicate.resolve(interner),
            },
            LogicExpr::Relation(data) => ExprView::Relation {
                subject: data.subject.resolve(interner),
                verb: interner.resolve(data.verb),
                object: data.object.resolve(interner),
            },
            LogicExpr::Modal { vector, operand } => ExprView::Modal {
                vector: *vector,
                operand: Box::new(operand.resolve(interner)),
            },
            LogicExpr::Temporal { operator, body } => ExprView::Temporal {
                operator: *operator,
                body: Box::new(body.resolve(interner)),
            },
            LogicExpr::Aspectual { operator, body } => ExprView::Aspectual {
                operator: *operator,
                body: Box::new(body.resolve(interner)),
            },
            LogicExpr::Voice { operator, body } => ExprView::Voice {
                operator: *operator,
                body: Box::new(body.resolve(interner)),
            },
            LogicExpr::BinaryOp { left, op, right } => ExprView::BinaryOp {
                left: Box::new(left.resolve(interner)),
                op: op.clone(),
                right: Box::new(right.resolve(interner)),
            },
            LogicExpr::UnaryOp { op, operand } => ExprView::UnaryOp {
                op: op.clone(),
                operand: Box::new(operand.resolve(interner)),
            },
            LogicExpr::Question { wh_variable, body } => ExprView::Question {
                wh_variable: interner.resolve(*wh_variable),
                body: Box::new(body.resolve(interner)),
            },
            LogicExpr::YesNoQuestion { body } => ExprView::YesNoQuestion {
                body: Box::new(body.resolve(interner)),
            },
            LogicExpr::Atom(s) => ExprView::Atom(interner.resolve(*s)),
            LogicExpr::Lambda { variable, body } => ExprView::Lambda {
                variable: interner.resolve(*variable),
                body: Box::new(body.resolve(interner)),
            },
            LogicExpr::App { function, argument } => ExprView::App {
                function: Box::new(function.resolve(interner)),
                argument: Box::new(argument.resolve(interner)),
            },
            LogicExpr::Intensional { operator, content } => ExprView::Intensional {
                operator: interner.resolve(*operator),
                content: Box::new(content.resolve(interner)),
            },
            LogicExpr::Event { predicate, adverbs } => ExprView::Event {
                predicate: Box::new(predicate.resolve(interner)),
                adverbs: adverbs.iter().map(|s| interner.resolve(*s)).collect(),
            },
            LogicExpr::NeoEvent(data) => ExprView::NeoEvent {
                event_var: interner.resolve(data.event_var),
                verb: interner.resolve(data.verb),
                roles: data.roles.iter().map(|(role, term)| (*role, term.resolve(interner))).collect(),
                modifiers: data.modifiers.iter().map(|s| interner.resolve(*s)).collect(),
            },
            LogicExpr::Imperative { action } => ExprView::Imperative {
                action: Box::new(action.resolve(interner)),
            },
            LogicExpr::SpeechAct {
                performer,
                act_type,
                content,
            } => ExprView::SpeechAct {
                performer: interner.resolve(*performer),
                act_type: interner.resolve(*act_type),
                content: Box::new(content.resolve(interner)),
            },
            LogicExpr::Counterfactual { antecedent, consequent } => ExprView::Counterfactual {
                antecedent: Box::new(antecedent.resolve(interner)),
                consequent: Box::new(consequent.resolve(interner)),
            },
            LogicExpr::Causal { effect, cause } => ExprView::Causal {
                effect: Box::new(effect.resolve(interner)),
                cause: Box::new(cause.resolve(interner)),
            },
            LogicExpr::Comparative { adjective, subject, object, difference } => ExprView::Comparative {
                adjective: interner.resolve(*adjective),
                subject: subject.resolve(interner),
                object: object.resolve(interner),
                difference: difference.map(|d| Box::new(d.resolve(interner))),
            },
            LogicExpr::Superlative { adjective, subject, domain } => ExprView::Superlative {
                adjective: interner.resolve(*adjective),
                subject: subject.resolve(interner),
                domain: interner.resolve(*domain),
            },
            LogicExpr::Scopal { operator, body } => ExprView::Scopal {
                operator: interner.resolve(*operator),
                body: Box::new(body.resolve(interner)),
            },
            LogicExpr::Control {
                verb,
                subject,
                object,
                infinitive,
            } => ExprView::Control {
                verb: interner.resolve(*verb),
                subject: subject.resolve(interner),
                object: object.map(|o| o.resolve(interner)),
                infinitive: Box::new(infinitive.resolve(interner)),
            },
            LogicExpr::Presupposition { assertion, presupposition } => ExprView::Presupposition {
                assertion: Box::new(assertion.resolve(interner)),
                presupposition: Box::new(presupposition.resolve(interner)),
            },
            LogicExpr::Focus { kind, focused, scope } => ExprView::Focus {
                kind: *kind,
                focused: focused.resolve(interner),
                scope: Box::new(scope.resolve(interner)),
            },
            LogicExpr::TemporalAnchor { anchor, body } => ExprView::TemporalAnchor {
                anchor: interner.resolve(*anchor),
                body: Box::new(body.resolve(interner)),
            },
            LogicExpr::Distributive { predicate } => ExprView::Distributive {
                predicate: Box::new(predicate.resolve(interner)),
            },
            LogicExpr::GroupQuantifier { group_var, count, member_var, restriction, body } => ExprView::GroupQuantifier {
                group_var: interner.resolve(*group_var),
                count: *count,
                member_var: interner.resolve(*member_var),
                restriction: Box::new(restriction.resolve(interner)),
                body: Box::new(body.resolve(interner)),
            },
        }
    }
}

#[cfg(test)]
mod term_view_tests {
    use super::*;
    use crate::arena::Arena;

    #[test]
    fn resolve_term_constant() {
        let mut interner = Interner::new();
        let sym = interner.intern("Socrates");
        let term = Term::Constant(sym);
        assert_eq!(term.resolve(&interner), TermView::Constant("Socrates"));
    }

    #[test]
    fn resolve_term_variable() {
        let mut interner = Interner::new();
        let x = interner.intern("x");
        let term = Term::Variable(x);
        assert_eq!(term.resolve(&interner), TermView::Variable("x"));
    }

    #[test]
    fn resolve_term_function() {
        let mut interner = Interner::new();
        let term_arena: Arena<Term> = Arena::new();
        let father = interner.intern("father");
        let john = interner.intern("John");
        let term = Term::Function(father, term_arena.alloc_slice([Term::Constant(john)]));

        assert_eq!(
            term.resolve(&interner),
            TermView::Function("father", vec![TermView::Constant("John")])
        );
    }

    #[test]
    fn resolve_term_group() {
        let mut interner = Interner::new();
        let term_arena: Arena<Term> = Arena::new();
        let j = interner.intern("John");
        let m = interner.intern("Mary");
        let term = Term::Group(term_arena.alloc_slice([Term::Constant(j), Term::Constant(m)]));

        assert_eq!(
            term.resolve(&interner),
            TermView::Group(vec![
                TermView::Constant("John"),
                TermView::Constant("Mary")
            ])
        );
    }

    #[test]
    fn resolve_term_possessed() {
        let mut interner = Interner::new();
        let term_arena: Arena<Term> = Arena::new();
        let john = interner.intern("John");
        let dog = interner.intern("dog");
        let term = Term::Possessed {
            possessor: term_arena.alloc(Term::Constant(john)),
            possessed: dog,
        };

        assert_eq!(
            term.resolve(&interner),
            TermView::Possessed {
                possessor: Box::new(TermView::Constant("John")),
                possessed: "dog",
            }
        );
    }

    #[test]
    fn term_view_equality_is_bit_exact() {
        let a = TermView::Constant("test");
        let b = TermView::Constant("test");
        let c = TermView::Constant("Test");
        assert_eq!(a, b);
        assert_ne!(a, c);
    }

    #[test]
    fn nested_function_resolve() {
        let mut interner = Interner::new();
        let term_arena: Arena<Term> = Arena::new();
        let f = interner.intern("f");
        let g = interner.intern("g");
        let x = interner.intern("x");

        let inner = Term::Function(g, term_arena.alloc_slice([Term::Variable(x)]));
        let outer = Term::Function(f, term_arena.alloc_slice([inner]));

        assert_eq!(
            outer.resolve(&interner),
            TermView::Function(
                "f",
                vec![TermView::Function("g", vec![TermView::Variable("x")])]
            )
        );
    }
}

#[cfg(test)]
mod expr_view_tests {
    use super::*;
    use crate::arena::Arena;
    use crate::ast::ModalDomain;

    #[test]
    fn resolve_expr_predicate() {
        let mut interner = Interner::new();
        let term_arena: Arena<Term> = Arena::new();
        let mortal = interner.intern("Mortal");
        let x = interner.intern("x");
        let expr = LogicExpr::Predicate {
            name: mortal,
            args: term_arena.alloc_slice([Term::Variable(x)]),
        };

        assert_eq!(
            expr.resolve(&interner),
            ExprView::Predicate {
                name: "Mortal",
                args: vec![TermView::Variable("x")],
            }
        );
    }

    #[test]
    fn resolve_expr_identity() {
        let mut interner = Interner::new();
        let term_arena: Arena<Term> = Arena::new();
        let clark = interner.intern("Clark");
        let superman = interner.intern("Superman");
        let expr = LogicExpr::Identity {
            left: term_arena.alloc(Term::Constant(clark)),
            right: term_arena.alloc(Term::Constant(superman)),
        };

        assert_eq!(
            expr.resolve(&interner),
            ExprView::Identity {
                left: TermView::Constant("Clark"),
                right: TermView::Constant("Superman"),
            }
        );
    }

    #[test]
    fn resolve_expr_quantifier() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();
        let x = interner.intern("x");
        let mortal = interner.intern("Mortal");

        let body = expr_arena.alloc(LogicExpr::Predicate {
            name: mortal,
            args: term_arena.alloc_slice([Term::Variable(x)]),
        });
        let expr = LogicExpr::Quantifier {
            kind: QuantifierKind::Universal,
            variable: x,
            body,
            island_id: 0,
        };

        assert_eq!(
            expr.resolve(&interner),
            ExprView::Quantifier {
                kind: QuantifierKind::Universal,
                variable: "x",
                body: Box::new(ExprView::Predicate {
                    name: "Mortal",
                    args: vec![TermView::Variable("x")],
                }),
            }
        );
    }

    #[test]
    fn resolve_expr_atom() {
        let mut interner = Interner::new();
        let p = interner.intern("P");
        let expr = LogicExpr::Atom(p);

        assert_eq!(expr.resolve(&interner), ExprView::Atom("P"));
    }

    #[test]
    fn resolve_expr_binary_op() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let p = interner.intern("P");
        let q = interner.intern("Q");
        let expr = LogicExpr::BinaryOp {
            left: expr_arena.alloc(LogicExpr::Atom(p)),
            op: TokenType::And,
            right: expr_arena.alloc(LogicExpr::Atom(q)),
        };

        assert_eq!(
            expr.resolve(&interner),
            ExprView::BinaryOp {
                left: Box::new(ExprView::Atom("P")),
                op: TokenType::And,
                right: Box::new(ExprView::Atom("Q")),
            }
        );
    }

    #[test]
    fn resolve_expr_lambda() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let x = interner.intern("x");
        let p = interner.intern("P");
        let expr = LogicExpr::Lambda {
            variable: x,
            body: expr_arena.alloc(LogicExpr::Atom(p)),
        };

        assert_eq!(
            expr.resolve(&interner),
            ExprView::Lambda {
                variable: "x",
                body: Box::new(ExprView::Atom("P")),
            }
        );
    }

    #[test]
    fn resolve_expr_temporal() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let run = interner.intern("Run");
        let expr = LogicExpr::Temporal {
            operator: TemporalOperator::Past,
            body: expr_arena.alloc(LogicExpr::Atom(run)),
        };

        assert_eq!(
            expr.resolve(&interner),
            ExprView::Temporal {
                operator: TemporalOperator::Past,
                body: Box::new(ExprView::Atom("Run")),
            }
        );
    }

    #[test]
    fn resolve_expr_modal() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let rain = interner.intern("Rain");
        let expr = LogicExpr::Modal {
            vector: ModalVector {
                domain: ModalDomain::Alethic,
                force: 1.0,
            },
            operand: expr_arena.alloc(LogicExpr::Atom(rain)),
        };

        assert_eq!(
            expr.resolve(&interner),
            ExprView::Modal {
                vector: ModalVector {
                    domain: ModalDomain::Alethic,
                    force: 1.0,
                },
                operand: Box::new(ExprView::Atom("Rain")),
            }
        );
    }

    #[test]
    fn modal_vector_equality_is_bit_exact() {
        let v1 = ModalVector {
            domain: ModalDomain::Alethic,
            force: 0.5,
        };
        let v2 = ModalVector {
            domain: ModalDomain::Alethic,
            force: 0.5,
        };
        let v3 = ModalVector {
            domain: ModalDomain::Alethic,
            force: 0.51,
        };

        assert_eq!(v1, v2);
        assert_ne!(v1, v3);
    }

    #[test]
    fn resolve_expr_unary_op() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let p = interner.intern("P");
        let expr = LogicExpr::UnaryOp {
            op: TokenType::Not,
            operand: expr_arena.alloc(LogicExpr::Atom(p)),
        };

        assert_eq!(
            expr.resolve(&interner),
            ExprView::UnaryOp {
                op: TokenType::Not,
                operand: Box::new(ExprView::Atom("P")),
            }
        );
    }

    #[test]
    fn resolve_expr_app() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let f = interner.intern("f");
        let x = interner.intern("x");
        let expr = LogicExpr::App {
            function: expr_arena.alloc(LogicExpr::Atom(f)),
            argument: expr_arena.alloc(LogicExpr::Atom(x)),
        };

        assert_eq!(
            expr.resolve(&interner),
            ExprView::App {
                function: Box::new(ExprView::Atom("f")),
                argument: Box::new(ExprView::Atom("x")),
            }
        );
    }

    #[test]
    fn expr_view_equality_complex() {
        let a = ExprView::Quantifier {
            kind: QuantifierKind::Universal,
            variable: "x",
            body: Box::new(ExprView::Predicate {
                name: "P",
                args: vec![TermView::Variable("x")],
            }),
        };
        let b = ExprView::Quantifier {
            kind: QuantifierKind::Universal,
            variable: "x",
            body: Box::new(ExprView::Predicate {
                name: "P",
                args: vec![TermView::Variable("x")],
            }),
        };
        assert_eq!(a, b);
    }
}

```

---

### Semantics Module

**File:** `src/semantics/mod.rs`

Entry point for semantic axiom layer. Includes generated axiom_data and exports apply_axioms().

```rust
mod axioms;

pub use axioms::apply_axioms;

include!(concat!(env!("OUT_DIR"), "/axiom_data.rs"));

```

---

### Axiom Expansion

**File:** `src/semantics/axioms.rs`

AST transformation for meaning postulates. Handles noun entailments (bachelor→unmarried), hypernyms (dog→animal), privative adjectives (fake→¬N∧Resembles), and verb entailments (murder→kill).

```rust
use crate::arena::Arena;
use crate::ast::{LogicExpr, NeoEventData, Term, ThematicRole};
use crate::intern::{Interner, Symbol};
use crate::token::TokenType;

use super::{is_privative_adjective, lookup_noun_entailments, lookup_noun_hypernyms, lookup_verb_entailment};

pub fn apply_axioms<'a>(
    expr: &'a LogicExpr<'a>,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
    interner: &mut Interner,
) -> &'a LogicExpr<'a> {
    transform_expr(expr, expr_arena, term_arena, interner)
}

fn transform_expr<'a>(
    expr: &'a LogicExpr<'a>,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
    interner: &mut Interner,
) -> &'a LogicExpr<'a> {
    match expr {
        LogicExpr::Predicate { name, args } => {
            expand_predicate(*name, args, expr_arena, term_arena, interner)
        }

        LogicExpr::Quantifier { kind, variable, body, island_id } => {
            let new_body = transform_expr(body, expr_arena, term_arena, interner);
            expr_arena.alloc(LogicExpr::Quantifier {
                kind: *kind,
                variable: *variable,
                body: new_body,
                island_id: *island_id,
            })
        }

        LogicExpr::BinaryOp { left, op, right } => {
            let new_left = transform_expr(left, expr_arena, term_arena, interner);
            let new_right = transform_expr(right, expr_arena, term_arena, interner);
            expr_arena.alloc(LogicExpr::BinaryOp {
                left: new_left,
                op: op.clone(),
                right: new_right,
            })
        }

        LogicExpr::UnaryOp { op, operand } => {
            let new_operand = transform_expr(operand, expr_arena, term_arena, interner);
            expr_arena.alloc(LogicExpr::UnaryOp {
                op: op.clone(),
                operand: new_operand,
            })
        }

        LogicExpr::NeoEvent(data) => {
            expand_neo_event(data, expr_arena, term_arena, interner)
        }

        LogicExpr::Modal { vector, operand } => {
            let new_operand = transform_expr(operand, expr_arena, term_arena, interner);
            expr_arena.alloc(LogicExpr::Modal {
                vector: *vector,
                operand: new_operand,
            })
        }

        LogicExpr::Temporal { operator, body } => {
            let new_body = transform_expr(body, expr_arena, term_arena, interner);
            expr_arena.alloc(LogicExpr::Temporal {
                operator: *operator,
                body: new_body,
            })
        }

        LogicExpr::Lambda { variable, body } => {
            let new_body = transform_expr(body, expr_arena, term_arena, interner);
            expr_arena.alloc(LogicExpr::Lambda {
                variable: *variable,
                body: new_body,
            })
        }

        LogicExpr::Question { wh_variable, body } => {
            let new_body = transform_expr(body, expr_arena, term_arena, interner);
            expr_arena.alloc(LogicExpr::Question {
                wh_variable: *wh_variable,
                body: new_body,
            })
        }

        LogicExpr::YesNoQuestion { body } => {
            let new_body = transform_expr(body, expr_arena, term_arena, interner);
            expr_arena.alloc(LogicExpr::YesNoQuestion { body: new_body })
        }

        _ => expr,
    }
}

fn expand_predicate<'a>(
    name: Symbol,
    args: &'a [Term<'a>],
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
    interner: &mut Interner,
) -> &'a LogicExpr<'a> {
    let name_str = interner.resolve(name).to_string();
    let lower_name = name_str.to_lowercase();

    // Check for compound predicates (e.g., Fake-Gun from non-intersective adjectives)
    if let Some(hyphen_pos) = name_str.find('-') {
        let adj_part = name_str[..hyphen_pos].to_string();
        let noun_part = name_str[hyphen_pos + 1..].to_string();

        if is_privative_adjective(&adj_part) {
            return expand_privative(&noun_part, args, expr_arena, term_arena, interner);
        }
    }

    // Check for noun entailments (Bachelor -> Unmarried + Male)
    let entailments = lookup_noun_entailments(&lower_name);
    if !entailments.is_empty() {
        return expand_noun_entailments(name, args, entailments, expr_arena, term_arena, interner);
    }

    // Check for hypernyms (Dog -> Animal)
    let hypernyms = lookup_noun_hypernyms(&lower_name);
    if !hypernyms.is_empty() {
        return expand_hypernyms(name, args, hypernyms, expr_arena, term_arena, interner);
    }

    // No expansion needed - return original
    expr_arena.alloc(LogicExpr::Predicate { name, args })
}

fn expand_privative<'a>(
    noun: &str,
    args: &'a [Term<'a>],
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
    interner: &mut Interner,
) -> &'a LogicExpr<'a> {
    // Fake-Gun(x) => ¬Gun(x) ∧ Resembles(x, ^Gun)
    let noun_sym = interner.intern(noun);
    let resembles_sym = interner.intern("Resembles");

    // Gun(x)
    let noun_pred = expr_arena.alloc(LogicExpr::Predicate {
        name: noun_sym,
        args,
    });

    // ¬Gun(x)
    let negated_noun = expr_arena.alloc(LogicExpr::UnaryOp {
        op: TokenType::Not,
        operand: noun_pred,
    });

    // Resembles(x, ^Gun)
    let intension_term = Term::Intension(noun_sym);
    let mut resembles_args_vec = Vec::with_capacity(args.len() + 1);
    if !args.is_empty() {
        resembles_args_vec.push(clone_term(&args[0], term_arena));
    }
    resembles_args_vec.push(intension_term);
    let resembles_args = term_arena.alloc_slice(resembles_args_vec);

    let resembles_pred = expr_arena.alloc(LogicExpr::Predicate {
        name: resembles_sym,
        args: resembles_args,
    });

    // ¬Gun(x) ∧ Resembles(x, ^Gun)
    expr_arena.alloc(LogicExpr::BinaryOp {
        left: negated_noun,
        op: TokenType::And,
        right: resembles_pred,
    })
}

fn expand_noun_entailments<'a>(
    base: Symbol,
    args: &'a [Term<'a>],
    entailments: &[&str],
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
    interner: &mut Interner,
) -> &'a LogicExpr<'a> {
    // Bachelor(x) => Bachelor(x) ∧ Unmarried(x) ∧ Male(x)
    let base_pred = expr_arena.alloc(LogicExpr::Predicate { name: base, args });

    let mut result: &LogicExpr = base_pred;
    for entailment in entailments {
        let ent_sym = interner.intern(entailment);
        let ent_pred = expr_arena.alloc(LogicExpr::Predicate {
            name: ent_sym,
            args,
        });
        result = expr_arena.alloc(LogicExpr::BinaryOp {
            left: result,
            op: TokenType::And,
            right: ent_pred,
        });
    }

    result
}

fn expand_hypernyms<'a>(
    base: Symbol,
    args: &'a [Term<'a>],
    hypernyms: &[&str],
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
    interner: &mut Interner,
) -> &'a LogicExpr<'a> {
    // Dog(x) => Dog(x) ∧ Animal(x)
    let base_pred = expr_arena.alloc(LogicExpr::Predicate { name: base, args });

    let mut result: &LogicExpr = base_pred;
    for hypernym in hypernyms {
        let hyp_sym = interner.intern(hypernym);
        let hyp_pred = expr_arena.alloc(LogicExpr::Predicate {
            name: hyp_sym,
            args,
        });
        result = expr_arena.alloc(LogicExpr::BinaryOp {
            left: result,
            op: TokenType::And,
            right: hyp_pred,
        });
    }

    result
}

fn expand_neo_event<'a>(
    data: &NeoEventData<'a>,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
    interner: &mut Interner,
) -> &'a LogicExpr<'a> {
    let verb_str = interner.resolve(data.verb);

    if let Some((base_verb, manner_preds)) = lookup_verb_entailment(&verb_str.to_lowercase()) {
        // Murder(e) => Murder(e) ∧ Kill(e) ∧ Intentional(Agent)
        let base_verb_sym = interner.intern(base_verb);

        // Keep original NeoEvent
        let original = expr_arena.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
            event_var: data.event_var,
            verb: data.verb,
            roles: data.roles,
            modifiers: data.modifiers,
        })));

        // Create entailed verb NeoEvent (e.g., Kill)
        let entailed_event = expr_arena.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
            event_var: data.event_var,
            verb: base_verb_sym,
            roles: data.roles,
            modifiers: data.modifiers,
        })));

        // Conjoin original with entailed
        let mut result = expr_arena.alloc(LogicExpr::BinaryOp {
            left: original,
            op: TokenType::And,
            right: entailed_event,
        });

        // Add manner predicates (e.g., Intentional(Agent))
        for manner in manner_preds {
            let manner_sym = interner.intern(manner);

            // Find the agent in roles
            let agent_term = data.roles.iter()
                .find(|(role, _)| *role == ThematicRole::Agent)
                .map(|(_, term)| term);

            if let Some(agent) = agent_term {
                let manner_args = term_arena.alloc_slice([clone_term(agent, term_arena)]);
                let manner_pred = expr_arena.alloc(LogicExpr::Predicate {
                    name: manner_sym,
                    args: manner_args,
                });
                result = expr_arena.alloc(LogicExpr::BinaryOp {
                    left: result,
                    op: TokenType::And,
                    right: manner_pred,
                });
            }
        }

        result
    } else {
        // No entailment - return original unchanged
        expr_arena.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
            event_var: data.event_var,
            verb: data.verb,
            roles: data.roles,
            modifiers: data.modifiers,
        })))
    }
}

fn clone_term<'a>(term: &Term<'a>, arena: &'a Arena<Term<'a>>) -> Term<'a> {
    match term {
        Term::Constant(s) => Term::Constant(*s),
        Term::Variable(s) => Term::Variable(*s),
        Term::Function(s, args) => {
            let cloned_args: Vec<Term<'a>> = args.iter().map(|t| clone_term(t, arena)).collect();
            Term::Function(*s, arena.alloc_slice(cloned_args))
        }
        Term::Group(terms) => {
            let cloned: Vec<Term<'a>> = terms.iter().map(|t| clone_term(t, arena)).collect();
            Term::Group(arena.alloc_slice(cloned))
        }
        Term::Possessed { possessor, possessed } => {
            let cloned_possessor = arena.alloc(clone_term(possessor, arena));
            Term::Possessed { possessor: cloned_possessor, possessed: *possessed }
        }
        Term::Sigma(s) => Term::Sigma(*s),
        Term::Intension(s) => Term::Intension(*s),
        Term::Proposition(e) => Term::Proposition(*e),
        Term::Value { kind, unit, dimension } => Term::Value {
            kind: *kind,
            unit: *unit,
            dimension: *dimension,
        },
    }
}

```

---

## Type Analysis

Two-pass compilation infrastructure for type discovery and resolution.

**Location:** `src/analysis/`

### Analysis Module

**File:** `src/analysis/mod.rs`

Entry point for type analysis. Re-exports TypeRegistry and DiscoveryPass for two-pass compilation.

```rust
pub mod registry;
pub mod discovery;

pub use registry::{TypeRegistry, TypeDef};
pub use discovery::DiscoveryPass;

```

---

### Type Registry

**File:** `src/analysis/registry.rs`

TypeRegistry struct for tracking type definitions. TypeDef enum with variants: Generic (type parameters), Struct (record types), Enum (sum types). register_type() adds definitions; resolve_type() looks up by name. Supports the Adjective System where adjectives become type parameters.

```rust
use std::collections::HashMap;
use crate::intern::{Interner, Symbol};

/// Type reference for struct fields (avoids circular deps with ast::TypeExpr)
#[derive(Debug, Clone, PartialEq, Eq)]
pub enum FieldType {
    /// Primitive type name (Int, Nat, Text, Bool, etc.)
    Primitive(Symbol),
    /// User-defined type name
    Named(Symbol),
    /// Generic type with parameters (List of Int, Seq of Text)
    Generic { base: Symbol, params: Vec<FieldType> },
    /// Phase 34: Type parameter reference (T, U, etc.)
    TypeParam(Symbol),
}

/// Field definition within a struct
#[derive(Debug, Clone, PartialEq, Eq)]
pub struct FieldDef {
    pub name: Symbol,
    pub ty: FieldType,
    pub is_public: bool,
}

/// Phase 33: Variant definition for sum types
#[derive(Debug, Clone, PartialEq, Eq)]
pub struct VariantDef {
    pub name: Symbol,
    pub fields: Vec<FieldDef>,  // Empty for unit variants
}

#[derive(Debug, Clone, PartialEq, Eq)]
pub enum TypeDef {
    /// Primitive type (Nat, Int, Text, Bool)
    Primitive,
    /// Struct with named fields and visibility
    /// Phase 34: Now includes optional type parameters
    Struct {
        fields: Vec<FieldDef>,
        generics: Vec<Symbol>,  // [T, U] for "A Pair of [T] and [U] has:"
    },
    /// Phase 33: Enum with variants (unit or with payload)
    /// Phase 34: Now includes optional type parameters
    Enum {
        variants: Vec<VariantDef>,
        generics: Vec<Symbol>,  // [T] for "A Maybe of [T] is either:"
    },
    /// Built-in generic type (List, Option, Result)
    Generic { param_count: usize },
    /// Type alias
    Alias { target: Symbol },
}

#[derive(Debug, Default, Clone)]
pub struct TypeRegistry {
    types: HashMap<Symbol, TypeDef>,
}

impl TypeRegistry {
    pub fn new() -> Self {
        Self::default()
    }

    /// Register a type definition
    pub fn register(&mut self, name: Symbol, def: TypeDef) {
        self.types.insert(name, def);
    }

    /// Check if a symbol is a known type
    pub fn is_type(&self, name: Symbol) -> bool {
        self.types.contains_key(&name)
    }

    /// Check if a symbol is a generic type (takes parameters)
    pub fn is_generic(&self, name: Symbol) -> bool {
        match self.types.get(&name) {
            Some(TypeDef::Generic { .. }) => true,
            Some(TypeDef::Struct { generics, .. }) => !generics.is_empty(),
            Some(TypeDef::Enum { generics, .. }) => !generics.is_empty(),
            _ => false,
        }
    }

    /// Phase 34: Get type parameters for a user-defined generic type
    pub fn get_generics(&self, name: Symbol) -> Option<&[Symbol]> {
        match self.types.get(&name)? {
            TypeDef::Struct { generics, .. } => Some(generics),
            TypeDef::Enum { generics, .. } => Some(generics),
            _ => None,
        }
    }

    /// Get type definition
    pub fn get(&self, name: Symbol) -> Option<&TypeDef> {
        self.types.get(&name)
    }

    /// Iterate over all registered types (for codegen)
    pub fn iter_types(&self) -> impl Iterator<Item = (&Symbol, &TypeDef)> {
        self.types.iter()
    }

    /// Phase 33: Check if a symbol is a known enum variant
    /// Returns Some((enum_name, variant_def)) if found
    pub fn find_variant(&self, variant_name: Symbol) -> Option<(Symbol, &VariantDef)> {
        for (enum_name, type_def) in &self.types {
            if let TypeDef::Enum { variants, .. } = type_def {
                for variant in variants {
                    if variant.name == variant_name {
                        return Some((*enum_name, variant));
                    }
                }
            }
        }
        None
    }

    /// Phase 33: Check if a symbol is an enum variant
    pub fn is_variant(&self, name: Symbol) -> bool {
        self.find_variant(name).is_some()
    }

    /// Pre-register primitives and intrinsic generics
    pub fn with_primitives(interner: &mut Interner) -> Self {
        let mut reg = Self::new();

        // LOGOS Core Primitives
        reg.register(interner.intern("Nat"), TypeDef::Primitive);
        reg.register(interner.intern("Int"), TypeDef::Primitive);
        reg.register(interner.intern("Text"), TypeDef::Primitive);
        reg.register(interner.intern("Bool"), TypeDef::Primitive);
        reg.register(interner.intern("Boolean"), TypeDef::Primitive);
        reg.register(interner.intern("Unit"), TypeDef::Primitive);

        // Intrinsic Generics
        reg.register(interner.intern("List"), TypeDef::Generic { param_count: 1 });
        reg.register(interner.intern("Seq"), TypeDef::Generic { param_count: 1 });  // Phase 30: Sequences
        reg.register(interner.intern("Option"), TypeDef::Generic { param_count: 1 });
        reg.register(interner.intern("Result"), TypeDef::Generic { param_count: 2 });

        reg
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn registry_stores_and_retrieves() {
        let mut interner = Interner::new();
        let mut registry = TypeRegistry::new();
        let foo = interner.intern("Foo");
        registry.register(foo, TypeDef::Primitive);
        assert!(registry.is_type(foo));
        assert!(!registry.is_generic(foo));
    }
}

```

---

### Discovery Pass

**File:** `src/analysis/discovery.rs`

First pass of two-pass compilation. DiscoveryPass scans source for ## Definition blocks to populate TypeRegistry before full parsing. Enables forward references and mutual recursion in type definitions. Extracts type names, parameters, and kind (struct/enum) from definition headers.

```rust
use crate::token::{Token, TokenType, BlockType};
use crate::intern::{Interner, Symbol};
use super::registry::{TypeRegistry, TypeDef, FieldDef, FieldType, VariantDef};

/// Discovery pass that scans tokens before main parsing to build a TypeRegistry.
///
/// This pass looks for type definitions in `## Definition` blocks:
/// - "A Stack is a generic collection." → Generic type
/// - "A User is a structure." → Struct type
/// - "A Shape is an enum." → Enum type
pub struct DiscoveryPass<'a> {
    tokens: &'a [Token],
    pos: usize,
    interner: &'a mut Interner,
}

impl<'a> DiscoveryPass<'a> {
    pub fn new(tokens: &'a [Token], interner: &'a mut Interner) -> Self {
        Self { tokens, pos: 0, interner }
    }

    /// Run discovery pass, returning populated TypeRegistry
    pub fn run(&mut self) -> TypeRegistry {
        let mut registry = TypeRegistry::with_primitives(self.interner);

        while self.pos < self.tokens.len() {
            // Look for Definition blocks
            if self.check_block_header(BlockType::Definition) {
                self.advance(); // consume ## Definition
                self.scan_definition_block(&mut registry);
            } else {
                self.advance();
            }
        }

        registry
    }

    fn check_block_header(&self, expected: BlockType) -> bool {
        matches!(
            self.tokens.get(self.pos),
            Some(Token { kind: TokenType::BlockHeader { block_type }, .. })
            if *block_type == expected
        )
    }

    fn scan_definition_block(&mut self, registry: &mut TypeRegistry) {
        // Scan until next block header or EOF
        while self.pos < self.tokens.len() {
            if matches!(self.peek(), Some(Token { kind: TokenType::BlockHeader { .. }, .. })) {
                break;
            }

            // Look for "A [Name] is a..." pattern
            if self.check_article() {
                self.try_parse_type_definition(registry);
            } else {
                self.advance();
            }
        }
    }

    fn try_parse_type_definition(&mut self, registry: &mut TypeRegistry) {
        self.advance(); // skip article

        if let Some(name_sym) = self.consume_noun_or_proper() {
            // Phase 34: Check for "of [T]" which indicates user-defined generic
            let type_params = if self.check_preposition("of") {
                self.advance(); // consume "of"
                self.parse_type_params()
            } else {
                vec![]
            };

            // Phase 31/34: Check for "has:" which indicates struct with fields
            // Pattern: "A Point has:" or "A Box of [T] has:"
            if self.check_word("has") {
                self.advance(); // consume "has"
                if self.check_colon() {
                    self.advance(); // consume ":"
                    // Skip newline if present
                    if self.check_newline() {
                        self.advance();
                    }
                    if self.check_indent() {
                        self.advance(); // consume INDENT
                        let fields = self.parse_struct_fields_with_params(&type_params);
                        registry.register(name_sym, TypeDef::Struct { fields, generics: type_params });
                        return;
                    }
                }
            }

            // Check for "is either:" pattern (Phase 33/34: Sum types with variants)
            if self.check_copula() {
                self.advance(); // consume is/are

                // Phase 33: Check for "either:" pattern
                if self.check_either() {
                    self.advance(); // consume "either"
                    if self.check_colon() {
                        self.advance(); // consume ":"
                        // Skip newline if present
                        if self.check_newline() {
                            self.advance();
                        }
                        if self.check_indent() {
                            self.advance(); // consume INDENT
                            let variants = self.parse_enum_variants_with_params(&type_params);
                            registry.register(name_sym, TypeDef::Enum { variants, generics: type_params });
                            return;
                        }
                    }
                }

                if self.check_article() {
                    self.advance(); // consume a/an

                    // Look for type indicators
                    if self.check_word("generic") {
                        registry.register(name_sym, TypeDef::Generic { param_count: 1 });
                        self.skip_to_period();
                    } else if self.check_word("record") || self.check_word("struct") || self.check_word("structure") {
                        registry.register(name_sym, TypeDef::Struct { fields: vec![], generics: vec![] });
                        self.skip_to_period();
                    } else if self.check_word("sum") || self.check_word("enum") || self.check_word("choice") {
                        registry.register(name_sym, TypeDef::Enum { variants: vec![], generics: vec![] });
                        self.skip_to_period();
                    }
                }
            } else if !type_params.is_empty() {
                // "A Stack of [Things] is..." - old generic syntax, still supported
                registry.register(name_sym, TypeDef::Generic { param_count: type_params.len() });
                self.skip_to_period();
            }
        }
    }

    /// Phase 33/34: Parse enum variants in "is either:" block
    /// Each variant: "A VariantName." or "A VariantName with a field, which is Type."
    /// or concise: "A VariantName (field: Type)."
    fn parse_enum_variants_with_params(&mut self, type_params: &[Symbol]) -> Vec<VariantDef> {
        let mut variants = Vec::new();

        while self.pos < self.tokens.len() {
            // Exit on dedent or next block
            if self.check_dedent() {
                self.advance();
                break;
            }
            if matches!(self.peek(), Some(Token { kind: TokenType::BlockHeader { .. }, .. })) {
                break;
            }

            // Skip newlines between variants
            if self.check_newline() {
                self.advance();
                continue;
            }

            // Parse variant: "A VariantName [with fields | (field: Type)]."
            if self.check_article() {
                self.advance(); // consume "A"/"An"

                if let Some(variant_name) = self.consume_noun_or_proper() {
                    // Check for payload fields
                    let fields = if self.check_word("with") {
                        // Natural syntax: "A Circle with a radius, which is Int."
                        self.parse_variant_fields_natural_with_params(type_params)
                    } else if self.check_lparen() {
                        // Concise syntax: "A Circle (radius: Int)."
                        self.parse_variant_fields_concise_with_params(type_params)
                    } else {
                        // Unit variant: "A Point."
                        vec![]
                    };

                    variants.push(VariantDef {
                        name: variant_name,
                        fields,
                    });

                    // Consume period
                    if self.check_period() {
                        self.advance();
                    }
                } else {
                    self.advance(); // skip malformed token
                }
            } else {
                self.advance();
            }
        }

        variants
    }

    /// Phase 33: Parse enum variants (backward compat wrapper)
    fn parse_enum_variants(&mut self) -> Vec<VariantDef> {
        self.parse_enum_variants_with_params(&[])
    }

    /// Parse variant fields in natural syntax: "with a radius, which is Int."
    fn parse_variant_fields_natural_with_params(&mut self, type_params: &[Symbol]) -> Vec<FieldDef> {
        let mut fields = Vec::new();

        // "with" has already been detected, consume it
        self.advance();

        loop {
            // Skip article
            if self.check_article() {
                self.advance();
            }

            // Get field name
            if let Some(field_name) = self.consume_noun_or_proper() {
                // Expect ", which is Type" pattern
                let ty = if self.check_comma() {
                    self.advance(); // consume ","
                    // Consume "which"
                    if self.check_word("which") {
                        self.advance();
                    }
                    // Consume "is"
                    if self.check_copula() {
                        self.advance();
                    }
                    self.consume_field_type_with_params(type_params)
                } else {
                    FieldType::Primitive(self.interner.intern("Unknown"))
                };

                fields.push(FieldDef {
                    name: field_name,
                    ty,
                    is_public: true, // Variant fields are always public
                });

                // Check for "and" to continue: ", and a height, which is Int"
                // May have comma before "and"
                if self.check_comma() {
                    self.advance(); // consume comma before "and"
                }
                if self.check_word("and") {
                    self.advance();
                    continue;
                }
            }
            break;
        }

        fields
    }

    /// Backward compat wrapper
    fn parse_variant_fields_natural(&mut self) -> Vec<FieldDef> {
        self.parse_variant_fields_natural_with_params(&[])
    }

    /// Parse variant fields in concise syntax: "(radius: Int)" or "(width: Int, height: Int)"
    fn parse_variant_fields_concise_with_params(&mut self, type_params: &[Symbol]) -> Vec<FieldDef> {
        let mut fields = Vec::new();

        // Consume "("
        self.advance();

        loop {
            // Get field name
            if let Some(field_name) = self.consume_noun_or_proper() {
                // Expect ": Type" pattern
                let ty = if self.check_colon() {
                    self.advance(); // consume ":"
                    self.consume_field_type_with_params(type_params)
                } else {
                    FieldType::Primitive(self.interner.intern("Unknown"))
                };

                fields.push(FieldDef {
                    name: field_name,
                    ty,
                    is_public: true, // Variant fields are always public
                });

                // Check for "," to continue
                if self.check_comma() {
                    self.advance();
                    continue;
                }
            }
            break;
        }

        // Consume ")"
        if self.check_rparen() {
            self.advance();
        }

        fields
    }

    /// Backward compat wrapper
    fn parse_variant_fields_concise(&mut self) -> Vec<FieldDef> {
        self.parse_variant_fields_concise_with_params(&[])
    }

    /// Parse struct fields in "has:" block
    /// Each field: "a [public] name, which is Type."
    fn parse_struct_fields_with_params(&mut self, type_params: &[Symbol]) -> Vec<FieldDef> {
        let mut fields = Vec::new();

        while self.pos < self.tokens.len() {
            // Exit on dedent or next block
            if self.check_dedent() {
                self.advance();
                break;
            }
            if matches!(self.peek(), Some(Token { kind: TokenType::BlockHeader { .. }, .. })) {
                break;
            }

            // Skip newlines between fields
            if self.check_newline() {
                self.advance();
                continue;
            }

            // Parse field: "a [public] name, which is Type."
            if self.check_article() {
                self.advance(); // consume "a"/"an"

                // Check for "public" modifier
                let is_public = if self.check_word("public") {
                    self.advance();
                    true
                } else {
                    false
                };

                // Get field name
                if let Some(field_name) = self.consume_noun_or_proper() {
                    // Expect ", which is Type." pattern
                    let ty = if self.check_comma() {
                        self.advance(); // consume ","
                        // Consume "which"
                        if self.check_word("which") {
                            self.advance();
                        }
                        // Consume "is"
                        if self.check_copula() {
                            self.advance();
                        }
                        self.consume_field_type_with_params(type_params)
                    } else {
                        // Fallback: unknown type
                        FieldType::Primitive(self.interner.intern("Unknown"))
                    };

                    fields.push(FieldDef {
                        name: field_name,
                        ty,
                        is_public,
                    });

                    // Consume period
                    if self.check_period() {
                        self.advance();
                    }
                } else {
                    self.advance(); // skip malformed token
                }
            } else {
                self.advance();
            }
        }

        fields
    }

    /// Backward compat wrapper
    fn parse_struct_fields(&mut self) -> Vec<FieldDef> {
        self.parse_struct_fields_with_params(&[])
    }

    /// Parse a field type reference
    fn consume_field_type(&mut self) -> FieldType {
        if let Some(name) = self.consume_noun_or_proper() {
            // Check for generic: "List of Int", "Seq of Text"
            if self.check_preposition("of") {
                self.advance();
                let param = self.consume_field_type();
                return FieldType::Generic { base: name, params: vec![param] };
            }

            // Check if primitive
            let name_str = self.interner.resolve(name);
            match name_str {
                "Int" | "Nat" | "Text" | "Bool" | "Real" | "Unit" => FieldType::Primitive(name),
                _ => FieldType::Named(name),
            }
        } else {
            FieldType::Primitive(self.interner.intern("Unknown"))
        }
    }

    // Helper methods
    fn peek(&self) -> Option<&Token> {
        self.tokens.get(self.pos)
    }

    fn advance(&mut self) {
        if self.pos < self.tokens.len() {
            self.pos += 1;
        }
    }

    fn check_article(&self) -> bool {
        match self.peek() {
            Some(Token { kind: TokenType::Article(_), .. }) => true,
            // Also accept ProperName("A") / ProperName("An") which can occur at line starts
            Some(Token { kind: TokenType::ProperName(sym), .. }) => {
                let text = self.interner.resolve(*sym);
                text.eq_ignore_ascii_case("a") || text.eq_ignore_ascii_case("an")
            }
            _ => false,
        }
    }

    fn check_copula(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::Is | TokenType::Are, .. }))
    }

    fn check_preposition(&self, word: &str) -> bool {
        if let Some(Token { kind: TokenType::Preposition(sym), .. }) = self.peek() {
            self.interner.resolve(*sym) == word
        } else {
            false
        }
    }

    fn consume_noun_or_proper(&mut self) -> Option<Symbol> {
        let t = self.peek()?;
        match &t.kind {
            TokenType::Noun(s) | TokenType::ProperName(s) => {
                let sym = *s;
                self.advance();
                Some(sym)
            }
            // Phase 31: Also accept Adjective as identifier (for field names like "x")
            TokenType::Adjective(s) => {
                let sym = *s;
                self.advance();
                Some(sym)
            }
            // Phase 34: Accept special tokens as identifiers using their lexeme
            TokenType::Items | TokenType::Some => {
                let sym = t.lexeme;
                self.advance();
                Some(sym)
            }
            _ => None
        }
    }

    fn check_word(&self, word: &str) -> bool {
        if let Some(token) = self.peek() {
            // Check against the lexeme of the token
            self.interner.resolve(token.lexeme).eq_ignore_ascii_case(word)
        } else {
            false
        }
    }

    fn skip_to_period(&mut self) {
        while self.pos < self.tokens.len() {
            if matches!(self.peek(), Some(Token { kind: TokenType::Period, .. })) {
                self.advance();
                break;
            }
            self.advance();
        }
    }

    fn check_colon(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::Colon, .. }))
    }

    fn check_newline(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::Newline, .. }))
    }

    fn check_indent(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::Indent, .. }))
    }

    fn check_dedent(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::Dedent, .. }))
    }

    fn check_comma(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::Comma, .. }))
    }

    fn check_period(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::Period, .. }))
    }

    fn check_either(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::Either, .. }))
    }

    fn check_lparen(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::LParen, .. }))
    }

    fn check_rparen(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::RParen, .. }))
    }

    // Phase 34: Bracket checks for type parameters
    fn check_lbracket(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::LBracket, .. }))
    }

    fn check_rbracket(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::RBracket, .. }))
    }

    /// Phase 34: Parse type parameters in brackets: "[T]" or "[A] and [B]"
    fn parse_type_params(&mut self) -> Vec<Symbol> {
        let mut params = Vec::new();

        loop {
            if self.check_lbracket() {
                self.advance(); // consume [
                if let Some(param) = self.consume_noun_or_proper() {
                    params.push(param);
                }
                if self.check_rbracket() {
                    self.advance(); // consume ]
                }
            }

            // Check for "and" separator for multi-param generics
            if self.check_word("and") {
                self.advance();
                continue;
            }
            break;
        }
        params
    }

    /// Phase 34: Parse a field type reference, recognizing type parameters
    fn consume_field_type_with_params(&mut self, type_params: &[Symbol]) -> FieldType {
        // Phase 34: Single-letter type params like "A" may be tokenized as Article
        // Check for Article that matches a type param first
        if let Some(Token { kind: TokenType::Article(_), lexeme, .. }) = self.peek() {
            let text = self.interner.resolve(*lexeme);
            // Find matching type param by name (case-insensitive for single letters)
            for &param_sym in type_params {
                let param_name = self.interner.resolve(param_sym);
                if text.eq_ignore_ascii_case(param_name) {
                    self.advance(); // consume the article token
                    return FieldType::TypeParam(param_sym);
                }
            }
        }

        if let Some(name) = self.consume_noun_or_proper() {
            // Check if this is a type parameter reference
            if type_params.contains(&name) {
                return FieldType::TypeParam(name);
            }

            // Check for generic: "List of Int", "Seq of Text", "List of T"
            if self.check_preposition("of") {
                self.advance();
                let param = self.consume_field_type_with_params(type_params);
                return FieldType::Generic { base: name, params: vec![param] };
            }

            // Check if primitive
            let name_str = self.interner.resolve(name);
            match name_str {
                "Int" | "Nat" | "Text" | "Bool" | "Real" | "Unit" => FieldType::Primitive(name),
                _ => FieldType::Named(name),
            }
        } else {
            FieldType::Primitive(self.interner.intern("Unknown"))
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::Lexer;
    use crate::mwe;

    fn make_tokens(source: &str, interner: &mut Interner) -> Vec<Token> {
        let mut lexer = Lexer::new(source, interner);
        let tokens = lexer.tokenize();
        let mwe_trie = mwe::build_mwe_trie();
        mwe::apply_mwe_pipeline(tokens, &mwe_trie, interner)
    }

    #[test]
    fn discovery_finds_generic_in_definition_block() {
        let source = "## Definition\nA Stack is a generic collection.";
        let mut interner = Interner::new();
        let tokens = make_tokens(source, &mut interner);

        let mut discovery = DiscoveryPass::new(&tokens, &mut interner);
        let registry = discovery.run();

        let stack = interner.intern("Stack");
        assert!(registry.is_generic(stack), "Stack should be discovered as generic");
    }

    #[test]
    fn discovery_parses_struct_with_fields() {
        let source = r#"## Definition
A Point has:
    an x, which is Int.
    a y, which is Int.
"#;
        let mut interner = Interner::new();
        let tokens = make_tokens(source, &mut interner);

        let mut discovery = DiscoveryPass::new(&tokens, &mut interner);
        let registry = discovery.run();

        let point = interner.intern("Point");
        assert!(registry.is_type(point), "Point should be registered");

        if let Some(TypeDef::Struct { fields, generics }) = registry.get(point) {
            assert_eq!(fields.len(), 2, "Point should have 2 fields, got {:?}", fields);
            assert_eq!(interner.resolve(fields[0].name), "x");
            assert_eq!(interner.resolve(fields[1].name), "y");
            assert!(generics.is_empty(), "Point should have no generics");
        } else {
            panic!("Point should be a struct with fields");
        }
    }
}

```

---

## Code Generation

Rust code emission from imperative AST.

**Location:** `src/codegen.rs`, `src/compile.rs`, `src/scope.rs`

### Rust Code Generation

**File:** `src/codegen.rs`

Converts imperative Stmt AST to valid Rust source code. codegen_program() emits complete program with main(). codegen_stmt() handles each Stmt variant: Let→let binding, Set→assignment, Call→function call, If→if/else, While→while loop, Return→return, Assert→debug_assert!, Give→move semantics, Show→borrow. codegen_expr() handles imperative expressions. Uses String buffer for zero-dependency output.

```rust
use std::fmt::Write;

use crate::analysis::registry::{FieldDef, FieldType, TypeDef, TypeRegistry, VariantDef};
use crate::ast::logic::{LogicExpr, NumberKind, Term};
use crate::ast::stmt::{BinaryOpKind, Expr, Literal, Stmt, TypeExpr};
use crate::intern::{Interner, Symbol};
use crate::token::TokenType;

/// Generate complete Rust program with struct definitions and main function.
///
/// Phase 31: Structs are wrapped in `mod user_types` to enforce visibility.
/// Phase 32: Function definitions are emitted before main.
pub fn codegen_program(stmts: &[Stmt], registry: &TypeRegistry, interner: &Interner) -> String {
    let mut output = String::new();

    // Prelude
    writeln!(output, "use logos_core::prelude::*;\n").unwrap();

    // Collect user-defined structs from registry (Phase 34: now with generics)
    let structs: Vec<_> = registry.iter_types()
        .filter_map(|(name, def)| {
            if let TypeDef::Struct { fields, generics } = def {
                if !fields.is_empty() || !generics.is_empty() {
                    Some((*name, fields.clone(), generics.clone()))
                } else {
                    None
                }
            } else {
                None
            }
        })
        .collect();

    // Phase 33/34: Collect user-defined enums from registry (now with generics)
    let enums: Vec<_> = registry.iter_types()
        .filter_map(|(name, def)| {
            if let TypeDef::Enum { variants, generics } = def {
                if !variants.is_empty() || !generics.is_empty() {
                    Some((*name, variants.clone(), generics.clone()))
                } else {
                    None
                }
            } else {
                None
            }
        })
        .collect();

    // Emit struct and enum definitions in user_types module if any exist
    if !structs.is_empty() || !enums.is_empty() {
        writeln!(output, "pub mod user_types {{").unwrap();
        writeln!(output, "    use super::*;\n").unwrap();

        for (name, fields, generics) in &structs {
            output.push_str(&codegen_struct_def(*name, fields, generics, interner, 4));
        }

        for (name, variants, generics) in &enums {
            output.push_str(&codegen_enum_def(*name, variants, generics, interner, 4));
        }

        writeln!(output, "}}\n").unwrap();
        writeln!(output, "use user_types::*;\n").unwrap();
    }

    // Phase 32: Emit function definitions before main
    for stmt in stmts {
        if let Stmt::FunctionDef { name, params, body, return_type } = stmt {
            output.push_str(&codegen_function_def(*name, params, body, *return_type, interner));
        }
    }

    // Main function
    writeln!(output, "fn main() {{").unwrap();
    for stmt in stmts {
        // Skip function definitions - they're already emitted above
        if matches!(stmt, Stmt::FunctionDef { .. }) {
            continue;
        }
        output.push_str(&codegen_stmt(stmt, interner, 1));
    }
    writeln!(output, "}}").unwrap();
    output
}

/// Phase 32: Generate a function definition.
fn codegen_function_def(
    name: Symbol,
    params: &[(Symbol, Symbol)],
    body: &[Stmt],
    return_type: Option<Symbol>,
    interner: &Interner,
) -> String {
    let mut output = String::new();
    let func_name = interner.resolve(name);

    // Build parameter list
    let params_str: Vec<String> = params.iter()
        .map(|(param_name, param_type)| {
            let name = interner.resolve(*param_name);
            let ty = map_type_to_rust(interner.resolve(*param_type));
            format!("{}: {}", name, ty)
        })
        .collect();

    // Infer return type from body if not specified
    let inferred_return = return_type.map(|s| interner.resolve(s).to_string())
        .or_else(|| infer_return_type_from_body(body, interner));

    // Emit function signature
    if let Some(ret_ty) = inferred_return {
        let rust_ret = map_type_to_rust(&ret_ty);
        if rust_ret != "()" {
            writeln!(output, "fn {}({}) -> {} {{", func_name, params_str.join(", "), rust_ret).unwrap();
        } else {
            writeln!(output, "fn {}({}) {{", func_name, params_str.join(", ")).unwrap();
        }
    } else {
        writeln!(output, "fn {}({}) {{", func_name, params_str.join(", ")).unwrap();
    }

    // Emit body
    for stmt in body {
        output.push_str(&codegen_stmt(stmt, interner, 1));
    }

    writeln!(output, "}}\n").unwrap();
    output
}

/// Infer return type from function body by looking at Return statements.
fn infer_return_type_from_body(body: &[Stmt], _interner: &Interner) -> Option<String> {
    for stmt in body {
        if let Stmt::Return { value: Some(_) } = stmt {
            // For now, assume Int for any expression return
            // TODO: Implement proper type inference
            return Some("Int".to_string());
        }
    }
    None
}

/// Map LOGOS type names to Rust types.
fn map_type_to_rust(ty: &str) -> String {
    match ty {
        "Int" => "i64".to_string(),
        "Nat" => "u64".to_string(),
        "Text" => "String".to_string(),
        "Bool" | "Boolean" => "bool".to_string(),
        "Real" => "f64".to_string(),
        "Unit" | "()" => "()".to_string(),
        other => other.to_string(),
    }
}

/// Generate a single struct definition with derives and visibility.
/// Phase 34: Now supports generic type parameters.
fn codegen_struct_def(name: Symbol, fields: &[FieldDef], generics: &[Symbol], interner: &Interner, indent: usize) -> String {
    let ind = " ".repeat(indent);
    let mut output = String::new();

    // Build generic parameter string: <T, U> or empty
    let generic_str = if generics.is_empty() {
        String::new()
    } else {
        let params: Vec<&str> = generics.iter()
            .map(|g| interner.resolve(*g))
            .collect();
        format!("<{}>", params.join(", "))
    };

    writeln!(output, "{}#[derive(Default, Debug, Clone)]", ind).unwrap();
    writeln!(output, "{}pub struct {}{} {{", ind, interner.resolve(name), generic_str).unwrap();

    for field in fields {
        let vis = if field.is_public { "pub " } else { "" };
        let rust_type = codegen_field_type(&field.ty, interner);
        writeln!(output, "{}    {}{}: {},", ind, vis, interner.resolve(field.name), rust_type).unwrap();
    }

    writeln!(output, "{}}}\n", ind).unwrap();
    output
}

/// Phase 33/34: Generate enum definition with optional generic parameters.
fn codegen_enum_def(name: Symbol, variants: &[VariantDef], generics: &[Symbol], interner: &Interner, indent: usize) -> String {
    let ind = " ".repeat(indent);
    let mut output = String::new();

    // Build generic parameter string: <T, U> or empty
    let generic_str = if generics.is_empty() {
        String::new()
    } else {
        let params: Vec<&str> = generics.iter()
            .map(|g| interner.resolve(*g))
            .collect();
        format!("<{}>", params.join(", "))
    };

    writeln!(output, "{}#[derive(Debug, Clone)]", ind).unwrap();
    writeln!(output, "{}pub enum {}{} {{", ind, interner.resolve(name), generic_str).unwrap();

    for variant in variants {
        let variant_name = interner.resolve(variant.name);
        if variant.fields.is_empty() {
            // Unit variant
            writeln!(output, "{}    {},", ind, variant_name).unwrap();
        } else {
            // Struct variant with named fields
            let fields_str: Vec<String> = variant.fields.iter()
                .map(|f| {
                    let rust_type = codegen_field_type(&f.ty, interner);
                    format!("{}: {}", interner.resolve(f.name), rust_type)
                })
                .collect();
            writeln!(output, "{}    {} {{ {} }},", ind, variant_name, fields_str.join(", ")).unwrap();
        }
    }

    writeln!(output, "{}}}\n", ind).unwrap();
    output
}

/// Convert FieldType to Rust type string.
fn codegen_field_type(ty: &FieldType, interner: &Interner) -> String {
    match ty {
        FieldType::Primitive(sym) => {
            match interner.resolve(*sym) {
                "Int" => "i64".to_string(),
                "Nat" => "u64".to_string(),
                "Text" => "String".to_string(),
                "Bool" | "Boolean" => "bool".to_string(),
                "Real" => "f64".to_string(),
                "Unit" => "()".to_string(),
                other => other.to_string(),
            }
        }
        FieldType::Named(sym) => interner.resolve(*sym).to_string(),
        FieldType::Generic { base, params } => {
            let base_str = match interner.resolve(*base) {
                "List" | "Seq" => "Vec",
                "Option" => "Option",
                "Result" => "Result",
                other => other,
            };
            let param_strs: Vec<String> = params.iter()
                .map(|p| codegen_field_type(p, interner))
                .collect();
            format!("{}<{}>", base_str, param_strs.join(", "))
        }
        // Phase 34: Type parameter reference (T, U, etc.)
        FieldType::TypeParam(sym) => interner.resolve(*sym).to_string(),
    }
}

pub fn codegen_stmt(stmt: &Stmt, interner: &Interner, indent: usize) -> String {
    let indent_str = "    ".repeat(indent);
    let mut output = String::new();

    match stmt {
        Stmt::Let { var, ty, value, mutable } => {
            let var_name = interner.resolve(*var);
            let value_str = codegen_expr(value, interner);
            let type_annotation = ty.map(|t| codegen_type_expr(t, interner));

            match (*mutable, type_annotation) {
                (true, Some(t)) => writeln!(output, "{}let mut {}: {} = {};", indent_str, var_name, t, value_str).unwrap(),
                (true, None) => writeln!(output, "{}let mut {} = {};", indent_str, var_name, value_str).unwrap(),
                (false, Some(t)) => writeln!(output, "{}let {}: {} = {};", indent_str, var_name, t, value_str).unwrap(),
                (false, None) => writeln!(output, "{}let {} = {};", indent_str, var_name, value_str).unwrap(),
            }
        }

        Stmt::Set { target, value } => {
            let target_name = interner.resolve(*target);
            let value_str = codegen_expr(value, interner);
            writeln!(output, "{}{} = {};", indent_str, target_name, value_str).unwrap();
        }

        Stmt::Call { function, args } => {
            let func_name = interner.resolve(*function);
            let args_str: Vec<String> = args.iter().map(|a| codegen_expr(a, interner)).collect();
            writeln!(output, "{}{}({});", indent_str, func_name, args_str.join(", ")).unwrap();
        }

        Stmt::If { cond, then_block, else_block } => {
            let cond_str = codegen_expr(cond, interner);
            writeln!(output, "{}if {} {{", indent_str, cond_str).unwrap();
            for stmt in *then_block {
                output.push_str(&codegen_stmt(stmt, interner, indent + 1));
            }
            if let Some(else_stmts) = else_block {
                writeln!(output, "{}}} else {{", indent_str).unwrap();
                for stmt in *else_stmts {
                    output.push_str(&codegen_stmt(stmt, interner, indent + 1));
                }
            }
            writeln!(output, "{}}}", indent_str).unwrap();
        }

        Stmt::While { cond, body } => {
            let cond_str = codegen_expr(cond, interner);
            writeln!(output, "{}while {} {{", indent_str, cond_str).unwrap();
            for stmt in *body {
                output.push_str(&codegen_stmt(stmt, interner, indent + 1));
            }
            writeln!(output, "{}}}", indent_str).unwrap();
        }

        Stmt::Repeat { var, iterable, body } => {
            let var_name = interner.resolve(*var);
            let iter_str = codegen_expr(iterable, interner);
            writeln!(output, "{}for {} in {} {{", indent_str, var_name, iter_str).unwrap();
            for stmt in *body {
                output.push_str(&codegen_stmt(stmt, interner, indent + 1));
            }
            writeln!(output, "{}}}", indent_str).unwrap();
        }

        Stmt::Return { value } => {
            if let Some(v) = value {
                let value_str = codegen_expr(v, interner);
                writeln!(output, "{}return {};", indent_str, value_str).unwrap();
            } else {
                writeln!(output, "{}return;", indent_str).unwrap();
            }
        }

        Stmt::Assert { proposition } => {
            let condition = codegen_assertion(proposition, interner);
            writeln!(output, "{}debug_assert!({});", indent_str, condition).unwrap();
        }

        // Phase 35: Trust with documented justification
        Stmt::Trust { proposition, justification } => {
            let reason = interner.resolve(*justification);
            // Strip quotes if present (string literals include their quotes)
            let reason_clean = reason.trim_matches('"');
            writeln!(output, "{}// TRUST: {}", indent_str, reason_clean).unwrap();
            let condition = codegen_assertion(proposition, interner);
            writeln!(output, "{}debug_assert!({});", indent_str, condition).unwrap();
        }

        Stmt::Give { object, recipient } => {
            // Move semantics: pass ownership without borrowing
            let obj_str = codegen_expr(object, interner);
            let recv_str = codegen_expr(recipient, interner);
            writeln!(output, "{}{}({});", indent_str, recv_str, obj_str).unwrap();
        }

        Stmt::Show { object, recipient } => {
            // Borrow semantics: pass immutable reference
            let obj_str = codegen_expr(object, interner);
            let recv_str = codegen_expr(recipient, interner);
            writeln!(output, "{}{}(&{});", indent_str, recv_str, obj_str).unwrap();
        }

        Stmt::SetField { object, field, value } => {
            let obj_str = codegen_expr(object, interner);
            let field_name = interner.resolve(*field);
            let value_str = codegen_expr(value, interner);
            writeln!(output, "{}{}.{} = {};", indent_str, obj_str, field_name, value_str).unwrap();
        }

        Stmt::StructDef { .. } => {
            // Struct definitions are handled in codegen_program, not here
        }

        Stmt::FunctionDef { .. } => {
            // Function definitions are handled in codegen_program, not here
        }

        Stmt::Inspect { target, arms, .. } => {
            let target_str = codegen_expr(target, interner);
            writeln!(output, "{}match {} {{", indent_str, target_str).unwrap();

            for arm in arms {
                if let Some(variant) = arm.variant {
                    let variant_name = interner.resolve(variant);
                    // Get the enum name from the arm, or fallback to just variant name
                    let enum_prefix = arm.enum_name
                        .map(|e| format!("{}::", interner.resolve(e)))
                        .unwrap_or_default();

                    if arm.bindings.is_empty() {
                        // Unit variant pattern
                        writeln!(output, "{}    {}{} => {{", indent_str, enum_prefix, variant_name).unwrap();
                    } else {
                        // Pattern with bindings
                        let bindings_str: Vec<String> = arm.bindings.iter()
                            .map(|(field, binding)| {
                                let field_name = interner.resolve(*field);
                                let binding_name = interner.resolve(*binding);
                                if field_name == binding_name {
                                    format!("ref {}", field_name)
                                } else {
                                    format!("{}: ref {}", field_name, binding_name)
                                }
                            })
                            .collect();
                        writeln!(output, "{}    {}{} {{ {} }} => {{", indent_str, enum_prefix, variant_name, bindings_str.join(", ")).unwrap();
                    }
                } else {
                    // Otherwise (wildcard) pattern
                    writeln!(output, "{}    _ => {{", indent_str).unwrap();
                }

                for stmt in arm.body {
                    output.push_str(&codegen_stmt(stmt, interner, indent + 2));
                }
                writeln!(output, "{}    }}", indent_str).unwrap();
            }

            writeln!(output, "{}}}", indent_str).unwrap();
        }
    }

    output
}

pub fn codegen_expr(expr: &Expr, interner: &Interner) -> String {
    match expr {
        Expr::Literal(lit) => codegen_literal(lit, interner),

        Expr::Identifier(sym) => interner.resolve(*sym).to_string(),

        Expr::BinaryOp { op, left, right } => {
            let left_str = codegen_expr(left, interner);
            let right_str = codegen_expr(right, interner);
            let op_str = match op {
                BinaryOpKind::Add => "+",
                BinaryOpKind::Subtract => "-",
                BinaryOpKind::Multiply => "*",
                BinaryOpKind::Divide => "/",
                BinaryOpKind::Eq => "==",
                BinaryOpKind::NotEq => "!=",
                BinaryOpKind::Lt => "<",
                BinaryOpKind::Gt => ">",
                BinaryOpKind::LtEq => "<=",
                BinaryOpKind::GtEq => ">=",
            };
            format!("({} {} {})", left_str, op_str, right_str)
        }

        Expr::Call { function, args } => {
            let func_name = interner.resolve(*function);
            let args_str: Vec<String> = args.iter().map(|a| codegen_expr(a, interner)).collect();
            format!("{}({})", func_name, args_str.join(", "))
        }

        Expr::Index { collection, index } => {
            let coll_str = codegen_expr(collection, interner);
            format!("{}[{}]", coll_str, index - 1)
        }

        Expr::Slice { collection, start, end } => {
            let coll_str = codegen_expr(collection, interner);
            // 1-indexed to 0-indexed: items 2 through 5 → &list[1..5]
            format!("&{}[{}..{}]", coll_str, start - 1, end)
        }

        Expr::List(ref items) => {
            let item_strs: Vec<String> = items.iter()
                .map(|i| codegen_expr(i, interner))
                .collect();
            format!("vec![{}]", item_strs.join(", "))
        }

        Expr::Range { start, end } => {
            let start_str = codegen_expr(start, interner);
            let end_str = codegen_expr(end, interner);
            format!("({}..={})", start_str, end_str)
        }

        Expr::FieldAccess { object, field } => {
            let obj_str = codegen_expr(object, interner);
            let field_name = interner.resolve(*field);
            format!("{}.{}", obj_str, field_name)
        }

        Expr::New { type_name, type_args } => {
            let type_str = interner.resolve(*type_name);
            if type_args.is_empty() {
                format!("{}::default()", type_str)
            } else {
                // Phase 34: Turbofish syntax for generic instantiation
                let args_str = type_args.iter()
                    .map(|s| map_type_to_rust(interner.resolve(*s)))
                    .collect::<Vec<_>>()
                    .join(", ");
                format!("{}::<{}>::default()", type_str, args_str)
            }
        }

        Expr::NewVariant { enum_name, variant, fields } => {
            let enum_str = interner.resolve(*enum_name);
            let variant_str = interner.resolve(*variant);
            if fields.is_empty() {
                // Unit variant: Shape::Point
                format!("{}::{}", enum_str, variant_str)
            } else {
                // Struct variant: Shape::Circle { radius: 10 }
                let fields_str: Vec<String> = fields.iter()
                    .map(|(field_name, value)| {
                        let name = interner.resolve(*field_name);
                        let val = codegen_expr(value, interner);
                        format!("{}: {}", name, val)
                    })
                    .collect();
                format!("{}::{} {{ {} }}", enum_str, variant_str, fields_str.join(", "))
            }
        }
    }
}

fn codegen_literal(lit: &Literal, interner: &Interner) -> String {
    match lit {
        Literal::Number(n) => n.to_string(),
        Literal::Text(sym) => format!("\"{}\"", interner.resolve(*sym)),
        Literal::Boolean(b) => b.to_string(),
        Literal::Nothing => "()".to_string(),
    }
}

fn codegen_type_expr(ty: &TypeExpr, interner: &Interner) -> String {
    match ty {
        TypeExpr::Primitive(sym) => {
            match interner.resolve(*sym) {
                "Int" => "i64".to_string(),
                "Nat" => "u64".to_string(),  // Spec §10.6.1: Nat → u64
                "Text" => "String".to_string(),
                "Bool" | "Boolean" => "bool".to_string(),
                "Unit" => "()".to_string(),
                other => other.to_string(),
            }
        }
        TypeExpr::Named(sym) => interner.resolve(*sym).to_string(),
        TypeExpr::Generic { base, params } => {
            let base_str = match interner.resolve(*base) {
                "List" | "Seq" => "Vec",
                "Option" => "Option",
                "Result" => "Result",
                other => other,
            };
            let param_strs: Vec<String> = params.iter()
                .map(|p| codegen_type_expr(p, interner))
                .collect();
            format!("{}<{}>", base_str, param_strs.join(", "))
        }
        TypeExpr::Function { inputs, output } => {
            let input_strs: Vec<String> = inputs.iter()
                .map(|p| codegen_type_expr(p, interner))
                .collect();
            let output_str = codegen_type_expr(output, interner);
            format!("fn({}) -> {}", input_strs.join(", "), output_str)
        }
    }
}

pub fn codegen_assertion(expr: &LogicExpr, interner: &Interner) -> String {
    match expr {
        LogicExpr::Atom(sym) => interner.resolve(*sym).to_string(),

        LogicExpr::Identity { left, right } => {
            let left_str = codegen_term(left, interner);
            let right_str = codegen_term(right, interner);
            format!("({} == {})", left_str, right_str)
        }

        LogicExpr::Predicate { name, args } => {
            let pred_name = interner.resolve(*name).to_lowercase();
            match pred_name.as_str() {
                "greater" if args.len() == 2 => {
                    let left = codegen_term(&args[0], interner);
                    let right = codegen_term(&args[1], interner);
                    format!("({} > {})", left, right)
                }
                "less" if args.len() == 2 => {
                    let left = codegen_term(&args[0], interner);
                    let right = codegen_term(&args[1], interner);
                    format!("({} < {})", left, right)
                }
                "equal" if args.len() == 2 => {
                    let left = codegen_term(&args[0], interner);
                    let right = codegen_term(&args[1], interner);
                    format!("({} == {})", left, right)
                }
                "greaterequal" | "greaterorequal" if args.len() == 2 => {
                    let left = codegen_term(&args[0], interner);
                    let right = codegen_term(&args[1], interner);
                    format!("({} >= {})", left, right)
                }
                "lessequal" | "lessorequal" if args.len() == 2 => {
                    let left = codegen_term(&args[0], interner);
                    let right = codegen_term(&args[1], interner);
                    format!("({} <= {})", left, right)
                }
                "positive" if args.len() == 1 => {
                    let arg = codegen_term(&args[0], interner);
                    format!("({} > 0)", arg)
                }
                "negative" if args.len() == 1 => {
                    let arg = codegen_term(&args[0], interner);
                    format!("({} < 0)", arg)
                }
                "zero" if args.len() == 1 => {
                    let arg = codegen_term(&args[0], interner);
                    format!("({} == 0)", arg)
                }
                _ => {
                    let args_str: Vec<String> = args.iter()
                        .map(|a| codegen_term(a, interner))
                        .collect();
                    format!("{}({})", interner.resolve(*name), args_str.join(", "))
                }
            }
        }

        LogicExpr::BinaryOp { left, op, right } => {
            let left_str = codegen_assertion(left, interner);
            let right_str = codegen_assertion(right, interner);
            let op_str = match op {
                TokenType::And => "&&",
                TokenType::Or => "||",
                TokenType::Iff => "==",
                _ => "/* unknown op */",
            };
            format!("({} {} {})", left_str, op_str, right_str)
        }

        LogicExpr::UnaryOp { op, operand } => {
            let operand_str = codegen_assertion(operand, interner);
            match op {
                TokenType::Not => format!("(!{})", operand_str),
                _ => format!("/* unknown unary op */({})", operand_str),
            }
        }

        LogicExpr::Comparative { adjective, subject, object, .. } => {
            let adj_name = interner.resolve(*adjective).to_lowercase();
            let subj_str = codegen_term(subject, interner);
            let obj_str = codegen_term(object, interner);
            match adj_name.as_str() {
                "great" | "big" | "large" | "tall" | "old" | "high" => {
                    format!("({} > {})", subj_str, obj_str)
                }
                "small" | "little" | "short" | "young" | "low" => {
                    format!("({} < {})", subj_str, obj_str)
                }
                _ => format!("({} > {})", subj_str, obj_str), // default to greater-than
            }
        }

        _ => "/* unsupported LogicExpr */true".to_string(),
    }
}

pub fn codegen_term(term: &Term, interner: &Interner) -> String {
    match term {
        Term::Constant(sym) => interner.resolve(*sym).to_string(),
        Term::Variable(sym) => interner.resolve(*sym).to_string(),
        Term::Value { kind, .. } => match kind {
            NumberKind::Integer(n) => n.to_string(),
            NumberKind::Real(f) => f.to_string(),
            NumberKind::Symbolic(sym) => interner.resolve(*sym).to_string(),
        },
        Term::Function(name, args) => {
            let args_str: Vec<String> = args.iter()
                .map(|a| codegen_term(a, interner))
                .collect();
            format!("{}({})", interner.resolve(*name), args_str.join(", "))
        }
        Term::Possessed { possessor, possessed } => {
            let poss_str = codegen_term(possessor, interner);
            format!("{}.{}", poss_str, interner.resolve(*possessed))
        }
        Term::Group(members) => {
            let members_str: Vec<String> = members.iter()
                .map(|m| codegen_term(m, interner))
                .collect();
            format!("({})", members_str.join(", "))
        }
        _ => "/* unsupported Term */".to_string(),
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_literal_number() {
        let interner = Interner::new();
        let expr = Expr::Literal(Literal::Number(42));
        assert_eq!(codegen_expr(&expr, &interner), "42");
    }

    #[test]
    fn test_literal_boolean() {
        let interner = Interner::new();
        assert_eq!(codegen_expr(&Expr::Literal(Literal::Boolean(true)), &interner), "true");
        assert_eq!(codegen_expr(&Expr::Literal(Literal::Boolean(false)), &interner), "false");
    }

    #[test]
    fn test_literal_nothing() {
        let interner = Interner::new();
        assert_eq!(codegen_expr(&Expr::Literal(Literal::Nothing), &interner), "()");
    }
}

```

---

### Compilation Orchestration

**File:** `src/compile.rs`

High-level compilation pipeline. compile_to_rust() coordinates lexer→parser→codegen for imperative programs. Manages parser mode switching between declarative and imperative contexts. Handles ## Main and ## Definition block routing.

```rust
//! LOGOS Compilation Pipeline
//!
//! This module provides the end-to-end compilation pipeline:
//! LOGOS source → Rust source → executable

use std::fs;
use std::io::Write;
use std::path::Path;
use std::process::Command;

// Embed runtime at compile time
const LOGOS_CORE_TOML: &str = include_str!("../logos_core/Cargo.toml");
const LOGOS_CORE_LIB: &str = include_str!("../logos_core/src/lib.rs");
const LOGOS_CORE_TYPES: &str = include_str!("../logos_core/src/types.rs");
const LOGOS_CORE_IO: &str = include_str!("../logos_core/src/io.rs");

use crate::analysis::DiscoveryPass;
use crate::arena::Arena;
use crate::arena_ctx::AstContext;
use crate::ast::{Expr, Stmt, TypeExpr};
use crate::codegen::codegen_program;
use crate::context::DiscourseContext;
use crate::error::ParseError;
use crate::intern::Interner;
use crate::lexer::Lexer;
use crate::parser::Parser;

/// Compile LOGOS source to Rust source code.
pub fn compile_to_rust(source: &str) -> Result<String, ParseError> {
    let mut interner = Interner::new();
    let mut lexer = Lexer::new(source, &mut interner);
    let tokens = lexer.tokenize();

    // Pass 1: Discovery - scan for type definitions
    let type_registry = {
        let mut discovery = DiscoveryPass::new(&tokens, &mut interner);
        discovery.run()
    };
    // Clone for codegen (parser takes ownership)
    let codegen_registry = type_registry.clone();

    let mut ctx = DiscourseContext::new();
    let expr_arena = Arena::new();
    let term_arena = Arena::new();
    let np_arena = Arena::new();
    let sym_arena = Arena::new();
    let role_arena = Arena::new();
    let pp_arena = Arena::new();
    let stmt_arena: Arena<Stmt> = Arena::new();
    let imperative_expr_arena: Arena<Expr> = Arena::new();
    let type_expr_arena: Arena<TypeExpr> = Arena::new();

    let ast_ctx = AstContext::with_types(
        &expr_arena,
        &term_arena,
        &np_arena,
        &sym_arena,
        &role_arena,
        &pp_arena,
        &stmt_arena,
        &imperative_expr_arena,
        &type_expr_arena,
    );

    // Pass 2: Parse with type context
    let mut parser = Parser::with_types(tokens, &mut ctx, &mut interner, ast_ctx, type_registry);
    // Note: Don't call process_block_headers() - parse_program handles blocks itself

    let stmts = parser.parse_program()?;
    let rust_code = codegen_program(&stmts, &codegen_registry, &interner);

    Ok(rust_code)
}

/// Compile LOGOS source and write output to a directory.
/// Creates a Cargo project with logos_core dependency.
pub fn compile_to_dir(source: &str, output_dir: &Path) -> Result<(), CompileError> {
    let rust_code = compile_to_rust(source).map_err(CompileError::Parse)?;

    // Create output directory structure
    let src_dir = output_dir.join("src");
    fs::create_dir_all(&src_dir).map_err(|e| CompileError::Io(e.to_string()))?;

    // Write main.rs with logos_core import
    let main_rs = format!(
        "use logos_core::prelude::*;\n\n{}",
        rust_code
    );
    let main_path = src_dir.join("main.rs");
    let mut file = fs::File::create(&main_path).map_err(|e| CompileError::Io(e.to_string()))?;
    file.write_all(main_rs.as_bytes()).map_err(|e| CompileError::Io(e.to_string()))?;

    // Write Cargo.toml
    let cargo_toml = format!(
        r#"[package]
name = "logos_output"
version = "0.1.0"
edition = "2021"

[dependencies]
logos_core = {{ path = "./logos_core" }}
"#
    );
    let cargo_path = output_dir.join("Cargo.toml");
    let mut file = fs::File::create(&cargo_path).map_err(|e| CompileError::Io(e.to_string()))?;
    file.write_all(cargo_toml.as_bytes()).map_err(|e| CompileError::Io(e.to_string()))?;

    // Copy logos_core to output directory
    copy_logos_core(output_dir)?;

    Ok(())
}

/// Copy the embedded logos_core crate to the output directory.
fn copy_logos_core(output_dir: &Path) -> Result<(), CompileError> {
    let core_dir = output_dir.join("logos_core");
    let src_dir = core_dir.join("src");

    fs::create_dir_all(&src_dir).map_err(|e| CompileError::Io(e.to_string()))?;

    fs::write(core_dir.join("Cargo.toml"), LOGOS_CORE_TOML)
        .map_err(|e| CompileError::Io(e.to_string()))?;
    fs::write(src_dir.join("lib.rs"), LOGOS_CORE_LIB)
        .map_err(|e| CompileError::Io(e.to_string()))?;
    fs::write(src_dir.join("types.rs"), LOGOS_CORE_TYPES)
        .map_err(|e| CompileError::Io(e.to_string()))?;
    fs::write(src_dir.join("io.rs"), LOGOS_CORE_IO)
        .map_err(|e| CompileError::Io(e.to_string()))?;

    Ok(())
}

/// Compile and run a LOGOS program.
pub fn compile_and_run(source: &str, output_dir: &Path) -> Result<String, CompileError> {
    compile_to_dir(source, output_dir)?;

    // Run cargo build
    let build_output = Command::new("cargo")
        .arg("build")
        .current_dir(output_dir)
        .output()
        .map_err(|e| CompileError::Io(e.to_string()))?;

    if !build_output.status.success() {
        let stderr = String::from_utf8_lossy(&build_output.stderr);
        return Err(CompileError::Build(stderr.to_string()));
    }

    // Run the compiled program
    let run_output = Command::new("cargo")
        .arg("run")
        .arg("--quiet")
        .current_dir(output_dir)
        .output()
        .map_err(|e| CompileError::Io(e.to_string()))?;

    if !run_output.status.success() {
        let stderr = String::from_utf8_lossy(&run_output.stderr);
        return Err(CompileError::Runtime(stderr.to_string()));
    }

    let stdout = String::from_utf8_lossy(&run_output.stdout);
    Ok(stdout.to_string())
}

/// Compile a LOGOS source file.
pub fn compile_file(path: &Path) -> Result<String, CompileError> {
    let source = fs::read_to_string(path).map_err(|e| CompileError::Io(e.to_string()))?;
    compile_to_rust(&source).map_err(CompileError::Parse)
}

/// Errors that can occur during compilation.
#[derive(Debug)]
pub enum CompileError {
    Parse(ParseError),
    Io(String),
    Build(String),
    Runtime(String),
}

impl std::fmt::Display for CompileError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            CompileError::Parse(e) => write!(f, "Parse error: {:?}", e),
            CompileError::Io(e) => write!(f, "IO error: {}", e),
            CompileError::Build(e) => write!(f, "Build error: {}", e),
            CompileError::Runtime(e) => write!(f, "Runtime error: {}", e),
        }
    }
}

impl std::error::Error for CompileError {}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_compile_let_statement() {
        let source = "## Main\nLet x be 5.";
        let result = compile_to_rust(source);
        assert!(result.is_ok(), "Should compile: {:?}", result);
        let rust = result.unwrap();
        assert!(rust.contains("fn main()"));
        assert!(rust.contains("let x = 5;"));
    }

    #[test]
    fn test_compile_return_statement() {
        let source = "## Main\nReturn 42.";
        let result = compile_to_rust(source);
        assert!(result.is_ok(), "Should compile: {:?}", result);
        let rust = result.unwrap();
        assert!(rust.contains("return 42;"));
    }
}

```

---

### Scope Management

**File:** `src/scope.rs`

Variable scope tracking for imperative blocks. ScopeStack manages nested lexical scopes with push/pop. resolve_identifier() finds variable bindings respecting shadowing. Tracks ownership state (owned/moved/borrowed) for each binding.

```rust
use std::collections::HashMap;
use crate::context::OwnershipState;

#[derive(Debug, Clone)]
pub struct ScopeEntry {
    pub symbol: String,
    pub ownership: OwnershipState,
}

impl ScopeEntry {
    pub fn variable(name: &str) -> Self {
        Self {
            symbol: name.to_string(),
            ownership: OwnershipState::Owned,
        }
    }
}

#[derive(Debug, Default)]
pub struct ScopeStack {
    scopes: Vec<HashMap<String, ScopeEntry>>,
}

impl ScopeStack {
    pub fn new() -> Self {
        Self::default()
    }

    pub fn push_scope(&mut self) {
        self.scopes.push(HashMap::new());
    }

    pub fn pop_scope(&mut self) {
        self.scopes.pop();
    }

    pub fn bind(&mut self, name: &str, entry: ScopeEntry) {
        if let Some(scope) = self.scopes.last_mut() {
            scope.insert(name.to_string(), entry);
        }
    }

    pub fn lookup(&self, name: &str) -> Option<&ScopeEntry> {
        for scope in self.scopes.iter().rev() {
            if let Some(entry) = scope.get(name) {
                return Some(entry);
            }
        }
        None
    }

    pub fn lookup_mut(&mut self, name: &str) -> Option<&mut ScopeEntry> {
        for scope in self.scopes.iter_mut().rev() {
            if let Some(entry) = scope.get_mut(name) {
                return Some(entry);
            }
        }
        None
    }
}

```

---

## Public API

The public interface for embedding LOGICAFFEINE in other applications.

**Location:** `src/lib.rs`

### Library Entry Point

**File:** `src/lib.rs`

Exports compile(), compile_with_options(), compile_ambiguous(), compile_all_scopes(), compile_all_scopes_with_options(), compile_discourse(), compile_discourse_with_options(), and compile_with_context(). **Phase 12 Parse Forest:** compile_forest() and compile_forest_with_options() return Vec<String> of all valid readings for ambiguous sentences. MAX_FOREST_READINGS (12) limits output size. Handles lexical ambiguity (Noun/Verb tokens) via noun_priority_mode forking and structural ambiguity (PP attachment) via pp_attachment_mode. **Ambiguity APIs:** compile_ambiguous() returns Vec<String> for PP-attachment ambiguity; compile_all_scopes() returns all quantifier scope readings PLUS intensional readings (de re/de dicto) by calling enumerate_scopings() for scope permutations then enumerate_intensional_readings() for opaque verb ambiguity. **Discourse API:** compile_discourse() handles multi-sentence input with persistent DiscourseContext. Defines TranspileContext, CompileOptions, and OutputFormat (Unicode/LaTeX).

```rust
/// Maximum number of readings in a parse forest.
/// Prevents exponential blowup from ambiguous sentences.
pub const MAX_FOREST_READINGS: usize = 12;

pub mod arena;
pub mod arena_ctx;
pub mod ast;
pub mod audio;
pub mod codegen;
#[cfg(not(target_arch = "wasm32"))]
pub mod compile;
pub mod content;
pub mod context;
pub mod debug;
pub mod error;
pub mod formatter;
pub mod game;
pub mod generator;
pub mod grader;
pub mod achievements;
pub mod analysis;
pub mod intern;
pub mod lambda;
pub mod lexer;
pub mod lexicon;
pub mod mwe;
pub mod ontology;
pub mod parser;
pub mod pragmatics;
pub mod progress;
pub mod runtime_lexicon;
pub mod semantics;
pub mod registry;
pub mod scope;
#[cfg(target_arch = "wasm32")]
pub mod storage;
pub mod srs;
pub mod style;
pub mod suggest;
pub mod token;
pub mod transpile;
pub mod ui;
pub mod view;
pub mod visitor;

pub mod test_utils;

pub use analysis::{TypeRegistry, TypeDef, DiscoveryPass};
pub use arena::Arena;
pub use arena_ctx::AstContext;
pub use ast::{LogicExpr, NounPhrase, Term, ThematicRole};
pub use context::{DiscourseContext, OwnershipState, TimeConstraint, TimeRelation};
pub use error::{ParseError, ParseErrorKind, socratic_explanation};
pub use debug::{DebugWorld, DisplayWith, WithInterner};
pub use formatter::{LatexFormatter, LogicFormatter, UnicodeFormatter};
pub use intern::{Interner, Symbol, SymbolEq};
pub use lexer::Lexer;
pub use parser::{Parser, ParserMode};
pub use parser::QuantifierParsing;
pub use registry::SymbolRegistry;
pub use scope::{ScopeStack, ScopeEntry};
pub use token::{BlockType, Token, TokenType};
pub use view::{ExprView, NounPhraseView, Resolve, TermView};
pub use visitor::{Visitor, walk_expr, walk_term, walk_np};

// ═══════════════════════════════════════════════════════════════════
// Output Format Configuration
// ═══════════════════════════════════════════════════════════════════

#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
pub enum OutputFormat {
    #[default]
    Unicode,
    LaTeX,
    SimpleFOL,
}

// ═══════════════════════════════════════════════════════════════════
// Transpile Context
// ═══════════════════════════════════════════════════════════════════

pub struct TranspileContext<'a> {
    pub registry: &'a mut SymbolRegistry,
    pub interner: &'a Interner,
}

impl<'a> TranspileContext<'a> {
    pub fn new(registry: &'a mut SymbolRegistry, interner: &'a Interner) -> Self {
        TranspileContext { registry, interner }
    }
}

#[derive(Debug, Clone, Copy)]
pub struct CompileOptions {
    pub format: OutputFormat,
}

impl Default for CompileOptions {
    fn default() -> Self {
        CompileOptions {
            format: OutputFormat::Unicode,
        }
    }
}

// ═══════════════════════════════════════════════════════════════════
// Public API
// ═══════════════════════════════════════════════════════════════════

pub fn compile(input: &str) -> Result<String, ParseError> {
    compile_with_options(input, CompileOptions::default())
}

pub fn compile_simple(input: &str) -> Result<String, ParseError> {
    compile_with_options(input, CompileOptions {
        format: OutputFormat::SimpleFOL,
    })
}

pub fn compile_with_options(input: &str, options: CompileOptions) -> Result<String, ParseError> {
    let mut interner = Interner::new();
    let mut lexer = Lexer::new(input, &mut interner);
    let tokens = lexer.tokenize();

    // Apply MWE collapsing
    let mwe_trie = mwe::build_mwe_trie();
    let tokens = mwe::apply_mwe_pipeline(tokens, &mwe_trie, &mut interner);

    // Pass 1: Discovery - scan for type definitions
    let type_registry = {
        let mut discovery = analysis::DiscoveryPass::new(&tokens, &mut interner);
        discovery.run()
    };

    let expr_arena = Arena::new();
    let term_arena = Arena::new();
    let np_arena = Arena::new();
    let sym_arena = Arena::new();
    let role_arena = Arena::new();
    let pp_arena = Arena::new();

    let ctx = AstContext::new(
        &expr_arena,
        &term_arena,
        &np_arena,
        &sym_arena,
        &role_arena,
        &pp_arena,
    );

    // Pass 2: Parse with type context
    let mut discourse = DiscourseContext::new();
    let mut parser = Parser::with_types(tokens, &mut discourse, &mut interner, ctx, type_registry);
    let ast = parser.parse()?;
    let ast = semantics::apply_axioms(ast, ctx.exprs, ctx.terms, &mut interner);
    let ast = pragmatics::apply_pragmatics(ast, ctx.exprs, &interner);
    let mut registry = SymbolRegistry::new();
    let main_output = ast.transpile(&mut registry, &interner, options.format);

    let constraints = discourse.time_constraints();
    if constraints.is_empty() {
        Ok(main_output)
    } else {
        let constraint_strs: Vec<String> = constraints.iter().map(|c| {
            match c.relation {
                TimeRelation::Precedes => format!("Precedes({}, {})", c.left, c.right),
                TimeRelation::Equals => format!("{}={}", c.left, c.right),
            }
        }).collect();
        Ok(format!("{} ∧ {}", main_output, constraint_strs.join(" ∧ ")))
    }
}

pub fn compile_with_context(input: &str, ctx: &mut DiscourseContext) -> Result<String, ParseError> {
    compile_with_context_options(input, ctx, CompileOptions::default())
}

pub fn compile_with_context_options(
    input: &str,
    ctx: &mut DiscourseContext,
    options: CompileOptions,
) -> Result<String, ParseError> {
    let mut interner = Interner::new();
    let mut lexer = Lexer::new(input, &mut interner);
    let tokens = lexer.tokenize();

    // Apply MWE collapsing
    let mwe_trie = mwe::build_mwe_trie();
    let tokens = mwe::apply_mwe_pipeline(tokens, &mwe_trie, &mut interner);

    // Pass 1: Discovery - scan for type definitions
    let type_registry = {
        let mut discovery = analysis::DiscoveryPass::new(&tokens, &mut interner);
        discovery.run()
    };

    let expr_arena = Arena::new();
    let term_arena = Arena::new();
    let np_arena = Arena::new();
    let sym_arena = Arena::new();
    let role_arena = Arena::new();
    let pp_arena = Arena::new();

    let ast_ctx = AstContext::new(
        &expr_arena,
        &term_arena,
        &np_arena,
        &sym_arena,
        &role_arena,
        &pp_arena,
    );

    // Pass 2: Parse with type context
    let mut parser = Parser::with_types(tokens, ctx, &mut interner, ast_ctx, type_registry);
    let ast = parser.parse()?;
    let mut registry = SymbolRegistry::new();
    Ok(ast.transpile(&mut registry, &interner, options.format))
}

pub fn compile_discourse(sentences: &[&str]) -> Result<String, ParseError> {
    compile_discourse_with_options(sentences, CompileOptions::default())
}

pub fn compile_discourse_with_options(sentences: &[&str], options: CompileOptions) -> Result<String, ParseError> {
    let mut interner = Interner::new();
    let mut ctx = DiscourseContext::new();
    let mut results = Vec::new();
    let mut registry = SymbolRegistry::new();
    let mwe_trie = mwe::build_mwe_trie();

    for sentence in sentences {
        let event_var_name = ctx.next_event_var();
        let event_var_symbol = interner.intern(&event_var_name);

        let mut lexer = Lexer::new(sentence, &mut interner);
        let tokens = lexer.tokenize();

        // Apply MWE collapsing
        let tokens = mwe::apply_mwe_pipeline(tokens, &mwe_trie, &mut interner);

        // Pass 1: Discovery - scan for type definitions
        let type_registry = {
            let mut discovery = analysis::DiscoveryPass::new(&tokens, &mut interner);
            discovery.run()
        };

        let expr_arena = Arena::new();
        let term_arena = Arena::new();
        let np_arena = Arena::new();
        let sym_arena = Arena::new();
        let role_arena = Arena::new();
        let pp_arena = Arena::new();

        let ast_ctx = AstContext::new(
            &expr_arena,
            &term_arena,
            &np_arena,
            &sym_arena,
            &role_arena,
            &pp_arena,
        );

        // Pass 2: Parse with type context
        let mut parser = Parser::with_types(tokens, &mut ctx, &mut interner, ast_ctx, type_registry);
        parser.set_discourse_event_var(event_var_symbol);
        let ast = parser.parse()?;
        results.push(ast.transpile(&mut registry, &interner, options.format));
    }

    let event_history = ctx.event_history();
    let mut precedes = Vec::new();
    for i in 0..event_history.len().saturating_sub(1) {
        precedes.push(format!("Precedes({}, {})", event_history[i], event_history[i + 1]));
    }

    if precedes.is_empty() {
        Ok(results.join(" ∧ "))
    } else {
        Ok(format!("{} ∧ {}", results.join(" ∧ "), precedes.join(" ∧ ")))
    }
}

/// Returns all possible scope readings for a sentence.
/// For sentences with multiple quantifiers, this returns all permutations.
/// Example: "Every woman loves a man" returns both:
///   - Surface: ∀x(Woman(x) → ∃y(Man(y) ∧ Loves(x, y)))
///   - Inverse: ∃y(Man(y) ∧ ∀x(Woman(x) → Loves(x, y)))
pub fn compile_all_scopes(input: &str) -> Result<Vec<String>, ParseError> {
    compile_all_scopes_with_options(input, CompileOptions::default())
}

pub fn compile_all_scopes_with_options(input: &str, options: CompileOptions) -> Result<Vec<String>, ParseError> {
    let mut interner = Interner::new();
    let mut lexer = Lexer::new(input, &mut interner);
    let tokens = lexer.tokenize();

    // Apply MWE collapsing
    let mwe_trie = mwe::build_mwe_trie();
    let tokens = mwe::apply_mwe_pipeline(tokens, &mwe_trie, &mut interner);

    // Pass 1: Discovery - scan for type definitions
    let type_registry = {
        let mut discovery = analysis::DiscoveryPass::new(&tokens, &mut interner);
        discovery.run()
    };

    let expr_arena = Arena::new();
    let term_arena = Arena::new();
    let np_arena = Arena::new();
    let sym_arena = Arena::new();
    let role_arena = Arena::new();
    let pp_arena = Arena::new();

    let ctx = AstContext::new(
        &expr_arena,
        &term_arena,
        &np_arena,
        &sym_arena,
        &role_arena,
        &pp_arena,
    );

    // Pass 2: Parse with type context
    let mut discourse = DiscourseContext::new();
    let mut parser = Parser::with_types(tokens, &mut discourse, &mut interner, ctx, type_registry);
    let ast = parser.parse()?;

    let scope_arena = Arena::new();
    let scope_term_arena = Arena::new();
    let scopings = lambda::enumerate_scopings(ast, &mut interner, &scope_arena, &scope_term_arena);

    let intensional_arena = Arena::new();
    let intensional_term_arena = Arena::new();
    let intensional_role_arena: Arena<(ast::ThematicRole, ast::Term)> = Arena::new();

    let mut results = Vec::new();
    for scoped_expr in scopings {
        let intensional_readings = lambda::enumerate_intensional_readings(
            scoped_expr,
            &mut interner,
            &intensional_arena,
            &intensional_term_arena,
            &intensional_role_arena,
        );
        for reading in intensional_readings {
            let mut registry = SymbolRegistry::new();
            results.push(reading.transpile(&mut registry, &interner, options.format));
        }
    }

    Ok(results)
}

pub fn compile_ambiguous(input: &str) -> Result<Vec<String>, ParseError> {
    compile_ambiguous_with_options(input, CompileOptions::default())
}

pub fn compile_ambiguous_with_options(input: &str, options: CompileOptions) -> Result<Vec<String>, ParseError> {
    let mut interner = Interner::new();
    let mut lexer = Lexer::new(input, &mut interner);
    let tokens = lexer.tokenize();

    // Apply MWE collapsing
    let mwe_trie = mwe::build_mwe_trie();
    let tokens = mwe::apply_mwe_pipeline(tokens, &mwe_trie, &mut interner);

    // Pass 1: Discovery - scan for type definitions
    let type_registry = {
        let mut discovery = analysis::DiscoveryPass::new(&tokens, &mut interner);
        discovery.run()
    };

    let expr_arena = Arena::new();
    let term_arena = Arena::new();
    let np_arena = Arena::new();
    let sym_arena = Arena::new();
    let role_arena = Arena::new();
    let pp_arena = Arena::new();

    let ctx = AstContext::new(
        &expr_arena,
        &term_arena,
        &np_arena,
        &sym_arena,
        &role_arena,
        &pp_arena,
    );

    // Pass 2: Parse with type context
    let mut discourse = DiscourseContext::new();
    let mut parser = Parser::with_types(tokens.clone(), &mut discourse, &mut interner, ctx, type_registry.clone());
    let ast = parser.parse()?;
    let mut registry = SymbolRegistry::new();
    let reading1 = ast.transpile(&mut registry, &interner, options.format);

    let has_pp_ambiguity = tokens.iter().any(|t| {
        if let token::TokenType::Preposition(sym) = &t.kind {
            let prep = interner.resolve(*sym);
            prep == "with" || prep == "by" || prep == "for"
        } else {
            false
        }
    });

    if has_pp_ambiguity {
        let expr_arena2 = Arena::new();
        let term_arena2 = Arena::new();
        let np_arena2 = Arena::new();
        let sym_arena2 = Arena::new();
        let role_arena2 = Arena::new();
        let pp_arena2 = Arena::new();

        let ctx2 = AstContext::new(
            &expr_arena2,
            &term_arena2,
            &np_arena2,
            &sym_arena2,
            &role_arena2,
            &pp_arena2,
        );

        let mut discourse2 = DiscourseContext::new();
        let mut parser2 = Parser::with_types(tokens, &mut discourse2, &mut interner, ctx2, type_registry);
        parser2.set_pp_attachment_mode(true);
        let ast2 = parser2.parse()?;
        let mut registry2 = SymbolRegistry::new();
        let reading2 = ast2.transpile(&mut registry2, &interner, options.format);

        if reading1 != reading2 {
            return Ok(vec![reading1, reading2]);
        }
    }

    Ok(vec![reading1])
}

/// Phase 12: Parse Forest - Returns all valid readings for ambiguous sentences.
/// Handles lexical ambiguity (Noun/Verb) and structural ambiguity (PP attachment).
pub fn compile_forest(input: &str) -> Vec<String> {
    compile_forest_with_options(input, CompileOptions::default())
}

pub fn compile_forest_with_options(input: &str, options: CompileOptions) -> Vec<String> {
    let mut interner = Interner::new();
    let mut lexer = Lexer::new(input, &mut interner);
    let tokens = lexer.tokenize();

    // Apply MWE collapsing
    let mwe_trie = mwe::build_mwe_trie();
    let tokens = mwe::apply_mwe_pipeline(tokens, &mwe_trie, &mut interner);

    // Pass 1: Discovery - scan for type definitions
    let type_registry = {
        let mut discovery = analysis::DiscoveryPass::new(&tokens, &mut interner);
        discovery.run()
    };

    let has_lexical_ambiguity = tokens.iter().any(|t| {
        matches!(t.kind, token::TokenType::Ambiguous { .. })
    });

    let has_pp_ambiguity = tokens.iter().any(|t| {
        if let token::TokenType::Preposition(sym) = &t.kind {
            let prep = interner.resolve(*sym);
            prep == "with" || prep == "by" || prep == "for"
        } else {
            false
        }
    });

    // Phase 18: Detect plurality ambiguity (mixed verb + plural subject)
    let has_mixed_verb = tokens.iter().any(|t| {
        if let token::TokenType::Verb { lemma, .. } = &t.kind {
            Lexer::is_mixed_verb(interner.resolve(*lemma))
        } else {
            false
        }
    });

    // Phase 19: Detect collective verbs (always require group reading with cardinals)
    let has_collective_verb = tokens.iter().any(|t| {
        if let token::TokenType::Verb { lemma, .. } = &t.kind {
            Lexer::is_collective_verb(interner.resolve(*lemma))
        } else {
            false
        }
    });

    let has_plural_subject = tokens.iter().any(|t| {
        matches!(t.kind, token::TokenType::Cardinal(_))
            || matches!(&t.kind, token::TokenType::Article(def) if matches!(def, lexicon::Definiteness::Definite))
    });

    let has_plurality_ambiguity = (has_mixed_verb || has_collective_verb) && has_plural_subject;

    let mut results: Vec<String> = Vec::new();

    // Reading 1: Default mode (verb priority for Ambiguous tokens)
    {
        let expr_arena = Arena::new();
        let term_arena = Arena::new();
        let np_arena = Arena::new();
        let sym_arena = Arena::new();
        let role_arena = Arena::new();
        let pp_arena = Arena::new();

        let ast_ctx = AstContext::new(
            &expr_arena,
            &term_arena,
            &np_arena,
            &sym_arena,
            &role_arena,
            &pp_arena,
        );

        // Pass 2: Parse with type context
        let mut discourse_ctx = context::DiscourseContext::new();
        let mut parser = Parser::with_types(tokens.clone(), &mut discourse_ctx, &mut interner, ast_ctx, type_registry.clone());
        parser.set_noun_priority_mode(false);

        if let Ok(ast) = parser.parse() {
            let mut registry = SymbolRegistry::new();
            results.push(ast.transpile(&mut registry, &interner, options.format));
        }
    }

    // Reading 2: Noun priority mode (for lexical ambiguity)
    if has_lexical_ambiguity {
        let expr_arena = Arena::new();
        let term_arena = Arena::new();
        let np_arena = Arena::new();
        let sym_arena = Arena::new();
        let role_arena = Arena::new();
        let pp_arena = Arena::new();

        let ast_ctx = AstContext::new(
            &expr_arena,
            &term_arena,
            &np_arena,
            &sym_arena,
            &role_arena,
            &pp_arena,
        );

        let mut discourse_ctx = context::DiscourseContext::new();
        let mut parser = Parser::with_types(tokens.clone(), &mut discourse_ctx, &mut interner, ast_ctx, type_registry.clone());
        parser.set_noun_priority_mode(true);

        if let Ok(ast) = parser.parse() {
            let mut registry = SymbolRegistry::new();
            let reading = ast.transpile(&mut registry, &interner, options.format);
            if !results.contains(&reading) {
                results.push(reading);
            }
        }
    }

    // Reading 3: PP attachment mode (for structural ambiguity)
    if has_pp_ambiguity {
        let expr_arena = Arena::new();
        let term_arena = Arena::new();
        let np_arena = Arena::new();
        let sym_arena = Arena::new();
        let role_arena = Arena::new();
        let pp_arena = Arena::new();

        let ast_ctx = AstContext::new(
            &expr_arena,
            &term_arena,
            &np_arena,
            &sym_arena,
            &role_arena,
            &pp_arena,
        );

        let mut discourse_ctx = context::DiscourseContext::new();
        let mut parser = Parser::with_types(tokens.clone(), &mut discourse_ctx, &mut interner, ast_ctx, type_registry.clone());
        parser.set_pp_attachment_mode(true);

        if let Ok(ast) = parser.parse() {
            let mut registry = SymbolRegistry::new();
            let reading = ast.transpile(&mut registry, &interner, options.format);
            if !results.contains(&reading) {
                results.push(reading);
            }
        }
    }

    // Reading 4: Collective mode (for plurality ambiguity with mixed verbs)
    if has_plurality_ambiguity {
        let expr_arena = Arena::new();
        let term_arena = Arena::new();
        let np_arena = Arena::new();
        let sym_arena = Arena::new();
        let role_arena = Arena::new();
        let pp_arena = Arena::new();

        let ast_ctx = AstContext::new(
            &expr_arena,
            &term_arena,
            &np_arena,
            &sym_arena,
            &role_arena,
            &pp_arena,
        );

        let mut discourse_ctx = context::DiscourseContext::new();
        let mut parser = Parser::with_types(tokens.clone(), &mut discourse_ctx, &mut interner, ast_ctx, type_registry);
        parser.set_collective_mode(true);

        if let Ok(ast) = parser.parse() {
            // Transform cardinal quantifiers to group quantifiers for collective reading
            if let Ok(transformed) = parser.transform_cardinal_to_group(ast) {
                let mut registry = SymbolRegistry::new();
                let reading = transformed.transpile(&mut registry, &interner, options.format);
                if !results.contains(&reading) {
                    results.push(reading);
                }
            }
        }
    }

    // Enforce MAX_FOREST_READINGS limit
    results.truncate(MAX_FOREST_READINGS);

    results
}

// ═══════════════════════════════════════════════════════════════════
// UI API - For Live Transpilation & Visualization
// ═══════════════════════════════════════════════════════════════════

use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub enum TokenCategory {
    Quantifier,
    Noun,
    Verb,
    Adjective,
    Connective,
    Determiner,
    Preposition,
    Pronoun,
    Modal,
    Punctuation,
    Proper,
    Other,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TokenInfo {
    pub start: usize,
    pub end: usize,
    pub text: String,
    pub category: TokenCategory,
}

fn categorize_token(kind: &TokenType, _interner: &Interner) -> TokenCategory {
    match kind {
        TokenType::All | TokenType::Some | TokenType::No | TokenType::Any
        | TokenType::Most | TokenType::Few | TokenType::Many
        | TokenType::Cardinal(_) | TokenType::AtLeast(_) | TokenType::AtMost(_) => TokenCategory::Quantifier,
        TokenType::Noun(_) => TokenCategory::Noun,
        TokenType::Verb { .. } => TokenCategory::Verb,
        TokenType::Adjective(_) | TokenType::NonIntersectiveAdjective(_) => TokenCategory::Adjective,
        TokenType::And | TokenType::Or | TokenType::Not | TokenType::If | TokenType::Then
        | TokenType::Iff | TokenType::Because => TokenCategory::Connective,
        TokenType::Article(_) => TokenCategory::Determiner,
        TokenType::Preposition(_) => TokenCategory::Preposition,
        TokenType::Pronoun { .. } => TokenCategory::Pronoun,
        TokenType::Must | TokenType::Can | TokenType::Should | TokenType::Shall
        | TokenType::Would | TokenType::Could | TokenType::May | TokenType::Cannot => TokenCategory::Modal,
        TokenType::Period | TokenType::Comma => TokenCategory::Punctuation,
        TokenType::ProperName(_) => TokenCategory::Proper,
        _ => TokenCategory::Other,
    }
}

pub fn tokenize_for_ui(input: &str) -> Vec<TokenInfo> {
    let mut interner = Interner::new();
    let mut lexer = Lexer::new(input, &mut interner);
    let tokens = lexer.tokenize();

    tokens.iter().map(|t| TokenInfo {
        start: t.span.start,
        end: t.span.end,
        text: input[t.span.start..t.span.end].to_string(),
        category: categorize_token(&t.kind, &interner),
    }).collect()
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct AstNode {
    pub label: String,
    pub node_type: String,
    pub children: Vec<AstNode>,
}

impl AstNode {
    pub fn leaf(label: &str, node_type: &str) -> Self {
        AstNode {
            label: label.to_string(),
            node_type: node_type.to_string(),
            children: Vec::new(),
        }
    }

    pub fn with_children(label: &str, node_type: &str, children: Vec<AstNode>) -> Self {
        AstNode {
            label: label.to_string(),
            node_type: node_type.to_string(),
            children,
        }
    }
}

pub fn expr_to_ast_node(expr: &LogicExpr, interner: &Interner) -> AstNode {
    match expr {
        LogicExpr::Predicate { name, args } => {
            let name_str = interner.resolve(*name);
            let arg_nodes: Vec<AstNode> = args.iter()
                .map(|t| term_to_ast_node(t, interner))
                .collect();
            AstNode::with_children(
                &format!("{}({})", name_str, args.len()),
                "predicate",
                arg_nodes,
            )
        }
        LogicExpr::Quantifier { kind, variable, body, .. } => {
            let var_str = interner.resolve(*variable);
            let symbol = match kind {
                ast::QuantifierKind::Universal => "∀",
                ast::QuantifierKind::Existential => "∃",
                ast::QuantifierKind::Most => "MOST",
                ast::QuantifierKind::Few => "FEW",
                ast::QuantifierKind::Many => "MANY",
                ast::QuantifierKind::Cardinal(n) => return AstNode::with_children(
                    &format!("∃={}{}", n, var_str),
                    "quantifier",
                    vec![expr_to_ast_node(body, interner)],
                ),
                ast::QuantifierKind::AtLeast(n) => return AstNode::with_children(
                    &format!("∃≥{}{}", n, var_str),
                    "quantifier",
                    vec![expr_to_ast_node(body, interner)],
                ),
                ast::QuantifierKind::AtMost(n) => return AstNode::with_children(
                    &format!("∃≤{}{}", n, var_str),
                    "quantifier",
                    vec![expr_to_ast_node(body, interner)],
                ),
                ast::QuantifierKind::Generic => "GEN",
            };
            AstNode::with_children(
                &format!("{}{}", symbol, var_str),
                "quantifier",
                vec![expr_to_ast_node(body, interner)],
            )
        }
        LogicExpr::BinaryOp { left, op, right } => {
            let op_str = match op {
                TokenType::And => "∧",
                TokenType::Or => "∨",
                TokenType::If | TokenType::Then => "→",
                TokenType::Iff => "↔",
                _ => "?",
            };
            AstNode::with_children(
                op_str,
                "binary_op",
                vec![
                    expr_to_ast_node(left, interner),
                    expr_to_ast_node(right, interner),
                ],
            )
        }
        LogicExpr::UnaryOp { op, operand } => {
            let op_str = match op {
                TokenType::Not => "¬",
                _ => "?",
            };
            AstNode::with_children(
                op_str,
                "unary_op",
                vec![expr_to_ast_node(operand, interner)],
            )
        }
        LogicExpr::Identity { left, right } => {
            AstNode::with_children(
                "=",
                "identity",
                vec![
                    term_to_ast_node(left, interner),
                    term_to_ast_node(right, interner),
                ],
            )
        }
        LogicExpr::Modal { vector, operand } => {
            AstNode::with_children(
                &format!("□{:?}", vector.domain),
                "modal",
                vec![expr_to_ast_node(operand, interner)],
            )
        }
        LogicExpr::Lambda { variable, body } => {
            let var_str = interner.resolve(*variable);
            AstNode::with_children(
                &format!("λ{}", var_str),
                "lambda",
                vec![expr_to_ast_node(body, interner)],
            )
        }
        _ => AstNode::leaf(&format!("{:?}", expr), "other"),
    }
}

fn term_to_ast_node(term: &Term, interner: &Interner) -> AstNode {
    match term {
        Term::Constant(sym) => AstNode::leaf(interner.resolve(*sym), "constant"),
        Term::Variable(sym) => AstNode::leaf(interner.resolve(*sym), "variable"),
        Term::Function(name, args) => {
            let name_str = interner.resolve(*name);
            let arg_nodes: Vec<AstNode> = args.iter()
                .map(|t| term_to_ast_node(t, interner))
                .collect();
            AstNode::with_children(&format!("{}()", name_str), "function", arg_nodes)
        }
        Term::Group(terms) => {
            let term_nodes: Vec<AstNode> = terms.iter()
                .map(|t| term_to_ast_node(t, interner))
                .collect();
            AstNode::with_children("⊕", "group", term_nodes)
        }
        _ => AstNode::leaf(&format!("{:?}", term), "term"),
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CompileResult {
    pub logic: Option<String>,
    pub ast: Option<AstNode>,
    pub readings: Vec<String>,
    pub tokens: Vec<TokenInfo>,
    pub error: Option<String>,
}

pub fn compile_for_ui(input: &str) -> CompileResult {
    let tokens = tokenize_for_ui(input);
    let readings = compile_forest(input);

    let mut interner = Interner::new();
    let mut lexer = Lexer::new(input, &mut interner);
    let lex_tokens = lexer.tokenize();

    let mwe_trie = mwe::build_mwe_trie();
    let lex_tokens = mwe::apply_mwe_pipeline(lex_tokens, &mwe_trie, &mut interner);

    // Pass 1: Discovery - scan for type definitions
    let type_registry = {
        let mut discovery = analysis::DiscoveryPass::new(&lex_tokens, &mut interner);
        discovery.run()
    };

    let expr_arena = Arena::new();
    let term_arena = Arena::new();
    let np_arena = Arena::new();
    let sym_arena = Arena::new();
    let role_arena = Arena::new();
    let pp_arena = Arena::new();

    let ctx = AstContext::new(
        &expr_arena,
        &term_arena,
        &np_arena,
        &sym_arena,
        &role_arena,
        &pp_arena,
    );

    // Pass 2: Parse with type context
    let mut discourse = DiscourseContext::new();
    let mut parser = Parser::with_types(lex_tokens, &mut discourse, &mut interner, ctx, type_registry);

    match parser.parse() {
        Ok(ast) => {
            let ast_node = expr_to_ast_node(ast, &interner);
            let mut registry = SymbolRegistry::new();
            let logic = ast.transpile(&mut registry, &interner, OutputFormat::Unicode);

            CompileResult {
                logic: Some(logic),
                ast: Some(ast_node),
                readings,
                tokens,
                error: None,
            }
        }
        Err(e) => {
            let advice = socratic_explanation(&e, &interner);
            CompileResult {
                logic: None,
                ast: None,
                readings: Vec::new(),
                tokens,
                error: Some(advice),
            }
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    // ═══════════════════════════════════════════════════════════════════
    // Phase 0: Output Format Configuration (FOL Upgrade)
    // ═══════════════════════════════════════════════════════════════════

    #[test]
    fn compile_with_unicode_default() {
        let result = compile("All men are mortal.").unwrap();
        assert!(
            result.contains("∀") || result.contains("→"),
            "Unicode format should use ∀ or →: got '{}'",
            result
        );
    }

    #[test]
    fn compile_with_latex_option() {
        let options = CompileOptions {
            format: OutputFormat::LaTeX,
        };
        let result = compile_with_options("All men are mortal.", options).unwrap();
        assert!(
            result.contains("\\forall") && result.contains("\\supset"),
            "LaTeX format should use \\forall and \\supset: got '{}'",
            result
        );
    }

    #[test]
    fn latex_uses_latex_operators() {
        let options = CompileOptions {
            format: OutputFormat::LaTeX,
        };
        let result = compile_with_options("If it is raining, then it is pouring.", options).unwrap();
        assert!(
            result.contains("\\supset"),
            "LaTeX format should use \\supset: got '{}'",
            result
        );
    }

    // ═══════════════════════════════════════════════════════════════════
    // Phase 2: AST Structure Tests (FOL Upgrade)
    // ═══════════════════════════════════════════════════════════════════

    #[test]
    fn term_constant_creation() {
        use crate::ast::Term;
        let mut interner = Interner::new();
        let sym = interner.intern("Socrates");
        let term = Term::Constant(sym);
        assert!(matches!(term, Term::Constant(_)));
    }

    #[test]
    fn term_variable_creation() {
        use crate::ast::Term;
        let mut interner = Interner::new();
        let x = interner.intern("x");
        let term = Term::Variable(x);
        assert!(matches!(term, Term::Variable(_)));
    }

    #[test]
    fn predicate_unary() {
        use crate::ast::{LogicExpr, Term};
        let mut interner = Interner::new();
        let term_arena: Arena<Term> = Arena::new();
        let mortal = interner.intern("Mortal");
        let x = interner.intern("x");
        let expr = LogicExpr::Predicate {
            name: mortal,
            args: term_arena.alloc_slice([Term::Variable(x)]),
        };
        assert!(matches!(expr, LogicExpr::Predicate { .. }));
    }

    #[test]
    fn predicate_binary() {
        use crate::ast::{LogicExpr, Term};
        let mut interner = Interner::new();
        let term_arena: Arena<Term> = Arena::new();
        let loves = interner.intern("Loves");
        let john = interner.intern("John");
        let mary = interner.intern("Mary");
        let expr = LogicExpr::Predicate {
            name: loves,
            args: term_arena.alloc_slice([
                Term::Constant(john),
                Term::Constant(mary),
            ]),
        };
        if let LogicExpr::Predicate { args, .. } = expr {
            assert_eq!(args.len(), 2);
        }
    }

    #[test]
    fn identity_expression() {
        use crate::ast::{LogicExpr, Term};
        let mut interner = Interner::new();
        let term_arena: Arena<Term> = Arena::new();
        let clark = interner.intern("Clark");
        let superman = interner.intern("Superman");
        let expr = LogicExpr::Identity {
            left: term_arena.alloc(Term::Constant(clark)),
            right: term_arena.alloc(Term::Constant(superman)),
        };
        assert!(matches!(expr, LogicExpr::Identity { .. }));
    }

    #[test]
    fn quantifier_universal() {
        use crate::ast::{LogicExpr, QuantifierKind, Term};
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();
        let x = interner.intern("x");
        let mortal = interner.intern("Mortal");
        let body = expr_arena.alloc(LogicExpr::Predicate {
            name: mortal,
            args: term_arena.alloc_slice([Term::Variable(x)]),
        });
        let expr = LogicExpr::Quantifier {
            kind: QuantifierKind::Universal,
            variable: x,
            body,
            island_id: 0,
        };
        assert!(matches!(
            expr,
            LogicExpr::Quantifier {
                kind: QuantifierKind::Universal,
                ..
            }
        ));
    }

    // ═══════════════════════════════════════════════════════════════════
    // Phase 3: Parser Desugaring Tests (FOL Upgrade)
    // ═══════════════════════════════════════════════════════════════════

    #[test]
    fn all_produces_universal_quantifier() {
        let result = compile("All men are mortal.").unwrap();
        assert!(
            result.contains("∀") && result.contains("→"),
            "All should produce ∀x(S(x) → P(x)): got '{}'",
            result
        );
    }

    #[test]
    fn some_produces_existential_quantifier() {
        let result = compile("Some cats are black.").unwrap();
        assert!(
            result.contains("∃") && result.contains("∧"),
            "Some should produce ∃x(S(x) ∧ P(x)): got '{}'",
            result
        );
    }

    #[test]
    fn no_produces_universal_negation() {
        let result = compile("No dogs are cats.").unwrap();
        assert!(
            result.contains("∀") && result.contains("¬"),
            "No should produce ∀x(S(x) → ¬P(x)): got '{}'",
            result
        );
    }

    #[test]
    fn multiple_quantifiers_have_unique_variables() {
        // Compound sentence with two quantified clauses
        let result = compile("All men are mortal and some cats are black.").unwrap();
        assert!(
            result.contains("x") && result.contains("y"),
            "Multiple quantifiers should have unique variables: got '{}'",
            result
        );
    }

    // ═══════════════════════════════════════════════════════════════════
    // Phase 4: N-Ary Relations & Prepositions (FOL Upgrade)
    // ═══════════════════════════════════════════════════════════════════

    #[test]
    fn ternary_relation_with_to() {
        // Debug: check tokens
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("John gave the book to Mary.", &mut interner);
        let tokens = lexer.tokenize();
        eprintln!("Tokens: {:?}", tokens);

        let result = compile("John gave the book to Mary.").unwrap();
        eprintln!("Result: {}", result);

        // Should have 3 arguments (2 commas)
        let comma_count = result.matches(',').count();
        assert!(
            comma_count >= 2,
            "Ternary relation should have 3 args (2+ commas): got '{}'",
            result
        );
    }

    #[test]
    fn binary_relation_basic() {
        let result = compile("John loves Mary.").unwrap();
        assert!(
            (result.contains("Agent(e, J)") && result.contains("Theme(e, M)"))
                || result.contains("(J, M)"),
            "Binary relation should have Agent and Theme roles: got '{}'",
            result
        );
    }

    // ═══════════════════════════════════════════════════════════════════
    // Legacy Tests (will be updated as we progress)
    // ═══════════════════════════════════════════════════════════════════

    #[test]
    fn dogs_and_dangerous_get_different_symbols() {
        let output = compile("All dogs are dangerous.").unwrap();
        assert_ne!(output, "All D is D", "dogs and dangerous should have different symbols");
    }

    #[test]
    fn men_and_mortal_get_different_symbols() {
        let output = compile("All men are mortal.").unwrap();
        assert_ne!(output, "All M is M", "men and mortal should have different symbols");
    }

    #[test]
    fn same_word_gets_same_symbol() {
        let output = compile("All cats are cats.").unwrap();
        // FOL output: ∀x((C(x) → C(x))) - same symbol C for same word
        let c_count = output.matches("C(").count();
        assert!(
            c_count >= 2,
            "same word should get same symbol (C appears twice): got '{}'",
            output
        );
    }

    #[test]
    fn compile_conditional() {
        let output = compile("If it is raining, then it is pouring.").unwrap();
        assert!(
            output.contains("→") || output.contains("\\supset"),
            "conditional should produce implication: got '{}'",
            output
        );
    }

    #[test]
    fn parse_adjective_noun_subject() {
        let output = compile("All old men are mortal.").unwrap();
        assert!(
            !output.contains("All O is"),
            "should not treat 'old' as the subject"
        );
    }

    #[test]
    fn parse_multiple_adjectives() {
        let output = compile("All old tired men are happy.").unwrap();
        assert!(
            !output.contains("All O is"),
            "should not treat first adjective as subject"
        );
    }

    // ═══════════════════════════════════════════════════════════════════
    // Phase 4: Transitive Verbs (Relations)
    // ═══════════════════════════════════════════════════════════════════

    #[test]
    fn parse_transitive_verb() {
        let output = compile("John loves Mary.").unwrap();
        assert!(
            (output.contains("Agent(e, J)") && output.contains("Theme(e, M)"))
                || output.contains("(J, M)"),
            "transitive verb should produce Agent/Theme roles or binary predicate: got '{}'",
            output
        );
    }

    #[test]
    fn parse_transitive_verb_symbols_unique() {
        let output = compile("John sees Jane.").unwrap();
        assert!(
            output.contains("J2") || output.contains("(J, J2)"),
            "John and Jane should get unique symbols: got '{}'",
            output
        );
    }

    // ═══════════════════════════════════════════════════════════════════
    // Phase 5: Modal Vector Theory
    // ═══════════════════════════════════════════════════════════════════

    #[test]
    fn parse_modal_must_alethic() {
        let output = compile("All cats must sleep.").unwrap();
        assert!(
            output.contains("□_{1.0}") || output.contains("\\Box_{1.0}"),
            "must should produce alethic necessity: got '{}'",
            output
        );
    }

    #[test]
    fn parse_modal_should_deontic() {
        let output = compile("All students should study.").unwrap();
        assert!(
            output.contains("O_{0.6}"),
            "should produces deontic obligation: got '{}'",
            output
        );
    }

    #[test]
    fn parse_modal_can_possibility() {
        let output = compile("Some birds can fly.").unwrap();
        assert!(
            output.contains("◇") || output.contains("\\Diamond"),
            "can should produce possibility: got '{}'",
            output
        );
    }

    #[test]
    fn parse_modal_cannot_impossibility() {
        let output = compile("All code cannot run.").unwrap();
        assert!(
            output.contains("□_{0.0}") || output.contains("\\Box_{0.0}"),
            "cannot should produce impossibility: got '{}'",
            output
        );
    }

    #[test]
    fn parse_compound_modal_sentence() {
        let output = compile("The user should compile and the code cannot run.").unwrap();
        assert!(
            output.contains("O_{0.6}") && (output.contains("□_{0.0}") || output.contains("\\Box_{0.0}")),
            "compound modal should have both operators: got '{}'",
            output
        );
    }

    // ═══════════════════════════════════════════════════════════════════
    // Phase 1: Identity & Biconditional (TDD RED)
    // ═══════════════════════════════════════════════════════════════════

    #[test]
    fn identity_clark_is_superman() {
        let result = compile("Clark is equal to Superman.").unwrap();
        assert!(
            result.contains("="),
            "Identity should produce =: got '{}'",
            result
        );
    }

    #[test]
    fn identity_same_constant() {
        let result = compile("Socrates is identical to Socrates.").unwrap();
        assert!(
            result.contains("S = S"),
            "Same constant should appear twice: got '{}'",
            result
        );
    }

    #[test]
    fn iff_produces_biconditional() {
        let result = compile("A if and only if B.").unwrap();
        assert!(
            result.contains("↔"),
            "Iff should produce ↔: got '{}'",
            result
        );
    }

    #[test]
    fn iff_latex_uses_equiv() {
        let options = CompileOptions {
            format: OutputFormat::LaTeX,
        };
        let result = compile_with_options("A if and only if B.", options).unwrap();
        assert!(
            result.contains("\\equiv"),
            "LaTeX Iff should use \\equiv: got '{}'",
            result
        );
    }

    // ═══════════════════════════════════════════════════════════════════
    // Phase 2: Reflexive Binding (TDD RED)
    // ═══════════════════════════════════════════════════════════════════

    #[test]
    fn reflexive_binds_to_subject() {
        let result = compile("John loves himself.").unwrap();
        assert!(
            (result.contains("Agent(e, J)") && result.contains("Theme(e, J)"))
                || result.contains("(J, J)"),
            "Reflexive should bind Agent and Theme to same entity: got '{}'",
            result
        );
    }

    #[test]
    fn reflexive_with_herself() {
        let result = compile("Mary sees herself.").unwrap();
        assert!(
            (result.contains("Agent(e, M)") && result.contains("Theme(e, M)"))
                || result.contains("(M, M)"),
            "Reflexive herself should bind: got '{}'",
            result
        );
    }

    #[test]
    fn reflexive_in_prepositional_phrase() {
        let result = compile("John gave the book to himself.").unwrap();
        assert!(
            result.contains("Agent(e, J)") && result.contains("Theme(e, B)")
                || result.contains("(J, B, J)"),
            "Reflexive in preposition should bind to subject: got '{}'",
            result
        );
    }

    #[test]
    fn relative_clause_with_preposition() {
        let result = compile("All dogs that ran to the house are tired.").unwrap();
        assert!(
            result.contains("R(x, H)"),
            "Relative clause should support prepositions: got '{}'",
            result
        );
    }

    #[test]
    fn relative_clause_with_reflexive_preposition() {
        let result = compile("All men that speak to themselves are wise.").unwrap();
        assert!(
            result.contains("S(x, x)"),
            "Relative clause reflexive should bind to variable: got '{}'",
            result
        );
    }

    // ═══════════════════════════════════════════════════════════════════
    // Phase 3: Relative Clauses & Adjective Predicates (TDD RED)
    // ═══════════════════════════════════════════════════════════════════

    #[test]
    fn adjectives_as_separate_predicates() {
        let result = compile("All happy dogs are friendly.").unwrap();
        // Subject should be: Happy(x) ∧ Dog(x) → Friendly(x)
        // Check that adjective creates separate predicate in conjunction
        assert!(
            result.contains("H(x)") && result.contains("∧") && result.contains("D(x)"),
            "Adjectives should create separate predicates: got '{}'",
            result
        );
    }

    #[test]
    fn relative_clause_basic() {
        let result = compile("All dogs that bark are loud.").unwrap();
        // Subject should be: Dog(x) ∧ Bark(x) → Loud(x)
        assert!(
            result.contains("D(x)") && result.contains("∧") && result.contains("B(x)"),
            "Relative clause should create conjunction: got '{}'",
            result
        );
    }

    #[test]
    fn relative_clause_with_object() {
        let result = compile("All cats that chase mice are hunters.").unwrap();
        // Subject should be: Cat(x) ∧ Chase(x, M) → Hunter(x)
        assert!(
            result.contains("∧") && (result.contains("(x, M)") || result.contains("(x,M)")),
            "Relative clause should include predicate with object: got '{}'",
            result
        );
    }

    // ═══════════════════════════════════════════════════════════════════
    // Phase 1: Discourse Context & Pronoun Resolution (TDD RED)
    // ═══════════════════════════════════════════════════════════════════

    #[test]
    fn discourse_basic_pronoun_he() {
        use crate::context::DiscourseContext;
        let mut ctx = DiscourseContext::new();
        let _r1 = compile_with_context("John ran.", &mut ctx).unwrap();
        let r2 = compile_with_context("He stopped.", &mut ctx).unwrap();
        assert!(
            r2.contains("J"),
            "He should resolve to John (J): got '{}'",
            r2
        );
    }

    #[test]
    fn discourse_basic_pronoun_she() {
        use crate::context::DiscourseContext;
        let mut ctx = DiscourseContext::new();
        let _r1 = compile_with_context("Mary ran.", &mut ctx).unwrap();
        let r2 = compile_with_context("She stopped.", &mut ctx).unwrap();
        assert!(
            r2.contains("M"),
            "She should resolve to Mary (M): got '{}'",
            r2
        );
    }

    #[test]
    fn discourse_multiple_entities() {
        use crate::context::DiscourseContext;
        let mut ctx = DiscourseContext::new();
        compile_with_context("John saw Mary.", &mut ctx).unwrap();
        let result = compile_with_context("He loves her.", &mut ctx).unwrap();
        assert!(
            (result.contains("Agent(e, J)") && result.contains("Theme(e, M)"))
                || result.contains("(J, M)")
                || result.contains("(J,M)"),
            "He->John, her->Mary: got '{}'",
            result
        );
    }

    #[test]
    fn discourse_definite_reference() {
        use crate::context::DiscourseContext;
        let mut ctx = DiscourseContext::new();
        compile_with_context("A dog barked.", &mut ctx).unwrap();
        let result = compile_with_context("The dog ran.", &mut ctx).unwrap();
        assert!(
            !result.contains("D2"),
            "The dog should refer to same entity, not D2: got '{}'",
            result
        );
    }

    #[test]
    fn discourse_plural_pronoun_they() {
        use crate::context::DiscourseContext;
        let mut ctx = DiscourseContext::new();
        compile_with_context("The dogs ran.", &mut ctx).unwrap();
        let result = compile_with_context("They barked.", &mut ctx).unwrap();
        assert!(
            result.contains("D"),
            "They should resolve to dogs: got '{}'",
            result
        );
    }

    #[test]
    fn discourse_object_pronoun_him() {
        use crate::context::DiscourseContext;
        let mut ctx = DiscourseContext::new();
        compile_with_context("John entered.", &mut ctx).unwrap();
        let result = compile_with_context("Mary saw him.", &mut ctx).unwrap();
        assert!(
            (result.contains("Agent(e, M)") && result.contains("Theme(e, J)"))
                || result.contains("(M, J)"),
            "him should resolve to John: got '{}'",
            result
        );
    }

    #[test]
    fn compile_discourse_batch() {
        let result = compile_discourse(&["John ran.", "He stopped."]).unwrap();
        assert!(
            result.contains("J") && result.contains("∧"),
            "Batch compile should conjoin and resolve: got '{}'",
            result
        );
    }

    // ═══════════════════════════════════════════════════════════════════
    // Phase 2: Recursive Relative Clauses (TDD RED)
    // ═══════════════════════════════════════════════════════════════════

    #[test]
    fn relative_clause_object_gap() {
        // "The cat that the dog chased ran."
        // The cat is the OBJECT of "chased" (gap), not the subject
        let result = compile("The cat that the dog chased ran.").unwrap();
        // C2 is Chase (C is Cat), D is Dog
        // Structure: ∃x(Cat(x) ∧ Chase(D, x) ∧ Ran(x))
        assert!(
            result.contains("Theme(e, x)") && result.contains("C(x)"),
            "Object-gap relative: dog chases cat, cat ran: got '{}'",
            result
        );
    }

    #[test]
    fn relative_clause_who_subject() {
        // "The man who loves Mary left."
        // "who" = subject of "loves"
        let result = compile("The man who loves Mary left.").unwrap();
        // L is Love, M is Man, M2 is Mary
        // Structure: ∃x(Man(x) ∧ Love(x, Mary) ∧ Left(x))
        assert!(
            result.contains("(x, M") && result.contains("M(x)"),
            "Who-clause should bind subject: got '{}'",
            result
        );
    }

    #[test]
    fn relative_clause_who_object() {
        // "The man who Mary loves left."
        // "who" = object of "loves"
        let result = compile("The man who Mary loves left.").unwrap();
        // Structure: ∃x(Man(x) ∧ Love(Mary, x) ∧ Left(x))
        assert!(
            result.contains("(M") && result.contains(", x)") && result.contains("M(x)"),
            "Who as object: Mary loves the man: got '{}'",
            result
        );
    }

    #[test]
    fn nested_relative_clause() {
        // "The rat that the cat that the dog chased ate died."
        // dog chased cat, cat ate rat, rat died
        let result = compile("The rat that the cat that the dog chased ate died.").unwrap();
        assert!(
            result.contains("D(") || result.contains("Die(") || result.contains("Died("),
            "Nested relatives should parse: got '{}'",
            result
        );
    }

    #[test]
    fn relative_clause_with_transitive() {
        // "The book that John read is good."
        let result = compile("The book that John read is good.").unwrap();
        assert!(
            result.contains("Agent(e, J)") && result.contains("Theme(e, x)"),
            "Book is object of read: got '{}'",
            result
        );
    }

    // ═══════════════════════════════════════════════════════════════════
    // Phase 3: Generalized Quantifiers (TDD RED)
    // ═══════════════════════════════════════════════════════════════════

    #[test]
    fn quantifier_most() {
        let result = compile("Most dogs bark.").unwrap();
        assert!(
            result.contains("MOST") && result.contains("D(x)") && result.contains("B(x)"),
            "Most should produce MOST x(D(x), B(x)): got '{}'",
            result
        );
    }

    #[test]
    fn quantifier_few() {
        let result = compile("Few cats swim.").unwrap();
        assert!(
            result.contains("FEW") && result.contains("C(x)") && result.contains("S(x)"),
            "Few should produce FEW x(C(x), S(x)): got '{}'",
            result
        );
    }

    #[test]
    fn quantifier_cardinal_three() {
        let result = compile("Three dogs bark.").unwrap();
        assert!(
            result.contains("∃≥3") || result.contains("∃=3"),
            "Three should produce cardinal quantifier: got '{}'",
            result
        );
    }

    #[test]
    fn quantifier_at_least_two() {
        let result = compile("At least two birds fly.").unwrap();
        assert!(
            result.contains("∃≥2"),
            "At least two should produce ∃≥2: got '{}'",
            result
        );
    }

    #[test]
    fn quantifier_at_most_five() {
        let result = compile("At most five cats sleep.").unwrap();
        assert!(
            result.contains("∃≤5"),
            "At most five should produce ∃≤5: got '{}'",
            result
        );
    }

    // ═══════════════════════════════════════════════════════════════════
    // Phase 4: Wh-Questions (TDD RED)
    // ═══════════════════════════════════════════════════════════════════

    #[test]
    fn wh_question_who_subject() {
        let result = compile("Who loves Mary?").unwrap();
        assert!(
            result.contains("λx") && result.contains("L(x, M)"),
            "Who-subject should produce λx.L(x, M): got '{}'",
            result
        );
    }

    #[test]
    fn wh_question_what_object() {
        let result = compile("What does John love?").unwrap();
        assert!(
            result.contains("λx") && result.contains("L(J, x)"),
            "What-object should produce λx.L(J, x): got '{}'",
            result
        );
    }

    #[test]
    fn yes_no_question() {
        let result = compile("Does John love Mary?").unwrap();
        assert!(
            result.contains("?") || result.contains("L(J, M)"),
            "Yes/no question should produce query: got '{}'",
            result
        );
    }

    // ═══════════════════════════════════════════════════════════════════
    // Phase 5: Passive Voice (TDD RED)
    // ═══════════════════════════════════════════════════════════════════

    #[test]
    fn passive_with_agent() {
        let result = compile("Mary was loved by John.").unwrap();
        assert!(
            result.contains("L(J, M)"),
            "Passive 'Mary was loved by John' should produce L(J, M): got '{}'",
            result
        );
    }

    #[test]
    fn passive_without_agent() {
        let result = compile("The book was read.").unwrap();
        assert!(
            result.contains("∃") && result.contains("R("),
            "Agentless passive should produce ∃x.R(x, B): got '{}'",
            result
        );
    }
}

```

---

## Linguistic Data

Dictionary and semantic information for word classification.

**Location:** `src/lexicon.rs`

### Lexicon

**File:** `src/lexicon.rs`

Feature-based lexical database. Feature enum (22 variants) classifies words by transitivity (Transitive, Intransitive, Ditransitive), control theory (SubjectControl, ObjectControl, Raising), semantics (Opaque, Factive, Performative, Collective), noun properties (Count, Mass, Proper, Masculine, Feminine, Neuter, Animate, Inanimate), and adjective types (Intersective, Subsective, NonIntersective, Gradable). Subsective adjectives use intension (^Noun) for class-relative predicates like 'small elephant' → S(x, ^E). VerbClass enum implements Vendler's Aktionsart with is_stative()/is_durative()/is_telic(). Metadata structs (VerbMetadata, NounMetadata, AdjectiveMetadata) provide lemma plus feature arrays. Generated lookup functions (lookup_verb_db, lookup_noun_db, lookup_adjective_db) return full metadata at runtime. is_subsective() generated check for adjective type. **Zero-Derivation Morphology:** Consonant cluster heuristic (vowel + consonant + l/r) recovers silent-e lemmas: 'tabled' → 'table', 'googled' → 'google'. **Phase 11 Sort System:** Sort enum (Human, Animate, Celestial, Abstract, Physical, Value) for ontological type hierarchy. lookup_sort() returns Sort for proper names. is_compatible_with() checks sort subsumption (Human⊂Animate⊂Physical). Used for metaphor detection via sort violations ('Juliet is the sun' violates Human/Celestial compatibility).

```rust
include!(concat!(env!("OUT_DIR"), "/lexicon_data.rs"));

/// Feature-based lexical properties
/// Words can have multiple overlapping features
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum Feature {
    // Verb Transitivity
    Transitive,
    Intransitive,
    Ditransitive,

    // Control Theory
    SubjectControl, // "I want to run"
    ObjectControl,  // "I persuaded him to run"
    Raising,        // "He seems to run"

    // Semantics
    Opaque,      // "I seek a unicorn" (De Dicto/De Re ambiguity)
    Factive,     // "I know that..." (Presupposes truth)
    Performative, // "I promise"
    Collective,  // "The group gathered"
    Mixed,       // "Lift" - can be collective or distributive

    // Noun Features
    Count,
    Mass,
    Proper, // Proper Name

    // Gender
    Masculine,
    Feminine,
    Neuter,

    // Animacy
    Animate,
    Inanimate,

    // Adjective Features
    Intersective,    // "Red ball" -> Red(x) AND Ball(x)
    NonIntersective, // "Fake gun" -> Fake(Gun)
    Subsective,      // "Small elephant" -> Small(x, ^Elephant)
    Gradable,        // "Tall", "Taller"
}

impl Feature {
    pub fn from_str(s: &str) -> Option<Feature> {
        match s {
            "Transitive" => Some(Feature::Transitive),
            "Intransitive" => Some(Feature::Intransitive),
            "Ditransitive" => Some(Feature::Ditransitive),
            "SubjectControl" => Some(Feature::SubjectControl),
            "ObjectControl" => Some(Feature::ObjectControl),
            "Raising" => Some(Feature::Raising),
            "Opaque" => Some(Feature::Opaque),
            "Factive" => Some(Feature::Factive),
            "Performative" => Some(Feature::Performative),
            "Collective" => Some(Feature::Collective),
            "Count" => Some(Feature::Count),
            "Mass" => Some(Feature::Mass),
            "Proper" => Some(Feature::Proper),
            "Masculine" => Some(Feature::Masculine),
            "Feminine" => Some(Feature::Feminine),
            "Neuter" => Some(Feature::Neuter),
            "Animate" => Some(Feature::Animate),
            "Inanimate" => Some(Feature::Inanimate),
            "Intersective" => Some(Feature::Intersective),
            "NonIntersective" => Some(Feature::NonIntersective),
            "Subsective" => Some(Feature::Subsective),
            "Gradable" => Some(Feature::Gradable),
            _ => None,
        }
    }
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum Sort {
    Entity,
    Physical,
    Animate,
    Human,
    Plant,
    Place,
    Time,
    Abstract,
    Information,
    Event,
    Celestial,
    Value,
    Group,
}

impl Sort {
    pub fn is_compatible_with(self, other: Sort) -> bool {
        if self == other {
            return true;
        }
        match (self, other) {
            (Sort::Human, Sort::Animate) => true,
            (Sort::Plant, Sort::Animate) => true,
            (Sort::Animate, Sort::Physical) => true,
            (Sort::Human, Sort::Physical) => true,
            (Sort::Plant, Sort::Physical) => true,
            (_, Sort::Entity) => true,
            _ => false,
        }
    }
}

/// Vendler's Lexical Aspect Classes (Aktionsart)
///
/// Classification based on three binary features:
/// - Static: Does the predicate involve change?
/// - Durative: Does the predicate extend over time?
/// - Telic: Does the predicate have a natural endpoint?
#[derive(Debug, Clone, Copy, PartialEq, Eq, Default, Hash)]
pub enum VerbClass {
    /// +static, +durative, -telic: know, love, exist
    State,
    /// -static, +durative, -telic: run, swim, drive
    #[default]
    Activity,
    /// -static, +durative, +telic: build, draw, write
    Accomplishment,
    /// -static, -durative, +telic: win, find, die
    Achievement,
    /// -static, -durative, -telic: knock, cough, blink
    Semelfactive,
}

impl VerbClass {
    /// Returns true if this verb class is stative (+static)
    pub fn is_stative(&self) -> bool {
        matches!(self, VerbClass::State)
    }

    /// Returns true if this verb class is durative (+durative)
    pub fn is_durative(&self) -> bool {
        matches!(
            self,
            VerbClass::State | VerbClass::Activity | VerbClass::Accomplishment
        )
    }

    /// Returns true if this verb class is telic (+telic)
    pub fn is_telic(&self) -> bool {
        matches!(self, VerbClass::Accomplishment | VerbClass::Achievement)
    }
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum Time {
    Past,
    Present,
    Future,
    None,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum Aspect {
    Simple,
    Progressive,
    Perfect,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum Definiteness {
    Definite,
    Indefinite,
    Proximal,
    Distal,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum Number {
    Singular,
    Plural,
}

#[derive(Debug, Clone, PartialEq, Eq)]
pub struct VerbEntry {
    pub lemma: String,
    pub time: Time,
    pub aspect: Aspect,
    pub class: VerbClass,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub struct VerbMetadata {
    pub lemma: &'static str,
    pub class: VerbClass,
    pub time: Time,
    pub aspect: Aspect,
    pub features: &'static [Feature],
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub struct NounMetadata {
    pub lemma: &'static str,
    pub number: Number,
    pub features: &'static [Feature],
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub struct AdjectiveMetadata {
    pub lemma: &'static str,
    pub features: &'static [Feature],
}

pub struct Lexicon {}

impl Lexicon {
    pub fn new() -> Self {
        Lexicon {}
    }

    pub fn lookup_verb(&self, word: &str) -> Option<VerbEntry> {
        let lower = word.to_lowercase();

        if let Some(entry) = lookup_irregular_verb(&lower) {
            return Some(entry);
        }

        if lower.ends_with("ing") {
            let stem = self.strip_ing(&lower);
            let lemma = Self::capitalize(&stem);
            let class = self.lookup_verb_class(&lemma.to_lowercase());
            return Some(VerbEntry {
                lemma,
                time: Time::None,
                aspect: Aspect::Progressive,
                class,
            });
        }

        if lower.ends_with("ed") {
            let stem = self.strip_ed(&lower);
            let lemma = Self::capitalize(&stem);
            let class = self.lookup_verb_class(&lemma.to_lowercase());
            return Some(VerbEntry {
                lemma,
                time: Time::Past,
                aspect: Aspect::Simple,
                class,
            });
        }

        let is_third_person = if lower.ends_with("es") && lower.len() > 2 {
            true
        } else if lower.ends_with("s") && !lower.ends_with("ss") && lower.len() > 2 {
            true
        } else {
            false
        };

        if is_third_person {
            if is_stemming_exception(&lower) {
                return None;
            }

            let stem = self.strip_s(&lower);
            if !is_base_verb(&stem) {
                return None;
            }
            let lemma = Self::capitalize(&stem);
            let class = self.lookup_verb_class(&lemma.to_lowercase());
            return Some(VerbEntry {
                lemma,
                time: Time::Present,
                aspect: Aspect::Simple,
                class,
            });
        }

        // Check if this is a base verb form
        if is_base_verb(&lower) {
            let lemma = Self::capitalize(&lower);
            let class = self.lookup_verb_class(&lower);
            return Some(VerbEntry {
                lemma,
                time: Time::Present,
                aspect: Aspect::Simple,
                class,
            });
        }

        None
    }

    fn lookup_verb_class(&self, lemma: &str) -> VerbClass {
        lookup_verb_class(lemma)
    }

    fn strip_ing(&self, word: &str) -> String {
        let base = &word[..word.len() - 3];

        if base.len() >= 2 {
            let chars: Vec<char> = base.chars().collect();
            let last = chars[chars.len() - 1];
            let second_last = chars[chars.len() - 2];

            if last == second_last && !"aeiou".contains(last) {
                return base[..base.len() - 1].to_string();
            }
        }

        if needs_e_ing(base) {
            return format!("{}e", base);
        }

        base.to_string()
    }

    fn strip_ed(&self, word: &str) -> String {
        let base = &word[..word.len() - 2];

        if base.ends_with("i") {
            return format!("{}y", &base[..base.len() - 1]);
        }

        if base.len() >= 2 {
            let chars: Vec<char> = base.chars().collect();
            let last = chars[chars.len() - 1];
            let second_last = chars[chars.len() - 2];

            if last == second_last && !"aeiou".contains(last) {
                return base[..base.len() - 1].to_string();
            }

            // Consonant clusters that typically come from silent-e verbs:
            // "tabled" → "tabl" needs "e", "googled" → "googl" needs "e"
            // Pattern: consonant + l/r at end, with vowel before the consonant
            if (last == 'l' || last == 'r') && !"aeiou".contains(second_last) {
                if chars.len() >= 3 && "aeiou".contains(chars[chars.len() - 3]) {
                    return format!("{}e", base);
                }
            }
        }

        if needs_e_ed(base) {
            return format!("{}e", base);
        }

        base.to_string()
    }

    fn strip_s(&self, word: &str) -> String {
        if word.ends_with("ies") {
            return format!("{}y", &word[..word.len() - 3]);
        }
        // For verbs ending in silent 'e': hopes → hope, decides → decide
        // These add "s" not "es", so stripping just "s" gives correct lemma
        if word.ends_with("es") {
            let base_minus_es = &word[..word.len() - 2];
            let base_minus_s = &word[..word.len() - 1];
            // If base-1 ends in 'e', probably a silent-e verb: hopes → hope
            if base_minus_s.ends_with('e') {
                return base_minus_s.to_string();
            }
            // Otherwise it's a sibilant ending: watches → watch, fixes → fix
            return base_minus_es.to_string();
        }
        word[..word.len() - 1].to_string()
    }

    fn capitalize(s: &str) -> String {
        let mut chars = s.chars();
        match chars.next() {
            None => String::new(),
            Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
        }
    }
}

impl Default for Lexicon {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn feature_from_str_ditransitive() {
        assert_eq!(
            Feature::from_str("Ditransitive"),
            Some(Feature::Ditransitive)
        );
    }

    #[test]
    fn feature_from_str_subject_control() {
        assert_eq!(
            Feature::from_str("SubjectControl"),
            Some(Feature::SubjectControl)
        );
    }

    #[test]
    fn feature_from_str_opaque() {
        assert_eq!(Feature::from_str("Opaque"), Some(Feature::Opaque));
    }

    #[test]
    fn feature_from_str_unknown() {
        assert_eq!(Feature::from_str("Unknown"), None);
    }

    #[test]
    fn irregular_past_ran() {
        let lex = Lexicon::new();
        let entry = lex.lookup_verb("ran").unwrap();
        assert_eq!(entry.lemma, "Run");
        assert_eq!(entry.time, Time::Past);
        assert_eq!(entry.aspect, Aspect::Simple);
    }

    #[test]
    fn irregular_progressive_running() {
        let lex = Lexicon::new();
        let entry = lex.lookup_verb("running").unwrap();
        assert_eq!(entry.lemma, "Run");
        assert_eq!(entry.time, Time::None);
        assert_eq!(entry.aspect, Aspect::Progressive);
    }

    #[test]
    fn regular_past_jumped() {
        let lex = Lexicon::new();
        let entry = lex.lookup_verb("jumped").unwrap();
        assert_eq!(entry.lemma, "Jump");
        assert_eq!(entry.time, Time::Past);
    }

    #[test]
    fn regular_present_runs() {
        let lex = Lexicon::new();
        let entry = lex.lookup_verb("runs").unwrap();
        assert_eq!(entry.lemma, "Run");
        assert_eq!(entry.time, Time::Present);
    }

    #[test]
    fn present_silent_e_hopes() {
        let lex = Lexicon::new();
        let entry = lex.lookup_verb("hopes").unwrap();
        assert_eq!(entry.lemma, "Hope");
        assert_eq!(entry.time, Time::Present);
    }

    #[test]
    fn present_silent_e_decides() {
        let lex = Lexicon::new();
        let entry = lex.lookup_verb("decides").unwrap();
        assert_eq!(entry.lemma, "Decide");
        assert_eq!(entry.time, Time::Present);
    }

    #[test]
    fn present_silent_e_convinces() {
        let lex = Lexicon::new();
        let entry = lex.lookup_verb("convinces").unwrap();
        assert_eq!(entry.lemma, "Convince");
        assert_eq!(entry.time, Time::Present);
    }

    #[test]
    fn past_silent_e_decided() {
        let lex = Lexicon::new();
        let entry = lex.lookup_verb("decided").unwrap();
        assert_eq!(entry.lemma, "Decide");
        assert_eq!(entry.time, Time::Past);
    }

    #[test]
    fn regular_progressive_jumping() {
        let lex = Lexicon::new();
        let entry = lex.lookup_verb("jumping").unwrap();
        assert_eq!(entry.lemma, "Jump");
        assert_eq!(entry.aspect, Aspect::Progressive);
    }

    #[test]
    fn regular_present_barks() {
        let lex = Lexicon::new();
        let entry = lex.lookup_verb("barks").unwrap();
        assert_eq!(entry.lemma, "Bark");
        assert_eq!(entry.time, Time::Present);
    }

    #[test]
    fn verb_db_returns_metadata_with_features() {
        let meta = lookup_verb_db("give").unwrap();
        assert_eq!(meta.lemma, "Give");
        assert_eq!(meta.class, VerbClass::Achievement);
        assert!(meta.features.contains(&Feature::Ditransitive));
    }

    #[test]
    fn verb_db_irregular_past() {
        let meta = lookup_verb_db("ran").unwrap();
        assert_eq!(meta.lemma, "Run");
        assert_eq!(meta.time, Time::Past);
    }

    #[test]
    fn verb_db_opaque_verb_has_feature() {
        let meta = lookup_verb_db("seek").unwrap();
        assert_eq!(meta.lemma, "Seek");
        assert!(meta.features.contains(&Feature::Opaque));
    }

    #[test]
    fn noun_db_returns_metadata() {
        let meta = lookup_noun_db("dog").unwrap();
        assert_eq!(meta.lemma, "Dog");
        assert_eq!(meta.number, Number::Singular);
    }

    #[test]
    fn noun_db_plural_form() {
        let meta = lookup_noun_db("men").unwrap();
        assert_eq!(meta.lemma, "Man");
        assert_eq!(meta.number, Number::Plural);
    }

    #[test]
    fn noun_db_proper_name_has_features() {
        let meta = lookup_noun_db("john").unwrap();
        assert_eq!(meta.lemma, "John");
        assert!(meta.features.contains(&Feature::Proper));
        assert!(meta.features.contains(&Feature::Masculine));
    }

    #[test]
    fn adjective_db_returns_metadata() {
        let meta = lookup_adjective_db("fake").unwrap();
        assert_eq!(meta.lemma, "Fake");
        assert!(meta.features.contains(&Feature::NonIntersective));
    }

    #[test]
    fn adjective_db_gradable() {
        let meta = lookup_adjective_db("tall").unwrap();
        assert_eq!(meta.lemma, "Tall");
        assert!(meta.features.contains(&Feature::Gradable));
    }
}

```

---

### Multi-Word Expressions

**File:** `src/mwe.rs`

Post-tokenization MWE pipeline (Phase 13). MweTrie for pattern storage with longest-match lookup. apply_mwe_pipeline() collapses multi-token sequences into single semantic units. Handles compound nouns (fire engine → FireEngine), idioms (kicked the bucket → Die), and phrasal verbs (gave up → Surrender). Inherits tense from head token for morphological variants. build_mwe_trie() creates default vocabulary with common MWEs.

```rust
//! Multi-Word Expression (MWE) processing
//!
//! Post-tokenization pipeline that collapses multi-token sequences
//! into single semantic units (e.g., "fire engine" -> FireEngine).

use std::collections::HashMap;
use crate::token::{Token, TokenType};
use crate::lexicon::{VerbClass, Time, Aspect};
use crate::intern::Interner;

#[derive(Debug, Clone)]
pub struct MweTarget {
    pub lemma: &'static str,
    pub pos: &'static str,
    pub class: Option<VerbClass>,
}

#[derive(Default, Debug)]
pub struct MweTrie {
    pub children: HashMap<String, MweTrie>,
    pub target: Option<MweTarget>,
}

impl MweTrie {
    pub fn insert(&mut self, pattern: &[&str], target: MweTarget) {
        if pattern.is_empty() {
            self.target = Some(target);
            return;
        }
        self.children
            .entry(pattern[0].to_lowercase())
            .or_default()
            .insert(&pattern[1..], target);
    }
}

/// Apply MWE collapsing to a token stream.
/// Matches on lemmas (not raw strings) to handle morphological variants.
pub fn apply_mwe_pipeline(
    tokens: Vec<Token>,
    trie: &MweTrie,
    interner: &mut Interner,
) -> Vec<Token> {
    let mut result = Vec::new();
    let mut i = 0;

    while i < tokens.len() {
        if let Some((match_len, target)) = find_longest_match(&tokens[i..], trie, interner) {
            let merged = create_merged_token(&tokens[i], target, interner);
            result.push(merged);
            i += match_len;
        } else {
            result.push(tokens[i].clone());
            i += 1;
        }
    }
    result
}

/// Extract lemma from a token for MWE matching.
/// Uses lowercase for case-insensitive matching.
fn get_lemma(token: &Token, interner: &Interner) -> String {
    match &token.kind {
        TokenType::Verb { lemma, .. } => interner.resolve(*lemma).to_lowercase(),
        TokenType::Noun(sym) => interner.resolve(*sym).to_lowercase(),
        TokenType::Adjective(sym) => interner.resolve(*sym).to_lowercase(),
        TokenType::NonIntersectiveAdjective(sym) => interner.resolve(*sym).to_lowercase(),
        TokenType::Preposition(sym) => interner.resolve(*sym).to_lowercase(),
        TokenType::Particle(sym) => interner.resolve(*sym).to_lowercase(),
        TokenType::Article(_) => interner.resolve(token.lexeme).to_lowercase(),
        _ => interner.resolve(token.lexeme).to_lowercase(),
    }
}

/// Find the longest MWE match starting at the beginning of the token slice.
fn find_longest_match<'a>(
    tokens: &[Token],
    trie: &'a MweTrie,
    interner: &Interner,
) -> Option<(usize, &'a MweTarget)> {
    let mut node = trie;
    let mut best: Option<(usize, &MweTarget)> = None;

    for (i, token) in tokens.iter().enumerate() {
        let lemma = get_lemma(token, interner);
        if let Some(child) = node.children.get(&lemma) {
            node = child;
            if let Some(target) = &node.target {
                best = Some((i + 1, target));
            }
        } else {
            break;
        }
    }
    best
}

/// Create a merged token from the MWE target, inheriting tense from the head token.
fn create_merged_token(head: &Token, target: &MweTarget, interner: &mut Interner) -> Token {
    let lemma_sym = interner.intern(target.lemma);

    let kind = match target.pos {
        "Noun" => TokenType::Noun(lemma_sym),
        "Verb" => {
            let (time, aspect) = match &head.kind {
                TokenType::Verb { time, aspect, .. } => (*time, *aspect),
                _ => (Time::Present, Aspect::Simple),
            };
            TokenType::Verb {
                lemma: lemma_sym,
                time,
                aspect,
                class: target.class.unwrap_or(VerbClass::Activity),
            }
        }
        "Preposition" => TokenType::Preposition(lemma_sym),
        "Conjunction" => TokenType::And,
        "Quantifier" => TokenType::NoOne,
        _ => TokenType::Noun(lemma_sym),
    };

    Token {
        kind,
        lexeme: lemma_sym,
        span: head.span,
    }
}

include!(concat!(env!("OUT_DIR"), "/mwe_data.rs"));

```

---

### Ontology Module

**File:** `src/ontology.rs`

Bridging anaphora and sort checking (Phase 14). find_bridging_wholes() returns possible whole objects for parts (e.g., 'engine' → ['car', 'plane']). check_sort_compatibility() validates predicate-subject sort match for metaphor detection. required_sort() gets predicate's required sort. Uses generated ontology_data.rs from build.rs with part-whole mappings and predicate sort requirements.

```rust
//! Ontology module for bridging anaphora and sort compatibility checking.
//!
//! This module provides:
//! - Part-whole relationship lookup for bridging anaphora resolution
//! - Predicate sort requirements for metaphor detection

use crate::lexicon::Sort;

include!(concat!(env!("OUT_DIR"), "/ontology_data.rs"));

/// Find possible whole objects for a given part noun.
/// Returns None if the noun is not a known part of any whole.
pub fn find_bridging_wholes(part_noun: &str) -> Option<&'static [&'static str]> {
    let wholes = get_possible_wholes(&part_noun.to_lowercase());
    if wholes.is_empty() {
        None
    } else {
        Some(wholes)
    }
}

/// Check if a predicate is compatible with a subject's sort.
/// Returns true if compatible or no sort requirement exists.
pub fn check_sort_compatibility(predicate: &str, subject_sort: Sort) -> bool {
    match get_predicate_sort(&predicate.to_lowercase()) {
        Some(required) => subject_sort.is_compatible_with(required),
        None => true,
    }
}

/// Get the required sort for a predicate, if any.
pub fn required_sort(predicate: &str) -> Option<Sort> {
    get_predicate_sort(&predicate.to_lowercase())
}

```

---

## Memory Management

Efficient memory allocation strategies for AST construction.

**Location:** `src/intern.rs`, `src/arena.rs`

### Symbol Interning

**File:** `src/intern.rs`

Interner and Symbol types for efficient string storage. Enables O(1) symbol comparisons and reduced memory footprint.

```rust
use std::collections::HashMap;

#[derive(Clone, Copy, PartialEq, Eq, Hash, Debug)]
pub struct Symbol(u32);

impl Symbol {
    pub const EMPTY: Symbol = Symbol(0);

    pub fn index(self) -> usize {
        self.0 as usize
    }
}

impl Default for Symbol {
    fn default() -> Self {
        Self::EMPTY
    }
}

pub struct Interner {
    map: HashMap<String, Symbol>,
    vec: Vec<String>,
}

impl Interner {
    pub fn new() -> Self {
        let mut interner = Interner {
            map: HashMap::new(),
            vec: Vec::new(),
        };
        interner.vec.push(String::new());
        interner
    }

    pub fn intern(&mut self, s: &str) -> Symbol {
        if let Some(&sym) = self.map.get(s) {
            return sym;
        }
        let sym = Symbol(self.vec.len() as u32);
        self.vec.push(s.to_string());
        self.map.insert(s.to_string(), sym);
        sym
    }

    pub fn resolve(&self, sym: Symbol) -> &str {
        &self.vec[sym.0 as usize]
    }

    pub fn len(&self) -> usize {
        self.vec.len()
    }

    pub fn is_empty(&self) -> bool {
        self.vec.len() <= 1
    }
}

impl Default for Interner {
    fn default() -> Self {
        Self::new()
    }
}

pub trait SymbolEq {
    fn is(&self, interner: &Interner, s: &str) -> bool;
}

impl SymbolEq for Symbol {
    #[inline]
    fn is(&self, interner: &Interner, s: &str) -> bool {
        interner.resolve(*self) == s
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn intern_returns_same_symbol_for_same_string() {
        let mut interner = Interner::new();
        let s1 = interner.intern("hello");
        let s2 = interner.intern("hello");
        assert_eq!(s1, s2);
    }

    #[test]
    fn intern_returns_different_symbols_for_different_strings() {
        let mut interner = Interner::new();
        let s1 = interner.intern("hello");
        let s2 = interner.intern("world");
        assert_ne!(s1, s2);
    }

    #[test]
    fn resolve_returns_original_string() {
        let mut interner = Interner::new();
        let sym = interner.intern("test");
        assert_eq!(interner.resolve(sym), "test");
    }

    #[test]
    fn empty_symbol_resolves_to_empty_string() {
        let interner = Interner::new();
        assert_eq!(interner.resolve(Symbol::EMPTY), "");
    }

    #[test]
    fn symbols_are_copy() {
        let mut interner = Interner::new();
        let s1 = interner.intern("copy_test");
        let s2 = s1;
        assert_eq!(s1, s2);
        assert_eq!(interner.resolve(s1), interner.resolve(s2));
    }

    #[test]
    fn symbol_equality_is_fast() {
        let mut interner = Interner::new();
        let s1 = interner.intern("a_very_long_string_that_would_be_slow_to_compare");
        let s2 = interner.intern("a_very_long_string_that_would_be_slow_to_compare");
        assert_eq!(s1, s2);
    }

    #[test]
    fn len_tracks_interned_count() {
        let mut interner = Interner::new();
        assert_eq!(interner.len(), 1);
        interner.intern("first");
        assert_eq!(interner.len(), 2);
        interner.intern("second");
        assert_eq!(interner.len(), 3);
        interner.intern("first");
        assert_eq!(interner.len(), 3);
    }

    #[test]
    fn is_empty_after_new() {
        let interner = Interner::new();
        assert!(interner.is_empty());
    }

    #[test]
    fn not_empty_after_intern() {
        let mut interner = Interner::new();
        interner.intern("something");
        assert!(!interner.is_empty());
    }

    #[test]
    fn symbol_index_matches_position() {
        let mut interner = Interner::new();
        let s1 = interner.intern("first");
        let s2 = interner.intern("second");
        assert_eq!(s1.index(), 1);
        assert_eq!(s2.index(), 2);
    }

    #[test]
    fn symbol_is_matches_interned_string() {
        let mut interner = Interner::new();
        let sym = interner.intern("test");
        assert!(sym.is(&interner, "test"));
    }

    #[test]
    fn symbol_is_rejects_different_string() {
        let mut interner = Interner::new();
        let sym = interner.intern("hello");
        assert!(!sym.is(&interner, "world"));
    }

    #[test]
    fn symbol_is_case_sensitive() {
        let mut interner = Interner::new();
        let sym = interner.intern("Test");
        assert!(!sym.is(&interner, "test"));
        assert!(sym.is(&interner, "Test"));
    }

    #[test]
    fn symbol_empty_is_empty_string() {
        let interner = Interner::new();
        assert!(Symbol::EMPTY.is(&interner, ""));
    }
}

```

---

### Arena Allocation

**File:** `src/arena.rs`

Bumpalo-based arena allocator for AST nodes. Provides fast allocation with batch deallocation.

```rust
use bumpalo::Bump;

pub struct Arena<T> {
    bump: Bump,
    _marker: std::marker::PhantomData<T>,
}

impl<T> Arena<T> {
    pub fn new() -> Self {
        Arena {
            bump: Bump::new(),
            _marker: std::marker::PhantomData,
        }
    }

    pub fn alloc(&self, value: T) -> &T {
        self.bump.alloc(value)
    }

    pub fn alloc_slice<I>(&self, items: I) -> &[T]
    where
        I: IntoIterator<Item = T>,
        I::IntoIter: ExactSizeIterator,
    {
        self.bump.alloc_slice_fill_iter(items)
    }

    /// Resets the arena, invalidating all references but keeping allocated capacity.
    /// This enables zero-allocation REPL loops by reusing memory.
    pub fn reset(&mut self) {
        self.bump.reset();
    }
}

impl<T> Default for Arena<T> {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn alloc_returns_stable_reference() {
        let arena: Arena<i32> = Arena::new();
        let r1 = arena.alloc(42);
        let r2 = arena.alloc(100);
        assert_eq!(*r1, 42);
        assert_eq!(*r2, 100);
    }

    #[test]
    fn references_remain_valid_after_many_allocations() {
        let arena: Arena<i32> = Arena::new();
        let refs: Vec<&i32> = (0..10000).map(|i| arena.alloc(i)).collect();
        for (i, r) in refs.iter().enumerate() {
            assert_eq!(**r, i as i32);
        }
    }

    #[test]
    fn works_with_structs() {
        #[derive(Debug, PartialEq)]
        struct Point {
            x: i32,
            y: i32,
        }

        let arena: Arena<Point> = Arena::new();
        let p1 = arena.alloc(Point { x: 1, y: 2 });
        let p2 = arena.alloc(Point { x: 3, y: 4 });
        assert_eq!(p1, &Point { x: 1, y: 2 });
        assert_eq!(p2, &Point { x: 3, y: 4 });
    }

    #[test]
    fn alloc_slice_works() {
        let arena: Arena<i32> = Arena::new();
        let slice = arena.alloc_slice([1, 2, 3]);
        assert_eq!(slice, &[1, 2, 3]);
    }

    #[test]
    fn alloc_slice_from_vec() {
        let arena: Arena<i32> = Arena::new();
        let vec = vec![10, 20, 30];
        let slice = arena.alloc_slice(vec);
        assert_eq!(slice, &[10, 20, 30]);
    }

    #[test]
    fn alloc_empty_slice() {
        let arena: Arena<i32> = Arena::new();
        let empty: Vec<i32> = vec![];
        let slice = arena.alloc_slice(empty);
        assert!(slice.is_empty());
    }
}

```

---

### AST Context

**File:** `src/arena_ctx.rs`

AstContext struct unifying 6 separate arenas into one Copy struct. Provides alloc_expr(), alloc_term(), alloc_slice() helpers for ergonomic AST construction. Fluent expression builders: binary(), unary(), quantifier(), temporal(), aspectual(), modal() with #[inline(always)].

```rust
use crate::arena::Arena;
use crate::ast::{AspectOperator, LogicExpr, ModalVector, NounPhrase, QuantifierKind, TemporalOperator, VoiceOperator, Term, ThematicRole, Stmt, Expr, TypeExpr};
use crate::intern::Symbol;
use crate::token::TokenType;

#[derive(Clone, Copy)]
pub struct AstContext<'a> {
    pub exprs: &'a Arena<LogicExpr<'a>>,
    pub terms: &'a Arena<Term<'a>>,
    pub nps: &'a Arena<NounPhrase<'a>>,
    pub syms: &'a Arena<Symbol>,
    pub roles: &'a Arena<(ThematicRole, Term<'a>)>,
    pub pps: &'a Arena<&'a LogicExpr<'a>>,
    pub stmts: Option<&'a Arena<Stmt<'a>>>,
    pub imperative_exprs: Option<&'a Arena<Expr<'a>>>,
    pub type_exprs: Option<&'a Arena<TypeExpr<'a>>>,
}

impl<'a> AstContext<'a> {
    pub fn new(
        exprs: &'a Arena<LogicExpr<'a>>,
        terms: &'a Arena<Term<'a>>,
        nps: &'a Arena<NounPhrase<'a>>,
        syms: &'a Arena<Symbol>,
        roles: &'a Arena<(ThematicRole, Term<'a>)>,
        pps: &'a Arena<&'a LogicExpr<'a>>,
    ) -> Self {
        AstContext { exprs, terms, nps, syms, roles, pps, stmts: None, imperative_exprs: None, type_exprs: None }
    }

    pub fn with_imperative(
        exprs: &'a Arena<LogicExpr<'a>>,
        terms: &'a Arena<Term<'a>>,
        nps: &'a Arena<NounPhrase<'a>>,
        syms: &'a Arena<Symbol>,
        roles: &'a Arena<(ThematicRole, Term<'a>)>,
        pps: &'a Arena<&'a LogicExpr<'a>>,
        stmts: &'a Arena<Stmt<'a>>,
        imperative_exprs: &'a Arena<Expr<'a>>,
    ) -> Self {
        AstContext { exprs, terms, nps, syms, roles, pps, stmts: Some(stmts), imperative_exprs: Some(imperative_exprs), type_exprs: None }
    }

    pub fn with_types(
        exprs: &'a Arena<LogicExpr<'a>>,
        terms: &'a Arena<Term<'a>>,
        nps: &'a Arena<NounPhrase<'a>>,
        syms: &'a Arena<Symbol>,
        roles: &'a Arena<(ThematicRole, Term<'a>)>,
        pps: &'a Arena<&'a LogicExpr<'a>>,
        stmts: &'a Arena<Stmt<'a>>,
        imperative_exprs: &'a Arena<Expr<'a>>,
        type_exprs: &'a Arena<TypeExpr<'a>>,
    ) -> Self {
        AstContext {
            exprs, terms, nps, syms, roles, pps,
            stmts: Some(stmts),
            imperative_exprs: Some(imperative_exprs),
            type_exprs: Some(type_exprs),
        }
    }

    pub fn alloc_stmt(&self, stmt: Stmt<'a>) -> &'a Stmt<'a> {
        self.stmts.expect("imperative arenas not initialized").alloc(stmt)
    }

    pub fn alloc_imperative_expr(&self, expr: Expr<'a>) -> &'a Expr<'a> {
        self.imperative_exprs.expect("imperative arenas not initialized").alloc(expr)
    }

    pub fn alloc_type_expr(&self, ty: TypeExpr<'a>) -> &'a TypeExpr<'a> {
        self.type_exprs.expect("type_exprs arena not initialized").alloc(ty)
    }

    pub fn alloc_type_exprs<I>(&self, types: I) -> &'a [TypeExpr<'a>]
    where
        I: IntoIterator<Item = TypeExpr<'a>>,
        I::IntoIter: ExactSizeIterator,
    {
        self.type_exprs.expect("type_exprs arena not initialized").alloc_slice(types)
    }

    pub fn alloc_expr(&self, expr: LogicExpr<'a>) -> &'a LogicExpr<'a> {
        self.exprs.alloc(expr)
    }

    pub fn alloc_term(&self, term: Term<'a>) -> &'a Term<'a> {
        self.terms.alloc(term)
    }

    pub fn alloc_terms<I>(&self, terms: I) -> &'a [Term<'a>]
    where
        I: IntoIterator<Item = Term<'a>>,
        I::IntoIter: ExactSizeIterator,
    {
        self.terms.alloc_slice(terms)
    }

    pub fn alloc_np(&self, np: NounPhrase<'a>) -> &'a NounPhrase<'a> {
        self.nps.alloc(np)
    }

    pub fn alloc_syms<I>(&self, syms: I) -> &'a [Symbol]
    where
        I: IntoIterator<Item = Symbol>,
        I::IntoIter: ExactSizeIterator,
    {
        self.syms.alloc_slice(syms)
    }

    pub fn alloc_roles<I>(&self, roles: I) -> &'a [(ThematicRole, Term<'a>)]
    where
        I: IntoIterator<Item = (ThematicRole, Term<'a>)>,
        I::IntoIter: ExactSizeIterator,
    {
        self.roles.alloc_slice(roles)
    }

    pub fn alloc_pps<I>(&self, pps: I) -> &'a [&'a LogicExpr<'a>]
    where
        I: IntoIterator<Item = &'a LogicExpr<'a>>,
        I::IntoIter: ExactSizeIterator,
    {
        self.pps.alloc_slice(pps)
    }

    pub fn predicate(&self, name: Symbol, args: &'a [Term<'a>]) -> &'a LogicExpr<'a> {
        self.exprs.alloc(LogicExpr::Predicate { name, args })
    }

    #[inline(always)]
    pub fn binary(&self, left: &'a LogicExpr<'a>, op: TokenType, right: &'a LogicExpr<'a>) -> &'a LogicExpr<'a> {
        self.exprs.alloc(LogicExpr::BinaryOp { left, op, right })
    }

    #[inline(always)]
    pub fn unary(&self, op: TokenType, operand: &'a LogicExpr<'a>) -> &'a LogicExpr<'a> {
        self.exprs.alloc(LogicExpr::UnaryOp { op, operand })
    }

    #[inline(always)]
    pub fn quantifier(&self, kind: QuantifierKind, variable: Symbol, body: &'a LogicExpr<'a>, island_id: u32) -> &'a LogicExpr<'a> {
        self.exprs.alloc(LogicExpr::Quantifier { kind, variable, body, island_id })
    }

    #[inline(always)]
    pub fn temporal(&self, operator: TemporalOperator, body: &'a LogicExpr<'a>) -> &'a LogicExpr<'a> {
        self.exprs.alloc(LogicExpr::Temporal { operator, body })
    }

    #[inline(always)]
    pub fn aspectual(&self, operator: AspectOperator, body: &'a LogicExpr<'a>) -> &'a LogicExpr<'a> {
        self.exprs.alloc(LogicExpr::Aspectual { operator, body })
    }

    #[inline(always)]
    pub fn voice(&self, operator: VoiceOperator, body: &'a LogicExpr<'a>) -> &'a LogicExpr<'a> {
        self.exprs.alloc(LogicExpr::Voice { operator, body })
    }

    #[inline(always)]
    pub fn modal(&self, vector: ModalVector, operand: &'a LogicExpr<'a>) -> &'a LogicExpr<'a> {
        self.exprs.alloc(LogicExpr::Modal { vector, operand })
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::ast::{QuantifierKind, TemporalOperator, AspectOperator, ModalVector, ModalDomain};
    use crate::intern::Interner;
    use crate::token::TokenType;

    fn setup<'a>(
        expr_arena: &'a Arena<LogicExpr<'a>>,
        term_arena: &'a Arena<Term<'a>>,
        np_arena: &'a Arena<NounPhrase<'a>>,
        sym_arena: &'a Arena<Symbol>,
        role_arena: &'a Arena<(ThematicRole, Term<'a>)>,
        pp_arena: &'a Arena<&'a LogicExpr<'a>>,
    ) -> AstContext<'a> {
        AstContext::new(expr_arena, term_arena, np_arena, sym_arena, role_arena, pp_arena)
    }

    #[test]
    fn binary_builder_creates_binary_op() {
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();
        let np_arena: Arena<NounPhrase> = Arena::new();
        let sym_arena: Arena<Symbol> = Arena::new();
        let role_arena: Arena<(ThematicRole, Term)> = Arena::new();
        let pp_arena: Arena<&LogicExpr> = Arena::new();
        let ctx = setup(&expr_arena, &term_arena, &np_arena, &sym_arena, &role_arena, &pp_arena);

        let mut interner = Interner::new();
        let p = interner.intern("P");
        let q = interner.intern("Q");

        let left = ctx.alloc_expr(LogicExpr::Atom(p));
        let right = ctx.alloc_expr(LogicExpr::Atom(q));
        let result = ctx.binary(left, TokenType::And, right);

        assert!(matches!(result, LogicExpr::BinaryOp { op: TokenType::And, .. }));
    }

    #[test]
    fn unary_builder_creates_unary_op() {
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();
        let np_arena: Arena<NounPhrase> = Arena::new();
        let sym_arena: Arena<Symbol> = Arena::new();
        let role_arena: Arena<(ThematicRole, Term)> = Arena::new();
        let pp_arena: Arena<&LogicExpr> = Arena::new();
        let ctx = setup(&expr_arena, &term_arena, &np_arena, &sym_arena, &role_arena, &pp_arena);

        let mut interner = Interner::new();
        let p = interner.intern("P");
        let operand = ctx.alloc_expr(LogicExpr::Atom(p));
        let result = ctx.unary(TokenType::Not, operand);

        assert!(matches!(result, LogicExpr::UnaryOp { op: TokenType::Not, .. }));
    }

    #[test]
    fn quantifier_builder_creates_quantifier() {
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();
        let np_arena: Arena<NounPhrase> = Arena::new();
        let sym_arena: Arena<Symbol> = Arena::new();
        let role_arena: Arena<(ThematicRole, Term)> = Arena::new();
        let pp_arena: Arena<&LogicExpr> = Arena::new();
        let ctx = setup(&expr_arena, &term_arena, &np_arena, &sym_arena, &role_arena, &pp_arena);

        let mut interner = Interner::new();
        let x = interner.intern("x");
        let p = interner.intern("P");
        let body = ctx.alloc_expr(LogicExpr::Atom(p));
        let result = ctx.quantifier(QuantifierKind::Universal, x, body, 0);

        assert!(matches!(result, LogicExpr::Quantifier { kind: QuantifierKind::Universal, .. }));
    }

    #[test]
    fn temporal_builder_creates_temporal() {
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();
        let np_arena: Arena<NounPhrase> = Arena::new();
        let sym_arena: Arena<Symbol> = Arena::new();
        let role_arena: Arena<(ThematicRole, Term)> = Arena::new();
        let pp_arena: Arena<&LogicExpr> = Arena::new();
        let ctx = setup(&expr_arena, &term_arena, &np_arena, &sym_arena, &role_arena, &pp_arena);

        let mut interner = Interner::new();
        let p = interner.intern("P");
        let body = ctx.alloc_expr(LogicExpr::Atom(p));
        let result = ctx.temporal(TemporalOperator::Past, body);

        assert!(matches!(result, LogicExpr::Temporal { operator: TemporalOperator::Past, .. }));
    }

    #[test]
    fn aspectual_builder_creates_aspectual() {
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();
        let np_arena: Arena<NounPhrase> = Arena::new();
        let sym_arena: Arena<Symbol> = Arena::new();
        let role_arena: Arena<(ThematicRole, Term)> = Arena::new();
        let pp_arena: Arena<&LogicExpr> = Arena::new();
        let ctx = setup(&expr_arena, &term_arena, &np_arena, &sym_arena, &role_arena, &pp_arena);

        let mut interner = Interner::new();
        let p = interner.intern("P");
        let body = ctx.alloc_expr(LogicExpr::Atom(p));
        let result = ctx.aspectual(AspectOperator::Progressive, body);

        assert!(matches!(result, LogicExpr::Aspectual { operator: AspectOperator::Progressive, .. }));
    }

    #[test]
    fn modal_builder_creates_modal() {
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();
        let np_arena: Arena<NounPhrase> = Arena::new();
        let sym_arena: Arena<Symbol> = Arena::new();
        let role_arena: Arena<(ThematicRole, Term)> = Arena::new();
        let pp_arena: Arena<&LogicExpr> = Arena::new();
        let ctx = setup(&expr_arena, &term_arena, &np_arena, &sym_arena, &role_arena, &pp_arena);

        let mut interner = Interner::new();
        let p = interner.intern("P");
        let operand = ctx.alloc_expr(LogicExpr::Atom(p));
        let vector = ModalVector { domain: ModalDomain::Alethic, force: 1.0 };
        let result = ctx.modal(vector, operand);

        assert!(matches!(result, LogicExpr::Modal { .. }));
    }
}

```

---

## Error Handling

User-friendly error reporting with educational feedback.

**Location:** `src/error.rs`

### Error Types

**File:** `src/error.rs`

ParseError and ParseErrorKind types. ParseError includes Span for source location. display_with_source() renders errors with ANSI colors, line numbers, underline markers, and 'did you mean?' suggestions. Implements socratic_explanation() for Socratic-style error guidance.

```rust
use crate::intern::Interner;
use crate::style::Style;
use crate::suggest::{find_similar, KNOWN_WORDS};
use crate::token::{Span, TokenType};

#[derive(Debug, Clone)]
pub struct ParseError {
    pub kind: ParseErrorKind,
    pub span: Span,
}

impl ParseError {
    pub fn display_with_source(&self, source: &str) -> String {
        let (line_num, line_start, line_content) = self.find_context(source);
        let col = self.span.start.saturating_sub(line_start);
        let len = (self.span.end - self.span.start).max(1);
        let underline = format!("{}{}", " ".repeat(col), "^".repeat(len));

        let error_label = Style::bold_red("error");
        let kind_str = format!("{:?}", self.kind);
        let line_num_str = Style::blue(&format!("{:4}", line_num));
        let pipe = Style::blue("|");
        let underline_colored = Style::red(&underline);

        let mut result = format!(
            "{}: {}\n\n{} {} {}\n     {} {}",
            error_label, kind_str, line_num_str, pipe, line_content, pipe, underline_colored
        );

        if let Some(word) = self.extract_word(source) {
            if let Some(suggestion) = find_similar(&word, KNOWN_WORDS, 2) {
                let hint = Style::cyan("help");
                result.push_str(&format!("\n     {} {}: did you mean '{}'?", pipe, hint, Style::green(suggestion)));
            }
        }

        result
    }

    fn extract_word<'a>(&self, source: &'a str) -> Option<&'a str> {
        if self.span.start < source.len() && self.span.end <= source.len() {
            let word = &source[self.span.start..self.span.end];
            if !word.is_empty() && word.chars().all(|c| c.is_alphabetic()) {
                return Some(word);
            }
        }
        None
    }

    fn find_context<'a>(&self, source: &'a str) -> (usize, usize, &'a str) {
        let mut line_num = 1;
        let mut line_start = 0;

        for (i, c) in source.char_indices() {
            if i >= self.span.start {
                break;
            }
            if c == '\n' {
                line_num += 1;
                line_start = i + 1;
            }
        }

        let line_end = source[line_start..]
            .find('\n')
            .map(|off| line_start + off)
            .unwrap_or(source.len());

        (line_num, line_start, &source[line_start..line_end])
    }
}

#[derive(Debug, Clone)]
pub enum ParseErrorKind {
    UnexpectedToken {
        expected: TokenType,
        found: TokenType,
    },
    ExpectedContentWord {
        found: TokenType,
    },
    ExpectedCopula,
    UnknownQuantifier {
        found: TokenType,
    },
    UnknownModal {
        found: TokenType,
    },
    ExpectedVerb {
        found: TokenType,
    },
    ExpectedTemporalAdverb,
    ExpectedPresuppositionTrigger,
    ExpectedFocusParticle,
    ExpectedScopalAdverb,
    ExpectedSuperlativeAdjective,
    ExpectedComparativeAdjective,
    ExpectedThan,
    ExpectedNumber,
    EmptyRestriction,
    GappingResolutionFailed,
    StativeProgressiveConflict,
    UndefinedVariable {
        name: String,
    },
    UseAfterMove {
        name: String,
    },
    IsValueEquality {
        variable: String,
        value: String,
    },
    ZeroIndex,
    ExpectedStatement,
    ExpectedKeyword { keyword: String },
    ExpectedExpression,
    ExpectedIdentifier,
}

#[cold]
pub fn socratic_explanation(error: &ParseError, _interner: &Interner) -> String {
    let pos = error.span.start;
    match &error.kind {
        ParseErrorKind::UnexpectedToken { expected, found } => {
            format!(
                "I was following your logic, but I stumbled at position {}. \
                I expected {:?}, but found {:?}. Perhaps you meant to use a different word here?",
                pos, expected, found
            )
        }
        ParseErrorKind::ExpectedContentWord { found } => {
            format!(
                "I was looking for a noun, verb, or adjective at position {}, \
                but found {:?} instead. The logic needs a content word to ground it.",
                pos, found
            )
        }
        ParseErrorKind::ExpectedCopula => {
            format!(
                "At position {}, I expected 'is' or 'are' to link the subject and predicate. \
                Without it, the sentence structure is incomplete.",
                pos
            )
        }
        ParseErrorKind::UnknownQuantifier { found } => {
            format!(
                "At position {}, I found {:?} where I expected a quantifier like 'all', 'some', or 'no'. \
                These words tell me how many things we're talking about.",
                pos, found
            )
        }
        ParseErrorKind::UnknownModal { found } => {
            format!(
                "At position {}, I found {:?} where I expected a modal like 'must', 'can', or 'should'. \
                Modals express possibility, necessity, or obligation.",
                pos, found
            )
        }
        ParseErrorKind::ExpectedVerb { found } => {
            format!(
                "At position {}, I expected a verb to describe an action or state, \
                but found {:?}. Every sentence needs a verb.",
                pos, found
            )
        }
        ParseErrorKind::ExpectedTemporalAdverb => {
            format!(
                "At position {}, I expected a temporal adverb like 'yesterday' or 'tomorrow' \
                to anchor the sentence in time.",
                pos
            )
        }
        ParseErrorKind::ExpectedPresuppositionTrigger => {
            format!(
                "At position {}, I expected a presupposition trigger like 'stopped', 'realized', or 'regrets'. \
                These words carry hidden assumptions.",
                pos
            )
        }
        ParseErrorKind::ExpectedFocusParticle => {
            format!(
                "At position {}, I expected a focus particle like 'only', 'even', or 'just'. \
                These words highlight what's important in the sentence.",
                pos
            )
        }
        ParseErrorKind::ExpectedScopalAdverb => {
            format!(
                "At position {}, I expected a scopal adverb that modifies the entire proposition.",
                pos
            )
        }
        ParseErrorKind::ExpectedSuperlativeAdjective => {
            format!(
                "At position {}, I expected a superlative adjective like 'tallest' or 'fastest'. \
                These words compare one thing to all others.",
                pos
            )
        }
        ParseErrorKind::ExpectedComparativeAdjective => {
            format!(
                "At position {}, I expected a comparative adjective like 'taller' or 'faster'. \
                These words compare two things.",
                pos
            )
        }
        ParseErrorKind::ExpectedThan => {
            format!(
                "At position {}, I expected 'than' after the comparative. \
                Comparisons need 'than' to introduce the thing being compared to.",
                pos
            )
        }
        ParseErrorKind::ExpectedNumber => {
            format!(
                "At position {}, I expected a numeric value like '2', '3.14', or 'aleph_0'. \
                Measure phrases require a number.",
                pos
            )
        }
        ParseErrorKind::EmptyRestriction => {
            format!(
                "At position {}, the restriction clause is empty. \
                A relative clause needs content to restrict the noun phrase.",
                pos
            )
        }
        ParseErrorKind::GappingResolutionFailed => {
            format!(
                "At position {}, I see a gapped construction (like '...and Mary, a pear'), \
                but I couldn't find a verb in the previous clause to borrow. \
                Gapping requires a clear action to repeat.",
                pos
            )
        }
        ParseErrorKind::StativeProgressiveConflict => {
            format!(
                "At position {}, a stative verb like 'know' or 'love' cannot be used with progressive aspect. \
                Stative verbs describe states, not activities in progress.",
                pos
            )
        }
        ParseErrorKind::UndefinedVariable { name } => {
            format!(
                "At position {}, I found '{}' but this variable has not been defined. \
                In imperative mode, all variables must be declared before use.",
                pos, name
            )
        }
        ParseErrorKind::UseAfterMove { name } => {
            format!(
                "At position {}, I found '{}' but this value has been moved. \
                Once a value is moved, it cannot be used again.",
                pos, name
            )
        }
        ParseErrorKind::IsValueEquality { variable, value } => {
            format!(
                "At position {}, I found '{} is {}' but 'is' is for type/predicate checks. \
                For value equality, use '{} equals {}'.",
                pos, variable, value, variable, value
            )
        }
        ParseErrorKind::ZeroIndex => {
            format!(
                "At position {}, I found 'item 0' but indices in LOGOS start at 1. \
                In English, 'the 1st item' is the first item, not the zeroth. \
                Try 'item 1 of list' to get the first element.",
                pos
            )
        }
        ParseErrorKind::ExpectedStatement => {
            format!(
                "At position {}, I expected a statement like 'Let', 'Set', or 'Return'.",
                pos
            )
        }
        ParseErrorKind::ExpectedKeyword { keyword } => {
            format!(
                "At position {}, I expected the keyword '{}'.",
                pos, keyword
            )
        }
        ParseErrorKind::ExpectedExpression => {
            format!(
                "At position {}, I expected an expression (number, variable, or computation).",
                pos
            )
        }
        ParseErrorKind::ExpectedIdentifier => {
            format!(
                "At position {}, I expected an identifier (variable name).",
                pos
            )
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::token::Span;

    #[test]
    fn parse_error_has_span() {
        let error = ParseError {
            kind: ParseErrorKind::ExpectedCopula,
            span: Span::new(5, 10),
        };
        assert_eq!(error.span.start, 5);
        assert_eq!(error.span.end, 10);
    }

    #[test]
    fn display_with_source_shows_line_and_underline() {
        let error = ParseError {
            kind: ParseErrorKind::ExpectedCopula,
            span: Span::new(8, 14),
        };
        let source = "All men mortal are.";
        let display = error.display_with_source(source);
        assert!(display.contains("mortal"), "Should contain source word: {}", display);
        assert!(display.contains("^^^^^^"), "Should contain underline: {}", display);
    }

    #[test]
    fn display_with_source_suggests_typo_fix() {
        let error = ParseError {
            kind: ParseErrorKind::ExpectedCopula,
            span: Span::new(0, 5),
        };
        let source = "logoc is the study of reason.";
        let display = error.display_with_source(source);
        assert!(display.contains("did you mean"), "Should suggest fix: {}", display);
        assert!(display.contains("logic"), "Should suggest 'logic': {}", display);
    }

    #[test]
    fn display_with_source_has_color_codes() {
        let error = ParseError {
            kind: ParseErrorKind::ExpectedCopula,
            span: Span::new(0, 3),
        };
        let source = "Alll men are mortal.";
        let display = error.display_with_source(source);
        assert!(display.contains("\x1b["), "Should contain ANSI escape codes: {}", display);
    }
}

```

---

## Suggestions & Styling

Compiler-style error presentation with typo correction and ANSI colors.

**Location:** `src/suggest.rs`, `src/style.rs`

### Typo Suggestions

**File:** `src/suggest.rs`

Zero-dependency Levenshtein distance algorithm. find_similar() finds closest vocabulary match for 'did you mean?' suggestions in error messages.

```rust
pub fn levenshtein(a: &str, b: &str) -> usize {
    let a_chars: Vec<char> = a.chars().collect();
    let b_chars: Vec<char> = b.chars().collect();
    let m = a_chars.len();
    let n = b_chars.len();

    if m == 0 {
        return n;
    }
    if n == 0 {
        return m;
    }

    let mut prev: Vec<usize> = (0..=n).collect();
    let mut curr = vec![0; n + 1];

    for i in 1..=m {
        curr[0] = i;
        for j in 1..=n {
            let cost = if a_chars[i - 1] == b_chars[j - 1] { 0 } else { 1 };
            curr[j] = (prev[j] + 1)
                .min(curr[j - 1] + 1)
                .min(prev[j - 1] + cost);
        }
        std::mem::swap(&mut prev, &mut curr);
    }

    prev[n]
}

pub fn find_similar<'a>(word: &str, candidates: &[&'a str], max_distance: usize) -> Option<&'a str> {
    let word_lower = word.to_lowercase();
    let mut best: Option<(&str, usize)> = None;

    for &candidate in candidates {
        let dist = levenshtein(&word_lower, &candidate.to_lowercase());
        if dist <= max_distance {
            match best {
                None => best = Some((candidate, dist)),
                Some((_, d)) if dist < d => best = Some((candidate, dist)),
                _ => {}
            }
        }
    }

    best.map(|(s, _)| s)
}

pub const KNOWN_WORDS: &[&str] = &[
    "all", "some", "no", "most", "few", "every",
    "the", "a", "an", "this", "that",
    "is", "are", "was", "were", "be",
    "and", "or", "if", "then", "not",
    "must", "can", "may", "should", "would", "could",
    "who", "what", "where", "when", "why", "how",
    "man", "men", "woman", "women", "dog", "cat", "bird",
    "mortal", "happy", "sad", "tall", "fast", "slow",
    "loves", "runs", "sees", "knows", "thinks",
    "logic", "reason", "truth", "false",
    "John", "Mary", "Socrates", "Aristotle",
    "to", "by", "with", "from", "for", "in", "on", "at",
    "himself", "herself", "itself", "themselves",
    "he", "she", "it", "they", "him", "her", "them",
];

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn levenshtein_identical() {
        assert_eq!(levenshtein("hello", "hello"), 0);
    }

    #[test]
    fn levenshtein_one_char_diff() {
        assert_eq!(levenshtein("hello", "hallo"), 1);
    }

    #[test]
    fn levenshtein_insertion() {
        assert_eq!(levenshtein("hello", "helllo"), 1);
    }

    #[test]
    fn levenshtein_deletion() {
        assert_eq!(levenshtein("hello", "helo"), 1);
    }

    #[test]
    fn levenshtein_empty() {
        assert_eq!(levenshtein("", "abc"), 3);
        assert_eq!(levenshtein("abc", ""), 3);
    }

    #[test]
    fn levenshtein_transposition() {
        assert_eq!(levenshtein("ab", "ba"), 2);
    }

    #[test]
    fn find_similar_typo() {
        let result = find_similar("logoc", KNOWN_WORDS, 2);
        assert_eq!(result, Some("logic"));
    }

    #[test]
    fn find_similar_no_match() {
        let result = find_similar("xyzzy", KNOWN_WORDS, 2);
        assert_eq!(result, None);
    }

    #[test]
    fn find_similar_case_insensitive() {
        let result = find_similar("LOGIC", KNOWN_WORDS, 2);
        assert_eq!(result, Some("logic"));
    }
}

```

---

### ANSI Styling

**File:** `src/style.rs`

Style struct with red(), blue(), cyan(), green(), bold_red() methods for terminal color output. Integrated into display_with_source() for compiler-style error presentation.

```rust
pub struct Style;

impl Style {
    pub const RESET: &'static str = "\x1b[0m";
    pub const BOLD: &'static str = "\x1b[1m";
    pub const RED: &'static str = "\x1b[31m";
    pub const GREEN: &'static str = "\x1b[32m";
    pub const YELLOW: &'static str = "\x1b[33m";
    pub const BLUE: &'static str = "\x1b[34m";
    pub const CYAN: &'static str = "\x1b[36m";

    pub fn red(s: &str) -> String {
        format!("{}{}{}", Self::RED, s, Self::RESET)
    }

    pub fn blue(s: &str) -> String {
        format!("{}{}{}", Self::BLUE, s, Self::RESET)
    }

    pub fn cyan(s: &str) -> String {
        format!("{}{}{}", Self::CYAN, s, Self::RESET)
    }

    pub fn yellow(s: &str) -> String {
        format!("{}{}{}", Self::YELLOW, s, Self::RESET)
    }

    pub fn green(s: &str) -> String {
        format!("{}{}{}", Self::GREEN, s, Self::RESET)
    }

    pub fn bold(s: &str) -> String {
        format!("{}{}{}", Self::BOLD, s, Self::RESET)
    }

    pub fn bold_red(s: &str) -> String {
        format!("{}{}{}{}", Self::BOLD, Self::RED, s, Self::RESET)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn red_wraps_string() {
        let result = Style::red("error");
        assert!(result.contains("\x1b[31m"));
        assert!(result.contains("error"));
        assert!(result.contains("\x1b[0m"));
    }

    #[test]
    fn bold_red_combines_codes() {
        let result = Style::bold_red("Error");
        assert!(result.contains("\x1b[1m"));
        assert!(result.contains("\x1b[31m"));
    }
}

```

---

## Debug Utilities

Development and introspection tools.

**Location:** `src/debug.rs`

### Debug Tools

**File:** `src/debug.rs`

DebugWorld for AST introspection. DisplayWith trait for custom formatting during development. Includes Causal expression display support.

```rust
use std::fmt;

use crate::ast::{
    AspectOperator, LogicExpr, NounPhrase, QuantifierKind, TemporalOperator, VoiceOperator, Term,
};
use crate::intern::{Interner, Symbol};
use crate::token::TokenType;

pub trait DisplayWith {
    fn fmt_with(&self, interner: &Interner, f: &mut fmt::Formatter<'_>) -> fmt::Result;

    fn with<'a>(&'a self, interner: &'a Interner) -> WithInterner<'a, Self> {
        WithInterner {
            target: self,
            interner,
        }
    }
}

pub struct WithInterner<'a, T: ?Sized> {
    pub target: &'a T,
    pub interner: &'a Interner,
}

impl<'a, T: DisplayWith> fmt::Display for WithInterner<'a, T> {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        self.target.fmt_with(self.interner, f)
    }
}

pub struct DebugWorld<'a, T: ?Sized> {
    pub target: &'a T,
    pub interner: &'a Interner,
}

impl<'a, T: DisplayWith> fmt::Debug for DebugWorld<'a, T> {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        self.target.fmt_with(self.interner, f)
    }
}

impl DisplayWith for Symbol {
    fn fmt_with(&self, interner: &Interner, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(f, "{}", interner.resolve(*self))
    }
}

impl<'a> DisplayWith for Term<'a> {
    fn fmt_with(&self, interner: &Interner, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            Term::Constant(s) => write!(f, "{}", interner.resolve(*s)),
            Term::Variable(s) => write!(f, "{}", interner.resolve(*s)),
            Term::Function(name, args) => {
                write!(f, "{}(", interner.resolve(*name))?;
                for (i, arg) in args.iter().enumerate() {
                    if i > 0 {
                        write!(f, ", ")?;
                    }
                    arg.fmt_with(interner, f)?;
                }
                write!(f, ")")
            }
            Term::Group(members) => {
                write!(f, "[")?;
                for (i, m) in members.iter().enumerate() {
                    if i > 0 {
                        write!(f, " ⊕ ")?;
                    }
                    m.fmt_with(interner, f)?;
                }
                write!(f, "]")
            }
            Term::Possessed { possessor, possessed } => {
                possessor.fmt_with(interner, f)?;
                write!(f, ".{}", interner.resolve(*possessed))
            }
            Term::Sigma(predicate) => {
                write!(f, "σx.{}(x)", interner.resolve(*predicate))
            }
            Term::Intension(predicate) => {
                write!(f, "^{}", interner.resolve(*predicate))
            }
            Term::Proposition(expr) => {
                write!(f, "[{:?}]", expr)
            }
            Term::Value { kind, unit, dimension } => {
                use crate::ast::NumberKind;
                match kind {
                    NumberKind::Real(r) => write!(f, "{}", r)?,
                    NumberKind::Integer(i) => write!(f, "{}", i)?,
                    NumberKind::Symbolic(s) => write!(f, "{}", interner.resolve(*s))?,
                }
                if let Some(u) = unit {
                    write!(f, " {}", interner.resolve(*u))?;
                }
                if let Some(d) = dimension {
                    write!(f, " [{:?}]", d)?;
                }
                Ok(())
            }
        }
    }
}

impl<'a> DisplayWith for NounPhrase<'a> {
    fn fmt_with(&self, interner: &Interner, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        if let Some(def) = &self.definiteness {
            write!(f, "{:?} ", def)?;
        }
        for adj in self.adjectives {
            write!(f, "{} ", interner.resolve(*adj))?;
        }
        write!(f, "{}", interner.resolve(self.noun))
    }
}

impl<'a> DisplayWith for LogicExpr<'a> {
    fn fmt_with(&self, interner: &Interner, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            LogicExpr::Predicate { name, args } => {
                write!(f, "{}(", interner.resolve(*name))?;
                for (i, arg) in args.iter().enumerate() {
                    if i > 0 {
                        write!(f, ", ")?;
                    }
                    arg.fmt_with(interner, f)?;
                }
                write!(f, ")")
            }
            LogicExpr::Identity { left, right } => {
                left.fmt_with(interner, f)?;
                write!(f, " = ")?;
                right.fmt_with(interner, f)
            }
            LogicExpr::Metaphor { tenor, vehicle } => {
                write!(f, "Metaphor(")?;
                tenor.fmt_with(interner, f)?;
                write!(f, ", ")?;
                vehicle.fmt_with(interner, f)?;
                write!(f, ")")
            }
            LogicExpr::Quantifier { kind, variable, body, .. } => {
                let q = match kind {
                    QuantifierKind::Universal => "∀",
                    QuantifierKind::Existential => "∃",
                    QuantifierKind::Most => "MOST",
                    QuantifierKind::Few => "FEW",
                    QuantifierKind::Many => "MANY",
                    QuantifierKind::Generic => "Gen",
                    QuantifierKind::Cardinal(n) => return write!(f, "∃={}{}.{}", n, interner.resolve(*variable), body.with(interner)),
                    QuantifierKind::AtLeast(n) => return write!(f, "∃≥{}{}.{}", n, interner.resolve(*variable), body.with(interner)),
                    QuantifierKind::AtMost(n) => return write!(f, "∃≤{}{}.{}", n, interner.resolve(*variable), body.with(interner)),
                };
                write!(f, "{}{}.{}", q, interner.resolve(*variable), body.with(interner))
            }
            LogicExpr::Categorical(data) => {
                let q = match &data.quantifier {
                    TokenType::All => "All",
                    TokenType::Some => "Some",
                    TokenType::No => "No",
                    _ => "?",
                };
                let cop = if data.copula_negative { "are not" } else { "are" };
                write!(f, "{} {} {} {}", q, data.subject.with(interner), cop, data.predicate.with(interner))
            }
            LogicExpr::Relation(data) => {
                write!(f, "{}({}, {})", interner.resolve(data.verb), data.subject.with(interner), data.object.with(interner))
            }
            LogicExpr::Modal { vector, operand } => {
                let op = match (vector.domain, vector.force >= 0.5) {
                    (crate::ast::ModalDomain::Alethic, true) => "□",
                    (crate::ast::ModalDomain::Alethic, false) => "◇",
                    (crate::ast::ModalDomain::Deontic, true) => "O",
                    (crate::ast::ModalDomain::Deontic, false) => "P",
                };
                write!(f, "{}({})", op, operand.with(interner))
            }
            LogicExpr::Temporal { operator, body } => {
                let op = match operator {
                    TemporalOperator::Past => "P",
                    TemporalOperator::Future => "F",
                };
                write!(f, "{}({})", op, body.with(interner))
            }
            LogicExpr::Aspectual { operator, body } => {
                let op = match operator {
                    AspectOperator::Progressive => "PROG",
                    AspectOperator::Perfect => "PERF",
                    AspectOperator::Habitual => "HAB",
                    AspectOperator::Iterative => "ITER",
                };
                write!(f, "{}({})", op, body.with(interner))
            }
            LogicExpr::Voice { operator, body } => {
                let op = match operator {
                    VoiceOperator::Passive => "PASS",
                };
                write!(f, "{}({})", op, body.with(interner))
            }
            LogicExpr::BinaryOp { left, op, right } => {
                let sym = match op {
                    TokenType::And => "∧",
                    TokenType::Or => "∨",
                    TokenType::If => "→",
                    TokenType::Iff => "↔",
                    _ => "?",
                };
                write!(f, "({} {} {})", left.with(interner), sym, right.with(interner))
            }
            LogicExpr::UnaryOp { op, operand } => {
                let sym = match op {
                    TokenType::Not => "¬",
                    _ => "?",
                };
                write!(f, "{}({})", sym, operand.with(interner))
            }
            LogicExpr::Question { wh_variable, body } => {
                write!(f, "?{}.{}", interner.resolve(*wh_variable), body.with(interner))
            }
            LogicExpr::YesNoQuestion { body } => {
                write!(f, "?{}", body.with(interner))
            }
            LogicExpr::Atom(s) => write!(f, "{}", interner.resolve(*s)),
            LogicExpr::Lambda { variable, body } => {
                write!(f, "λ{}.{}", interner.resolve(*variable), body.with(interner))
            }
            LogicExpr::App { function, argument } => {
                write!(f, "({})({})", function.with(interner), argument.with(interner))
            }
            LogicExpr::Intensional { operator, content } => {
                write!(f, "{}({})", interner.resolve(*operator), content.with(interner))
            }
            LogicExpr::Event { predicate, adverbs } => {
                predicate.fmt_with(interner, f)?;
                for adv in *adverbs {
                    write!(f, "[{}]", interner.resolve(*adv))?;
                }
                Ok(())
            }
            LogicExpr::NeoEvent(data) => {
                write!(f, "∃{}({}({})", interner.resolve(data.event_var), interner.resolve(data.verb), interner.resolve(data.event_var))?;
                for (role, term) in data.roles.iter() {
                    write!(f, " ∧ {:?}({}, {})", role, interner.resolve(data.event_var), term.with(interner))?;
                }
                for mod_sym in data.modifiers.iter() {
                    write!(f, " ∧ {}({})", interner.resolve(*mod_sym), interner.resolve(data.event_var))?;
                }
                write!(f, ")")
            }
            LogicExpr::Imperative { action } => {
                write!(f, "!({})", action.with(interner))
            }
            LogicExpr::SpeechAct { performer, act_type, content } => {
                write!(f, "{}:{}({})", interner.resolve(*performer), interner.resolve(*act_type), content.with(interner))
            }
            LogicExpr::Counterfactual { antecedent, consequent } => {
                write!(f, "({} □→ {})", antecedent.with(interner), consequent.with(interner))
            }
            LogicExpr::Causal { effect, cause } => {
                write!(f, "Cause({}, {})", cause.with(interner), effect.with(interner))
            }
            LogicExpr::Comparative { adjective, subject, object, difference } => {
                if let Some(diff) = difference {
                    write!(f, "{}({}, {}, by: {})", interner.resolve(*adjective), subject.with(interner), object.with(interner), diff.with(interner))
                } else {
                    write!(f, "{}({}, {})", interner.resolve(*adjective), subject.with(interner), object.with(interner))
                }
            }
            LogicExpr::Superlative { adjective, subject, domain } => {
                write!(f, "MOST-{}({}, {})", interner.resolve(*adjective), subject.with(interner), interner.resolve(*domain))
            }
            LogicExpr::Scopal { operator, body } => {
                write!(f, "{}({})", interner.resolve(*operator), body.with(interner))
            }
            LogicExpr::Control { verb, subject, object, infinitive } => {
                write!(f, "{}(", interner.resolve(*verb))?;
                subject.fmt_with(interner, f)?;
                if let Some(obj) = object {
                    write!(f, ", ")?;
                    obj.fmt_with(interner, f)?;
                }
                write!(f, ", {})", infinitive.with(interner))
            }
            LogicExpr::Presupposition { assertion, presupposition } => {
                write!(f, "[{} | {}]", assertion.with(interner), presupposition.with(interner))
            }
            LogicExpr::Focus { kind, focused, scope } => {
                let k = match kind {
                    crate::token::FocusKind::Only => "ONLY",
                    crate::token::FocusKind::Even => "EVEN",
                    crate::token::FocusKind::Just => "JUST",
                };
                write!(f, "{}[", k)?;
                focused.fmt_with(interner, f)?;
                write!(f, "]({})", scope.with(interner))
            }
            LogicExpr::TemporalAnchor { anchor, body } => {
                write!(f, "@{}({})", interner.resolve(*anchor), body.with(interner))
            }
            LogicExpr::Distributive { predicate } => {
                write!(f, "*")?;
                predicate.fmt_with(interner, f)
            }
            LogicExpr::GroupQuantifier { group_var, count, member_var, restriction, body } => {
                write!(
                    f,
                    "∃{}(Group({}) ∧ Count({}, {}) ∧ ∀{}(Member({}, {}) → ",
                    interner.resolve(*group_var),
                    interner.resolve(*group_var),
                    interner.resolve(*group_var),
                    count,
                    interner.resolve(*member_var),
                    interner.resolve(*member_var),
                    interner.resolve(*group_var)
                )?;
                restriction.fmt_with(interner, f)?;
                write!(f, ") ∧ ")?;
                body.fmt_with(interner, f)?;
                write!(f, ")")
            }
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::arena::Arena;

    #[test]
    fn symbol_display_with_interner() {
        let mut interner = Interner::new();
        let sym = interner.intern("Socrates");
        assert_eq!(sym.with(&interner).to_string(), "Socrates");
    }

    #[test]
    fn symbol_empty_displays_empty() {
        let interner = Interner::new();
        assert_eq!(Symbol::EMPTY.with(&interner).to_string(), "");
    }

    #[test]
    fn term_constant_display() {
        let mut interner = Interner::new();
        let sym = interner.intern("John");
        let term = Term::Constant(sym);
        assert_eq!(term.with(&interner).to_string(), "John");
    }

    #[test]
    fn term_variable_display() {
        let mut interner = Interner::new();
        let x = interner.intern("x");
        let term = Term::Variable(x);
        assert_eq!(term.with(&interner).to_string(), "x");
    }

    #[test]
    fn term_function_display() {
        let mut interner = Interner::new();
        let term_arena: Arena<Term> = Arena::new();
        let f = interner.intern("father");
        let j = interner.intern("John");
        let term = Term::Function(f, term_arena.alloc_slice([Term::Constant(j)]));
        assert_eq!(term.with(&interner).to_string(), "father(John)");
    }

    #[test]
    fn term_group_display() {
        let mut interner = Interner::new();
        let term_arena: Arena<Term> = Arena::new();
        let j = interner.intern("John");
        let m = interner.intern("Mary");
        let term = Term::Group(term_arena.alloc_slice([Term::Constant(j), Term::Constant(m)]));
        assert_eq!(term.with(&interner).to_string(), "[John ⊕ Mary]");
    }

    #[test]
    fn term_possessed_display() {
        let mut interner = Interner::new();
        let term_arena: Arena<Term> = Arena::new();
        let j = interner.intern("John");
        let dog = interner.intern("dog");
        let term = Term::Possessed {
            possessor: term_arena.alloc(Term::Constant(j)),
            possessed: dog,
        };
        assert_eq!(term.with(&interner).to_string(), "John.dog");
    }

    #[test]
    fn expr_predicate_display() {
        let mut interner = Interner::new();
        let term_arena: Arena<Term> = Arena::new();
        let mortal = interner.intern("Mortal");
        let x = interner.intern("x");
        let expr = LogicExpr::Predicate {
            name: mortal,
            args: term_arena.alloc_slice([Term::Variable(x)]),
        };
        assert_eq!(expr.with(&interner).to_string(), "Mortal(x)");
    }

    #[test]
    fn expr_quantifier_display() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();
        let x = interner.intern("x");
        let mortal = interner.intern("Mortal");
        let body = expr_arena.alloc(LogicExpr::Predicate {
            name: mortal,
            args: term_arena.alloc_slice([Term::Variable(x)]),
        });
        let expr = LogicExpr::Quantifier {
            kind: QuantifierKind::Universal,
            variable: x,
            body,
            island_id: 0,
        };
        assert_eq!(expr.with(&interner).to_string(), "∀x.Mortal(x)");
    }

    #[test]
    fn expr_atom_display() {
        let mut interner = Interner::new();
        let p = interner.intern("P");
        let expr = LogicExpr::Atom(p);
        assert_eq!(expr.with(&interner).to_string(), "P");
    }

    #[test]
    fn expr_binary_op_display() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let p = interner.intern("P");
        let q = interner.intern("Q");
        let expr = LogicExpr::BinaryOp {
            left: expr_arena.alloc(LogicExpr::Atom(p)),
            op: TokenType::And,
            right: expr_arena.alloc(LogicExpr::Atom(q)),
        };
        assert_eq!(expr.with(&interner).to_string(), "(P ∧ Q)");
    }

    #[test]
    fn expr_lambda_display() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let x = interner.intern("x");
        let p = interner.intern("P");
        let expr = LogicExpr::Lambda {
            variable: x,
            body: expr_arena.alloc(LogicExpr::Atom(p)),
        };
        assert_eq!(expr.with(&interner).to_string(), "λx.P");
    }

    #[test]
    fn debug_world_works_with_dbg_pattern() {
        let mut interner = Interner::new();
        let sym = interner.intern("test");
        let term = Term::Constant(sym);
        let debug_str = format!("{:?}", DebugWorld { target: &term, interner: &interner });
        assert!(debug_str.contains("test"));
    }

    #[test]
    fn expr_temporal_display() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let p = interner.intern("Run");
        let expr = LogicExpr::Temporal {
            operator: TemporalOperator::Past,
            body: expr_arena.alloc(LogicExpr::Atom(p)),
        };
        assert_eq!(expr.with(&interner).to_string(), "P(Run)");
    }

    #[test]
    fn expr_modal_display() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let p = interner.intern("Rain");
        let expr = LogicExpr::Modal {
            vector: crate::ast::ModalVector {
                domain: crate::ast::ModalDomain::Alethic,
                force: 1.0,
            },
            operand: expr_arena.alloc(LogicExpr::Atom(p)),
        };
        assert_eq!(expr.with(&interner).to_string(), "□(Rain)");
    }
}

```

---

## Visitor Pattern

Tree traversal infrastructure for AST analysis.

**Location:** `src/visitor.rs`

### Visitor Trait

**File:** `src/visitor.rs`

Visitor trait with walk_expr() and walk_term() functions for AST traversal. Enables analysis passes without manual recursion.

```rust
use crate::ast::{LogicExpr, NounPhrase, Term};

pub trait Visitor<'a>: Sized {
    fn visit_expr(&mut self, expr: &'a LogicExpr<'a>) {
        walk_expr(self, expr);
    }

    fn visit_term(&mut self, term: &'a Term<'a>) {
        walk_term(self, term);
    }

    fn visit_np(&mut self, np: &'a NounPhrase<'a>) {
        walk_np(self, np);
    }
}

pub fn walk_expr<'a, V: Visitor<'a>>(v: &mut V, expr: &'a LogicExpr<'a>) {
    match expr {
        LogicExpr::Predicate { args, .. } => {
            for arg in *args {
                v.visit_term(arg);
            }
        }

        LogicExpr::Identity { left, right } => {
            v.visit_term(left);
            v.visit_term(right);
        }

        LogicExpr::Metaphor { tenor, vehicle } => {
            v.visit_term(tenor);
            v.visit_term(vehicle);
        }

        LogicExpr::Quantifier { body, .. } => {
            v.visit_expr(body);
        }

        LogicExpr::Categorical(data) => {
            v.visit_np(&data.subject);
            v.visit_np(&data.predicate);
        }

        LogicExpr::Relation(data) => {
            v.visit_np(&data.subject);
            v.visit_np(&data.object);
        }

        LogicExpr::Modal { operand, .. } => {
            v.visit_expr(operand);
        }

        LogicExpr::Temporal { body, .. } => {
            v.visit_expr(body);
        }

        LogicExpr::Aspectual { body, .. } => {
            v.visit_expr(body);
        }

        LogicExpr::Voice { body, .. } => {
            v.visit_expr(body);
        }

        LogicExpr::BinaryOp { left, right, .. } => {
            v.visit_expr(left);
            v.visit_expr(right);
        }

        LogicExpr::UnaryOp { operand, .. } => {
            v.visit_expr(operand);
        }

        LogicExpr::Question { body, .. } => {
            v.visit_expr(body);
        }

        LogicExpr::YesNoQuestion { body } => {
            v.visit_expr(body);
        }

        LogicExpr::Atom(_) => {}

        LogicExpr::Lambda { body, .. } => {
            v.visit_expr(body);
        }

        LogicExpr::App { function, argument } => {
            v.visit_expr(function);
            v.visit_expr(argument);
        }

        LogicExpr::Intensional { content, .. } => {
            v.visit_expr(content);
        }

        LogicExpr::Event { predicate, .. } => {
            v.visit_expr(predicate);
        }

        LogicExpr::NeoEvent(data) => {
            for (_, term) in data.roles.iter() {
                v.visit_term(term);
            }
        }

        LogicExpr::Imperative { action } => {
            v.visit_expr(action);
        }

        LogicExpr::SpeechAct { content, .. } => {
            v.visit_expr(content);
        }

        LogicExpr::Counterfactual { antecedent, consequent } => {
            v.visit_expr(antecedent);
            v.visit_expr(consequent);
        }

        LogicExpr::Causal { effect, cause } => {
            v.visit_expr(cause);
            v.visit_expr(effect);
        }

        LogicExpr::Comparative { subject, object, .. } => {
            v.visit_term(subject);
            v.visit_term(object);
        }

        LogicExpr::Superlative { subject, .. } => {
            v.visit_term(subject);
        }

        LogicExpr::Scopal { body, .. } => {
            v.visit_expr(body);
        }

        LogicExpr::Control { subject, object, infinitive, .. } => {
            v.visit_term(subject);
            if let Some(obj) = object {
                v.visit_term(obj);
            }
            v.visit_expr(infinitive);
        }

        LogicExpr::Presupposition { assertion, presupposition } => {
            v.visit_expr(assertion);
            v.visit_expr(presupposition);
        }

        LogicExpr::Focus { focused, scope, .. } => {
            v.visit_term(focused);
            v.visit_expr(scope);
        }

        LogicExpr::TemporalAnchor { body, .. } => {
            v.visit_expr(body);
        }

        LogicExpr::Distributive { predicate } => {
            v.visit_expr(predicate);
        }

        LogicExpr::GroupQuantifier { restriction, body, .. } => {
            v.visit_expr(restriction);
            v.visit_expr(body);
        }
    }
}

pub fn walk_term<'a, V: Visitor<'a>>(v: &mut V, term: &'a Term<'a>) {
    match term {
        Term::Constant(_) | Term::Variable(_) | Term::Sigma(_) | Term::Intension(_) | Term::Value { .. } => {}

        Term::Function(_, args) => {
            for arg in *args {
                v.visit_term(arg);
            }
        }

        Term::Group(members) => {
            for m in *members {
                v.visit_term(m);
            }
        }

        Term::Possessed { possessor, .. } => {
            v.visit_term(possessor);
        }

        Term::Proposition(expr) => {
            v.visit_expr(expr);
        }
    }
}

pub fn walk_np<'a, V: Visitor<'a>>(v: &mut V, np: &'a NounPhrase<'a>) {
    if let Some(poss) = np.possessor {
        v.visit_np(poss);
    }
    for pp in np.pps.iter() {
        v.visit_expr(pp);
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::intern::Symbol;

    struct VariableCollector {
        variables: Vec<Symbol>,
    }

    impl<'a> Visitor<'a> for VariableCollector {
        fn visit_term(&mut self, term: &'a Term<'a>) {
            if let Term::Variable(sym) = term {
                self.variables.push(*sym);
            }
            walk_term(self, term);
        }
    }

    struct ExprCounter {
        count: usize,
    }

    impl<'a> Visitor<'a> for ExprCounter {
        fn visit_expr(&mut self, expr: &'a LogicExpr<'a>) {
            self.count += 1;
            walk_expr(self, expr);
        }
    }

    #[test]
    fn variable_collector_finds_variables() {
        use crate::arena::Arena;
        use crate::intern::Interner;

        let mut interner = Interner::new();
        let x = interner.intern("x");
        let y = interner.intern("y");

        let term_arena: Arena<Term> = Arena::new();
        let terms = term_arena.alloc_slice([Term::Variable(x), Term::Variable(y)]);

        let expr_arena: Arena<LogicExpr> = Arena::new();
        let pred = interner.intern("P");
        let expr = expr_arena.alloc(LogicExpr::Predicate { name: pred, args: terms });

        let mut collector = VariableCollector { variables: vec![] };
        collector.visit_expr(expr);

        assert_eq!(collector.variables.len(), 2);
        assert!(collector.variables.contains(&x));
        assert!(collector.variables.contains(&y));
    }

    #[test]
    fn expr_counter_counts_nested() {
        use crate::arena::Arena;
        use crate::intern::Interner;
        use crate::token::TokenType;

        let mut interner = Interner::new();
        let p = interner.intern("P");
        let q = interner.intern("Q");

        let expr_arena: Arena<LogicExpr> = Arena::new();

        let left = expr_arena.alloc(LogicExpr::Atom(p));
        let right = expr_arena.alloc(LogicExpr::Atom(q));
        let binary = expr_arena.alloc(LogicExpr::BinaryOp {
            left,
            op: TokenType::And,
            right,
        });

        let mut counter = ExprCounter { count: 0 };
        counter.visit_expr(binary);

        assert_eq!(counter.count, 3);
    }
}

```

---

## Test Utilities

Helper functions for unit and integration testing.

**Location:** `src/test_utils.rs`

### Test Helpers

**File:** `src/test_utils.rs`

Utility functions for constructing test cases and validating transpilation output. assert_snapshot! macro for golden master testing. Snapshots stored in tests/snapshots/. Set UPDATE_SNAPSHOTS=1 to regenerate.

```rust
use crate::ast::{AspectOperator, ModalDomain, ModalVector, QuantifierKind, TemporalOperator};
use crate::token::{FocusKind, TokenType};
use crate::view::{ExprView, NounPhraseView, TermView};
use crate::lexicon::Definiteness;

#[macro_export]
macro_rules! assert_snapshot {
    ($name:expr, $actual:expr) => {{
        let manifest_dir = std::env::var("CARGO_MANIFEST_DIR")
            .expect("CARGO_MANIFEST_DIR not set");
        let snapshot_dir = std::path::Path::new(&manifest_dir)
            .join("tests")
            .join("snapshots");
        let snapshot_path = snapshot_dir.join(format!("{}.txt", $name));

        if !snapshot_dir.exists() {
            std::fs::create_dir_all(&snapshot_dir).expect("Failed to create snapshot dir");
        }

        let actual_str = $actual.trim();
        let force_update = std::env::var("UPDATE_SNAPSHOTS").is_ok();

        if force_update || !snapshot_path.exists() {
            std::fs::write(&snapshot_path, actual_str).expect("Failed to write snapshot");
            println!("Snapshot created/updated: {:?}", snapshot_path);
        } else {
            let expected = std::fs::read_to_string(&snapshot_path)
                .expect("Failed to read snapshot");
            let expected_str = expected.trim();

            if actual_str != expected_str {
                panic!(
                    "\nSnapshot Mismatch: {}\n\nExpected:\n{}\n\nActual:\n{}\n\n\
                    Run `UPDATE_SNAPSHOTS=1 cargo test` to update.\n",
                    $name, expected_str, actual_str
                );
            }
        }
    }};
}

#[macro_export]
macro_rules! parse {
    ($input:expr) => {{
        use $crate::{Arena, AstContext, LogicExpr, Interner, Lexer, NounPhrase, Parser, Resolve, Symbol, Term, ThematicRole};

        let interner: &'static mut Interner = Box::leak(Box::new(Interner::new()));
        let expr_arena: &'static Arena<LogicExpr> = Box::leak(Box::new(Arena::new()));
        let term_arena: &'static Arena<Term> = Box::leak(Box::new(Arena::new()));
        let np_arena: &'static Arena<NounPhrase> = Box::leak(Box::new(Arena::new()));
        let sym_arena: &'static Arena<Symbol> = Box::leak(Box::new(Arena::new()));
        let role_arena: &'static Arena<(ThematicRole, Term)> = Box::leak(Box::new(Arena::new()));
        let pp_arena: &'static Arena<&'static LogicExpr> = Box::leak(Box::new(Arena::new()));

        let ctx = AstContext::new(
            expr_arena,
            term_arena,
            np_arena,
            sym_arena,
            role_arena,
            pp_arena,
        );

        let mut lexer = Lexer::new($input, interner);
        let tokens = lexer.tokenize();

        let mut parser = Parser::new(tokens, interner, ctx);

        let ast = parser.parse().unwrap();
        ast.resolve(interner)
    }};
}

pub mod dsl {
    use super::*;

    fn b<T>(t: T) -> Box<T> {
        Box::new(t)
    }

    // === Terms ===
    pub fn c(name: &'static str) -> TermView<'static> {
        TermView::Constant(name)
    }

    pub fn v(name: &'static str) -> TermView<'static> {
        TermView::Variable(name)
    }

    pub fn func(name: &'static str, args: Vec<TermView<'static>>) -> TermView<'static> {
        TermView::Function(name, args)
    }

    pub fn group(members: Vec<TermView<'static>>) -> TermView<'static> {
        TermView::Group(members)
    }

    pub fn possessed(possessor: TermView<'static>, possessed: &'static str) -> TermView<'static> {
        TermView::Possessed {
            possessor: b(possessor),
            possessed,
        }
    }

    // === Atoms & Predicates ===
    pub fn atom(s: &'static str) -> ExprView<'static> {
        ExprView::Atom(s)
    }

    pub fn pred(name: &'static str, args: Vec<TermView<'static>>) -> ExprView<'static> {
        ExprView::Predicate { name, args }
    }

    pub fn pred1(name: &'static str, arg: &'static str) -> ExprView<'static> {
        pred(name, vec![c(arg)])
    }

    pub fn pred1v(name: &'static str, var: &'static str) -> ExprView<'static> {
        pred(name, vec![v(var)])
    }

    pub fn pred2(name: &'static str, a1: &'static str, a2: &'static str) -> ExprView<'static> {
        pred(name, vec![c(a1), c(a2)])
    }

    pub fn pred2v(name: &'static str, v1: &'static str, v2: &'static str) -> ExprView<'static> {
        pred(name, vec![v(v1), v(v2)])
    }

    // === Identity ===
    pub fn identity(left: TermView<'static>, right: TermView<'static>) -> ExprView<'static> {
        ExprView::Identity { left, right }
    }

    // === Quantifiers ===
    pub fn forall(var: &'static str, body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Quantifier {
            kind: QuantifierKind::Universal,
            variable: var,
            body: b(body),
        }
    }

    pub fn exists(var: &'static str, body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Quantifier {
            kind: QuantifierKind::Existential,
            variable: var,
            body: b(body),
        }
    }

    pub fn most(var: &'static str, body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Quantifier {
            kind: QuantifierKind::Most,
            variable: var,
            body: b(body),
        }
    }

    pub fn few(var: &'static str, body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Quantifier {
            kind: QuantifierKind::Few,
            variable: var,
            body: b(body),
        }
    }

    pub fn cardinal(n: u32, var: &'static str, body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Quantifier {
            kind: QuantifierKind::Cardinal(n),
            variable: var,
            body: b(body),
        }
    }

    pub fn at_least(n: u32, var: &'static str, body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Quantifier {
            kind: QuantifierKind::AtLeast(n),
            variable: var,
            body: b(body),
        }
    }

    pub fn at_most(n: u32, var: &'static str, body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Quantifier {
            kind: QuantifierKind::AtMost(n),
            variable: var,
            body: b(body),
        }
    }

    // === Temporal ===
    pub fn past(body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Temporal {
            operator: TemporalOperator::Past,
            body: b(body),
        }
    }

    pub fn future(body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Temporal {
            operator: TemporalOperator::Future,
            body: b(body),
        }
    }

    // === Aspect ===
    pub fn prog(body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Aspectual {
            operator: AspectOperator::Progressive,
            body: b(body),
        }
    }

    pub fn perf(body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Aspectual {
            operator: AspectOperator::Perfect,
            body: b(body),
        }
    }

    // === Modal ===
    pub fn necessity(body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Modal {
            vector: ModalVector {
                domain: ModalDomain::Alethic,
                force: 1.0,
            },
            operand: b(body),
        }
    }

    pub fn possibility(body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Modal {
            vector: ModalVector {
                domain: ModalDomain::Alethic,
                force: 0.0,
            },
            operand: b(body),
        }
    }

    pub fn obligation(force: f32, body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Modal {
            vector: ModalVector {
                domain: ModalDomain::Deontic,
                force,
            },
            operand: b(body),
        }
    }

    pub fn modal(domain: ModalDomain, force: f32, body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Modal {
            vector: ModalVector { domain, force },
            operand: b(body),
        }
    }

    // === Binary Ops ===
    pub fn and(left: ExprView<'static>, right: ExprView<'static>) -> ExprView<'static> {
        ExprView::BinaryOp {
            left: b(left),
            op: TokenType::And,
            right: b(right),
        }
    }

    pub fn or(left: ExprView<'static>, right: ExprView<'static>) -> ExprView<'static> {
        ExprView::BinaryOp {
            left: b(left),
            op: TokenType::Or,
            right: b(right),
        }
    }

    pub fn implies(left: ExprView<'static>, right: ExprView<'static>) -> ExprView<'static> {
        ExprView::BinaryOp {
            left: b(left),
            op: TokenType::If,
            right: b(right),
        }
    }

    pub fn iff(left: ExprView<'static>, right: ExprView<'static>) -> ExprView<'static> {
        ExprView::BinaryOp {
            left: b(left),
            op: TokenType::Iff,
            right: b(right),
        }
    }

    // === Unary Ops ===
    pub fn not(body: ExprView<'static>) -> ExprView<'static> {
        ExprView::UnaryOp {
            op: TokenType::Not,
            operand: b(body),
        }
    }

    // === Lambda & Application ===
    pub fn lambda(var: &'static str, body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Lambda {
            variable: var,
            body: b(body),
        }
    }

    pub fn app(func: ExprView<'static>, arg: ExprView<'static>) -> ExprView<'static> {
        ExprView::App {
            function: b(func),
            argument: b(arg),
        }
    }

    // === Questions ===
    pub fn wh_question(var: &'static str, body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Question {
            wh_variable: var,
            body: b(body),
        }
    }

    pub fn yes_no_question(body: ExprView<'static>) -> ExprView<'static> {
        ExprView::YesNoQuestion { body: b(body) }
    }

    // === Intensional ===
    pub fn intensional(op: &'static str, content: ExprView<'static>) -> ExprView<'static> {
        ExprView::Intensional {
            operator: op,
            content: b(content),
        }
    }

    // === Event ===
    pub fn event(pred: ExprView<'static>, adverbs: Vec<&'static str>) -> ExprView<'static> {
        ExprView::Event {
            predicate: b(pred),
            adverbs,
        }
    }

    // === Imperative ===
    pub fn imperative(action: ExprView<'static>) -> ExprView<'static> {
        ExprView::Imperative { action: b(action) }
    }

    // === Speech Act ===
    pub fn speech_act(
        performer: &'static str,
        act_type: &'static str,
        content: ExprView<'static>,
    ) -> ExprView<'static> {
        ExprView::SpeechAct {
            performer,
            act_type,
            content: b(content),
        }
    }

    // === Counterfactual ===
    pub fn counterfactual(
        antecedent: ExprView<'static>,
        consequent: ExprView<'static>,
    ) -> ExprView<'static> {
        ExprView::Counterfactual {
            antecedent: b(antecedent),
            consequent: b(consequent),
        }
    }

    // === Comparative & Superlative ===
    pub fn comparative(
        adj: &'static str,
        subject: TermView<'static>,
        object: TermView<'static>,
    ) -> ExprView<'static> {
        ExprView::Comparative {
            adjective: adj,
            subject,
            object,
            difference: None,
        }
    }

    pub fn superlative(
        adj: &'static str,
        subject: TermView<'static>,
        domain: &'static str,
    ) -> ExprView<'static> {
        ExprView::Superlative {
            adjective: adj,
            subject,
            domain,
        }
    }

    // === Scopal ===
    pub fn scopal(op: &'static str, body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Scopal {
            operator: op,
            body: b(body),
        }
    }

    // === Control ===
    pub fn control(
        verb: &'static str,
        subject: TermView<'static>,
        object: Option<TermView<'static>>,
        infinitive: ExprView<'static>,
    ) -> ExprView<'static> {
        ExprView::Control {
            verb,
            subject,
            object,
            infinitive: b(infinitive),
        }
    }

    // === Presupposition ===
    pub fn presupposition(
        assertion: ExprView<'static>,
        presup: ExprView<'static>,
    ) -> ExprView<'static> {
        ExprView::Presupposition {
            assertion: b(assertion),
            presupposition: b(presup),
        }
    }

    // === Focus ===
    pub fn focus_only(
        focused: TermView<'static>,
        scope: ExprView<'static>,
    ) -> ExprView<'static> {
        ExprView::Focus {
            kind: FocusKind::Only,
            focused,
            scope: b(scope),
        }
    }

    pub fn focus_even(
        focused: TermView<'static>,
        scope: ExprView<'static>,
    ) -> ExprView<'static> {
        ExprView::Focus {
            kind: FocusKind::Even,
            focused,
            scope: b(scope),
        }
    }

    pub fn focus_just(
        focused: TermView<'static>,
        scope: ExprView<'static>,
    ) -> ExprView<'static> {
        ExprView::Focus {
            kind: FocusKind::Just,
            focused,
            scope: b(scope),
        }
    }

    // === Temporal Anchor ===
    pub fn temporal_anchor(anchor: &'static str, body: ExprView<'static>) -> ExprView<'static> {
        ExprView::TemporalAnchor {
            anchor,
            body: b(body),
        }
    }

    // === Categorical (legacy support) ===
    pub fn categorical(
        quantifier: TokenType,
        subject: NounPhraseView<'static>,
        copula_negative: bool,
        predicate: NounPhraseView<'static>,
    ) -> ExprView<'static> {
        ExprView::Categorical {
            quantifier,
            subject,
            copula_negative,
            predicate,
        }
    }

    // === Relation (legacy support) ===
    pub fn relation(
        subject: NounPhraseView<'static>,
        verb: &'static str,
        object: NounPhraseView<'static>,
    ) -> ExprView<'static> {
        ExprView::Relation {
            subject,
            verb,
            object,
        }
    }

    // === NounPhrase builders ===
    pub fn np(noun: &'static str) -> NounPhraseView<'static> {
        NounPhraseView {
            definiteness: None,
            adjectives: vec![],
            noun,
            possessor: None,
            pps: vec![],
            superlative: None,
        }
    }

    pub fn np_def(definiteness: Definiteness, noun: &'static str) -> NounPhraseView<'static> {
        NounPhraseView {
            definiteness: Some(definiteness),
            adjectives: vec![],
            noun,
            possessor: None,
            pps: vec![],
            superlative: None,
        }
    }

    pub fn np_adj(
        adjectives: Vec<&'static str>,
        noun: &'static str,
    ) -> NounPhraseView<'static> {
        NounPhraseView {
            definiteness: None,
            adjectives,
            noun,
            possessor: None,
            pps: vec![],
            superlative: None,
        }
    }

    pub fn np_full(
        definiteness: Option<Definiteness>,
        adjectives: Vec<&'static str>,
        noun: &'static str,
        possessor: Option<NounPhraseView<'static>>,
    ) -> NounPhraseView<'static> {
        NounPhraseView {
            definiteness,
            adjectives,
            noun,
            possessor: possessor.map(Box::new),
            pps: vec![],
            superlative: None,
        }
    }
}

#[cfg(test)]
mod tests {
    use super::dsl::*;
    use crate::ast::{ModalDomain, QuantifierKind, TemporalOperator};
    use crate::token::TokenType;
    use crate::view::{ExprView, TermView};

    #[test]
    fn dsl_constant_term() {
        let term = c("John");
        assert_eq!(term, TermView::Constant("John"));
    }

    #[test]
    fn dsl_variable_term() {
        let term = v("x");
        assert_eq!(term, TermView::Variable("x"));
    }

    #[test]
    fn dsl_atom() {
        let expr = atom("P");
        assert_eq!(expr, ExprView::Atom("P"));
    }

    #[test]
    fn dsl_pred1() {
        let expr = pred1("Run", "John");
        assert_eq!(
            expr,
            ExprView::Predicate {
                name: "Run",
                args: vec![TermView::Constant("John")],
            }
        );
    }

    #[test]
    fn dsl_pred2() {
        let expr = pred2("Love", "John", "Mary");
        assert_eq!(
            expr,
            ExprView::Predicate {
                name: "Love",
                args: vec![
                    TermView::Constant("John"),
                    TermView::Constant("Mary")
                ],
            }
        );
    }

    #[test]
    fn dsl_forall() {
        let expr = forall("x", pred1v("P", "x"));
        assert_eq!(
            expr,
            ExprView::Quantifier {
                kind: QuantifierKind::Universal,
                variable: "x",
                body: Box::new(ExprView::Predicate {
                    name: "P",
                    args: vec![TermView::Variable("x")],
                }),
            }
        );
    }

    #[test]
    fn dsl_exists() {
        let expr = exists("x", pred1v("P", "x"));
        assert_eq!(
            expr,
            ExprView::Quantifier {
                kind: QuantifierKind::Existential,
                variable: "x",
                body: Box::new(ExprView::Predicate {
                    name: "P",
                    args: vec![TermView::Variable("x")],
                }),
            }
        );
    }

    #[test]
    fn dsl_past() {
        let expr = past(pred1("Run", "John"));
        assert_eq!(
            expr,
            ExprView::Temporal {
                operator: TemporalOperator::Past,
                body: Box::new(ExprView::Predicate {
                    name: "Run",
                    args: vec![TermView::Constant("John")],
                }),
            }
        );
    }

    #[test]
    fn dsl_and() {
        let expr = and(atom("P"), atom("Q"));
        assert_eq!(
            expr,
            ExprView::BinaryOp {
                left: Box::new(ExprView::Atom("P")),
                op: TokenType::And,
                right: Box::new(ExprView::Atom("Q")),
            }
        );
    }

    #[test]
    fn dsl_implies() {
        let expr = implies(atom("P"), atom("Q"));
        assert_eq!(
            expr,
            ExprView::BinaryOp {
                left: Box::new(ExprView::Atom("P")),
                op: TokenType::If,
                right: Box::new(ExprView::Atom("Q")),
            }
        );
    }

    #[test]
    fn dsl_not() {
        let expr = not(atom("P"));
        assert_eq!(
            expr,
            ExprView::UnaryOp {
                op: TokenType::Not,
                operand: Box::new(ExprView::Atom("P")),
            }
        );
    }

    #[test]
    fn dsl_lambda() {
        let expr = lambda("x", pred1v("P", "x"));
        assert_eq!(
            expr,
            ExprView::Lambda {
                variable: "x",
                body: Box::new(ExprView::Predicate {
                    name: "P",
                    args: vec![TermView::Variable("x")],
                }),
            }
        );
    }

    #[test]
    fn dsl_modal_necessity() {
        let expr = necessity(atom("Rain"));
        if let ExprView::Modal { vector, operand } = expr {
            assert_eq!(vector.domain, ModalDomain::Alethic);
            assert_eq!(vector.force, 1.0);
            assert_eq!(*operand, ExprView::Atom("Rain"));
        } else {
            panic!("Expected Modal");
        }
    }

    #[test]
    fn dsl_complex_nested() {
        let expr = forall(
            "x",
            implies(pred1v("Human", "x"), pred1v("Mortal", "x")),
        );

        assert_eq!(
            expr,
            ExprView::Quantifier {
                kind: QuantifierKind::Universal,
                variable: "x",
                body: Box::new(ExprView::BinaryOp {
                    left: Box::new(ExprView::Predicate {
                        name: "Human",
                        args: vec![TermView::Variable("x")],
                    }),
                    op: TokenType::If,
                    right: Box::new(ExprView::Predicate {
                        name: "Mortal",
                        args: vec![TermView::Variable("x")],
                    }),
                }),
            }
        );
    }

    #[test]
    fn dsl_box_is_hidden() {
        let expr = past(pred1("Run", "John"));
        if let ExprView::Temporal { body, .. } = expr {
            assert!(matches!(*body, ExprView::Predicate { .. }));
        }
    }

    #[test]
    fn parse_macro_returns_static_view() {
        let view = crate::parse!("John ran.");
        assert!(
            matches!(view, ExprView::NeoEvent { .. }) || matches!(view, ExprView::Temporal { .. }),
            "Expected NeoEvent or Temporal, got {:?}", view
        );
    }

    #[test]
    fn snapshot_macro_creates_file() {
        let output = "test output";
        crate::assert_snapshot!("test_snapshot_macro", output);
    }
}

```

---

## Pragmatics

Speech act theory and modal-to-imperative conversion.

**Location:** `src/pragmatics.rs`

### Pragmatics Module

**File:** `src/pragmatics.rs`

Modal-to-imperative conversion for indirect speech acts. Detects when modal questions should be interpreted as imperatives (e.g., 'Can you pass the salt?' → Pass(you, salt), 'Could you please open the door?' → Open(you, door)). Handles both Expr::NeoEvent and Expr::Predicate forms for addressee detection.

```rust
use crate::ast::{LogicExpr, ModalDomain, ThematicRole, Term};
use crate::arena::Arena;
use crate::intern::Interner;

pub fn apply_pragmatics<'a>(
    expr: &'a LogicExpr<'a>,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    interner: &Interner,
) -> &'a LogicExpr<'a> {
    match expr {
        LogicExpr::Modal { vector, operand } => {
            if vector.domain == ModalDomain::Alethic && vector.force > 0.0 && vector.force < 1.0 {
                if is_addressee_agent(operand, interner) {
                    return expr_arena.alloc(LogicExpr::Imperative { action: *operand });
                }
            }
            expr
        }
        LogicExpr::Question { body, .. } => {
            if let LogicExpr::Modal { vector, operand } = body {
                if vector.domain == ModalDomain::Alethic && vector.force > 0.0 && vector.force < 1.0 {
                    if is_addressee_agent(operand, interner) {
                        return expr_arena.alloc(LogicExpr::Imperative { action: *operand });
                    }
                }
            }
            expr
        }
        LogicExpr::YesNoQuestion { body } => {
            if let LogicExpr::Modal { vector, operand } = body {
                if vector.domain == ModalDomain::Alethic && vector.force > 0.0 && vector.force < 1.0 {
                    if is_addressee_agent(operand, interner) {
                        return expr_arena.alloc(LogicExpr::Imperative { action: *operand });
                    }
                }
            }
            expr
        }
        _ => expr,
    }
}

fn is_addressee_agent(expr: &LogicExpr, interner: &Interner) -> bool {
    match expr {
        LogicExpr::NeoEvent(data) => {
            for (role, term) in data.roles.iter() {
                if *role == ThematicRole::Agent {
                    if let Term::Constant(sym) = term {
                        let name = interner.resolve(*sym);
                        if name == "Addressee" {
                            return true;
                        }
                    }
                }
            }
            false
        }
        LogicExpr::Predicate { args, .. } => {
            if let Some(Term::Constant(sym)) = args.first() {
                let name = interner.resolve(*sym);
                return name == "Addressee";
            }
            false
        }
        _ => false,
    }
}

```

---

## Gamification

Achievement system, progress tracking, and spaced repetition for learning engagement.

**Location:** `src/achievements.rs`, `src/progress.rs`, `src/game.rs`, `src/srs.rs`

### Achievements

**File:** `src/achievements.rs`

Achievement system with unlock conditions and tracking. Defines achievements for milestones (first problem, streak, mastery). Checks unlock conditions and emits events for UI notifications.

```rust
use crate::progress::UserProgress;

#[derive(Debug, Clone, PartialEq, Eq)]
pub struct Achievement {
    pub id: &'static str,
    pub title: &'static str,
    pub description: &'static str,
    pub xp_reward: u64,
    pub unlocks_title: Option<&'static str>,
    pub grants_freeze: bool,
}

pub const ACHIEVEMENTS: &[Achievement] = &[
    Achievement {
        id: "first_blood",
        title: "First Blood",
        description: "Answer your first question correctly",
        xp_reward: 50,
        unlocks_title: None,
        grants_freeze: false,
    },
    Achievement {
        id: "combo_5",
        title: "On Fire",
        description: "Get a 5-answer combo",
        xp_reward: 100,
        unlocks_title: None,
        grants_freeze: false,
    },
    Achievement {
        id: "combo_10",
        title: "Unstoppable",
        description: "Get a 10-answer combo",
        xp_reward: 250,
        unlocks_title: Some("Logic Machine"),
        grants_freeze: false,
    },
    Achievement {
        id: "combo_25",
        title: "Terminator",
        description: "Get a 25-answer combo",
        xp_reward: 500,
        unlocks_title: Some("Automaton"),
        grants_freeze: false,
    },
    Achievement {
        id: "streak_3",
        title: "Getting Started",
        description: "Maintain a 3-day streak",
        xp_reward: 75,
        unlocks_title: None,
        grants_freeze: false,
    },
    Achievement {
        id: "streak_7",
        title: "Week Warrior",
        description: "Maintain a 7-day streak",
        xp_reward: 200,
        unlocks_title: Some("Dedicated"),
        grants_freeze: true,
    },
    Achievement {
        id: "streak_14",
        title: "Fortnight Fighter",
        description: "Maintain a 14-day streak",
        xp_reward: 400,
        unlocks_title: None,
        grants_freeze: true,
    },
    Achievement {
        id: "streak_30",
        title: "Monthly Master",
        description: "Maintain a 30-day streak",
        xp_reward: 1000,
        unlocks_title: Some("Logician"),
        grants_freeze: true,
    },
    Achievement {
        id: "perfect_module",
        title: "Flawless",
        description: "Complete a module with no mistakes",
        xp_reward: 300,
        unlocks_title: None,
        grants_freeze: false,
    },
    Achievement {
        id: "century",
        title: "Century",
        description: "Answer 100 questions correctly",
        xp_reward: 500,
        unlocks_title: Some("Scholar"),
        grants_freeze: false,
    },
    Achievement {
        id: "millennium",
        title: "Millennium",
        description: "Answer 1000 questions correctly",
        xp_reward: 2000,
        unlocks_title: Some("Sage"),
        grants_freeze: false,
    },
    Achievement {
        id: "level_10",
        title: "Double Digits",
        description: "Reach level 10",
        xp_reward: 300,
        unlocks_title: None,
        grants_freeze: false,
    },
    Achievement {
        id: "level_25",
        title: "Quarter Century",
        description: "Reach level 25",
        xp_reward: 750,
        unlocks_title: Some("Adept"),
        grants_freeze: false,
    },
    Achievement {
        id: "level_50",
        title: "Half Century",
        description: "Reach level 50",
        xp_reward: 1500,
        unlocks_title: Some("Grandmaster"),
        grants_freeze: false,
    },
];

pub fn get_achievement(id: &str) -> Option<&'static Achievement> {
    ACHIEVEMENTS.iter().find(|a| a.id == id)
}

pub fn check_achievements(progress: &UserProgress) -> Vec<&'static Achievement> {
    let mut newly_unlocked = Vec::new();

    for achievement in ACHIEVEMENTS {
        if progress.achievements.contains(achievement.id) {
            continue;
        }

        let earned = match achievement.id {
            "first_blood" => total_correct(progress) >= 1,
            "combo_5" => progress.best_combo >= 5,
            "combo_10" => progress.best_combo >= 10,
            "combo_25" => progress.best_combo >= 25,
            "streak_3" => progress.streak_days >= 3,
            "streak_7" => progress.streak_days >= 7,
            "streak_14" => progress.streak_days >= 14,
            "streak_30" => progress.streak_days >= 30,
            "century" => total_correct(progress) >= 100,
            "millennium" => total_correct(progress) >= 1000,
            "level_10" => progress.level >= 10,
            "level_25" => progress.level >= 25,
            "level_50" => progress.level >= 50,
            "perfect_module" => false, // Checked separately in lesson completion
            _ => false,
        };

        if earned {
            newly_unlocked.push(achievement);
        }
    }

    newly_unlocked
}

fn total_correct(progress: &UserProgress) -> u32 {
    progress.exercises.values().map(|e| e.correct_count).sum()
}

pub fn unlock_achievement(progress: &mut UserProgress, achievement: &Achievement) {
    progress.achievements.insert(achievement.id.to_string());
    progress.xp += achievement.xp_reward;
    progress.level = crate::progress::calculate_level(progress.xp);

    if let Some(title) = achievement.unlocks_title {
        if progress.title.is_none() {
            progress.title = Some(title.to_string());
        }
    }

    if achievement.grants_freeze && progress.streak_freezes < 3 {
        progress.streak_freezes += 1;
    }

    progress.save();
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_get_achievement() {
        let achievement = get_achievement("first_blood");
        assert!(achievement.is_some());
        assert_eq!(achievement.unwrap().title, "First Blood");
    }

    #[test]
    fn test_achievement_not_found() {
        let achievement = get_achievement("nonexistent");
        assert!(achievement.is_none());
    }

    #[test]
    fn test_check_achievements_first_blood() {
        let mut progress = UserProgress::new();
        progress.record_attempt("test", true);

        let newly_unlocked = check_achievements(&progress);
        assert!(newly_unlocked.iter().any(|a| a.id == "first_blood"));
    }

    #[test]
    fn test_check_achievements_combo() {
        let mut progress = UserProgress::new();
        progress.best_combo = 5;

        let newly_unlocked = check_achievements(&progress);
        assert!(newly_unlocked.iter().any(|a| a.id == "combo_5"));
        assert!(!newly_unlocked.iter().any(|a| a.id == "combo_10"));
    }

    #[test]
    fn test_streak_achievements_grant_freeze() {
        let streak_7 = get_achievement("streak_7").unwrap();
        assert!(streak_7.grants_freeze);

        let first_blood = get_achievement("first_blood").unwrap();
        assert!(!first_blood.grants_freeze);
    }
}

```

---

### Progress Tracking

**File:** `src/progress.rs`

Lesson and module progress tracking. Tracks completion status, scores, and time spent. Persists progress to storage for cross-session continuity.

```rust
use serde::{Deserialize, Serialize};
use std::collections::{HashMap, HashSet};

#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct UserProgress {
    pub xp: u64,
    pub level: u32,
    pub streak_days: u32,
    pub last_session: Option<String>,
    pub exercises: HashMap<String, ExerciseProgress>,
    pub modules: HashMap<String, ModuleProgress>,
    #[serde(default)]
    pub combo: u32,
    #[serde(default)]
    pub best_combo: u32,
    #[serde(default)]
    pub streak_freezes: u8,
    #[serde(default)]
    pub last_streak_date: Option<String>,
    #[serde(default)]
    pub achievements: HashSet<String>,
    #[serde(default)]
    pub title: Option<String>,
    #[serde(default)]
    pub last_weekly_freeze_date: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExerciseProgress {
    pub exercise_id: String,
    pub attempts: u32,
    pub correct_count: u32,
    pub last_attempt: Option<String>,
    pub srs: SrsData,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SrsData {
    pub ease_factor: f64,
    pub interval: u32,
    pub repetitions: u32,
    pub next_review: Option<String>,
}

impl Default for SrsData {
    fn default() -> Self {
        Self {
            ease_factor: 2.5,
            interval: 1,
            repetitions: 0,
            next_review: None,
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModuleProgress {
    pub module_id: String,
    pub unlocked: bool,
    pub completed: bool,
    pub stars: u8,
    pub best_score: u32,
    pub attempts: u32,
}

impl Default for ModuleProgress {
    fn default() -> Self {
        Self {
            module_id: String::new(),
            unlocked: false,
            completed: false,
            stars: 0,
            best_score: 0,
            attempts: 0,
        }
    }
}

impl UserProgress {
    pub fn new() -> Self {
        Self {
            level: 1,
            ..Default::default()
        }
    }

    pub fn load() -> Self {
        #[cfg(target_arch = "wasm32")]
        {
            crate::storage::load_raw()
                .and_then(|json| serde_json::from_str(&json).ok())
                .unwrap_or_else(Self::new)
        }
        #[cfg(not(target_arch = "wasm32"))]
        {
            Self::new()
        }
    }

    pub fn save(&self) {
        #[cfg(target_arch = "wasm32")]
        {
            if let Ok(json) = serde_json::to_string(self) {
                crate::storage::save_raw(&json);
            }
        }
    }

    pub fn add_xp(&mut self, amount: u64) {
        self.xp += amount;
        self.level = calculate_level(self.xp);
        self.save();
    }

    pub fn record_attempt(&mut self, exercise_id: &str, correct: bool) {
        let entry = self.exercises.entry(exercise_id.to_string()).or_insert_with(|| {
            ExerciseProgress {
                exercise_id: exercise_id.to_string(),
                attempts: 0,
                correct_count: 0,
                last_attempt: None,
                srs: SrsData::default(),
            }
        });

        entry.attempts += 1;
        if correct {
            entry.correct_count += 1;
        }

        self.save();
    }

    pub fn get_exercise_progress(&self, exercise_id: &str) -> Option<&ExerciseProgress> {
        self.exercises.get(exercise_id)
    }

    pub fn get_module_progress(&self, module_id: &str) -> Option<&ModuleProgress> {
        self.modules.get(module_id)
    }

    pub fn update_module_score(&mut self, module_id: &str, score: u32) {
        let entry = self.modules.entry(module_id.to_string()).or_insert_with(|| {
            ModuleProgress {
                module_id: module_id.to_string(),
                ..Default::default()
            }
        });

        entry.attempts += 1;
        if score > entry.best_score {
            entry.best_score = score;
        }

        self.save();
    }
}

pub fn calculate_level(xp: u64) -> u32 {
    ((xp as f64).sqrt() / 10.0).floor() as u32 + 1
}

pub fn xp_for_level(level: u32) -> u64 {
    let l = level as u64;
    l * l * 100
}

pub fn calculate_xp_reward(difficulty: u32, first_try: bool, streak_days: u32) -> u64 {
    let base: u64 = 10;
    let difficulty_bonus = (difficulty.saturating_sub(1) as u64) * 5;
    let first_try_bonus = if first_try { 5 } else { 0 };
    let streak_bonus = (streak_days.min(7) as u64) * 2;

    base + difficulty_bonus + first_try_bonus + streak_bonus
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_level_calculation() {
        assert_eq!(calculate_level(0), 1);
        assert_eq!(calculate_level(100), 2);
        assert_eq!(calculate_level(400), 3);
        assert_eq!(calculate_level(900), 4);
    }

    #[test]
    fn test_xp_reward() {
        assert_eq!(calculate_xp_reward(1, false, 0), 10);
        assert_eq!(calculate_xp_reward(1, true, 0), 15);
        assert_eq!(calculate_xp_reward(2, false, 0), 15);
        assert_eq!(calculate_xp_reward(1, false, 3), 16);
        assert_eq!(calculate_xp_reward(3, true, 5), 10 + 10 + 5 + 10);
    }

    #[test]
    fn test_user_progress_record() {
        let mut progress = UserProgress::new();
        progress.record_attempt("test_q1", true);
        progress.record_attempt("test_q1", false);

        let ex = progress.get_exercise_progress("test_q1").unwrap();
        assert_eq!(ex.attempts, 2);
        assert_eq!(ex.correct_count, 1);
    }
}

```

---

### Game State

**File:** `src/game.rs`

Central game state management. Tracks XP, level, combo/streak counters, and current lesson. Coordinates between achievements, progress, and SRS systems.

```rust
use crate::progress::UserProgress;
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub struct XpReward {
    pub base: u64,
    pub combo_bonus: u64,
    pub streak_bonus: u64,
    pub critical_bonus: u64,
    pub first_try_bonus: u64,
    pub total: u64,
    pub is_critical: bool,
}

pub fn calculate_xp_reward(
    difficulty: u32,
    combo: u32,
    streak_days: u32,
    first_try: bool,
    rng_seed: u64,
) -> XpReward {
    let base = 10 + (difficulty.saturating_sub(1) * 5) as u64;

    let combo_mult = 1.0 + (combo.min(10) as f64 * 0.1);
    let combo_bonus = ((base as f64) * (combo_mult - 1.0)) as u64;

    let streak_bonus = (streak_days.min(7) * 2) as u64;

    let first_try_bonus = if first_try { 5 } else { 0 };

    let is_critical = (rng_seed % 10) == 0;
    let critical_bonus = if is_critical { base } else { 0 };

    let total = base + combo_bonus + streak_bonus + first_try_bonus + critical_bonus;

    XpReward {
        base,
        combo_bonus,
        streak_bonus,
        critical_bonus,
        first_try_bonus,
        total,
        is_critical,
    }
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum StreakStatus {
    Active { days: u32 },
    AtRisk,
    Frozen,
    Lost { was: u32 },
}

pub fn update_streak(progress: &mut UserProgress, today: &str) -> StreakStatus {
    match &progress.last_streak_date {
        None => {
            progress.streak_days = 1;
            progress.last_streak_date = Some(today.to_string());
            StreakStatus::Active { days: 1 }
        }
        Some(last) if last == today => {
            StreakStatus::Active { days: progress.streak_days }
        }
        Some(last) if is_yesterday(last, today) => {
            progress.streak_days += 1;
            progress.last_streak_date = Some(today.to_string());
            StreakStatus::Active { days: progress.streak_days }
        }
        Some(last) if is_two_days_ago(last, today) && progress.streak_freezes > 0 => {
            progress.streak_freezes -= 1;
            progress.last_streak_date = Some(today.to_string());
            StreakStatus::Frozen
        }
        Some(_) => {
            let was = progress.streak_days;
            progress.streak_days = 1;
            progress.last_streak_date = Some(today.to_string());
            StreakStatus::Lost { was }
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ComboResult {
    pub new_combo: u32,
    pub is_new_record: bool,
    pub multiplier: f64,
}

pub fn update_combo(progress: &mut UserProgress, correct: bool) -> ComboResult {
    if correct {
        progress.combo += 1;
        let is_new_record = progress.combo > progress.best_combo;
        if is_new_record {
            progress.best_combo = progress.combo;
        }
        let multiplier = 1.0 + (progress.combo.min(10) as f64 * 0.1);
        ComboResult { new_combo: progress.combo, is_new_record, multiplier }
    } else {
        progress.combo = 0;
        ComboResult { new_combo: 0, is_new_record: false, multiplier: 1.0 }
    }
}

pub fn level_title(level: u32) -> &'static str {
    match level {
        1 => "Novice",
        2..=4 => "Apprentice",
        5..=9 => "Student",
        10..=14 => "Scholar",
        15..=19 => "Adept",
        20..=29 => "Expert",
        30..=39 => "Master",
        40..=49 => "Sage",
        _ => "Grandmaster",
    }
}

pub fn xp_progress_to_next_level(xp: u64, level: u32) -> (u64, u64, f64) {
    let current_threshold = crate::progress::xp_for_level(level);
    let next_threshold = crate::progress::xp_for_level(level + 1);
    let progress = xp.saturating_sub(current_threshold);
    let needed = next_threshold - current_threshold;
    let percentage = if needed > 0 {
        (progress as f64) / (needed as f64)
    } else {
        0.0
    };
    (progress, needed, percentage)
}

pub struct FreezeGrant {
    pub freezes: u8,
    pub reason: &'static str,
}

pub fn check_level_up_freeze_grants(old_level: u32, new_level: u32) -> Option<FreezeGrant> {
    let freeze_count = (old_level + 1..=new_level)
        .filter(|l| l % 5 == 0)
        .count() as u8;

    if freeze_count > 0 {
        Some(FreezeGrant {
            freezes: freeze_count,
            reason: "Level milestone reward",
        })
    } else {
        None
    }
}

pub fn is_sunday(date: &str) -> bool {
    if let Ok(num) = parse_date_to_days(date) {
        (num + 4) % 7 == 0
    } else {
        false
    }
}

fn is_yesterday(last: &str, today: &str) -> bool {
    if let (Ok(l), Ok(t)) = (parse_date_to_days(last), parse_date_to_days(today)) {
        t - l == 1
    } else {
        false
    }
}

fn is_two_days_ago(last: &str, today: &str) -> bool {
    if let (Ok(l), Ok(t)) = (parse_date_to_days(last), parse_date_to_days(today)) {
        t - l == 2
    } else {
        false
    }
}

fn parse_date_to_days(date: &str) -> Result<i64, ()> {
    let parts: Vec<&str> = date.split('-').collect();
    if parts.len() != 3 {
        return Err(());
    }

    let year: i64 = parts[0].parse().map_err(|_| ())?;
    let month: i64 = parts[1].parse().map_err(|_| ())?;
    let day: i64 = parts[2].parse().map_err(|_| ())?;

    let days = year * 365 + (year / 4) - (year / 100) + (year / 400)
        + (month * 30) + day;
    Ok(days)
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_xp_reward_base() {
        let reward = calculate_xp_reward(1, 0, 0, false, 1);
        assert_eq!(reward.base, 10);
        assert_eq!(reward.combo_bonus, 0);
        assert_eq!(reward.total, 10);
        assert!(!reward.is_critical);
    }

    #[test]
    fn test_xp_reward_with_combo() {
        let reward = calculate_xp_reward(1, 5, 0, false, 1);
        assert_eq!(reward.base, 10);
        assert_eq!(reward.combo_bonus, 5); // 10 * 0.5 = 5
        assert_eq!(reward.total, 15);
    }

    #[test]
    fn test_xp_reward_critical() {
        let reward = calculate_xp_reward(1, 0, 0, false, 10); // seed % 10 == 0
        assert!(reward.is_critical);
        assert_eq!(reward.critical_bonus, 10);
        assert_eq!(reward.total, 20);
    }

    #[test]
    fn test_xp_reward_full() {
        // difficulty 3, combo 10, streak 7, first try, non-crit
        let reward = calculate_xp_reward(3, 10, 7, true, 1);
        // base = 10 + (2 * 5) = 20
        // combo = 20 * 1.0 = 20
        // streak = 14
        // first_try = 5
        // total = 20 + 20 + 14 + 5 = 59
        assert_eq!(reward.base, 20);
        assert_eq!(reward.combo_bonus, 20);
        assert_eq!(reward.streak_bonus, 14);
        assert_eq!(reward.first_try_bonus, 5);
        assert_eq!(reward.total, 59);
    }

    #[test]
    fn test_combo_increment() {
        let mut progress = UserProgress::new();

        let result = update_combo(&mut progress, true);
        assert_eq!(result.new_combo, 1);
        assert!(result.is_new_record);

        let result = update_combo(&mut progress, true);
        assert_eq!(result.new_combo, 2);
        assert!(result.is_new_record);

        let result = update_combo(&mut progress, false);
        assert_eq!(result.new_combo, 0);
        assert!(!result.is_new_record);
    }

    #[test]
    fn test_combo_multiplier() {
        let mut progress = UserProgress::new();

        for _ in 0..10 {
            update_combo(&mut progress, true);
        }

        let result = update_combo(&mut progress, true);
        assert!((result.multiplier - 2.0).abs() < 0.01);
    }

    #[test]
    fn test_level_titles() {
        assert_eq!(level_title(1), "Novice");
        assert_eq!(level_title(5), "Student");
        assert_eq!(level_title(10), "Scholar");
        assert_eq!(level_title(50), "Grandmaster");
    }

    #[test]
    fn test_level_up_freeze_grants() {
        assert!(check_level_up_freeze_grants(1, 4).is_none());

        let grant = check_level_up_freeze_grants(4, 5).unwrap();
        assert_eq!(grant.freezes, 1);

        let grant = check_level_up_freeze_grants(1, 10).unwrap();
        assert_eq!(grant.freezes, 2); // levels 5 and 10
    }

    #[test]
    fn test_is_yesterday() {
        assert!(is_yesterday("2025-01-01", "2025-01-02"));
        assert!(!is_yesterday("2025-01-01", "2025-01-03"));
    }
}

```

---

### Spaced Repetition

**File:** `src/srs.rs`

SM-2 style spaced repetition algorithm for review scheduling. Calculates next review date based on performance. Prioritizes due items in review queue.

```rust
use crate::progress::SrsData;

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum ResponseQuality {
    Blackout = 0,
    Incorrect = 1,
    IncorrectEasy = 2,
    CorrectDifficult = 3,
    CorrectHesitation = 4,
    Perfect = 5,
}

impl ResponseQuality {
    pub fn from_score(score: u8) -> Self {
        match score {
            0 => Self::Blackout,
            1 => Self::Incorrect,
            2 => Self::IncorrectEasy,
            3 => Self::CorrectDifficult,
            4 => Self::CorrectHesitation,
            _ => Self::Perfect,
        }
    }

    pub fn is_correct(self) -> bool {
        (self as u8) >= 3
    }
}

pub fn sm2_update(srs: &mut SrsData, quality: ResponseQuality) {
    let q = quality as u8 as f64;

    if quality.is_correct() {
        srs.repetitions += 1;
        srs.interval = match srs.repetitions {
            1 => 1,
            2 => 6,
            _ => (srs.interval as f64 * srs.ease_factor).round() as u32,
        };

        srs.ease_factor += 0.1 - (5.0 - q) * (0.08 + (5.0 - q) * 0.02);
        if srs.ease_factor < 1.3 {
            srs.ease_factor = 1.3;
        }
    } else {
        srs.repetitions = 0;
        srs.interval = 1;
    }
}

pub fn calculate_next_review(current_date: &str, interval_days: u32) -> String {
    if let Ok(date) = parse_date(current_date) {
        let next = date + interval_days as i64;
        format_date(next)
    } else {
        current_date.to_string()
    }
}

pub fn is_due(next_review: Option<&str>, today: &str) -> bool {
    match next_review {
        None => true,
        Some(review_date) => {
            if let (Ok(review), Ok(now)) = (parse_date(review_date), parse_date(today)) {
                review <= now
            } else {
                true
            }
        }
    }
}

fn parse_date(date_str: &str) -> Result<i64, ()> {
    let parts: Vec<&str> = date_str.split('-').collect();
    if parts.len() != 3 {
        return Err(());
    }

    let year: i64 = parts[0].parse().map_err(|_| ())?;
    let month: i64 = parts[1].parse().map_err(|_| ())?;
    let day: i64 = parts[2].parse().map_err(|_| ())?;

    Ok(year * 10000 + month * 100 + day)
}

fn format_date(date_num: i64) -> String {
    let year = date_num / 10000;
    let month = (date_num % 10000) / 100;
    let day = date_num % 100;

    let (year, month, day) = normalize_date(year as i32, month as i32, day as i32);
    format!("{:04}-{:02}-{:02}", year, month, day)
}

fn normalize_date(year: i32, month: i32, day: i32) -> (i32, i32, i32) {
    let days_in_month = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31];

    let mut y = year;
    let mut m = month;
    let mut d = day;

    while d > days_in_month[(m - 1) as usize] {
        d -= days_in_month[(m - 1) as usize];
        m += 1;
        if m > 12 {
            m = 1;
            y += 1;
        }
    }

    (y, m, d)
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_sm2_first_correct() {
        let mut srs = SrsData::default();
        sm2_update(&mut srs, ResponseQuality::Perfect);

        assert_eq!(srs.repetitions, 1);
        assert_eq!(srs.interval, 1);
        assert!(srs.ease_factor > 2.5);
    }

    #[test]
    fn test_sm2_second_correct() {
        let mut srs = SrsData::default();
        sm2_update(&mut srs, ResponseQuality::Perfect);
        sm2_update(&mut srs, ResponseQuality::Perfect);

        assert_eq!(srs.repetitions, 2);
        assert_eq!(srs.interval, 6);
    }

    #[test]
    fn test_sm2_incorrect_resets() {
        let mut srs = SrsData::default();
        sm2_update(&mut srs, ResponseQuality::Perfect);
        sm2_update(&mut srs, ResponseQuality::Perfect);
        sm2_update(&mut srs, ResponseQuality::Incorrect);

        assert_eq!(srs.repetitions, 0);
        assert_eq!(srs.interval, 1);
    }

    #[test]
    fn test_sm2_ease_factor_minimum() {
        let mut srs = SrsData::default();
        srs.ease_factor = 1.3;
        sm2_update(&mut srs, ResponseQuality::CorrectDifficult);

        assert!(srs.ease_factor >= 1.3);
    }

    #[test]
    fn test_is_due_none() {
        assert!(is_due(None, "2025-01-01"));
    }

    #[test]
    fn test_is_due_past() {
        assert!(is_due(Some("2025-01-01"), "2025-01-02"));
    }

    #[test]
    fn test_is_due_future() {
        assert!(!is_due(Some("2025-01-05"), "2025-01-02"));
    }

    #[test]
    fn test_is_due_today() {
        assert!(is_due(Some("2025-01-01"), "2025-01-01"));
    }

    #[test]
    fn test_calculate_next_review() {
        let next = calculate_next_review("2025-01-15", 6);
        assert_eq!(next, "2025-01-21");
    }

    #[test]
    fn test_calculate_next_review_month_overflow() {
        let next = calculate_next_review("2025-01-28", 6);
        assert_eq!(next, "2025-02-03");
    }

    #[test]
    fn test_response_quality_is_correct() {
        assert!(!ResponseQuality::Blackout.is_correct());
        assert!(!ResponseQuality::Incorrect.is_correct());
        assert!(!ResponseQuality::IncorrectEasy.is_correct());
        assert!(ResponseQuality::CorrectDifficult.is_correct());
        assert!(ResponseQuality::CorrectHesitation.is_correct());
        assert!(ResponseQuality::Perfect.is_correct());
    }
}

```

---

### Audio Feedback

**File:** `src/audio.rs`

Sound effect management for feedback. Plays success/failure/achievement sounds. Uses web audio API in WASM context.

```rust
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum SoundEffect {
    XpGain,
    CriticalHit,
    ComboUp,
    ComboBreak,
    Achievement,
    LevelUp,
    StreakSaved,
    StreakLost,
    Correct,
    Incorrect,
}

impl SoundEffect {
    pub fn as_str(&self) -> &'static str {
        match self {
            Self::XpGain => "xp_gain",
            Self::CriticalHit => "critical",
            Self::ComboUp => "combo_up",
            Self::ComboBreak => "combo_break",
            Self::Achievement => "achievement",
            Self::LevelUp => "level_up",
            Self::StreakSaved => "streak_saved",
            Self::StreakLost => "streak_lost",
            Self::Correct => "correct",
            Self::Incorrect => "incorrect",
        }
    }
}

#[cfg(target_arch = "wasm32")]
mod wasm {
    use super::SoundEffect;
    use wasm_bindgen::prelude::*;

    #[wasm_bindgen]
    extern "C" {
        #[wasm_bindgen(js_namespace = window, js_name = playSound)]
        fn play_sound_js(effect: &str);
    }

    pub fn play_sound(effect: SoundEffect) {
        play_sound_js(effect.as_str());
    }
}

#[cfg(target_arch = "wasm32")]
pub use wasm::play_sound;

#[cfg(not(target_arch = "wasm32"))]
pub fn play_sound(_effect: SoundEffect) {
    // No-op on non-wasm targets
}

```

---

### Persistent Storage

**File:** `src/storage.rs`

LocalStorage interface for saving game state. Handles serialization/deserialization of progress, settings, and achievements. Provides fallback for browsers without storage access.

```rust
use wasm_bindgen::prelude::*;

const PROGRESS_KEY: &str = "logos_user_progress";

#[wasm_bindgen]
extern "C" {
    #[wasm_bindgen(js_namespace = localStorage, js_name = getItem)]
    fn local_storage_get(key: &str) -> Option<String>;

    #[wasm_bindgen(js_namespace = localStorage, js_name = setItem)]
    fn local_storage_set(key: &str, value: &str);

    #[wasm_bindgen(js_namespace = localStorage, js_name = removeItem)]
    fn local_storage_remove(key: &str);
}

pub fn load_raw() -> Option<String> {
    local_storage_get(PROGRESS_KEY)
}

pub fn save_raw(json: &str) {
    local_storage_set(PROGRESS_KEY, json);
}

pub fn clear() {
    local_storage_remove(PROGRESS_KEY);
}

```

---

## Entry Point

Command-line interface and REPL for interactive use.

**Location:** `src/main.rs`

### Application Entry Point

**File:** `src/main.rs`

Web application entry point. Launches Dioxus web UI with Router for SPA navigation. Build with 'dx serve' for development or 'dx build' for production WASM deployment.

```rust
fn main() {
    dioxus::launch(logos::ui::App);
}

```

---

## Web Application

Dioxus-based web application with routing and multiple pages.

**Location:** `src/ui/`

**Architecture:**
- Router-based SPA with client-side navigation
- Pages: Home (Quadrivium menu), Workspace (chat interface), Pricing, Learn (curriculum browser), Lesson (problem-solving)
- Components: Reusable UI elements (chat display, input area)
- Problem Generator: Template-based exercise generation with semantic grading
- Fair Source licensing with honor system toggle

### UI: App

**File:** `src/ui/app.rs`

Root application component with Router wrapper and global CSS styles (gradients, glassmorphism, animations).

```rust
use dioxus::prelude::*;
use crate::ui::router::Route;
use crate::ui::state::LicenseState;

const GLOBAL_STYLE: &str = r#"
* {
    margin: 0;
    padding: 0;
    box-sizing: border-box;
}

html, body {
    height: 100%;
    background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
    color: #e8e8e8;
    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
    overflow-x: hidden;
}

#main {
    min-height: 100vh;
}

a {
    color: inherit;
    text-decoration: none;
}

.chat-area {
    flex: 1;
    overflow-y: auto;
    padding: 30px;
    display: flex;
    flex-direction: column;
    gap: 16px;
}

.message {
    max-width: 75%;
    padding: 14px 20px;
    border-radius: 16px;
    line-height: 1.6;
    animation: fadeIn 0.3s ease;
}

@keyframes fadeIn {
    from { opacity: 0; transform: translateY(10px); }
    to { opacity: 1; transform: translateY(0); }
}

.message.user {
    align-self: flex-end;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    border-bottom-right-radius: 4px;
    box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
}

.message.system {
    align-self: flex-start;
    background: rgba(255, 255, 255, 0.08);
    border: 1px solid rgba(255, 255, 255, 0.15);
    border-bottom-left-radius: 4px;
    font-family: 'SF Mono', 'Fira Code', 'Consolas', monospace;
    font-size: 18px;
    color: #00d4ff;
    text-shadow: 0 0 20px rgba(0, 212, 255, 0.3);
}

.message.error {
    align-self: flex-start;
    background: linear-gradient(135deg, #ff6b6b 0%, #c92a2a 100%);
    color: white;
    border-bottom-left-radius: 4px;
    font-style: italic;
    box-shadow: 0 4px 15px rgba(255, 107, 107, 0.3);
}

.input-area {
    background: rgba(0, 0, 0, 0.4);
    backdrop-filter: blur(10px);
    padding: 20px 30px;
    border-top: 1px solid rgba(255, 255, 255, 0.1);
}

.input-row {
    display: flex;
    gap: 12px;
    align-items: center;
}

.input-row input {
    flex: 1;
    background: rgba(255, 255, 255, 0.08);
    border: 1px solid rgba(255, 255, 255, 0.2);
    border-radius: 12px;
    padding: 14px 20px;
    font-size: 16px;
    color: white;
    outline: none;
    transition: all 0.2s ease;
}

.input-row input::placeholder {
    color: #666;
}

.input-row input:focus {
    border-color: #667eea;
    box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.2);
}

.input-row button {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    border: none;
    border-radius: 12px;
    padding: 14px 28px;
    font-size: 16px;
    font-weight: 600;
    color: white;
    cursor: pointer;
    transition: all 0.2s ease;
    box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
}

.input-row button:hover {
    transform: translateY(-2px);
    box-shadow: 0 6px 20px rgba(102, 126, 234, 0.4);
}

.input-row button:active {
    transform: translateY(0);
}
"#;

pub fn App() -> Element {
    let license_state = use_context_provider(LicenseState::new);

    use_effect(move || {
        let mut license_state = license_state.clone();
        spawn(async move {
            if license_state.has_license() && license_state.needs_revalidation() {
                license_state.validate().await;
            }
        });
    });

    rsx! {
        style { "{GLOBAL_STYLE}" }
        Router::<Route> {}
    }
}

```

---

### UI: mod

**File:** `src/ui/mod.rs`

UI module built with Dioxus 0.6.

```rust
pub mod app;
pub mod state;
pub mod components;
pub mod router;
pub mod pages;

pub use app::App;

```

---

### UI: Router

**File:** `src/ui/router.rs`

Dioxus Router with routes: / (Home), /pricing (Pricing), /studio (Studio), /learn (Learn), /lesson/:era/:module (Lesson), /workspace/:subject (Workspace), /:..route (NotFound 404 handler). Includes NotFound component for graceful 404 handling.

```rust
use dioxus::prelude::*;
use crate::ui::pages::{Home, Landing, Learn, Lesson, Pricing, Privacy, Review, Roadmap, Success, Terms, Workspace, Studio};

#[derive(Clone, Routable, Debug, PartialEq)]
pub enum Route {
    #[route("/")]
    Landing {},

    #[route("/home")]
    Home {},

    #[route("/pricing")]
    Pricing {},

    #[route("/privacy")]
    Privacy {},

    #[route("/terms")]
    Terms {},

    #[route("/roadmap")]
    Roadmap {},

    #[route("/success")]
    Success {},

    #[route("/studio")]
    Studio {},

    #[route("/learn")]
    Learn {},

    #[route("/review")]
    Review {},

    #[route("/lesson/:era/:module/:mode")]
    Lesson { era: String, module: String, mode: String },

    #[route("/workspace/:subject")]
    Workspace { subject: String },

    #[route("/:..route")]
    NotFound { route: Vec<String> },
}

#[component]
fn NotFound(route: Vec<String>) -> Element {
    rsx! {
        div {
            style: "min-height: 100vh; display: flex; flex-direction: column; align-items: center; justify-content: center; background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%); color: #e8e8e8;",
            h1 { style: "font-size: 48px; margin-bottom: 16px;", "404" }
            p { style: "color: #888; margin-bottom: 24px;", "Page not found: /{route.join(\"/\")}" }
            Link {
                to: Route::Home {},
                style: "padding: 12px 24px; background: linear-gradient(135deg, #667eea, #764ba2); border-radius: 8px; color: white; text-decoration: none;",
                "Go Home"
            }
        }
    }
}

```

---

### UI: State

**File:** `src/ui/state.rs`

Application state management with Signal-based reactivity. ChatMessage history and compile integration.

```rust
use dioxus::prelude::*;
use crate::{compile_with_options, CompileOptions, OutputFormat};

const LICENSE_VALIDATOR_URL: &str = "https://api.logicaffeine.com/validate";
const VALIDATION_INTERVAL_MS: f64 = 24.0 * 60.0 * 60.0 * 1000.0; // 24 hours

#[derive(Clone, PartialEq, Debug)]
pub enum LicensePlan {
    None,
    Free,
    Supporter,
    Pro,
    Premium,
    Lifetime,
    Enterprise,
}

impl LicensePlan {
    pub fn from_str(s: &str) -> Self {
        match s.to_lowercase().as_str() {
            "free" => Self::Free,
            "supporter" => Self::Supporter,
            "pro" => Self::Pro,
            "premium" => Self::Premium,
            "lifetime" => Self::Lifetime,
            "enterprise" => Self::Enterprise,
            _ => Self::None,
        }
    }

    pub fn is_commercial(&self) -> bool {
        matches!(self, Self::Pro | Self::Premium | Self::Lifetime | Self::Enterprise)
    }

    pub fn is_paid(&self) -> bool {
        !matches!(self, Self::None | Self::Free)
    }
}

#[derive(Clone, PartialEq)]
pub struct LicenseState {
    pub key: Signal<Option<String>>,
    pub plan: Signal<LicensePlan>,
    pub is_valid: Signal<bool>,
    pub validated_at: Signal<Option<f64>>,
    pub is_validating: Signal<bool>,
}

impl LicenseState {
    pub fn new() -> Self {
        let (key, plan, validated_at) = load_license_from_storage();

        Self {
            key: Signal::new(key),
            plan: Signal::new(plan),
            is_valid: Signal::new(false),
            validated_at: Signal::new(validated_at),
            is_validating: Signal::new(false),
        }
    }

    pub fn has_license(&self) -> bool {
        self.key.read().is_some()
    }

    pub fn is_commercial(&self) -> bool {
        self.plan.read().is_commercial() && *self.is_valid.read()
    }

    pub fn needs_revalidation(&self) -> bool {
        match *self.validated_at.read() {
            Some(timestamp) => {
                let now = js_sys::Date::now();
                now - timestamp > VALIDATION_INTERVAL_MS
            }
            None => true,
        }
    }

    pub fn set_license(&mut self, license_key: String, plan: LicensePlan) {
        self.key.set(Some(license_key.clone()));
        self.plan.set(plan.clone());
        self.is_valid.set(true);
        let now = js_sys::Date::now();
        self.validated_at.set(Some(now));

        save_license_to_storage(&license_key, &plan, now);
    }

    pub fn clear_license(&mut self) {
        self.key.set(None);
        self.plan.set(LicensePlan::None);
        self.is_valid.set(false);
        self.validated_at.set(None);

        clear_license_from_storage();
    }

    pub async fn validate(&mut self) {
        let license_key = match self.key.read().clone() {
            Some(key) => key,
            None => return,
        };

        self.is_validating.set(true);

        match validate_license_async(&license_key).await {
            Ok((is_valid, plan)) => {
                self.is_valid.set(is_valid);
                if is_valid {
                    self.plan.set(plan);
                    let now = js_sys::Date::now();
                    self.validated_at.set(Some(now));
                    save_license_to_storage(&license_key, &self.plan.read(), now);
                }
            }
            Err(_) => {
                self.is_valid.set(false);
            }
        }

        self.is_validating.set(false);
    }
}

async fn validate_license_async(license_key: &str) -> Result<(bool, LicensePlan), String> {
    use gloo_net::http::Request;

    let body = serde_json::json!({ "licenseKey": license_key });

    let response = Request::post(LICENSE_VALIDATOR_URL)
        .header("Content-Type", "application/json")
        .body(body.to_string())
        .map_err(|e| e.to_string())?
        .send()
        .await
        .map_err(|e| e.to_string())?;

    if !response.ok() {
        return Ok((false, LicensePlan::None));
    }

    let data: serde_json::Value = response
        .json()
        .await
        .map_err(|e| e.to_string())?;

    let is_valid = data["valid"].as_bool().unwrap_or(false);
    let plan_str = data["plan"].as_str().unwrap_or("none");
    let plan = LicensePlan::from_str(plan_str);

    Ok((is_valid, plan))
}

fn load_license_from_storage() -> (Option<String>, LicensePlan, Option<f64>) {
    if let Some(window) = web_sys::window() {
        if let Ok(Some(storage)) = window.local_storage() {
            let key = storage.get_item("logos_license_key").ok().flatten();
            let plan_str = storage.get_item("logos_license_plan").ok().flatten().unwrap_or_default();
            let validated_at = storage
                .get_item("logos_license_validated_at")
                .ok()
                .flatten()
                .and_then(|s| s.parse::<f64>().ok());

            let plan = LicensePlan::from_str(&plan_str);
            return (key, plan, validated_at);
        }
    }
    (None, LicensePlan::None, None)
}

fn save_license_to_storage(key: &str, plan: &LicensePlan, validated_at: f64) {
    if let Some(window) = web_sys::window() {
        if let Ok(Some(storage)) = window.local_storage() {
            let _ = storage.set_item("logos_license_key", key);
            let plan_str = format!("{:?}", plan).to_lowercase();
            let _ = storage.set_item("logos_license_plan", &plan_str);
            let _ = storage.set_item("logos_license_validated_at", &validated_at.to_string());
        }
    }
}

fn clear_license_from_storage() {
    if let Some(window) = web_sys::window() {
        if let Ok(Some(storage)) = window.local_storage() {
            let _ = storage.remove_item("logos_license_key");
            let _ = storage.remove_item("logos_license_plan");
            let _ = storage.remove_item("logos_license_validated_at");
        }
    }
}

#[derive(Clone, PartialEq)]
pub struct ChatMessage {
    pub role: Role,
    pub content: String,
}

#[derive(Clone, PartialEq)]
pub enum Role {
    User,
    System,
    Error,
}

#[derive(Clone, Copy)]
pub struct AppState {
    history: Signal<Vec<ChatMessage>>,
}

impl AppState {
    pub fn new() -> Self {
        Self {
            history: Signal::new(vec![ChatMessage {
                role: Role::System,
                content: "The Council is assembled. State your premise.".to_string(),
            }]),
        }
    }

    pub fn add_user_message(&mut self, text: String) {
        self.history.write().push(ChatMessage {
            role: Role::User,
            content: text.clone(),
        });
        self.process_logic(text);
    }

    fn process_logic(&mut self, input: String) {
        let options = CompileOptions { format: OutputFormat::Unicode };

        let response = match compile_with_options(&input, options) {
            Ok(logic) => ChatMessage {
                role: Role::System,
                content: logic,
            },
            Err(e) => {
                let interner = crate::Interner::new();
                let advice = crate::socratic_explanation(&e, &interner);
                ChatMessage {
                    role: Role::Error,
                    content: advice,
                }
            }
        };
        self.history.write().push(response);
    }

    pub fn get_history(&self) -> Vec<ChatMessage> {
        self.history.read().clone()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_license_plan_from_str() {
        assert_eq!(LicensePlan::from_str("free"), LicensePlan::Free);
        assert_eq!(LicensePlan::from_str("FREE"), LicensePlan::Free);
        assert_eq!(LicensePlan::from_str("Free"), LicensePlan::Free);
        assert_eq!(LicensePlan::from_str("supporter"), LicensePlan::Supporter);
        assert_eq!(LicensePlan::from_str("pro"), LicensePlan::Pro);
        assert_eq!(LicensePlan::from_str("premium"), LicensePlan::Premium);
        assert_eq!(LicensePlan::from_str("lifetime"), LicensePlan::Lifetime);
        assert_eq!(LicensePlan::from_str("enterprise"), LicensePlan::Enterprise);
        assert_eq!(LicensePlan::from_str("unknown"), LicensePlan::None);
        assert_eq!(LicensePlan::from_str(""), LicensePlan::None);
    }

    #[test]
    fn test_license_plan_is_commercial() {
        assert!(!LicensePlan::None.is_commercial());
        assert!(!LicensePlan::Free.is_commercial());
        assert!(!LicensePlan::Supporter.is_commercial());
        assert!(LicensePlan::Pro.is_commercial());
        assert!(LicensePlan::Premium.is_commercial());
        assert!(LicensePlan::Lifetime.is_commercial());
        assert!(LicensePlan::Enterprise.is_commercial());
    }

    #[test]
    fn test_license_plan_is_paid() {
        assert!(!LicensePlan::None.is_paid());
        assert!(!LicensePlan::Free.is_paid());
        assert!(LicensePlan::Supporter.is_paid());
        assert!(LicensePlan::Pro.is_paid());
        assert!(LicensePlan::Premium.is_paid());
        assert!(LicensePlan::Lifetime.is_paid());
        assert!(LicensePlan::Enterprise.is_paid());
    }
}

```

---

### Page: Home

**File:** `src/ui/pages/home.rs`

Quadrivium landing page with 4 subject portals (Logic, English, Coding, Mathematics) and Fair Source license banner with honor system toggle.

```rust
use dioxus::prelude::*;
use crate::ui::router::Route;
use crate::ui::components::logic_output::highlight_logic;

const HOME_STYLE: &str = r#"
.home-wrapper {
    display: flex;
    flex-direction: column;
    align-items: center;
    min-height: 100vh;
    padding: 60px 20px;
    background: radial-gradient(circle at top center, #1e293b 0%, #0f172a 100%);
}

.brand-header {
    text-align: center;
    margin-bottom: 60px;
    animation: fadeIn 1s ease;
}

.brand-header h1 {
    font-size: 56px;
    font-weight: 800;
    margin-bottom: 12px;
    background: linear-gradient(135deg, #60a5fa 0%, #a78bfa 100%);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    letter-spacing: -1px;
}

.brand-header p {
    font-size: 18px;
    color: #94a3b8;
}

.portal-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
    gap: 30px;
    max-width: 1000px;
    width: 100%;
}

.portal-card {
    background: rgba(255, 255, 255, 0.03);
    border: 1px solid rgba(255, 255, 255, 0.08);
    border-radius: 20px;
    padding: 40px 30px;
    text-align: left;
    text-decoration: none;
    transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
    position: relative;
    overflow: hidden;
}

.portal-card:hover {
    transform: translateY(-5px);
    background: rgba(255, 255, 255, 0.05);
    border-color: rgba(129, 140, 248, 0.3);
    box-shadow: 0 20px 40px rgba(0, 0, 0, 0.4);
}

.portal-card .icon {
    font-size: 42px;
    margin-bottom: 20px;
    background: rgba(255, 255, 255, 0.1);
    width: 80px;
    height: 80px;
    border-radius: 16px;
    display: flex;
    align-items: center;
    justify-content: center;
}

.portal-card h2 {
    color: #fff;
    font-size: 24px;
    margin-bottom: 10px;
}

.portal-card p {
    color: #94a3b8;
    line-height: 1.5;
    font-size: 15px;
}

.portal-card .arrow {
    position: absolute;
    bottom: 30px;
    right: 30px;
    opacity: 0;
    transition: all 0.3s ease;
    color: #818cf8;
    font-size: 24px;
}

.portal-card:hover .arrow {
    opacity: 1;
    transform: translateX(5px);
}

@keyframes fadeIn {
    from { opacity: 0; transform: translateY(20px); }
    to { opacity: 1; transform: translateY(0); }
}

@media (max-width: 600px) {
    .portal-grid {
        grid-template-columns: 1fr;
    }
    .brand-header h1 {
        font-size: 40px;
    }
    .example-showcase {
        padding: 20px;
    }
    .example-sentence {
        font-size: 16px !important;
    }
    .example-output {
        font-size: 14px !important;
    }
}

.example-showcase {
    max-width: 800px;
    width: 100%;
    margin-bottom: 50px;
    animation: fadeIn 1s ease 0.2s both;
}

.example-tabs {
    display: flex;
    gap: 8px;
    margin-bottom: 20px;
    flex-wrap: wrap;
}

.example-tab {
    padding: 10px 20px;
    border-radius: 8px;
    border: 1px solid rgba(255, 255, 255, 0.1);
    background: rgba(255, 255, 255, 0.03);
    color: #94a3b8;
    cursor: pointer;
    transition: all 0.2s ease;
    font-size: 14px;
    font-weight: 500;
}

.example-tab:hover {
    background: rgba(255, 255, 255, 0.08);
    color: #e8e8e8;
}

.example-tab.active {
    background: linear-gradient(135deg, #667eea, #764ba2);
    color: white;
    border-color: transparent;
}

.example-content {
    background: rgba(255, 255, 255, 0.03);
    border: 1px solid rgba(255, 255, 255, 0.08);
    border-radius: 16px;
    padding: 30px;
    text-align: center;
}

.example-sentence {
    font-size: 20px;
    color: #e8e8e8;
    font-style: italic;
    margin-bottom: 0;
    line-height: 1.5;
}

.example-arrow {
    color: #667eea;
    font-size: 28px;
    margin: 20px 0;
}

.example-output {
    font-family: 'SF Mono', 'Fira Code', 'Consolas', monospace;
    font-size: 18px;
    line-height: 1.6;
    text-align: left;
    background: rgba(0, 0, 0, 0.2);
    padding: 20px;
    border-radius: 8px;
    overflow-x: auto;
}

.logic-quantifier { color: #c678dd; font-weight: 600; }
.logic-connective { color: #56b6c2; }
.logic-variable { color: #61afef; }
.logic-predicate { color: #98c379; }
.logic-constant { color: #e5c07b; }
.logic-paren { color: #abb2bf; }

@keyframes slideIn {
    from { opacity: 0; transform: translateX(20px); }
    to { opacity: 1; transform: translateX(0); }
}

.example-content {
    animation: slideIn 0.3s ease;
}

.example-nav {
    display: flex;
    justify-content: center;
    align-items: center;
    gap: 20px;
    margin-top: 20px;
}

.nav-arrow {
    width: 40px;
    height: 40px;
    border-radius: 50%;
    border: 1px solid rgba(255, 255, 255, 0.2);
    background: rgba(255, 255, 255, 0.05);
    color: #94a3b8;
    cursor: pointer;
    transition: all 0.2s;
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 18px;
}

.nav-arrow:hover:not(:disabled) {
    background: rgba(102, 126, 234, 0.3);
    border-color: #667eea;
    color: white;
}

.nav-arrow:disabled {
    opacity: 0.3;
    cursor: not-allowed;
}

.nav-dots {
    display: flex;
    gap: 8px;
}

.nav-dot {
    width: 8px;
    height: 8px;
    border-radius: 50%;
    background: rgba(255, 255, 255, 0.2);
    cursor: pointer;
    transition: all 0.2s;
}

.nav-dot:hover {
    background: rgba(255, 255, 255, 0.4);
}

.nav-dot.active {
    background: #667eea;
    transform: scale(1.2);
}
"#;

const EXAMPLES: &[(&str, &str, &str)] = &[
    (
        "Universal",
        "Every user who has a key enters the room.",
        "∃y(∀x(((User(x) ∧ (Key(y) ∧ Have(x, y))) → Enter(x, Room))))"
    ),
    (
        "Conditional",
        "If a user enters the room, the alarm triggers.",
        "(Enter(User, Room) → Trigger(Alarm))"
    ),
    (
        "Negation",
        "No user who lacks a key can enter the room.",
        "∀x(((User(x) ∧ (Key(y) ∧ Lack(x, y))) → ¬Enter(x)))"
    ),
    (
        "Donkey",
        "If a farmer owns a donkey, he beats it.",
        "∀x∀y((Farmer(x) ∧ Donkey(y) ∧ Own(x, y)) → Beat(x, y))"
    ),
    (
        "Focus",
        "Only John ate the cake.",
        "Only(John, ∃e(Eat(e) ∧ Agent(e, John) ∧ Theme(e, Cake)))"
    ),
];

#[component]
pub fn Home() -> Element {
    let mut active_tab = use_signal(|| 0usize);

    rsx! {
        style { "{HOME_STYLE}" }

        div { class: "home-wrapper",
            div { class: "brand-header",
                h1 { "LOGICAFFEINE" }
                p { "Choose your path to logical mastery." }
            }

            div { class: "example-showcase",
                div { class: "example-tabs",
                    for (i, (label, _, _)) in EXAMPLES.iter().enumerate() {
                        button {
                            key: "{i}",
                            class: if active_tab() == i { "example-tab active" } else { "example-tab" },
                            onclick: move |_| active_tab.set(i),
                            "{label}"
                        }
                    }
                }
                div {
                    key: "{active_tab()}",
                    class: "example-content",
                    p { class: "example-sentence",
                        "\"{EXAMPLES[active_tab()].1}\""
                    }
                    div { class: "example-arrow", "↓" }
                    div {
                        class: "example-output",
                        dangerous_inner_html: highlight_logic(EXAMPLES[active_tab()].2)
                    }
                }
                div { class: "example-nav",
                    button {
                        class: "nav-arrow",
                        disabled: active_tab() == 0,
                        onclick: move |_| {
                            if active_tab() > 0 {
                                active_tab.set(active_tab() - 1);
                            }
                        },
                        "←"
                    }
                    div { class: "nav-dots",
                        for i in 0..EXAMPLES.len() {
                            div {
                                key: "{i}",
                                class: if active_tab() == i { "nav-dot active" } else { "nav-dot" },
                                onclick: move |_| active_tab.set(i),
                            }
                        }
                    }
                    button {
                        class: "nav-arrow",
                        disabled: active_tab() == EXAMPLES.len() - 1,
                        onclick: move |_| {
                            if active_tab() < EXAMPLES.len() - 1 {
                                active_tab.set(active_tab() + 1);
                            }
                        },
                        "→"
                    }
                }
            }

            div { class: "portal-grid",
                Link {
                    to: Route::Learn {},
                    class: "portal-card",
                    div { class: "icon", "🎓" }
                    h2 { "Curriculum" }
                    p { "Step-by-step interactive lessons from basics to advanced logic." }
                    div { class: "arrow", "→" }
                }

                Link {
                    to: Route::Studio {},
                    class: "portal-card",
                    div { class: "icon", "⚙️" }
                    h2 { "Studio" }
                    p { "Free-form sandbox. Type English, get Logic. Inspect the AST." }
                    div { class: "arrow", "→" }
                }

                Link {
                    to: Route::Review {},
                    class: "portal-card",
                    div { class: "icon", "🔄" }
                    h2 { "Daily Review" }
                    p { "Spaced repetition practice to keep your skills sharp." }
                    div { class: "arrow", "→" }
                }

                Link {
                    to: Route::Pricing {},
                    class: "portal-card",
                    div { class: "icon", "💼" }
                    h2 { "Enterprise" }
                    p { "Commercial licensing and team management features." }
                    div { class: "arrow", "→" }
                }
            }
        }
    }
}

```

---

### Page: landing

**File:** `src/ui/pages/landing.rs`

Application page component.

```rust
use dioxus::prelude::*;
use crate::ui::router::Route;

const LANDING_STYLE: &str = r#"
:root {
  --bg0: #070a12;
  --bg1: #0b1022;
  --card: rgba(255,255,255,0.06);
  --card2: rgba(255,255,255,0.04);
  --border: rgba(255,255,255,0.10);
  --border2: rgba(255,255,255,0.14);
  --text: #e5e7eb;
  --muted: rgba(229,231,235,0.72);
  --muted2: rgba(229,231,235,0.56);
  --brand: #a78bfa;
  --brand2:#60a5fa;
  --ok: #22c55e;
  --shadow: 0 30px 80px rgba(0,0,0,0.55);
}

* { box-sizing: border-box; }
a { color: inherit; }

body:has(.landing) {
  overflow: hidden;
}

.landing {
  height: 100vh;
  color: var(--text);
  background:
    radial-gradient(1200px 600px at 50% -120px, rgba(167,139,250,0.18), transparent 60%),
    radial-gradient(900px 500px at 15% 30%, rgba(96,165,250,0.18), transparent 60%),
    radial-gradient(800px 450px at 90% 45%, rgba(34,197,94,0.10), transparent 62%),
    linear-gradient(180deg, var(--bg0), var(--bg1) 55%, #070a12);
  overflow-x: hidden;
  overflow-y: auto;
  font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Inter, "Helvetica Neue", Arial, "Noto Sans", "Apple Color Emoji", "Segoe UI Emoji";
  position: relative;
}

.bg-orb {
  position: absolute;
  inset: auto;
  width: 520px;
  height: 520px;
  border-radius: 999px;
  filter: blur(42px);
  opacity: 0.22;
  pointer-events: none;
  animation: float 14s ease-in-out infinite, pulse-glow 10s ease-in-out infinite;
}
.orb1 { top: -220px; left: -160px; background: radial-gradient(circle at 30% 30%, var(--brand2), transparent 60%); animation-delay: 0s; }
.orb2 { top: 120px; right: -200px; background: radial-gradient(circle at 40% 35%, var(--brand), transparent 60%); animation-delay: -5s; }
.orb3 { bottom: -260px; left: 20%; background: radial-gradient(circle at 40% 35%, rgba(34,197,94,0.9), transparent 60%); animation-delay: -10s; }

.container {
  width: 100%;
  max-width: 1120px;
  margin: 0 auto;
  padding: 0 20px;
}

.nav {
  position: sticky;
  top: 0;
  z-index: 50;
  backdrop-filter: blur(18px);
  background: linear-gradient(180deg, rgba(7,10,18,0.72), rgba(7,10,18,0.44));
  border-bottom: 1px solid rgba(255,255,255,0.06);
}

.nav-inner {
  display: flex;
  align-items: center;
  justify-content: space-between;
  padding: 16px 0;
  gap: 14px;
}

.brand {
  display: flex;
  align-items: center;
  gap: 12px;
  text-decoration: none;
}

.logo {
  width: 36px;
  height: 36px;
  border-radius: 12px;
  background:
    radial-gradient(circle at 30% 30%, rgba(96,165,250,0.85), transparent 55%),
    radial-gradient(circle at 65% 60%, rgba(167,139,250,0.85), transparent 55%),
    rgba(255,255,255,0.06);
  border: 1px solid rgba(255,255,255,0.10);
  box-shadow: 0 14px 35px rgba(0,0,0,0.35);
}

.brand-name {
  display: flex;
  flex-direction: column;
  line-height: 1.05;
}

.brand-name strong {
  font-weight: 800;
  letter-spacing: -0.5px;
  font-size: 14px;
}
.brand-name span {
  font-size: 12px;
  color: var(--muted2);
}

.nav-links {
  display: flex;
  gap: 18px;
  align-items: center;
  color: var(--muted);
  font-size: 14px;
}
.nav-links a {
  text-decoration: none;
  padding: 8px 10px;
  border-radius: 10px;
  transition: background 0.18s ease, color 0.18s ease;
}
.nav-links a:hover {
  background: rgba(255,255,255,0.05);
  color: rgba(255,255,255,0.92);
}

.nav-cta {
  display: flex;
  gap: 10px;
  align-items: center;
}

.btn {
  display: inline-flex;
  align-items: center;
  justify-content: center;
  gap: 10px;
  padding: 12px 16px;
  border-radius: 14px;
  border: 1px solid rgba(255,255,255,0.10);
  background: rgba(255,255,255,0.05);
  text-decoration: none;
  font-weight: 650;
  font-size: 14px;
  transition: transform 0.18s ease, background 0.18s ease, border-color 0.18s ease;
  will-change: transform;
}
.btn:hover { transform: translateY(-1px); background: rgba(255,255,255,0.07); border-color: rgba(255,255,255,0.18); }
.btn:active { transform: translateY(0px); }

.btn-primary {
  background: linear-gradient(135deg, rgba(96,165,250,0.95), rgba(167,139,250,0.95));
  border-color: rgba(255,255,255,0.20);
  color: #060814;
  box-shadow: 0 18px 40px rgba(96,165,250,0.18);
}
.btn-primary:hover {
  background: linear-gradient(135deg, rgba(96,165,250,1.0), rgba(167,139,250,1.0));
}

.btn-ghost {
  background: rgba(255,255,255,0.03);
}

.btn-icon {
  padding: 10px;
  background: rgba(255,255,255,0.03);
}
.btn-icon svg {
  width: 20px;
  height: 20px;
  fill: currentColor;
}

.github-link {
  display: inline-flex;
  align-items: center;
  gap: 6px;
  color: inherit;
  text-decoration: none;
  transition: color 0.2s ease;
}
.github-link:hover {
  color: var(--text);
}

.hero {
  padding: 84px 0 30px;
}

.hero-grid {
  display: grid;
  grid-template-columns: 1.05fr 0.95fr;
  gap: 36px;
  align-items: center;
}

.badge {
  display: inline-flex;
  align-items: center;
  gap: 10px;
  padding: 10px 14px;
  border-radius: 999px;
  background: rgba(255,255,255,0.06);
  border: 1px solid rgba(255,255,255,0.10);
  backdrop-filter: blur(18px);
  box-shadow: 0 18px 40px rgba(0,0,0,0.25);
  color: rgba(255,255,255,0.88);
  font-size: 13px;
  font-weight: 650;
}
.badge .dot {
  width: 8px;
  height: 8px;
  border-radius: 99px;
  background: var(--ok);
  box-shadow: 0 0 0 6px rgba(34,197,94,0.12);
  animation: pulse-glow 2s ease-in-out infinite;
}

.hero .badge { animation: fadeInUp 0.6s ease both; }
.hero .h-title { animation: fadeInUp 0.6s ease 0.08s both; }
.hero .h-sub { animation: fadeInUp 0.6s ease 0.16s both; }
.hero .hero-ctas { animation: fadeInUp 0.6s ease 0.24s both; }
.hero .microcopy { animation: fadeInUp 0.6s ease 0.30s both; }
.hero .kpi { animation: fadeInUp 0.6s ease 0.36s both; }
.hero .demo { animation: fadeInUp 0.8s ease 0.44s both; }

.h-title {
  margin: 18px 0 12px;
  font-size: 62px;
  line-height: 1.04;
  letter-spacing: -2px;
  font-weight: 900;
  background: linear-gradient(180deg, #ffffff 0%, rgba(229,231,235,0.78) 65%, rgba(229,231,235,0.62) 100%);
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
}

.h-sub {
  margin: 0 0 20px;
  max-width: 580px;
  color: var(--muted);
  font-size: 18px;
  line-height: 1.65;
}

.hero-ctas {
  display: flex;
  gap: 12px;
  flex-wrap: wrap;
  margin: 18px 0 14px;
}

.microcopy {
  font-size: 13px;
  color: var(--muted2);
}

.demo {
  border-radius: 20px;
  border: 1px solid rgba(255,255,255,0.10);
  background: linear-gradient(180deg, rgba(255,255,255,0.06), rgba(255,255,255,0.03));
  backdrop-filter: blur(18px);
  box-shadow: var(--shadow);
  overflow: hidden;
  position: relative;
}

.demo::before {
  content: "";
  position: absolute;
  inset: -2px;
  background: radial-gradient(600px 280px at 10% 10%, rgba(96,165,250,0.22), transparent 55%),
              radial-gradient(520px 240px at 90% 20%, rgba(167,139,250,0.22), transparent 55%);
  opacity: 0.9;
  pointer-events: none;
}

.demo-head {
  position: relative;
  display: flex;
  align-items: center;
  justify-content: space-between;
  padding: 14px 16px;
  border-bottom: 1px solid rgba(255,255,255,0.06);
  background: rgba(0,0,0,0.10);
}

.win-dots { display: flex; gap: 8px; align-items: center; }
.wdot { width: 11px; height: 11px; border-radius: 99px; opacity: 0.9; }
.wr { background: #ef4444; } .wy { background: #fbbf24; } .wg { background: #22c55e; }

.demo-label {
  font-size: 12px;
  color: rgba(229,231,235,0.78);
  border: 1px solid rgba(255,255,255,0.10);
  padding: 7px 10px;
  border-radius: 999px;
  background: rgba(255,255,255,0.04);
}

.demo-body {
  position: relative;
  display: grid;
  grid-template-columns: 1fr 1fr;
}

.demo-col {
  padding: 18px 18px 22px;
  min-height: 240px;
}

.demo-col + .demo-col {
  border-left: 1px solid rgba(255,255,255,0.06);
  background: rgba(0,0,0,0.18);
}

.demo-kicker {
  display: flex;
  align-items: center;
  justify-content: space-between;
  margin-bottom: 12px;
  font-size: 12px;
  color: rgba(229,231,235,0.72);
}

.pill {
  border: 1px solid rgba(255,255,255,0.10);
  background: rgba(255,255,255,0.04);
  padding: 6px 10px;
  border-radius: 999px;
}

.code {
  font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
  font-size: 13px;
  line-height: 1.6;
  color: rgba(229,231,235,0.90);
  white-space: pre-wrap;
}

.code.logic { color: rgba(167,139,250,0.96); }

.demo-foot {
  display: flex;
  gap: 10px;
  flex-wrap: wrap;
  padding: 14px 16px;
  border-top: 1px solid rgba(255,255,255,0.06);
  background: rgba(0,0,0,0.12);
  color: rgba(229,231,235,0.70);
  font-size: 13px;
}

.section {
  padding: 74px 0;
}

.section-title {
  font-size: 30px;
  letter-spacing: -0.8px;
  margin: 0 0 10px;
}
.section-sub {
  margin: 0 0 26px;
  color: var(--muted);
  line-height: 1.65;
  max-width: 760px;
}

.grid3 {
  display: grid;
  grid-template-columns: repeat(3, 1fr);
  gap: 18px;
}
.grid2 {
  display: grid;
  grid-template-columns: 1fr 1fr;
  gap: 18px;
}

.card {
  position: relative;
  border-radius: 18px;
  border: 1px solid rgba(255,255,255,0.10);
  background: rgba(255,255,255,0.04);
  backdrop-filter: blur(18px);
  padding: 18px;
  transition: transform 0.18s ease, border-color 0.18s ease, background 0.18s ease;
  overflow: hidden;
}
.card::before {
  content: "";
  position: absolute;
  inset: 0;
  border-radius: 18px;
  background: linear-gradient(135deg, rgba(96,165,250,0.12), rgba(167,139,250,0.12));
  opacity: 0;
  transition: opacity 0.3s ease;
  pointer-events: none;
}
.card:hover {
  transform: translateY(-3px);
  border-color: rgba(167,139,250,0.28);
  background: rgba(255,255,255,0.06);
}
.card:hover::before {
  opacity: 1;
}

.icon {
  width: 42px; height: 42px;
  border-radius: 14px;
  display: grid;
  place-items: center;
  background: rgba(255,255,255,0.06);
  border: 1px solid rgba(255,255,255,0.10);
  margin-bottom: 12px;
}

.card h3 {
  margin: 0 0 8px;
  font-size: 16px;
  letter-spacing: -0.2px;
}
.card p {
  margin: 0;
  color: var(--muted);
  line-height: 1.6;
  font-size: 14px;
}

.quote {
  font-size: 14px;
  line-height: 1.65;
  color: rgba(229,231,235,0.86);
}
.quoter {
  margin-top: 10px;
  color: var(--muted2);
  font-size: 13px;
}

.kpi {
  display: flex;
  gap: 14px;
  flex-wrap: wrap;
  margin-top: 18px;
}
.kpi .pill {
  background: rgba(255,255,255,0.04);
}

.tech-stack {
  display: flex;
  gap: 10px;
  flex-wrap: wrap;
  margin-top: 14px;
}

.tech-badge {
  font-size: 12px;
  padding: 6px 12px;
  border-radius: 6px;
  background: rgba(255,255,255,0.03);
  border: 1px solid rgba(255,255,255,0.08);
  color: var(--muted);
}

.tech-badge.rust {
  background: linear-gradient(135deg, rgba(183,65,14,0.15), rgba(222,165,132,0.10));
  border-color: rgba(222,165,132,0.3);
  color: #dea584;
}

.hello-demo {
  display: flex;
  align-items: center;
  justify-content: center;
  gap: 24px;
  flex-wrap: wrap;
  margin: 24px 0;
}

.hello-code, .hello-result {
  flex: 1;
  min-width: 280px;
  max-width: 400px;
  border-radius: 12px;
  border: 1px solid rgba(255,255,255,0.10);
  background: rgba(0,0,0,0.3);
  overflow: hidden;
}

.code-header {
  padding: 10px 14px;
  font-size: 12px;
  color: var(--muted);
  background: rgba(255,255,255,0.03);
  border-bottom: 1px solid rgba(255,255,255,0.06);
  font-family: ui-monospace, monospace;
}

.hello-code .code {
  margin: 0;
  padding: 16px;
  font-size: 14px;
  line-height: 1.6;
}

.terminal {
  padding: 16px;
  font-family: ui-monospace, monospace;
  font-size: 14px;
}

.terminal .prompt {
  color: var(--ok);
}

.terminal .output {
  color: var(--text);
}

.hello-arrow {
  font-size: 28px;
  color: var(--brand);
}

.hello-note {
  text-align: center;
  font-size: 14px;
  color: var(--muted);
  margin-top: 8px;
}

.compare-table {
  display: flex;
  flex-direction: column;
  border-radius: 12px;
  border: 1px solid rgba(255,255,255,0.10);
  overflow: hidden;
  max-width: 800px;
  margin: 0 auto;
}

.compare-row {
  display: grid;
  grid-template-columns: 1.2fr repeat(4, 1fr);
}

.compare-row.header {
  background: rgba(255,255,255,0.05);
  font-weight: 600;
  font-size: 13px;
}

.compare-row:not(.header) {
  border-top: 1px solid rgba(255,255,255,0.06);
}

.compare-cell {
  padding: 12px 14px;
  font-size: 13px;
  color: var(--muted);
  text-align: center;
}

.compare-cell.label {
  text-align: left;
  color: var(--text);
  font-weight: 500;
}

.compare-cell.highlight {
  background: rgba(167,139,250,0.08);
  color: var(--brand);
  font-weight: 500;
}

.compare-row.header .compare-cell.highlight {
  background: rgba(167,139,250,0.15);
}

@media (max-width: 700px) {
  .compare-row {
    grid-template-columns: 1fr 1fr 1fr;
  }
  .compare-cell:nth-child(4),
  .compare-cell:nth-child(5) {
    display: none;
  }
}

.faq-item {
  padding: 16px 16px 14px;
  border-radius: 16px;
  border: 1px solid rgba(255,255,255,0.10);
  background: rgba(255,255,255,0.03);
}
.faq-q { font-weight: 750; margin-bottom: 8px; }
.faq-a { color: var(--muted); line-height: 1.6; font-size: 14px; }

.footer {
  padding: 34px 0 44px;
  border-top: 1px solid rgba(255,255,255,0.06);
  color: var(--muted2);
  font-size: 13px;
}

.footer-row {
  display: flex;
  align-items: center;
  justify-content: space-between;
  gap: 16px;
  flex-wrap: wrap;
}

@media (max-width: 980px) {
  .hero-grid { grid-template-columns: 1fr; }
  .demo-body { grid-template-columns: 1fr; }
  .demo-col + .demo-col { border-left: none; border-top: 1px solid rgba(255,255,255,0.06); }
  .grid3 { grid-template-columns: 1fr; }
  .grid2 { grid-template-columns: 1fr; }
  .h-title { font-size: 48px; }
  .nav-links { display: none; }
}

@keyframes fadeInUp {
  from { opacity: 0; transform: translateY(24px); }
  to { opacity: 1; transform: translateY(0); }
}

@keyframes float {
  0%, 100% { transform: translate3d(0, 0, 0); }
  50% { transform: translate3d(0, -20px, 0); }
}

@keyframes pulse-glow {
  0%, 100% { opacity: 0.22; }
  50% { opacity: 0.32; }
}

@keyframes blink {
  50% { opacity: 0; }
}

html { scroll-behavior: smooth; }

.section + .section {
  border-top: 1px solid rgba(255,255,255,0.04);
}

.steps {
  display: flex;
  align-items: center;
  justify-content: center;
  gap: 20px;
  flex-wrap: wrap;
}

.step {
  flex: 1;
  min-width: 200px;
  max-width: 280px;
  text-align: center;
  padding: 24px;
  border-radius: 18px;
  background: rgba(255,255,255,0.04);
  border: 1px solid rgba(255,255,255,0.10);
  animation: fadeInUp 0.6s ease both;
}

.step:nth-child(1) { animation-delay: 0s; }
.step:nth-child(3) { animation-delay: 0.1s; }
.step:nth-child(5) { animation-delay: 0.2s; }

.step-num {
  width: 48px;
  height: 48px;
  margin: 0 auto 16px;
  border-radius: 50%;
  background: linear-gradient(135deg, var(--brand2), var(--brand));
  color: #060814;
  font-weight: 800;
  font-size: 20px;
  display: grid;
  place-items: center;
}

.step h3 {
  margin: 0 0 8px;
  font-size: 18px;
}

.step p {
  margin: 0;
  color: var(--muted);
  font-size: 14px;
  line-height: 1.5;
}

.step-arrow {
  font-size: 24px;
  color: var(--muted2);
}

.grid3 .card:nth-child(1) .icon { background: rgba(96,165,250,0.15); }
.grid3 .card:nth-child(2) .icon { background: rgba(167,139,250,0.15); }
.grid3 .card:nth-child(3) .icon { background: rgba(34,197,94,0.15); }
.grid3 .card:nth-child(4) .icon { background: rgba(251,191,36,0.15); }
.grid3 .card:nth-child(5) .icon { background: rgba(236,72,153,0.15); }
.grid3 .card:nth-child(6) .icon { background: rgba(139,92,246,0.15); }

.demo-col:first-child .code::after {
  content: " ▋";
  animation: blink 1s step-end infinite;
  color: var(--brand2);
}

@media (max-width: 980px) {
  .hero-grid { grid-template-columns: 1fr; }
  .demo-body { grid-template-columns: 1fr; }
  .demo-col + .demo-col { border-left: none; border-top: 1px solid rgba(255,255,255,0.06); }
  .grid3 { grid-template-columns: 1fr; }
  .grid2 { grid-template-columns: 1fr; }
  .h-title { font-size: 48px; }
  .nav-links { display: none; }
  .step-arrow { display: none; }
  .steps { flex-direction: column; }
}

@media (prefers-reduced-motion: reduce) {
  * { transition: none !important; animation: none !important; }
}
"#;

#[component]
pub fn Landing() -> Element {
    rsx! {
        style { "{LANDING_STYLE}" }

        div { class: "landing",
            div { class: "bg-orb orb1" }
            div { class: "bg-orb orb2" }
            div { class: "bg-orb orb3" }

            header { class: "nav",
                div { class: "container",
                    div { class: "nav-inner",
                        Link {
                            to: Route::Landing {},
                            class: "brand",
                            div { class: "logo" }
                            div { class: "brand-name",
                                strong { "LOGICAFFEINE" }
                                span { "Debug your thoughts." }
                            }
                        }

                        nav { class: "nav-links",
                            a { href: "#product", "Product" }
                            a { href: "#for", "Who it's for" }
                            a { href: "#faq", "FAQ" }
                            Link { to: Route::Roadmap {}, "Roadmap" }
                            Link { to: Route::Pricing {}, "Pricing" }
                        }

                        div { class: "nav-cta",
                            a {
                                href: "https://github.com/Brahmastra-Labs/logicaffeine",
                                target: "_blank",
                                class: "btn btn-icon",
                                title: "View on GitHub",
                                svg {
                                    xmlns: "http://www.w3.org/2000/svg",
                                    view_box: "0 0 24 24",
                                    path {
                                        d: "M12 0C5.37 0 0 5.37 0 12c0 5.31 3.435 9.795 8.205 11.385.6.105.825-.255.825-.57 0-.285-.015-1.23-.015-2.235-3.015.555-3.795-.735-4.035-1.41-.135-.345-.72-1.41-1.23-1.695-.42-.225-1.02-.78-.015-.795.945-.015 1.62.87 1.845 1.23 1.08 1.815 2.805 1.305 3.495.99.105-.78.42-1.305.765-1.605-2.67-.3-5.46-1.335-5.46-5.925 0-1.305.465-2.385 1.23-3.225-.12-.3-.54-1.53.12-3.18 0 0 1.005-.315 3.3 1.23.96-.27 1.98-.405 3-.405s2.04.135 3 .405c2.295-1.56 3.3-1.23 3.3-1.23.66 1.65.24 2.88.12 3.18.765.84 1.23 1.905 1.23 3.225 0 4.605-2.805 5.625-5.475 5.925.435.375.81 1.095.81 2.22 0 1.605-.015 2.895-.015 3.3 0 .315.225.69.825.57A12.02 12.02 0 0024 12c0-6.63-5.37-12-12-12z"
                                    }
                                }
                            }
                            Link { to: Route::Pricing {}, class: "btn btn-ghost", "Licenses" }
                            Link { to: Route::Home {}, class: "btn btn-primary", "Launch App" }
                        }
                    }
                }
            }

            main { class: "container",
                section { class: "hero",
                    div { class: "hero-grid",
                        div {
                            div { class: "badge",
                                div { class: "dot" }
                                span { "Free for individuals • Commercial licenses available" }
                            }

                            h1 { class: "h-title", "Debug Your Thoughts." }

                            p { class: "h-sub",
                                "Turn everyday English into rigorous First-Order Logic. Verify arguments, surface hidden assumptions, and build rule systems that actually hold up."
                            }

                            div { class: "hero-ctas",
                                Link { to: Route::Learn {}, class: "btn btn-primary", "Start Learning" }
                                Link { to: Route::Studio {}, class: "btn", "Open Studio" }
                                Link { to: Route::Pricing {}, class: "btn btn-ghost", "See Pricing" }
                            }

                            p { class: "microcopy",
                                "Built for people who take thinking seriously: students, researchers, engineers, analysts, and attorneys."
                            }

                            div { class: "kpi",
                                span { class: "pill", "Plain English in" }
                                span { class: "pill", "Formal logic out" }
                                span { class: "pill", "Zero guesswork" }
                            }

                            div { class: "tech-stack",
                                span { class: "tech-badge rust", "Rust-Powered 🦀" }
                                span { class: "tech-badge", "WASM Ready" }
                                span { class: "tech-badge", "Markdown Source" }
                                span { class: "tech-badge", "Proof-Checked" }
                            }
                        }

                        div { class: "demo", id: "product",
                            div { class: "demo-head",
                                div { class: "win-dots",
                                    div { class: "wdot wr" }
                                    div { class: "wdot wy" }
                                    div { class: "wdot wg" }
                                }
                                div { class: "demo-label", "Live Transpilation Preview" }
                            }

                            div { class: "demo-body",
                                div { class: "demo-col",
                                    div { class: "demo-kicker",
                                        span { "Input (English)" }
                                        span { class: "pill", "Plain language" }
                                    }
                                    div { class: "code",
r#"Every user who has a key enters the room.
If a user enters the room, the alarm triggers.
No user who lacks a key can enter the room."# }
                                }

                                div { class: "demo-col",
                                    div { class: "demo-kicker",
                                        span { "Output (First-Order Logic)" }
                                        span { class: "pill", "Machine-checkable" }
                                    }
                                    div { class: "code logic",
r#"1) ∀x((User(x) ∧ ∃y(Key(y) ∧ Has(x,y))) → Enter(x, Room))
2) ∀x((User(x) ∧ Enter(x, Room)) → Trigger(Alarm))
3) ∀x((User(x) ∧ ¬∃y(Key(y) ∧ Has(x,y))) → ¬Enter(x, Room))"# }
                                }
                            }

                            div { class: "demo-foot",
                                span { "Your logic, formalized in milliseconds." }
                            }
                        }
                    }
                }

                section { class: "section how-it-works",
                    h2 { class: "section-title", "How it works" }
                    p { class: "section-sub",
                        "Three steps from thought to proof."
                    }

                    div { class: "steps",
                        div { class: "step",
                            div { class: "step-num", "1" }
                            h3 { "Write in English" }
                            p { "Type your argument, rule, or statement in plain language." }
                        }
                        div { class: "step-arrow", "→" }
                        div { class: "step",
                            div { class: "step-num", "2" }
                            h3 { "Get formal logic" }
                            p { "Instantly see the First-Order Logic representation." }
                        }
                        div { class: "step-arrow", "→" }
                        div { class: "step",
                            div { class: "step-num", "3" }
                            h3 { "Validate & refine" }
                            p { "The tutor surfaces ambiguities. You fix them." }
                        }
                    }
                }

                section { class: "section hello-world",
                    h2 { class: "section-title", "Hello World in LOGOS" }
                    p { class: "section-sub",
                        "Markdown files compile directly to native binaries. No ceremony, no boilerplate."
                    }

                    div { class: "hello-demo",
                        div { class: "hello-code",
                            div { class: "code-header", "hello.md" }
                            pre { class: "code",
r#"# Hello World

To run:
    Show "Hello, World!" to the console."# }
                        }
                        div { class: "hello-arrow", "→" }
                        div { class: "hello-result",
                            div { class: "code-header", "Output" }
                            div { class: "terminal",
                                span { class: "prompt", "$ " }
                                span { "logos run hello.md" }
                                br {}
                                span { class: "output", "Hello, World!" }
                            }
                        }
                    }
                    p { class: "hello-note", "Compiles to a native binary via Rust. Zero runtime overhead." }
                }

                section { class: "section",
                    h2 { class: "section-title", "What you get" }
                    p { class: "section-sub",
                        "LOGICAFFEINE translates intuition into structure — so you can test it, teach it, or ship it."
                    }

                    div { class: "grid3",
                        div { class: "card",
                            div { class: "icon", "⚡" }
                            h3 { "Instant Transpilation" }
                            p { "Type normal English. Get precise logic in seconds — readable enough to learn from, strict enough to verify." }
                        }
                        div { class: "card",
                            div { class: "icon", "🧠" }
                            h3 { "Socratic Tutor" }
                            p { "When your statement is ambiguous, the tutor asks questions that force clarity instead of guessing." }
                        }
                        div { class: "card",
                            div { class: "icon", "🧾" }
                            h3 { "Assumption Surfacing" }
                            p { "Reveal missing premises, hidden quantifiers, and scope mistakes — the usual sources of bad arguments." }
                        }
                        div { class: "card",
                            div { class: "icon", "🧪" }
                            h3 { "Consistency & Validity Checks" }
                            p { "Spot contradictions, invalid inferences, and rule collisions early — before they hit production or policy." }
                        }
                        div { class: "card",
                            div { class: "icon", "🧰" }
                            h3 { "Studio + Curriculum" }
                            p { "Explore freely in Studio, then build mastery in Learn with structured lessons and practice." }
                        }
                        div { class: "card",
                            div { class: "icon", "🔒" }
                            h3 { "Commercial-Ready" }
                            p { "Licensing options for teams and enterprises — with a path toward governance and controlled deployments." }
                        }
                    }
                }

                section { class: "section", id: "for",
                    h2 { class: "section-title", "Who uses LOGICAFFEINE" }
                    p { class: "section-sub",
                        "For people who want their reasoning to survive contact with reality."
                    }

                    div { class: "grid3",
                        div { class: "card",
                            div { class: "icon", "🎓" }
                            h3 { "Students & Educators" }
                            p { "Teach formal reasoning with feedback that's immediate, concrete, and harder to game than multiple choice." }
                        }
                        div { class: "card",
                            div { class: "icon", "⚖️" }
                            h3 { "Law, Policy, Compliance" }
                            p { "Translate policy language into verifiable rules. Reduce ambiguity. Make reviews faster and safer." }
                        }
                        div { class: "card",
                            div { class: "icon", "🛠️" }
                            h3 { "Engineering & Research" }
                            p { "Specify systems, constraints, and invariants in a form you can test — without forcing everyone into formal syntax." }
                        }
                    }
                }

                section { class: "section compare-section",
                    h2 { class: "section-title", "How LOGOS Compares" }
                    p { class: "section-sub",
                        "A new approach to formal reasoning."
                    }

                    div { class: "compare-table",
                        div { class: "compare-row header",
                            div { class: "compare-cell", "Feature" }
                            div { class: "compare-cell highlight", "LOGOS" }
                            div { class: "compare-cell", "Lean 4" }
                            div { class: "compare-cell", "Rust" }
                            div { class: "compare-cell", "Python" }
                        }
                        div { class: "compare-row",
                            div { class: "compare-cell label", "Syntax" }
                            div { class: "compare-cell highlight", "English prose" }
                            div { class: "compare-cell", "Lean DSL" }
                            div { class: "compare-cell", "Symbols" }
                            div { class: "compare-cell", "Symbols" }
                        }
                        div { class: "compare-row",
                            div { class: "compare-cell label", "File Format" }
                            div { class: "compare-cell highlight", "Markdown (.md)" }
                            div { class: "compare-cell", ".lean" }
                            div { class: "compare-cell", ".rs" }
                            div { class: "compare-cell", ".py" }
                        }
                        div { class: "compare-row",
                            div { class: "compare-cell label", "Performance" }
                            div { class: "compare-cell highlight", "Native (via Rust)" }
                            div { class: "compare-cell", "Native" }
                            div { class: "compare-cell", "Native" }
                            div { class: "compare-cell", "Interpreted" }
                        }
                        div { class: "compare-row",
                            div { class: "compare-cell label", "Proofs" }
                            div { class: "compare-cell highlight", "Built-in" }
                            div { class: "compare-cell", "Required" }
                            div { class: "compare-cell", "Optional" }
                            div { class: "compare-cell", "None" }
                        }
                        div { class: "compare-row",
                            div { class: "compare-cell label", "Memory" }
                            div { class: "compare-cell highlight", "Ownership (English)" }
                            div { class: "compare-cell", "GC" }
                            div { class: "compare-cell", "Ownership" }
                            div { class: "compare-cell", "GC" }
                        }
                    }
                }

                section { class: "section", id: "faq",
                    h2 { class: "section-title", "FAQ" }
                    p { class: "section-sub",
                        "Common questions about LOGICAFFEINE."
                    }

                    div { class: "grid2",
                        div { class: "faq-item",
                            div { class: "faq-q", "Is it really free?" }
                            div { class: "faq-a", "Yes — free for individuals. Teams and commercial use should use the licensing options on the Pricing page." }
                        }
                        div { class: "faq-item",
                            div { class: "faq-q", "Do I need to know logic already?" }
                            div { class: "faq-a", "No. Start in Learn. The system introduces concepts progressively and uses examples to teach scope, quantifiers, and structure." }
                        }
                        div { class: "faq-item",
                            div { class: "faq-q", "Is this an AI that \"guesses\"?" }
                            div { class: "faq-a", "The goal is the opposite: to force explicit structure. When language is ambiguous, the tutor prompts clarifying questions." }
                        }
                        div { class: "faq-item",
                            div { class: "faq-q", "Where do I begin?" }
                            div { class: "faq-a", "If you want speed, open Studio. If you want mastery, Start Learning and follow the lessons." }
                        }
                        div { class: "faq-item",
                            div { class: "faq-q", "What is LOGOS written in?" }
                            div { class: "faq-a", "Rust. The entire transpiler, parser, and runtime are written in Rust for maximum performance and safety." }
                        }
                        div { class: "faq-item",
                            div { class: "faq-q", "How fast is it?" }
                            div { class: "faq-a", "Native speed. LOGOS compiles to Rust, which then compiles via LLVM to optimized machine code. Zero interpreter overhead." }
                        }
                    }
                }

                section { class: "section",
                    div { class: "card",
                        h2 { class: "section-title", "Make your reasoning impossible to ignore." }
                        p { class: "section-sub",
                            "Start with the Curriculum, or jump into the Studio. Either way, the product is built to sharpen your mind."
                        }
                        div { class: "hero-ctas",
                            Link { to: Route::Learn {}, class: "btn btn-primary", "Start Learning" }
                            Link { to: Route::Home {}, class: "btn", "Launch App" }
                            Link { to: Route::Pricing {}, class: "btn btn-ghost", "View Licenses" }
                        }
                    }
                }

                footer { class: "footer",
                    div { class: "footer-row",
                        div { "© 2025 Brahmastra Labs LLC  •  Written in Rust 🦀" }
                        div {
                            a {
                                href: "https://github.com/Brahmastra-Labs/logicaffeine",
                                target: "_blank",
                                class: "github-link",
                                svg {
                                    xmlns: "http://www.w3.org/2000/svg",
                                    width: "16",
                                    height: "16",
                                    view_box: "0 0 24 24",
                                    fill: "currentColor",
                                    path {
                                        d: "M12 0C5.37 0 0 5.37 0 12c0 5.31 3.435 9.795 8.205 11.385.6.105.825-.255.825-.57 0-.285-.015-1.23-.015-2.235-3.015.555-3.795-.735-4.035-1.41-.135-.345-.72-1.41-1.23-1.695-.42-.225-1.02-.78-.015-.795.945-.015 1.62.87 1.845 1.23 1.08 1.815 2.805 1.305 3.495.99.105-.78.42-1.305.765-1.605-2.67-.3-5.46-1.335-5.46-5.925 0-1.305.465-2.385 1.23-3.225-.12-.3-.54-1.53.12-3.18 0 0 1.005-.315 3.3 1.23.96-.27 1.98-.405 3-.405s2.04.135 3 .405c2.295-1.56 3.3-1.23 3.3-1.23.66 1.65.24 2.88.12 3.18.765.84 1.23 1.905 1.23 3.225 0 4.605-2.805 5.625-5.475 5.925.435.375.81 1.095.81 2.22 0 1.605-.015 2.895-.015 3.3 0 .315.225.69.825.57A12.02 12.02 0 0024 12c0-6.63-5.37-12-12-12z"
                                    }
                                }
                                "GitHub"
                            }
                            span { "  •  " }
                            Link { to: Route::Privacy {}, "Privacy Policy" }
                            span { "  •  " }
                            Link { to: Route::Terms {}, "Terms of Use" }
                            span { "  •  " }
                            Link { to: Route::Pricing {}, "Pricing" }
                            span { "  •  " }
                            Link { to: Route::Home {}, "App" }
                            span { "  •  " }
                            Link { to: Route::Learn {}, "Learn" }
                        }
                    }
                }
            }
        }
    }
}

```

---

### Page: Learn

**File:** `src/ui/pages/learn.rs`

Curriculum browser with expandable era/module hierarchy. Displays Trivium, Quadrivium, and Metaphysics eras with nested modules.

```rust
use dioxus::prelude::*;
use crate::ui::router::Route;
use crate::ui::components::mode_selector::{ModeSelector, ModeInfo};

const LEARN_STYLE: &str = r#"
.learn-container {
    min-height: 100vh;
    background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
    color: #e8e8e8;
    padding: 40px 20px;
}

.learn-header {
    max-width: 1000px;
    margin: 0 auto 40px;
}

.learn-header h1 {
    font-size: 36px;
    font-weight: 700;
    background: linear-gradient(90deg, #00d4ff, #7b2cbf);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    margin-bottom: 8px;
}

.learn-header p {
    color: #888;
    font-size: 16px;
}

.era-list {
    max-width: 1000px;
    margin: 0 auto;
    display: flex;
    flex-direction: column;
    gap: 24px;
}

.era-card {
    background: rgba(255, 255, 255, 0.05);
    border: 1px solid rgba(255, 255, 255, 0.1);
    border-radius: 16px;
    overflow: hidden;
}

.era-header {
    padding: 24px;
    cursor: pointer;
    display: flex;
    justify-content: space-between;
    align-items: center;
    transition: background 0.2s ease;
}

.era-header:hover {
    background: rgba(255, 255, 255, 0.03);
}

.era-title {
    font-size: 24px;
    font-weight: 600;
    color: #fff;
    margin-bottom: 4px;
}

.era-description {
    color: #888;
    font-size: 14px;
}

.era-toggle {
    font-size: 24px;
    color: #667eea;
    transition: transform 0.3s ease;
}

.era-toggle.open {
    transform: rotate(180deg);
}

.module-list {
    padding: 0 24px 24px;
    display: flex;
    flex-direction: column;
    gap: 12px;
}

.module-card {
    background: rgba(255, 255, 255, 0.03);
    border: 1px solid rgba(255, 255, 255, 0.08);
    border-radius: 12px;
    padding: 16px 20px;
    display: flex;
    justify-content: space-between;
    align-items: center;
    cursor: pointer;
    transition: all 0.2s ease;
    text-decoration: none;
}

.module-card:hover {
    background: rgba(255, 255, 255, 0.06);
    border-color: #667eea;
    transform: translateX(4px);
}

.module-info h3 {
    color: #fff;
    font-size: 16px;
    margin-bottom: 4px;
}

.module-info p {
    color: #666;
    font-size: 13px;
}

.module-stats {
    display: flex;
    align-items: center;
    gap: 16px;
}

.exercise-count {
    color: #888;
    font-size: 13px;
}

.difficulty-stars {
    color: #667eea;
    font-size: 14px;
}

.start-btn {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    border: none;
    padding: 8px 16px;
    border-radius: 8px;
    font-size: 14px;
    cursor: pointer;
    transition: transform 0.2s ease;
}

.start-btn:hover {
    transform: scale(1.05);
}

.back-link {
    display: inline-flex;
    align-items: center;
    gap: 8px;
    color: #667eea;
    text-decoration: none;
    margin-bottom: 24px;
    font-size: 14px;
}

.back-link:hover {
    text-decoration: underline;
}
"#;

#[component]
pub fn Learn() -> Element {
    let mut expanded_era = use_signal(|| Some("logicaffeine".to_string()));
    let mut pending_module = use_signal(|| None::<(String, String, String)>);
    let navigator = use_navigator();

    let eras = vec![
        ("logicaffeine", "Practice", "Classic logic exercises from Gensler's Introduction to Logic.", vec![
            ("syllogistic", "The Syllogism", "Translate English into syllogistic notation", 99, 1),
            ("propositional", "Propositional Logic", "AND, OR, NOT, and IF-THEN connectives", 114, 2),
            ("modal", "Modal Logic", "Possibility and necessity operators", 34, 3),
            ("deontic", "Deontic Logic", "Obligation, permission, and prohibition", 38, 3),
            ("belief", "Belief Logic", "Beliefs, knowledge, and attitudes", 15, 3),
            ("informal", "Definitions & Meanings", "Identify problems with definitions", 48, 2),
        ]),
        ("trivium", "Basics", "Learn to name objects, describe properties, and express relationships.", vec![
            ("atomic", "The Atomic World", "Properties as functions mapping individuals to Truth", 3, 1),
            ("relations", "Connections", "Relations bind multiple individuals", 2, 2),
            ("negation", "Negation", "Negation flips truth values", 2, 2),
        ]),
        ("quadrivium", "Quantifiers", "Master universal and existential quantifiers that give logic its power.", vec![
            ("universal", "Universal Quantification", "The ∀ expresses claims about ALL", 3, 3),
            ("existential", "Existential Quantification", "The ∃ asserts that SOME exists", 2, 3),
            ("scope", "Scope Ambiguity", "Multiple quantifiers create ambiguity", 1, 4),
        ]),
        ("metaphysics", "Modality & Time", "Express possibility, necessity, and temporal relationships.", vec![
            ("modality", "Modal Logic", "Possibility and necessity", 2, 4),
            ("time", "Temporal Logic", "Past and future operators", 2, 4),
        ]),
    ];

    rsx! {
        style { "{LEARN_STYLE}" }

        div { class: "learn-container",
            button {
                class: "back-link",
                onclick: |_| { let _ = web_sys::window().unwrap().history().unwrap().back(); },
                "← Back"
            }

            div { class: "learn-header",
                h1 { "Curriculum" }
                p { "Master first-order logic through progressive challenges" }
            }

            div { class: "era-list",
                for (era_id, title, description, modules) in eras.iter() {
                    div { class: "era-card",
                        div {
                            class: "era-header",
                            onclick: {
                                let era_id_str = era_id.to_string();
                                move |_| {
                                    if expanded_era().as_ref() == Some(&era_id_str) {
                                        expanded_era.set(None);
                                    } else {
                                        expanded_era.set(Some(era_id_str.clone()));
                                    }
                                }
                            },
                            div {
                                div { class: "era-title", "{title}" }
                                div { class: "era-description", "{description}" }
                            }
                            span {
                                class: if expanded_era().as_ref() == Some(&era_id.to_string()) { "era-toggle open" } else { "era-toggle" },
                                "▼"
                            }
                        }

                        if expanded_era().as_ref() == Some(&era_id.to_string()) {
                            div { class: "module-list",
                                for (mod_id, mod_title, mod_desc, ex_count, difficulty) in modules.iter() {
                                    {
                                        let era_for_click = era_id.to_string();
                                        let mod_for_click = mod_id.to_string();
                                        let title_for_click = mod_title.to_string();
                                        rsx! {
                                            div {
                                                class: "module-card",
                                                onclick: move |_| {
                                                    pending_module.set(Some((
                                                        era_for_click.clone(),
                                                        mod_for_click.clone(),
                                                        title_for_click.clone(),
                                                    )));
                                                },
                                                div { class: "module-info",
                                                    h3 { "{mod_title}" }
                                                    p { "{mod_desc}" }
                                                }
                                                div { class: "module-stats",
                                                    span { class: "exercise-count", "{ex_count} exercises" }
                                                    span { class: "difficulty-stars",
                                                        for _ in 0..*difficulty {
                                                            "★"
                                                        }
                                                        for _ in *difficulty..5 {
                                                            "☆"
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                }
            }

            if let Some((era, module, title)) = pending_module() {
                ModeSelector {
                    info: ModeInfo {
                        era: era.clone(),
                        module: module.clone(),
                        title: title.clone(),
                    },
                    on_select: move |mode: String| {
                        let nav = navigator.clone();
                        let e = era.clone();
                        let m = module.clone();
                        pending_module.set(None);
                        nav.push(Route::Lesson {
                            era: e,
                            module: m,
                            mode,
                        });
                    },
                    on_cancel: move |_| {
                        pending_module.set(None);
                    },
                }
            }
        }
    }
}

```

---

### Page: Lesson

**File:** `src/ui/pages/lesson.rs`

Interactive problem-solving interface. Displays generated challenges, accepts FOL input, provides semantic grading with feedback, and tracks progress through exercises.

```rust
use dioxus::prelude::*;
use crate::ui::router::Route;
use crate::ui::components::mixed_text::MixedText;
use crate::ui::components::xp_popup::XpPopup;
use crate::ui::components::combo_indicator::ComboIndicator;
use crate::ui::components::achievement_toast::AchievementToast;
use crate::content::ContentEngine;
use crate::generator::{Generator, Challenge, AnswerType};
use crate::grader::{check_answer, GradeResult};
use crate::progress::UserProgress;
use crate::game::{XpReward, ComboResult, calculate_xp_reward, update_combo};
use crate::achievements::{Achievement, check_achievements, unlock_achievement};
use crate::audio::{SoundEffect, play_sound};

#[derive(Clone, Copy, PartialEq, Default, Debug)]
pub enum SessionMode {
    Textbook,
    #[default]
    Learning,
    Testing,
}

impl SessionMode {
    pub fn from_str(s: &str) -> Self {
        match s.to_lowercase().as_str() {
            "textbook" | "read" => SessionMode::Textbook,
            "testing" | "test" => SessionMode::Testing,
            _ => SessionMode::Learning,
        }
    }

    pub fn to_str(&self) -> &'static str {
        match self {
            SessionMode::Textbook => "textbook",
            SessionMode::Learning => "learning",
            SessionMode::Testing => "testing",
        }
    }

    pub fn shows_hints(&self) -> bool {
        matches!(self, SessionMode::Learning)
    }

    pub fn shows_immediate_feedback(&self) -> bool {
        matches!(self, SessionMode::Learning)
    }

    pub fn shows_explanation(&self) -> bool {
        matches!(self, SessionMode::Learning)
    }

    pub fn xp_multiplier(&self) -> f64 {
        match self {
            SessionMode::Textbook => 0.0,
            SessionMode::Learning => 0.5,
            SessionMode::Testing => 1.0,
        }
    }
}

const LESSON_STYLE: &str = r#"
.lesson-container {
    min-height: 100vh;
    background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
    color: #e8e8e8;
    display: flex;
    flex-direction: column;
}

.lesson-header {
    padding: 16px 24px;
    background: rgba(0, 0, 0, 0.2);
    border-bottom: 1px solid rgba(255, 255, 255, 0.08);
    display: flex;
    justify-content: space-between;
    align-items: center;
}

.breadcrumb {
    display: flex;
    align-items: center;
    gap: 8px;
    color: #888;
    font-size: 14px;
}

.breadcrumb a {
    color: #667eea;
    text-decoration: none;
}

.progress-info {
    display: flex;
    align-items: center;
    gap: 16px;
}

.progress-bar {
    width: 200px;
    height: 8px;
    background: rgba(255, 255, 255, 0.1);
    border-radius: 4px;
    overflow: hidden;
}

.progress-fill {
    height: 100%;
    background: linear-gradient(90deg, #667eea, #764ba2);
    transition: width 0.3s ease;
}

.score-display {
    color: #667eea;
    font-weight: 600;
}

.xp-display {
    color: #4ade80;
    font-weight: 600;
    font-size: 14px;
}

.lesson-main {
    flex: 1;
    display: flex;
    flex-direction: column;
    align-items: center;
    justify-content: center;
    padding: 40px 20px;
}

.problem-card {
    background: rgba(255, 255, 255, 0.05);
    border: 1px solid rgba(255, 255, 255, 0.1);
    border-radius: 20px;
    padding: 40px;
    max-width: 700px;
    width: 100%;
    position: relative;
}

.combo-row {
    position: absolute;
    top: -40px;
    left: 50%;
    transform: translateX(-50%);
}

.problem-prompt {
    color: #888;
    font-size: 14px;
    margin-bottom: 16px;
    text-transform: uppercase;
    letter-spacing: 1px;
}

.problem-sentence {
    font-size: 28px;
    font-weight: 500;
    color: #fff;
    margin-bottom: 32px;
    line-height: 1.4;
}

.answer-input {
    width: 100%;
    padding: 16px 20px;
    font-size: 18px;
    font-family: 'SF Mono', 'Fira Code', monospace;
    background: rgba(255, 255, 255, 0.08);
    border: 2px solid rgba(255, 255, 255, 0.15);
    border-radius: 12px;
    color: #e8e8e8;
    outline: none;
    transition: border-color 0.2s ease;
}

.answer-input:focus {
    border-color: #667eea;
}

.answer-input.correct {
    border-color: #4ade80;
    background: rgba(74, 222, 128, 0.1);
}

.answer-input.incorrect {
    border-color: #f87171;
    background: rgba(248, 113, 113, 0.1);
}

.multiple-choice {
    display: flex;
    flex-direction: column;
    gap: 12px;
}

.choice-btn {
    padding: 16px 20px;
    background: rgba(255, 255, 255, 0.05);
    border: 2px solid rgba(255, 255, 255, 0.1);
    border-radius: 12px;
    color: #e8e8e8;
    font-size: 16px;
    text-align: left;
    cursor: pointer;
    transition: all 0.2s ease;
}

.choice-btn:hover {
    background: rgba(255, 255, 255, 0.08);
    border-color: #667eea;
}

.choice-btn.selected {
    background: rgba(102, 126, 234, 0.2);
    border-color: #667eea;
}

.choice-btn.correct {
    background: rgba(74, 222, 128, 0.2);
    border-color: #4ade80;
}

.choice-btn.incorrect {
    background: rgba(248, 113, 113, 0.2);
    border-color: #f87171;
}

.action-row {
    display: flex;
    justify-content: space-between;
    align-items: center;
    margin-top: 24px;
}

.hint-btn {
    padding: 10px 20px;
    background: transparent;
    border: 1px solid rgba(255, 255, 255, 0.2);
    border-radius: 8px;
    color: #888;
    cursor: pointer;
    transition: all 0.2s ease;
}

.hint-btn:hover {
    border-color: #667eea;
    color: #667eea;
}

.submit-btn {
    padding: 12px 32px;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    border: none;
    border-radius: 8px;
    color: white;
    font-size: 16px;
    font-weight: 600;
    cursor: pointer;
    transition: transform 0.2s ease;
}

.submit-btn:hover {
    transform: scale(1.02);
}

.submit-btn:disabled {
    opacity: 0.5;
    cursor: not-allowed;
}

.feedback-box {
    margin-top: 20px;
    padding: 16px 20px;
    border-radius: 12px;
    font-size: 15px;
}

.feedback-correct {
    background: rgba(74, 222, 128, 0.15);
    border: 1px solid rgba(74, 222, 128, 0.3);
    color: #4ade80;
}

.feedback-incorrect {
    background: rgba(248, 113, 113, 0.15);
    border: 1px solid rgba(248, 113, 113, 0.3);
    color: #f87171;
}

.feedback-partial {
    background: rgba(251, 191, 36, 0.15);
    border: 1px solid rgba(251, 191, 36, 0.3);
    color: #fbbf24;
}

.hint-box {
    margin-top: 16px;
    padding: 16px 20px;
    background: rgba(102, 126, 234, 0.1);
    border: 1px solid rgba(102, 126, 234, 0.2);
    border-radius: 12px;
    color: #a5b4fc;
    font-size: 14px;
}

.explanation-box {
    margin-top: 16px;
    padding: 16px 20px;
    background: rgba(248, 113, 113, 0.08);
    border: 1px solid rgba(248, 113, 113, 0.2);
    border-radius: 12px;
    color: #fca5a5;
    font-size: 14px;
    line-height: 1.6;
}

.explanation-box strong {
    color: #f87171;
    font-weight: 600;
}

.next-btn {
    padding: 12px 32px;
    background: linear-gradient(135deg, #4ade80 0%, #22c55e 100%);
    border: none;
    border-radius: 8px;
    color: white;
    font-size: 16px;
    font-weight: 600;
    cursor: pointer;
}

.complete-message {
    text-align: center;
}

.complete-message h2 {
    font-size: 32px;
    color: #4ade80;
    margin-bottom: 16px;
}

.complete-message p {
    color: #888;
    margin-bottom: 24px;
}

.reading-list {
    display: flex;
    flex-direction: column;
    gap: 8px;
}

.reading-item {
    padding: 12px 16px;
    background: rgba(255, 255, 255, 0.03);
    border: 1px solid rgba(255, 255, 255, 0.08);
    border-radius: 8px;
    font-family: 'SF Mono', 'Fira Code', monospace;
    font-size: 14px;
    color: #a5b4fc;
}

.mode-badge {
    padding: 4px 12px;
    border-radius: 12px;
    font-size: 12px;
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.5px;
}

.mode-badge.learning {
    background: rgba(74, 222, 128, 0.2);
    color: #4ade80;
    border: 1px solid rgba(74, 222, 128, 0.3);
}

.mode-badge.testing {
    background: rgba(251, 146, 60, 0.2);
    color: #fb923c;
    border: 1px solid rgba(251, 146, 60, 0.3);
}

.mode-badge.textbook {
    background: rgba(96, 165, 250, 0.2);
    color: #60a5fa;
    border: 1px solid rgba(96, 165, 250, 0.3);
}

.test-summary {
    margin-top: 24px;
    padding: 20px;
    background: rgba(255, 255, 255, 0.03);
    border-radius: 12px;
    border: 1px solid rgba(255, 255, 255, 0.08);
}

.test-summary h3 {
    margin-bottom: 16px;
    color: #888;
    font-size: 14px;
    text-transform: uppercase;
    letter-spacing: 1px;
}

.result-item {
    padding: 12px;
    margin-bottom: 8px;
    border-radius: 8px;
    display: flex;
    align-items: flex-start;
    gap: 12px;
}

.result-item.correct {
    background: rgba(74, 222, 128, 0.1);
    border: 1px solid rgba(74, 222, 128, 0.2);
}

.result-item.incorrect {
    background: rgba(248, 113, 113, 0.1);
    border: 1px solid rgba(248, 113, 113, 0.2);
}

.result-icon {
    font-size: 18px;
}

.result-content {
    flex: 1;
}

.result-question {
    color: #e8e8e8;
    margin-bottom: 4px;
}

.result-explanation {
    color: #888;
    font-size: 13px;
}

.textbook-container {
    max-width: 700px;
    width: 100%;
}

.textbook-card {
    background: rgba(255, 255, 255, 0.05);
    border: 1px solid rgba(255, 255, 255, 0.1);
    border-radius: 20px;
    padding: 32px;
    margin-bottom: 20px;
}

.textbook-card h2 {
    color: #fff;
    font-size: 24px;
    margin-bottom: 16px;
}

.textbook-intro {
    color: #aaa;
    font-size: 16px;
    line-height: 1.6;
    margin-bottom: 24px;
}

.example-section {
    margin-top: 24px;
}

.example-section h3 {
    color: #667eea;
    font-size: 14px;
    text-transform: uppercase;
    letter-spacing: 1px;
    margin-bottom: 16px;
}

.example-item {
    background: rgba(255, 255, 255, 0.03);
    border: 1px solid rgba(255, 255, 255, 0.08);
    border-radius: 12px;
    padding: 16px;
    margin-bottom: 12px;
}

.example-sentence {
    color: #e8e8e8;
    font-size: 18px;
    margin-bottom: 12px;
}

.example-explanation {
    color: #888;
    font-size: 14px;
    line-height: 1.5;
    padding-left: 16px;
    border-left: 2px solid rgba(102, 126, 234, 0.3);
}

.textbook-nav {
    display: flex;
    justify-content: space-between;
    margin-top: 24px;
}

.textbook-nav-btn {
    padding: 12px 24px;
    background: transparent;
    border: 1px solid rgba(255, 255, 255, 0.2);
    border-radius: 8px;
    color: #888;
    font-size: 14px;
    cursor: pointer;
    transition: all 0.2s ease;
}

.textbook-nav-btn:hover {
    border-color: #667eea;
    color: #667eea;
}

.textbook-nav-btn.primary {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    border: none;
    color: white;
}

.textbook-nav-btn.primary:hover {
    transform: scale(1.02);
}

.page-indicator {
    color: #666;
    font-size: 14px;
    align-self: center;
}
"#;

#[component]
pub fn Lesson(era: String, module: String, mode: String) -> Element {
    let session_mode = SessionMode::from_str(&mode);

    let mut current_index = use_signal(|| 0usize);
    let mut score = use_signal(|| 0u32);
    let mut answer = use_signal(String::new);
    let mut selected_choice = use_signal(|| None::<usize>);
    let mut submitted = use_signal(|| false);
    let mut grade_result = use_signal(|| None::<GradeResult>);
    let mut show_hint = use_signal(|| false);
    let mut challenges = use_signal(Vec::<Challenge>::new);
    let mut initialized = use_signal(|| false);
    let mut test_results = use_signal(Vec::<(usize, bool, String, Option<String>)>::new);

    let mut progress = use_signal(UserProgress::load);
    let mut show_xp_popup = use_signal(|| false);
    let mut current_xp_reward = use_signal(|| None::<XpReward>);
    let mut combo_result = use_signal(|| ComboResult { new_combo: 0, is_new_record: false, multiplier: 1.0 });
    let mut show_achievement = use_signal(|| false);
    let mut current_achievement = use_signal(|| None::<&'static Achievement>);
    let mut first_try_tracker = use_signal(|| std::collections::HashSet::<usize>::new());
    let mut mistakes_in_module = use_signal(|| 0u32);

    let engine = ContentEngine::new();
    let generator = Generator::new();

    let module_data = engine.get_module(&era, &module);

    if !initialized() {
        if let Some(mod_data) = engine.get_module(&era, &module) {
            let mut rng = rand::thread_rng();
            let generated: Vec<Challenge> = mod_data.exercises.iter()
                .filter_map(|ex| generator.generate(ex, &mut rng))
                .collect();
            challenges.set(generated);
            initialized.set(true);
        }
    }

    let total_exercises = challenges.read().len();
    let progress_pct = if total_exercises > 0 {
        ((current_index() + 1) as f64 / total_exercises as f64 * 100.0) as u32
    } else {
        0
    };

    let module_title = module_data.map(|m| m.meta.title.clone()).unwrap_or_default();
    let era_title = match era.as_str() {
        "trivium" => "Basics",
        "quadrivium" => "Quantifiers",
        "metaphysics" => "Modality & Time",
        "logicaffeine" => "Practice",
        _ => "Training",
    };

    let progress_style = format!("width: {}%", progress_pct);
    let user_xp = progress.read().xp;
    let user_combo = progress.read().combo;

    rsx! {
        style { "{LESSON_STYLE}" }

        if show_xp_popup() {
            if let Some(reward) = current_xp_reward() {
                XpPopup {
                    reward: reward.clone(),
                    on_dismiss: move |_| show_xp_popup.set(false)
                }
            }
        }

        if show_achievement() {
            if let Some(achievement) = current_achievement() {
                AchievementToast {
                    achievement: achievement,
                    on_dismiss: move |_| show_achievement.set(false)
                }
            }
        }

        div { class: "lesson-container",
            header { class: "lesson-header",
                nav { class: "breadcrumb",
                    Link { to: Route::Learn {}, "Curriculum" }
                    span { " > " }
                    span { "{era_title}" }
                    span { " > " }
                    span { "{module_title}" }
                    span {
                        class: "mode-badge {session_mode.to_str()}",
                        style: "margin-left: 12px;",
                        "{session_mode.to_str()}"
                    }
                }
                div { class: "progress-info",
                    div { class: "progress-bar",
                        div {
                            class: "progress-fill",
                            style: "{progress_style}",
                        }
                    }
                    if session_mode.xp_multiplier() > 0.0 {
                        span { class: "xp-display", "{user_xp} XP" }
                    }
                    span { class: "score-display", "Score: {score}" }
                }
            }

            main { class: "lesson-main",
                {
                    let challenges_read = challenges.read();
                    let current = current_index();

                    if current >= total_exercises && total_exercises > 0 {
                        let correct_count = test_results.read().iter().filter(|(_, c, _, _)| *c).count();
                        let results_clone = test_results.read().clone();
                        rsx! {
                            div { class: "problem-card complete-message",
                                h2 { "Module Complete!" }
                                p { "You scored {score} points" }
                                if session_mode == SessionMode::Testing {
                                    p { style: "color: #667eea; font-size: 18px; margin-bottom: 8px;",
                                        "Test Results: {correct_count}/{total_exercises} correct"
                                    }
                                }
                                if mistakes_in_module() == 0 && total_exercises > 0 {
                                    p { style: "color: #fbbf24;", "🏆 Flawless! No mistakes!" }
                                }

                                if session_mode == SessionMode::Testing && !results_clone.is_empty() {
                                    div { class: "test-summary",
                                        h3 { "Review Your Answers" }
                                        for (idx, is_correct, sentence, explanation) in results_clone.iter() {
                                            {
                                                let item_class = if *is_correct { "result-item correct" } else { "result-item incorrect" };
                                                let icon = if *is_correct { "✓" } else { "✗" };
                                                rsx! {
                                                    div { class: "{item_class}",
                                                        span { class: "result-icon", "{icon}" }
                                                        div { class: "result-content",
                                                            p { class: "result-question", "Q{idx + 1}: {sentence}" }
                                                            if !is_correct {
                                                                if let Some(expl) = explanation {
                                                                    p { class: "result-explanation", "{expl}" }
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }

                                button {
                                    class: "submit-btn",
                                    onclick: |_| { let _ = web_sys::window().unwrap().history().unwrap().back(); },
                                    "← Back"
                                }
                            }
                        }
                    } else if session_mode == SessionMode::Textbook {
                        let page = current / 5;
                        let total_pages = (challenges_read.len() + 4) / 5;
                        let examples: Vec<_> = challenges_read.iter()
                            .filter_map(|c| {
                                c.explanation.as_ref().map(|e| (c.sentence.clone(), e.clone()))
                            })
                            .skip(page * 5)
                            .take(5)
                            .collect();
                        let era_clone = era.clone();
                        let module_clone = module.clone();
                        rsx! {
                            div { class: "textbook-container",
                                div { class: "textbook-card",
                                    h2 { "{module_title}" }
                                    p { class: "textbook-intro",
                                        "Study the examples below to understand how English sentences translate to first-order logic. Pay attention to the patterns and explanations."
                                    }

                                    div { class: "example-section",
                                        h3 { "Examples" }
                                        for (sentence, explanation) in examples.iter() {
                                            div { class: "example-item",
                                                div { class: "example-sentence",
                                                    MixedText { content: sentence.clone() }
                                                }
                                                div { class: "example-explanation",
                                                    MixedText { content: explanation.clone() }
                                                }
                                            }
                                        }
                                    }

                                    div { class: "textbook-nav",
                                        if page > 0 {
                                            button {
                                                class: "textbook-nav-btn",
                                                onclick: move |_| current_index.set((page - 1) * 5),
                                                "← Previous"
                                            }
                                        } else {
                                            div {}
                                        }

                                        span { class: "page-indicator", "Page {page + 1} of {total_pages}" }

                                        if page + 1 < total_pages {
                                            button {
                                                class: "textbook-nav-btn",
                                                onclick: move |_| current_index.set((page + 1) * 5),
                                                "Next →"
                                            }
                                        } else {
                                            Link {
                                                to: Route::Lesson {
                                                    era: era_clone.clone(),
                                                    module: module_clone.clone(),
                                                    mode: "learning".to_string(),
                                                },
                                                class: "textbook-nav-btn primary",
                                                "Start Practice →"
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    } else if let Some(challenge) = challenges_read.get(current) {
                        let prompt = challenge.prompt.clone();
                        let sentence = challenge.sentence.clone();
                        let hint_text = challenge.hint.clone();
                        let explanation_text = challenge.explanation.clone();
                        let exercise_id = challenge.exercise_id.clone();

                        let input_class = if submitted() {
                            if grade_result().map(|r| r.correct).unwrap_or(false) {
                                "answer-input correct"
                            } else {
                                "answer-input incorrect"
                            }
                        } else {
                            "answer-input"
                        };

                        rsx! {
                            div { class: "problem-card",
                                if user_combo > 0 {
                                    div { class: "combo-row",
                                        ComboIndicator {
                                            combo: user_combo,
                                            multiplier: combo_result().multiplier,
                                            is_new_record: combo_result().is_new_record
                                        }
                                    }
                                }

                                div { class: "problem-prompt", MixedText { content: prompt.clone() } }
                                div { class: "problem-sentence", MixedText { content: sentence.clone() } }

                                {match &challenge.answer {
                                    AnswerType::FreeForm { .. } => rsx! {
                                        input {
                                            class: "{input_class}",
                                            r#type: "text",
                                            placeholder: "Enter your answer in FOL...",
                                            value: "{answer}",
                                            disabled: submitted(),
                                            oninput: move |e| answer.set(e.value()),
                                        }
                                    },
                                    AnswerType::MultipleChoice { options, correct_index } => {
                                        let correct_idx = *correct_index;
                                        let opts = options.clone();
                                        let show_result_colors = session_mode.shows_immediate_feedback();
                                        rsx! {
                                            div { class: "multiple-choice",
                                                for (i, option) in opts.iter().enumerate() {
                                                    {
                                                        let btn_class = if submitted() && show_result_colors {
                                                            if i == correct_idx {
                                                                "choice-btn correct"
                                                            } else if selected_choice() == Some(i) {
                                                                "choice-btn incorrect"
                                                            } else {
                                                                "choice-btn"
                                                            }
                                                        } else if selected_choice() == Some(i) {
                                                            "choice-btn selected"
                                                        } else {
                                                            "choice-btn"
                                                        };
                                                        rsx! {
                                                            button {
                                                                class: "{btn_class}",
                                                                disabled: submitted(),
                                                                onclick: move |_| selected_choice.set(Some(i)),
                                                                MixedText { content: option.clone() }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    },
                                    AnswerType::Ambiguity { readings } => {
                                        let rds = readings.clone();
                                        rsx! {
                                            div { class: "reading-list",
                                                for reading in rds.iter() {
                                                    div { class: "reading-item", "{reading}" }
                                                }
                                            }
                                        }
                                    },
                                }}

                                if session_mode.shows_immediate_feedback() {
                                    if let Some(result) = grade_result() {
                                        {
                                            let fb_class = if result.correct {
                                                "feedback-box feedback-correct"
                                            } else if result.partial {
                                                "feedback-box feedback-partial"
                                            } else {
                                                "feedback-box feedback-incorrect"
                                            };
                                            rsx! {
                                                div { class: "{fb_class}", "{result.feedback}" }
                                            }
                                        }
                                    }
                                }

                                if session_mode.shows_explanation() && submitted() && !grade_result().map(|r| r.correct).unwrap_or(true) {
                                    if let Some(ref expl) = explanation_text {
                                        div { class: "explanation-box",
                                            strong { "Explanation: " }
                                            MixedText { content: expl.clone() }
                                        }
                                    }
                                }

                                if session_mode.shows_hints() && show_hint() && hint_text.is_some() {
                                    div { class: "hint-box", "{hint_text.as_ref().unwrap()}" }
                                }

                                div { class: "action-row",
                                    if session_mode.shows_hints() && !submitted() && hint_text.is_some() {
                                        button {
                                            class: "hint-btn",
                                            onclick: move |_| show_hint.set(true),
                                            "Show Hint"
                                        }
                                    } else {
                                        div {}
                                    }

                                    if submitted() {
                                        button {
                                            class: "next-btn",
                                            onclick: move |_| {
                                                current_index.set(current_index() + 1);
                                                answer.set(String::new());
                                                selected_choice.set(None);
                                                submitted.set(false);
                                                grade_result.set(None);
                                                show_hint.set(false);
                                            },
                                            if current + 1 >= total_exercises {
                                                "Complete Module"
                                            } else {
                                                "Next Problem"
                                            }
                                        }
                                    } else {
                                        {
                                            let can_submit = match &challenge.answer {
                                                AnswerType::FreeForm { .. } => !answer.read().is_empty(),
                                                AnswerType::MultipleChoice { .. } => selected_choice().is_some(),
                                                AnswerType::Ambiguity { .. } => true,
                                            };
                                            let answer_clone = challenge.answer.clone();
                                            let ex_id = exercise_id.clone();
                                            let sentence_for_results = sentence.clone();
                                            let explanation_for_results = explanation_text.clone();
                                            rsx! {
                                                button {
                                                    class: "submit-btn",
                                                    disabled: !can_submit,
                                                    onclick: move |_| {
                                                        let is_correct = match &answer_clone {
                                                            AnswerType::FreeForm { golden_logic } => {
                                                                let result = check_answer(&answer.read(), golden_logic);
                                                                let correct = result.correct;
                                                                if result.correct {
                                                                    score.set(score() + 100);
                                                                } else if result.partial {
                                                                    score.set(score() + result.score);
                                                                }
                                                                grade_result.set(Some(result));
                                                                correct
                                                            }
                                                            AnswerType::MultipleChoice { correct_index, .. } => {
                                                                let correct = selected_choice() == Some(*correct_index);
                                                                let result = if correct {
                                                                    score.set(score() + 100);
                                                                    GradeResult {
                                                                        correct: true,
                                                                        partial: false,
                                                                        score: 100,
                                                                        feedback: "Correct!".to_string(),
                                                                    }
                                                                } else {
                                                                    GradeResult {
                                                                        correct: false,
                                                                        partial: false,
                                                                        score: 0,
                                                                        feedback: "Not quite.".to_string(),
                                                                    }
                                                                };
                                                                grade_result.set(Some(result));
                                                                correct
                                                            }
                                                            AnswerType::Ambiguity { .. } => {
                                                                grade_result.set(Some(GradeResult {
                                                                    correct: true,
                                                                    partial: false,
                                                                    score: 100,
                                                                    feedback: "Good analysis!".to_string(),
                                                                }));
                                                                score.set(score() + 100);
                                                                true
                                                            }
                                                        };

                                                        let is_first_try = !first_try_tracker.read().contains(&current);
                                                        first_try_tracker.write().insert(current);

                                                        {
                                                            let mut prog = progress.write();
                                                            prog.record_attempt(&ex_id, is_correct);

                                                            let cr = update_combo(&mut prog, is_correct);
                                                            combo_result.set(cr.clone());

                                                            if is_correct {
                                                                play_sound(SoundEffect::Correct);

                                                                let xp_mult = session_mode.xp_multiplier();
                                                                if xp_mult > 0.0 {
                                                                    let rng_seed = (prog.xp + current as u64) % 100;
                                                                    let mut reward = calculate_xp_reward(
                                                                        1,
                                                                        cr.new_combo,
                                                                        prog.streak_days,
                                                                        is_first_try,
                                                                        rng_seed,
                                                                    );

                                                                    reward.total = (reward.total as f64 * xp_mult) as u64;
                                                                    prog.xp += reward.total;
                                                                    prog.level = crate::progress::calculate_level(prog.xp);
                                                                    prog.save();

                                                                    current_xp_reward.set(Some(reward));
                                                                    show_xp_popup.set(true);

                                                                    let new_achievements = check_achievements(&prog);
                                                                    if let Some(achievement) = new_achievements.first() {
                                                                        current_achievement.set(Some(*achievement));
                                                                        show_achievement.set(true);
                                                                        unlock_achievement(&mut prog, achievement);
                                                                    }
                                                                }
                                                            } else {
                                                                play_sound(SoundEffect::Incorrect);
                                                                mistakes_in_module.set(mistakes_in_module() + 1);
                                                            }
                                                        }

                                                        if session_mode == SessionMode::Testing {
                                                            test_results.write().push((
                                                                current,
                                                                is_correct,
                                                                sentence_for_results.clone(),
                                                                explanation_for_results.clone(),
                                                            ));
                                                        }

                                                        submitted.set(true);
                                                    },
                                                    "Check Answer"
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    } else {
                        rsx! {
                            div { class: "problem-card",
                                p { "Loading exercises..." }
                            }
                        }
                    }
                }
            }
        }
    }
}

```

---

### Pages: Module

**File:** `src/ui/pages/mod.rs`

Page module exports for Home, Pricing, Workspace, Learn, Lesson, and Studio pages.

```rust
pub mod home;
pub mod landing;
pub mod learn;
pub mod lesson;
pub mod pricing;
pub mod privacy;
pub mod review;
pub mod roadmap;
pub mod success;
pub mod terms;
pub mod workspace;
pub mod studio;

pub use home::Home;
pub use landing::Landing;
pub use learn::Learn;
pub use lesson::Lesson;
pub use pricing::Pricing;
pub use privacy::Privacy;
pub use review::Review;
pub use roadmap::Roadmap;
pub use success::Success;
pub use terms::Terms;
pub use workspace::Workspace;
pub use studio::Studio;

```

---

### Page: Pricing

**File:** `src/ui/pages/pricing.rs`

Commercial licensing information page with Fair Source explanation and enterprise contact details.

```rust
use dioxus::prelude::*;

const PRICING_STYLE: &str = r#"
:root {
  --bg0: #070a12;
  --bg1: #0b1022;
  --card: rgba(255,255,255,0.06);
  --border: rgba(255,255,255,0.10);
  --border2: rgba(255,255,255,0.14);
  --text: #e5e7eb;
  --muted: rgba(229,231,235,0.72);
  --muted2: rgba(229,231,235,0.56);
  --brand: #a78bfa;
  --brand2: #60a5fa;
  --ok: #22c55e;
}

* { box-sizing: border-box; }
a { color: inherit; }

.pricing {
  height: 100vh;
  color: var(--text);
  background:
    radial-gradient(1200px 600px at 50% -120px, rgba(167,139,250,0.18), transparent 60%),
    radial-gradient(900px 500px at 15% 30%, rgba(96,165,250,0.18), transparent 60%),
    radial-gradient(800px 450px at 90% 45%, rgba(34,197,94,0.10), transparent 62%),
    linear-gradient(180deg, var(--bg0), var(--bg1) 55%, #070a12);
  overflow-x: hidden;
  overflow-y: auto;
  font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Inter, "Helvetica Neue", Arial, "Noto Sans";
  position: relative;
}

.bg-orb {
  position: absolute;
  inset: auto;
  width: 520px;
  height: 520px;
  border-radius: 999px;
  filter: blur(42px);
  opacity: 0.22;
  pointer-events: none;
  animation: float 14s ease-in-out infinite, pulse-glow 10s ease-in-out infinite;
}
.orb1 { top: -220px; left: -160px; background: radial-gradient(circle at 30% 30%, var(--brand2), transparent 60%); animation-delay: 0s; }
.orb2 { top: 120px; right: -200px; background: radial-gradient(circle at 40% 35%, var(--brand), transparent 60%); animation-delay: -5s; }
.orb3 { bottom: -260px; left: 20%; background: radial-gradient(circle at 40% 35%, rgba(34,197,94,0.9), transparent 60%); animation-delay: -10s; }

@keyframes float {
  0%, 100% { transform: translate3d(0, 0, 0); }
  50% { transform: translate3d(0, -20px, 0); }
}

@keyframes pulse-glow {
  0%, 100% { opacity: 0.22; }
  50% { opacity: 0.32; }
}

@keyframes fadeInUp {
  from { opacity: 0; transform: translateY(24px); }
  to { opacity: 1; transform: translateY(0); }
}

.pricing-container {
  position: relative;
  display: flex;
  flex-direction: column;
  align-items: center;
  padding: 60px 20px;
  max-width: 1000px;
  margin: 0 auto;
}

.pricing-header {
  text-align: center;
  margin-bottom: 50px;
  animation: fadeInUp 0.6s ease both;
}

.pricing-header h1 {
  font-size: 48px;
  font-weight: 900;
  letter-spacing: -2px;
  background: linear-gradient(180deg, #ffffff 0%, rgba(229,231,235,0.78) 65%, rgba(229,231,235,0.62) 100%);
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
  margin-bottom: 16px;
}

.pricing-header p {
  color: var(--muted);
  font-size: 18px;
  line-height: 1.65;
}

.pricing-tiers {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
  gap: 24px;
  width: 100%;
  margin-bottom: 40px;
}

.tier-card {
  position: relative;
  background: rgba(255,255,255,0.04);
  border: 1px solid var(--border);
  border-radius: 18px;
  padding: 32px;
  display: flex;
  flex-direction: column;
  backdrop-filter: blur(18px);
  transition: transform 0.18s ease, border-color 0.18s ease, background 0.18s ease;
  overflow: hidden;
  animation: fadeInUp 0.6s ease both;
}

.tier-card:nth-child(1) { animation-delay: 0.1s; }
.tier-card:nth-child(2) { animation-delay: 0.15s; }
.tier-card:nth-child(3) { animation-delay: 0.2s; }
.tier-card:nth-child(4) { animation-delay: 0.25s; }
.tier-card:nth-child(5) { animation-delay: 0.3s; }

.tier-card::before {
  content: "";
  position: absolute;
  inset: 0;
  border-radius: 18px;
  background: linear-gradient(135deg, rgba(96,165,250,0.12), rgba(167,139,250,0.12));
  opacity: 0;
  transition: opacity 0.3s ease;
  pointer-events: none;
}

.tier-card:hover {
  transform: translateY(-3px);
  border-color: rgba(167,139,250,0.28);
  background: rgba(255,255,255,0.06);
}

.tier-card:hover::before {
  opacity: 1;
}

.tier-card.supporter {
  border-color: rgba(167,139,250,0.35);
  background: linear-gradient(135deg, rgba(167,139,250,0.08) 0%, rgba(96,165,250,0.06) 100%);
}

.tier-card.disabled {
  opacity: 0.4;
  pointer-events: none;
  filter: grayscale(0.5);
}

.tier-card.disabled:hover {
  transform: none;
  border-color: var(--border);
  background: rgba(255,255,255,0.04);
}

.tier-card.disabled::before {
  display: none;
}

.tier-card.disabled .btn-primary,
.tier-card.disabled .btn-secondary,
.tier-card.disabled .btn-contact {
  background: rgba(255,255,255,0.08);
  cursor: not-allowed;
  box-shadow: none;
}

.free-license-banner {
  position: relative;
  background: rgba(255,255,255,0.04);
  border: 1px solid var(--border);
  border-radius: 18px;
  padding: 32px;
  margin-bottom: 40px;
  width: 100%;
  text-align: center;
  backdrop-filter: blur(18px);
  animation: fadeInUp 0.6s ease 0.05s both;
}

.free-license-banner.disabled {
  opacity: 0.4;
  pointer-events: none;
  filter: grayscale(0.5);
}

.free-license-banner h2 {
  color: var(--text);
  font-size: 24px;
  margin-bottom: 12px;
  font-weight: 700;
}

.free-license-banner p {
  color: var(--muted);
  margin-bottom: 20px;
  line-height: 1.65;
}

.free-license-banner .btn-free {
  display: inline-block;
  background: linear-gradient(135deg, rgba(96,165,250,0.95), rgba(167,139,250,0.95));
  color: #060814;
  padding: 14px 32px;
  border-radius: 14px;
  font-size: 16px;
  font-weight: 650;
  text-decoration: none;
  transition: all 0.2s ease;
  box-shadow: 0 18px 40px rgba(96,165,250,0.18);
}

.free-license-banner .btn-free:hover {
  transform: translateY(-2px);
  box-shadow: 0 6px 20px rgba(96,165,250,0.4);
}

.tier-badge {
  display: inline-block;
  background: linear-gradient(135deg, var(--brand2), var(--brand));
  color: #060814;
  font-size: 11px;
  font-weight: 700;
  padding: 5px 12px;
  border-radius: 999px;
  margin-bottom: 16px;
  align-self: flex-start;
  text-transform: uppercase;
  letter-spacing: 0.5px;
}

.early-access-badge {
  display: inline-block;
  background: linear-gradient(135deg, var(--ok), #16a34a);
  color: #060814;
  font-size: 10px;
  font-weight: 700;
  padding: 4px 10px;
  border-radius: 999px;
  margin-bottom: 12px;
  align-self: flex-start;
  text-transform: uppercase;
  letter-spacing: 0.5px;
}

.coming-soon-badge {
  display: inline-block;
  background: rgba(255,255,255,0.12);
  color: var(--muted);
  font-size: 10px;
  font-weight: 700;
  padding: 4px 10px;
  border-radius: 999px;
  margin-bottom: 12px;
  align-self: flex-start;
  text-transform: uppercase;
  letter-spacing: 0.5px;
}

.tier-name {
  color: var(--text);
  font-size: 24px;
  font-weight: 700;
  margin-bottom: 8px;
}

.tier-revenue {
  color: var(--muted);
  font-size: 14px;
  margin-bottom: 20px;
}

.tier-price {
  margin-bottom: 8px;
}

.tier-price .amount {
  color: var(--text);
  font-size: 36px;
  font-weight: 800;
}

.tier-price .period {
  color: var(--muted);
  font-size: 16px;
}

.tier-annual {
  color: var(--brand);
  font-size: 14px;
  margin-bottom: 24px;
}

.tier-features {
  list-style: none;
  padding: 0;
  margin: 0 0 24px 0;
  flex-grow: 1;
}

.tier-features li {
  color: var(--muted);
  font-size: 14px;
  padding: 8px 0;
  padding-left: 24px;
  position: relative;
  line-height: 1.5;
}

.tier-features li::before {
  content: "✓";
  position: absolute;
  left: 0;
  color: var(--brand);
}

.tier-buttons {
  display: flex;
  flex-direction: column;
  gap: 12px;
}

.btn-primary {
  display: block;
  background: linear-gradient(135deg, rgba(96,165,250,0.95), rgba(167,139,250,0.95));
  color: #060814;
  padding: 14px 24px;
  border-radius: 14px;
  font-size: 16px;
  font-weight: 650;
  text-decoration: none;
  text-align: center;
  transition: all 0.2s ease;
  box-shadow: 0 18px 40px rgba(96,165,250,0.18);
}

.btn-primary:hover {
  transform: translateY(-2px);
  box-shadow: 0 6px 20px rgba(96,165,250,0.4);
}

.btn-secondary {
  display: block;
  background: rgba(255,255,255,0.05);
  color: var(--brand);
  padding: 14px 24px;
  border: 1px solid rgba(167,139,250,0.3);
  border-radius: 14px;
  font-size: 14px;
  font-weight: 600;
  text-decoration: none;
  text-align: center;
  transition: all 0.2s ease;
}

.btn-secondary:hover {
  background: rgba(167,139,250,0.1);
  border-color: rgba(167,139,250,0.5);
}

.btn-contact {
  display: block;
  background: rgba(255,255,255,0.06);
  color: var(--text);
  padding: 14px 24px;
  border-radius: 14px;
  border: 1px solid var(--border);
  font-size: 16px;
  font-weight: 600;
  text-decoration: none;
  text-align: center;
  transition: all 0.2s ease;
}

.btn-contact:hover {
  background: rgba(255,255,255,0.10);
  border-color: var(--border2);
}

.lifetime-section {
  position: relative;
  background: linear-gradient(135deg, rgba(167,139,250,0.12) 0%, rgba(96,165,250,0.08) 100%);
  border: 1px solid rgba(167,139,250,0.3);
  border-radius: 18px;
  padding: 40px;
  text-align: center;
  width: 100%;
  margin-bottom: 40px;
  backdrop-filter: blur(18px);
  animation: fadeInUp 0.6s ease 0.1s both;
  overflow: hidden;
}

.lifetime-section::before {
  content: "";
  position: absolute;
  inset: 0;
  background: radial-gradient(600px 300px at 50% 0%, rgba(167,139,250,0.15), transparent 70%);
  pointer-events: none;
}

.lifetime-section h2 {
  position: relative;
  color: var(--text);
  font-size: 24px;
  font-weight: 700;
  margin-bottom: 12px;
}

.lifetime-section .price {
  position: relative;
  color: var(--brand);
  font-size: 42px;
  font-weight: 800;
  margin-bottom: 8px;
}

.lifetime-section .subtext {
  position: relative;
  color: var(--muted);
  font-size: 14px;
  margin-bottom: 24px;
}

.license-section {
  background: rgba(255,255,255,0.04);
  border: 1px solid var(--border);
  border-radius: 18px;
  padding: 40px;
  margin-bottom: 40px;
  width: 100%;
  backdrop-filter: blur(18px);
  animation: fadeInUp 0.6s ease 0.35s both;
}

.license-section h2 {
  color: var(--text);
  font-size: 24px;
  font-weight: 700;
  margin-bottom: 20px;
}

.license-section h3 {
  color: var(--brand);
  font-size: 18px;
  font-weight: 600;
  margin: 24px 0 12px 0;
}

.license-section p {
  color: var(--muted);
  line-height: 1.8;
  margin-bottom: 16px;
}

.license-section ul {
  color: var(--muted);
  line-height: 1.8;
  margin-left: 24px;
  margin-bottom: 16px;
}

.license-section li {
  margin-bottom: 8px;
}

.manage-section {
  background: rgba(255,255,255,0.03);
  border: 1px solid var(--border);
  border-radius: 18px;
  padding: 32px;
  text-align: center;
  width: 100%;
  margin-bottom: 40px;
  backdrop-filter: blur(18px);
  animation: fadeInUp 0.6s ease 0.3s both;
}

.manage-section p {
  color: var(--muted);
  margin-bottom: 16px;
  line-height: 1.65;
}

.contact-section {
  background: linear-gradient(135deg, rgba(96,165,250,0.08) 0%, rgba(167,139,250,0.08) 100%);
  border: 1px solid rgba(167,139,250,0.25);
  border-radius: 18px;
  padding: 40px;
  text-align: center;
  width: 100%;
  backdrop-filter: blur(18px);
  animation: fadeInUp 0.6s ease 0.4s both;
}

.contact-section h2 {
  color: var(--text);
  font-size: 24px;
  font-weight: 700;
  margin-bottom: 16px;
}

.contact-section p {
  color: var(--muted);
  margin-bottom: 24px;
  line-height: 1.65;
}

.contact-links {
  display: flex;
  gap: 16px;
  justify-content: center;
  flex-wrap: wrap;
}

.contact-email {
  display: inline-block;
  background: linear-gradient(135deg, rgba(96,165,250,0.95), rgba(167,139,250,0.95));
  color: #060814;
  padding: 14px 32px;
  border-radius: 14px;
  font-size: 16px;
  font-weight: 650;
  text-decoration: none;
  transition: all 0.2s ease;
  box-shadow: 0 18px 40px rgba(96,165,250,0.18);
}

.contact-email:hover {
  transform: translateY(-2px);
  box-shadow: 0 6px 20px rgba(96,165,250,0.4);
}

.back-link {
  margin-top: 40px;
  background: rgba(255,255,255,0.05);
  border: 1px solid var(--border);
  border-radius: 14px;
  padding: 12px 24px;
  color: var(--muted);
  font-size: 15px;
  font-weight: 600;
  cursor: pointer;
  transition: all 0.2s ease;
}

.back-link:hover {
  background: rgba(255,255,255,0.08);
  color: var(--text);
  border-color: var(--border2);
}

.pricing-footer-links {
  display: flex;
  gap: 12px;
  align-items: center;
  margin-top: 40px;
}

.github-btn {
  display: flex;
  align-items: center;
  justify-content: center;
  gap: 8px;
  background: rgba(255,255,255,0.05);
  border: 1px solid var(--border);
  border-radius: 14px;
  padding: 12px 20px;
  color: var(--muted);
  font-size: 15px;
  font-weight: 600;
  text-decoration: none;
  transition: all 0.2s ease;
}

.github-btn:hover {
  background: rgba(255,255,255,0.08);
  color: var(--text);
  border-color: var(--border2);
}

.github-btn svg {
  width: 18px;
  height: 18px;
  fill: currentColor;
}

@media (max-width: 700px) {
  .pricing-header h1 {
    font-size: 36px;
  }
  .pricing-tiers {
    grid-template-columns: 1fr;
  }
}

@media (prefers-reduced-motion: reduce) {
  * { transition: none !important; animation: none !important; }
}
"#;

const STRIPE_FREE_LICENSE: &str = "https://buy.stripe.com/9B63cx77ZgB5cKu40Ue3e06";
const STRIPE_SUPPORTER_MONTHLY: &str = "https://buy.stripe.com/5kQbJ33VN5Wr25Q8hae3e05";
const STRIPE_PRO_MONTHLY: &str = "https://buy.stripe.com/eVq00lgIzckPbGqcxqe3e03";
const STRIPE_PRO_ANNUAL: &str = "https://buy.stripe.com/4gM3cxakb0C76m69lee3e04";
const STRIPE_PREMIUM_MONTHLY: &str = "https://buy.stripe.com/dRm4gB9g73OjfWG2WQe3e01";
const STRIPE_PREMIUM_ANNUAL: &str = "https://buy.stripe.com/5kQ9AVcsjfx1h0K54Ye3e02";
const STRIPE_LIFETIME: &str = "https://buy.stripe.com/8x200l3VN98D7qa1SMe3e00";
const STRIPE_CUSTOMER_PORTAL: &str = "https://billing.stripe.com/p/login/8x200l3VN98D7qa1SMe3e00";

#[component]
pub fn Pricing() -> Element {
    rsx! {
        style { "{PRICING_STYLE}" }

        div { class: "pricing",
            div { class: "bg-orb orb1" }
            div { class: "bg-orb orb2" }
            div { class: "bg-orb orb3" }

            div { class: "pricing-container",
                div { class: "pricing-header",
                    h1 { "Commercial Licensing" }
                    p { "Business Source License — free for individuals and small teams" }
                }

                div { class: "free-license-banner disabled",
                    h2 { "Free for Small Teams" }
                    p {
                        "Individuals and organizations with fewer than 25 employees can use LOGOS at no cost. "
                        "Get a free license to track your usage and unlock all features."
                    }
                    a {
                        class: "btn-free",
                        href: STRIPE_FREE_LICENSE,
                        target: "_blank",
                        "Get Free License"
                    }
                }

                div { class: "lifetime-section",
                    span { class: "early-access-badge", "Early Access Pricing" }
                    h2 { "Lifetime License" }
                    div { class: "price", "$50/seat" }
                    div { class: "subtext", "One-time payment. Permanent, transferable commercial license." }
                    a {
                        class: "btn-primary",
                        href: STRIPE_LIFETIME,
                        target: "_blank",
                        "Buy Lifetime License"
                    }
                }

                div { class: "pricing-tiers",
                    div { class: "tier-card supporter",
                        span { class: "early-access-badge", "Early Access Pricing" }
                        div { class: "tier-name", "Supporter" }
                        div { class: "tier-revenue", "For individuals and hobbyists" }
                        div { class: "tier-price",
                            span { class: "amount", "$5" }
                            span { class: "period", " /month" }
                        }
                        div { class: "tier-annual", "Optional - personal use is free" }
                        ul { class: "tier-features",
                            li { "Support LOGOS development" }
                            li { "Personal/hobbyist use" }
                            li { "Full feature access" }
                        }
                        div { class: "tier-buttons",
                            a {
                                class: "btn-primary",
                                href: STRIPE_SUPPORTER_MONTHLY,
                                target: "_blank",
                                "Become a Supporter"
                            }
                        }
                    }

                    div { class: "tier-card disabled",
                        span { class: "coming-soon-badge", "Coming Soon" }
                        div { class: "tier-name", "Pro" }
                        div { class: "tier-revenue", "For organizations with 25-100 employees" }
                        div { class: "tier-price",
                            span { class: "amount", "$25" }
                            span { class: "period", " /seat/month" }
                        }
                        div { class: "tier-annual", "or $240/seat/year (save 20%)" }
                        ul { class: "tier-features",
                            li { "Commercial use license" }
                            li { "Full feature access" }
                            li { "Regular updates" }
                        }
                        div { class: "tier-buttons",
                            a {
                                class: "btn-primary",
                                href: STRIPE_PRO_MONTHLY,
                                target: "_blank",
                                "Subscribe Monthly"
                            }
                            a {
                                class: "btn-secondary",
                                href: STRIPE_PRO_ANNUAL,
                                target: "_blank",
                                "Subscribe Annually"
                            }
                        }
                    }

                    div { class: "tier-card disabled",
                        span { class: "coming-soon-badge", "Coming Soon" }
                        div { class: "tier-name", "Premium" }
                        div { class: "tier-revenue", "For organizations with 100-500 employees" }
                        div { class: "tier-price",
                            span { class: "amount", "$50" }
                            span { class: "period", " /seat/month" }
                        }
                        div { class: "tier-annual", "or $480/seat/year (save 20%)" }
                        ul { class: "tier-features",
                            li { "Everything in Pro" }
                            li { "Early access to new features" }
                            li { "Custom integrations" }
                        }
                        div { class: "tier-buttons",
                            a {
                                class: "btn-primary",
                                href: STRIPE_PREMIUM_MONTHLY,
                                target: "_blank",
                                "Subscribe Monthly"
                            }
                            a {
                                class: "btn-secondary",
                                href: STRIPE_PREMIUM_ANNUAL,
                                target: "_blank",
                                "Subscribe Annually"
                            }
                        }
                    }

                    div { class: "tier-card disabled",
                        span { class: "coming-soon-badge", "Coming Soon" }
                        div { class: "tier-name", "Enterprise" }
                        div { class: "tier-revenue", "For organizations with 500+ employees" }
                        div { class: "tier-price",
                            span { class: "amount", "Custom" }
                        }
                        div { class: "tier-annual", "Tailored to your needs" }
                        ul { class: "tier-features",
                            li { "Everything in Premium" }
                            li { "On-premise deployment options" }
                            li { "Volume discounts" }
                        }
                        div { class: "tier-buttons",
                            a {
                                class: "btn-contact",
                                href: "mailto:tristen@brahmastra-labs.com",
                                "Contact Sales"
                            }
                        }
                    }

                    div { class: "tier-card disabled",
                        span { class: "coming-soon-badge", "Coming Soon" }
                        div { class: "tier-name", "Support Plans" }
                        div { class: "tier-revenue", "Technical support available separately" }
                        div { class: "tier-price",
                            span { class: "amount", "Custom" }
                        }
                        div { class: "tier-annual", "Tailored to your needs" }
                        ul { class: "tier-features",
                            li { "Priority email support" }
                            li { "Dedicated support" }
                            li { "Custom SLAs" }
                            li { "Training and onboarding" }
                        }
                        div { class: "tier-buttons",
                            a {
                                class: "btn-contact",
                                href: "mailto:tristen@brahmastra-labs.com",
                                "Contact for Pricing"
                            }
                        }
                    }
                }

                div { class: "manage-section",
                    p { "Already a subscriber? Manage your subscription, update payment methods, or view invoices." }
                    a {
                        class: "btn-secondary",
                        href: STRIPE_CUSTOMER_PORTAL,
                        target: "_blank",
                        "Manage Subscription"
                    }
                }

                div { class: "license-section",
                    h2 { "Business Source License" }

                    p {
                        "LOGOS is released under the Business Source License 1.1. The source code is "
                        "publicly available, and the software is free to use for individuals and small teams."
                    }

                    h3 { "Free Use" }
                    p { "You may use LOGOS at no cost if you are:" }
                    ul {
                        li { "An individual" }
                        li { "An organization with fewer than 25 employees" }
                    }

                    h3 { "Commercial License Required" }
                    p {
                        "If your organization has 25 or more employees and you wish to use "
                        "LOGOS as a Logic Service, a commercial license is required. Select a tier above "
                        "based on your organization's size."
                    }

                    h3 { "Open Source Transition" }
                    p {
                        "On December 24, 2029, LOGOS will transition to the MIT License, "
                        "making it fully open source."
                    }
                }

                div { class: "contact-section",
                    h2 { "Get in Touch" }
                    p { "Questions about licensing, support contracts, or enterprise needs?" }
                    div { class: "contact-links",
                        a {
                            class: "contact-email",
                            href: "mailto:tristen@brahmastra-labs.com",
                            "Enterprise Sales"
                        }
                        a {
                            class: "contact-email",
                            href: "mailto:tristen@brahmastra-labs.com",
                            "Support Inquiries"
                        }
                    }
                }

                div { class: "pricing-footer-links",
                    a {
                        href: "https://github.com/Brahmastra-Labs/logicaffeine",
                        target: "_blank",
                        class: "github-btn",
                        svg {
                            xmlns: "http://www.w3.org/2000/svg",
                            view_box: "0 0 24 24",
                            path {
                                d: "M12 0C5.37 0 0 5.37 0 12c0 5.31 3.435 9.795 8.205 11.385.6.105.825-.255.825-.57 0-.285-.015-1.23-.015-2.235-3.015.555-3.795-.735-4.035-1.41-.135-.345-.72-1.41-1.23-1.695-.42-.225-1.02-.78-.015-.795.945-.015 1.62.87 1.845 1.23 1.08 1.815 2.805 1.305 3.495.99.105-.78.42-1.305.765-1.605-2.67-.3-5.46-1.335-5.46-5.925 0-1.305.465-2.385 1.23-3.225-.12-.3-.54-1.53.12-3.18 0 0 1.005-.315 3.3 1.23.96-.27 1.98-.405 3-.405s2.04.135 3 .405c2.295-1.56 3.3-1.23 3.3-1.23.66 1.65.24 2.88.12 3.18.765.84 1.23 1.905 1.23 3.225 0 4.605-2.805 5.625-5.475 5.925.435.375.81 1.095.81 2.22 0 1.605-.015 2.895-.015 3.3 0 .315.225.69.825.57A12.02 12.02 0 0024 12c0-6.63-5.37-12-12-12z"
                            }
                        }
                        "GitHub"
                    }
                    button {
                        class: "back-link",
                        onclick: |_| { let _ = web_sys::window().unwrap().history().unwrap().back(); },
                        "← Back"
                    }
                }
            }
        }
    }
}

```

---

### Page: privacy

**File:** `src/ui/pages/privacy.rs`

Application page component.

```rust
use dioxus::prelude::*;
use crate::ui::router::Route;

const PRIVACY_HTML: &str = include_str!("../../../privacy.html");

const LEGAL_STYLE: &str = r#"
.legal-container {
    min-height: 100vh;
    display: flex;
    flex-direction: column;
    background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
}

.legal-nav {
    position: sticky;
    top: 0;
    z-index: 50;
    backdrop-filter: blur(18px);
    background: linear-gradient(180deg, rgba(7,10,18,0.72), rgba(7,10,18,0.44));
    border-bottom: 1px solid rgba(255,255,255,0.06);
    padding: 16px 20px;
}

.legal-nav-inner {
    max-width: 1120px;
    margin: 0 auto;
    display: flex;
    align-items: center;
    justify-content: space-between;
}

.legal-brand {
    display: flex;
    align-items: center;
    gap: 12px;
    text-decoration: none;
    color: #e5e7eb;
}

.legal-logo {
    width: 36px;
    height: 36px;
    border-radius: 12px;
    background:
        radial-gradient(circle at 30% 30%, rgba(96,165,250,0.85), transparent 55%),
        radial-gradient(circle at 65% 60%, rgba(167,139,250,0.85), transparent 55%),
        rgba(255,255,255,0.06);
    border: 1px solid rgba(255,255,255,0.10);
}

.legal-brand-name {
    font-weight: 800;
    font-size: 14px;
    letter-spacing: -0.5px;
}

.legal-back {
    color: #a78bfa;
    text-decoration: none;
    font-size: 14px;
    padding: 8px 16px;
    border-radius: 8px;
    border: 1px solid rgba(167,139,250,0.3);
    transition: all 0.2s ease;
}

.legal-back:hover {
    background: rgba(167,139,250,0.1);
    border-color: rgba(167,139,250,0.5);
}

.legal-content {
    flex: 1;
    max-width: 900px;
    margin: 0 auto;
    padding: 40px 20px 60px;
    width: 100%;
}

.legal-content-inner {
    background: rgba(255, 255, 255, 0.98);
    border-radius: 16px;
    padding: 40px;
    box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
}

.legal-footer {
    border-top: 1px solid rgba(255,255,255,0.06);
    padding: 24px 20px;
    text-align: center;
    color: rgba(229,231,235,0.56);
    font-size: 13px;
}

.legal-footer a {
    color: rgba(229,231,235,0.72);
    text-decoration: none;
    margin: 0 8px;
}

.legal-footer a:hover {
    color: #a78bfa;
}

.legal-nav-links {
    display: flex;
    align-items: center;
    gap: 12px;
}

.legal-github {
    display: flex;
    align-items: center;
    justify-content: center;
    width: 36px;
    height: 36px;
    border-radius: 8px;
    border: 1px solid rgba(255,255,255,0.1);
    background: rgba(255,255,255,0.03);
    color: rgba(229,231,235,0.72);
    transition: all 0.2s ease;
}

.legal-github:hover {
    background: rgba(255,255,255,0.08);
    color: #e5e7eb;
    border-color: rgba(255,255,255,0.2);
}

.legal-github svg {
    width: 18px;
    height: 18px;
    fill: currentColor;
}

.github-link {
    display: inline-flex;
    align-items: center;
    gap: 6px;
}
"#;

#[component]
pub fn Privacy() -> Element {
    rsx! {
        style { "{LEGAL_STYLE}" }

        div { class: "legal-container",
            nav { class: "legal-nav",
                div { class: "legal-nav-inner",
                    Link {
                        to: Route::Landing {},
                        class: "legal-brand",
                        div { class: "legal-logo" }
                        span { class: "legal-brand-name", "LOGICAFFEINE" }
                    }
                    div { class: "legal-nav-links",
                        a {
                            href: "https://github.com/Brahmastra-Labs/logicaffeine",
                            target: "_blank",
                            class: "legal-github",
                            title: "View on GitHub",
                            svg {
                                xmlns: "http://www.w3.org/2000/svg",
                                view_box: "0 0 24 24",
                                path {
                                    d: "M12 0C5.37 0 0 5.37 0 12c0 5.31 3.435 9.795 8.205 11.385.6.105.825-.255.825-.57 0-.285-.015-1.23-.015-2.235-3.015.555-3.795-.735-4.035-1.41-.135-.345-.72-1.41-1.23-1.695-.42-.225-1.02-.78-.015-.795.945-.015 1.62.87 1.845 1.23 1.08 1.815 2.805 1.305 3.495.99.105-.78.42-1.305.765-1.605-2.67-.3-5.46-1.335-5.46-5.925 0-1.305.465-2.385 1.23-3.225-.12-.3-.54-1.53.12-3.18 0 0 1.005-.315 3.3 1.23.96-.27 1.98-.405 3-.405s2.04.135 3 .405c2.295-1.56 3.3-1.23 3.3-1.23.66 1.65.24 2.88.12 3.18.765.84 1.23 1.905 1.23 3.225 0 4.605-2.805 5.625-5.475 5.925.435.375.81 1.095.81 2.22 0 1.605-.015 2.895-.015 3.3 0 .315.225.69.825.57A12.02 12.02 0 0024 12c0-6.63-5.37-12-12-12z"
                                }
                            }
                        }
                        Link {
                            to: Route::Landing {},
                            class: "legal-back",
                            "← Back to Home"
                        }
                    }
                }
            }

            main { class: "legal-content",
                div {
                    class: "legal-content-inner",
                    dangerous_inner_html: "{PRIVACY_HTML}"
                }
            }

            footer { class: "legal-footer",
                span { "© 2025 Brahmastra Labs LLC" }
                span { " • " }
                a {
                    href: "https://github.com/Brahmastra-Labs/logicaffeine",
                    target: "_blank",
                    class: "github-link",
                    svg {
                        xmlns: "http://www.w3.org/2000/svg",
                        width: "14",
                        height: "14",
                        view_box: "0 0 24 24",
                        fill: "currentColor",
                        path {
                            d: "M12 0C5.37 0 0 5.37 0 12c0 5.31 3.435 9.795 8.205 11.385.6.105.825-.255.825-.57 0-.285-.015-1.23-.015-2.235-3.015.555-3.795-.735-4.035-1.41-.135-.345-.72-1.41-1.23-1.695-.42-.225-1.02-.78-.015-.795.945-.015 1.62.87 1.845 1.23 1.08 1.815 2.805 1.305 3.495.99.105-.78.42-1.305.765-1.605-2.67-.3-5.46-1.335-5.46-5.925 0-1.305.465-2.385 1.23-3.225-.12-.3-.54-1.53.12-3.18 0 0 1.005-.315 3.3 1.23.96-.27 1.98-.405 3-.405s2.04.135 3 .405c2.295-1.56 3.3-1.23 3.3-1.23.66 1.65.24 2.88.12 3.18.765.84 1.23 1.905 1.23 3.225 0 4.605-2.805 5.625-5.475 5.925.435.375.81 1.095.81 2.22 0 1.605-.015 2.895-.015 3.3 0 .315.225.69.825.57A12.02 12.02 0 0024 12c0-6.63-5.37-12-12-12z"
                        }
                    }
                    "GitHub"
                }
                span { " • " }
                Link { to: Route::Privacy {}, "Privacy Policy" }
                span { " • " }
                Link { to: Route::Terms {}, "Terms of Use" }
            }
        }
    }
}

```

---

### Page: review

**File:** `src/ui/pages/review.rs`

Application page component.

```rust
use dioxus::prelude::*;
use crate::ui::router::Route;
use crate::ui::components::mixed_text::MixedText;
use crate::ui::components::xp_popup::XpPopup;
use crate::ui::components::combo_indicator::ComboIndicator;
use crate::ui::components::streak_display::StreakDisplay;
use crate::ui::components::achievement_toast::AchievementToast;
use crate::content::ContentEngine;
use crate::generator::{Generator, Challenge, AnswerType};
use crate::grader::{check_answer, GradeResult};
use crate::progress::UserProgress;
use crate::srs::{ResponseQuality, sm2_update, calculate_next_review, is_due};
use crate::game::{XpReward, ComboResult, StreakStatus, calculate_xp_reward, update_combo, update_streak};
use crate::achievements::{Achievement, check_achievements, unlock_achievement};
use crate::audio::{SoundEffect, play_sound};

const REVIEW_STYLE: &str = r#"
.review-container {
    min-height: 100vh;
    background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
    color: #e8e8e8;
    display: flex;
    flex-direction: column;
}

.review-header {
    padding: 16px 24px;
    background: rgba(0, 0, 0, 0.2);
    border-bottom: 1px solid rgba(255, 255, 255, 0.08);
    display: flex;
    justify-content: space-between;
    align-items: center;
}

.review-title {
    font-size: 20px;
    font-weight: 600;
    color: #a5b4fc;
}

.review-count {
    color: #888;
    font-size: 14px;
}

.review-stats {
    display: flex;
    align-items: center;
    gap: 16px;
}

.xp-display {
    color: #4ade80;
    font-weight: 600;
    font-size: 14px;
}

.combo-row {
    position: absolute;
    top: -40px;
    left: 50%;
    transform: translateX(-50%);
}

.review-main {
    flex: 1;
    display: flex;
    flex-direction: column;
    align-items: center;
    justify-content: center;
    padding: 40px 20px;
}

.review-card {
    background: rgba(255, 255, 255, 0.05);
    border: 1px solid rgba(255, 255, 255, 0.1);
    border-radius: 20px;
    padding: 40px;
    max-width: 700px;
    width: 100%;
    position: relative;
}

.review-prompt {
    color: #888;
    font-size: 14px;
    margin-bottom: 16px;
    text-transform: uppercase;
    letter-spacing: 1px;
}

.review-sentence {
    font-size: 28px;
    font-weight: 500;
    color: #fff;
    margin-bottom: 32px;
    line-height: 1.4;
}

.multiple-choice {
    display: flex;
    flex-direction: column;
    gap: 12px;
}

.choice-btn {
    padding: 16px 20px;
    background: rgba(255, 255, 255, 0.05);
    border: 2px solid rgba(255, 255, 255, 0.1);
    border-radius: 12px;
    color: #e8e8e8;
    font-size: 16px;
    text-align: left;
    cursor: pointer;
    transition: all 0.2s ease;
}

.choice-btn:hover {
    background: rgba(255, 255, 255, 0.08);
    border-color: #667eea;
}

.choice-btn.selected {
    background: rgba(102, 126, 234, 0.2);
    border-color: #667eea;
}

.choice-btn.correct {
    background: rgba(74, 222, 128, 0.2);
    border-color: #4ade80;
}

.choice-btn.incorrect {
    background: rgba(248, 113, 113, 0.2);
    border-color: #f87171;
}

.answer-input {
    width: 100%;
    padding: 16px 20px;
    font-size: 18px;
    font-family: 'SF Mono', 'Fira Code', monospace;
    background: rgba(255, 255, 255, 0.08);
    border: 2px solid rgba(255, 255, 255, 0.15);
    border-radius: 12px;
    color: #e8e8e8;
    outline: none;
}

.answer-input.correct {
    border-color: #4ade80;
    background: rgba(74, 222, 128, 0.1);
}

.answer-input.incorrect {
    border-color: #f87171;
    background: rgba(248, 113, 113, 0.1);
}

.feedback-box {
    margin-top: 20px;
    padding: 16px 20px;
    border-radius: 12px;
}

.feedback-correct {
    background: rgba(74, 222, 128, 0.15);
    border: 1px solid rgba(74, 222, 128, 0.3);
    color: #4ade80;
}

.feedback-incorrect {
    background: rgba(248, 113, 113, 0.15);
    border: 1px solid rgba(248, 113, 113, 0.3);
    color: #f87171;
}

.srs-buttons {
    display: flex;
    gap: 12px;
    margin-top: 24px;
    flex-wrap: wrap;
}

.srs-btn {
    padding: 12px 20px;
    border: 1px solid rgba(255, 255, 255, 0.2);
    border-radius: 8px;
    background: transparent;
    color: #e8e8e8;
    cursor: pointer;
    font-size: 14px;
    transition: all 0.2s ease;
}

.srs-btn:hover {
    background: rgba(255, 255, 255, 0.08);
}

.srs-btn.hard {
    border-color: rgba(248, 113, 113, 0.5);
    color: #f87171;
}

.srs-btn.good {
    border-color: rgba(251, 191, 36, 0.5);
    color: #fbbf24;
}

.srs-btn.easy {
    border-color: rgba(74, 222, 128, 0.5);
    color: #4ade80;
}

.action-row {
    display: flex;
    justify-content: flex-end;
    margin-top: 24px;
}

.submit-btn {
    padding: 12px 32px;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    border: none;
    border-radius: 8px;
    color: white;
    font-size: 16px;
    font-weight: 600;
    cursor: pointer;
}

.submit-btn:disabled {
    opacity: 0.5;
    cursor: not-allowed;
}

.empty-state {
    text-align: center;
    padding: 60px 40px;
}

.empty-state h2 {
    font-size: 28px;
    color: #4ade80;
    margin-bottom: 16px;
}

.empty-state p {
    color: #888;
    margin-bottom: 24px;
}

.back-btn {
    display: inline-block;
    padding: 12px 24px;
    background: linear-gradient(135deg, #667eea, #764ba2);
    border-radius: 8px;
    color: white;
    text-decoration: none;
}
"#;

#[component]
pub fn Review() -> Element {
    let mut current_index = use_signal(|| 0usize);
    let mut answer = use_signal(String::new);
    let mut selected_choice = use_signal(|| None::<usize>);
    let mut submitted = use_signal(|| false);
    let mut grade_result = use_signal(|| None::<GradeResult>);
    let mut due_challenges = use_signal(Vec::<(String, Challenge)>::new);
    let mut initialized = use_signal(|| false);
    let mut progress = use_signal(UserProgress::load);

    let mut show_xp_popup = use_signal(|| false);
    let mut current_xp_reward = use_signal(|| None::<XpReward>);
    let mut combo_result = use_signal(|| ComboResult { new_combo: 0, is_new_record: false, multiplier: 1.0 });
    let mut show_achievement = use_signal(|| false);
    let mut current_achievement = use_signal(|| None::<&'static Achievement>);
    let mut streak_status = use_signal(|| None::<StreakStatus>);
    let mut first_try_tracker = use_signal(|| std::collections::HashSet::<usize>::new());

    let engine = ContentEngine::new();
    let generator = Generator::new();

    if !initialized() {
        let today = get_today();

        {
            let mut prog = progress.write();
            let status = update_streak(&mut prog, &today);
            streak_status.set(Some(status.clone()));

            match &status {
                StreakStatus::Frozen => play_sound(SoundEffect::StreakSaved),
                StreakStatus::Lost { .. } => play_sound(SoundEffect::StreakLost),
                _ => {}
            }

            prog.save();
        }

        let user_progress = progress.read();
        let mut challenges = Vec::new();

        for era in engine.eras() {
            if let Some(era_data) = engine.get_era(&era.meta.id) {
                for module in &era_data.modules {
                    for exercise in &module.exercises {
                        let exercise_id = &exercise.id;
                        let srs_due = user_progress
                            .get_exercise_progress(exercise_id)
                            .map(|ep| is_due(ep.srs.next_review.as_deref(), &today))
                            .unwrap_or(true);

                        if srs_due {
                            let mut rng = rand::thread_rng();
                            if let Some(challenge) = generator.generate(exercise, &mut rng) {
                                challenges.push((exercise_id.clone(), challenge));
                            }
                        }
                    }
                }
            }
        }

        due_challenges.set(challenges);
        initialized.set(true);
    }

    let total_due = due_challenges.read().len();
    let current = current_index();

    let user_xp = progress.read().xp;
    let user_combo = progress.read().combo;
    let user_streak = progress.read().streak_days;
    let user_freezes = progress.read().streak_freezes;

    rsx! {
        style { "{REVIEW_STYLE}" }

        if show_xp_popup() {
            if let Some(reward) = current_xp_reward() {
                XpPopup {
                    reward: reward.clone(),
                    on_dismiss: move |_| show_xp_popup.set(false)
                }
            }
        }

        if show_achievement() {
            if let Some(achievement) = current_achievement() {
                AchievementToast {
                    achievement: achievement,
                    on_dismiss: move |_| show_achievement.set(false)
                }
            }
        }

        div { class: "review-container",
            header { class: "review-header",
                div {
                    span { class: "review-title", "Daily Review" }
                    span { class: "review-count",
                        if total_due > 0 {
                            " • {current + 1} of {total_due}"
                        } else {
                            ""
                        }
                    }
                }
                div { class: "review-stats",
                    if let Some(status) = streak_status() {
                        StreakDisplay {
                            streak: user_streak,
                            status: status,
                            freezes: user_freezes
                        }
                    }
                    span { class: "xp-display", "{user_xp} XP" }
                }
            }

            main { class: "review-main",
                {
                    let challenges_read = due_challenges.read();

                    if total_due == 0 {
                        rsx! {
                            div { class: "review-card empty-state",
                                h2 { "All caught up!" }
                                p { "No exercises are due for review right now." }
                                button {
                                    class: "back-btn",
                                    onclick: |_| { let _ = web_sys::window().unwrap().history().unwrap().back(); },
                                    "← Back"
                                }
                            }
                        }
                    } else if current >= total_due {
                        rsx! {
                            div { class: "review-card empty-state",
                                h2 { "Review Complete!" }
                                p { "You reviewed {total_due} items." }
                                button {
                                    class: "back-btn",
                                    onclick: |_| { let _ = web_sys::window().unwrap().history().unwrap().back(); },
                                    "← Back"
                                }
                            }
                        }
                    } else if let Some((exercise_id, challenge)) = challenges_read.get(current) {
                        let ex_id = exercise_id.clone();
                        let prompt = challenge.prompt.clone();
                        let sentence = challenge.sentence.clone();

                        let input_class = if submitted() {
                            if grade_result().map(|r| r.correct).unwrap_or(false) {
                                "answer-input correct"
                            } else {
                                "answer-input incorrect"
                            }
                        } else {
                            "answer-input"
                        };

                        rsx! {
                            div { class: "review-card",
                                if user_combo > 0 {
                                    div { class: "combo-row",
                                        ComboIndicator {
                                            combo: user_combo,
                                            multiplier: combo_result().multiplier,
                                            is_new_record: combo_result().is_new_record
                                        }
                                    }
                                }

                                div { class: "review-prompt", MixedText { content: prompt } }
                                div { class: "review-sentence", MixedText { content: sentence } }

                                {match &challenge.answer {
                                    AnswerType::FreeForm { .. } => rsx! {
                                        input {
                                            class: "{input_class}",
                                            r#type: "text",
                                            placeholder: "Enter your answer...",
                                            value: "{answer}",
                                            disabled: submitted(),
                                            oninput: move |e| answer.set(e.value()),
                                        }
                                    },
                                    AnswerType::MultipleChoice { options, correct_index } => {
                                        let correct_idx = *correct_index;
                                        let opts = options.clone();
                                        rsx! {
                                            div { class: "multiple-choice",
                                                for (i, option) in opts.iter().enumerate() {
                                                    {
                                                        let btn_class = if submitted() {
                                                            if i == correct_idx {
                                                                "choice-btn correct"
                                                            } else if selected_choice() == Some(i) {
                                                                "choice-btn incorrect"
                                                            } else {
                                                                "choice-btn"
                                                            }
                                                        } else if selected_choice() == Some(i) {
                                                            "choice-btn selected"
                                                        } else {
                                                            "choice-btn"
                                                        };
                                                        rsx! {
                                                            button {
                                                                class: "{btn_class}",
                                                                disabled: submitted(),
                                                                onclick: move |_| selected_choice.set(Some(i)),
                                                                MixedText { content: option.clone() }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    },
                                    AnswerType::Ambiguity { readings } => {
                                        let rds = readings.clone();
                                        rsx! {
                                            div { class: "reading-list",
                                                for reading in rds.iter() {
                                                    div { class: "reading-item", "{reading}" }
                                                }
                                            }
                                        }
                                    },
                                }}

                                if let Some(result) = grade_result() {
                                    {
                                        let fb_class = if result.correct {
                                            "feedback-box feedback-correct"
                                        } else {
                                            "feedback-box feedback-incorrect"
                                        };
                                        rsx! {
                                            div { class: "{fb_class}", "{result.feedback}" }
                                        }
                                    }
                                }

                                if submitted() {
                                    {
                                        let is_correct = grade_result().map(|r| r.correct).unwrap_or(false);
                                        let ex_id_clone = ex_id.clone();
                                        rsx! {
                                            div { class: "srs-buttons",
                                                button {
                                                    class: "srs-btn hard",
                                                    onclick: move |_| {
                                                        record_srs(&mut progress, &ex_id_clone, ResponseQuality::CorrectDifficult);
                                                        advance_review(&mut current_index, &mut answer, &mut selected_choice, &mut submitted, &mut grade_result);
                                                    },
                                                    "Hard"
                                                }
                                                button {
                                                    class: "srs-btn good",
                                                    onclick: move |_| {
                                                        let quality = if is_correct { ResponseQuality::CorrectHesitation } else { ResponseQuality::Incorrect };
                                                        record_srs(&mut progress, &ex_id, quality);
                                                        advance_review(&mut current_index, &mut answer, &mut selected_choice, &mut submitted, &mut grade_result);
                                                    },
                                                    if is_correct { "Good" } else { "Again" }
                                                }
                                                if is_correct {
                                                    button {
                                                        class: "srs-btn easy",
                                                        onclick: {
                                                            let ex_id_easy = ex_id.clone();
                                                            move |_| {
                                                                record_srs(&mut progress, &ex_id_easy, ResponseQuality::Perfect);
                                                                advance_review(&mut current_index, &mut answer, &mut selected_choice, &mut submitted, &mut grade_result);
                                                            }
                                                        },
                                                        "Easy"
                                                    }
                                                }
                                            }
                                        }
                                    }
                                } else {
                                    {
                                        let can_submit = match &challenge.answer {
                                            AnswerType::FreeForm { .. } => !answer.read().is_empty(),
                                            AnswerType::MultipleChoice { .. } => selected_choice().is_some(),
                                            AnswerType::Ambiguity { .. } => true,
                                        };
                                        let answer_clone = challenge.answer.clone();
                                        let ex_id_submit = ex_id.clone();
                                        rsx! {
                                            div { class: "action-row",
                                                button {
                                                    class: "submit-btn",
                                                    disabled: !can_submit,
                                                    onclick: move |_| {
                                                        let is_correct = match &answer_clone {
                                                            AnswerType::FreeForm { golden_logic } => {
                                                                let result = check_answer(&answer.read(), golden_logic);
                                                                let correct = result.correct;
                                                                grade_result.set(Some(result));
                                                                correct
                                                            }
                                                            AnswerType::MultipleChoice { correct_index, .. } => {
                                                                let correct = selected_choice() == Some(*correct_index);
                                                                let result = if correct {
                                                                    GradeResult {
                                                                        correct: true,
                                                                        partial: false,
                                                                        score: 100,
                                                                        feedback: "Correct!".to_string(),
                                                                    }
                                                                } else {
                                                                    GradeResult {
                                                                        correct: false,
                                                                        partial: false,
                                                                        score: 0,
                                                                        feedback: "Not quite.".to_string(),
                                                                    }
                                                                };
                                                                grade_result.set(Some(result));
                                                                correct
                                                            }
                                                            AnswerType::Ambiguity { .. } => {
                                                                grade_result.set(Some(GradeResult {
                                                                    correct: true,
                                                                    partial: false,
                                                                    score: 100,
                                                                    feedback: "Good analysis!".to_string(),
                                                                }));
                                                                true
                                                            }
                                                        };

                                                        let is_first_try = !first_try_tracker.read().contains(&current);
                                                        first_try_tracker.write().insert(current);

                                                        {
                                                            let mut prog = progress.write();
                                                            prog.record_attempt(&ex_id_submit, is_correct);

                                                            let cr = update_combo(&mut prog, is_correct);
                                                            combo_result.set(cr.clone());

                                                            if is_correct {
                                                                play_sound(SoundEffect::Correct);

                                                                let rng_seed = (prog.xp + current as u64) % 100;
                                                                let reward = calculate_xp_reward(
                                                                    1,
                                                                    cr.new_combo,
                                                                    prog.streak_days,
                                                                    is_first_try,
                                                                    rng_seed,
                                                                );

                                                                prog.xp += reward.total;
                                                                prog.level = crate::progress::calculate_level(prog.xp);
                                                                prog.save();

                                                                current_xp_reward.set(Some(reward));
                                                                show_xp_popup.set(true);

                                                                let new_achievements = check_achievements(&prog);
                                                                if let Some(achievement) = new_achievements.first() {
                                                                    current_achievement.set(Some(*achievement));
                                                                    show_achievement.set(true);
                                                                    unlock_achievement(&mut prog, achievement);
                                                                }
                                                            } else {
                                                                play_sound(SoundEffect::Incorrect);
                                                            }
                                                        }

                                                        submitted.set(true);
                                                    },
                                                    "Check Answer"
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    } else {
                        rsx! {
                            div { class: "review-card",
                                p { "Loading..." }
                            }
                        }
                    }
                }
            }
        }
    }
}

fn record_srs(progress: &mut Signal<UserProgress>, exercise_id: &str, quality: ResponseQuality) {
    let today = get_today();
    let mut user_progress = progress.write();

    user_progress.record_attempt(exercise_id, quality.is_correct());

    if let Some(ep) = user_progress.exercises.get_mut(exercise_id) {
        sm2_update(&mut ep.srs, quality);
        ep.srs.next_review = Some(calculate_next_review(&today, ep.srs.interval));
    }

    user_progress.save();
}

fn advance_review(
    current_index: &mut Signal<usize>,
    answer: &mut Signal<String>,
    selected_choice: &mut Signal<Option<usize>>,
    submitted: &mut Signal<bool>,
    grade_result: &mut Signal<Option<GradeResult>>,
) {
    current_index.set(current_index() + 1);
    answer.set(String::new());
    selected_choice.set(None);
    submitted.set(false);
    grade_result.set(None);
}

fn get_today() -> String {
    #[cfg(target_arch = "wasm32")]
    {
        use wasm_bindgen::prelude::*;

        #[wasm_bindgen]
        extern "C" {
            #[wasm_bindgen(js_namespace = Date, js_name = now)]
            fn date_now() -> f64;
        }

        let ms = date_now() as i64;
        let days_since_epoch = ms / 86400000;
        let year = 1970 + (days_since_epoch / 365) as i32;
        let day_of_year = (days_since_epoch % 365) as i32;
        let month = (day_of_year / 30).min(11) + 1;
        let day = (day_of_year % 30) + 1;
        format!("{:04}-{:02}-{:02}", year, month, day)
    }

    #[cfg(not(target_arch = "wasm32"))]
    {
        "2025-01-01".to_string()
    }
}

```

---

### Page: roadmap

**File:** `src/ui/pages/roadmap.rs`

Application page component.

```rust
use dioxus::prelude::*;
use crate::ui::router::Route;

// (label, english, simple_fol, unicode)
const MILESTONE_EXAMPLES: &[&[(&str, &str, &str, &str)]] = &[
    // Phase 1: Core Transpiler
    &[
        ("Universal", "Every user who has a key enters the room.",
            "For all x: User(x) and HasKey(x) implies Enter(x, Room)",
            "∀x((User(x) ∧ HasKey(x)) → Enter(x, Room))"),
        ("Conditional", "If a user enters the room, the alarm triggers.",
            "Enter(User, Room) implies Trigger(Alarm)",
            "(Enter(User, Room) → Trigger(Alarm))"),
        ("Negation", "No user who lacks a key can enter.",
            "For all x: User(x) and LacksKey(x) implies not Enter(x)",
            "∀x((User(x) ∧ LacksKey(x)) → ¬Enter(x))"),
    ],
    // Phase 2: Web Platform
    &[
        ("Interactive", "Check that the answer equals expected.",
            "Assert: answer equals expected",
            "Assert(Eq(answer, expected))"),
        ("Feedback", "Show the hint to the learner.",
            "Display hint to learner",
            "Display(hint, learner)"),
    ],
    // Phase 3: Codegen Pipeline
    &[
        ("Hello World", "To run:\n    Show \"Hello, World!\" to the console.",
            "fn main() {\n    println!(\"Hello, World!\");\n}",
            "fn main() -> Result<(), Error> {\n    println!(\"Hello, World!\");\n    Ok(())\n}"),
        ("Binding", "Let result be the factorial of 10.",
            "let result = factorial(10);",
            "let result: u64 = factorial(10);"),
    ],
    // Phase 4: Type System
    &[
        ("Refinement", "Let age be an Integer where age > 0.",
            "Age = Int where value > 0",
            "type Age = { n: Int | n > 0 }"),
        ("Dependent", "A Vector of n elements.",
            "Vec<T, n: Nat>",
            "struct Vec<T, const N: usize>"),
    ],
    // Phase 5: Proof System
    &[
        ("Theorem", "The factorial terminates for all naturals.",
            "For all n in Nat: terminates(factorial(n))",
            "∀n:ℕ. terminates(factorial(n))"),
        ("Proof", "By structural induction on n. Auto.",
            "Proof: induction on n. QED",
            "induction(n); auto. QED"),
    ],
    // Phase 6: Concurrency
    &[
        ("Parallel", "Attempt all of the following:\n    Process A.\n    Process B.",
            "parallel {\n    process_a()\n    process_b()\n}",
            "join!(process_a(), process_b())"),
        ("Channel", "Send the message through the channel.",
            "channel.send(message)",
            "tx.send(message).await"),
    ],
    // Phase 7: Standard Library
    &[
        ("I/O", "Read a line from the console.",
            "read_line(console)",
            "io::stdin().read_line(&mut buf)"),
        ("FFI", "Call the external C function.",
            "external from C",
            "extern \"C\" { fn external(); }"),
    ],
];

const ROADMAP_STYLE: &str = r#"
.roadmap-container {
    min-height: 100vh;
    background: linear-gradient(135deg, #070a12 0%, #0b1022 50%, #070a12 100%);
    color: #e5e7eb;
    font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, sans-serif;
}

.roadmap-nav {
    position: sticky;
    top: 0;
    z-index: 50;
    backdrop-filter: blur(18px);
    background: linear-gradient(180deg, rgba(7,10,18,0.72), rgba(7,10,18,0.44));
    border-bottom: 1px solid rgba(255,255,255,0.06);
    padding: 16px 20px;
}

.roadmap-nav-inner {
    max-width: 1000px;
    margin: 0 auto;
    display: flex;
    align-items: center;
    justify-content: space-between;
}

.roadmap-brand {
    display: flex;
    align-items: center;
    gap: 12px;
    text-decoration: none;
    color: #e5e7eb;
}

.roadmap-logo {
    width: 36px;
    height: 36px;
    border-radius: 12px;
    background:
        radial-gradient(circle at 30% 30%, rgba(96,165,250,0.85), transparent 55%),
        radial-gradient(circle at 65% 60%, rgba(167,139,250,0.85), transparent 55%),
        rgba(255,255,255,0.06);
    border: 1px solid rgba(255,255,255,0.10);
}

.roadmap-brand-name {
    font-weight: 800;
    font-size: 14px;
    letter-spacing: -0.5px;
}

.roadmap-back {
    color: #a78bfa;
    text-decoration: none;
    font-size: 14px;
    padding: 8px 16px;
    border-radius: 8px;
    border: 1px solid rgba(167,139,250,0.3);
    transition: all 0.2s ease;
}

.roadmap-back:hover {
    background: rgba(167,139,250,0.1);
    border-color: rgba(167,139,250,0.5);
}

.roadmap-hero {
    text-align: center;
    padding: 60px 20px 40px;
    max-width: 800px;
    margin: 0 auto;
}

.roadmap-hero h1 {
    font-size: 42px;
    font-weight: 800;
    letter-spacing: -1px;
    background: linear-gradient(180deg, #ffffff 0%, rgba(229,231,235,0.78) 100%);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    margin-bottom: 12px;
}

.roadmap-hero .version {
    display: inline-block;
    font-size: 14px;
    padding: 6px 14px;
    border-radius: 20px;
    background: rgba(167,139,250,0.15);
    border: 1px solid rgba(167,139,250,0.3);
    color: #a78bfa;
    margin-bottom: 16px;
}

.roadmap-hero p {
    color: rgba(229,231,235,0.72);
    font-size: 18px;
    line-height: 1.6;
}

.timeline {
    max-width: 700px;
    margin: 0 auto;
    padding: 0 20px 80px;
    position: relative;
}

.timeline::before {
    content: "";
    position: absolute;
    left: 28px;
    top: 0;
    bottom: 80px;
    width: 3px;
    background: linear-gradient(
        180deg,
        #22c55e 0%,
        #22c55e 28%,
        #a78bfa 32%,
        #a78bfa 56%,
        rgba(255,255,255,0.15) 62%,
        rgba(255,255,255,0.08) 100%
    );
    border-radius: 2px;
}

.milestone {
    position: relative;
    padding-left: 70px;
    margin-bottom: 40px;
}

.milestone-dot {
    position: absolute;
    left: 16px;
    top: 4px;
    width: 24px;
    height: 24px;
    border-radius: 50%;
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 12px;
    font-weight: 600;
}

.milestone-dot.done {
    background: linear-gradient(135deg, #22c55e, #16a34a);
    box-shadow: 0 0 20px rgba(34,197,94,0.4);
}

.milestone-dot.progress {
    background: linear-gradient(135deg, #a78bfa, #8b5cf6);
    box-shadow: 0 0 20px rgba(167,139,250,0.4);
    animation: pulse 2s ease-in-out infinite;
}

.milestone-dot.planned {
    background: rgba(255,255,255,0.1);
    border: 2px solid rgba(255,255,255,0.2);
}

@keyframes pulse {
    0%, 100% { transform: scale(1); }
    50% { transform: scale(1.1); }
}

.milestone-content {
    background: rgba(255,255,255,0.03);
    border: 1px solid rgba(255,255,255,0.08);
    border-radius: 16px;
    padding: 24px;
    transition: all 0.2s ease;
}

.milestone-content:hover {
    background: rgba(255,255,255,0.05);
    border-color: rgba(255,255,255,0.12);
}

.milestone-header {
    display: flex;
    align-items: center;
    gap: 12px;
    margin-bottom: 12px;
}

.milestone-title {
    font-size: 20px;
    font-weight: 700;
    color: #fff;
}

.milestone-badge {
    font-size: 11px;
    font-weight: 600;
    padding: 4px 10px;
    border-radius: 12px;
    text-transform: uppercase;
    letter-spacing: 0.5px;
}

.milestone-badge.done {
    background: rgba(34,197,94,0.15);
    color: #22c55e;
    border: 1px solid rgba(34,197,94,0.3);
}

.milestone-badge.progress {
    background: rgba(167,139,250,0.15);
    color: #a78bfa;
    border: 1px solid rgba(167,139,250,0.3);
}

.milestone-badge.planned {
    background: rgba(255,255,255,0.05);
    color: rgba(255,255,255,0.5);
    border: 1px solid rgba(255,255,255,0.1);
}

.milestone-desc {
    color: rgba(229,231,235,0.72);
    font-size: 14px;
    line-height: 1.6;
    margin-bottom: 16px;
}

.milestone-features {
    display: flex;
    flex-wrap: wrap;
    gap: 8px;
}

.feature-tag {
    font-size: 12px;
    padding: 6px 12px;
    border-radius: 8px;
    background: rgba(255,255,255,0.04);
    border: 1px solid rgba(255,255,255,0.08);
    color: rgba(229,231,235,0.8);
}

.feature-tag.done {
    background: rgba(34,197,94,0.08);
    border-color: rgba(34,197,94,0.2);
    color: #86efac;
}

.roadmap-footer {
    border-top: 1px solid rgba(255,255,255,0.06);
    padding: 24px 20px;
    text-align: center;
    color: rgba(229,231,235,0.56);
    font-size: 13px;
}

.roadmap-footer a {
    color: rgba(229,231,235,0.72);
    text-decoration: none;
    margin: 0 8px;
}

.roadmap-footer a:hover {
    color: #a78bfa;
}

.roadmap-nav-links {
    display: flex;
    align-items: center;
    gap: 12px;
}

.roadmap-github {
    display: flex;
    align-items: center;
    justify-content: center;
    width: 36px;
    height: 36px;
    border-radius: 8px;
    border: 1px solid rgba(255,255,255,0.1);
    background: rgba(255,255,255,0.03);
    color: rgba(229,231,235,0.72);
    transition: all 0.2s ease;
}

.roadmap-github:hover {
    background: rgba(255,255,255,0.08);
    color: #e5e7eb;
    border-color: rgba(255,255,255,0.2);
}

.roadmap-github svg {
    width: 18px;
    height: 18px;
    fill: currentColor;
}

.github-link {
    display: inline-flex;
    align-items: center;
    gap: 6px;
}

@media (max-width: 600px) {
    .timeline::before {
        left: 18px;
    }
    .milestone {
        padding-left: 50px;
    }
    .milestone-dot {
        left: 6px;
        width: 20px;
        height: 20px;
    }
    .milestone-title {
        font-size: 18px;
    }
}

.milestone-examples {
    margin-top: 16px;
    border-top: 1px solid rgba(255,255,255,0.06);
    padding-top: 16px;
}

.milestone-tabs {
    display: flex;
    gap: 6px;
    margin-bottom: 12px;
    flex-wrap: wrap;
}

.milestone-tab {
    padding: 6px 12px;
    border-radius: 6px;
    border: 1px solid rgba(255,255,255,0.1);
    background: rgba(255,255,255,0.03);
    color: #94a3b8;
    cursor: pointer;
    font-size: 12px;
    font-weight: 500;
    transition: all 0.2s ease;
}

.milestone-tab:hover {
    background: rgba(255,255,255,0.08);
    color: #e8e8e8;
}

.milestone-tab.active {
    background: linear-gradient(135deg, #667eea, #764ba2);
    color: white;
    border-color: transparent;
}

.milestone-code {
    background: rgba(0,0,0,0.25);
    border-radius: 8px;
    padding: 16px;
    font-family: 'SF Mono', 'Fira Code', 'Consolas', monospace;
    font-size: 13px;
}

.milestone-english {
    color: #e8e8e8;
    font-style: italic;
    margin-bottom: 8px;
    white-space: pre-wrap;
    line-height: 1.5;
}

.milestone-arrow {
    color: #667eea;
    margin: 8px 0;
    font-size: 16px;
}

.milestone-output {
    color: #98c379;
    white-space: pre-wrap;
    line-height: 1.4;
}

.format-toggle {
    display: flex;
    gap: 4px;
    margin-bottom: 8px;
}

.format-btn {
    padding: 3px 8px;
    border-radius: 4px;
    border: 1px solid rgba(255,255,255,0.1);
    background: rgba(255,255,255,0.03);
    color: #64748b;
    cursor: pointer;
    font-size: 10px;
    font-weight: 500;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    transition: all 0.15s ease;
}

.format-btn:hover {
    background: rgba(255,255,255,0.06);
    color: #94a3b8;
}

.format-btn.active {
    background: rgba(102,126,234,0.2);
    border-color: rgba(102,126,234,0.4);
    color: #a5b4fc;
}
"#;

#[component]
fn MilestoneExamples(index: usize) -> Element {
    let mut active = use_signal(|| 0usize);
    let mut use_unicode = use_signal(|| false);
    let examples = MILESTONE_EXAMPLES[index];

    rsx! {
        div { class: "milestone-examples",
            div { class: "milestone-tabs",
                for (i, (label, _, _, _)) in examples.iter().enumerate() {
                    button {
                        key: "{i}",
                        class: if active() == i { "milestone-tab active" } else { "milestone-tab" },
                        onclick: move |_| active.set(i),
                        "{label}"
                    }
                }
            }
            div { class: "milestone-code",
                div { class: "milestone-english", "\"{examples[active()].1}\"" }
                div { class: "milestone-arrow", "↓" }
                div { class: "format-toggle",
                    button {
                        class: if !use_unicode() { "format-btn active" } else { "format-btn" },
                        onclick: move |_| use_unicode.set(false),
                        "Simple"
                    }
                    button {
                        class: if use_unicode() { "format-btn active" } else { "format-btn" },
                        onclick: move |_| use_unicode.set(true),
                        "Unicode"
                    }
                }
                div { class: "milestone-output",
                    if use_unicode() {
                        "{examples[active()].3}"
                    } else {
                        "{examples[active()].2}"
                    }
                }
            }
        }
    }
}

#[component]
pub fn Roadmap() -> Element {
    rsx! {
        style { "{ROADMAP_STYLE}" }

        div { class: "roadmap-container",
            nav { class: "roadmap-nav",
                div { class: "roadmap-nav-inner",
                    Link {
                        to: Route::Landing {},
                        class: "roadmap-brand",
                        div { class: "roadmap-logo" }
                        span { class: "roadmap-brand-name", "LOGICAFFEINE" }
                    }
                    div { class: "roadmap-nav-links",
                        a {
                            href: "https://github.com/Brahmastra-Labs/logicaffeine",
                            target: "_blank",
                            class: "roadmap-github",
                            title: "View on GitHub",
                            svg {
                                xmlns: "http://www.w3.org/2000/svg",
                                view_box: "0 0 24 24",
                                path {
                                    d: "M12 0C5.37 0 0 5.37 0 12c0 5.31 3.435 9.795 8.205 11.385.6.105.825-.255.825-.57 0-.285-.015-1.23-.015-2.235-3.015.555-3.795-.735-4.035-1.41-.135-.345-.72-1.41-1.23-1.695-.42-.225-1.02-.78-.015-.795.945-.015 1.62.87 1.845 1.23 1.08 1.815 2.805 1.305 3.495.99.105-.78.42-1.305.765-1.605-2.67-.3-5.46-1.335-5.46-5.925 0-1.305.465-2.385 1.23-3.225-.12-.3-.54-1.53.12-3.18 0 0 1.005-.315 3.3 1.23.96-.27 1.98-.405 3-.405s2.04.135 3 .405c2.295-1.56 3.3-1.23 3.3-1.23.66 1.65.24 2.88.12 3.18.765.84 1.23 1.905 1.23 3.225 0 4.605-2.805 5.625-5.475 5.925.435.375.81 1.095.81 2.22 0 1.605-.015 2.895-.015 3.3 0 .315.225.69.825.57A12.02 12.02 0 0024 12c0-6.63-5.37-12-12-12z"
                                }
                            }
                        }
                        Link {
                            to: Route::Landing {},
                            class: "roadmap-back",
                            "← Back to Home"
                        }
                    }
                }
            }

            section { class: "roadmap-hero",
                h1 { "LOGOS Roadmap" }
                p { "From English to executable logic. Track our journey from transpiler to full programming language." }
            }

            div { class: "timeline",
                // Phase 1: Core Transpiler - DONE
                div { class: "milestone",
                    div { class: "milestone-dot done", "✓" }
                    div { class: "milestone-content",
                        div { class: "milestone-header",
                            span { class: "milestone-title", "Core Transpiler" }
                            span { class: "milestone-badge done", "Complete" }
                        }
                        p { class: "milestone-desc",
                            "The foundation: parse English, produce First-Order Logic. 901 tests validate 32 linguistic phenomena."
                        }
                        div { class: "milestone-features",
                            span { class: "feature-tag done", "Lexer" }
                            span { class: "feature-tag done", "Parser" }
                            span { class: "feature-tag done", "AST" }
                            span { class: "feature-tag done", "Transpiler" }
                            span { class: "feature-tag done", "Quantifiers" }
                            span { class: "feature-tag done", "Modals" }
                            span { class: "feature-tag done", "Aspect/Tense" }
                        }
                        MilestoneExamples { index: 0 }
                    }
                }

                // Phase 2: Web Platform - DONE
                div { class: "milestone",
                    div { class: "milestone-dot done", "✓" }
                    div { class: "milestone-content",
                        div { class: "milestone-header",
                            span { class: "milestone-title", "Web Platform" }
                            span { class: "milestone-badge done", "Complete" }
                        }
                        p { class: "milestone-desc",
                            "Learn logic interactively. Structured curriculum, free-form studio, and gamification to keep you engaged."
                        }
                        div { class: "milestone-features",
                            span { class: "feature-tag done", "Dioxus WASM" }
                            span { class: "feature-tag done", "Learn Mode" }
                            span { class: "feature-tag done", "Studio" }
                            span { class: "feature-tag done", "Achievements" }
                            span { class: "feature-tag done", "Streaks" }
                        }
                        MilestoneExamples { index: 1 }
                    }
                }

                // Phase 3: Codegen Pipeline - IN PROGRESS
                div { class: "milestone",
                    div { class: "milestone-dot progress", "◐" }
                    div { class: "milestone-content",
                        div { class: "milestone-header",
                            span { class: "milestone-title", "Codegen Pipeline" }
                            span { class: "milestone-badge progress", "In Progress" }
                        }
                        p { class: "milestone-desc",
                            "From English to native binary. Generate Rust code, compile to executables, target WASM for the web."
                        }
                        div { class: "milestone-features",
                            span { class: "feature-tag done", "Rust Codegen" }
                            span { class: "feature-tag done", "Functions" }
                            span { class: "feature-tag done", "Structs" }
                            span { class: "feature-tag done", "Guards" }
                            span { class: "feature-tag done", "Iteration" }
                            span { class: "feature-tag", "Native Compilation" }
                            span { class: "feature-tag", "WASM Target" }
                        }
                        MilestoneExamples { index: 2 }
                    }
                }

                // Phase 4: Type System - IN PROGRESS
                div { class: "milestone",
                    div { class: "milestone-dot progress", "◐" }
                    div { class: "milestone-content",
                        div { class: "milestone-header",
                            span { class: "milestone-title", "Type System" }
                            span { class: "milestone-badge progress", "In Progress" }
                        }
                        p { class: "milestone-desc",
                            "Type annotations, inference, and constraints. Catch bugs at compile time with English type syntax."
                        }
                        div { class: "milestone-features",
                            span { class: "feature-tag done", "Type Annotations" }
                            span { class: "feature-tag done", "Return Inference" }
                            span { class: "feature-tag done", "Primitives" }
                            span { class: "feature-tag", "Dependent Types" }
                            span { class: "feature-tag", "Refinements" }
                        }
                        MilestoneExamples { index: 3 }
                    }
                }

                // Phase 5: Proof System - PLANNED
                div { class: "milestone",
                    div { class: "milestone-dot planned" }
                    div { class: "milestone-content",
                        div { class: "milestone-header",
                            span { class: "milestone-title", "Proof System" }
                            span { class: "milestone-badge planned", "Planned" }
                        }
                        p { class: "milestone-desc",
                            "Curry-Howard in English. Write proofs as prose. The compiler verifies your reasoning."
                        }
                        div { class: "milestone-features",
                            span { class: "feature-tag", "Proof Obligations" }
                            span { class: "feature-tag", "Auto Tactic" }
                            span { class: "feature-tag", "Induction" }
                            span { class: "feature-tag", "Totality Checking" }
                        }
                        MilestoneExamples { index: 4 }
                    }
                }

                // Phase 6: Concurrency - PLANNED
                div { class: "milestone",
                    div { class: "milestone-dot planned" }
                    div { class: "milestone-content",
                        div { class: "milestone-header",
                            span { class: "milestone-title", "Concurrency Model" }
                            span { class: "milestone-badge planned", "Planned" }
                        }
                        p { class: "milestone-desc",
                            "Structured concurrency with proof obligations. Channels, pipelines, and distributed agents — all verified."
                        }
                        div { class: "milestone-features",
                            span { class: "feature-tag", "Structured Concurrency" }
                            span { class: "feature-tag", "Channels" }
                            span { class: "feature-tag", "Agent Model" }
                            span { class: "feature-tag", "CSP Processes" }
                        }
                        MilestoneExamples { index: 5 }
                    }
                }

                // Phase 7: Standard Library - PLANNED
                div { class: "milestone",
                    div { class: "milestone-dot planned" }
                    div { class: "milestone-content",
                        div { class: "milestone-header",
                            span { class: "milestone-title", "Standard Library & Beyond" }
                            span { class: "milestone-badge planned", "Planned" }
                        }
                        p { class: "milestone-desc",
                            "A complete standard library. FFI for Rust and C. The Live Codex IDE for real-time proof visualization."
                        }
                        div { class: "milestone-features",
                            span { class: "feature-tag", "Core Types" }
                            span { class: "feature-tag", "I/O Operations" }
                            span { class: "feature-tag", "FFI" }
                            span { class: "feature-tag", "Live Codex IDE" }
                        }
                        MilestoneExamples { index: 6 }
                    }
                }
            }

            footer { class: "roadmap-footer",
                span { "© 2025 Brahmastra Labs LLC  •  Written in Rust 🦀" }
                span { " • " }
                a {
                    href: "https://github.com/Brahmastra-Labs/logicaffeine",
                    target: "_blank",
                    class: "github-link",
                    svg {
                        xmlns: "http://www.w3.org/2000/svg",
                        width: "14",
                        height: "14",
                        view_box: "0 0 24 24",
                        fill: "currentColor",
                        path {
                            d: "M12 0C5.37 0 0 5.37 0 12c0 5.31 3.435 9.795 8.205 11.385.6.105.825-.255.825-.57 0-.285-.015-1.23-.015-2.235-3.015.555-3.795-.735-4.035-1.41-.135-.345-.72-1.41-1.23-1.695-.42-.225-1.02-.78-.015-.795.945-.015 1.62.87 1.845 1.23 1.08 1.815 2.805 1.305 3.495.99.105-.78.42-1.305.765-1.605-2.67-.3-5.46-1.335-5.46-5.925 0-1.305.465-2.385 1.23-3.225-.12-.3-.54-1.53.12-3.18 0 0 1.005-.315 3.3 1.23.96-.27 1.98-.405 3-.405s2.04.135 3 .405c2.295-1.56 3.3-1.23 3.3-1.23.66 1.65.24 2.88.12 3.18.765.84 1.23 1.905 1.23 3.225 0 4.605-2.805 5.625-5.475 5.925.435.375.81 1.095.81 2.22 0 1.605-.015 2.895-.015 3.3 0 .315.225.69.825.57A12.02 12.02 0 0024 12c0-6.63-5.37-12-12-12z"
                        }
                    }
                    "GitHub"
                }
                span { " • " }
                Link { to: Route::Privacy {}, "Privacy" }
                span { " • " }
                Link { to: Route::Terms {}, "Terms" }
                span { " • " }
                Link { to: Route::Pricing {}, "Pricing" }
            }
        }
    }
}

```

---

### Page: Studio

**File:** `src/ui/pages/studio.rs`

Live transpilation sandbox with AST visualization, portal animations, and real-time English-to-FOL conversion. Header nav uses Link components for client-side routing to Home and Learn pages.

```rust
use dioxus::prelude::*;
use crate::{compile_for_ui, CompileResult};
use crate::ui::router::Route;
use crate::ui::components::editor::LiveEditor;
use crate::ui::components::logic_output::{LogicOutput, OutputFormat};
use crate::ui::components::ast_tree::AstTree;
use crate::ui::components::socratic_guide::{SocraticGuide, GuideMode, get_success_message, get_context_hint};

const STUDIO_STYLE: &str = r#"
.studio-container {
    display: flex;
    flex-direction: column;
    height: 100vh;
    background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
    color: #e8e8e8;
}

.studio-header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    padding: 16px 24px;
    background: rgba(0, 0, 0, 0.2);
    border-bottom: 1px solid rgba(255, 255, 255, 0.08);
}

.studio-logo {
    display: flex;
    align-items: center;
    gap: 12px;
}

.studio-logo-icon {
    font-size: 24px;
}

.studio-logo-text {
    font-size: 20px;
    font-weight: 700;
    background: linear-gradient(135deg, #667eea, #764ba2);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    background-clip: text;
}

.studio-nav {
    display: flex;
    gap: 8px;
}

.studio-nav-btn {
    padding: 8px 16px;
    border-radius: 8px;
    border: 1px solid rgba(255, 255, 255, 0.15);
    background: rgba(255, 255, 255, 0.05);
    color: #888;
    font-size: 14px;
    cursor: pointer;
    transition: all 0.2s ease;
    text-decoration: none;
}

.studio-nav-btn:hover {
    background: rgba(255, 255, 255, 0.1);
    color: #e8e8e8;
}

.studio-main {
    flex: 1;
    display: flex;
    overflow: hidden;
}

.studio-panel {
    background: rgba(0, 0, 0, 0.3);
    display: flex;
    flex-direction: column;
    overflow: hidden;
    min-width: 200px;
}

.panel-header {
    padding: 12px 16px;
    border-bottom: 1px solid rgba(255, 255, 255, 0.08);
    font-size: 12px;
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    color: #888;
    display: flex;
    justify-content: space-between;
    align-items: center;
    flex-shrink: 0;
}

.panel-content {
    flex: 1;
    overflow: auto;
}

.panel-resizer {
    width: 6px;
    background: rgba(255, 255, 255, 0.05);
    cursor: col-resize;
    transition: background 0.2s ease;
    flex-shrink: 0;
}

.panel-resizer:hover,
.panel-resizer.active {
    background: rgba(102, 126, 234, 0.5);
}

.format-toggle {
    display: flex;
    gap: 4px;
    background: rgba(255, 255, 255, 0.05);
    border-radius: 6px;
    padding: 2px;
}

.format-btn {
    padding: 4px 10px;
    border: none;
    background: transparent;
    color: #888;
    font-size: 11px;
    border-radius: 4px;
    cursor: pointer;
    transition: all 0.2s ease;
}

.format-btn:hover {
    color: #e8e8e8;
}

.format-btn.active {
    background: rgba(255, 255, 255, 0.1);
    color: #e8e8e8;
}

.studio-footer {
    background: rgba(0, 0, 0, 0.3);
    border-top: 1px solid rgba(255, 255, 255, 0.08);
}

@media (max-width: 768px) {
    .studio-main {
        flex-direction: column;
    }
    .panel-resizer {
        width: 100%;
        height: 6px;
        cursor: row-resize;
    }
    .studio-panel {
        min-width: unset;
        min-height: 150px;
    }
}
"#;

#[component]
pub fn Studio() -> Element {
    let mut input = use_signal(String::new);
    let mut result = use_signal(|| CompileResult {
        logic: None,
        ast: None,
        readings: Vec::new(),
        tokens: Vec::new(),
        error: None,
    });
    let mut format = use_signal(|| OutputFormat::Unicode);

    let mut left_width = use_signal(|| 35.0f64);
    let mut right_width = use_signal(|| 25.0f64);
    let mut resizing = use_signal(|| None::<&'static str>);

    let handle_input = move |new_value: String| {
        input.set(new_value.clone());
        if !new_value.trim().is_empty() {
            let compiled = compile_for_ui(&new_value);
            result.set(compiled);
        } else {
            result.set(CompileResult {
                logic: None,
                ast: None,
                readings: Vec::new(),
                tokens: Vec::new(),
                error: None,
            });
        }
    };

    let current_result = result.read();
    let guide_mode = if let Some(err) = &current_result.error {
        GuideMode::Error(err.clone())
    } else if current_result.logic.is_some() {
        let msg = get_success_message(current_result.readings.len());
        if let Some(hint) = get_context_hint(&input.read()) {
            GuideMode::Info(format!("{} {}", msg, hint))
        } else {
            GuideMode::Success(msg)
        }
    } else {
        GuideMode::Idle
    };

    let left_w = *left_width.read();
    let right_w = *right_width.read();
    let center_w = 100.0 - left_w - right_w;

    let handle_mouse_move = move |evt: MouseEvent| {
        if let Some(which) = *resizing.read() {
            let window = web_sys::window().unwrap();
            let width = window.inner_width().unwrap().as_f64().unwrap();
            let coords = evt.data().client_coordinates();
            let x: f64 = coords.x;
            let pct: f64 = (x / width) * 100.0;

            match which {
                "left" => {
                    let new_left: f64 = pct.clamp(15.0, 60.0);
                    left_width.set(new_left);
                }
                "right" => {
                    let new_right: f64 = (100.0 - pct).clamp(15.0, 40.0);
                    right_width.set(new_right);
                }
                _ => {}
            }
        }
    };

    let handle_mouse_up = move |_: MouseEvent| {
        resizing.set(None);
    };

    let current_format = *format.read();

    rsx! {
        style { "{STUDIO_STYLE}" }

        div {
            class: "studio-container",
            onmousemove: handle_mouse_move,
            onmouseup: handle_mouse_up,
            onmouseleave: handle_mouse_up,

            header { class: "studio-header",
                div { class: "studio-logo",
                    span { class: "studio-logo-icon", "\u{03BB}" }
                    span { class: "studio-logo-text", "LOGOS Studio" }
                }
                nav { class: "studio-nav",
                    Link { class: "studio-nav-btn", to: Route::Home {}, "Home" }
                    Link { class: "studio-nav-btn", to: Route::Learn {}, "Learn" }
                }
            }

            main { class: "studio-main",
                section {
                    class: "studio-panel",
                    style: "width: {left_w}%;",
                    div { class: "panel-header",
                        span { "English Input" }
                    }
                    div { class: "panel-content",
                        LiveEditor {
                            on_change: handle_input,
                            placeholder: Some("Type an English sentence...".to_string()),
                        }
                    }
                }

                div {
                    class: if resizing.read().is_some() { "panel-resizer active" } else { "panel-resizer" },
                    onmousedown: move |_| resizing.set(Some("left")),
                }

                section {
                    class: "studio-panel",
                    style: "width: {center_w}%;",
                    div { class: "panel-header",
                        span { "Logic Output" }
                        div { class: "format-toggle",
                            button {
                                class: if current_format == OutputFormat::Unicode { "format-btn active" } else { "format-btn" },
                                onclick: move |_| format.set(OutputFormat::Unicode),
                                "\u{2200}x"
                            }
                            button {
                                class: if current_format == OutputFormat::LaTeX { "format-btn active" } else { "format-btn" },
                                onclick: move |_| format.set(OutputFormat::LaTeX),
                                "LaTeX"
                            }
                        }
                    }
                    div { class: "panel-content",
                        LogicOutput {
                            logic: current_result.logic.clone(),
                            readings: current_result.readings.clone(),
                            error: current_result.error.clone(),
                            format: current_format,
                        }
                    }
                }

                div {
                    class: if resizing.read().is_some() { "panel-resizer active" } else { "panel-resizer" },
                    onmousedown: move |_| resizing.set(Some("right")),
                }

                aside {
                    class: "studio-panel",
                    style: "width: {right_w}%;",
                    div { class: "panel-header",
                        span { "AST Inspector" }
                    }
                    div { class: "panel-content",
                        AstTree {
                            ast: current_result.ast.clone(),
                        }
                    }
                }
            }

            footer { class: "studio-footer",
                SocraticGuide {
                    mode: guide_mode,
                    on_hint_request: None,
                }
            }
        }
    }
}

```

---

### Page: success

**File:** `src/ui/pages/success.rs`

Application page component.

```rust
use dioxus::prelude::*;
use crate::ui::router::Route;
use crate::ui::state::{LicenseState, LicensePlan};

const LICENSE_API_URL: &str = "https://api.logicaffeine.com/session";

const SUCCESS_STYLE: &str = r#"
.success-container {
    min-height: 100vh;
    display: flex;
    flex-direction: column;
    align-items: center;
    justify-content: center;
    padding: 60px 20px;
    text-align: center;
    max-width: 600px;
    margin: 0 auto;
}

.success-icon {
    width: 80px;
    height: 80px;
    background: linear-gradient(135deg, #00d4ff 0%, #7b2cbf 100%);
    border-radius: 50%;
    display: flex;
    align-items: center;
    justify-content: center;
    margin-bottom: 32px;
    font-size: 40px;
}

.success-title {
    font-size: 36px;
    font-weight: 700;
    color: #fff;
    margin-bottom: 16px;
}

.success-message {
    color: #aaa;
    font-size: 18px;
    line-height: 1.6;
    margin-bottom: 32px;
}

.license-box {
    background: rgba(0, 212, 255, 0.1);
    border: 1px solid rgba(0, 212, 255, 0.3);
    border-radius: 12px;
    padding: 24px;
    margin-bottom: 32px;
    width: 100%;
    max-width: 400px;
}

.license-label {
    color: #00d4ff;
    font-size: 14px;
    font-weight: 600;
    margin-bottom: 12px;
    text-transform: uppercase;
    letter-spacing: 1px;
}

.license-key {
    background: rgba(0, 0, 0, 0.3);
    border: 1px solid rgba(255, 255, 255, 0.1);
    border-radius: 8px;
    padding: 16px;
    font-family: monospace;
    font-size: 14px;
    color: #fff;
    word-break: break-all;
    margin-bottom: 12px;
}

.copy-btn {
    background: linear-gradient(135deg, #00d4ff 0%, #7b2cbf 100%);
    color: white;
    border: none;
    padding: 10px 20px;
    border-radius: 8px;
    font-size: 14px;
    font-weight: 600;
    cursor: pointer;
    transition: all 0.2s ease;
}

.copy-btn:hover {
    transform: translateY(-1px);
    box-shadow: 0 4px 12px rgba(0, 212, 255, 0.3);
}

.license-saved {
    color: #4ade80;
    font-size: 13px;
    margin-top: 12px;
}

.success-actions {
    display: flex;
    flex-direction: column;
    gap: 16px;
    width: 100%;
    max-width: 320px;
}

.btn-primary {
    display: block;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    padding: 16px 32px;
    border-radius: 12px;
    font-size: 16px;
    font-weight: 600;
    text-decoration: none;
    text-align: center;
    transition: all 0.2s ease;
}

.btn-primary:hover {
    transform: translateY(-2px);
    box-shadow: 0 6px 20px rgba(102, 126, 234, 0.4);
}

.btn-secondary {
    display: block;
    background: transparent;
    color: #667eea;
    padding: 16px 32px;
    border: 1px solid #667eea;
    border-radius: 12px;
    font-size: 16px;
    font-weight: 500;
    text-decoration: none;
    text-align: center;
    transition: all 0.2s ease;
}

.btn-secondary:hover {
    background: rgba(102, 126, 234, 0.1);
}

.success-note {
    margin-top: 40px;
    padding: 20px;
    background: rgba(255, 255, 255, 0.05);
    border-radius: 12px;
    border: 1px solid rgba(255, 255, 255, 0.1);
}

.success-note p {
    color: #888;
    font-size: 14px;
    margin: 0;
}

.success-note a {
    color: #00d4ff;
    text-decoration: none;
}

.success-note a:hover {
    text-decoration: underline;
}

.loading-spinner {
    width: 40px;
    height: 40px;
    border: 3px solid rgba(0, 212, 255, 0.3);
    border-top: 3px solid #00d4ff;
    border-radius: 50%;
    animation: spin 1s linear infinite;
    margin: 20px auto;
}

@keyframes spin {
    0% { transform: rotate(0deg); }
    100% { transform: rotate(360deg); }
}

.error-message {
    color: #ef4444;
    background: rgba(239, 68, 68, 0.1);
    border: 1px solid rgba(239, 68, 68, 0.3);
    border-radius: 8px;
    padding: 16px;
    margin-bottom: 24px;
}
"#;

const STRIPE_CUSTOMER_PORTAL: &str = "https://billing.stripe.com/p/login/8x200l3VN98D7qa1SMe3e00";

fn get_session_id_from_url() -> Option<String> {
    let window = web_sys::window()?;
    let location = window.location();
    let search = location.search().ok()?;

    let params = web_sys::UrlSearchParams::new_with_str(&search).ok()?;
    params.get("session_id")
}

fn save_license_to_storage(license_key: &str, plan: &str) {
    if let Some(window) = web_sys::window() {
        if let Ok(Some(storage)) = window.local_storage() {
            let _ = storage.set_item("logos_license_key", license_key);
            let _ = storage.set_item("logos_license_plan", plan);
            let timestamp = js_sys::Date::now().to_string();
            let _ = storage.set_item("logos_license_validated_at", &timestamp);
        }
    }
}

fn copy_to_clipboard(text: &str) {
    if let Some(window) = web_sys::window() {
        let clipboard = window.navigator().clipboard();
        let _ = clipboard.write_text(text);
    }
}

#[derive(Clone, PartialEq)]
enum LicenseStatus {
    Loading,
    Success { subscription_id: String, plan: String },
    Error(String),
    NoSession,
}

async fn fetch_license_from_session(session_id: String) -> LicenseStatus {
    use gloo_net::http::Request;

    let body = serde_json::json!({ "sessionId": session_id });

    let response = Request::post(LICENSE_API_URL)
        .header("Content-Type", "application/json")
        .body(body.to_string())
        .unwrap()
        .send()
        .await;

    match response {
        Ok(resp) => {
            if resp.ok() {
                match resp.json::<serde_json::Value>().await {
                    Ok(data) => {
                        let subscription_id = data["subscriptionId"]
                            .as_str()
                            .unwrap_or("")
                            .to_string();
                        let plan = data["plan"]
                            .as_str()
                            .unwrap_or("unknown")
                            .to_string();
                        LicenseStatus::Success { subscription_id, plan }
                    }
                    Err(_) => LicenseStatus::Error("Failed to parse response".to_string()),
                }
            } else {
                LicenseStatus::Error("License lookup failed".to_string())
            }
        }
        Err(e) => LicenseStatus::Error(format!("Network error: {}", e)),
    }
}

#[component]
pub fn Success() -> Element {
    let mut license_status = use_signal(|| LicenseStatus::Loading);
    let mut copied = use_signal(|| false);
    let mut saved = use_signal(|| false);
    let license_state = use_context::<LicenseState>();

    use_effect(move || {
        let mut license_state = license_state.clone();
        spawn(async move {
            if let Some(session_id) = get_session_id_from_url() {
                let result = fetch_license_from_session(session_id).await;
                if let LicenseStatus::Success { ref subscription_id, ref plan } = result {
                    save_license_to_storage(subscription_id, plan);
                    license_state.set_license(
                        subscription_id.clone(),
                        LicensePlan::from_str(plan),
                    );
                    saved.set(true);
                }
                license_status.set(result);
            } else {
                license_status.set(LicenseStatus::NoSession);
            }
        });
    });

    let on_copy = move |_| {
        if let LicenseStatus::Success { ref subscription_id, .. } = *license_status.read() {
            copy_to_clipboard(subscription_id);
            copied.set(true);
        }
    };

    let (has_license, license_key) = match &*license_status.read() {
        LicenseStatus::Success { subscription_id, .. } => (true, subscription_id.clone()),
        _ => (false, String::new()),
    };

    let is_loading = matches!(*license_status.read(), LicenseStatus::Loading);

    rsx! {
        style { "{SUCCESS_STYLE}" }

        div { class: "success-container",
            div { class: "success-icon", "✓" }

            h1 { class: "success-title", "Thank You!" }

            p { class: "success-message",
                "Your payment was successful. Welcome to logicaffeine! "
                "You now have access to use LOGOS for commercial purposes."
            }

            if is_loading {
                div { class: "loading-spinner" }
                p { class: "success-message", "Retrieving your license..." }
            }

            match &*license_status.read() {
                LicenseStatus::Error(msg) => rsx! {
                    div { class: "error-message", "{msg}" }
                },
                LicenseStatus::NoSession => rsx! {
                    div { class: "error-message", "No checkout session found. Please try again." }
                },
                _ => rsx! {}
            }

            if has_license {
                div { class: "license-box",
                    div { class: "license-label", "Your License Key" }
                    div { class: "license-key", "{license_key}" }
                    button {
                        class: "copy-btn",
                        onclick: on_copy,
                        if *copied.read() { "Copied!" } else { "Copy to Clipboard" }
                    }
                    if *saved.read() {
                        div { class: "license-saved",
                            "✓ License saved to your browser"
                        }
                    }
                }
            }

            div { class: "success-actions",
                Link {
                    class: "btn-primary",
                    to: Route::Studio {},
                    "Open Studio"
                }

                a {
                    class: "btn-secondary",
                    href: STRIPE_CUSTOMER_PORTAL,
                    target: "_blank",
                    "Manage Subscription"
                }
            }

            div { class: "success-note",
                p {
                    "Save your license key somewhere safe. "
                    "Need help? Contact us at "
                    a { href: "mailto:tristen@brahmastra-labs.com", "tristen@brahmastra-labs.com" }
                    "."
                }
            }
        }
    }
}

```

---

### Page: terms

**File:** `src/ui/pages/terms.rs`

Application page component.

```rust
use dioxus::prelude::*;
use crate::ui::router::Route;

const TERMS_HTML: &str = include_str!("../../../terms.html");

const LEGAL_STYLE: &str = r#"
.legal-container {
    min-height: 100vh;
    display: flex;
    flex-direction: column;
    background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
}

.legal-nav {
    position: sticky;
    top: 0;
    z-index: 50;
    backdrop-filter: blur(18px);
    background: linear-gradient(180deg, rgba(7,10,18,0.72), rgba(7,10,18,0.44));
    border-bottom: 1px solid rgba(255,255,255,0.06);
    padding: 16px 20px;
}

.legal-nav-inner {
    max-width: 1120px;
    margin: 0 auto;
    display: flex;
    align-items: center;
    justify-content: space-between;
}

.legal-brand {
    display: flex;
    align-items: center;
    gap: 12px;
    text-decoration: none;
    color: #e5e7eb;
}

.legal-logo {
    width: 36px;
    height: 36px;
    border-radius: 12px;
    background:
        radial-gradient(circle at 30% 30%, rgba(96,165,250,0.85), transparent 55%),
        radial-gradient(circle at 65% 60%, rgba(167,139,250,0.85), transparent 55%),
        rgba(255,255,255,0.06);
    border: 1px solid rgba(255,255,255,0.10);
}

.legal-brand-name {
    font-weight: 800;
    font-size: 14px;
    letter-spacing: -0.5px;
}

.legal-back {
    color: #a78bfa;
    text-decoration: none;
    font-size: 14px;
    padding: 8px 16px;
    border-radius: 8px;
    border: 1px solid rgba(167,139,250,0.3);
    transition: all 0.2s ease;
}

.legal-back:hover {
    background: rgba(167,139,250,0.1);
    border-color: rgba(167,139,250,0.5);
}

.legal-content {
    flex: 1;
    max-width: 900px;
    margin: 0 auto;
    padding: 40px 20px 60px;
    width: 100%;
}

.legal-content-inner {
    background: rgba(255, 255, 255, 0.98);
    border-radius: 16px;
    padding: 40px;
    box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
}

.legal-footer {
    border-top: 1px solid rgba(255,255,255,0.06);
    padding: 24px 20px;
    text-align: center;
    color: rgba(229,231,235,0.56);
    font-size: 13px;
}

.legal-footer a {
    color: rgba(229,231,235,0.72);
    text-decoration: none;
    margin: 0 8px;
}

.legal-footer a:hover {
    color: #a78bfa;
}

.legal-nav-links {
    display: flex;
    align-items: center;
    gap: 12px;
}

.legal-github {
    display: flex;
    align-items: center;
    justify-content: center;
    width: 36px;
    height: 36px;
    border-radius: 8px;
    border: 1px solid rgba(255,255,255,0.1);
    background: rgba(255,255,255,0.03);
    color: rgba(229,231,235,0.72);
    transition: all 0.2s ease;
}

.legal-github:hover {
    background: rgba(255,255,255,0.08);
    color: #e5e7eb;
    border-color: rgba(255,255,255,0.2);
}

.legal-github svg {
    width: 18px;
    height: 18px;
    fill: currentColor;
}

.github-link {
    display: inline-flex;
    align-items: center;
    gap: 6px;
}
"#;

#[component]
pub fn Terms() -> Element {
    rsx! {
        style { "{LEGAL_STYLE}" }

        div { class: "legal-container",
            nav { class: "legal-nav",
                div { class: "legal-nav-inner",
                    Link {
                        to: Route::Landing {},
                        class: "legal-brand",
                        div { class: "legal-logo" }
                        span { class: "legal-brand-name", "LOGICAFFEINE" }
                    }
                    div { class: "legal-nav-links",
                        a {
                            href: "https://github.com/Brahmastra-Labs/logicaffeine",
                            target: "_blank",
                            class: "legal-github",
                            title: "View on GitHub",
                            svg {
                                xmlns: "http://www.w3.org/2000/svg",
                                view_box: "0 0 24 24",
                                path {
                                    d: "M12 0C5.37 0 0 5.37 0 12c0 5.31 3.435 9.795 8.205 11.385.6.105.825-.255.825-.57 0-.285-.015-1.23-.015-2.235-3.015.555-3.795-.735-4.035-1.41-.135-.345-.72-1.41-1.23-1.695-.42-.225-1.02-.78-.015-.795.945-.015 1.62.87 1.845 1.23 1.08 1.815 2.805 1.305 3.495.99.105-.78.42-1.305.765-1.605-2.67-.3-5.46-1.335-5.46-5.925 0-1.305.465-2.385 1.23-3.225-.12-.3-.54-1.53.12-3.18 0 0 1.005-.315 3.3 1.23.96-.27 1.98-.405 3-.405s2.04.135 3 .405c2.295-1.56 3.3-1.23 3.3-1.23.66 1.65.24 2.88.12 3.18.765.84 1.23 1.905 1.23 3.225 0 4.605-2.805 5.625-5.475 5.925.435.375.81 1.095.81 2.22 0 1.605-.015 2.895-.015 3.3 0 .315.225.69.825.57A12.02 12.02 0 0024 12c0-6.63-5.37-12-12-12z"
                                }
                            }
                        }
                        Link {
                            to: Route::Landing {},
                            class: "legal-back",
                            "← Back to Home"
                        }
                    }
                }
            }

            main { class: "legal-content",
                div {
                    class: "legal-content-inner",
                    dangerous_inner_html: "{TERMS_HTML}"
                }
            }

            footer { class: "legal-footer",
                span { "© 2025 Brahmastra Labs LLC" }
                span { " • " }
                a {
                    href: "https://github.com/Brahmastra-Labs/logicaffeine",
                    target: "_blank",
                    class: "github-link",
                    svg {
                        xmlns: "http://www.w3.org/2000/svg",
                        width: "14",
                        height: "14",
                        view_box: "0 0 24 24",
                        fill: "currentColor",
                        path {
                            d: "M12 0C5.37 0 0 5.37 0 12c0 5.31 3.435 9.795 8.205 11.385.6.105.825-.255.825-.57 0-.285-.015-1.23-.015-2.235-3.015.555-3.795-.735-4.035-1.41-.135-.345-.72-1.41-1.23-1.695-.42-.225-1.02-.78-.015-.795.945-.015 1.62.87 1.845 1.23 1.08 1.815 2.805 1.305 3.495.99.105-.78.42-1.305.765-1.605-2.67-.3-5.46-1.335-5.46-5.925 0-1.305.465-2.385 1.23-3.225-.12-.3-.54-1.53.12-3.18 0 0 1.005-.315 3.3 1.23.96-.27 1.98-.405 3-.405s2.04.135 3 .405c2.295-1.56 3.3-1.23 3.3-1.23.66 1.65.24 2.88.12 3.18.765.84 1.23 1.905 1.23 3.225 0 4.605-2.805 5.625-5.475 5.925.435.375.81 1.095.81 2.22 0 1.605-.015 2.895-.015 3.3 0 .315.225.69.825.57A12.02 12.02 0 0024 12c0-6.63-5.37-12-12-12z"
                        }
                    }
                    "GitHub"
                }
                span { " • " }
                Link { to: Route::Privacy {}, "Privacy Policy" }
                span { " • " }
                Link { to: Route::Terms {}, "Terms of Use" }
            }
        }
    }
}

```

---

### Page: Workspace

**File:** `src/ui/pages/workspace.rs`

Three-column learning interface: sidebar (lesson tree, history), center (chat/proof interface), right panel (AST inspector).

```rust
use dioxus::prelude::*;
use crate::ui::state::AppState;
use crate::ui::components::chat::ChatDisplay;
use crate::ui::components::input::InputArea;
use crate::ui::router::Route;

const WORKSPACE_STYLE: &str = r#"
.workspace {
    height: 100vh;
    display: flex;
    flex-direction: column;
}

.workspace-header {
    background: rgba(0, 0, 0, 0.3);
    backdrop-filter: blur(10px);
    padding: 16px 24px;
    border-bottom: 1px solid rgba(255, 255, 255, 0.1);
    display: flex;
    justify-content: space-between;
    align-items: center;
}

.workspace-header .breadcrumb {
    display: flex;
    align-items: center;
    gap: 8px;
}

.workspace-header .breadcrumb a {
    color: #888;
    text-decoration: none;
    font-size: 14px;
}

.workspace-header .breadcrumb a:hover {
    color: #00d4ff;
}

.workspace-header .breadcrumb span {
    color: #666;
}

.workspace-header h1 {
    font-size: 20px;
    font-weight: 600;
    background: linear-gradient(90deg, #00d4ff, #7b2cbf);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
}

.workspace-content {
    flex: 1;
    display: flex;
    overflow: hidden;
}

.sidebar {
    width: 260px;
    background: rgba(0, 0, 0, 0.2);
    border-right: 1px solid rgba(255, 255, 255, 0.1);
    padding: 20px;
    overflow-y: auto;
}

.sidebar h3 {
    color: #888;
    font-size: 12px;
    text-transform: uppercase;
    letter-spacing: 1px;
    margin-bottom: 16px;
}

.lesson-tree {
    list-style: none;
}

.lesson-tree li {
    padding: 10px 12px;
    margin-bottom: 4px;
    border-radius: 8px;
    color: #aaa;
    font-size: 14px;
    cursor: pointer;
    transition: all 0.2s ease;
}

.lesson-tree li:hover {
    background: rgba(255, 255, 255, 0.05);
    color: #fff;
}

.lesson-tree li.active {
    background: rgba(102, 126, 234, 0.2);
    color: #667eea;
}

.lesson-tree li.locked {
    opacity: 0.4;
    cursor: not-allowed;
}

.main-area {
    flex: 1;
    display: flex;
    flex-direction: column;
    overflow: hidden;
}

.inspector {
    width: 300px;
    background: rgba(0, 0, 0, 0.2);
    border-left: 1px solid rgba(255, 255, 255, 0.1);
    padding: 20px;
    overflow-y: auto;
}

.inspector h3 {
    color: #888;
    font-size: 12px;
    text-transform: uppercase;
    letter-spacing: 1px;
    margin-bottom: 16px;
}

.inspector-placeholder {
    color: #666;
    font-size: 14px;
    font-style: italic;
    text-align: center;
    padding: 40px 20px;
}

@media (max-width: 900px) {
    .sidebar, .inspector {
        display: none;
    }
}
"#;

#[component]
pub fn Workspace(subject: String) -> Element {
    let mut state = use_context_provider(|| Signal::new(AppState::new()));

    let title = match subject.as_str() {
        "logic" => "First-Order Logic",
        "english" => "English",
        "coding" => "Coding",
        "math" => "Mathematics",
        _ => "Workspace",
    };

    rsx! {
        style { "{WORKSPACE_STYLE}" }

        div { class: "workspace",
            div { class: "workspace-header",
                div { class: "breadcrumb",
                    Link { to: Route::Home {}, "Home" }
                    span { "›" }
                    span { "{title}" }
                }
                h1 { "LOGOS" }
            }

            div { class: "workspace-content",
                div { class: "sidebar",
                    h3 { "The Path" }
                    ul { class: "lesson-tree",
                        li { class: "active", "1. Basic Propositions" }
                        li { "2. Connectives" }
                        li { "3. Quantifiers" }
                        li { "4. Predicates" }
                        li { class: "locked", "5. Modal Logic" }
                        li { class: "locked", "6. Temporal Logic" }
                    }

                    h3 { style: "margin-top: 32px;", "History" }
                    p { style: "color: #666; font-size: 13px;", "Your recent sessions will appear here." }
                }

                div { class: "main-area",
                    ChatDisplay { messages: state.read().get_history() }
                    InputArea { on_send: move |text| state.write().add_user_message(text) }
                }

                div { class: "inspector",
                    h3 { "AST Inspector" }
                    div { class: "inspector-placeholder",
                        "Parse a sentence to see its abstract syntax tree visualization here."
                    }
                }
            }
        }
    }
}

```

---

### Component: achievement_toast

**File:** `src/ui/components/achievement_toast.rs`

Reusable UI component.

```rust
use dioxus::prelude::*;
use crate::achievements::Achievement;
use crate::audio::{SoundEffect, play_sound};

const ACHIEVEMENT_STYLE: &str = r#"
.achievement-overlay {
    position: fixed;
    top: 0;
    left: 0;
    right: 0;
    bottom: 0;
    background: rgba(0, 0, 0, 0.8);
    display: flex;
    align-items: center;
    justify-content: center;
    z-index: 2000;
    animation: overlay-fade 0.3s ease-out;
}

@keyframes overlay-fade {
    from { opacity: 0; }
    to { opacity: 1; }
}

.achievement-card {
    background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
    border: 2px solid #fbbf24;
    border-radius: 20px;
    padding: 40px 60px;
    text-align: center;
    box-shadow: 0 0 60px rgba(251, 191, 36, 0.4);
    animation: card-appear 0.5s ease-out;
}

@keyframes card-appear {
    0% { transform: scale(0.5) translateY(50px); opacity: 0; }
    70% { transform: scale(1.05) translateY(0); }
    100% { transform: scale(1) translateY(0); opacity: 1; }
}

.achievement-icon {
    font-size: 64px;
    margin-bottom: 16px;
    animation: icon-bounce 0.5s ease-out 0.3s both;
}

@keyframes icon-bounce {
    0% { transform: scale(0); }
    50% { transform: scale(1.3); }
    100% { transform: scale(1); }
}

.achievement-label {
    font-size: 14px;
    color: #fbbf24;
    text-transform: uppercase;
    letter-spacing: 2px;
    margin-bottom: 8px;
}

.achievement-title {
    font-size: 32px;
    font-weight: 700;
    color: #fff;
    margin-bottom: 12px;
}

.achievement-description {
    font-size: 16px;
    color: #888;
    margin-bottom: 24px;
}

.achievement-reward {
    font-size: 24px;
    color: #4ade80;
    font-weight: 600;
    margin-bottom: 16px;
}

.achievement-title-unlock {
    background: linear-gradient(90deg, #fbbf24, #f59e0b);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    background-clip: text;
    font-size: 18px;
    font-weight: 600;
    margin-bottom: 24px;
}

.achievement-dismiss {
    padding: 12px 32px;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    border: none;
    border-radius: 8px;
    color: white;
    font-size: 16px;
    font-weight: 600;
    cursor: pointer;
    transition: transform 0.2s ease;
}

.achievement-dismiss:hover {
    transform: scale(1.05);
}

.particles {
    position: absolute;
    top: 0;
    left: 0;
    right: 0;
    bottom: 0;
    pointer-events: none;
    overflow: hidden;
}

.particle {
    position: absolute;
    font-size: 24px;
    animation: particle-fall 2s ease-out forwards;
}

@keyframes particle-fall {
    0% { transform: translateY(-50px) rotate(0deg); opacity: 1; }
    100% { transform: translateY(100vh) rotate(720deg); opacity: 0; }
}
"#;

#[component]
pub fn AchievementToast(achievement: &'static Achievement, on_dismiss: EventHandler<()>) -> Element {
    use_effect(move || {
        play_sound(SoundEffect::Achievement);
    });

    rsx! {
        style { "{ACHIEVEMENT_STYLE}" }
        div {
            class: "achievement-overlay",
            onclick: move |_| on_dismiss.call(()),
            div { class: "particles",
                for i in 0..20 {
                    span {
                        class: "particle",
                        style: "left: {(i * 5) % 100}%; animation-delay: {i as f32 * 0.1}s;",
                        if i % 3 == 0 { "⭐" } else if i % 3 == 1 { "✨" } else { "🎉" }
                    }
                }
            }
            div { class: "achievement-card",
                div { class: "achievement-icon", "🏆" }
                div { class: "achievement-label", "Achievement Unlocked" }
                div { class: "achievement-title", "{achievement.title}" }
                div { class: "achievement-description", "{achievement.description}" }
                div { class: "achievement-reward", "+{achievement.xp_reward} XP" }
                if let Some(title) = achievement.unlocks_title {
                    div { class: "achievement-title-unlock",
                        "Title Unlocked: {title}"
                    }
                }
                if achievement.grants_freeze {
                    div { class: "achievement-title-unlock",
                        "🛡️ +1 Streak Freeze!"
                    }
                }
                button {
                    class: "achievement-dismiss",
                    onclick: move |e| {
                        e.stop_propagation();
                        on_dismiss.call(());
                    },
                    "Continue"
                }
            }
        }
    }
}

```

---

### Component: ast_tree

**File:** `src/ui/components/ast_tree.rs`

Reusable UI component.

```rust
use dioxus::prelude::*;
use crate::AstNode;

const TREE_STYLE: &str = r#"
.ast-tree-container {
    display: flex;
    flex-direction: column;
    height: 100%;
    overflow: auto;
    padding: 16px;
}

.ast-tree-empty {
    color: #666;
    font-style: italic;
    text-align: center;
    padding: 40px 20px;
}

.ast-node {
    margin-left: 16px;
    position: relative;
}

.ast-node:before {
    content: '';
    position: absolute;
    left: -12px;
    top: 0;
    height: 100%;
    width: 1px;
    background: rgba(255, 255, 255, 0.1);
}

.ast-node:last-child:before {
    height: 12px;
}

.ast-node-label {
    display: flex;
    align-items: center;
    gap: 6px;
    padding: 4px 8px;
    border-radius: 4px;
    cursor: pointer;
    transition: background 0.15s ease;
    position: relative;
}

.ast-node-label:hover {
    background: rgba(255, 255, 255, 0.05);
}

.ast-node-label:before {
    content: '';
    position: absolute;
    left: -12px;
    top: 50%;
    width: 8px;
    height: 1px;
    background: rgba(255, 255, 255, 0.1);
}

.ast-node-toggle {
    width: 16px;
    height: 16px;
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 10px;
    color: #666;
    transition: transform 0.15s ease;
}

.ast-node-toggle.expanded {
    transform: rotate(90deg);
}

.ast-node-text {
    font-family: 'SF Mono', 'Fira Code', 'Consolas', monospace;
    font-size: 13px;
}

.ast-node-type {
    font-size: 10px;
    padding: 2px 6px;
    border-radius: 3px;
    background: rgba(255, 255, 255, 0.08);
    color: #888;
}

.ast-node-type.quantifier { background: rgba(198, 120, 221, 0.2); color: #c678dd; }
.ast-node-type.predicate { background: rgba(152, 195, 121, 0.2); color: #98c379; }
.ast-node-type.binary_op { background: rgba(198, 120, 221, 0.2); color: #c678dd; }
.ast-node-type.unary_op { background: rgba(224, 108, 117, 0.2); color: #e06c75; }
.ast-node-type.constant { background: rgba(229, 192, 123, 0.2); color: #e5c07b; }
.ast-node-type.variable { background: rgba(97, 175, 239, 0.2); color: #61afef; }
.ast-node-type.modal { background: rgba(86, 182, 194, 0.2); color: #56b6c2; }
.ast-node-type.lambda { background: rgba(224, 108, 117, 0.2); color: #e06c75; }

.ast-children {
    display: none;
}

.ast-children.expanded {
    display: block;
}

.ast-root {
    margin-left: 0;
}

.ast-root:before {
    display: none;
}

.ast-root > .ast-node-label:before {
    display: none;
}
"#;

#[component]
pub fn AstTree(ast: Option<AstNode>) -> Element {
    rsx! {
        style { "{TREE_STYLE}" }

        div { class: "ast-tree-container",
            if let Some(node) = ast {
                AstNodeView { node: node, is_root: true }
            } else {
                div { class: "ast-tree-empty",
                    "Parse a sentence to see its AST..."
                }
            }
        }
    }
}

#[component]
fn AstNodeView(node: AstNode, is_root: bool) -> Element {
    let mut expanded = use_signal(|| true);
    let has_children = !node.children.is_empty();

    let node_class = if is_root { "ast-node ast-root" } else { "ast-node" };
    let toggle_class = if *expanded.read() { "ast-node-toggle expanded" } else { "ast-node-toggle" };
    let children_class = if *expanded.read() { "ast-children expanded" } else { "ast-children" };
    let type_class = format!("ast-node-type {}", node.node_type);

    rsx! {
        div { class: "{node_class}",
            div {
                class: "ast-node-label",
                onclick: move |_| {
                    if has_children {
                        let current = *expanded.read();
                        expanded.set(!current);
                    }
                },
                if has_children {
                    span { class: "{toggle_class}", "\u{25B6}" }
                } else {
                    span { class: "ast-node-toggle", "\u{2022}" }
                }
                span { class: "ast-node-text", "{node.label}" }
                span { class: "{type_class}", "{node.node_type}" }
            }

            if has_children {
                div { class: "{children_class}",
                    for child in node.children.iter() {
                        AstNodeView { node: child.clone(), is_root: false }
                    }
                }
            }
        }
    }
}

```

---

### Component: ChatDisplay

**File:** `src/ui/components/chat.rs`

Renders chat message history with role-based styling (user, system, error).

```rust
use dioxus::prelude::*;
use crate::ui::state::{ChatMessage, Role};

#[component]
pub fn ChatDisplay(messages: Vec<ChatMessage>) -> Element {
    rsx! {
        div { class: "chat-area",
            for (i, msg) in messages.iter().enumerate() {
                div {
                    key: "{i}",
                    class: match msg.role {
                        Role::User => "message user",
                        Role::System => "message system",
                        Role::Error => "message error",
                    },
                    "{msg.content}"
                }
            }
        }
    }
}

```

---

### Component: combo_indicator

**File:** `src/ui/components/combo_indicator.rs`

Reusable UI component.

```rust
use dioxus::prelude::*;

const COMBO_STYLE: &str = r#"
.combo-record {
    position: absolute;
    top: -24px;
    left: 50%;
    transform: translateX(-50%);
    font-size: 12px;
    color: #fbbf24;
    font-weight: 600;
    animation: record-flash 1.5s ease-out forwards;
    white-space: nowrap;
    pointer-events: none;
}

@keyframes record-flash {
    0% { opacity: 0; transform: translateX(-50%) translateY(10px) scale(0.8); }
    20% { opacity: 1; transform: translateX(-50%) translateY(0) scale(1.1); }
    40% { opacity: 1; transform: translateX(-50%) translateY(0) scale(1); }
    100% { opacity: 0; transform: translateX(-50%) translateY(-10px) scale(0.9); }
}
.combo-indicator {
    display: flex;
    align-items: center;
    gap: 8px;
    padding: 8px 16px;
    background: rgba(249, 115, 22, 0.15);
    border: 1px solid rgba(249, 115, 22, 0.3);
    border-radius: 24px;
    animation: combo-pulse 0.3s ease-out;
}

@keyframes combo-pulse {
    0% { transform: scale(1); }
    50% { transform: scale(1.1); }
    100% { transform: scale(1); }
}

.combo-flames {
    display: flex;
    gap: 2px;
}

.flame {
    font-size: 16px;
    animation: flame-dance 0.5s ease-in-out infinite alternate;
}

.flame:nth-child(2) { animation-delay: 0.1s; }
.flame:nth-child(3) { animation-delay: 0.2s; }

@keyframes flame-dance {
    from { transform: translateY(0) scale(1); }
    to { transform: translateY(-2px) scale(1.1); }
}

.combo-count {
    font-size: 20px;
    font-weight: 700;
    color: #f97316;
}

.combo-multiplier {
    font-size: 14px;
    color: #fb923c;
    font-weight: 500;
}

.combo-wrapper {
    position: relative;
    display: inline-flex;
}
"#;

#[component]
pub fn ComboIndicator(combo: u32, multiplier: f64, is_new_record: bool) -> Element {
    let mut show_record = use_signal(|| false);
    let mut last_record_combo = use_signal(|| 0u32);

    if is_new_record && combo > last_record_combo() {
        show_record.set(true);
        last_record_combo.set(combo);

        spawn(async move {
            gloo_timers::future::TimeoutFuture::new(1500).await;
            show_record.set(false);
        });
    }

    if combo == 0 {
        return rsx! {};
    }

    let flame_count = (combo.min(5)) as usize;

    rsx! {
        style { "{COMBO_STYLE}" }
        div { class: "combo-wrapper",
            if show_record() {
                div { class: "combo-record", "NEW RECORD!" }
            }
            div { class: "combo-indicator",
                div { class: "combo-flames",
                    for _ in 0..flame_count {
                        span { class: "flame", "🔥" }
                    }
                }
                span { class: "combo-count", "{combo}x" }
                span { class: "combo-multiplier", "({multiplier:.1}x)" }
            }
        }
    }
}

```

---

### Component: editor

**File:** `src/ui/components/editor.rs`

Reusable UI component.

```rust
use dioxus::prelude::*;
use wasm_bindgen::prelude::*;

#[wasm_bindgen]
extern "C" {
    #[wasm_bindgen(js_namespace = window, js_name = initCodeMirror)]
    fn init_codemirror(element_id: &str, on_change: &Closure<dyn FnMut(String)>) -> JsValue;

    #[wasm_bindgen(js_namespace = window, js_name = setCodeMirrorValue)]
    fn set_codemirror_value(editor: &JsValue, value: &str);

    #[wasm_bindgen(js_namespace = window, js_name = getCodeMirrorValue)]
    fn get_codemirror_value(editor: &JsValue) -> String;
}

const EDITOR_STYLE: &str = r#"
.editor-container {
    flex: 1;
    display: flex;
    flex-direction: column;
    min-height: 200px;
    padding: 16px;
}

.editor-wrapper {
    flex: 1;
    background: rgba(255, 255, 255, 0.08);
    border: 1px solid rgba(255, 255, 255, 0.2);
    border-radius: 12px;
    overflow: hidden;
}

.editor-fallback {
    width: 100%;
    height: 100%;
    min-height: 150px;
    background: rgba(255, 255, 255, 0.08);
    border: 1px solid rgba(255, 255, 255, 0.2);
    border-radius: 12px;
    padding: 16px;
    font-size: 16px;
    font-family: 'SF Mono', 'Fira Code', 'Consolas', monospace;
    color: #e8e8e8;
    resize: none;
    outline: none;
}

.editor-fallback:focus {
    border-color: #667eea;
    box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.2);
}

.editor-fallback::placeholder {
    color: #666;
}
"#;

#[component]
pub fn Editor(
    value: String,
    on_change: EventHandler<String>,
    placeholder: Option<String>,
) -> Element {
    let placeholder_text = placeholder.unwrap_or_else(|| "Type an English sentence...".to_string());

    rsx! {
        style { "{EDITOR_STYLE}" }

        div { class: "editor-container",
            textarea {
                class: "editor-fallback",
                placeholder: "{placeholder_text}",
                value: "{value}",
                oninput: move |evt| on_change.call(evt.value()),
            }
        }
    }
}

#[component]
pub fn LiveEditor(
    on_change: EventHandler<String>,
    placeholder: Option<String>,
) -> Element {
    let mut text = use_signal(String::new);
    let placeholder_text = placeholder.unwrap_or_else(|| "Type an English sentence...".to_string());

    let handle_input = move |evt: Event<FormData>| {
        let new_value = evt.value();
        text.set(new_value.clone());
        on_change.call(new_value);
    };

    rsx! {
        style { "{EDITOR_STYLE}" }

        div { class: "editor-container",
            textarea {
                class: "editor-fallback",
                placeholder: "{placeholder_text}",
                value: "{text}",
                oninput: handle_input,
                spellcheck: "false",
                autocomplete: "off",
                autocapitalize: "off",
            }
        }
    }
}

```

---

### Component: InputArea

**File:** `src/ui/components/input.rs`

Text input with Enter key submission and Transpile button.

```rust
use dioxus::prelude::*;

#[component]
pub fn InputArea(on_send: EventHandler<String>) -> Element {
    let mut text = use_signal(String::new);

    let mut submit = move || {
        let current_text = text.read().clone();
        if !current_text.trim().is_empty() {
            on_send.call(current_text);
            text.set(String::new());
        }
    };

    rsx! {
        div { class: "input-area",
            div { class: "input-row",
                input {
                    placeholder: "Type an English sentence...",
                    value: "{text}",
                    oninput: move |evt| text.set(evt.value()),
                    onkeydown: move |evt| {
                        if evt.key() == Key::Enter {
                            submit();
                        }
                    }
                }
                button {
                    onclick: move |_| submit(),
                    "Transpile →"
                }
            }
        }
    }
}

```

---

### Component: katex

**File:** `src/ui/components/katex.rs`

Reusable UI component.

```rust
use dioxus::prelude::*;
use wasm_bindgen::prelude::*;

#[wasm_bindgen]
extern "C" {
    #[wasm_bindgen(js_namespace = window, js_name = renderKaTeX)]
    fn render_katex(element_id: &str, latex: &str, display_mode: bool);
}

static KATEX_COUNTER: std::sync::atomic::AtomicU64 = std::sync::atomic::AtomicU64::new(0);

fn next_katex_id() -> String {
    let id = KATEX_COUNTER.fetch_add(1, std::sync::atomic::Ordering::Relaxed);
    format!("katex-{}", id)
}

#[component]
pub fn KatexSpan(latex: String, #[props(default = false)] display: bool) -> Element {
    let element_id = use_signal(|| next_katex_id());

    use_effect(move || {
        let id = element_id.read().clone();
        let latex = latex.clone();
        render_katex(&id, &latex, display);
    });

    rsx! {
        span {
            id: "{element_id}",
            class: if display { "katex-display" } else { "katex-inline" }
        }
    }
}

#[derive(Debug, Clone, PartialEq)]
pub enum TextPart {
    Plain(String),
    Latex { content: String, display: bool },
}

pub fn parse_latex_in_text(text: &str) -> Vec<TextPart> {
    let mut parts = Vec::new();
    let mut remaining = text;

    while !remaining.is_empty() {
        let display_pos = remaining.find("$$");
        let inline_pos = remaining.find('$');

        match (display_pos, inline_pos) {
            (Some(d), Some(i)) if d <= i => {
                if d > 0 {
                    parts.push(TextPart::Plain(remaining[..d].to_string()));
                }
                remaining = &remaining[d + 2..];
                if let Some(end) = remaining.find("$$") {
                    parts.push(TextPart::Latex {
                        content: remaining[..end].to_string(),
                        display: true,
                    });
                    remaining = &remaining[end + 2..];
                } else {
                    parts.push(TextPart::Plain(format!("$${}", remaining)));
                    break;
                }
            }
            (_, Some(i)) => {
                if i > 0 {
                    parts.push(TextPart::Plain(remaining[..i].to_string()));
                }
                remaining = &remaining[i + 1..];
                if let Some(end) = remaining.find('$') {
                    parts.push(TextPart::Latex {
                        content: remaining[..end].to_string(),
                        display: false,
                    });
                    remaining = &remaining[end + 1..];
                } else {
                    parts.push(TextPart::Plain(format!("${}", remaining)));
                    break;
                }
            }
            (Some(d), None) => {
                if d > 0 {
                    parts.push(TextPart::Plain(remaining[..d].to_string()));
                }
                remaining = &remaining[d + 2..];
                if let Some(end) = remaining.find("$$") {
                    parts.push(TextPart::Latex {
                        content: remaining[..end].to_string(),
                        display: true,
                    });
                    remaining = &remaining[end + 2..];
                } else {
                    parts.push(TextPart::Plain(format!("$${}", remaining)));
                    break;
                }
            }
            (None, None) => {
                parts.push(TextPart::Plain(remaining.to_string()));
                break;
            }
        }
    }

    parts
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_parse_plain_text() {
        let parts = parse_latex_in_text("Hello world");
        assert_eq!(parts.len(), 1);
        assert_eq!(parts[0], TextPart::Plain("Hello world".to_string()));
    }

    #[test]
    fn test_parse_inline_latex() {
        let parts = parse_latex_in_text("The formula $x + y$ is simple");
        assert_eq!(parts.len(), 3);
        assert_eq!(parts[0], TextPart::Plain("The formula ".to_string()));
        assert_eq!(parts[1], TextPart::Latex { content: "x + y".to_string(), display: false });
        assert_eq!(parts[2], TextPart::Plain(" is simple".to_string()));
    }

    #[test]
    fn test_parse_display_latex() {
        let parts = parse_latex_in_text("Consider: $$\\forall x$$ as shown");
        assert_eq!(parts.len(), 3);
        assert_eq!(parts[0], TextPart::Plain("Consider: ".to_string()));
        assert_eq!(parts[1], TextPart::Latex { content: "\\forall x".to_string(), display: true });
        assert_eq!(parts[2], TextPart::Plain(" as shown".to_string()));
    }

    #[test]
    fn test_parse_mixed() {
        let parts = parse_latex_in_text("$A$ and $B$ implies $$A \\land B$$");
        assert_eq!(parts.len(), 5);
        assert_eq!(parts[0], TextPart::Latex { content: "A".to_string(), display: false });
        assert_eq!(parts[1], TextPart::Plain(" and ".to_string()));
        assert_eq!(parts[2], TextPart::Latex { content: "B".to_string(), display: false });
        assert_eq!(parts[3], TextPart::Plain(" implies ".to_string()));
        assert_eq!(parts[4], TextPart::Latex { content: "A \\land B".to_string(), display: true });
    }

    #[test]
    fn test_unclosed_inline() {
        let parts = parse_latex_in_text("Start $unclosed");
        assert_eq!(parts.len(), 2);
        assert_eq!(parts[0], TextPart::Plain("Start ".to_string()));
        assert_eq!(parts[1], TextPart::Plain("$unclosed".to_string()));
    }
}

```

---

### Component: logic_output

**File:** `src/ui/components/logic_output.rs`

Reusable UI component.

```rust
use dioxus::prelude::*;

const OUTPUT_STYLE: &str = r#"
.logic-output-container {
    display: flex;
    flex-direction: column;
    height: 100%;
    padding: 16px;
}

.reading-selector {
    display: flex;
    align-items: center;
    gap: 8px;
    margin-bottom: 12px;
}

.reading-selector span {
    color: #888;
    font-size: 14px;
}

.reading-btn {
    width: 28px;
    height: 28px;
    border-radius: 6px;
    border: 1px solid rgba(255, 255, 255, 0.2);
    background: rgba(255, 255, 255, 0.08);
    color: #888;
    font-size: 12px;
    cursor: pointer;
    transition: all 0.2s ease;
}

.reading-btn:hover {
    background: rgba(255, 255, 255, 0.15);
    color: #e8e8e8;
}

.reading-btn.active {
    background: linear-gradient(135deg, #667eea, #764ba2);
    border-color: transparent;
    color: white;
}

.logic-display {
    flex: 1;
    background: rgba(255, 255, 255, 0.08);
    border: 1px solid rgba(255, 255, 255, 0.2);
    border-radius: 12px;
    padding: 20px;
    font-family: 'SF Mono', 'Fira Code', 'Consolas', monospace;
    font-size: 18px;
    line-height: 1.6;
    color: #e8e8e8;
    overflow: auto;
}

.logic-display.empty {
    color: #666;
    font-style: italic;
    display: flex;
    align-items: center;
    justify-content: center;
}

.logic-display.error {
    border-color: rgba(224, 108, 117, 0.3);
    color: #e06c75;
}

.logic-quantifier { color: #c678dd; font-weight: 500; }
.logic-variable { color: #61afef; }
.logic-predicate { color: #98c379; }
.logic-connective { color: #c678dd; }
.logic-constant { color: #e5c07b; }
.logic-paren { color: #abb2bf; }
"#;

#[derive(Clone, Copy, PartialEq, Default)]
pub enum OutputFormat {
    #[default]
    Unicode,
    LaTeX,
}

#[component]
pub fn LogicOutput(
    logic: Option<String>,
    readings: Vec<String>,
    error: Option<String>,
    format: OutputFormat,
) -> Element {
    let mut current_reading = use_signal(|| 0usize);

    let total_readings = readings.len().max(1);
    let display_logic = if !readings.is_empty() {
        let idx = (*current_reading.read()).min(readings.len().saturating_sub(1));
        Some(readings.get(idx).cloned().unwrap_or_default())
    } else {
        logic.clone()
    };

    let formatted_output = match (&display_logic, format) {
        (Some(logic), OutputFormat::LaTeX) => convert_to_latex(logic),
        (Some(logic), OutputFormat::Unicode) => logic.clone(),
        (None, _) => String::new(),
    };

    rsx! {
        style { "{OUTPUT_STYLE}" }

        div { class: "logic-output-container",
            if total_readings > 1 {
                div { class: "reading-selector",
                    span { "Reading" }
                    for i in 0..total_readings {
                        button {
                            class: if *current_reading.read() == i { "reading-btn active" } else { "reading-btn" },
                            onclick: move |_| current_reading.set(i),
                            "{i + 1}"
                        }
                    }
                    span { "of {total_readings}" }
                }
            }

            if let Some(err) = &error {
                div { class: "logic-display error",
                    "{err}"
                }
            } else if formatted_output.is_empty() {
                div { class: "logic-display empty",
                    "Type a sentence to see its logical form..."
                }
            } else {
                div { class: "logic-display",
                    dangerous_inner_html: highlight_logic(&formatted_output)
                }
            }
        }
    }
}

fn convert_to_latex(unicode: &str) -> String {
    unicode
        .replace('\u{2200}', "\\forall ")
        .replace('\u{2203}', "\\exists ")
        .replace('\u{00AC}', "\\neg ")
        .replace('\u{2227}', "\\land ")
        .replace('\u{2228}', "\\lor ")
        .replace('\u{2192}', "\\rightarrow ")
        .replace('\u{2194}', "\\leftrightarrow ")
        .replace('\u{22A5}', "\\bot ")
        .replace('\u{22A4}', "\\top ")
}

pub fn highlight_logic(logic: &str) -> String {
    let mut result = String::new();
    let mut chars = logic.chars().peekable();

    while let Some(c) = chars.next() {
        match c {
            '\u{2200}' | '\u{2203}' => {
                result.push_str(&format!(r#"<span class="logic-quantifier">{}</span>"#, c));
            }
            '\u{00AC}' | '\u{2227}' | '\u{2228}' | '\u{2192}' | '\u{2194}' => {
                result.push_str(&format!(r#"<span class="logic-connective">{}</span>"#, c));
            }
            '(' | ')' | '[' | ']' => {
                result.push_str(&format!(r#"<span class="logic-paren">{}</span>"#, c));
            }
            'a'..='z' if chars.peek().map(|n| !n.is_alphabetic()).unwrap_or(true) => {
                result.push_str(&format!(r#"<span class="logic-variable">{}</span>"#, c));
            }
            'A'..='Z' => {
                let mut word = String::from(c);
                while let Some(&next) = chars.peek() {
                    if next.is_alphanumeric() {
                        word.push(chars.next().unwrap());
                    } else {
                        break;
                    }
                }
                if word.chars().next().map(|c| c.is_uppercase()).unwrap_or(false)
                    && word.len() > 1
                    && word.chars().skip(1).all(|c| c.is_lowercase() || c.is_numeric())
                {
                    result.push_str(&format!(r#"<span class="logic-constant">{}</span>"#, word));
                } else {
                    result.push_str(&format!(r#"<span class="logic-predicate">{}</span>"#, word));
                }
            }
            _ => result.push(c),
        }
    }

    result
}

```

---

### Component: mixed_text

**File:** `src/ui/components/mixed_text.rs`

Reusable UI component.

```rust
use dioxus::prelude::*;
use super::katex::{KatexSpan, TextPart, parse_latex_in_text};

#[component]
pub fn MixedText(content: String) -> Element {
    let parts = parse_latex_in_text(&content);

    rsx! {
        span { class: "mixed-text",
            for (i, part) in parts.iter().enumerate() {
                match part {
                    TextPart::Plain(text) => rsx! {
                        span { key: "{i}", "{text}" }
                    },
                    TextPart::Latex { content, display } => rsx! {
                        KatexSpan { key: "{i}", latex: content.clone(), display: *display }
                    },
                }
            }
        }
    }
}

```

---

### Component: mod

**File:** `src/ui/components/mod.rs`

Reusable UI component.

```rust
pub mod chat;
pub mod input;
pub mod editor;
pub mod logic_output;
pub mod ast_tree;
pub mod socratic_guide;
pub mod katex;
pub mod mixed_text;
pub mod xp_popup;
pub mod combo_indicator;
pub mod streak_display;
pub mod achievement_toast;
pub mod mode_selector;

```

---

### Component: mode_selector

**File:** `src/ui/components/mode_selector.rs`

Reusable UI component.

```rust
use dioxus::prelude::*;

const MODE_SELECTOR_STYLE: &str = r#"
.mode-overlay {
    position: fixed;
    top: 0;
    left: 0;
    right: 0;
    bottom: 0;
    background: rgba(0, 0, 0, 0.8);
    display: flex;
    align-items: center;
    justify-content: center;
    z-index: 1000;
    animation: fade-in 0.2s ease-out;
}

@keyframes fade-in {
    from { opacity: 0; }
    to { opacity: 1; }
}

.mode-dialog {
    background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
    border: 1px solid rgba(255, 255, 255, 0.1);
    border-radius: 20px;
    padding: 32px;
    max-width: 600px;
    width: 90%;
    animation: slide-up 0.3s ease-out;
}

@keyframes slide-up {
    from { transform: translateY(20px); opacity: 0; }
    to { transform: translateY(0); opacity: 1; }
}

.mode-dialog h2 {
    color: #e8e8e8;
    font-size: 24px;
    margin-bottom: 8px;
    text-align: center;
}

.mode-dialog p {
    color: #888;
    font-size: 14px;
    text-align: center;
    margin-bottom: 24px;
}

.mode-options {
    display: flex;
    flex-direction: column;
    gap: 12px;
}

.mode-option {
    display: flex;
    align-items: center;
    gap: 16px;
    padding: 20px;
    background: rgba(255, 255, 255, 0.03);
    border: 2px solid rgba(255, 255, 255, 0.08);
    border-radius: 12px;
    cursor: pointer;
    transition: all 0.2s ease;
}

.mode-option:hover {
    background: rgba(255, 255, 255, 0.06);
    border-color: rgba(255, 255, 255, 0.15);
    transform: translateX(4px);
}

.mode-option.textbook:hover {
    border-color: rgba(96, 165, 250, 0.5);
}

.mode-option.learning:hover {
    border-color: rgba(74, 222, 128, 0.5);
}

.mode-option.testing:hover {
    border-color: rgba(251, 146, 60, 0.5);
}

.mode-icon {
    width: 48px;
    height: 48px;
    display: flex;
    align-items: center;
    justify-content: center;
    border-radius: 12px;
    font-size: 24px;
}

.mode-icon.textbook {
    background: rgba(96, 165, 250, 0.2);
}

.mode-icon.learning {
    background: rgba(74, 222, 128, 0.2);
}

.mode-icon.testing {
    background: rgba(251, 146, 60, 0.2);
}

.mode-info {
    flex: 1;
}

.mode-info h3 {
    color: #e8e8e8;
    font-size: 18px;
    margin-bottom: 4px;
}

.mode-info p {
    color: #888;
    font-size: 13px;
    text-align: left;
    margin: 0;
}

.mode-arrow {
    color: #666;
    font-size: 20px;
}

.mode-cancel {
    display: block;
    width: 100%;
    margin-top: 16px;
    padding: 12px;
    background: transparent;
    border: 1px solid rgba(255, 255, 255, 0.1);
    border-radius: 8px;
    color: #888;
    font-size: 14px;
    cursor: pointer;
    transition: all 0.2s ease;
}

.mode-cancel:hover {
    border-color: rgba(255, 255, 255, 0.2);
    color: #aaa;
}

.recommended-badge {
    background: rgba(74, 222, 128, 0.2);
    color: #4ade80;
    padding: 2px 8px;
    border-radius: 4px;
    font-size: 10px;
    font-weight: 600;
    text-transform: uppercase;
    margin-left: 8px;
}
"#;

#[derive(Clone, PartialEq)]
pub struct ModeInfo {
    pub era: String,
    pub module: String,
    pub title: String,
}

#[component]
pub fn ModeSelector(
    info: ModeInfo,
    on_select: EventHandler<String>,
    on_cancel: EventHandler<()>,
) -> Element {
    rsx! {
        style { "{MODE_SELECTOR_STYLE}" }
        div {
            class: "mode-overlay",
            onclick: move |_| on_cancel.call(()),
            div {
                class: "mode-dialog",
                onclick: move |e| e.stop_propagation(),
                h2 { "{info.title}" }
                p { "Choose how you want to approach this module" }

                div { class: "mode-options",
                    button {
                        class: "mode-option textbook",
                        onclick: move |_| on_select.call("textbook".to_string()),
                        div { class: "mode-icon textbook", "📖" }
                        div { class: "mode-info",
                            h3 { "Read" }
                            p { "Study the concepts and examples before practicing" }
                        }
                        span { class: "mode-arrow", "→" }
                    }

                    button {
                        class: "mode-option learning",
                        onclick: move |_| on_select.call("learning".to_string()),
                        div { class: "mode-icon learning", "🎓" }
                        div { class: "mode-info",
                            h3 {
                                "Practice"
                                span { class: "recommended-badge", "Recommended" }
                            }
                            p { "Learn with hints and immediate feedback on your answers" }
                        }
                        span { class: "mode-arrow", "→" }
                    }

                    button {
                        class: "mode-option testing",
                        onclick: move |_| on_select.call("testing".to_string()),
                        div { class: "mode-icon testing", "📋" }
                        div { class: "mode-info",
                            h3 { "Test" }
                            p { "Prove your knowledge with no hints - see results at the end" }
                        }
                        span { class: "mode-arrow", "→" }
                    }
                }

                button {
                    class: "mode-cancel",
                    onclick: move |_| on_cancel.call(()),
                    "Cancel"
                }
            }
        }
    }
}

```

---

### Component: socratic_guide

**File:** `src/ui/components/socratic_guide.rs`

Reusable UI component.

```rust
use dioxus::prelude::*;

const GUIDE_STYLE: &str = r#"
.socratic-guide {
    display: flex;
    align-items: flex-start;
    gap: 12px;
    padding: 16px 20px;
    background: rgba(255, 255, 255, 0.03);
    border-top: 1px solid rgba(255, 255, 255, 0.08);
    min-height: 60px;
}

.guide-avatar {
    width: 36px;
    height: 36px;
    border-radius: 50%;
    background: linear-gradient(135deg, #667eea, #764ba2);
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 18px;
    flex-shrink: 0;
}

.guide-content {
    flex: 1;
    display: flex;
    flex-direction: column;
    gap: 4px;
}

.guide-label {
    font-size: 11px;
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    color: #667eea;
}

.guide-message {
    font-size: 14px;
    line-height: 1.5;
    color: #c8c8c8;
}

.guide-message.error {
    color: #e06c75;
}

.guide-message.hint {
    color: #98c379;
}

.guide-message.info {
    color: #61afef;
}

.guide-message code {
    font-family: 'SF Mono', 'Fira Code', 'Consolas', monospace;
    background: rgba(255, 255, 255, 0.08);
    padding: 2px 6px;
    border-radius: 4px;
    font-size: 13px;
}

.guide-actions {
    display: flex;
    gap: 8px;
    margin-top: 8px;
}

.guide-btn {
    padding: 6px 12px;
    border-radius: 6px;
    border: 1px solid rgba(255, 255, 255, 0.15);
    background: rgba(255, 255, 255, 0.05);
    color: #888;
    font-size: 12px;
    cursor: pointer;
    transition: all 0.2s ease;
}

.guide-btn:hover {
    background: rgba(255, 255, 255, 0.1);
    color: #e8e8e8;
}

.guide-btn.primary {
    background: linear-gradient(135deg, #667eea, #764ba2);
    border-color: transparent;
    color: white;
}

.guide-btn.primary:hover {
    opacity: 0.9;
}

.guide-empty {
    color: #666;
    font-style: italic;
}
"#;

#[derive(Clone, PartialEq)]
pub enum GuideMode {
    Idle,
    Success(String),
    Error(String),
    Hint(String),
    Info(String),
}

impl Default for GuideMode {
    fn default() -> Self {
        GuideMode::Idle
    }
}

#[component]
pub fn SocraticGuide(
    mode: GuideMode,
    on_hint_request: Option<EventHandler<()>>,
) -> Element {
    let (message_class, label, message) = match &mode {
        GuideMode::Idle => {
            return rsx! {
                style { "{GUIDE_STYLE}" }
                div { class: "socratic-guide",
                    div { class: "guide-avatar", "\u{1F989}" }
                    div { class: "guide-content",
                        div { class: "guide-label", "Socrates" }
                        div { class: "guide-message guide-empty",
                            "Type a sentence to begin your journey into logic..."
                        }
                    }
                }
            }
        }
        GuideMode::Success(msg) => ("guide-message", "Analysis", msg.clone()),
        GuideMode::Error(msg) => ("guide-message error", "Something to consider", msg.clone()),
        GuideMode::Hint(msg) => ("guide-message hint", "Hint", msg.clone()),
        GuideMode::Info(msg) => ("guide-message info", "Observation", msg.clone()),
    };

    rsx! {
        style { "{GUIDE_STYLE}" }

        div { class: "socratic-guide",
            div { class: "guide-avatar", "\u{1F989}" }
            div { class: "guide-content",
                div { class: "guide-label", "{label}" }
                div { class: "{message_class}",
                    dangerous_inner_html: format_guide_message(&message)
                }
                if on_hint_request.is_some() && matches!(mode, GuideMode::Error(_)) {
                    div { class: "guide-actions",
                        button {
                            class: "guide-btn",
                            onclick: move |_| {
                                if let Some(handler) = &on_hint_request {
                                    handler.call(());
                                }
                            },
                            "Show me a hint"
                        }
                    }
                }
            }
        }
    }
}

fn format_guide_message(message: &str) -> String {
    let mut result = message.to_string();

    let code_patterns = [
        ("\u{2200}", "<code>\u{2200}</code>"),
        ("\u{2203}", "<code>\u{2203}</code>"),
        ("\u{2227}", "<code>\u{2227}</code>"),
        ("\u{2228}", "<code>\u{2228}</code>"),
        ("\u{2192}", "<code>\u{2192}</code>"),
        ("\u{00AC}", "<code>\u{00AC}</code>"),
    ];

    for (pattern, replacement) in &code_patterns {
        result = result.replace(pattern, replacement);
    }

    result
}

pub fn get_success_message(readings_count: usize) -> String {
    match readings_count {
        0 => "Hmm, I couldn't parse that sentence. Let me think about why...".to_string(),
        1 => "This sentence has a single, unambiguous logical form.".to_string(),
        2 => format!(
            "Interesting! This sentence is ambiguous. I found {} different readings. \
            Click the reading buttons above to explore each interpretation.",
            readings_count
        ),
        n => format!(
            "Fascinating complexity! I discovered {} different ways to interpret this sentence. \
            Each represents a valid logical reading of your input.",
            n
        ),
    }
}

pub fn get_context_hint(input: &str) -> Option<String> {
    let lower = input.to_lowercase();

    if lower.starts_with("every") || lower.starts_with("all") {
        Some("Universal quantification (\u{2200}) asserts something about ALL members of a set.".to_string())
    } else if lower.starts_with("some") || lower.starts_with("a ") {
        Some("Existential quantification (\u{2203}) asserts the EXISTENCE of at least one entity.".to_string())
    } else if lower.contains(" loves ") || lower.contains(" sees ") {
        Some("Transitive verbs create two-place predicates relating a subject to an object.".to_string())
    } else if lower.contains(" is ") && lower.contains(" not ") {
        Some("Negation (\u{00AC}) inverts the truth value of the proposition it scopes over.".to_string())
    } else {
        None
    }
}

```

---

### Component: streak_display

**File:** `src/ui/components/streak_display.rs`

Reusable UI component.

```rust
use dioxus::prelude::*;
use crate::game::StreakStatus;

const STREAK_STYLE: &str = r#"
.streak-display {
    display: flex;
    align-items: center;
    gap: 8px;
    padding: 6px 12px;
    border-radius: 20px;
    font-size: 14px;
    font-weight: 500;
}

.streak-active {
    background: rgba(249, 115, 22, 0.15);
    border: 1px solid rgba(249, 115, 22, 0.3);
    color: #f97316;
}

.streak-at-risk {
    background: rgba(248, 113, 113, 0.15);
    border: 1px solid rgba(248, 113, 113, 0.3);
    color: #f87171;
    animation: risk-pulse 1s ease-in-out infinite;
}

@keyframes risk-pulse {
    0%, 100% { opacity: 1; }
    50% { opacity: 0.7; }
}

.streak-frozen {
    background: rgba(56, 189, 248, 0.15);
    border: 1px solid rgba(56, 189, 248, 0.3);
    color: #38bdf8;
}

.streak-lost {
    background: rgba(107, 114, 128, 0.15);
    border: 1px solid rgba(107, 114, 128, 0.3);
    color: #9ca3af;
}

.streak-icon {
    font-size: 16px;
}

.streak-count {
    font-weight: 600;
}

.streak-label {
    color: #888;
    font-size: 12px;
}

.freeze-tokens {
    display: flex;
    gap: 4px;
    margin-left: 8px;
    padding-left: 8px;
    border-left: 1px solid rgba(255, 255, 255, 0.1);
}

.freeze-token {
    font-size: 12px;
    opacity: 0.8;
}

.freeze-token.empty {
    opacity: 0.3;
}
"#;

#[component]
pub fn StreakDisplay(streak: u32, status: StreakStatus, freezes: u8) -> Element {
    let (class, icon, text) = match status {
        StreakStatus::Active { days } => {
            ("streak-display streak-active", "🔥", format!("{} day streak", days))
        }
        StreakStatus::AtRisk => {
            ("streak-display streak-at-risk", "⚠️", "Streak at risk!".to_string())
        }
        StreakStatus::Frozen => {
            ("streak-display streak-frozen", "🛡️", format!("{} days (frozen)", streak))
        }
        StreakStatus::Lost { was } => {
            ("streak-display streak-lost", "💔", format!("Lost {} day streak", was))
        }
    };

    rsx! {
        style { "{STREAK_STYLE}" }
        div { class: "{class}",
            span { class: "streak-icon", "{icon}" }
            span { class: "streak-count", "{text}" }
            div { class: "freeze-tokens",
                for i in 0..3u8 {
                    span {
                        class: if i < freezes { "freeze-token" } else { "freeze-token empty" },
                        "🛡️"
                    }
                }
            }
        }
    }
}

```

---

### Component: xp_popup

**File:** `src/ui/components/xp_popup.rs`

Reusable UI component.

```rust
use dioxus::prelude::*;
use crate::game::XpReward;
use crate::audio::{SoundEffect, play_sound};

const XP_POPUP_STYLE: &str = r#"
.xp-popup {
    position: fixed;
    top: 50%;
    left: 50%;
    transform: translate(-50%, -50%);
    z-index: 1000;
    cursor: pointer;
    animation: xp-appear 2s ease-out forwards;
}

@keyframes xp-appear {
    0% { opacity: 0; transform: translate(-50%, -50%) scale(0.5); }
    10% { opacity: 1; transform: translate(-50%, -50%) scale(1.1); }
    20% { opacity: 1; transform: translate(-50%, -50%) scale(1); }
    80% { opacity: 1; transform: translate(-50%, -50%) scale(1); }
    100% { opacity: 0; transform: translate(-50%, -50%) scale(0.9) translateY(-20px); }
}

.xp-popup-content {
    background: rgba(0, 0, 0, 0.9);
    border: 2px solid #667eea;
    border-radius: 16px;
    padding: 24px 40px;
    text-align: center;
    box-shadow: 0 0 40px rgba(102, 126, 234, 0.4);
}

.xp-total {
    font-size: 48px;
    font-weight: 700;
    color: #4ade80;
    margin-bottom: 8px;
}

.xp-total.critical {
    color: #fbbf24;
    text-shadow: 0 0 20px #fbbf24;
    animation: critical-pulse 0.5s ease-in-out infinite alternate;
}

@keyframes critical-pulse {
    from { text-shadow: 0 0 20px #fbbf24; }
    to { text-shadow: 0 0 40px #fbbf24, 0 0 60px #f59e0b; }
}

.xp-breakdown {
    display: flex;
    flex-direction: column;
    gap: 4px;
    font-size: 14px;
    color: #888;
}

.xp-line {
    display: flex;
    justify-content: space-between;
    gap: 16px;
}

.xp-line.combo { color: #f97316; }
.xp-line.streak { color: #06b6d4; }
.xp-line.critical { color: #fbbf24; font-weight: 600; }
.xp-line.first-try { color: #a78bfa; }
"#;

#[component]
pub fn XpPopup(reward: XpReward, on_dismiss: EventHandler<()>) -> Element {
    use_effect(move || {
        if reward.is_critical {
            play_sound(SoundEffect::CriticalHit);
        } else {
            play_sound(SoundEffect::XpGain);
        }
    });

    use_effect(move || {
        let handler = on_dismiss.clone();
        spawn(async move {
            gloo_timers::future::TimeoutFuture::new(2000).await;
            handler.call(());
        });
    });

    let total_class = if reward.is_critical { "xp-total critical" } else { "xp-total" };

    rsx! {
        style { "{XP_POPUP_STYLE}" }
        div {
            class: "xp-popup",
            onclick: move |_| on_dismiss.call(()),
            div { class: "xp-popup-content",
                div { class: "{total_class}", "+{reward.total} XP" }
                div { class: "xp-breakdown",
                    div { class: "xp-line",
                        span { "Base" }
                        span { "+{reward.base}" }
                    }
                    if reward.combo_bonus > 0 {
                        div { class: "xp-line combo",
                            span { "Combo Bonus" }
                            span { "+{reward.combo_bonus}" }
                        }
                    }
                    if reward.streak_bonus > 0 {
                        div { class: "xp-line streak",
                            span { "Streak Bonus" }
                            span { "+{reward.streak_bonus}" }
                        }
                    }
                    if reward.first_try_bonus > 0 {
                        div { class: "xp-line first-try",
                            span { "First Try" }
                            span { "+{reward.first_try_bonus}" }
                        }
                    }
                    if reward.critical_bonus > 0 {
                        div { class: "xp-line critical",
                            span { "CRITICAL!" }
                            span { "+{reward.critical_bonus}" }
                        }
                    }
                }
            }
        }
    }
}

```

---

## Problem Generator

The Problem Generator transforms LOGOS from a sandbox into an interactive teaching tool with curriculum-based exercises.

**Location:** `src/content.rs`, `src/generator.rs`, `src/grader.rs`, `src/runtime_lexicon.rs`

**Architecture:**
```
┌─────────────────────────────────────────────────────────────────────────────┐
│                         Problem Generator Pipeline                           │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   ┌───────────┐    ┌───────────┐    ┌───────────┐    ┌───────────┐        │
│   │ Curriculum│───▶│ Generator │───▶│ Challenge │───▶│  Grader   │        │
│   │   JSON    │    │  Engine   │    │           │    │           │        │
│   └───────────┘    └─────┬─────┘    └───────────┘    └─────┬─────┘        │
│                          │                                  │              │
│                          ▼                                  ▼              │
│                    ┌───────────┐                      ┌───────────┐        │
│                    │  Runtime  │                      │ Semantic  │        │
│                    │  Lexicon  │                      │ Equality  │        │
│                    └───────────┘                      └───────────┘        │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### Curriculum Structure

Filesystem-based curriculum organization embedded at compile time via `include_dir`.

```
assets/curriculum/
├── 01_trivium/                    # Era I: Naming
│   ├── meta.json                  # Era metadata (id, title, description)
│   ├── 01_atomic/                 # Module: Predication
│   │   ├── meta.json              # Module metadata (pedagogy, order)
│   │   ├── ex_01_adjectives.json  # Exercise: {ProperName} is {Adjective}
│   │   └── ex_02_intransitive.json
│   ├── 02_relations/              # Module: Transitive verbs
│   └── 03_negation/               # Module: Negation
├── 02_quadrivium/                 # Era II: Quantification
│   ├── 01_universal/              # ∀x patterns
│   ├── 02_existential/            # ∃x patterns
│   └── 03_scope/                  # Scope ambiguity
└── 03_metaphysics/                # Era III: Modality & Time
    ├── 01_modality/               # □ and ◇ operators
    └── 02_time/                   # Past and Future operators
```

**Exercise Schema:**
```json
{
  "id": "ex_01",
  "type": "translation",
  "difficulty": 1,
  "prompt": "Translate this observation:",
  "template": "{ProperName} is {Adjective}.",
  "constraints": { "Adjective": ["Intersective"] },
  "hint": "Apply the adjective as a predicate to the constant."
}
```

### Template Slots

| Slot | Example | Constraints |
|------|---------|-------------|
| `{ProperName}` | John, Mary | Proper nouns from lexicon |
| `{Noun}` | dog, cat | Common nouns, filterable by sort |
| `{Noun:Plural}` | dogs, cats | Plural form of common noun |
| `{Verb}` | runs, sleeps | Intransitive verbs |
| `{Verb:Past}` | ran, slept | Past tense form |
| `{Adjective}` | happy, tall | Intersective by default |

### Semantic Grading

The grader performs semantic equivalence checking, not string matching:

1. **Unicode normalization**: `\forall` → `∀`, `->` → `→`, `&` → `∧`
2. **Whitespace removal**: `∀x ( P(x) )` → `∀x(P(x))`
3. **Commutativity**: `P ∧ Q` equals `Q ∧ P`
4. **Structural similarity**: Partial credit for close attempts

**Grading Results:**
| Score | Meaning |
|-------|---------|
| 100 | Correct (semantically equivalent) |
| 35-50 | Partial (close structure) |
| 0 | Incorrect |

### Content Engine

**File:** `src/content.rs`

Loads curriculum from embedded JSON files. Uses include_dir to embed assets/curriculum/ at compile time. Provides ContentEngine for querying eras, modules, and exercises.

```rust
use include_dir::{include_dir, Dir};
use serde::Deserialize;
use std::collections::HashMap;

static CURRICULUM_DIR: Dir = include_dir!("$CARGO_MANIFEST_DIR/assets/curriculum");

#[derive(Debug, Clone, Deserialize)]
pub struct EraMeta {
    pub id: String,
    pub title: String,
    pub description: String,
    pub order: u32,
}

#[derive(Debug, Clone, Deserialize)]
pub struct ModuleMeta {
    pub id: String,
    pub title: String,
    pub pedagogy: String,
    pub order: u32,
}

#[derive(Debug, Clone, Deserialize)]
pub struct ExerciseConfig {
    pub id: String,
    #[serde(rename = "type")]
    pub exercise_type: ExerciseType,
    pub difficulty: u32,
    pub prompt: String,
    #[serde(default)]
    pub template: Option<String>,
    #[serde(default)]
    pub constraints: HashMap<String, Vec<String>>,
    #[serde(default)]
    pub hint: Option<String>,
    #[serde(default)]
    pub explanation: Option<String>,
    #[serde(default)]
    pub options: Option<Vec<String>>,
    #[serde(default)]
    pub correct: Option<usize>,
}

#[derive(Debug, Clone, Deserialize, PartialEq)]
#[serde(rename_all = "snake_case")]
pub enum ExerciseType {
    Translation,
    MultipleChoice,
    Ambiguity,
}

#[derive(Debug, Clone)]
pub struct Module {
    pub meta: ModuleMeta,
    pub exercises: Vec<ExerciseConfig>,
}

#[derive(Debug, Clone)]
pub struct Era {
    pub meta: EraMeta,
    pub modules: Vec<Module>,
}

#[derive(Debug, Clone)]
pub struct Curriculum {
    pub eras: Vec<Era>,
}

pub struct ContentEngine {
    pub curriculum: Curriculum,
}

impl ContentEngine {
    pub fn new() -> Self {
        let curriculum = Self::load_curriculum();
        Self { curriculum }
    }

    fn load_curriculum() -> Curriculum {
        let mut eras = Vec::new();

        for era_entry in CURRICULUM_DIR.dirs() {
            if let Some(era) = Self::load_era(era_entry) {
                eras.push(era);
            }
        }

        eras.sort_by_key(|e| e.meta.order);
        Curriculum { eras }
    }

    fn load_era(era_dir: &Dir) -> Option<Era> {
        // era_dir.path() returns "01_trivium", file paths are "01_trivium/meta.json"
        let era_path = era_dir.path().to_string_lossy();
        let meta_path = format!("{}/meta.json", era_path);
        let meta_file = era_dir.get_file(&meta_path)?;
        let meta_content = meta_file.contents_utf8()?;
        let meta: EraMeta = serde_json::from_str(meta_content).ok()?;

        let mut modules = Vec::new();
        for module_entry in era_dir.dirs() {
            if let Some(module) = Self::load_module(module_entry) {
                modules.push(module);
            }
        }

        modules.sort_by_key(|m| m.meta.order);
        Some(Era { meta, modules })
    }

    fn load_module(module_dir: &Dir) -> Option<Module> {
        // module_dir.path() returns "01_trivium/01_atomic"
        let module_path = module_dir.path().to_string_lossy();
        let meta_path = format!("{}/meta.json", module_path);
        let meta_file = module_dir.get_file(&meta_path)?;
        let meta_content = meta_file.contents_utf8()?;
        let meta: ModuleMeta = serde_json::from_str(meta_content).ok()?;

        let mut exercises = Vec::new();
        for file in module_dir.files() {
            if let Some(name) = file.path().file_name() {
                let name_str = name.to_string_lossy();
                if name_str.starts_with("ex_") && name_str.ends_with(".json") {
                    if let Some(content) = file.contents_utf8() {
                        if let Ok(exercise) = serde_json::from_str::<ExerciseConfig>(content) {
                            exercises.push(exercise);
                        }
                    }
                }
            }
        }

        exercises.sort_by(|a, b| a.id.cmp(&b.id));
        Some(Module { meta, exercises })
    }

    pub fn get_era(&self, era_id: &str) -> Option<&Era> {
        self.curriculum.eras.iter().find(|e| e.meta.id == era_id)
    }

    pub fn get_module(&self, era_id: &str, module_id: &str) -> Option<&Module> {
        self.get_era(era_id)?
            .modules
            .iter()
            .find(|m| m.meta.id == module_id)
    }

    pub fn get_exercise(&self, era_id: &str, module_id: &str, exercise_id: &str) -> Option<&ExerciseConfig> {
        self.get_module(era_id, module_id)?
            .exercises
            .iter()
            .find(|e| e.id == exercise_id)
    }

    pub fn eras(&self) -> &[Era] {
        &self.curriculum.eras
    }

    pub fn era_count(&self) -> usize {
        self.curriculum.eras.len()
    }

    pub fn module_count(&self, era_id: &str) -> usize {
        self.get_era(era_id).map(|e| e.modules.len()).unwrap_or(0)
    }

    pub fn exercise_count(&self, era_id: &str, module_id: &str) -> usize {
        self.get_module(era_id, module_id)
            .map(|m| m.exercises.len())
            .unwrap_or(0)
    }
}

impl Default for ContentEngine {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_dir_contents() {
        // Debug: print what's in the embedded directory
        println!("Files in CURRICULUM_DIR:");
        for f in CURRICULUM_DIR.files() {
            println!("  file: {:?}", f.path());
        }
        println!("Dirs in CURRICULUM_DIR:");
        for d in CURRICULUM_DIR.dirs() {
            println!("  era dir: {:?}", d.path());
            for f in d.files() {
                println!("    era file: {:?}", f.path());
            }
            for module_d in d.dirs() {
                println!("    module dir: {:?}", module_d.path());
                for f in module_d.files() {
                    println!("      module file: {:?}", f.path());
                }
            }
        }
        assert!(!CURRICULUM_DIR.dirs().collect::<Vec<_>>().is_empty(), "Should have embedded directories");
    }

    #[test]
    fn test_curriculum_loads() {
        let engine = ContentEngine::new();
        assert!(engine.era_count() >= 3, "Should have at least 3 eras (got {})", engine.era_count());
    }

    #[test]
    fn test_era_trivium_exists() {
        let engine = ContentEngine::new();
        let trivium = engine.get_era("trivium");
        assert!(trivium.is_some(), "Trivium era should exist");
        assert_eq!(trivium.unwrap().meta.title, "Basics");
    }

    #[test]
    fn test_module_atomic_exists() {
        let engine = ContentEngine::new();
        let atomic = engine.get_module("trivium", "atomic");
        assert!(atomic.is_some(), "Atomic module should exist");
        assert_eq!(atomic.unwrap().meta.title, "The Atomic World");
    }

    #[test]
    fn test_exercises_load() {
        let engine = ContentEngine::new();
        let count = engine.exercise_count("trivium", "atomic");
        assert!(count >= 2, "Atomic module should have at least 2 exercises");
    }

    #[test]
    fn test_exercise_has_template() {
        let engine = ContentEngine::new();
        let ex = engine.get_exercise("trivium", "atomic", "ex_01");
        assert!(ex.is_some(), "Exercise ex_01 should exist");
        assert!(ex.unwrap().template.is_some(), "Exercise should have template");
    }

    #[test]
    fn test_logicaffeine_era_exists() {
        let engine = ContentEngine::new();
        let logicaffeine = engine.get_era("logicaffeine");
        assert!(logicaffeine.is_some(), "Logicaffeine era should exist");
        assert_eq!(logicaffeine.unwrap().meta.title, "Practice");
    }

    #[test]
    fn test_logicaffeine_syllogistic_module() {
        let engine = ContentEngine::new();
        let module = engine.get_module("logicaffeine", "syllogistic");
        assert!(module.is_some(), "Syllogistic module should exist");
        let m = module.unwrap();
        assert_eq!(m.meta.title, "The Syllogism");
        assert!(m.exercises.len() >= 90, "Should have at least 90 exercises (got {})", m.exercises.len());
    }

    #[test]
    fn test_logicaffeine_exercise_has_explanation() {
        let engine = ContentEngine::new();
        let ex = engine.get_exercise("logicaffeine", "syllogistic", "A_1.1");
        assert!(ex.is_some(), "Exercise A_1.1 should exist");
        let exercise = ex.unwrap();
        assert!(exercise.explanation.is_some(), "Exercise should have explanation");
        assert!(exercise.options.is_some(), "Exercise should have options");
        assert_eq!(exercise.exercise_type, ExerciseType::MultipleChoice);
    }
}

```

---

### Generator Engine

**File:** `src/generator.rs`

Template-based problem generation. Fills slots like {ProperName}, {Verb}, {Adjective} using runtime lexicon queries with constraint filtering. Applies morphological transforms for modifiers like :Plural and :Past.

```rust
use crate::content::{ExerciseConfig, ExerciseType};
use crate::runtime_lexicon::{LexiconIndex, pluralize, present_3s, past_tense, gerund};
use crate::compile;
use rand::Rng;
use rand::seq::SliceRandom;
use std::collections::HashMap;

pub struct Generator {
    lexicon: LexiconIndex,
}

#[derive(Debug, Clone)]
pub struct Challenge {
    pub exercise_id: String,
    pub prompt: String,
    pub sentence: String,
    pub answer: AnswerType,
    pub hint: Option<String>,
    pub explanation: Option<String>,
}

#[derive(Debug, Clone)]
pub enum AnswerType {
    FreeForm {
        golden_logic: String,
    },
    MultipleChoice {
        options: Vec<String>,
        correct_index: usize,
    },
    Ambiguity {
        readings: Vec<String>,
    },
}

impl Generator {
    pub fn new() -> Self {
        Self {
            lexicon: LexiconIndex::new(),
        }
    }

    pub fn generate(&self, exercise: &ExerciseConfig, rng: &mut impl Rng) -> Option<Challenge> {
        match exercise.exercise_type {
            ExerciseType::Translation => self.generate_translation(exercise, rng),
            ExerciseType::MultipleChoice => self.generate_multiple_choice(exercise, rng),
            ExerciseType::Ambiguity => self.generate_ambiguity(exercise, rng),
        }
    }

    fn generate_translation(&self, exercise: &ExerciseConfig, rng: &mut impl Rng) -> Option<Challenge> {
        let template = exercise.template.as_ref()?;
        let sentence = self.fill_template(template, &exercise.constraints, rng)?;

        let golden_logic = compile(&sentence).ok()?;

        Some(Challenge {
            exercise_id: exercise.id.clone(),
            prompt: exercise.prompt.clone(),
            sentence,
            answer: AnswerType::FreeForm { golden_logic },
            hint: exercise.hint.clone(),
            explanation: exercise.explanation.clone(),
        })
    }

    fn generate_multiple_choice(&self, exercise: &ExerciseConfig, rng: &mut impl Rng) -> Option<Challenge> {
        let options = exercise.options.clone()?;
        let correct_index = exercise.correct?;

        let sentence = if let Some(template) = &exercise.template {
            self.fill_template(template, &exercise.constraints, rng)?
        } else {
            exercise.prompt.clone()
        };

        Some(Challenge {
            exercise_id: exercise.id.clone(),
            prompt: exercise.prompt.clone(),
            sentence,
            answer: AnswerType::MultipleChoice { options, correct_index },
            hint: exercise.hint.clone(),
            explanation: exercise.explanation.clone(),
        })
    }

    fn generate_ambiguity(&self, exercise: &ExerciseConfig, rng: &mut impl Rng) -> Option<Challenge> {
        let template = exercise.template.as_ref()?;
        let sentence = self.fill_template(template, &exercise.constraints, rng)?;

        let readings = crate::compile_all_scopes(&sentence).ok()?;

        Some(Challenge {
            exercise_id: exercise.id.clone(),
            prompt: exercise.prompt.clone(),
            sentence,
            answer: AnswerType::Ambiguity { readings },
            hint: exercise.hint.clone(),
            explanation: exercise.explanation.clone(),
        })
    }

    fn fill_template(&self, template: &str, constraints: &HashMap<String, Vec<String>>, rng: &mut impl Rng) -> Option<String> {
        let mut result = template.to_string();
        let mut used_names: HashMap<String, String> = HashMap::new();

        while let Some(start) = result.find('{') {
            let end = result[start..].find('}')? + start;
            let slot = &result[start + 1..end];

            let (slot_type, modifier) = if let Some(colon_pos) = slot.find(':') {
                (&slot[..colon_pos], Some(&slot[colon_pos + 1..]))
            } else {
                (slot, None)
            };

            let slot_constraints = constraints.get(slot_type).map(|v| v.as_slice()).unwrap_or(&[]);
            let word = self.fill_slot(slot_type, slot_constraints, modifier, &mut used_names, rng)?;

            result = format!("{}{}{}", &result[..start], word, &result[end + 1..]);
        }

        Some(result)
    }

    fn fill_slot(
        &self,
        slot_type: &str,
        constraints: &[String],
        modifier: Option<&str>,
        used_names: &mut HashMap<String, String>,
        rng: &mut impl Rng,
    ) -> Option<String> {
        match slot_type {
            "ProperName" => {
                let key = format!("ProperName_{}", used_names.len());
                if let Some(existing) = used_names.get(&key) {
                    return Some(existing.clone());
                }

                let proper_nouns = self.lexicon.proper_nouns();
                let available: Vec<_> = proper_nouns
                    .iter()
                    .filter(|n| !used_names.values().any(|v| v == &n.lemma))
                    .copied()
                    .collect();

                let entry = if !available.is_empty() {
                    available.choose(rng)?
                } else {
                    proper_nouns.choose(rng)?
                };
                let name = entry.lemma.clone();
                used_names.insert(key, name.clone());
                Some(name)
            }
            "Noun" => {
                let nouns = if constraints.is_empty() {
                    self.lexicon.common_nouns()
                } else {
                    let mut filtered = Vec::new();
                    for constraint in constraints {
                        filtered.extend(self.lexicon.nouns_with_feature(constraint));
                    }
                    filtered
                };

                let entry = nouns.choose(rng)?;
                let word = entry.lemma.to_lowercase();

                match modifier {
                    Some("Plural") => Some(pluralize(entry)),
                    _ => Some(word),
                }
            }
            "Verb" => {
                let verbs = if constraints.contains(&"Intransitive".to_string()) {
                    self.lexicon.intransitive_verbs()
                } else if constraints.contains(&"Transitive".to_string()) {
                    self.lexicon.transitive_verbs()
                } else {
                    let mut result = Vec::new();
                    for constraint in constraints {
                        result.extend(self.lexicon.verbs_with_feature(constraint));
                    }
                    if result.is_empty() {
                        self.lexicon.intransitive_verbs()
                    } else {
                        result
                    }
                };

                let entry = verbs.choose(rng)?;

                match modifier {
                    Some("Past") => Some(past_tense(entry)),
                    Some("Gerund") => Some(gerund(entry)),
                    Some("Present3s") => Some(present_3s(entry)),
                    _ => Some(entry.lemma.to_lowercase()),
                }
            }
            "Adjective" => {
                let adjectives = if constraints.contains(&"Intersective".to_string()) {
                    self.lexicon.intersective_adjectives()
                } else if constraints.is_empty() {
                    self.lexicon.intersective_adjectives()
                } else {
                    let mut result = Vec::new();
                    for constraint in constraints {
                        result.extend(self.lexicon.adjectives_with_feature(constraint));
                    }
                    result
                };

                let entry = adjectives.choose(rng)?;
                Some(entry.lemma.to_lowercase())
            }
            _ => Some("thing".to_string()),
        }
    }
}

impl Default for Generator {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::content::ContentEngine;
    use rand::SeedableRng;
    use rand::rngs::StdRng;

    #[test]
    fn test_generate_translation_challenge() {
        let engine = ContentEngine::new();
        let generator = Generator::new();
        let mut rng = StdRng::seed_from_u64(42);

        let exercise = engine.get_exercise("trivium", "atomic", "ex_01").unwrap();
        let challenge = generator.generate(exercise, &mut rng);

        assert!(challenge.is_some(), "Should generate a challenge");
        let challenge = challenge.unwrap();
        assert!(!challenge.sentence.is_empty(), "Sentence should not be empty");

        if let AnswerType::FreeForm { golden_logic } = &challenge.answer {
            assert!(!golden_logic.is_empty(), "Golden logic should not be empty");
        } else {
            panic!("Expected FreeForm answer type");
        }
    }

    #[test]
    fn test_generate_multiple_choice() {
        let engine = ContentEngine::new();
        let generator = Generator::new();
        let mut rng = StdRng::seed_from_u64(42);

        let exercise = engine.get_exercise("trivium", "atomic", "ex_03").unwrap();
        let challenge = generator.generate(exercise, &mut rng);

        assert!(challenge.is_some(), "Should generate a challenge");
        let challenge = challenge.unwrap();

        if let AnswerType::MultipleChoice { options, correct_index } = &challenge.answer {
            assert_eq!(options.len(), 4, "Should have 4 options");
            assert_eq!(*correct_index, 0, "Correct answer should be first option");
        } else {
            panic!("Expected MultipleChoice answer type");
        }
    }

    #[test]
    fn test_fill_template_proper_names() {
        let generator = Generator::new();
        let mut rng = StdRng::seed_from_u64(42);

        let constraints = HashMap::new();
        let result = generator.fill_template("{ProperName} runs.", &constraints, &mut rng);

        assert!(result.is_some());
        let sentence = result.unwrap();
        assert!(sentence.ends_with(" runs."), "Template should be filled: {}", sentence);
        assert!(!sentence.starts_with("{"), "Slot should be replaced");
    }

    #[test]
    fn test_fill_template_with_modifier() {
        let generator = Generator::new();
        let mut rng = StdRng::seed_from_u64(42);

        let constraints = HashMap::new();
        let result = generator.fill_template("All {Noun:Plural} run.", &constraints, &mut rng);

        assert!(result.is_some());
        let sentence = result.unwrap();
        assert!(!sentence.contains("{"), "All slots should be filled: {}", sentence);
    }

    #[test]
    fn test_deterministic_with_seed() {
        let generator = Generator::new();
        let mut rng1 = StdRng::seed_from_u64(12345);
        let mut rng2 = StdRng::seed_from_u64(12345);

        let constraints = HashMap::new();
        let result1 = generator.fill_template("{ProperName} is {Adjective}.", &constraints, &mut rng1);
        let result2 = generator.fill_template("{ProperName} is {Adjective}.", &constraints, &mut rng2);

        assert_eq!(result1, result2, "Same seed should produce same output");
    }
}

```

---

### Answer Grader

**File:** `src/grader.rs`

Semantic equivalence checking for FOL answers. Normalizes Unicode, handles commutativity of ∧/∨, and provides partial credit scoring. Uses structural AST comparison after normalization.

```rust

#[derive(Debug, Clone)]
pub struct GradeResult {
    pub correct: bool,
    pub partial: bool,
    pub score: u32,
    pub feedback: String,
}

impl GradeResult {
    pub fn correct() -> Self {
        Self {
            correct: true,
            partial: false,
            score: 100,
            feedback: "Correct!".to_string(),
        }
    }

    pub fn partial(feedback: String, score: u32) -> Self {
        Self {
            correct: false,
            partial: true,
            score,
            feedback,
        }
    }

    pub fn incorrect(feedback: String) -> Self {
        Self {
            correct: false,
            partial: false,
            score: 0,
            feedback,
        }
    }
}

pub fn check_answer(user_input: &str, expected: &str) -> GradeResult {
    let user_normalized = normalize_logic(user_input);
    let expected_normalized = normalize_logic(expected);

    if user_normalized == expected_normalized {
        return GradeResult::correct();
    }

    let user_parsed = parse_to_normalized_ast(user_input);
    let expected_parsed = parse_to_normalized_ast(expected);

    match (user_parsed, expected_parsed) {
        (Some(user_ast), Some(expected_ast)) => {
            if structural_eq(&user_ast, &expected_ast) {
                return GradeResult::correct();
            }

            let similarity = structural_similarity(&user_ast, &expected_ast);
            if similarity > 0.7 {
                GradeResult::partial(
                    "Close! Check your quantifier or connective structure.".to_string(),
                    (similarity * 50.0) as u32,
                )
            } else if similarity > 0.4 {
                GradeResult::partial(
                    "Partially correct. Review the logical structure.".to_string(),
                    (similarity * 30.0) as u32,
                )
            } else {
                GradeResult::incorrect(
                    "Not quite. Consider the relationship between subject and predicate.".to_string(),
                )
            }
        }
        (None, _) => GradeResult::incorrect(
            "Could not parse your answer. Check syntax.".to_string(),
        ),
        (_, None) => GradeResult::incorrect(
            "Internal error: could not parse expected answer.".to_string(),
        ),
    }
}

fn normalize_logic(input: &str) -> String {
    let mut result = input.to_string();

    result = result.replace("\\forall", "∀");
    result = result.replace("\\exists", "∃");
    result = result.replace("\\neg", "¬");
    result = result.replace("\\land", "∧");
    result = result.replace("\\lor", "∨");
    result = result.replace("\\supset", "→");
    result = result.replace("\\equiv", "↔");
    result = result.replace("\\Box", "□");
    result = result.replace("\\Diamond", "◇");

    // Order matters: replace <-> before ->
    result = result.replace("<->", "↔");
    result = result.replace("->", "→");
    result = result.replace("&", "∧");
    result = result.replace("|", "∨");
    result = result.replace("~", "¬");
    result = result.replace("!", "¬");

    result = result.chars().filter(|c| !c.is_whitespace()).collect();

    result
}

#[derive(Debug, Clone)]
struct NormalizedExpr {
    kind: NormalizedKind,
}

#[derive(Debug, Clone)]
enum NormalizedKind {
    Predicate { name: String, arity: usize },
    Quantifier { kind: String, body: Box<NormalizedExpr> },
    Binary { op: String, left: Box<NormalizedExpr>, right: Box<NormalizedExpr> },
    Unary { op: String, operand: Box<NormalizedExpr> },
    Atom(String),
}

fn parse_to_normalized_ast(input: &str) -> Option<NormalizedExpr> {
    let normalized = normalize_logic(input);

    if normalized.starts_with('∀') || normalized.starts_with('∃') {
        let quantifier = if normalized.starts_with('∀') { "∀" } else { "∃" };
        let rest = &normalized[quantifier.len()..];

        if let Some(paren_start) = rest.find('(') {
            let body = &rest[paren_start..];
            if let Some(inner) = extract_balanced(body) {
                return Some(NormalizedExpr {
                    kind: NormalizedKind::Quantifier {
                        kind: quantifier.to_string(),
                        body: Box::new(parse_to_normalized_ast(&inner)?),
                    },
                });
            }
        }
    }

    if let Some(impl_pos) = find_main_connective(&normalized, "→") {
        let left = &normalized[..impl_pos];
        let right = &normalized[impl_pos + "→".len()..];
        return Some(NormalizedExpr {
            kind: NormalizedKind::Binary {
                op: "→".to_string(),
                left: Box::new(parse_to_normalized_ast(left)?),
                right: Box::new(parse_to_normalized_ast(right)?),
            },
        });
    }

    if let Some(and_pos) = find_main_connective(&normalized, "∧") {
        let left = &normalized[..and_pos];
        let right = &normalized[and_pos + "∧".len()..];
        return Some(NormalizedExpr {
            kind: NormalizedKind::Binary {
                op: "∧".to_string(),
                left: Box::new(parse_to_normalized_ast(left)?),
                right: Box::new(parse_to_normalized_ast(right)?),
            },
        });
    }

    if normalized.starts_with('¬') {
        let operand = &normalized["¬".len()..];
        return Some(NormalizedExpr {
            kind: NormalizedKind::Unary {
                op: "¬".to_string(),
                operand: Box::new(parse_to_normalized_ast(operand)?),
            },
        });
    }

    if let Some(paren_pos) = normalized.find('(') {
        let name = &normalized[..paren_pos];
        let args = &normalized[paren_pos..];
        let arity = args.matches(',').count() + 1;
        return Some(NormalizedExpr {
            kind: NormalizedKind::Predicate {
                name: name.to_string(),
                arity,
            },
        });
    }

    Some(NormalizedExpr {
        kind: NormalizedKind::Atom(normalized),
    })
}

fn extract_balanced(s: &str) -> Option<String> {
    if !s.starts_with('(') {
        return None;
    }

    let mut depth = 0;
    let mut end = 0;

    for (i, c) in s.chars().enumerate() {
        match c {
            '(' => depth += 1,
            ')' => {
                depth -= 1;
                if depth == 0 {
                    end = i;
                    break;
                }
            }
            _ => {}
        }
    }

    if depth == 0 && end > 0 {
        Some(s[1..end].to_string())
    } else {
        None
    }
}

fn find_main_connective(s: &str, connective: &str) -> Option<usize> {
    let mut depth = 0;
    let mut byte_idx = 0;

    for c in s.chars() {
        match c {
            '(' => depth += 1,
            ')' => depth -= 1,
            _ if depth == 0 && s[byte_idx..].starts_with(connective) => {
                return Some(byte_idx);
            }
            _ => {}
        }
        byte_idx += c.len_utf8();
    }

    None
}

fn structural_eq(a: &NormalizedExpr, b: &NormalizedExpr) -> bool {
    match (&a.kind, &b.kind) {
        (NormalizedKind::Predicate { name: n1, arity: a1 }, NormalizedKind::Predicate { name: n2, arity: a2 }) => {
            n1 == n2 && a1 == a2
        }
        (NormalizedKind::Quantifier { kind: k1, body: b1 }, NormalizedKind::Quantifier { kind: k2, body: b2 }) => {
            k1 == k2 && structural_eq(b1, b2)
        }
        (NormalizedKind::Binary { op: o1, left: l1, right: r1 }, NormalizedKind::Binary { op: o2, left: l2, right: r2 }) => {
            if o1 != o2 {
                return false;
            }
            if structural_eq(l1, l2) && structural_eq(r1, r2) {
                return true;
            }
            if o1 == "∧" || o1 == "∨" {
                structural_eq(l1, r2) && structural_eq(r1, l2)
            } else {
                false
            }
        }
        (NormalizedKind::Unary { op: o1, operand: op1 }, NormalizedKind::Unary { op: o2, operand: op2 }) => {
            o1 == o2 && structural_eq(op1, op2)
        }
        (NormalizedKind::Atom(a1), NormalizedKind::Atom(a2)) => a1 == a2,
        _ => false,
    }
}

fn structural_similarity(a: &NormalizedExpr, b: &NormalizedExpr) -> f64 {
    match (&a.kind, &b.kind) {
        (NormalizedKind::Predicate { name: n1, arity: a1 }, NormalizedKind::Predicate { name: n2, arity: a2 }) => {
            let name_match = if n1 == n2 { 0.7 } else { 0.0 };
            let arity_match = if a1 == a2 { 0.3 } else { 0.0 };
            name_match + arity_match
        }
        (NormalizedKind::Quantifier { kind: k1, body: b1 }, NormalizedKind::Quantifier { kind: k2, body: b2 }) => {
            let kind_match = if k1 == k2 { 0.4 } else { 0.0 };
            let body_sim = structural_similarity(b1, b2);
            kind_match + body_sim * 0.6
        }
        (NormalizedKind::Binary { op: o1, left: l1, right: r1 }, NormalizedKind::Binary { op: o2, left: l2, right: r2 }) => {
            let op_match = if o1 == o2 { 0.3 } else { 0.0 };
            let left_sim = structural_similarity(l1, l2);
            let right_sim = structural_similarity(r1, r2);
            op_match + (left_sim + right_sim) * 0.35
        }
        (NormalizedKind::Unary { op: o1, operand: op1 }, NormalizedKind::Unary { op: o2, operand: op2 }) => {
            let op_match = if o1 == o2 { 0.3 } else { 0.0 };
            op_match + structural_similarity(op1, op2) * 0.7
        }
        (NormalizedKind::Atom(a1), NormalizedKind::Atom(a2)) => {
            if a1 == a2 { 1.0 } else { 0.0 }
        }
        _ => 0.0,
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_exact_match() {
        let result = check_answer("∀x(D(x) → B(x))", "∀x(D(x) → B(x))");
        assert!(result.correct, "Exact match should be correct");
    }

    #[test]
    fn test_whitespace_normalization() {
        let result = check_answer("∀x( D(x) → B(x) )", "∀x(D(x)→B(x))");
        assert!(result.correct, "Whitespace should be normalized");
    }

    #[test]
    fn test_latex_to_unicode() {
        let result = check_answer("\\forall x(D(x) \\supset B(x))", "∀x(D(x) → B(x))");
        assert!(result.correct, "LaTeX should normalize to Unicode");
    }

    #[test]
    fn test_ascii_shortcuts() {
        let result = check_answer("D(x) & B(x)", "D(x) ∧ B(x)");
        assert!(result.correct, "ASCII & should match ∧");
    }

    #[test]
    fn test_commutative_conjunction() {
        let result = check_answer("∃x(B(x) ∧ D(x))", "∃x(D(x) ∧ B(x))");
        assert!(result.correct, "Conjunction should be commutative");
    }

    #[test]
    fn test_wrong_quantifier() {
        let result = check_answer("∃x(D(x) → B(x))", "∀x(D(x) → B(x))");
        assert!(!result.correct, "Wrong quantifier should not match");
        assert!(result.partial, "Should get partial credit");
    }

    #[test]
    fn test_wrong_connective() {
        let result = check_answer("∀x(D(x) ∧ B(x))", "∀x(D(x) → B(x))");
        assert!(!result.correct, "Wrong connective should not match");
        assert!(result.partial, "Should get partial credit for structure");
    }

    #[test]
    fn test_completely_wrong() {
        let result = check_answer("P(a)", "∀x(D(x) → B(x))");
        assert!(!result.correct);
        assert!(!result.partial);
    }

    #[test]
    fn test_normalize_arrow() {
        let normalized = normalize_logic("A -> B");
        assert_eq!(normalized, "A→B");
    }

    #[test]
    fn test_normalize_biconditional() {
        let normalized = normalize_logic("A <-> B");
        assert_eq!(normalized, "A↔B");
    }
}

```

---

### Runtime Lexicon

**File:** `src/runtime_lexicon.rs`

Runtime access to lexicon data for the generator. Provides query APIs: nouns_with_feature(), verbs_with_feature(), nouns_with_sort(), proper_nouns(), common_nouns(). Loads from embedded lexicon.json.

```rust
use rand::seq::SliceRandom;
use serde::Deserialize;
use std::collections::HashMap;

const LEXICON_JSON: &str = include_str!("../assets/lexicon.json");

#[derive(Deserialize, Debug)]
pub struct LexiconData {
    pub nouns: Vec<NounEntry>,
    pub verbs: Vec<VerbEntry>,
    pub adjectives: Vec<AdjectiveEntry>,
}

#[derive(Deserialize, Debug, Clone)]
pub struct NounEntry {
    pub lemma: String,
    #[serde(default)]
    pub forms: HashMap<String, String>,
    #[serde(default)]
    pub features: Vec<String>,
    #[serde(default)]
    pub sort: Option<String>,
}

#[derive(Deserialize, Debug, Clone)]
pub struct VerbEntry {
    pub lemma: String,
    pub class: String,
    #[serde(default)]
    pub forms: HashMap<String, String>,
    #[serde(default)]
    pub features: Vec<String>,
}

#[derive(Deserialize, Debug, Clone)]
pub struct AdjectiveEntry {
    pub lemma: String,
    #[serde(default)]
    pub regular: bool,
    #[serde(default)]
    pub features: Vec<String>,
}

pub struct LexiconIndex {
    data: LexiconData,
}

impl LexiconIndex {
    pub fn new() -> Self {
        let data: LexiconData = serde_json::from_str(LEXICON_JSON)
            .expect("Failed to parse lexicon.json");
        Self { data }
    }

    pub fn proper_nouns(&self) -> Vec<&NounEntry> {
        self.data.nouns.iter()
            .filter(|n| n.features.iter().any(|f| f == "Proper"))
            .collect()
    }

    pub fn common_nouns(&self) -> Vec<&NounEntry> {
        self.data.nouns.iter()
            .filter(|n| !n.features.iter().any(|f| f == "Proper"))
            .collect()
    }

    pub fn nouns_with_feature(&self, feature: &str) -> Vec<&NounEntry> {
        self.data.nouns.iter()
            .filter(|n| n.features.iter().any(|f| f.eq_ignore_ascii_case(feature)))
            .collect()
    }

    pub fn nouns_with_sort(&self, sort: &str) -> Vec<&NounEntry> {
        self.data.nouns.iter()
            .filter(|n| n.sort.as_ref().map(|s| s.eq_ignore_ascii_case(sort)).unwrap_or(false))
            .collect()
    }

    pub fn verbs_with_feature(&self, feature: &str) -> Vec<&VerbEntry> {
        self.data.verbs.iter()
            .filter(|v| v.features.iter().any(|f| f.eq_ignore_ascii_case(feature)))
            .collect()
    }

    pub fn verbs_with_class(&self, class: &str) -> Vec<&VerbEntry> {
        self.data.verbs.iter()
            .filter(|v| v.class.eq_ignore_ascii_case(class))
            .collect()
    }

    pub fn intransitive_verbs(&self) -> Vec<&VerbEntry> {
        self.data.verbs.iter()
            .filter(|v| {
                !v.features.iter().any(|f|
                    f.eq_ignore_ascii_case("Transitive") ||
                    f.eq_ignore_ascii_case("Ditransitive")
                )
            })
            .collect()
    }

    pub fn transitive_verbs(&self) -> Vec<&VerbEntry> {
        self.data.verbs.iter()
            .filter(|v| {
                v.features.iter().any(|f| f.eq_ignore_ascii_case("Transitive")) ||
                v.features.iter().any(|f| f.eq_ignore_ascii_case("Ditransitive"))
            })
            .collect()
    }

    pub fn adjectives_with_feature(&self, feature: &str) -> Vec<&AdjectiveEntry> {
        self.data.adjectives.iter()
            .filter(|a| a.features.iter().any(|f| f.eq_ignore_ascii_case(feature)))
            .collect()
    }

    pub fn intersective_adjectives(&self) -> Vec<&AdjectiveEntry> {
        self.adjectives_with_feature("Intersective")
    }

    pub fn random_proper_noun(&self, rng: &mut impl rand::Rng) -> Option<&NounEntry> {
        self.proper_nouns().choose(rng).copied()
    }

    pub fn random_common_noun(&self, rng: &mut impl rand::Rng) -> Option<&NounEntry> {
        self.common_nouns().choose(rng).copied()
    }

    pub fn random_verb(&self, rng: &mut impl rand::Rng) -> Option<&VerbEntry> {
        self.data.verbs.choose(rng)
    }

    pub fn random_intransitive_verb(&self, rng: &mut impl rand::Rng) -> Option<&VerbEntry> {
        self.intransitive_verbs().choose(rng).copied()
    }

    pub fn random_transitive_verb(&self, rng: &mut impl rand::Rng) -> Option<&VerbEntry> {
        self.transitive_verbs().choose(rng).copied()
    }

    pub fn random_adjective(&self, rng: &mut impl rand::Rng) -> Option<&AdjectiveEntry> {
        self.data.adjectives.choose(rng)
    }

    pub fn random_intersective_adjective(&self, rng: &mut impl rand::Rng) -> Option<&AdjectiveEntry> {
        self.intersective_adjectives().choose(rng).copied()
    }
}

pub fn pluralize(noun: &NounEntry) -> String {
    if let Some(plural) = noun.forms.get("plural") {
        plural.clone()
    } else {
        let lemma = noun.lemma.to_lowercase();
        if lemma.ends_with('s') || lemma.ends_with('x') ||
           lemma.ends_with("ch") || lemma.ends_with("sh") {
            format!("{}es", lemma)
        } else if lemma.ends_with('y') && !lemma.ends_with("ay") &&
                  !lemma.ends_with("ey") && !lemma.ends_with("oy") && !lemma.ends_with("uy") {
            format!("{}ies", &lemma[..lemma.len()-1])
        } else {
            format!("{}s", lemma)
        }
    }
}

pub fn present_3s(verb: &VerbEntry) -> String {
    if let Some(form) = verb.forms.get("present3s") {
        form.clone()
    } else {
        let lemma = verb.lemma.to_lowercase();
        if lemma.ends_with('s') || lemma.ends_with('x') ||
           lemma.ends_with("ch") || lemma.ends_with("sh") || lemma.ends_with('o') {
            format!("{}es", lemma)
        } else if lemma.ends_with('y') && !lemma.ends_with("ay") &&
                  !lemma.ends_with("ey") && !lemma.ends_with("oy") && !lemma.ends_with("uy") {
            format!("{}ies", &lemma[..lemma.len()-1])
        } else {
            format!("{}s", lemma)
        }
    }
}

pub fn past_tense(verb: &VerbEntry) -> String {
    if let Some(form) = verb.forms.get("past") {
        form.clone()
    } else {
        let lemma = verb.lemma.to_lowercase();
        if lemma.ends_with('e') {
            format!("{}d", lemma)
        } else if lemma.ends_with('y') && !lemma.ends_with("ay") &&
                  !lemma.ends_with("ey") && !lemma.ends_with("oy") && !lemma.ends_with("uy") {
            format!("{}ied", &lemma[..lemma.len()-1])
        } else {
            format!("{}ed", lemma)
        }
    }
}

pub fn gerund(verb: &VerbEntry) -> String {
    if let Some(form) = verb.forms.get("gerund") {
        form.clone()
    } else {
        let lemma = verb.lemma.to_lowercase();
        if lemma.ends_with('e') && !lemma.ends_with("ee") {
            format!("{}ing", &lemma[..lemma.len()-1])
        } else {
            format!("{}ing", lemma)
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_lexicon_loads() {
        let index = LexiconIndex::new();
        assert!(!index.proper_nouns().is_empty());
        assert!(!index.common_nouns().is_empty());
        assert!(!index.intersective_adjectives().is_empty());
    }

    #[test]
    fn test_proper_nouns() {
        let index = LexiconIndex::new();
        let proper = index.proper_nouns();
        assert!(proper.iter().any(|n| n.lemma == "John"));
        assert!(proper.iter().any(|n| n.lemma == "Mary"));
    }

    #[test]
    fn test_intersective_adjectives() {
        let index = LexiconIndex::new();
        let adj = index.intersective_adjectives();
        assert!(adj.iter().any(|a| a.lemma == "Happy"));
        assert!(adj.iter().any(|a| a.lemma == "Red"));
    }

    #[test]
    fn test_pluralize() {
        let noun = NounEntry {
            lemma: "Dog".to_string(),
            forms: HashMap::new(),
            features: vec![],
            sort: None,
        };
        assert_eq!(pluralize(&noun), "dogs");

        let noun_irregular = NounEntry {
            lemma: "Man".to_string(),
            forms: [("plural".to_string(), "men".to_string())].into(),
            features: vec![],
            sort: None,
        };
        assert_eq!(pluralize(&noun_irregular), "men");
    }

    #[test]
    fn test_present_3s() {
        let verb = VerbEntry {
            lemma: "Run".to_string(),
            class: "Activity".to_string(),
            forms: HashMap::new(),
            features: vec![],
        };
        assert_eq!(present_3s(&verb), "runs");
    }
}

```

---

## Logos Core Runtime

Embedded runtime library for compiled LOGOS programs. Provides type aliases and IO functions per the Spec.

**Location:** `logos_core/src/`

### Runtime Library

**File:** `logos_core/src/lib.rs`

Entry point for logos_core crate. Re-exports io, types, and prelude modules. Embedded into compiled programs via include_str! in src/compile.rs.

```rust
//! LOGOS Runtime Library

pub mod io;
pub mod types;

pub fn panic_with(reason: &str) -> ! {
    panic!("{}", reason);
}

pub mod fmt {
    pub fn format<T: std::fmt::Display>(x: T) -> String {
        format!("{}", x)
    }
}

pub mod prelude {
    pub use crate::io::{show, read_line, println, eprintln, print, Showable};
    pub use crate::types::{Nat, Int, Real, Text, Bool, Unit, Seq};
    pub use crate::panic_with;
    pub use crate::fmt::format;
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_format() {
        assert_eq!(fmt::format(42), "42");
        assert_eq!(fmt::format("hello"), "hello");
    }

    #[test]
    fn test_type_aliases() {
        let _n: types::Nat = 42;
        let _i: types::Int = -42;
        let _r: types::Real = 3.14;
        let _t: types::Text = String::from("hello");
        let _b: types::Bool = true;
        let _u: types::Unit = ();
    }
}

```

---

### Type Aliases

**File:** `logos_core/src/types.rs`

Rust type aliases per Spec §10.6.1: Nat→u64, Int→i64, Real→f64, Text→String, Bool→bool, Unit→().

```rust
//! Core Type Definitions (Spec 3.2)

pub type Nat = u64;
pub type Int = i64;
pub type Real = f64;
pub type Text = String;
pub type Bool = bool;
pub type Unit = ();

// Phase 30: Collections
pub type Seq<T> = Vec<T>;

```

---

### IO Functions

**File:** `logos_core/src/io.rs`

Standard IO per Spec §10.5: show() for display, read_line() for input, println/eprintln/print for output.

```rust
//! IO Operations (Spec 10.5)

use std::fmt::{self, Display};

/// Custom trait for LOGOS Show verb - provides clean, natural output.
/// Primitives display without quotes, collections display with brackets.
pub trait Showable {
    fn format_show(&self, f: &mut fmt::Formatter) -> fmt::Result;
}

// Primitives: use Display formatting
impl Showable for i64 {
    fn format_show(&self, f: &mut fmt::Formatter) -> fmt::Result {
        Display::fmt(self, f)
    }
}

impl Showable for u64 {
    fn format_show(&self, f: &mut fmt::Formatter) -> fmt::Result {
        Display::fmt(self, f)
    }
}

impl Showable for f64 {
    fn format_show(&self, f: &mut fmt::Formatter) -> fmt::Result {
        Display::fmt(self, f)
    }
}

impl Showable for bool {
    fn format_show(&self, f: &mut fmt::Formatter) -> fmt::Result {
        Display::fmt(self, f)
    }
}

impl Showable for String {
    fn format_show(&self, f: &mut fmt::Formatter) -> fmt::Result {
        Display::fmt(self, f)
    }
}

impl Showable for &str {
    fn format_show(&self, f: &mut fmt::Formatter) -> fmt::Result {
        Display::fmt(self, f)
    }
}

// Sequences: bracket notation with recursive formatting
impl<T: Showable> Showable for Vec<T> {
    fn format_show(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "[")?;
        for (i, item) in self.iter().enumerate() {
            if i > 0 {
                write!(f, ", ")?;
            }
            item.format_show(f)?;
        }
        write!(f, "]")
    }
}

/// The Show verb - prints value with natural formatting
pub fn show<T: Showable>(value: T) {
    struct Wrapper<'a, T>(&'a T);
    impl<T: Showable> Display for Wrapper<'_, T> {
        fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
            self.0.format_show(f)
        }
    }
    println!("{}", Wrapper(&value));
}

pub fn read_line() -> String {
    let mut buffer = String::new();
    std::io::stdin().read_line(&mut buffer).unwrap_or(0);
    buffer.trim().to_string()
}

pub fn print<T: Display>(x: T) {
    print!("{}", x);
}

pub fn eprintln<T: Display>(x: T) {
    eprintln!("{}", x);
}

pub fn println<T: Display>(x: T) {
    println!("{}", x);
}

```

---

## Additional Modules

Any additional source files not explicitly categorized above.

### Module: achievements

**File:** `src/achievements.rs`

Additional source module.

```rust
use crate::progress::UserProgress;

#[derive(Debug, Clone, PartialEq, Eq)]
pub struct Achievement {
    pub id: &'static str,
    pub title: &'static str,
    pub description: &'static str,
    pub xp_reward: u64,
    pub unlocks_title: Option<&'static str>,
    pub grants_freeze: bool,
}

pub const ACHIEVEMENTS: &[Achievement] = &[
    Achievement {
        id: "first_blood",
        title: "First Blood",
        description: "Answer your first question correctly",
        xp_reward: 50,
        unlocks_title: None,
        grants_freeze: false,
    },
    Achievement {
        id: "combo_5",
        title: "On Fire",
        description: "Get a 5-answer combo",
        xp_reward: 100,
        unlocks_title: None,
        grants_freeze: false,
    },
    Achievement {
        id: "combo_10",
        title: "Unstoppable",
        description: "Get a 10-answer combo",
        xp_reward: 250,
        unlocks_title: Some("Logic Machine"),
        grants_freeze: false,
    },
    Achievement {
        id: "combo_25",
        title: "Terminator",
        description: "Get a 25-answer combo",
        xp_reward: 500,
        unlocks_title: Some("Automaton"),
        grants_freeze: false,
    },
    Achievement {
        id: "streak_3",
        title: "Getting Started",
        description: "Maintain a 3-day streak",
        xp_reward: 75,
        unlocks_title: None,
        grants_freeze: false,
    },
    Achievement {
        id: "streak_7",
        title: "Week Warrior",
        description: "Maintain a 7-day streak",
        xp_reward: 200,
        unlocks_title: Some("Dedicated"),
        grants_freeze: true,
    },
    Achievement {
        id: "streak_14",
        title: "Fortnight Fighter",
        description: "Maintain a 14-day streak",
        xp_reward: 400,
        unlocks_title: None,
        grants_freeze: true,
    },
    Achievement {
        id: "streak_30",
        title: "Monthly Master",
        description: "Maintain a 30-day streak",
        xp_reward: 1000,
        unlocks_title: Some("Logician"),
        grants_freeze: true,
    },
    Achievement {
        id: "perfect_module",
        title: "Flawless",
        description: "Complete a module with no mistakes",
        xp_reward: 300,
        unlocks_title: None,
        grants_freeze: false,
    },
    Achievement {
        id: "century",
        title: "Century",
        description: "Answer 100 questions correctly",
        xp_reward: 500,
        unlocks_title: Some("Scholar"),
        grants_freeze: false,
    },
    Achievement {
        id: "millennium",
        title: "Millennium",
        description: "Answer 1000 questions correctly",
        xp_reward: 2000,
        unlocks_title: Some("Sage"),
        grants_freeze: false,
    },
    Achievement {
        id: "level_10",
        title: "Double Digits",
        description: "Reach level 10",
        xp_reward: 300,
        unlocks_title: None,
        grants_freeze: false,
    },
    Achievement {
        id: "level_25",
        title: "Quarter Century",
        description: "Reach level 25",
        xp_reward: 750,
        unlocks_title: Some("Adept"),
        grants_freeze: false,
    },
    Achievement {
        id: "level_50",
        title: "Half Century",
        description: "Reach level 50",
        xp_reward: 1500,
        unlocks_title: Some("Grandmaster"),
        grants_freeze: false,
    },
];

pub fn get_achievement(id: &str) -> Option<&'static Achievement> {
    ACHIEVEMENTS.iter().find(|a| a.id == id)
}

pub fn check_achievements(progress: &UserProgress) -> Vec<&'static Achievement> {
    let mut newly_unlocked = Vec::new();

    for achievement in ACHIEVEMENTS {
        if progress.achievements.contains(achievement.id) {
            continue;
        }

        let earned = match achievement.id {
            "first_blood" => total_correct(progress) >= 1,
            "combo_5" => progress.best_combo >= 5,
            "combo_10" => progress.best_combo >= 10,
            "combo_25" => progress.best_combo >= 25,
            "streak_3" => progress.streak_days >= 3,
            "streak_7" => progress.streak_days >= 7,
            "streak_14" => progress.streak_days >= 14,
            "streak_30" => progress.streak_days >= 30,
            "century" => total_correct(progress) >= 100,
            "millennium" => total_correct(progress) >= 1000,
            "level_10" => progress.level >= 10,
            "level_25" => progress.level >= 25,
            "level_50" => progress.level >= 50,
            "perfect_module" => false, // Checked separately in lesson completion
            _ => false,
        };

        if earned {
            newly_unlocked.push(achievement);
        }
    }

    newly_unlocked
}

fn total_correct(progress: &UserProgress) -> u32 {
    progress.exercises.values().map(|e| e.correct_count).sum()
}

pub fn unlock_achievement(progress: &mut UserProgress, achievement: &Achievement) {
    progress.achievements.insert(achievement.id.to_string());
    progress.xp += achievement.xp_reward;
    progress.level = crate::progress::calculate_level(progress.xp);

    if let Some(title) = achievement.unlocks_title {
        if progress.title.is_none() {
            progress.title = Some(title.to_string());
        }
    }

    if achievement.grants_freeze && progress.streak_freezes < 3 {
        progress.streak_freezes += 1;
    }

    progress.save();
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_get_achievement() {
        let achievement = get_achievement("first_blood");
        assert!(achievement.is_some());
        assert_eq!(achievement.unwrap().title, "First Blood");
    }

    #[test]
    fn test_achievement_not_found() {
        let achievement = get_achievement("nonexistent");
        assert!(achievement.is_none());
    }

    #[test]
    fn test_check_achievements_first_blood() {
        let mut progress = UserProgress::new();
        progress.record_attempt("test", true);

        let newly_unlocked = check_achievements(&progress);
        assert!(newly_unlocked.iter().any(|a| a.id == "first_blood"));
    }

    #[test]
    fn test_check_achievements_combo() {
        let mut progress = UserProgress::new();
        progress.best_combo = 5;

        let newly_unlocked = check_achievements(&progress);
        assert!(newly_unlocked.iter().any(|a| a.id == "combo_5"));
        assert!(!newly_unlocked.iter().any(|a| a.id == "combo_10"));
    }

    #[test]
    fn test_streak_achievements_grant_freeze() {
        let streak_7 = get_achievement("streak_7").unwrap();
        assert!(streak_7.grants_freeze);

        let first_blood = get_achievement("first_blood").unwrap();
        assert!(!first_blood.grants_freeze);
    }
}

```

---

### Module: audio

**File:** `src/audio.rs`

Additional source module.

```rust
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum SoundEffect {
    XpGain,
    CriticalHit,
    ComboUp,
    ComboBreak,
    Achievement,
    LevelUp,
    StreakSaved,
    StreakLost,
    Correct,
    Incorrect,
}

impl SoundEffect {
    pub fn as_str(&self) -> &'static str {
        match self {
            Self::XpGain => "xp_gain",
            Self::CriticalHit => "critical",
            Self::ComboUp => "combo_up",
            Self::ComboBreak => "combo_break",
            Self::Achievement => "achievement",
            Self::LevelUp => "level_up",
            Self::StreakSaved => "streak_saved",
            Self::StreakLost => "streak_lost",
            Self::Correct => "correct",
            Self::Incorrect => "incorrect",
        }
    }
}

#[cfg(target_arch = "wasm32")]
mod wasm {
    use super::SoundEffect;
    use wasm_bindgen::prelude::*;

    #[wasm_bindgen]
    extern "C" {
        #[wasm_bindgen(js_namespace = window, js_name = playSound)]
        fn play_sound_js(effect: &str);
    }

    pub fn play_sound(effect: SoundEffect) {
        play_sound_js(effect.as_str());
    }
}

#[cfg(target_arch = "wasm32")]
pub use wasm::play_sound;

#[cfg(not(target_arch = "wasm32"))]
pub fn play_sound(_effect: SoundEffect) {
    // No-op on non-wasm targets
}

```

---

### Module: codegen

**File:** `src/codegen.rs`

Additional source module.

```rust
use std::fmt::Write;

use crate::analysis::registry::{FieldDef, FieldType, TypeDef, TypeRegistry, VariantDef};
use crate::ast::logic::{LogicExpr, NumberKind, Term};
use crate::ast::stmt::{BinaryOpKind, Expr, Literal, Stmt, TypeExpr};
use crate::intern::{Interner, Symbol};
use crate::token::TokenType;

/// Generate complete Rust program with struct definitions and main function.
///
/// Phase 31: Structs are wrapped in `mod user_types` to enforce visibility.
/// Phase 32: Function definitions are emitted before main.
pub fn codegen_program(stmts: &[Stmt], registry: &TypeRegistry, interner: &Interner) -> String {
    let mut output = String::new();

    // Prelude
    writeln!(output, "use logos_core::prelude::*;\n").unwrap();

    // Collect user-defined structs from registry (Phase 34: now with generics)
    let structs: Vec<_> = registry.iter_types()
        .filter_map(|(name, def)| {
            if let TypeDef::Struct { fields, generics } = def {
                if !fields.is_empty() || !generics.is_empty() {
                    Some((*name, fields.clone(), generics.clone()))
                } else {
                    None
                }
            } else {
                None
            }
        })
        .collect();

    // Phase 33/34: Collect user-defined enums from registry (now with generics)
    let enums: Vec<_> = registry.iter_types()
        .filter_map(|(name, def)| {
            if let TypeDef::Enum { variants, generics } = def {
                if !variants.is_empty() || !generics.is_empty() {
                    Some((*name, variants.clone(), generics.clone()))
                } else {
                    None
                }
            } else {
                None
            }
        })
        .collect();

    // Emit struct and enum definitions in user_types module if any exist
    if !structs.is_empty() || !enums.is_empty() {
        writeln!(output, "pub mod user_types {{").unwrap();
        writeln!(output, "    use super::*;\n").unwrap();

        for (name, fields, generics) in &structs {
            output.push_str(&codegen_struct_def(*name, fields, generics, interner, 4));
        }

        for (name, variants, generics) in &enums {
            output.push_str(&codegen_enum_def(*name, variants, generics, interner, 4));
        }

        writeln!(output, "}}\n").unwrap();
        writeln!(output, "use user_types::*;\n").unwrap();
    }

    // Phase 32: Emit function definitions before main
    for stmt in stmts {
        if let Stmt::FunctionDef { name, params, body, return_type } = stmt {
            output.push_str(&codegen_function_def(*name, params, body, *return_type, interner));
        }
    }

    // Main function
    writeln!(output, "fn main() {{").unwrap();
    for stmt in stmts {
        // Skip function definitions - they're already emitted above
        if matches!(stmt, Stmt::FunctionDef { .. }) {
            continue;
        }
        output.push_str(&codegen_stmt(stmt, interner, 1));
    }
    writeln!(output, "}}").unwrap();
    output
}

/// Phase 32: Generate a function definition.
fn codegen_function_def(
    name: Symbol,
    params: &[(Symbol, Symbol)],
    body: &[Stmt],
    return_type: Option<Symbol>,
    interner: &Interner,
) -> String {
    let mut output = String::new();
    let func_name = interner.resolve(name);

    // Build parameter list
    let params_str: Vec<String> = params.iter()
        .map(|(param_name, param_type)| {
            let name = interner.resolve(*param_name);
            let ty = map_type_to_rust(interner.resolve(*param_type));
            format!("{}: {}", name, ty)
        })
        .collect();

    // Infer return type from body if not specified
    let inferred_return = return_type.map(|s| interner.resolve(s).to_string())
        .or_else(|| infer_return_type_from_body(body, interner));

    // Emit function signature
    if let Some(ret_ty) = inferred_return {
        let rust_ret = map_type_to_rust(&ret_ty);
        if rust_ret != "()" {
            writeln!(output, "fn {}({}) -> {} {{", func_name, params_str.join(", "), rust_ret).unwrap();
        } else {
            writeln!(output, "fn {}({}) {{", func_name, params_str.join(", ")).unwrap();
        }
    } else {
        writeln!(output, "fn {}({}) {{", func_name, params_str.join(", ")).unwrap();
    }

    // Emit body
    for stmt in body {
        output.push_str(&codegen_stmt(stmt, interner, 1));
    }

    writeln!(output, "}}\n").unwrap();
    output
}

/// Infer return type from function body by looking at Return statements.
fn infer_return_type_from_body(body: &[Stmt], _interner: &Interner) -> Option<String> {
    for stmt in body {
        if let Stmt::Return { value: Some(_) } = stmt {
            // For now, assume Int for any expression return
            // TODO: Implement proper type inference
            return Some("Int".to_string());
        }
    }
    None
}

/// Map LOGOS type names to Rust types.
fn map_type_to_rust(ty: &str) -> String {
    match ty {
        "Int" => "i64".to_string(),
        "Nat" => "u64".to_string(),
        "Text" => "String".to_string(),
        "Bool" | "Boolean" => "bool".to_string(),
        "Real" => "f64".to_string(),
        "Unit" | "()" => "()".to_string(),
        other => other.to_string(),
    }
}

/// Generate a single struct definition with derives and visibility.
/// Phase 34: Now supports generic type parameters.
fn codegen_struct_def(name: Symbol, fields: &[FieldDef], generics: &[Symbol], interner: &Interner, indent: usize) -> String {
    let ind = " ".repeat(indent);
    let mut output = String::new();

    // Build generic parameter string: <T, U> or empty
    let generic_str = if generics.is_empty() {
        String::new()
    } else {
        let params: Vec<&str> = generics.iter()
            .map(|g| interner.resolve(*g))
            .collect();
        format!("<{}>", params.join(", "))
    };

    writeln!(output, "{}#[derive(Default, Debug, Clone)]", ind).unwrap();
    writeln!(output, "{}pub struct {}{} {{", ind, interner.resolve(name), generic_str).unwrap();

    for field in fields {
        let vis = if field.is_public { "pub " } else { "" };
        let rust_type = codegen_field_type(&field.ty, interner);
        writeln!(output, "{}    {}{}: {},", ind, vis, interner.resolve(field.name), rust_type).unwrap();
    }

    writeln!(output, "{}}}\n", ind).unwrap();
    output
}

/// Phase 33/34: Generate enum definition with optional generic parameters.
fn codegen_enum_def(name: Symbol, variants: &[VariantDef], generics: &[Symbol], interner: &Interner, indent: usize) -> String {
    let ind = " ".repeat(indent);
    let mut output = String::new();

    // Build generic parameter string: <T, U> or empty
    let generic_str = if generics.is_empty() {
        String::new()
    } else {
        let params: Vec<&str> = generics.iter()
            .map(|g| interner.resolve(*g))
            .collect();
        format!("<{}>", params.join(", "))
    };

    writeln!(output, "{}#[derive(Debug, Clone)]", ind).unwrap();
    writeln!(output, "{}pub enum {}{} {{", ind, interner.resolve(name), generic_str).unwrap();

    for variant in variants {
        let variant_name = interner.resolve(variant.name);
        if variant.fields.is_empty() {
            // Unit variant
            writeln!(output, "{}    {},", ind, variant_name).unwrap();
        } else {
            // Struct variant with named fields
            let fields_str: Vec<String> = variant.fields.iter()
                .map(|f| {
                    let rust_type = codegen_field_type(&f.ty, interner);
                    format!("{}: {}", interner.resolve(f.name), rust_type)
                })
                .collect();
            writeln!(output, "{}    {} {{ {} }},", ind, variant_name, fields_str.join(", ")).unwrap();
        }
    }

    writeln!(output, "{}}}\n", ind).unwrap();
    output
}

/// Convert FieldType to Rust type string.
fn codegen_field_type(ty: &FieldType, interner: &Interner) -> String {
    match ty {
        FieldType::Primitive(sym) => {
            match interner.resolve(*sym) {
                "Int" => "i64".to_string(),
                "Nat" => "u64".to_string(),
                "Text" => "String".to_string(),
                "Bool" | "Boolean" => "bool".to_string(),
                "Real" => "f64".to_string(),
                "Unit" => "()".to_string(),
                other => other.to_string(),
            }
        }
        FieldType::Named(sym) => interner.resolve(*sym).to_string(),
        FieldType::Generic { base, params } => {
            let base_str = match interner.resolve(*base) {
                "List" | "Seq" => "Vec",
                "Option" => "Option",
                "Result" => "Result",
                other => other,
            };
            let param_strs: Vec<String> = params.iter()
                .map(|p| codegen_field_type(p, interner))
                .collect();
            format!("{}<{}>", base_str, param_strs.join(", "))
        }
        // Phase 34: Type parameter reference (T, U, etc.)
        FieldType::TypeParam(sym) => interner.resolve(*sym).to_string(),
    }
}

pub fn codegen_stmt(stmt: &Stmt, interner: &Interner, indent: usize) -> String {
    let indent_str = "    ".repeat(indent);
    let mut output = String::new();

    match stmt {
        Stmt::Let { var, ty, value, mutable } => {
            let var_name = interner.resolve(*var);
            let value_str = codegen_expr(value, interner);
            let type_annotation = ty.map(|t| codegen_type_expr(t, interner));

            match (*mutable, type_annotation) {
                (true, Some(t)) => writeln!(output, "{}let mut {}: {} = {};", indent_str, var_name, t, value_str).unwrap(),
                (true, None) => writeln!(output, "{}let mut {} = {};", indent_str, var_name, value_str).unwrap(),
                (false, Some(t)) => writeln!(output, "{}let {}: {} = {};", indent_str, var_name, t, value_str).unwrap(),
                (false, None) => writeln!(output, "{}let {} = {};", indent_str, var_name, value_str).unwrap(),
            }
        }

        Stmt::Set { target, value } => {
            let target_name = interner.resolve(*target);
            let value_str = codegen_expr(value, interner);
            writeln!(output, "{}{} = {};", indent_str, target_name, value_str).unwrap();
        }

        Stmt::Call { function, args } => {
            let func_name = interner.resolve(*function);
            let args_str: Vec<String> = args.iter().map(|a| codegen_expr(a, interner)).collect();
            writeln!(output, "{}{}({});", indent_str, func_name, args_str.join(", ")).unwrap();
        }

        Stmt::If { cond, then_block, else_block } => {
            let cond_str = codegen_expr(cond, interner);
            writeln!(output, "{}if {} {{", indent_str, cond_str).unwrap();
            for stmt in *then_block {
                output.push_str(&codegen_stmt(stmt, interner, indent + 1));
            }
            if let Some(else_stmts) = else_block {
                writeln!(output, "{}}} else {{", indent_str).unwrap();
                for stmt in *else_stmts {
                    output.push_str(&codegen_stmt(stmt, interner, indent + 1));
                }
            }
            writeln!(output, "{}}}", indent_str).unwrap();
        }

        Stmt::While { cond, body } => {
            let cond_str = codegen_expr(cond, interner);
            writeln!(output, "{}while {} {{", indent_str, cond_str).unwrap();
            for stmt in *body {
                output.push_str(&codegen_stmt(stmt, interner, indent + 1));
            }
            writeln!(output, "{}}}", indent_str).unwrap();
        }

        Stmt::Repeat { var, iterable, body } => {
            let var_name = interner.resolve(*var);
            let iter_str = codegen_expr(iterable, interner);
            writeln!(output, "{}for {} in {} {{", indent_str, var_name, iter_str).unwrap();
            for stmt in *body {
                output.push_str(&codegen_stmt(stmt, interner, indent + 1));
            }
            writeln!(output, "{}}}", indent_str).unwrap();
        }

        Stmt::Return { value } => {
            if let Some(v) = value {
                let value_str = codegen_expr(v, interner);
                writeln!(output, "{}return {};", indent_str, value_str).unwrap();
            } else {
                writeln!(output, "{}return;", indent_str).unwrap();
            }
        }

        Stmt::Assert { proposition } => {
            let condition = codegen_assertion(proposition, interner);
            writeln!(output, "{}debug_assert!({});", indent_str, condition).unwrap();
        }

        // Phase 35: Trust with documented justification
        Stmt::Trust { proposition, justification } => {
            let reason = interner.resolve(*justification);
            // Strip quotes if present (string literals include their quotes)
            let reason_clean = reason.trim_matches('"');
            writeln!(output, "{}// TRUST: {}", indent_str, reason_clean).unwrap();
            let condition = codegen_assertion(proposition, interner);
            writeln!(output, "{}debug_assert!({});", indent_str, condition).unwrap();
        }

        Stmt::Give { object, recipient } => {
            // Move semantics: pass ownership without borrowing
            let obj_str = codegen_expr(object, interner);
            let recv_str = codegen_expr(recipient, interner);
            writeln!(output, "{}{}({});", indent_str, recv_str, obj_str).unwrap();
        }

        Stmt::Show { object, recipient } => {
            // Borrow semantics: pass immutable reference
            let obj_str = codegen_expr(object, interner);
            let recv_str = codegen_expr(recipient, interner);
            writeln!(output, "{}{}(&{});", indent_str, recv_str, obj_str).unwrap();
        }

        Stmt::SetField { object, field, value } => {
            let obj_str = codegen_expr(object, interner);
            let field_name = interner.resolve(*field);
            let value_str = codegen_expr(value, interner);
            writeln!(output, "{}{}.{} = {};", indent_str, obj_str, field_name, value_str).unwrap();
        }

        Stmt::StructDef { .. } => {
            // Struct definitions are handled in codegen_program, not here
        }

        Stmt::FunctionDef { .. } => {
            // Function definitions are handled in codegen_program, not here
        }

        Stmt::Inspect { target, arms, .. } => {
            let target_str = codegen_expr(target, interner);
            writeln!(output, "{}match {} {{", indent_str, target_str).unwrap();

            for arm in arms {
                if let Some(variant) = arm.variant {
                    let variant_name = interner.resolve(variant);
                    // Get the enum name from the arm, or fallback to just variant name
                    let enum_prefix = arm.enum_name
                        .map(|e| format!("{}::", interner.resolve(e)))
                        .unwrap_or_default();

                    if arm.bindings.is_empty() {
                        // Unit variant pattern
                        writeln!(output, "{}    {}{} => {{", indent_str, enum_prefix, variant_name).unwrap();
                    } else {
                        // Pattern with bindings
                        let bindings_str: Vec<String> = arm.bindings.iter()
                            .map(|(field, binding)| {
                                let field_name = interner.resolve(*field);
                                let binding_name = interner.resolve(*binding);
                                if field_name == binding_name {
                                    format!("ref {}", field_name)
                                } else {
                                    format!("{}: ref {}", field_name, binding_name)
                                }
                            })
                            .collect();
                        writeln!(output, "{}    {}{} {{ {} }} => {{", indent_str, enum_prefix, variant_name, bindings_str.join(", ")).unwrap();
                    }
                } else {
                    // Otherwise (wildcard) pattern
                    writeln!(output, "{}    _ => {{", indent_str).unwrap();
                }

                for stmt in arm.body {
                    output.push_str(&codegen_stmt(stmt, interner, indent + 2));
                }
                writeln!(output, "{}    }}", indent_str).unwrap();
            }

            writeln!(output, "{}}}", indent_str).unwrap();
        }
    }

    output
}

pub fn codegen_expr(expr: &Expr, interner: &Interner) -> String {
    match expr {
        Expr::Literal(lit) => codegen_literal(lit, interner),

        Expr::Identifier(sym) => interner.resolve(*sym).to_string(),

        Expr::BinaryOp { op, left, right } => {
            let left_str = codegen_expr(left, interner);
            let right_str = codegen_expr(right, interner);
            let op_str = match op {
                BinaryOpKind::Add => "+",
                BinaryOpKind::Subtract => "-",
                BinaryOpKind::Multiply => "*",
                BinaryOpKind::Divide => "/",
                BinaryOpKind::Eq => "==",
                BinaryOpKind::NotEq => "!=",
                BinaryOpKind::Lt => "<",
                BinaryOpKind::Gt => ">",
                BinaryOpKind::LtEq => "<=",
                BinaryOpKind::GtEq => ">=",
            };
            format!("({} {} {})", left_str, op_str, right_str)
        }

        Expr::Call { function, args } => {
            let func_name = interner.resolve(*function);
            let args_str: Vec<String> = args.iter().map(|a| codegen_expr(a, interner)).collect();
            format!("{}({})", func_name, args_str.join(", "))
        }

        Expr::Index { collection, index } => {
            let coll_str = codegen_expr(collection, interner);
            format!("{}[{}]", coll_str, index - 1)
        }

        Expr::Slice { collection, start, end } => {
            let coll_str = codegen_expr(collection, interner);
            // 1-indexed to 0-indexed: items 2 through 5 → &list[1..5]
            format!("&{}[{}..{}]", coll_str, start - 1, end)
        }

        Expr::List(ref items) => {
            let item_strs: Vec<String> = items.iter()
                .map(|i| codegen_expr(i, interner))
                .collect();
            format!("vec![{}]", item_strs.join(", "))
        }

        Expr::Range { start, end } => {
            let start_str = codegen_expr(start, interner);
            let end_str = codegen_expr(end, interner);
            format!("({}..={})", start_str, end_str)
        }

        Expr::FieldAccess { object, field } => {
            let obj_str = codegen_expr(object, interner);
            let field_name = interner.resolve(*field);
            format!("{}.{}", obj_str, field_name)
        }

        Expr::New { type_name, type_args } => {
            let type_str = interner.resolve(*type_name);
            if type_args.is_empty() {
                format!("{}::default()", type_str)
            } else {
                // Phase 34: Turbofish syntax for generic instantiation
                let args_str = type_args.iter()
                    .map(|s| map_type_to_rust(interner.resolve(*s)))
                    .collect::<Vec<_>>()
                    .join(", ");
                format!("{}::<{}>::default()", type_str, args_str)
            }
        }

        Expr::NewVariant { enum_name, variant, fields } => {
            let enum_str = interner.resolve(*enum_name);
            let variant_str = interner.resolve(*variant);
            if fields.is_empty() {
                // Unit variant: Shape::Point
                format!("{}::{}", enum_str, variant_str)
            } else {
                // Struct variant: Shape::Circle { radius: 10 }
                let fields_str: Vec<String> = fields.iter()
                    .map(|(field_name, value)| {
                        let name = interner.resolve(*field_name);
                        let val = codegen_expr(value, interner);
                        format!("{}: {}", name, val)
                    })
                    .collect();
                format!("{}::{} {{ {} }}", enum_str, variant_str, fields_str.join(", "))
            }
        }
    }
}

fn codegen_literal(lit: &Literal, interner: &Interner) -> String {
    match lit {
        Literal::Number(n) => n.to_string(),
        Literal::Text(sym) => format!("\"{}\"", interner.resolve(*sym)),
        Literal::Boolean(b) => b.to_string(),
        Literal::Nothing => "()".to_string(),
    }
}

fn codegen_type_expr(ty: &TypeExpr, interner: &Interner) -> String {
    match ty {
        TypeExpr::Primitive(sym) => {
            match interner.resolve(*sym) {
                "Int" => "i64".to_string(),
                "Nat" => "u64".to_string(),  // Spec §10.6.1: Nat → u64
                "Text" => "String".to_string(),
                "Bool" | "Boolean" => "bool".to_string(),
                "Unit" => "()".to_string(),
                other => other.to_string(),
            }
        }
        TypeExpr::Named(sym) => interner.resolve(*sym).to_string(),
        TypeExpr::Generic { base, params } => {
            let base_str = match interner.resolve(*base) {
                "List" | "Seq" => "Vec",
                "Option" => "Option",
                "Result" => "Result",
                other => other,
            };
            let param_strs: Vec<String> = params.iter()
                .map(|p| codegen_type_expr(p, interner))
                .collect();
            format!("{}<{}>", base_str, param_strs.join(", "))
        }
        TypeExpr::Function { inputs, output } => {
            let input_strs: Vec<String> = inputs.iter()
                .map(|p| codegen_type_expr(p, interner))
                .collect();
            let output_str = codegen_type_expr(output, interner);
            format!("fn({}) -> {}", input_strs.join(", "), output_str)
        }
    }
}

pub fn codegen_assertion(expr: &LogicExpr, interner: &Interner) -> String {
    match expr {
        LogicExpr::Atom(sym) => interner.resolve(*sym).to_string(),

        LogicExpr::Identity { left, right } => {
            let left_str = codegen_term(left, interner);
            let right_str = codegen_term(right, interner);
            format!("({} == {})", left_str, right_str)
        }

        LogicExpr::Predicate { name, args } => {
            let pred_name = interner.resolve(*name).to_lowercase();
            match pred_name.as_str() {
                "greater" if args.len() == 2 => {
                    let left = codegen_term(&args[0], interner);
                    let right = codegen_term(&args[1], interner);
                    format!("({} > {})", left, right)
                }
                "less" if args.len() == 2 => {
                    let left = codegen_term(&args[0], interner);
                    let right = codegen_term(&args[1], interner);
                    format!("({} < {})", left, right)
                }
                "equal" if args.len() == 2 => {
                    let left = codegen_term(&args[0], interner);
                    let right = codegen_term(&args[1], interner);
                    format!("({} == {})", left, right)
                }
                "greaterequal" | "greaterorequal" if args.len() == 2 => {
                    let left = codegen_term(&args[0], interner);
                    let right = codegen_term(&args[1], interner);
                    format!("({} >= {})", left, right)
                }
                "lessequal" | "lessorequal" if args.len() == 2 => {
                    let left = codegen_term(&args[0], interner);
                    let right = codegen_term(&args[1], interner);
                    format!("({} <= {})", left, right)
                }
                "positive" if args.len() == 1 => {
                    let arg = codegen_term(&args[0], interner);
                    format!("({} > 0)", arg)
                }
                "negative" if args.len() == 1 => {
                    let arg = codegen_term(&args[0], interner);
                    format!("({} < 0)", arg)
                }
                "zero" if args.len() == 1 => {
                    let arg = codegen_term(&args[0], interner);
                    format!("({} == 0)", arg)
                }
                _ => {
                    let args_str: Vec<String> = args.iter()
                        .map(|a| codegen_term(a, interner))
                        .collect();
                    format!("{}({})", interner.resolve(*name), args_str.join(", "))
                }
            }
        }

        LogicExpr::BinaryOp { left, op, right } => {
            let left_str = codegen_assertion(left, interner);
            let right_str = codegen_assertion(right, interner);
            let op_str = match op {
                TokenType::And => "&&",
                TokenType::Or => "||",
                TokenType::Iff => "==",
                _ => "/* unknown op */",
            };
            format!("({} {} {})", left_str, op_str, right_str)
        }

        LogicExpr::UnaryOp { op, operand } => {
            let operand_str = codegen_assertion(operand, interner);
            match op {
                TokenType::Not => format!("(!{})", operand_str),
                _ => format!("/* unknown unary op */({})", operand_str),
            }
        }

        LogicExpr::Comparative { adjective, subject, object, .. } => {
            let adj_name = interner.resolve(*adjective).to_lowercase();
            let subj_str = codegen_term(subject, interner);
            let obj_str = codegen_term(object, interner);
            match adj_name.as_str() {
                "great" | "big" | "large" | "tall" | "old" | "high" => {
                    format!("({} > {})", subj_str, obj_str)
                }
                "small" | "little" | "short" | "young" | "low" => {
                    format!("({} < {})", subj_str, obj_str)
                }
                _ => format!("({} > {})", subj_str, obj_str), // default to greater-than
            }
        }

        _ => "/* unsupported LogicExpr */true".to_string(),
    }
}

pub fn codegen_term(term: &Term, interner: &Interner) -> String {
    match term {
        Term::Constant(sym) => interner.resolve(*sym).to_string(),
        Term::Variable(sym) => interner.resolve(*sym).to_string(),
        Term::Value { kind, .. } => match kind {
            NumberKind::Integer(n) => n.to_string(),
            NumberKind::Real(f) => f.to_string(),
            NumberKind::Symbolic(sym) => interner.resolve(*sym).to_string(),
        },
        Term::Function(name, args) => {
            let args_str: Vec<String> = args.iter()
                .map(|a| codegen_term(a, interner))
                .collect();
            format!("{}({})", interner.resolve(*name), args_str.join(", "))
        }
        Term::Possessed { possessor, possessed } => {
            let poss_str = codegen_term(possessor, interner);
            format!("{}.{}", poss_str, interner.resolve(*possessed))
        }
        Term::Group(members) => {
            let members_str: Vec<String> = members.iter()
                .map(|m| codegen_term(m, interner))
                .collect();
            format!("({})", members_str.join(", "))
        }
        _ => "/* unsupported Term */".to_string(),
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_literal_number() {
        let interner = Interner::new();
        let expr = Expr::Literal(Literal::Number(42));
        assert_eq!(codegen_expr(&expr, &interner), "42");
    }

    #[test]
    fn test_literal_boolean() {
        let interner = Interner::new();
        assert_eq!(codegen_expr(&Expr::Literal(Literal::Boolean(true)), &interner), "true");
        assert_eq!(codegen_expr(&Expr::Literal(Literal::Boolean(false)), &interner), "false");
    }

    #[test]
    fn test_literal_nothing() {
        let interner = Interner::new();
        assert_eq!(codegen_expr(&Expr::Literal(Literal::Nothing), &interner), "()");
    }
}

```

---

### Module: compile

**File:** `src/compile.rs`

Additional source module.

```rust
//! LOGOS Compilation Pipeline
//!
//! This module provides the end-to-end compilation pipeline:
//! LOGOS source → Rust source → executable

use std::fs;
use std::io::Write;
use std::path::Path;
use std::process::Command;

// Embed runtime at compile time
const LOGOS_CORE_TOML: &str = include_str!("../logos_core/Cargo.toml");
const LOGOS_CORE_LIB: &str = include_str!("../logos_core/src/lib.rs");
const LOGOS_CORE_TYPES: &str = include_str!("../logos_core/src/types.rs");
const LOGOS_CORE_IO: &str = include_str!("../logos_core/src/io.rs");

use crate::analysis::DiscoveryPass;
use crate::arena::Arena;
use crate::arena_ctx::AstContext;
use crate::ast::{Expr, Stmt, TypeExpr};
use crate::codegen::codegen_program;
use crate::context::DiscourseContext;
use crate::error::ParseError;
use crate::intern::Interner;
use crate::lexer::Lexer;
use crate::parser::Parser;

/// Compile LOGOS source to Rust source code.
pub fn compile_to_rust(source: &str) -> Result<String, ParseError> {
    let mut interner = Interner::new();
    let mut lexer = Lexer::new(source, &mut interner);
    let tokens = lexer.tokenize();

    // Pass 1: Discovery - scan for type definitions
    let type_registry = {
        let mut discovery = DiscoveryPass::new(&tokens, &mut interner);
        discovery.run()
    };
    // Clone for codegen (parser takes ownership)
    let codegen_registry = type_registry.clone();

    let mut ctx = DiscourseContext::new();
    let expr_arena = Arena::new();
    let term_arena = Arena::new();
    let np_arena = Arena::new();
    let sym_arena = Arena::new();
    let role_arena = Arena::new();
    let pp_arena = Arena::new();
    let stmt_arena: Arena<Stmt> = Arena::new();
    let imperative_expr_arena: Arena<Expr> = Arena::new();
    let type_expr_arena: Arena<TypeExpr> = Arena::new();

    let ast_ctx = AstContext::with_types(
        &expr_arena,
        &term_arena,
        &np_arena,
        &sym_arena,
        &role_arena,
        &pp_arena,
        &stmt_arena,
        &imperative_expr_arena,
        &type_expr_arena,
    );

    // Pass 2: Parse with type context
    let mut parser = Parser::with_types(tokens, &mut ctx, &mut interner, ast_ctx, type_registry);
    // Note: Don't call process_block_headers() - parse_program handles blocks itself

    let stmts = parser.parse_program()?;
    let rust_code = codegen_program(&stmts, &codegen_registry, &interner);

    Ok(rust_code)
}

/// Compile LOGOS source and write output to a directory.
/// Creates a Cargo project with logos_core dependency.
pub fn compile_to_dir(source: &str, output_dir: &Path) -> Result<(), CompileError> {
    let rust_code = compile_to_rust(source).map_err(CompileError::Parse)?;

    // Create output directory structure
    let src_dir = output_dir.join("src");
    fs::create_dir_all(&src_dir).map_err(|e| CompileError::Io(e.to_string()))?;

    // Write main.rs with logos_core import
    let main_rs = format!(
        "use logos_core::prelude::*;\n\n{}",
        rust_code
    );
    let main_path = src_dir.join("main.rs");
    let mut file = fs::File::create(&main_path).map_err(|e| CompileError::Io(e.to_string()))?;
    file.write_all(main_rs.as_bytes()).map_err(|e| CompileError::Io(e.to_string()))?;

    // Write Cargo.toml
    let cargo_toml = format!(
        r#"[package]
name = "logos_output"
version = "0.1.0"
edition = "2021"

[dependencies]
logos_core = {{ path = "./logos_core" }}
"#
    );
    let cargo_path = output_dir.join("Cargo.toml");
    let mut file = fs::File::create(&cargo_path).map_err(|e| CompileError::Io(e.to_string()))?;
    file.write_all(cargo_toml.as_bytes()).map_err(|e| CompileError::Io(e.to_string()))?;

    // Copy logos_core to output directory
    copy_logos_core(output_dir)?;

    Ok(())
}

/// Copy the embedded logos_core crate to the output directory.
fn copy_logos_core(output_dir: &Path) -> Result<(), CompileError> {
    let core_dir = output_dir.join("logos_core");
    let src_dir = core_dir.join("src");

    fs::create_dir_all(&src_dir).map_err(|e| CompileError::Io(e.to_string()))?;

    fs::write(core_dir.join("Cargo.toml"), LOGOS_CORE_TOML)
        .map_err(|e| CompileError::Io(e.to_string()))?;
    fs::write(src_dir.join("lib.rs"), LOGOS_CORE_LIB)
        .map_err(|e| CompileError::Io(e.to_string()))?;
    fs::write(src_dir.join("types.rs"), LOGOS_CORE_TYPES)
        .map_err(|e| CompileError::Io(e.to_string()))?;
    fs::write(src_dir.join("io.rs"), LOGOS_CORE_IO)
        .map_err(|e| CompileError::Io(e.to_string()))?;

    Ok(())
}

/// Compile and run a LOGOS program.
pub fn compile_and_run(source: &str, output_dir: &Path) -> Result<String, CompileError> {
    compile_to_dir(source, output_dir)?;

    // Run cargo build
    let build_output = Command::new("cargo")
        .arg("build")
        .current_dir(output_dir)
        .output()
        .map_err(|e| CompileError::Io(e.to_string()))?;

    if !build_output.status.success() {
        let stderr = String::from_utf8_lossy(&build_output.stderr);
        return Err(CompileError::Build(stderr.to_string()));
    }

    // Run the compiled program
    let run_output = Command::new("cargo")
        .arg("run")
        .arg("--quiet")
        .current_dir(output_dir)
        .output()
        .map_err(|e| CompileError::Io(e.to_string()))?;

    if !run_output.status.success() {
        let stderr = String::from_utf8_lossy(&run_output.stderr);
        return Err(CompileError::Runtime(stderr.to_string()));
    }

    let stdout = String::from_utf8_lossy(&run_output.stdout);
    Ok(stdout.to_string())
}

/// Compile a LOGOS source file.
pub fn compile_file(path: &Path) -> Result<String, CompileError> {
    let source = fs::read_to_string(path).map_err(|e| CompileError::Io(e.to_string()))?;
    compile_to_rust(&source).map_err(CompileError::Parse)
}

/// Errors that can occur during compilation.
#[derive(Debug)]
pub enum CompileError {
    Parse(ParseError),
    Io(String),
    Build(String),
    Runtime(String),
}

impl std::fmt::Display for CompileError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            CompileError::Parse(e) => write!(f, "Parse error: {:?}", e),
            CompileError::Io(e) => write!(f, "IO error: {}", e),
            CompileError::Build(e) => write!(f, "Build error: {}", e),
            CompileError::Runtime(e) => write!(f, "Runtime error: {}", e),
        }
    }
}

impl std::error::Error for CompileError {}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_compile_let_statement() {
        let source = "## Main\nLet x be 5.";
        let result = compile_to_rust(source);
        assert!(result.is_ok(), "Should compile: {:?}", result);
        let rust = result.unwrap();
        assert!(rust.contains("fn main()"));
        assert!(rust.contains("let x = 5;"));
    }

    #[test]
    fn test_compile_return_statement() {
        let source = "## Main\nReturn 42.";
        let result = compile_to_rust(source);
        assert!(result.is_ok(), "Should compile: {:?}", result);
        let rust = result.unwrap();
        assert!(rust.contains("return 42;"));
    }
}

```

---

### Module: game

**File:** `src/game.rs`

Additional source module.

```rust
use crate::progress::UserProgress;
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub struct XpReward {
    pub base: u64,
    pub combo_bonus: u64,
    pub streak_bonus: u64,
    pub critical_bonus: u64,
    pub first_try_bonus: u64,
    pub total: u64,
    pub is_critical: bool,
}

pub fn calculate_xp_reward(
    difficulty: u32,
    combo: u32,
    streak_days: u32,
    first_try: bool,
    rng_seed: u64,
) -> XpReward {
    let base = 10 + (difficulty.saturating_sub(1) * 5) as u64;

    let combo_mult = 1.0 + (combo.min(10) as f64 * 0.1);
    let combo_bonus = ((base as f64) * (combo_mult - 1.0)) as u64;

    let streak_bonus = (streak_days.min(7) * 2) as u64;

    let first_try_bonus = if first_try { 5 } else { 0 };

    let is_critical = (rng_seed % 10) == 0;
    let critical_bonus = if is_critical { base } else { 0 };

    let total = base + combo_bonus + streak_bonus + first_try_bonus + critical_bonus;

    XpReward {
        base,
        combo_bonus,
        streak_bonus,
        critical_bonus,
        first_try_bonus,
        total,
        is_critical,
    }
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum StreakStatus {
    Active { days: u32 },
    AtRisk,
    Frozen,
    Lost { was: u32 },
}

pub fn update_streak(progress: &mut UserProgress, today: &str) -> StreakStatus {
    match &progress.last_streak_date {
        None => {
            progress.streak_days = 1;
            progress.last_streak_date = Some(today.to_string());
            StreakStatus::Active { days: 1 }
        }
        Some(last) if last == today => {
            StreakStatus::Active { days: progress.streak_days }
        }
        Some(last) if is_yesterday(last, today) => {
            progress.streak_days += 1;
            progress.last_streak_date = Some(today.to_string());
            StreakStatus::Active { days: progress.streak_days }
        }
        Some(last) if is_two_days_ago(last, today) && progress.streak_freezes > 0 => {
            progress.streak_freezes -= 1;
            progress.last_streak_date = Some(today.to_string());
            StreakStatus::Frozen
        }
        Some(_) => {
            let was = progress.streak_days;
            progress.streak_days = 1;
            progress.last_streak_date = Some(today.to_string());
            StreakStatus::Lost { was }
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ComboResult {
    pub new_combo: u32,
    pub is_new_record: bool,
    pub multiplier: f64,
}

pub fn update_combo(progress: &mut UserProgress, correct: bool) -> ComboResult {
    if correct {
        progress.combo += 1;
        let is_new_record = progress.combo > progress.best_combo;
        if is_new_record {
            progress.best_combo = progress.combo;
        }
        let multiplier = 1.0 + (progress.combo.min(10) as f64 * 0.1);
        ComboResult { new_combo: progress.combo, is_new_record, multiplier }
    } else {
        progress.combo = 0;
        ComboResult { new_combo: 0, is_new_record: false, multiplier: 1.0 }
    }
}

pub fn level_title(level: u32) -> &'static str {
    match level {
        1 => "Novice",
        2..=4 => "Apprentice",
        5..=9 => "Student",
        10..=14 => "Scholar",
        15..=19 => "Adept",
        20..=29 => "Expert",
        30..=39 => "Master",
        40..=49 => "Sage",
        _ => "Grandmaster",
    }
}

pub fn xp_progress_to_next_level(xp: u64, level: u32) -> (u64, u64, f64) {
    let current_threshold = crate::progress::xp_for_level(level);
    let next_threshold = crate::progress::xp_for_level(level + 1);
    let progress = xp.saturating_sub(current_threshold);
    let needed = next_threshold - current_threshold;
    let percentage = if needed > 0 {
        (progress as f64) / (needed as f64)
    } else {
        0.0
    };
    (progress, needed, percentage)
}

pub struct FreezeGrant {
    pub freezes: u8,
    pub reason: &'static str,
}

pub fn check_level_up_freeze_grants(old_level: u32, new_level: u32) -> Option<FreezeGrant> {
    let freeze_count = (old_level + 1..=new_level)
        .filter(|l| l % 5 == 0)
        .count() as u8;

    if freeze_count > 0 {
        Some(FreezeGrant {
            freezes: freeze_count,
            reason: "Level milestone reward",
        })
    } else {
        None
    }
}

pub fn is_sunday(date: &str) -> bool {
    if let Ok(num) = parse_date_to_days(date) {
        (num + 4) % 7 == 0
    } else {
        false
    }
}

fn is_yesterday(last: &str, today: &str) -> bool {
    if let (Ok(l), Ok(t)) = (parse_date_to_days(last), parse_date_to_days(today)) {
        t - l == 1
    } else {
        false
    }
}

fn is_two_days_ago(last: &str, today: &str) -> bool {
    if let (Ok(l), Ok(t)) = (parse_date_to_days(last), parse_date_to_days(today)) {
        t - l == 2
    } else {
        false
    }
}

fn parse_date_to_days(date: &str) -> Result<i64, ()> {
    let parts: Vec<&str> = date.split('-').collect();
    if parts.len() != 3 {
        return Err(());
    }

    let year: i64 = parts[0].parse().map_err(|_| ())?;
    let month: i64 = parts[1].parse().map_err(|_| ())?;
    let day: i64 = parts[2].parse().map_err(|_| ())?;

    let days = year * 365 + (year / 4) - (year / 100) + (year / 400)
        + (month * 30) + day;
    Ok(days)
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_xp_reward_base() {
        let reward = calculate_xp_reward(1, 0, 0, false, 1);
        assert_eq!(reward.base, 10);
        assert_eq!(reward.combo_bonus, 0);
        assert_eq!(reward.total, 10);
        assert!(!reward.is_critical);
    }

    #[test]
    fn test_xp_reward_with_combo() {
        let reward = calculate_xp_reward(1, 5, 0, false, 1);
        assert_eq!(reward.base, 10);
        assert_eq!(reward.combo_bonus, 5); // 10 * 0.5 = 5
        assert_eq!(reward.total, 15);
    }

    #[test]
    fn test_xp_reward_critical() {
        let reward = calculate_xp_reward(1, 0, 0, false, 10); // seed % 10 == 0
        assert!(reward.is_critical);
        assert_eq!(reward.critical_bonus, 10);
        assert_eq!(reward.total, 20);
    }

    #[test]
    fn test_xp_reward_full() {
        // difficulty 3, combo 10, streak 7, first try, non-crit
        let reward = calculate_xp_reward(3, 10, 7, true, 1);
        // base = 10 + (2 * 5) = 20
        // combo = 20 * 1.0 = 20
        // streak = 14
        // first_try = 5
        // total = 20 + 20 + 14 + 5 = 59
        assert_eq!(reward.base, 20);
        assert_eq!(reward.combo_bonus, 20);
        assert_eq!(reward.streak_bonus, 14);
        assert_eq!(reward.first_try_bonus, 5);
        assert_eq!(reward.total, 59);
    }

    #[test]
    fn test_combo_increment() {
        let mut progress = UserProgress::new();

        let result = update_combo(&mut progress, true);
        assert_eq!(result.new_combo, 1);
        assert!(result.is_new_record);

        let result = update_combo(&mut progress, true);
        assert_eq!(result.new_combo, 2);
        assert!(result.is_new_record);

        let result = update_combo(&mut progress, false);
        assert_eq!(result.new_combo, 0);
        assert!(!result.is_new_record);
    }

    #[test]
    fn test_combo_multiplier() {
        let mut progress = UserProgress::new();

        for _ in 0..10 {
            update_combo(&mut progress, true);
        }

        let result = update_combo(&mut progress, true);
        assert!((result.multiplier - 2.0).abs() < 0.01);
    }

    #[test]
    fn test_level_titles() {
        assert_eq!(level_title(1), "Novice");
        assert_eq!(level_title(5), "Student");
        assert_eq!(level_title(10), "Scholar");
        assert_eq!(level_title(50), "Grandmaster");
    }

    #[test]
    fn test_level_up_freeze_grants() {
        assert!(check_level_up_freeze_grants(1, 4).is_none());

        let grant = check_level_up_freeze_grants(4, 5).unwrap();
        assert_eq!(grant.freezes, 1);

        let grant = check_level_up_freeze_grants(1, 10).unwrap();
        assert_eq!(grant.freezes, 2); // levels 5 and 10
    }

    #[test]
    fn test_is_yesterday() {
        assert!(is_yesterday("2025-01-01", "2025-01-02"));
        assert!(!is_yesterday("2025-01-01", "2025-01-03"));
    }
}

```

---

### Module: mwe

**File:** `src/mwe.rs`

Additional source module.

```rust
//! Multi-Word Expression (MWE) processing
//!
//! Post-tokenization pipeline that collapses multi-token sequences
//! into single semantic units (e.g., "fire engine" -> FireEngine).

use std::collections::HashMap;
use crate::token::{Token, TokenType};
use crate::lexicon::{VerbClass, Time, Aspect};
use crate::intern::Interner;

#[derive(Debug, Clone)]
pub struct MweTarget {
    pub lemma: &'static str,
    pub pos: &'static str,
    pub class: Option<VerbClass>,
}

#[derive(Default, Debug)]
pub struct MweTrie {
    pub children: HashMap<String, MweTrie>,
    pub target: Option<MweTarget>,
}

impl MweTrie {
    pub fn insert(&mut self, pattern: &[&str], target: MweTarget) {
        if pattern.is_empty() {
            self.target = Some(target);
            return;
        }
        self.children
            .entry(pattern[0].to_lowercase())
            .or_default()
            .insert(&pattern[1..], target);
    }
}

/// Apply MWE collapsing to a token stream.
/// Matches on lemmas (not raw strings) to handle morphological variants.
pub fn apply_mwe_pipeline(
    tokens: Vec<Token>,
    trie: &MweTrie,
    interner: &mut Interner,
) -> Vec<Token> {
    let mut result = Vec::new();
    let mut i = 0;

    while i < tokens.len() {
        if let Some((match_len, target)) = find_longest_match(&tokens[i..], trie, interner) {
            let merged = create_merged_token(&tokens[i], target, interner);
            result.push(merged);
            i += match_len;
        } else {
            result.push(tokens[i].clone());
            i += 1;
        }
    }
    result
}

/// Extract lemma from a token for MWE matching.
/// Uses lowercase for case-insensitive matching.
fn get_lemma(token: &Token, interner: &Interner) -> String {
    match &token.kind {
        TokenType::Verb { lemma, .. } => interner.resolve(*lemma).to_lowercase(),
        TokenType::Noun(sym) => interner.resolve(*sym).to_lowercase(),
        TokenType::Adjective(sym) => interner.resolve(*sym).to_lowercase(),
        TokenType::NonIntersectiveAdjective(sym) => interner.resolve(*sym).to_lowercase(),
        TokenType::Preposition(sym) => interner.resolve(*sym).to_lowercase(),
        TokenType::Particle(sym) => interner.resolve(*sym).to_lowercase(),
        TokenType::Article(_) => interner.resolve(token.lexeme).to_lowercase(),
        _ => interner.resolve(token.lexeme).to_lowercase(),
    }
}

/// Find the longest MWE match starting at the beginning of the token slice.
fn find_longest_match<'a>(
    tokens: &[Token],
    trie: &'a MweTrie,
    interner: &Interner,
) -> Option<(usize, &'a MweTarget)> {
    let mut node = trie;
    let mut best: Option<(usize, &MweTarget)> = None;

    for (i, token) in tokens.iter().enumerate() {
        let lemma = get_lemma(token, interner);
        if let Some(child) = node.children.get(&lemma) {
            node = child;
            if let Some(target) = &node.target {
                best = Some((i + 1, target));
            }
        } else {
            break;
        }
    }
    best
}

/// Create a merged token from the MWE target, inheriting tense from the head token.
fn create_merged_token(head: &Token, target: &MweTarget, interner: &mut Interner) -> Token {
    let lemma_sym = interner.intern(target.lemma);

    let kind = match target.pos {
        "Noun" => TokenType::Noun(lemma_sym),
        "Verb" => {
            let (time, aspect) = match &head.kind {
                TokenType::Verb { time, aspect, .. } => (*time, *aspect),
                _ => (Time::Present, Aspect::Simple),
            };
            TokenType::Verb {
                lemma: lemma_sym,
                time,
                aspect,
                class: target.class.unwrap_or(VerbClass::Activity),
            }
        }
        "Preposition" => TokenType::Preposition(lemma_sym),
        "Conjunction" => TokenType::And,
        "Quantifier" => TokenType::NoOne,
        _ => TokenType::Noun(lemma_sym),
    };

    Token {
        kind,
        lexeme: lemma_sym,
        span: head.span,
    }
}

include!(concat!(env!("OUT_DIR"), "/mwe_data.rs"));

```

---

### Module: ontology

**File:** `src/ontology.rs`

Additional source module.

```rust
//! Ontology module for bridging anaphora and sort compatibility checking.
//!
//! This module provides:
//! - Part-whole relationship lookup for bridging anaphora resolution
//! - Predicate sort requirements for metaphor detection

use crate::lexicon::Sort;

include!(concat!(env!("OUT_DIR"), "/ontology_data.rs"));

/// Find possible whole objects for a given part noun.
/// Returns None if the noun is not a known part of any whole.
pub fn find_bridging_wholes(part_noun: &str) -> Option<&'static [&'static str]> {
    let wholes = get_possible_wholes(&part_noun.to_lowercase());
    if wholes.is_empty() {
        None
    } else {
        Some(wholes)
    }
}

/// Check if a predicate is compatible with a subject's sort.
/// Returns true if compatible or no sort requirement exists.
pub fn check_sort_compatibility(predicate: &str, subject_sort: Sort) -> bool {
    match get_predicate_sort(&predicate.to_lowercase()) {
        Some(required) => subject_sort.is_compatible_with(required),
        None => true,
    }
}

/// Get the required sort for a predicate, if any.
pub fn required_sort(predicate: &str) -> Option<Sort> {
    get_predicate_sort(&predicate.to_lowercase())
}

```

---

### Module: progress

**File:** `src/progress.rs`

Additional source module.

```rust
use serde::{Deserialize, Serialize};
use std::collections::{HashMap, HashSet};

#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct UserProgress {
    pub xp: u64,
    pub level: u32,
    pub streak_days: u32,
    pub last_session: Option<String>,
    pub exercises: HashMap<String, ExerciseProgress>,
    pub modules: HashMap<String, ModuleProgress>,
    #[serde(default)]
    pub combo: u32,
    #[serde(default)]
    pub best_combo: u32,
    #[serde(default)]
    pub streak_freezes: u8,
    #[serde(default)]
    pub last_streak_date: Option<String>,
    #[serde(default)]
    pub achievements: HashSet<String>,
    #[serde(default)]
    pub title: Option<String>,
    #[serde(default)]
    pub last_weekly_freeze_date: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExerciseProgress {
    pub exercise_id: String,
    pub attempts: u32,
    pub correct_count: u32,
    pub last_attempt: Option<String>,
    pub srs: SrsData,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SrsData {
    pub ease_factor: f64,
    pub interval: u32,
    pub repetitions: u32,
    pub next_review: Option<String>,
}

impl Default for SrsData {
    fn default() -> Self {
        Self {
            ease_factor: 2.5,
            interval: 1,
            repetitions: 0,
            next_review: None,
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModuleProgress {
    pub module_id: String,
    pub unlocked: bool,
    pub completed: bool,
    pub stars: u8,
    pub best_score: u32,
    pub attempts: u32,
}

impl Default for ModuleProgress {
    fn default() -> Self {
        Self {
            module_id: String::new(),
            unlocked: false,
            completed: false,
            stars: 0,
            best_score: 0,
            attempts: 0,
        }
    }
}

impl UserProgress {
    pub fn new() -> Self {
        Self {
            level: 1,
            ..Default::default()
        }
    }

    pub fn load() -> Self {
        #[cfg(target_arch = "wasm32")]
        {
            crate::storage::load_raw()
                .and_then(|json| serde_json::from_str(&json).ok())
                .unwrap_or_else(Self::new)
        }
        #[cfg(not(target_arch = "wasm32"))]
        {
            Self::new()
        }
    }

    pub fn save(&self) {
        #[cfg(target_arch = "wasm32")]
        {
            if let Ok(json) = serde_json::to_string(self) {
                crate::storage::save_raw(&json);
            }
        }
    }

    pub fn add_xp(&mut self, amount: u64) {
        self.xp += amount;
        self.level = calculate_level(self.xp);
        self.save();
    }

    pub fn record_attempt(&mut self, exercise_id: &str, correct: bool) {
        let entry = self.exercises.entry(exercise_id.to_string()).or_insert_with(|| {
            ExerciseProgress {
                exercise_id: exercise_id.to_string(),
                attempts: 0,
                correct_count: 0,
                last_attempt: None,
                srs: SrsData::default(),
            }
        });

        entry.attempts += 1;
        if correct {
            entry.correct_count += 1;
        }

        self.save();
    }

    pub fn get_exercise_progress(&self, exercise_id: &str) -> Option<&ExerciseProgress> {
        self.exercises.get(exercise_id)
    }

    pub fn get_module_progress(&self, module_id: &str) -> Option<&ModuleProgress> {
        self.modules.get(module_id)
    }

    pub fn update_module_score(&mut self, module_id: &str, score: u32) {
        let entry = self.modules.entry(module_id.to_string()).or_insert_with(|| {
            ModuleProgress {
                module_id: module_id.to_string(),
                ..Default::default()
            }
        });

        entry.attempts += 1;
        if score > entry.best_score {
            entry.best_score = score;
        }

        self.save();
    }
}

pub fn calculate_level(xp: u64) -> u32 {
    ((xp as f64).sqrt() / 10.0).floor() as u32 + 1
}

pub fn xp_for_level(level: u32) -> u64 {
    let l = level as u64;
    l * l * 100
}

pub fn calculate_xp_reward(difficulty: u32, first_try: bool, streak_days: u32) -> u64 {
    let base: u64 = 10;
    let difficulty_bonus = (difficulty.saturating_sub(1) as u64) * 5;
    let first_try_bonus = if first_try { 5 } else { 0 };
    let streak_bonus = (streak_days.min(7) as u64) * 2;

    base + difficulty_bonus + first_try_bonus + streak_bonus
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_level_calculation() {
        assert_eq!(calculate_level(0), 1);
        assert_eq!(calculate_level(100), 2);
        assert_eq!(calculate_level(400), 3);
        assert_eq!(calculate_level(900), 4);
    }

    #[test]
    fn test_xp_reward() {
        assert_eq!(calculate_xp_reward(1, false, 0), 10);
        assert_eq!(calculate_xp_reward(1, true, 0), 15);
        assert_eq!(calculate_xp_reward(2, false, 0), 15);
        assert_eq!(calculate_xp_reward(1, false, 3), 16);
        assert_eq!(calculate_xp_reward(3, true, 5), 10 + 10 + 5 + 10);
    }

    #[test]
    fn test_user_progress_record() {
        let mut progress = UserProgress::new();
        progress.record_attempt("test_q1", true);
        progress.record_attempt("test_q1", false);

        let ex = progress.get_exercise_progress("test_q1").unwrap();
        assert_eq!(ex.attempts, 2);
        assert_eq!(ex.correct_count, 1);
    }
}

```

---

### Module: scope

**File:** `src/scope.rs`

Additional source module.

```rust
use std::collections::HashMap;
use crate::context::OwnershipState;

#[derive(Debug, Clone)]
pub struct ScopeEntry {
    pub symbol: String,
    pub ownership: OwnershipState,
}

impl ScopeEntry {
    pub fn variable(name: &str) -> Self {
        Self {
            symbol: name.to_string(),
            ownership: OwnershipState::Owned,
        }
    }
}

#[derive(Debug, Default)]
pub struct ScopeStack {
    scopes: Vec<HashMap<String, ScopeEntry>>,
}

impl ScopeStack {
    pub fn new() -> Self {
        Self::default()
    }

    pub fn push_scope(&mut self) {
        self.scopes.push(HashMap::new());
    }

    pub fn pop_scope(&mut self) {
        self.scopes.pop();
    }

    pub fn bind(&mut self, name: &str, entry: ScopeEntry) {
        if let Some(scope) = self.scopes.last_mut() {
            scope.insert(name.to_string(), entry);
        }
    }

    pub fn lookup(&self, name: &str) -> Option<&ScopeEntry> {
        for scope in self.scopes.iter().rev() {
            if let Some(entry) = scope.get(name) {
                return Some(entry);
            }
        }
        None
    }

    pub fn lookup_mut(&mut self, name: &str) -> Option<&mut ScopeEntry> {
        for scope in self.scopes.iter_mut().rev() {
            if let Some(entry) = scope.get_mut(name) {
                return Some(entry);
            }
        }
        None
    }
}

```

---

### Module: srs

**File:** `src/srs.rs`

Additional source module.

```rust
use crate::progress::SrsData;

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum ResponseQuality {
    Blackout = 0,
    Incorrect = 1,
    IncorrectEasy = 2,
    CorrectDifficult = 3,
    CorrectHesitation = 4,
    Perfect = 5,
}

impl ResponseQuality {
    pub fn from_score(score: u8) -> Self {
        match score {
            0 => Self::Blackout,
            1 => Self::Incorrect,
            2 => Self::IncorrectEasy,
            3 => Self::CorrectDifficult,
            4 => Self::CorrectHesitation,
            _ => Self::Perfect,
        }
    }

    pub fn is_correct(self) -> bool {
        (self as u8) >= 3
    }
}

pub fn sm2_update(srs: &mut SrsData, quality: ResponseQuality) {
    let q = quality as u8 as f64;

    if quality.is_correct() {
        srs.repetitions += 1;
        srs.interval = match srs.repetitions {
            1 => 1,
            2 => 6,
            _ => (srs.interval as f64 * srs.ease_factor).round() as u32,
        };

        srs.ease_factor += 0.1 - (5.0 - q) * (0.08 + (5.0 - q) * 0.02);
        if srs.ease_factor < 1.3 {
            srs.ease_factor = 1.3;
        }
    } else {
        srs.repetitions = 0;
        srs.interval = 1;
    }
}

pub fn calculate_next_review(current_date: &str, interval_days: u32) -> String {
    if let Ok(date) = parse_date(current_date) {
        let next = date + interval_days as i64;
        format_date(next)
    } else {
        current_date.to_string()
    }
}

pub fn is_due(next_review: Option<&str>, today: &str) -> bool {
    match next_review {
        None => true,
        Some(review_date) => {
            if let (Ok(review), Ok(now)) = (parse_date(review_date), parse_date(today)) {
                review <= now
            } else {
                true
            }
        }
    }
}

fn parse_date(date_str: &str) -> Result<i64, ()> {
    let parts: Vec<&str> = date_str.split('-').collect();
    if parts.len() != 3 {
        return Err(());
    }

    let year: i64 = parts[0].parse().map_err(|_| ())?;
    let month: i64 = parts[1].parse().map_err(|_| ())?;
    let day: i64 = parts[2].parse().map_err(|_| ())?;

    Ok(year * 10000 + month * 100 + day)
}

fn format_date(date_num: i64) -> String {
    let year = date_num / 10000;
    let month = (date_num % 10000) / 100;
    let day = date_num % 100;

    let (year, month, day) = normalize_date(year as i32, month as i32, day as i32);
    format!("{:04}-{:02}-{:02}", year, month, day)
}

fn normalize_date(year: i32, month: i32, day: i32) -> (i32, i32, i32) {
    let days_in_month = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31];

    let mut y = year;
    let mut m = month;
    let mut d = day;

    while d > days_in_month[(m - 1) as usize] {
        d -= days_in_month[(m - 1) as usize];
        m += 1;
        if m > 12 {
            m = 1;
            y += 1;
        }
    }

    (y, m, d)
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_sm2_first_correct() {
        let mut srs = SrsData::default();
        sm2_update(&mut srs, ResponseQuality::Perfect);

        assert_eq!(srs.repetitions, 1);
        assert_eq!(srs.interval, 1);
        assert!(srs.ease_factor > 2.5);
    }

    #[test]
    fn test_sm2_second_correct() {
        let mut srs = SrsData::default();
        sm2_update(&mut srs, ResponseQuality::Perfect);
        sm2_update(&mut srs, ResponseQuality::Perfect);

        assert_eq!(srs.repetitions, 2);
        assert_eq!(srs.interval, 6);
    }

    #[test]
    fn test_sm2_incorrect_resets() {
        let mut srs = SrsData::default();
        sm2_update(&mut srs, ResponseQuality::Perfect);
        sm2_update(&mut srs, ResponseQuality::Perfect);
        sm2_update(&mut srs, ResponseQuality::Incorrect);

        assert_eq!(srs.repetitions, 0);
        assert_eq!(srs.interval, 1);
    }

    #[test]
    fn test_sm2_ease_factor_minimum() {
        let mut srs = SrsData::default();
        srs.ease_factor = 1.3;
        sm2_update(&mut srs, ResponseQuality::CorrectDifficult);

        assert!(srs.ease_factor >= 1.3);
    }

    #[test]
    fn test_is_due_none() {
        assert!(is_due(None, "2025-01-01"));
    }

    #[test]
    fn test_is_due_past() {
        assert!(is_due(Some("2025-01-01"), "2025-01-02"));
    }

    #[test]
    fn test_is_due_future() {
        assert!(!is_due(Some("2025-01-05"), "2025-01-02"));
    }

    #[test]
    fn test_is_due_today() {
        assert!(is_due(Some("2025-01-01"), "2025-01-01"));
    }

    #[test]
    fn test_calculate_next_review() {
        let next = calculate_next_review("2025-01-15", 6);
        assert_eq!(next, "2025-01-21");
    }

    #[test]
    fn test_calculate_next_review_month_overflow() {
        let next = calculate_next_review("2025-01-28", 6);
        assert_eq!(next, "2025-02-03");
    }

    #[test]
    fn test_response_quality_is_correct() {
        assert!(!ResponseQuality::Blackout.is_correct());
        assert!(!ResponseQuality::Incorrect.is_correct());
        assert!(!ResponseQuality::IncorrectEasy.is_correct());
        assert!(ResponseQuality::CorrectDifficult.is_correct());
        assert!(ResponseQuality::CorrectHesitation.is_correct());
        assert!(ResponseQuality::Perfect.is_correct());
    }
}

```

---

### Module: storage

**File:** `src/storage.rs`

Additional source module.

```rust
use wasm_bindgen::prelude::*;

const PROGRESS_KEY: &str = "logos_user_progress";

#[wasm_bindgen]
extern "C" {
    #[wasm_bindgen(js_namespace = localStorage, js_name = getItem)]
    fn local_storage_get(key: &str) -> Option<String>;

    #[wasm_bindgen(js_namespace = localStorage, js_name = setItem)]
    fn local_storage_set(key: &str, value: &str);

    #[wasm_bindgen(js_namespace = localStorage, js_name = removeItem)]
    fn local_storage_remove(key: &str);
}

pub fn load_raw() -> Option<String> {
    local_storage_get(PROGRESS_KEY)
}

pub fn save_raw(json: &str) {
    local_storage_set(PROGRESS_KEY, json);
}

pub fn clear() {
    local_storage_remove(PROGRESS_KEY);
}

```

---

## Build Configuration

### Package Manifest

**File:** `Cargo.toml`

Rust package configuration with dependencies: bumpalo (arena allocator), dioxus (desktop UI).

```toml
[package]
name = "logos"
version = "0.1.0"
edition = "2021"
authors = ["Logicaffeine Team"]
license = "BUSL-1.1"
description = "English-to-Logic Transpiler targeting Logicaffeine notation"
build = "build.rs"

[workspace]
exclude = ["logos_core"]

[dependencies]
bumpalo = "3.14"
dioxus = { version = "0.6", features = ["web", "router"] }
wasm-bindgen = "0.2"
js-sys = "0.3"
web-sys = { version = "0.3", features = [
    "Document", "Element", "HtmlElement", "Window", "History",
    "HtmlDivElement", "Event", "KeyboardEvent", "InputEvent",
    "Storage", "Navigator", "Clipboard", "UrlSearchParams"
] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
getrandom = { version = "0.2", features = ["js"] }
rand = "0.8"
include_dir = "0.7"
gloo-timers = { version = "0.3", features = ["futures"] }
gloo-net = "0.6"

[build-dependencies]
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

[profile]

[profile.wasm-dev]
inherits = "dev"
opt-level = 1

[profile.server-dev]
inherits = "dev"

[profile.android-dev]
inherits = "dev"

```

---

### Build Script

**File:** `build.rs`

Generates compile-time lookup functions from lexicon.json. Expands verbs into irregular verb entries and feature-based VerbDbEntry records. Derives behavioral lists (is_ditransitive_verb, is_subject_control_verb, is_object_control_verb, is_raising_verb, is_opaque_verb, is_collective_verb, is_performative) from feature arrays. Generates lookup_verb_db(), lookup_noun_db(), lookup_adjective_db() returning metadata with feature slices. Produces is_* check functions for closed classes and morphology rules.

```rust
use serde::Deserialize;
use std::collections::HashMap;
use std::env;
use std::fs;
use std::io::Write;
use std::path::Path;

// ═══════════════════════════════════════════════════════════════════
// JSON Schema for Refactored Lexicon
// ═══════════════════════════════════════════════════════════════════

#[derive(Deserialize)]
struct RefactoredLexiconData {
    keywords: HashMap<String, String>,
    pronouns: Vec<PronounEntry>,
    articles: HashMap<String, String>,
    auxiliaries: HashMap<String, String>,
    presupposition_triggers: HashMap<String, String>,
    number_words: HashMap<String, u32>,
    verbs: Vec<VerbDefinition>,
    nouns: Vec<NounDefinition>,
    adjectives: Vec<AdjectiveDefinition>,
    prepositions: Vec<String>,
    adverbs: Vec<String>,
    scopal_adverbs: Vec<String>,
    temporal_adverbs: Vec<String>,
    #[serde(default)]
    particles: Vec<String>,
    #[serde(default)]
    phrasal_verbs: HashMap<String, PhrasalVerbEntry>,
    not_adverbs: Vec<String>,
    noun_patterns: Vec<String>,
    disambiguation_not_verbs: Vec<String>,
    morphology: Morphology,
    #[serde(default)]
    units: HashMap<String, String>,
    #[serde(default)]
    multi_word_expressions: Vec<MweEntry>,
    #[serde(default)]
    ontology: Option<OntologyData>,
    #[serde(default)]
    axioms: Option<AxiomData>,
}

#[derive(Deserialize)]
struct PronounEntry {
    word: String,
    gender: String,
    number: String,
    case: String,
}

#[derive(Deserialize)]
struct VerbDefinition {
    lemma: String,
    class: String,
    #[serde(default)]
    forms: Option<VerbForms>,
    #[serde(default)]
    regular: bool,
    #[serde(default)]
    features: Vec<String>,
}

#[derive(Deserialize, Default)]
struct VerbForms {
    #[serde(default)]
    present3s: Option<String>,
    #[serde(default)]
    past: Option<String>,
    #[serde(default)]
    participle: Option<String>,
    #[serde(default)]
    gerund: Option<String>,
}

#[derive(Deserialize)]
struct NounDefinition {
    lemma: String,
    #[serde(default)]
    forms: Option<NounForms>,
    #[serde(default)]
    features: Vec<String>,
    #[serde(default)]
    sort: Option<String>,
}

#[derive(Deserialize, Default)]
struct NounForms {
    #[serde(default)]
    plural: Option<String>,
}

#[derive(Deserialize)]
struct AdjectiveDefinition {
    lemma: String,
    #[serde(default)]
    regular: bool,
    #[serde(default)]
    features: Vec<String>,
}

#[derive(Deserialize)]
struct Morphology {
    needs_e_ing: Vec<String>,
    needs_e_ed: Vec<String>,
    stemming_exceptions: Vec<String>,
}

#[derive(Deserialize)]
struct MweEntry {
    pattern: Vec<String>,
    lemma: String,
    pos: String,
    #[serde(default)]
    class: Option<String>,
    #[serde(default)]
    features: Vec<String>,
}

#[derive(Deserialize)]
struct PhrasalVerbEntry {
    lemma: String,
    class: String,
}

#[derive(Deserialize, Default)]
struct OntologyData {
    #[serde(default)]
    part_whole: Vec<PartWholeEntry>,
    #[serde(default)]
    predicate_sorts: HashMap<String, String>,
}

#[derive(Deserialize)]
struct PartWholeEntry {
    whole: String,
    parts: Vec<String>,
}

#[derive(Deserialize, Default)]
struct AxiomData {
    #[serde(default)]
    nouns: HashMap<String, NounAxiom>,
    #[serde(default)]
    adjectives: HashMap<String, AdjectiveAxiom>,
    #[serde(default)]
    verbs: HashMap<String, VerbAxiom>,
}

#[derive(Deserialize, Default)]
struct NounAxiom {
    #[serde(default)]
    entails: Vec<String>,
    #[serde(default)]
    hypernyms: Vec<String>,
}

#[derive(Deserialize)]
struct AdjectiveAxiom {
    #[serde(rename = "type")]
    axiom_type: String,
}

#[derive(Deserialize, Default)]
struct VerbAxiom {
    #[serde(default)]
    entails: Option<String>,
    #[serde(default)]
    manner: Vec<String>,
}

// Intermediate representation for irregular verb entries
struct IrregularVerbEntry {
    word: String,
    lemma: String,
    time: String,
    aspect: String,
    class: String,
}

// Full verb database entry with features
struct VerbDbEntry {
    word: String,
    lemma: String,
    time: String,
    aspect: String,
    class: String,
    features: Vec<String>,
}

// Noun database entry with features
struct NounDbEntry {
    word: String,
    lemma: String,
    number: String,
    features: Vec<String>,
}

// Adjective database entry with features
struct AdjectiveDbEntry {
    word: String,
    lemma: String,
    features: Vec<String>,
}

// ═══════════════════════════════════════════════════════════════════
// Main Build Function
// ═══════════════════════════════════════════════════════════════════

fn main() {
    let manifest_dir = env::var("CARGO_MANIFEST_DIR").unwrap();
    let json_path = Path::new(&manifest_dir).join("assets/lexicon.json");

    println!("cargo:rerun-if-changed=assets/lexicon.json");

    let json_content = fs::read_to_string(&json_path)
        .unwrap_or_else(|_| panic!("Failed to read {}", json_path.display()));

    let data: RefactoredLexiconData = serde_json::from_str(&json_content)
        .unwrap_or_else(|e| panic!("Failed to parse refactored_lexicon.json: {}", e));

    let out_dir = env::var("OUT_DIR").unwrap();
    let dest_path = Path::new(&out_dir).join("lexicon_data.rs");
    let mut file = fs::File::create(&dest_path).unwrap();

    // Generate unchanged lookup functions
    generate_lookup_keyword(&mut file, &data.keywords);
    generate_lookup_pronoun(&mut file, &data.pronouns);
    generate_lookup_article(&mut file, &data.articles);
    generate_lookup_auxiliary(&mut file, &data.auxiliaries);
    generate_lookup_presup_trigger(&mut file, &data.presupposition_triggers);
    generate_word_to_number(&mut file, &data.number_words);

    // Expand verbs into irregular verb entries and generate lookup
    let irregular_verbs = expand_verbs_to_entries(&data.verbs);
    generate_lookup_irregular_verb(&mut file, &irregular_verbs);

    // Generate singularize from noun forms
    let irregular_plurals = derive_irregular_plurals(&data.nouns);
    generate_singularize(&mut file, &irregular_plurals);

    // Generate closed class checks
    generate_is_check(&mut file, "is_preposition", &data.prepositions);
    generate_is_check(&mut file, "is_noun_pattern", &data.noun_patterns);
    generate_is_check(&mut file, "is_scopal_adverb", &data.scopal_adverbs);
    generate_is_check(&mut file, "is_temporal_adverb", &data.temporal_adverbs);
    generate_is_check(&mut file, "is_particle", &data.particles);
    generate_is_check(&mut file, "is_adverb", &data.adverbs);
    generate_is_check(&mut file, "is_not_adverb", &data.not_adverbs);
    generate_is_check(&mut file, "is_disambiguation_not_verb", &data.disambiguation_not_verbs);
    generate_is_check(&mut file, "needs_e_ing", &data.morphology.needs_e_ing);
    generate_is_check(&mut file, "needs_e_ed", &data.morphology.needs_e_ed);
    generate_is_check(&mut file, "is_stemming_exception", &data.morphology.stemming_exceptions);
    generate_is_check(
        &mut file,
        "is_irregular_plural",
        &irregular_plurals.keys().cloned().collect::<Vec<_>>(),
    );

    // Derive behavioral lists from verb features
    let (
        ditransitive_verbs,
        subject_control_verbs,
        object_control_verbs,
        raising_verbs,
        opaque_verbs,
        collective_verbs,
        performatives,
        mixed_verbs,
    ) = derive_verb_feature_lists(&data.verbs);

    generate_is_check(&mut file, "is_ditransitive_verb", &ditransitive_verbs);
    generate_is_check(&mut file, "is_subject_control_verb", &subject_control_verbs);
    generate_is_check(&mut file, "is_object_control_verb", &object_control_verbs);
    generate_is_check(&mut file, "is_raising_verb", &raising_verbs);
    generate_is_check(&mut file, "is_opaque_verb", &opaque_verbs);
    generate_is_check(&mut file, "is_collective_verb", &collective_verbs);
    generate_is_check(&mut file, "is_performative", &performatives);
    generate_is_check(&mut file, "is_mixed_verb", &mixed_verbs);

    // Generate base verb list from all verb lemmas
    let base_verbs: Vec<String> = data.verbs.iter().map(|v| v.lemma.to_lowercase()).collect();
    generate_is_check(&mut file, "is_base_verb", &base_verbs);
    generate_is_check(&mut file, "is_base_verb_early", &base_verbs[..base_verbs.len().min(30)].to_vec());
    generate_is_check(&mut file, "is_infinitive_verb", &base_verbs);

    // Derive adjective lists from features
    let (adjectives, non_intersective, subsective, gradable) = derive_adjective_lists(&data.adjectives);
    generate_is_check(&mut file, "is_adjective", &adjectives);
    generate_is_check(&mut file, "is_non_intersective", &non_intersective);
    generate_is_check(&mut file, "is_subsective", &subsective);
    generate_is_check(&mut file, "is_gradable_adjective", &gradable);

    // Derive noun lists from features
    let (common_nouns, male_names, female_names, male_nouns, female_nouns) =
        derive_noun_lists(&data.nouns);
    generate_is_check(&mut file, "is_common_noun", &common_nouns);
    generate_is_check(&mut file, "is_male_name", &male_names);
    generate_is_check(&mut file, "is_female_name", &female_names);
    generate_is_check(&mut file, "is_male_noun", &male_nouns);
    generate_is_check(&mut file, "is_female_noun", &female_nouns);

    // Generate verb class lookup from verb definitions
    let (state_verbs, activity_verbs, accomplishment_verbs, achievement_verbs, semelfactive_verbs) =
        derive_verb_class_lists(&data.verbs);
    generate_lookup_verb_class(
        &mut file,
        &state_verbs,
        &activity_verbs,
        &accomplishment_verbs,
        &achievement_verbs,
        &semelfactive_verbs,
    );

    // Generate feature-based metadata databases
    let verb_db_entries = expand_verbs_to_db_entries(&data.verbs);
    generate_lookup_verb_db(&mut file, &verb_db_entries);

    let noun_db_entries = expand_nouns_to_db_entries(&data.nouns);
    generate_lookup_noun_db(&mut file, &noun_db_entries);

    let adjective_db_entries = expand_adjectives_to_db_entries(&data.adjectives);
    generate_lookup_adjective_db(&mut file, &adjective_db_entries);

    // Generate unit dimension lookup for degree semantics
    generate_lookup_unit_dimension(&mut file, &data.units);

    // Generate phrasal verb lookup for particle movement
    generate_lookup_phrasal_verb(&mut file, &data.phrasal_verbs);

    // Generate sort lookup for semantic type system
    generate_lookup_sort(&mut file, &data.nouns);

    // Generate MWE trie initialization
    let mwe_path = Path::new(&out_dir).join("mwe_data.rs");
    let mut mwe_file = fs::File::create(&mwe_path).unwrap();
    generate_mwe_trie_init(&mut mwe_file, &data.multi_word_expressions);

    // Generate ontology lookup functions
    let ontology_path = Path::new(&out_dir).join("ontology_data.rs");
    let mut ontology_file = fs::File::create(&ontology_path).unwrap();
    generate_ontology_data(&mut ontology_file, &data.ontology);

    // Generate axiom lookup functions
    let axiom_path = Path::new(&out_dir).join("axiom_data.rs");
    let mut axiom_file = fs::File::create(&axiom_path).unwrap();
    generate_axiom_data(&mut axiom_file, &data.axioms);
}

// ═══════════════════════════════════════════════════════════════════
// Verb Form Expansion
// ═══════════════════════════════════════════════════════════════════

fn expand_verbs_to_entries(verbs: &[VerbDefinition]) -> Vec<IrregularVerbEntry> {
    let mut entries = Vec::new();

    for verb in verbs {
        let lemma = &verb.lemma;
        let class = &verb.class;
        let lower_lemma = lemma.to_lowercase();

        // Always add the base form (present)
        entries.push(IrregularVerbEntry {
            word: lower_lemma.clone(),
            lemma: lemma.clone(),
            time: "Present".to_string(),
            aspect: "Simple".to_string(),
            class: class.clone(),
        });

        if let Some(forms) = &verb.forms {
            // Irregular verb with explicit forms
            if let Some(present3s) = &forms.present3s {
                entries.push(IrregularVerbEntry {
                    word: present3s.to_lowercase(),
                    lemma: lemma.clone(),
                    time: "Present".to_string(),
                    aspect: "Simple".to_string(),
                    class: class.clone(),
                });
            }

            if let Some(past) = &forms.past {
                entries.push(IrregularVerbEntry {
                    word: past.to_lowercase(),
                    lemma: lemma.clone(),
                    time: "Past".to_string(),
                    aspect: "Simple".to_string(),
                    class: class.clone(),
                });
            }

            if let Some(participle) = &forms.participle {
                // Participle is past aspect simple (for "has eaten", "was broken")
                entries.push(IrregularVerbEntry {
                    word: participle.to_lowercase(),
                    lemma: lemma.clone(),
                    time: "Past".to_string(),
                    aspect: "Simple".to_string(),
                    class: class.clone(),
                });
            }

            if let Some(gerund) = &forms.gerund {
                entries.push(IrregularVerbEntry {
                    word: gerund.to_lowercase(),
                    lemma: lemma.clone(),
                    time: "None".to_string(),
                    aspect: "Progressive".to_string(),
                    class: class.clone(),
                });
            }
        }
        // Note: Regular verbs (regular: true without forms) are handled by
        // Lexicon::lookup_verb's morphological rules, not the irregular table
    }

    entries
}

// ═══════════════════════════════════════════════════════════════════
// Feature Derivation Functions
// ═══════════════════════════════════════════════════════════════════

fn derive_verb_feature_lists(
    verbs: &[VerbDefinition],
) -> (
    Vec<String>,
    Vec<String>,
    Vec<String>,
    Vec<String>,
    Vec<String>,
    Vec<String>,
    Vec<String>,
    Vec<String>,
) {
    let mut ditransitive = Vec::new();
    let mut subject_control = Vec::new();
    let mut object_control = Vec::new();
    let mut raising = Vec::new();
    let mut opaque = Vec::new();
    let mut collective = Vec::new();
    let mut performative = Vec::new();
    let mut mixed = Vec::new();

    for verb in verbs {
        let lower = verb.lemma.to_lowercase();
        for feature in &verb.features {
            match feature.as_str() {
                "Ditransitive" => ditransitive.push(lower.clone()),
                "SubjectControl" => subject_control.push(lower.clone()),
                "ObjectControl" => object_control.push(lower.clone()),
                "Raising" => raising.push(lower.clone()),
                "Opaque" => {
                    // Include base form and conjugated forms for opaque verb checks
                    opaque.push(lower.clone());
                    opaque.push(format!("{}s", lower)); // third person singular
                    opaque.push(format!("{}ed", lower)); // past tense (regular)
                    // Also include irregular forms if present
                    if let Some(forms) = &verb.forms {
                        if let Some(past) = &forms.past {
                            opaque.push(past.to_lowercase());
                        }
                        if let Some(participle) = &forms.participle {
                            opaque.push(participle.to_lowercase());
                        }
                    }
                }
                "Collective" => collective.push(lower.clone()),
                "Performative" => performative.push(lower.clone()),
                "Mixed" => mixed.push(lower.clone()),
                _ => {}
            }
        }
    }

    (
        ditransitive,
        subject_control,
        object_control,
        raising,
        opaque,
        collective,
        performative,
        mixed,
    )
}

fn derive_verb_class_lists(
    verbs: &[VerbDefinition],
) -> (Vec<String>, Vec<String>, Vec<String>, Vec<String>, Vec<String>) {
    let mut state = Vec::new();
    let mut activity = Vec::new();
    let mut accomplishment = Vec::new();
    let mut achievement = Vec::new();
    let mut semelfactive = Vec::new();

    for verb in verbs {
        let lower = verb.lemma.to_lowercase();
        match verb.class.as_str() {
            "State" => state.push(lower),
            "Activity" => activity.push(lower),
            "Accomplishment" => accomplishment.push(lower),
            "Achievement" => achievement.push(lower),
            "Semelfactive" => semelfactive.push(lower),
            _ => activity.push(lower),
        }
    }

    (state, activity, accomplishment, achievement, semelfactive)
}

fn derive_adjective_lists(
    adjectives: &[AdjectiveDefinition],
) -> (Vec<String>, Vec<String>, Vec<String>, Vec<String>) {
    let mut all_adj = Vec::new();
    let mut non_intersective = Vec::new();
    let mut subsective = Vec::new();
    let mut gradable = Vec::new();

    for adj in adjectives {
        let lower = adj.lemma.to_lowercase();
        all_adj.push(lower.clone());

        for feature in &adj.features {
            match feature.as_str() {
                "NonIntersective" => non_intersective.push(lower.clone()),
                "Subsective" => subsective.push(lower.clone()),
                "Gradable" => gradable.push(lower.clone()),
                _ => {}
            }
        }
    }

    (all_adj, non_intersective, subsective, gradable)
}

fn derive_noun_lists(
    nouns: &[NounDefinition],
) -> (Vec<String>, Vec<String>, Vec<String>, Vec<String>, Vec<String>) {
    let mut common_nouns = Vec::new();
    let mut male_names = Vec::new();
    let mut female_names = Vec::new();
    let mut male_nouns = Vec::new();
    let mut female_nouns = Vec::new();

    for noun in nouns {
        let lower = noun.lemma.to_lowercase();
        let is_proper = noun.features.iter().any(|f| f == "Proper");
        let is_masculine = noun.features.iter().any(|f| f == "Masculine");
        let is_feminine = noun.features.iter().any(|f| f == "Feminine");

        if is_proper {
            if is_masculine {
                male_names.push(lower.clone());
            }
            if is_feminine {
                female_names.push(lower.clone());
            }
        } else {
            common_nouns.push(lower.clone());
            if is_masculine {
                male_nouns.push(lower.clone());
            }
            if is_feminine {
                female_nouns.push(lower.clone());
            }
        }
    }

    (common_nouns, male_names, female_names, male_nouns, female_nouns)
}

fn derive_irregular_plurals(nouns: &[NounDefinition]) -> HashMap<String, String> {
    let mut plurals = HashMap::new();
    for noun in nouns {
        if let Some(forms) = &noun.forms {
            if let Some(plural) = &forms.plural {
                plurals.insert(plural.to_lowercase(), noun.lemma.clone());
            }
        }
    }
    plurals
}

// ═══════════════════════════════════════════════════════════════════
// Code Generation Functions
// ═══════════════════════════════════════════════════════════════════

fn generate_lookup_keyword(file: &mut fs::File, keywords: &HashMap<String, String>) {
    writeln!(
        file,
        "pub fn lookup_keyword(s: &str) -> Option<crate::token::TokenType> {{"
    )
    .unwrap();
    writeln!(file, "    match s.to_lowercase().as_str() {{").unwrap();

    for (word, token_type) in keywords {
        let token_expr = match token_type.as_str() {
            "All" => "crate::token::TokenType::All",
            "No" => "crate::token::TokenType::No",
            "Some" => "crate::token::TokenType::Some",
            "Any" => "crate::token::TokenType::Any",
            "Most" => "crate::token::TokenType::Most",
            "Few" => "crate::token::TokenType::Few",
            "Many" => "crate::token::TokenType::Many",
            "And" => "crate::token::TokenType::And",
            "Or" => "crate::token::TokenType::Or",
            "If" => "crate::token::TokenType::If",
            "Then" => "crate::token::TokenType::Then",
            "Not" => "crate::token::TokenType::Not",
            "Is" => "crate::token::TokenType::Is",
            "Are" => "crate::token::TokenType::Are",
            "Was" => "crate::token::TokenType::Was",
            "Were" => "crate::token::TokenType::Were",
            "That" => "crate::token::TokenType::That",
            "Who" => "crate::token::TokenType::Who",
            "What" => "crate::token::TokenType::What",
            "Where" => "crate::token::TokenType::Where",
            "When" => "crate::token::TokenType::When",
            "Why" => "crate::token::TokenType::Why",
            "Does" => "crate::token::TokenType::Does",
            "Do" => "crate::token::TokenType::Do",
            "Must" => "crate::token::TokenType::Must",
            "Shall" => "crate::token::TokenType::Shall",
            "Should" => "crate::token::TokenType::Should",
            "Can" => "crate::token::TokenType::Can",
            "May" => "crate::token::TokenType::May",
            "Cannot" => "crate::token::TokenType::Cannot",
            "Would" => "crate::token::TokenType::Would",
            "Could" => "crate::token::TokenType::Could",
            "Had" => "crate::token::TokenType::Had",
            "Than" => "crate::token::TokenType::Than",
            "Reflexive" => "crate::token::TokenType::Reflexive",
            "Because" => "crate::token::TokenType::Because",
            "Anything" => "crate::token::TokenType::Anything",
            "Anyone" => "crate::token::TokenType::Anyone",
            "Nothing" => "crate::token::TokenType::Nothing",
            "Nobody" => "crate::token::TokenType::Nobody",
            "Nowhere" => "crate::token::TokenType::Nowhere",
            "Ever" => "crate::token::TokenType::Ever",
            "Never" => "crate::token::TokenType::Never",
            "Repeat" => "crate::token::TokenType::Repeat",
            "For" => "crate::token::TokenType::For",
            "In" => "crate::token::TokenType::In",
            "From" => "crate::token::TokenType::From",
            _ => continue,
        };
        writeln!(file, "        \"{}\" => Some({}),", word, token_expr).unwrap();
    }

    writeln!(file, "        _ => None,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}\n").unwrap();
}

fn format_pronoun_token(p: &PronounEntry) -> String {
    let gender = match p.gender.as_str() {
        "Male" => "crate::context::Gender::Male",
        "Female" => "crate::context::Gender::Female",
        "Neuter" => "crate::context::Gender::Neuter",
        _ => "crate::context::Gender::Unknown",
    };
    let number = match p.number.as_str() {
        "Singular" => "crate::context::Number::Singular",
        _ => "crate::context::Number::Plural",
    };
    let case = match p.case.as_str() {
        "Subject" => "crate::context::Case::Subject",
        "Possessive" => "crate::context::Case::Possessive",
        _ => "crate::context::Case::Object",
    };
    format!(
        "crate::token::TokenType::Pronoun {{ gender: {}, number: {}, case: {} }}",
        gender, number, case
    )
}

fn generate_lookup_pronoun(file: &mut fs::File, pronouns: &[PronounEntry]) {
    use std::collections::BTreeMap;

    writeln!(
        file,
        "pub fn lookup_pronoun(s: &str) -> Option<crate::token::TokenType> {{"
    )
    .unwrap();
    writeln!(file, "    match s.to_lowercase().as_str() {{").unwrap();

    let mut map: BTreeMap<String, Vec<&PronounEntry>> = BTreeMap::new();
    for p in pronouns {
        map.entry(p.word.to_lowercase()).or_default().push(p);
    }

    for (word, entries) in map {
        if entries.len() == 1 {
            let code = format_pronoun_token(entries[0]);
            writeln!(file, "        \"{}\" => Some({}),", word, code).unwrap();
        } else {
            let primary_code = format_pronoun_token(entries[0]);
            let mut alt_codes = Vec::new();
            for p in &entries[1..] {
                alt_codes.push(format_pronoun_token(p));
            }
            let alts_str = alt_codes.join(", ");

            writeln!(
                file,
                "        \"{}\" => Some(crate::token::TokenType::Ambiguous {{ primary: Box::new({}), alternatives: vec![{}] }}),",
                word, primary_code, alts_str
            ).unwrap();
        }
    }

    writeln!(file, "        _ => None,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}\n").unwrap();
}

fn generate_lookup_article(file: &mut fs::File, articles: &HashMap<String, String>) {
    writeln!(
        file,
        "pub fn lookup_article(s: &str) -> Option<crate::lexicon::Definiteness> {{"
    )
    .unwrap();
    writeln!(file, "    match s.to_lowercase().as_str() {{").unwrap();

    for (word, def) in articles {
        let def_expr = match def.as_str() {
            "Definite" => "crate::lexicon::Definiteness::Definite",
            "Proximal" => "crate::lexicon::Definiteness::Proximal",
            "Distal" => "crate::lexicon::Definiteness::Distal",
            _ => "crate::lexicon::Definiteness::Indefinite",
        };
        writeln!(file, "        \"{}\" => Some({}),", word, def_expr).unwrap();
    }

    writeln!(file, "        _ => None,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}\n").unwrap();
}

fn generate_lookup_auxiliary(file: &mut fs::File, auxiliaries: &HashMap<String, String>) {
    writeln!(
        file,
        "pub fn lookup_auxiliary(s: &str) -> Option<crate::lexicon::Time> {{"
    )
    .unwrap();
    writeln!(file, "    match s.to_lowercase().as_str() {{").unwrap();

    for (word, time) in auxiliaries {
        let time_expr = match time.as_str() {
            "Future" => "crate::lexicon::Time::Future",
            "Past" => "crate::lexicon::Time::Past",
            "Present" => "crate::lexicon::Time::Present",
            _ => "crate::lexicon::Time::None",
        };
        writeln!(file, "        \"{}\" => Some({}),", word, time_expr).unwrap();
    }

    writeln!(file, "        _ => None,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}\n").unwrap();
}

fn generate_lookup_irregular_verb(file: &mut fs::File, verbs: &[IrregularVerbEntry]) {
    use std::collections::BTreeMap;

    writeln!(
        file,
        "pub fn lookup_irregular_verb(s: &str) -> Option<crate::lexicon::VerbEntry> {{"
    )
    .unwrap();
    writeln!(file, "    match s.to_lowercase().as_str() {{").unwrap();

    let mut seen: BTreeMap<String, &IrregularVerbEntry> = BTreeMap::new();
    for v in verbs {
        seen.entry(v.word.to_lowercase()).or_insert(v);
    }

    for (word, v) in seen {
        let time_expr = match v.time.as_str() {
            "Past" => "crate::lexicon::Time::Past",
            "Present" => "crate::lexicon::Time::Present",
            "Future" => "crate::lexicon::Time::Future",
            _ => "crate::lexicon::Time::None",
        };
        let aspect_expr = match v.aspect.as_str() {
            "Progressive" => "crate::lexicon::Aspect::Progressive",
            "Perfect" => "crate::lexicon::Aspect::Perfect",
            _ => "crate::lexicon::Aspect::Simple",
        };
        let class_expr = match v.class.as_str() {
            "State" => "crate::lexicon::VerbClass::State",
            "Activity" => "crate::lexicon::VerbClass::Activity",
            "Accomplishment" => "crate::lexicon::VerbClass::Accomplishment",
            "Achievement" => "crate::lexicon::VerbClass::Achievement",
            "Semelfactive" => "crate::lexicon::VerbClass::Semelfactive",
            _ => "crate::lexicon::VerbClass::Activity",
        };

        writeln!(
            file,
            "        \"{}\" => Some(crate::lexicon::VerbEntry {{ lemma: \"{}\".to_string(), time: {}, aspect: {}, class: {} }}),",
            word, v.lemma, time_expr, aspect_expr, class_expr
        )
        .unwrap();
    }

    writeln!(file, "        _ => None,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}\n").unwrap();
}

fn generate_lookup_presup_trigger(file: &mut fs::File, triggers: &HashMap<String, String>) {
    writeln!(
        file,
        "pub fn lookup_presup_trigger(s: &str) -> Option<crate::token::PresupKind> {{"
    )
    .unwrap();
    writeln!(file, "    match s.to_lowercase().as_str() {{").unwrap();

    for (word, kind) in triggers {
        let kind_expr = match kind.as_str() {
            "Stop" => "crate::token::PresupKind::Stop",
            "Start" => "crate::token::PresupKind::Start",
            "Regret" => "crate::token::PresupKind::Regret",
            "Continue" => "crate::token::PresupKind::Continue",
            "Realize" => "crate::token::PresupKind::Realize",
            "Know" => "crate::token::PresupKind::Know",
            _ => continue,
        };
        writeln!(file, "        \"{}\" => Some({}),", word, kind_expr).unwrap();
    }

    writeln!(file, "        _ => None,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}\n").unwrap();
}

fn generate_singularize(file: &mut fs::File, plurals: &HashMap<String, String>) {
    writeln!(
        file,
        "pub fn singularize(s: &str) -> Option<&'static str> {{"
    )
    .unwrap();
    writeln!(file, "    match s.to_lowercase().as_str() {{").unwrap();

    for (plural, singular) in plurals {
        writeln!(file, "        \"{}\" => Some(\"{}\"),", plural, singular).unwrap();
    }

    writeln!(file, "        _ => None,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}\n").unwrap();
}

fn generate_word_to_number(file: &mut fs::File, numbers: &HashMap<String, u32>) {
    writeln!(
        file,
        "pub fn word_to_number(s: &str) -> Option<u32> {{"
    )
    .unwrap();
    writeln!(file, "    match s.to_lowercase().as_str() {{").unwrap();

    for (word, num) in numbers {
        writeln!(file, "        \"{}\" => Some({}),", word, num).unwrap();
    }

    writeln!(file, "        _ => None,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}\n").unwrap();
}

fn generate_is_check(file: &mut fs::File, fn_name: &str, words: &[String]) {
    use std::collections::BTreeSet;

    writeln!(file, "pub fn {}(s: &str) -> bool {{", fn_name).unwrap();
    writeln!(file, "    match s.to_lowercase().as_str() {{").unwrap();

    let unique_words: BTreeSet<String> = words.iter().map(|w| w.to_lowercase()).collect();
    for word in unique_words {
        writeln!(file, "        \"{}\" => true,", word).unwrap();
    }

    writeln!(file, "        _ => false,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}\n").unwrap();
}

fn generate_lookup_verb_class(
    file: &mut fs::File,
    state_verbs: &[String],
    activity_verbs: &[String],
    accomplishment_verbs: &[String],
    achievement_verbs: &[String],
    semelfactive_verbs: &[String],
) {
    use std::collections::BTreeMap;

    writeln!(
        file,
        "pub fn lookup_verb_class(lemma: &str) -> crate::lexicon::VerbClass {{"
    )
    .unwrap();
    writeln!(file, "    match lemma.to_lowercase().as_str() {{").unwrap();

    let mut verb_classes: BTreeMap<String, &str> = BTreeMap::new();
    for verb in state_verbs {
        verb_classes.insert(verb.to_lowercase(), "State");
    }
    for verb in activity_verbs {
        verb_classes.entry(verb.to_lowercase()).or_insert("Activity");
    }
    for verb in accomplishment_verbs {
        verb_classes.entry(verb.to_lowercase()).or_insert("Accomplishment");
    }
    for verb in achievement_verbs {
        verb_classes.entry(verb.to_lowercase()).or_insert("Achievement");
    }
    for verb in semelfactive_verbs {
        verb_classes.entry(verb.to_lowercase()).or_insert("Semelfactive");
    }

    for (verb, class) in verb_classes {
        let class_expr = match class {
            "State" => "crate::lexicon::VerbClass::State",
            "Activity" => "crate::lexicon::VerbClass::Activity",
            "Accomplishment" => "crate::lexicon::VerbClass::Accomplishment",
            "Achievement" => "crate::lexicon::VerbClass::Achievement",
            "Semelfactive" => "crate::lexicon::VerbClass::Semelfactive",
            _ => "crate::lexicon::VerbClass::Activity",
        };
        writeln!(file, "        \"{}\" => {},", verb, class_expr).unwrap();
    }

    writeln!(file, "        _ => crate::lexicon::VerbClass::Activity,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}\n").unwrap();
}

// ═══════════════════════════════════════════════════════════════════
// Feature-Based Database Generation
// ═══════════════════════════════════════════════════════════════════

fn expand_verbs_to_db_entries(verbs: &[VerbDefinition]) -> Vec<VerbDbEntry> {
    let mut entries = Vec::new();

    for verb in verbs {
        let lemma = &verb.lemma;
        let class = &verb.class;
        let features = verb.features.clone();
        let lower_lemma = lemma.to_lowercase();

        // Base form (present)
        entries.push(VerbDbEntry {
            word: lower_lemma.clone(),
            lemma: lemma.clone(),
            time: "Present".to_string(),
            aspect: "Simple".to_string(),
            class: class.clone(),
            features: features.clone(),
        });

        if let Some(forms) = &verb.forms {
            if let Some(present3s) = &forms.present3s {
                entries.push(VerbDbEntry {
                    word: present3s.to_lowercase(),
                    lemma: lemma.clone(),
                    time: "Present".to_string(),
                    aspect: "Simple".to_string(),
                    class: class.clone(),
                    features: features.clone(),
                });
            }

            if let Some(past) = &forms.past {
                entries.push(VerbDbEntry {
                    word: past.to_lowercase(),
                    lemma: lemma.clone(),
                    time: "Past".to_string(),
                    aspect: "Simple".to_string(),
                    class: class.clone(),
                    features: features.clone(),
                });
            }

            if let Some(participle) = &forms.participle {
                entries.push(VerbDbEntry {
                    word: participle.to_lowercase(),
                    lemma: lemma.clone(),
                    time: "Past".to_string(),
                    aspect: "Simple".to_string(),
                    class: class.clone(),
                    features: features.clone(),
                });
            }

            if let Some(gerund) = &forms.gerund {
                entries.push(VerbDbEntry {
                    word: gerund.to_lowercase(),
                    lemma: lemma.clone(),
                    time: "None".to_string(),
                    aspect: "Progressive".to_string(),
                    class: class.clone(),
                    features: features.clone(),
                });
            }
        }
    }

    entries
}

fn expand_nouns_to_db_entries(nouns: &[NounDefinition]) -> Vec<NounDbEntry> {
    let mut entries = Vec::new();

    for noun in nouns {
        let lemma = &noun.lemma;
        let features = noun.features.clone();
        let lower_lemma = lemma.to_lowercase();

        // Singular form
        entries.push(NounDbEntry {
            word: lower_lemma.clone(),
            lemma: lemma.clone(),
            number: "Singular".to_string(),
            features: features.clone(),
        });

        // Plural form
        if let Some(forms) = &noun.forms {
            if let Some(plural) = &forms.plural {
                entries.push(NounDbEntry {
                    word: plural.to_lowercase(),
                    lemma: lemma.clone(),
                    number: "Plural".to_string(),
                    features: features.clone(),
                });
            }
        }
    }

    entries
}

fn expand_adjectives_to_db_entries(adjectives: &[AdjectiveDefinition]) -> Vec<AdjectiveDbEntry> {
    let mut entries = Vec::new();

    for adj in adjectives {
        let lemma = &adj.lemma;
        let features = adj.features.clone();
        let lower_lemma = lemma.to_lowercase();

        entries.push(AdjectiveDbEntry {
            word: lower_lemma,
            lemma: lemma.clone(),
            features,
        });
    }

    entries
}

fn format_features(features: &[String]) -> String {
    if features.is_empty() {
        return "&[]".to_string();
    }
    let feature_strs: Vec<String> = features
        .iter()
        .map(|f| format!("crate::lexicon::Feature::{}", f))
        .collect();
    format!("&[{}]", feature_strs.join(", "))
}

fn generate_lookup_verb_db(file: &mut fs::File, entries: &[VerbDbEntry]) {
    use std::collections::BTreeMap;

    writeln!(
        file,
        "pub fn lookup_verb_db(word: &str) -> Option<crate::lexicon::VerbMetadata> {{"
    )
    .unwrap();
    writeln!(file, "    match word.to_lowercase().as_str() {{").unwrap();

    let mut seen: BTreeMap<String, &VerbDbEntry> = BTreeMap::new();
    for entry in entries {
        seen.entry(entry.word.to_lowercase()).or_insert(entry);
    }

    for (word, entry) in seen {
        let time_expr = match entry.time.as_str() {
            "Past" => "crate::lexicon::Time::Past",
            "Present" => "crate::lexicon::Time::Present",
            "Future" => "crate::lexicon::Time::Future",
            _ => "crate::lexicon::Time::None",
        };
        let aspect_expr = match entry.aspect.as_str() {
            "Progressive" => "crate::lexicon::Aspect::Progressive",
            "Perfect" => "crate::lexicon::Aspect::Perfect",
            _ => "crate::lexicon::Aspect::Simple",
        };
        let class_expr = match entry.class.as_str() {
            "State" => "crate::lexicon::VerbClass::State",
            "Activity" => "crate::lexicon::VerbClass::Activity",
            "Accomplishment" => "crate::lexicon::VerbClass::Accomplishment",
            "Achievement" => "crate::lexicon::VerbClass::Achievement",
            "Semelfactive" => "crate::lexicon::VerbClass::Semelfactive",
            _ => "crate::lexicon::VerbClass::Activity",
        };
        let features_expr = format_features(&entry.features);

        writeln!(
            file,
            "        \"{}\" => Some(crate::lexicon::VerbMetadata {{ lemma: \"{}\", class: {}, time: {}, aspect: {}, features: {} }}),",
            word, entry.lemma, class_expr, time_expr, aspect_expr, features_expr
        )
        .unwrap();
    }

    writeln!(file, "        _ => None,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}\n").unwrap();
}

fn generate_lookup_noun_db(file: &mut fs::File, entries: &[NounDbEntry]) {
    use std::collections::BTreeMap;

    writeln!(
        file,
        "pub fn lookup_noun_db(word: &str) -> Option<crate::lexicon::NounMetadata> {{"
    )
    .unwrap();
    writeln!(file, "    match word.to_lowercase().as_str() {{").unwrap();

    let mut seen: BTreeMap<String, &NounDbEntry> = BTreeMap::new();
    for entry in entries {
        seen.entry(entry.word.to_lowercase()).or_insert(entry);
    }

    for (word, entry) in seen {
        let number_expr = match entry.number.as_str() {
            "Plural" => "crate::lexicon::Number::Plural",
            _ => "crate::lexicon::Number::Singular",
        };
        let features_expr = format_features(&entry.features);

        writeln!(
            file,
            "        \"{}\" => Some(crate::lexicon::NounMetadata {{ lemma: \"{}\", number: {}, features: {} }}),",
            word, entry.lemma, number_expr, features_expr
        )
        .unwrap();
    }

    writeln!(file, "        _ => None,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}\n").unwrap();
}

fn generate_lookup_adjective_db(file: &mut fs::File, entries: &[AdjectiveDbEntry]) {
    use std::collections::BTreeMap;

    writeln!(
        file,
        "pub fn lookup_adjective_db(word: &str) -> Option<crate::lexicon::AdjectiveMetadata> {{"
    )
    .unwrap();
    writeln!(file, "    match word.to_lowercase().as_str() {{").unwrap();

    let mut seen: BTreeMap<String, &AdjectiveDbEntry> = BTreeMap::new();
    for entry in entries {
        seen.entry(entry.word.to_lowercase()).or_insert(entry);
    }

    for (word, entry) in seen {
        let features_expr = format_features(&entry.features);

        writeln!(
            file,
            "        \"{}\" => Some(crate::lexicon::AdjectiveMetadata {{ lemma: \"{}\", features: {} }}),",
            word, entry.lemma, features_expr
        )
        .unwrap();
    }

    writeln!(file, "        _ => None,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}\n").unwrap();
}

fn generate_lookup_unit_dimension(file: &mut fs::File, units: &HashMap<String, String>) {
    writeln!(
        file,
        "pub fn lookup_unit_dimension(word: &str) -> Option<crate::ast::Dimension> {{"
    )
    .unwrap();
    writeln!(file, "    match word.to_lowercase().as_str() {{").unwrap();

    for (word, dimension) in units {
        let dim_expr = match dimension.as_str() {
            "Length" => "crate::ast::Dimension::Length",
            "Time" => "crate::ast::Dimension::Time",
            "Weight" => "crate::ast::Dimension::Weight",
            "Temperature" => "crate::ast::Dimension::Temperature",
            "Cardinality" => "crate::ast::Dimension::Cardinality",
            _ => continue,
        };
        writeln!(file, "        \"{}\" => Some({}),", word, dim_expr).unwrap();
    }

    writeln!(file, "        _ => None,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}\n").unwrap();
}

fn generate_lookup_phrasal_verb(file: &mut fs::File, phrasal_verbs: &HashMap<String, PhrasalVerbEntry>) {
    writeln!(
        file,
        "pub fn lookup_phrasal_verb(verb: &str, particle: &str) -> Option<(&'static str, crate::lexicon::VerbClass)> {{"
    )
    .unwrap();
    writeln!(file, "    let key = format!(\"{{}}_{{}}\", verb.to_lowercase(), particle.to_lowercase());").unwrap();
    writeln!(file, "    match key.as_str() {{").unwrap();

    for (key, entry) in phrasal_verbs {
        let class_expr = match entry.class.as_str() {
            "State" => "crate::lexicon::VerbClass::State",
            "Activity" => "crate::lexicon::VerbClass::Activity",
            "Accomplishment" => "crate::lexicon::VerbClass::Accomplishment",
            "Achievement" => "crate::lexicon::VerbClass::Achievement",
            "Semelfactive" => "crate::lexicon::VerbClass::Semelfactive",
            _ => "crate::lexicon::VerbClass::Activity",
        };
        writeln!(
            file,
            "        \"{}\" => Some((\"{}\", {})),",
            key, entry.lemma, class_expr
        )
        .unwrap();
    }

    writeln!(file, "        _ => None,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}\n").unwrap();
}

fn generate_lookup_sort(file: &mut fs::File, nouns: &[NounDefinition]) {
    writeln!(
        file,
        "pub fn lookup_sort(word: &str) -> Option<crate::lexicon::Sort> {{"
    )
    .unwrap();
    writeln!(file, "    match word.to_lowercase().as_str() {{").unwrap();

    for noun in nouns {
        if let Some(sort) = &noun.sort {
            let sort_expr = match sort.as_str() {
                "Entity" => "crate::lexicon::Sort::Entity",
                "Physical" => "crate::lexicon::Sort::Physical",
                "Animate" => "crate::lexicon::Sort::Animate",
                "Human" => "crate::lexicon::Sort::Human",
                "Plant" => "crate::lexicon::Sort::Plant",
                "Place" => "crate::lexicon::Sort::Place",
                "Time" => "crate::lexicon::Sort::Time",
                "Abstract" => "crate::lexicon::Sort::Abstract",
                "Information" => "crate::lexicon::Sort::Information",
                "Event" => "crate::lexicon::Sort::Event",
                "Celestial" => "crate::lexicon::Sort::Celestial",
                "Value" => "crate::lexicon::Sort::Value",
                "Group" => "crate::lexicon::Sort::Group",
                _ => continue,
            };
            writeln!(
                file,
                "        \"{}\" => Some({}),",
                noun.lemma.to_lowercase(),
                sort_expr
            )
            .unwrap();
        }
    }

    writeln!(file, "        _ => None,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}\n").unwrap();
}

// ═══════════════════════════════════════════════════════════════════
// Multi-Word Expression (MWE) Generation
// ═══════════════════════════════════════════════════════════════════

fn generate_mwe_trie_init(file: &mut fs::File, mwes: &[MweEntry]) {
    writeln!(file, "/// Build the MWE trie from lexicon data.").unwrap();
    writeln!(file, "pub fn build_mwe_trie() -> MweTrie {{").unwrap();
    writeln!(file, "    let mut trie = MweTrie::default();").unwrap();

    for mwe in mwes {
        let pattern: Vec<String> = mwe
            .pattern
            .iter()
            .map(|s| format!("\"{}\"", s.to_lowercase()))
            .collect();
        let class_expr = match &mwe.class {
            Some(c) => format!("Some(crate::lexicon::VerbClass::{})", c),
            None => "None".to_string(),
        };
        writeln!(
            file,
            "    trie.insert(&[{}], MweTarget {{ lemma: \"{}\", pos: \"{}\", class: {} }});",
            pattern.join(", "),
            mwe.lemma,
            mwe.pos,
            class_expr
        )
        .unwrap();
    }

    writeln!(file, "    trie").unwrap();
    writeln!(file, "}}").unwrap();
}

fn generate_ontology_data(file: &mut fs::File, ontology: &Option<OntologyData>) {
    let default_ontology = OntologyData::default();
    let ontology = ontology.as_ref().unwrap_or(&default_ontology);

    // Build reverse mapping: part -> list of wholes
    let mut part_to_wholes: HashMap<String, Vec<String>> = HashMap::new();
    for entry in &ontology.part_whole {
        for part in &entry.parts {
            part_to_wholes
                .entry(part.to_lowercase())
                .or_default()
                .push(entry.whole.clone());
        }
    }

    // Generate get_possible_wholes function
    writeln!(file, "/// Get possible whole objects for a given part noun.").unwrap();
    writeln!(file, "pub fn get_possible_wholes(part: &str) -> &'static [&'static str] {{").unwrap();
    writeln!(file, "    match part {{").unwrap();
    for (part, wholes) in &part_to_wholes {
        let wholes_str: Vec<String> = wholes.iter().map(|w| format!("\"{}\"", w)).collect();
        writeln!(file, "        \"{}\" => &[{}],", part, wholes_str.join(", ")).unwrap();
    }
    writeln!(file, "        _ => &[],").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}").unwrap();
    writeln!(file).unwrap();

    // Generate get_predicate_sort function
    writeln!(file, "/// Get the required sort for a predicate (adjective or verb).").unwrap();
    writeln!(file, "pub fn get_predicate_sort(predicate: &str) -> Option<crate::lexicon::Sort> {{").unwrap();
    writeln!(file, "    match predicate {{").unwrap();
    for (predicate, sort) in &ontology.predicate_sorts {
        writeln!(file, "        \"{}\" => Some(crate::lexicon::Sort::{}),", predicate.to_lowercase(), sort).unwrap();
    }
    writeln!(file, "        _ => None,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}").unwrap();
}

// ═══════════════════════════════════════════════════════════════════
// Axiom (Meaning Postulate) Generation
// ═══════════════════════════════════════════════════════════════════

fn generate_axiom_data(file: &mut fs::File, axioms: &Option<AxiomData>) {
    let default_axioms = AxiomData::default();
    let axioms = axioms.as_ref().unwrap_or(&default_axioms);

    // Generate lookup_noun_entailments
    writeln!(file, "/// Get entailment predicates for a noun (e.g., bachelor -> [Unmarried, Male]).").unwrap();
    writeln!(file, "pub fn lookup_noun_entailments(noun: &str) -> &'static [&'static str] {{").unwrap();
    writeln!(file, "    match noun.to_lowercase().as_str() {{").unwrap();
    for (noun, axiom) in &axioms.nouns {
        if !axiom.entails.is_empty() {
            let entails_str: Vec<String> = axiom.entails.iter().map(|e| format!("\"{}\"", e)).collect();
            writeln!(file, "        \"{}\" => &[{}],", noun, entails_str.join(", ")).unwrap();
        }
    }
    writeln!(file, "        _ => &[],").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}").unwrap();
    writeln!(file).unwrap();

    // Generate lookup_noun_hypernyms
    writeln!(file, "/// Get hypernym predicates for a noun (e.g., dog -> [Animal, Mammal]).").unwrap();
    writeln!(file, "pub fn lookup_noun_hypernyms(noun: &str) -> &'static [&'static str] {{").unwrap();
    writeln!(file, "    match noun.to_lowercase().as_str() {{").unwrap();
    for (noun, axiom) in &axioms.nouns {
        if !axiom.hypernyms.is_empty() {
            let hypernyms_str: Vec<String> = axiom.hypernyms.iter().map(|h| format!("\"{}\"", h)).collect();
            writeln!(file, "        \"{}\" => &[{}],", noun, hypernyms_str.join(", ")).unwrap();
        }
    }
    writeln!(file, "        _ => &[],").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}").unwrap();
    writeln!(file).unwrap();

    // Generate is_privative_adjective
    writeln!(file, "/// Check if an adjective is privative (e.g., fake, counterfeit).").unwrap();
    writeln!(file, "pub fn is_privative_adjective(adj: &str) -> bool {{").unwrap();
    writeln!(file, "    match adj.to_lowercase().as_str() {{").unwrap();
    for (adj, axiom) in &axioms.adjectives {
        if axiom.axiom_type == "Privative" {
            writeln!(file, "        \"{}\" => true,", adj).unwrap();
        }
    }
    writeln!(file, "        _ => false,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}").unwrap();
    writeln!(file).unwrap();

    // Generate lookup_verb_entailment
    writeln!(file, "/// Get verb entailment (e.g., murder -> (Kill, [Intentional])).").unwrap();
    writeln!(file, "pub fn lookup_verb_entailment(verb: &str) -> Option<(&'static str, &'static [&'static str])> {{").unwrap();
    writeln!(file, "    match verb.to_lowercase().as_str() {{").unwrap();
    for (verb, axiom) in &axioms.verbs {
        if let Some(entails) = &axiom.entails {
            let manner_str: Vec<String> = axiom.manner.iter().map(|m| format!("\"{}\"", m)).collect();
            writeln!(file, "        \"{}\" => Some((\"{}\", &[{}])),", verb, entails, manner_str.join(", ")).unwrap();
        }
    }
    writeln!(file, "        _ => None,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}").unwrap();
}

```

---


---

## Metadata

- **Generated:** Sun Dec 28 05:19:07 CST 2025
- **Repository:** /Users/tristen/logicaffeine/logicaffeine
- **Git Branch:** main
- **Git Commit:** 358bcdf
- **Documentation Size:** 1.4M

---

**Note:** This documentation is auto-generated. Run `./generate-docs.sh` to regenerate after code changes.
