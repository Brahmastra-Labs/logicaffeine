# LOGICAFFEINE 1.0 - Complete Source Documentation

An English-to-First-Order-Logic transpiler with modal operators, temporal logic, and semantic analysis.

**Technology Stack:**
- Rust (core transpiler)
- Dioxus 0.6 (web UI with Router)
- Bumpalo (arena allocation)
- WASM (browser deployment)

---

## Acknowledgments & History

Logicaffeine stands on the shoulders of giants. This project draws deep inspiration from **LogiCola**, the legendary logic tutorial software created by **Harry J. Gensler** at John Carroll University. For decades, LogiCola helped students worldwide master symbolic logic through interactive exercises and immediate feedback.

The creator of Logicaffeine first encountered LogiCola as a college student, and it sparked a lasting passion for formal logic and natural language processing. The pedagogical brilliance of Gensler's approach—breaking complex logical concepts into digestible, interactive exercises—directly influenced Logicaffeine's curriculum design.

While early prototypes referenced LogiCola's exercise format (LogiCola 3.0), **Logicaffeine 1.0** is a complete reimagining: a modern English-to-First-Order-Logic transpiler built from the ground up in Rust, featuring Montague semantics, Neo-Davidsonian event structures, and parse forest ambiguity resolution. The programming language component is called **LOGOS**.

We honor LogiCola's legacy while charting a new course—extending beyond tutorial software into a full formal semantics engine capable of translating natural English into rigorous logical notation.

---

## Table of Contents

### Overview
1. [Architecture Overview](#architecture-overview)

### Grammar & Semantics
2. [Grammar Rules](#grammar-rules)
   - [Sentence Patterns](#sentence-patterns)
   - [Quantifiers & Scope](#quantifier-scope)
   - [Modal & Temporal Operators](#modal-operators)
   - [Linguistic Phenomena](#linguistic-phenomena)
   - [Output Examples](#output-examples)
3. [Glossary](#glossary)

### Test Coverage
4. [Integration Tests](#integration-tests)
    - [Phase 1: Garden Path](#phase-1-garden-path)
    - [Phase 2: Polarity Items](#phase-2-polarity-items)
    - [Phase 3: Tense & Aspect](#phase-3-tense--aspect)
    - [Phase 4: Movement & Reciprocals](#phase-4-movement--reciprocals)
    - [Phase 5: Wh-Movement](#phase-5-wh-movement)
    - [Phase 6: Complex Tense](#phase-6-complex-tense)
    - [Phase 7: Intensional Semantics](#phase-7-intensional-semantics)
    - [Phase 8: Degrees & Comparatives](#phase-8-degrees--comparatives)
    - [Phase 8.5: Zone System](#phase-85-zone-system)
    - [Phase 9: Noun/Verb Conversion](#phase-9-nounverb-conversion)
    - [Phase 9.5: Structured Concurrency](#phase-95-structured-concurrency)
    - [Phase 10: Ellipsis & Sluicing](#phase-10-ellipsis--sluicing)
    - [Phase 11: Sorts & Metaphor](#phase-11-sorts--metaphor)
    - [Phase 12: Parse Forest](#phase-12-parse-forest)
    - [Phase 13: Multi-Word Expressions](#phase-13-mwe)
    - [Phase 14: Ontology & Bridging](#phase-14-ontology)
    - [Phase 15: Negation & Polarity](#phase-15-negation--polarity)
    - [Phase 16: Aspect Stack](#phase-16-aspect-stack)
    - [Phase 17: Comparatives & Superlatives](#phase-17-comparatives--superlatives)
    - [Phase 18: Plurality](#phase-18-plurality)
    - [Phase 19: Group Plurals](#phase-19-group-plurals)
    - [Phase 20: Axiom Layer](#phase-20-axiom-layer)
    - [Phase 21: Block Structure & Imperative](#phase-21-block-headers)
    - [Phase 22: Identity, Scope & Resolution](#phase-22-identity-scope)
    - [Phase 23: Type System & Statements](#phase-23-type-system)
    - [Phase 24: Code Generation](#phase-24-code-generation)
    - [Phase 25: Assertions & Smoke Tests](#phase-25-assertions)
    - [Phase 26: End-to-End Pipeline](#phase-26-end-to-end)
    - [Phase 27: Guards](#phase-27-guards)
    - [Phase 28: Precedence](#phase-28-precedence)
    - [Phase 29: Runtime Injection](#phase-29-runtime-injection)
    - [Phase 30: Collections & Iteration](#phase-30-collections--iteration)
    - [Phase 31: User-Defined Types](#phase-31-user-defined-types)
    - [Phase 32: Function Definitions & Inference](#phase-32-function-definitions--inference)
    - [Phase 33: Sum Types & Pattern Matching](#phase-33-sum-types--pattern-matching)
    - [Phase 34: User-Defined Generics](#phase-34-user-defined-generics)
    - [Phase 35: The Proof Bridge](#phase-35-the-proof-bridge)
    - [Phase 36: Module System](#phase-36-module-system)
    - [Phase 37: Project Manifest & Build Tool](#phase-37-project-manifest--build-tool)
    - [Phase 38: Standard Library (IO & System)](#phase-38-standard-library-io--system)
    - [Phase 41: Event Adjectives](#phase-41-event-adjectives)
    - [Phase 42: Discourse Representation Structures](#phase-42-discourse-representation-structures)
    - [Phase 42b: Z3 Static Verification](#phase-42b-z3-static-verification)
    - [Phase 42c: Refinement Verification](#phase-42c-refinement-verification)
    - [Phase 43: Type Safety & Collections](#phase-43-type-safety--collections)
    - [Phase 46: Agents](#phase-46-agents)
    - [Phase 48: Network Primitives](#phase-48-network-primitives)
    - [Phase 49: CRDT](#phase-49-crdt)
    - [Phase 50: Security Policies](#phase-50-security-policies)
    - [Phase 51: P2P Mesh Networking](#phase-51-p2p-mesh-networking)
    - [Phase 52: The Sync](#phase-52-the-sync)
    - [Phase 54: Go-like Concurrency](#phase-54-go-like-concurrency)
    - [End-to-End Tests](#end-to-end-tests)
5. [Statistics](#statistics)

### Source Code
6. [Lexicon Data](#lexicon-data)
7. [Lexer & Tokenization](#lexer--tokenization)
8. [Parser & AST](#parser--ast) (Dual-AST: logic.rs + stmt.rs)
9. [Transpilation](#transpilation)
10. [Semantic Analysis](#semantic-analysis)
11. [Type Analysis](#type-analysis) (analysis/ module)
12. [Code Generation](#code-generation) (codegen.rs, compile.rs, scope.rs)
13. [Public API](#public-api)
14. [Linguistic Data](#linguistic-data)
15. [Memory Management](#memory-management)
16. [Error Handling](#error-handling)
17. [Gamification](#gamification) (achievements, progress, SRS)
18. [Web Application](#web-application)
    - [Pages](#pages): Home, Workspace, Pricing, Learn, Lesson
    - [Components](#components): ChatDisplay, InputArea
    - [Router](#router): Client-side navigation
19. [Problem Generator](#problem-generator)
    - [Curriculum Structure](#curriculum-structure)
    - [Runtime Lexicon](#runtime-lexicon)
    - [Generator Engine](#generator-engine)
    - [Grader](#grader)
20. [Logos Core Runtime](#logos-core-runtime)
21. [Examples](#examples)

### Appendix
22. [Metadata](#metadata)

---

## Architecture Overview

LOGICAFFEINE implements a compiler pipeline for natural language to formal logic translation, with support for **structural ambiguity** via parse forests.

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                           LOGICAFFEINE 1.0 Pipeline                         │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   ┌─────────┐    ┌─────────┐    ┌─────────┐    ┌───────────┐    ┌───────┐  │
│   │  Input  │───▶│  Lexer  │───▶│ Parser  │───▶│ Transpile │───▶│Output │  │
│   │ English │    │         │    │         │    │           │    │ FOL   │  │
│   └─────────┘    └────┬────┘    └────┬────┘    └─────┬─────┘    └───────┘  │
│                       │              │               │                      │
│                       ▼              ▼               ▼                      │
│                  ┌─────────┐    ┌─────────┐    ┌───────────┐               │
│                  │ Tokens  │    │  Parse  │    │ Vec<AST>  │               │
│                  └─────────┘    │  Forest │    │ (multiple │               │
│                                 └─────────┘    │ readings) │               │
│                                      │         └───────────┘               │
│                                      ▼                                      │
│                              ┌───────────────┐                              │
│                              │    Lambda     │                              │
│                              │   Calculus    │                              │
│                              │  (Semantics)  │                              │
│                              └───────────────┘                              │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

**Data Flow:**
1. **Lexer** (`lexer.rs`, `token.rs`): Tokenizes English input using dictionary-based classification
2. **Parser** (`parser/`, `ast.rs`): Builds Arena-based AST via recursive descent; returns **parse forest** for ambiguous inputs
3. **Semantics** (`lambda.rs`, `context.rs`): Lambda calculus for compositional meaning
4. **Transpiler** (`transpile.rs`, `formatter.rs`): Generates Unicode or LaTeX logical notation

**Key Design Decisions:**
- **Arena allocation** (`bumpalo`) for zero-copy AST nodes with `Copy` semantics
- **Boxed AST variants** - Large variants boxed to reduce Expr size (112→32 bytes)
- **AstContext** - Unified arena access struct for ergonomic allocation
- **Visitor pattern** - walk_expr/walk_term for clean AST traversal
- **RAII checkpoints** - ParserCheckpoint for automatic backtracking cleanup
- **ParserGuard** - RAII guard with Deref/DerefMut for transparent parser access and automatic rollback
- **Fluent builders** - Type-safe expression construction with inline builders on AstContext
- **Semantic token sets** - Const arrays (WH_WORDS, MODALS) for declarative token matching via check_any()
- **Zero-alloc transpile** - write_to/write_logic methods avoid String allocation
- **Parse forest** output via `compile_ambiguous()` for structurally ambiguous sentences
- **Neo-Davidsonian event semantics** with thematic roles (Agent, Patient, Theme, etc.)
- **Control theory** (Chomsky) - raising verbs, control verbs, PRO binding
- **Generic quantifiers** (`Gen x`) for law-like generalizations ("Birds fly")
- **Mereology/Plurals** with Sigma operator (σ) and Distributive wrapper (*)
- **Presupposition & Focus** semantics (Strawson, Rooth)
- **Gapping/ellipsis** support via backtracking and verb recovery
- Symbol interning for efficient string comparisons
- Discourse context tracking for pronoun resolution
- Socratic error messages for educational feedback
- **Span tracking** - Source positions on tokens for rich error diagnostics with display_with_source()
- **Snapshot testing** - Golden master tests via assert_snapshot! macro (UPDATE_SNAPSHOTS=1 to regenerate)
- **Typo suggestions** - Zero-dependency Levenshtein distance for 'did you mean?' error messages
- **ANSI styling** - Compiler-style colored terminal output for errors
- **Reciprocals** - "each other" expands to bidirectional predicate conjunction
- **Polarity sensitivity** - Context-aware "any" interpretation (NPI vs free choice)
- **Garden path reanalysis** - Reduced relative clause detection with backtracking
- **Aspect chains** - Perfect/progressive/passive/modal stacking in verb groups
- **Voice operator** - Passive voice handling integrated with event semantics
- **Vendler classes (Aktionsart)** - Lexical aspect classification: State, Activity, Accomplishment, Achievement, Semelfactive
- **Zero-derivation** - Nouns dynamically coerced to verbs via morphological heuristics; consonant cluster recovery for silent-e lemmas
- **VP Ellipsis reconstruction** - EventTemplate stores verb + non-agent roles; try_parse_ellipsis() detects auxiliary + terminator pattern and rebuilds NeoEvent with new subject
- **Sluicing reconstruction** - Wh-word at sentence boundary triggers reconstruction from last_event_template; contraction expansion in lexer enables "don't know who" parsing
- **Verb-first classification** - Polysemous words (love, ring) classified as verbs first; parser accepts verbs in noun positions via consume_content_word()
- **Parse forest** - compile_forest() returns Vec<String> of all valid readings for ambiguous sentences
- **MAX_FOREST_READINGS** (12) - Limits parse forest size to prevent exponential blowup
- **noun_priority_mode** - Parser flag for lexical ambiguity forking; prefers noun interpretation for Ambiguous tokens
- **Sort system** - Ontological type hierarchy (Human⊂Animate⊂Physical) for semantic compatibility and metaphor detection
- **MWE Pipeline** - Post-tokenization trie-based collapsing of multi-word expressions (compound nouns, idioms, phrasal verbs)
- **Bridging Anaphora** - Part-whole inference for definite NPs without direct antecedent via ontology lookup
- **Copula Adjective Preference** - After copula, simple-aspect Verbs with Adjective alternatives prefer adjective reading
- **Content Word Classifiers** - Heuristic disambiguation via is_noun_like(), is_verb_like(), is_adjective_like()
- **NPI Licensing** - Negative Polarity Items (any, ever, anything) require licensing context; "no/nobody/nothing" are inherently negative quantifiers
- **Collective/Distributive ambiguity** - Mixed verbs (lift, carry) fork parse forest for plural subjects; collective verbs (gather, meet) force group reading; distributive verbs force individual reading
- **Distributive Expr** - Expr::Distributive wraps predicates for \`*\` operator transpilation
- **GroupQuantifier** - Expr::GroupQuantifier for cardinal indefinites with collective readings; outputs Group(g) ∧ Count(g, n) ∧ ∀x(Member(x, g) → R(x)) structure
- **Axiom Layer** - Post-parse AST transformation via apply_axioms(); expands predicates using meaning postulates from lexicon (analytic entailments, privatives, hypernyms, verb entailments)
- **Problem Generator** - Template-based exercise generation with {ProperName}, {Noun}, {Verb}, {Adjective} slots; runtime lexicon queries with constraint filtering; morphological modifiers (:Plural, :Past)
- **Semantic Grading** - Answer comparison via Unicode normalization, AST parsing, and structural equivalence; handles commutativity of ∧/∨; partial credit scoring
- **Curriculum Embedding** - Filesystem-based curriculum (assets/curriculum/) embedded at compile time via include_dir; JSON schemas for eras, modules, exercises
- **Catch-all 404 Route** - NotFound variant with /:..route pattern prevents router panics on invalid URLs
- **Refinement Types** - \`Type where predicate\` syntax with RefinementContext tracking; debug_assert!() enforcement at Let binding and Set mutation
- **Zone System** - Region-based memory with Heap (bumpalo arena) and Mapped (memmap2 file) variants; escape analysis enforces Hotel California rule; O(1) alloc/bulk dealloc
- **Diagnostic Bridge** - Rustc JSON parsing with SourceMap for error translation; E0382→"Cannot use X after giving it away"; Socratic explanations instead of raw compiler errors
- **Structured Concurrency** - \`Attempt all:\` for async I/O (tokio::join!); \`Simultaneously:\` for parallel CPU (rayon::join or thread::spawn); Let bindings destructure to tuples
- **Z3 Static Verification** - Smart Full Mapping: Int/Bool direct, Object uninterpreted sort, Predicates/Modals/Temporals → Apply; \`compile_to_rust_verified()\` opt-in; graceful degradation for complex linguistic constructs
- **CRDT types** - GCounter (grow-only), LWWRegister (last-write-wins) for distributed state; \`Shared\` modifier generates Merge impl
- **Policy-based security** - Predicate definitions (is_admin), capability checks (can_publish), Check statement for mandatory enforcement
- **Check vs Assert** - Check never optimized out (security); Assert becomes debug_assert (logic)
- **libp2p Mesh** - QUIC-first transport with TCP fallback, Noise encryption, Yamux multiplexing, mDNS peer discovery
- **Bincode Wire Protocol** - LogosWire trait for serialize/deserialize; /logos/mesh/1.0.0 protocol with 16MB max message size
- **Network Statements** - Listen on, Connect to, Send to remote, Let x be a PeerAgent at
- **Synced<T> Wrapper** - Auto-publishes on mutation, auto-merges on receive; \`Sync x on "topic"\` binds CRDT to GossipSub topic
- **Cross-Platform VFS** - Vfs trait with conditional Send+Sync; NativeVfs (tokio::fs) vs OpfsVfs (OPFS API); PlatformVfs alias for unified access
- **Go-like Concurrency** - Pipe<T> bounded channels (PipeSender/PipeReceiver split), TaskHandle<T> with abort/is_finished, spawn() for green threads, Select statement (tokio::select!), check_preemption() for cooperative yields

**Quantifier Kinds:**
| Kind | Symbol | Example | Meaning |
|------|--------|---------|---------|
| Universal | ∀ | "All birds fly" | Every individual |
| Existential | ∃ | "Some bird flies" | At least one |
| Generic | Gen | "Birds fly" | Characteristic/law-like |
| Negative | ¬∃ | "No birds swim" | None |
| Many | MANY | "Many dogs bark" | Significantly many |
| Most | MOST | "Most birds fly" | More than half |
| Few | FEW | "Few cats swim" | Small number |

**Scope Enumeration Complexity:**
| Scenario | Formula | Example |
|----------|---------|---------|
| Naive | n! | 3 quantifiers → 6 readings |
| With Islands | Π(k_i!) | 4 quantifiers (2+2) → 4 readings |
| + Intensionality | Π(k_i!) × 2^m | m opaque verbs add binary choice |

**Vendler Classes (Aktionsart):**
| Class | Features | Example Verbs | Meaning |
|-------|----------|---------------|---------|
| State | +static, +durative, -telic | know, love, exist | No change, extends in time |
| Activity | -static, +durative, -telic | run, swim, drive | Dynamic, no endpoint |
| Accomplishment | -static, +durative, +telic | build, draw, write | Dynamic with endpoint |
| Achievement | -static, -durative, +telic | win, find, die | Instantaneous change |
| Semelfactive | -static, -durative, -telic | knock, cough, blink | Single punctual event |

**Verb Plurality Classes:**
| Class | Example Verbs | Plural Subject Behavior |
|-------|---------------|------------------------|
| Collective | gather, meet, disperse | Group reading only |
| Distributive | sleep, run, die | Individual reading only |
| Mixed | lift, carry, surround | Ambiguous - forks readings |

**Word Classification Priority:**
| Word | In Verbs | In disambiguation_not_verbs | In Nouns | In Adjectives | Result |
|------|----------|----------------------------|----------|---------------|--------|
| love | ✓ | ✗ | ✓ | ✗ | Verb (parser handles noun positions) |
| ring | ✓ | ✓ | ✓ | ✗ | Noun (disambiguation + noun check) |
| bus  | ✓ | ✓ | ✓ | ✗ | Noun (disambiguation + noun check) |
| fake | ✓ | ✓ | ✗ | ✗ | Adjective (disambiguation, not noun) |
| open | ✓ | ✗ | ✗ | ✓ | Ambiguous{Verb, [Adj]} (copula prefers Adj) |

**Lexical Ambiguity (Phase 12):**
| Pattern | Example | Readings |
|---------|---------|----------|
| Noun/Verb | "I saw her duck" | duck=bird vs duck=action |
| Verb/Adjective | "The door is open" | open=Adj (copula preference) vs open=Verb |
| Possessive Pronoun | "her book" vs "saw her" | possessive determiner vs object pronoun |
| PP Attachment | "man with telescope" | VP attachment (instrument) vs NP attachment (modifier) |

**Sort Hierarchy (Phase 11):**
| Sort | Parent | Examples |
|------|--------|----------|
| Human | Animate | John, Mary, Juliet |
| Animate | Physical | dog, cat, bird |
| Celestial | - | Sun, Moon, stars |
| Abstract | - | Time, Justice, Love |
| Physical | - | Rock, Table, Book |
| Value | - | Money, Gold |

**Aspect Operators:**
| Operator | Symbol | Example | Meaning |
|----------|--------|---------|---------|
| Progressive | Prog | "is running" | Ongoing action |
| Perfect | Perf | "has eaten" | Completed with relevance |
| Habitual | HAB | "John runs" (present activity) | Characteristic behavior |
| Iterative | ITER | "kept knocking" | Repeated semelfactive |

**Plural Semantics (Link-style Mereology):**
| Feature | Syntax | Output | Meaning |
|---------|--------|--------|---------|
| Sigma operator | "The dogs" | σx.Dog(x) | Maximal sum of all dogs |
| Collective verb | "The dogs gathered" | P(G(σD)) | Group action |
| Distributive verb | "The dogs barked" | *P(B(σD)) | Each individual acted |
| Coordination | "John and Mary met" | P(M2(J ⊕ M)) | Sum of individuals |

**Event Semantics (Neo-Davidsonian):**
| Role | Example | Output |
|------|---------|--------|
| Agent | "John kicked the ball" | ∃e(Kick(e) ∧ Agent(e,j) ∧ Theme(e,b)) |
| Theme | "The ball was kicked" | ∃e(Kick(e) ∧ Theme(e,b)) |
| Recipient | "John gave Mary a book" | ∃e(Give(e) ∧ Agent(e,j) ∧ Recipient(e,m) ∧ Theme(e,b)) |
| Instrument | "with a hammer" | Instrument(e,h) |

**Ditransitive Verbs:**
| Verb | Example | Roles |
|------|---------|-------|
| give | "John gave Mary a book" | Agent, Recipient, Theme |
| send | "Mary sent John a letter" | Agent, Recipient, Theme |
| tell | "She told him a story" | Agent, Recipient, Theme |

**Causal Relations:**
| Type | Example | Output |
|------|---------|--------|
| Because | "John fell because he slipped" | Cause(Slip(j), Fall(j)) |

**Deixis (Demonstratives):**
| Type | Words | Predicate |
|------|-------|-----------|
| Proximal | this, these | Proximal(x) |
| Distal | that, those | Distal(x) |

**Gerunds:**
| Position | Example | Output |
|----------|---------|--------|
| Subject | "Running is healthy" | Healthy(Running) |
| Object | "John loves swimming" | Love(j, Swimming) |

**Mass Nouns:**
| Measure | Example | Output |
|---------|---------|--------|
| Much | "much water" | Measure(x, Much) ∧ Water(x) |
| Little | "little time" | Measure(x, Little) ∧ Time(x) |

**Control Theory (Chomsky):**
| Type | Example | Structure |
|------|---------|-----------|
| Subject Control | "John wants to leave" | Want(j, PRO_j leave) |
| Object Control | "John persuaded Mary to go" | Persuade(j, m, PRO_m go) |
| Raising | "John seems to be happy" | Seem(Happy(j)) |

**Adjective Types:**
| Type | Example | Output | Semantics |
|------|---------|--------|-----------|
| Intersective | "a red ball" | R(x) ∧ B(x) | Independent predicates |
| Subsective | "a small elephant" | S(x, ^E) ∧ E(x) | Relative to noun class |
| Non-Intersective | "a fake gun" | Fake(Gun) | Modifies concept |

**Measurement Semantics (Phase 8):**
| Dimension | Example | Output |
|-----------|---------|--------|
| Length | "5 meters long" | Value(5, meters, Length) |
| Temperature | "98.6 degrees" | Value(98.6, degrees, Temperature) |
| Cardinality | "aleph_0" | Value(aleph_0, ∅, Cardinality) |
| Comparative | "2 inches taller" | Taller(j, m, Value(2, inches)) |

**Compound Identifiers:**
| Pattern | Example | Output |
|---------|---------|--------|
| noun + label | "set A" | set_A |
| noun + proper | "King John" | King_John |
| noun + letter | "function F" | function_F |

**Zero-Derivation (Phase 9):**
| Pattern | Example | Output |
|---------|---------|--------|
| noun→verb (past) | "tabled the motion" | Table(committee, motion) |
| noun→verb (past) | "emailed him" | Email(she, him) |
| noun→verb (past) | "googled the answer" | Google(j, answer) |
| noun→verb (modal) | "should table" | Modal(Should, Table(x, motion)) |

**VP Ellipsis (Phase 10a):**
| Pattern | Example | Output |
|---------|---------|--------|
| does too | "John runs. Mary does too." | Run(j) ∧ Run(m) |
| modal too | "John can swim. Mary can too." | ◇Swim(j) ∧ ◇Swim(m) |
| does not | "John runs. Mary does not." | Run(j) ∧ ¬Run(m) |
| with object | "John eats an apple. Mary does too." | Eat(j,apple) ∧ Eat(m,apple) |

**Sluicing (Phase 10b):**
| Pattern | Example | Output |
|---------|---------|--------|
| who sluicing | "Someone left. I know who." | ∃x(Leave(x)) ∧ Know(I, ?y[Leave(y)]) |
| what sluicing | "John ate something. I know what." | ∃x(Eat(j,x)) ∧ Know(I, ?y[Eat(j,y)]) |
| negation | "Someone called. I don't know who." | ∃x(Call(x)) ∧ ¬Know(I, ?y[Call(y)]) |
| wonder | "Someone ran. I wonder who." | ∃x(Run(x)) ∧ Wonder(I, ?y[Run(y)]) |

---


## Grammar Rules

LOGICAFFEINE parses English sentences according to the following grammar patterns:

### Sentence Patterns

| Pattern | Example | Logic |
|---------|---------|-------|
| Universal | "All cats are mammals" | ∀x(Cat(x) → Mammal(x)) |
| Existential | "Some dogs bark" | ∃x(Dog(x) ∧ Bark(x)) |
| Generic | "Birds fly" | Gen x(Bird(x) → Fly(x)) |
| Singular | "Socrates is mortal" | Mortal(socrates) |
| Negative | "No fish fly" | ¬∃x(Fish(x) ∧ Fly(x)) |
| Conditional | "If it rains, the ground is wet" | Rain → Wet(ground) |
| Gapping | "John ate an apple, and Mary, a pear" | Ate(john, apple) ∧ Ate(mary, pear) |
| Plural Collective | "The dogs gathered" | P(G(σD)) |
| Plural Distributive | "The dogs barked" | *P(B(σD)) |
| Coordination | "John and Mary met" | P(M2(J ⊕ M)) |
| Subject Control | "John wants to leave" | Want(j, Leave(PRO_j)) |
| Object Control | "John persuaded Mary to go" | Persuade(j, m, Go(PRO_m)) |
| Raising | "John seems to be happy" | Seem(Happy(j)) |
| Focus | "Only John ran" | Only(j, Ran(j)) |
| Presupposition | "John stopped smoking" | Smoke(j)_presup ∧ ¬Smoke(j) |
| Counterfactual | "If John had run, he would have won" | □→(Run(j), Win(j)) |
| Comparative | "John is taller than Mary" | Taller(j, m) |
| Ditransitive | "John gave Mary a book" | ∃e(Give(e) ∧ Agent(e,j) ∧ Recipient(e,m) ∧ Theme(e,b)) |
| Causal | "John fell because he slipped" | Cause(Slip(j), Fall(j)) |
| Gerund Subject | "Running is healthy" | Healthy(Running) |
| Gerund Object | "John loves swimming" | Love(j, Swimming) |
| Deixis Proximal | "This cat meows" | ∃x(Proximal(x) ∧ Cat(x) ∧ Meow(x)) |
| Deixis Distal | "That dog barks" | ∃x(Distal(x) ∧ Dog(x) ∧ Bark(x)) |
| Mass Noun | "Much water flows" | ∃x(Measure(x, Much) ∧ Water(x) ∧ Flow(x)) |
| Reciprocal | "They love each other" | Love(x,y) ∧ Love(y,x) |
| NPI Any | "No one has any books" | ¬∃x∃y(Person(x) ∧ Book(y) ∧ Has(x,y)) |
| Free Choice Any | "Any book works" | ∀x(Book(x) → Works(x)) |
| Garden Path | "The horse raced past the barn fell" | ∃x(Horse(x) ∧ RacedPast(x,barn) ∧ Fell(x)) |
| Perfect Aspect | "John has eaten" | Perf(Eat(j)) |
| Progressive | "John is eating" | Prog(Eat(j)) |
| Passive Voice | "The ball was kicked" | ∃e(Kick(e) ∧ Theme(e,ball)) |
| Contact Clause | "The cat the dog chased ran" | ∃x(Cat(x) ∧ ∃y(Dog(y) ∧ Chase(y,x)) ∧ Run(x)) |
| Stacked Relatives | "Every book that John read that Mary wrote" | ∀x((Book(x) ∧ Read(j,x) ∧ Wrote(m,x)) → ...) |

### Quantifier Kinds

| Kind | Trigger | Symbol | Semantics |
|------|---------|--------|-----------|
| Universal | "all", "every", "each" | ∀ | True for every individual |
| Existential | "some", "a", "an" | ∃ | True for at least one |
| Generic | Bare plural ("birds") | Gen | Law-like/characteristic |
| Negative | "no", "none" | ¬∃ | True for none |

### Quantifier Scope

- Nested quantifiers resolve left-to-right by default
- "Every student read some book" → ∀x(Student(x) → ∃y(Book(y) ∧ Read(x,y)))
- Scope can be disambiguated via context

### Structural Ambiguity

Sentences with multiple valid parses return all readings via `compile_ambiguous()`:

| Sentence | Reading 1 | Reading 2 |
|----------|-----------|-----------|
| "I saw the man with the telescope" | See(i, man, with:telescope) | See(i, man) ∧ Has(man, telescope) |

**PP-Attachment:** Prepositional phrases can attach to VP (instrument) or NP (modifier).

### Modal Operators

| Operator | Symbol | Meaning |
|----------|--------|---------|
| Necessity | □ | "must", "necessarily" |
| Possibility | ◇ | "can", "possibly", "might" |
| Obligation | O | "ought", "should" |
| Permission | P | "may" (deontic) |

### Temporal Operators

| Operator | Symbol | Meaning |
|----------|--------|---------|
| Future | F | "will" |
| Past | P | "did", past tense |
| Always | G | "always" |
| Sometimes | F | "sometimes" |

### Linguistic Phenomena

LOGICAFFEINE supports the following linguistic constructs:

### Quantification
- Universal: "all", "every", "each", "any"
- Existential: "some", "a", "an", "there exists"
- Generic: bare plurals ("birds", "dogs") - law-like generalizations
- Negative: "no", "none", "not any"

### Plurals & Mereology (Link-style)
- Sigma operator (σ): maximal sum - "the dogs" → σx.Dog(x)
- Collective verbs: "gather", "meet", "assemble", "disperse" - no distributive wrapper
- Distributive verbs: most verbs - wrapped with * operator
- Group formation (⊕): "John and Mary" → J ⊕ M

### Event Semantics (Neo-Davidsonian)
- Event variables: ∃e(Kick(e) ∧ Agent(e,j) ∧ Theme(e,b))
- Thematic roles: Agent, Patient, Theme, Goal, Source, Recipient, Instrument, Location, Time, Manner
- Adverbial modification: Manner(e, quickly)

### Control Theory (Chomsky)
- Subject control: "want", "try", "promise" - PRO bound to subject
- Object control: "persuade", "force", "convince" - PRO bound to object
- Raising: "seem", "appear" - no PRO, subject raises

### Presupposition (Strawson)
- Factive triggers: "know", "regret", "realize"
- Aspectual triggers: "stop", "start", "continue" (require gerund complement)
  - "John stopped smoking." → presupposition: John was smoking
  - "John stopped." → no presupposition (simple past tense verb)
- Definite descriptions: presuppose existence

### Focus (Rooth)
- Focus particles: "only", "even", "just"
- Alternative semantics: focus introduces alternatives

### Connectives
- Conjunction: "and", "but", "yet"
- Disjunction: "or", "either...or"
- Implication: "if...then", "implies", "only if"
- Biconditional: "if and only if", "iff"

### Modality
- Alethic: "necessarily", "possibly", "must", "can"
- Deontic: "ought", "should", "may", "permitted"
- Epistemic: "knows", "believes"

### Anaphora
- Pronouns: "he", "she", "it", "they"
- Reflexives: "himself", "herself", "itself"
- Demonstratives: "this", "that"

### Relative Clauses
- Restrictive: "the man who runs"
- Non-restrictive: "John, who is tall"
- Stacked relatives: "the book that John read that Mary wrote" - multiple relative clauses on single head noun

### Presupposition Triggers
- Definite descriptions: "the king of France"
- Factive verbs: "knows that", "regrets that"
- Change of state: "stopped", "began" (gerund complement required)
  - Triggered: "stopped smoking" → presupposes was smoking
  - Not triggered: "stopped" alone → simple verb, no presupposition

### Ellipsis & Gapping
- Gapping: "John ate an apple, and Mary, a pear" (verb elided in second conjunct)
- VP Ellipsis: "John ran and Mary did too"
- Sluicing: "Someone left, but I don't know who"

### Structural Ambiguity
- PP-attachment: "I saw the man with the telescope" (VP vs NP attachment)
- Quantifier scope: "Every boy loves some girl" (wide vs narrow scope)
- Coordination: "old men and women" (old men + women vs old men + old women)

### Deixis (Demonstratives)
- Proximal: "this", "these" → Proximal(x) predicate
- Distal: "that", "those" → Distal(x) predicate
- Spatial reference relative to speaker position

### Ditransitive Verbs
- Double object construction: "give X Y", "send X Y", "tell X Y"
- Recipient thematic role for indirect object
- Three-argument event: Agent, Recipient, Theme

### Gerunds
- Gerund as subject: "Running is fun" → predicate applied to nominalized verb
- Gerund as object: "I love swimming" → verb as theme argument
- -ing form functioning as noun phrase

### Causal Connectives
- "because" introduces causal relation: Cause(antecedent, consequent)
- Antecedent is the cause, consequent is the effect
- Order: "X because Y" → Cause(Y, X)

### Mass Nouns
- "much" + noun → Measure(x, Much) ∧ Noun(x)
- "little" + noun → Measure(x, Little) ∧ Noun(x)
- Quantity expressions for uncountable nouns

### Reciprocals
- Pattern: "each other" with plural subject
- Expansion: P(x,y) ∧ P(y,x) for all pairs in the group
- Example: "John and Mary love each other" → Love(j,m) ∧ Love(m,j)

### Polarity Items
- NPI "any": Licensed by negation, questions, conditionals → existential
- Free choice "any": Universal interpretation in positive contexts
- Context tracking via negation depth in parser
- Example: "No one has any books" (NPI) vs "Any book will do" (free choice)

### Garden Path Sentences
- Reduced relative clauses: "The horse raced past the barn fell"
- Initially parsed as main verb, triggers reanalysis
- Backtracking to reduced relative interpretation
- Parser uses try_reduced_relative_interpretation()

### Vendler Classes (Aktionsart)
- State: +static, +durative, -telic (know, love) - no progressive allowed
- Activity: -static, +durative, -telic (run, swim) - present tense → Habitual
- Accomplishment: -static, +durative, +telic (build, write) - present tense → Habitual
- Achievement: -static, -durative, +telic (win, die) - present tense → Habitual
- Semelfactive: -static, -durative, -telic (knock, blink) - progressive → Iterative

### Aspect System
- Progressive: -ing form (is/was running) → Prog(φ)
- Perfect: have/has/had + past participle → Perf(φ)
- Habitual: present tense non-stative → HAB(φ)
- Iterative: semelfactive + progressive → ITER(φ)
- Passive: been + past participle → Voice(Passive, φ)
- Chains: Modal + Perfect + Passive + Progressive stacking
- Example: "would have been being eaten" → chains all four

### Contact Clauses
- Reduced relatives without overt relativizer: "The cat the dog chased ran"
- Pattern: NP + NP + Verb triggers contact clause interpretation
- Equivalent to: "The cat [that] the dog chased ran"
- Parser uses is_contact_clause_pattern() lookahead

### Intensionality (De Re / De Dicto)
- De Re: Object exists in actual world, quantifier scopes wide
- De Dicto: Object described intensionally, quantifier scopes narrow
- Opaque verbs: "seek", "want", "believe", "need", "fear"
- Montague up-arrow (^): Marks intension of predicate
- Example: "John seeks a unicorn"
  - De Re: ∃x(Unicorn(x) ∧ Seek(j, x)) - specific unicorn exists
  - De Dicto: Seek(j, ^Unicorn) - seeking unicorn-concept

### Scope Islands
- Island boundaries: conjunctions (if/and/or), relative clauses
- Quantifiers cannot scope out of their island
- Reduces exponential scope ambiguity to manageable product of factorials
- Example: "Every man runs AND some dog barks" → 1! × 1! = 1 reading (no cross-island scoping)

### Adjective Semantics
- Intersective: Property independent of noun - "red ball" → R(x) ∧ B(x)
- Subsective: Property relative to noun class - "small elephant" → S(x, ^E) ∧ E(x)
- Non-Intersective: Modifies concept - "fake gun" → Fake(Gun)
- Gradable: Allows comparison - "taller", "tallest"
- Montague up-arrow (^): Marks intension of noun for subsective context

### Generalized Quantifiers
- Beyond ∀/∃: MANY, MOST, FEW with cardinality semantics
- MANY x(P(x) ∧ Q(x)) - significantly many P's are Q's
- MOST x(P(x) → Q(x)) - more than half of P's are Q's
- FEW x(P(x) ∧ Q(x)) - small number of P's are Q's

### Zero-Derivation (Noun→Verb Conversion)
- English allows nouns to be used as verbs without morphological marking
- Pattern detection: Past tense "-ed" suffix on non-lexicon words
- Morphological recovery: Silent-e restoration via consonant cluster heuristics
- Example: "table" (noun) → "tabled" (verb) → "Table(x, y)"
- Handles: tabled, emailed, googled, skyped, friended, texted, etc.

### VP Ellipsis (Anaphoric Reconstruction)
- Elided VP reconstructed from discourse antecedent
- Pattern: Subject + Auxiliary + (not)? + Terminator (too/also/.)
- Template stores: verb + non-agent thematic roles + modifiers
- Reconstruction: New subject as Agent, preserve Theme/Goal/etc.
- Modal preservation: "can too" → same modal on reconstructed VP
- Negation: "does not" → negated reconstruction
- Examples: "John runs. Mary does too." → Run(j) ∧ Run(m)

### Sluicing (Wh-Ellipsis)
- Elided wh-clause reconstructed from discourse antecedent
- Pattern: Embedding verb + wh-word + terminator (period/comma/EOF)
- Template stores: verb + thematic roles from antecedent clause
- Reconstruction: wh-variable fills Agent (who) or Theme (what) slot
- Negation support: "I don't know who" via contraction expansion
- Embedding verbs: know, wonder (Opaque feature)
- Examples: "Someone left. I know who." → ∃x(Leave(x)) ∧ Know(I, ?y[Leave(y)])

### Degree Semantics (Phase 8)
- Comparative with measure: "2 inches taller" → Taller(j, m, 2 inches)
- Absolute measurement: "5 meters long" → Long(rope, 5 meters)
- Symbolic numbers: aleph_0, omega for infinite cardinals
- Dimension tracking: Length, Time, Weight, Temperature, Cardinality
- NumberKind types: Real(f64), Integer(i64), Symbolic(Symbol)
- Term::Value stores numeric value with optional unit and dimension

### Topicalization (Object Fronting)
- Pattern: "NP, Subject Verb" → fronted NP is object (Theme)
- Example: "The apple, John ate." → Eat(j, apple)
- Adjective preservation: "The red apple, John ate." keeps Red(x) ∧ Apple(x)
- Pronoun subject handling: "The book, he read."
- Implementation: parser/mod.rs lines 401-473, uses wrap_with_definiteness_full()

### Long-Distance Dependencies (Wh-Movement)
- Filler-Gap binding across clause boundaries
- Example: "Who did John say Mary loves?" → λx.Say(j, Loves(m, x))
- Parser field: filler_gap: Option<Symbol> in Parser struct
- Persists through recursive clause parsing for embedded extractions
- Pied-piping: "To whom did John give the book?" fronts P+wh together

### Sentential Complements (Embedded Clauses)
- Verbs like "say", "believe", "think" take clausal arguments
- Represented as Term::Proposition wrapping the embedded Expr
- Example: "John said Mary runs" → Say(j, [Run(m)])
- Bracket notation [expr] distinguishes from conjunction
- Supports wh-extraction across clause boundaries
- Communication verbs: say, tell, report, announce
- Propositional attitude verbs: believe, think, know, doubt

### Reichenbach Temporal Semantics
- Three-point temporal model: Event (E), Reference (R), Speech (S)
- Past: R < S (reference before speech)
- Future: S < R (speech before reference)
- Perfect: E < R (event before reference)
- Past Perfect: E < R < S ("had run")
- Future Perfect: E < R, S < R ("will have run")
- Present Perfect: E < R, R = S ("has run")
- Output uses Precedes(x, y) predicates for explicit temporal ordering

### Multi-Word Expressions (Phase 13)
- Compound nouns: "fire engine" → FireEngine (merged single token)
- Idioms: "kicked the bucket" → Die (semantic replacement)
- Phrasal verbs: "gave up" → Surrender
- Trie-based pattern matching for efficient MWE detection
- Tense inheritance: "kicked the bucket" inherits past tense from "kicked"
- Post-tokenization pipeline: apply_mwe_pipeline() collapses multi-token sequences

### Bridging Anaphora (Phase 14)
- Part-whole inference for definite NPs without direct antecedent
- Example: "I bought a car. The engine smoked." → PartOf(engine, car)
- Ontology lookup: find_bridging_wholes() returns possible whole objects
- Ambiguous bridging handled via parse forest forking
- Sort compatibility checking for semantic validation

### Metaphor Detection (Phase 14)
- Sort violations trigger Metaphor wrapper
- Example: "The rock was happy" → Metaphor(Happy(rock))
- Predicate sort requirements checked via ontology module
- Compatible sorts pass without Metaphor wrapping
- Example: "John was happy" → Happy(j) (no metaphor - Human compatible with mental predicates)

### Negation & Polarity Items (Phase 15)
- Free choice "any": "Any cat hunts" → ∀x(Cat(x) → Hunt(x))
- NPI "any" with negation: "did not see any X" → ¬∃x(X(x) ∧ See(...,x))
- Negative quantifiers: nobody, nothing, no one → ∀x(R(x) → ¬P(x))
- Scope: "Not all birds fly" → ¬∀ (negation scopes over universal)
- Temporal NPIs: "never" → inherent negation, "ever" → requires licensor
- NPI licensing by "no": "No dog saw anything" licenses existential in object

### Output Examples

#### Unicode Output

**Input:** "All humans are mortal"
**Output:** `∀x(Human(x) → Mortal(x))`

**Input:** "Birds fly" (Generic)
**Output:** `Gen x(Bird(x) → Fly(x))`

**Input:** "Socrates is human and Socrates is mortal"
**Output:** `Human(socrates) ∧ Mortal(socrates)`

**Input:** "John ate an apple, and Mary, a pear" (Gapping)
**Output:** `Ate(john, apple) ∧ Ate(mary, pear)`

**Input:** "Necessarily, if something is a bachelor then it is unmarried"
**Output:** `□∀x(Bachelor(x) → Unmarried(x))`

### Plural Output (Mereology)

**Input:** "The dogs gathered" (Collective)
**Output:** `P(G(σD))`

**Input:** "The dogs barked" (Distributive)
**Output:** `*P(B(σD))`

**Input:** "John and Mary met" (Coordination)
**Output:** `P(M2(J ⊕ M))`

### Event Semantics Output

**Input:** "John kicked the ball"
**Output:** `∃e(Kick(e) ∧ Agent(e,j) ∧ Theme(e,b))`

### Control Output

**Input:** "John wants to leave"
**Output:** `Want(j, Leave(PRO_j))`

**Input:** "John seems to be happy"
**Output:** `Seem(Happy(j))`

### Focus & Presupposition Output

**Input:** "Only John ran"
**Output:** `Only(j, Ran(j))`

**Input:** "John stopped smoking"
**Output:** `Stop(j, Smoke(j))` with presupposition: `Smoke(j)`

### Ambiguous Output (compile_ambiguous)

**Input:** "I saw the man with the telescope"
**Output (Reading 1 - VP attachment):** `See(i, man, with:telescope)`
**Output (Reading 2 - NP attachment):** `See(i, man) ∧ Has(man, telescope)`

### LaTeX Output

**Input:** "All humans are mortal"
**Output:** `\forall x(Human(x) \rightarrow Mortal(x))`

**Input:** "Birds fly" (Generic)
**Output:** `\text{Gen } x(Bird(x) \rightarrow Fly(x))`

**Input:** "Some cat loves every dog"
**Output:** `\exists x(Cat(x) \land \forall y(Dog(y) \rightarrow Loves(x,y)))`

### Ditransitive Output

**Input:** "John gave Mary a book"
**Output:** `∃e(Give(e) ∧ Agent(e, j) ∧ Recipient(e, m) ∧ Theme(e, b))`

**Input:** "She sent him a letter"
**Output:** `∃e(Send(e) ∧ Agent(e, s) ∧ Recipient(e, h) ∧ Theme(e, l))`

### Causal Output

**Input:** "John fell because he slipped"
**Output:** `Cause(Slip(j), Fall(j))`

**Input:** "The plant died because it lacked water"
**Output:** `Cause(Lack(p, w), Die(p))`

### Gerund Output

**Input:** "Running is healthy"
**Output:** `Healthy(Running)`

**Input:** "John loves swimming"
**Output:** `Love(j, Swimming)`

### Deixis Output

**Input:** "This dog barks"
**Output:** `∃x(Proximal(x) ∧ Dog(x) ∧ Bark(x))`

**Input:** "Those cats meow"
**Output:** `∃x(Distal(x) ∧ Cat(x) ∧ Meow(x))`

### Mass Noun Output

**Input:** "Much water flows"
**Output:** `∃x(Measure(x, Much) ∧ Water(x) ∧ Flow(x))`

**Input:** "Little time remains"
**Output:** `∃x(Measure(x, Little) ∧ Time(x) ∧ Remain(x))`

### Reciprocal Output

**Input:** "John and Mary love each other"
**Output:** `Love(j, m) ∧ Love(m, j)`

**Input:** "They saw each other"
**Output:** `See(x, y) ∧ See(y, x)`

### Polarity Output

**Input:** "No one has any books" (NPI)
**Output:** `¬∃x(Person(x) ∧ ∃y(Book(y) ∧ Has(x, y)))`

**Input:** "Any book works" (Free Choice)
**Output:** `∀x(Book(x) → Works(x))`

### Garden Path Output

**Input:** "The horse raced past the barn fell"
**Output:** `∃x(Horse(x) ∧ RacedPast(x, barn) ∧ Fell(x))`

### Aspect Output

**Input:** "John is running" (Progressive)
**Output:** `Prog(∃e(Run(e) ∧ Agent(e, j)))`

**Input:** "John has eaten" (Perfect)
**Output:** `Perf(∃e(Eat(e) ∧ Agent(e, j)))`

**Input:** "The ball was kicked" (Passive)
**Output:** `∃e(Kick(e) ∧ Theme(e, ball))`

**Input:** "John was running" (Past Progressive)
**Output:** `Past(Prog(∃e(Run(e) ∧ Agent(e, j))))`

### Vendler/Aktionsart Output

**Input:** "John runs" (Activity, Present)
**Output:** `HAB(∃e(Run(e) ∧ Agent(e, j)))`

**Input:** "John knows Mary" (State, Present)
**Output:** `∃e(Know(e) ∧ Agent(e, j) ∧ Theme(e, m))` (no Habitual wrapper)

**Input:** "John is knocking" (Semelfactive, Progressive)
**Output:** `ITER(∃e(Knock(e) ∧ Agent(e, j)))`

**Input:** "John built a house" (Accomplishment, Past)
**Output:** `Past(∃e(Build(e) ∧ Agent(e, j) ∧ Theme(e, h)))`

**Input:** "John won" (Achievement, Past)
**Output:** `Past(∃e(Win(e) ∧ Agent(e, j)))`

### Intensional Readings (De Re / De Dicto)

**Input:** "John seeks a unicorn"
**Output (De Re):** `∃x(Unicorn(x) ∧ ∃e(Seek(e) ∧ Agent(e, j) ∧ Theme(e, x)))`
**Output (De Dicto):** `∃e(Seek(e) ∧ Agent(e, j) ∧ Theme(e, ^Unicorn))`

**Input:** "Mary needs a doctor"
**Output (De Re):** `∃x(Doctor(x) ∧ Need(m, x))` - specific doctor
**Output (De Dicto):** `Need(m, ^Doctor)` - any doctor

**Input:** "John believes a spy exists"
**Output (De Re):** `∃x(Spy(x) ∧ Believe(j, Exists(x)))` - specific spy
**Output (De Dicto):** `Believe(j, ∃x(Spy(x)))` - belief in existence

### Adjective Output

**Input:** "A small elephant ran." (Subsective)
**Output:** `∃x(S(x, ^E) ∧ E(x) ∧ ∃e(Run(e) ∧ Agent(e, x)))`

**Input:** "A red ball rolled." (Intersective)
**Output:** `∃x(R(x) ∧ B(x) ∧ ∃e(Roll(e) ∧ Agent(e, x)))`

**Input:** "A large mouse ran." (Subsective)
**Output:** `∃x(L(x, ^M) ∧ M(x) ∧ ∃e(Run(e) ∧ Agent(e, x)))`

### Generalized Quantifier Output

**Input:** "Many dogs bark."
**Output:** `MANY x(D(x) ∧ B(x))`

**Input:** "Most birds fly."
**Output:** `MOST x(B(x) ∧ F(x))`

**Input:** "Few cats swim."
**Output:** `FEW x(C(x) ∧ S(x))`

### Measurement Output (Phase 8)

**Input:** "John is 2 inches taller than Mary."
**Output:** `Taller(j, m, 2 inches)`

**Input:** "The rope is 5 meters long."
**Output:** `Long(rope, 5 meters)`

**Input:** "Set A has cardinality aleph_0."
**Output:** `Cardinality(A, aleph_0)`

**Input:** "The temperature is 98.6 degrees."
**Output:** `Temperature(t, 98.6 degrees)`

### Zero-Derivation Output (Phase 9)

**Input:** "The committee tabled the discussion."
**Output:** `∃e(Table(e) ∧ Agent(e, committee) ∧ Theme(e, discussion))`

**Input:** "She emailed him."
**Output:** `∃e(Email(e) ∧ Agent(e, she) ∧ Theme(e, him))`

**Input:** "John googled the answer."
**Output:** `∃e(Google(e) ∧ Agent(e, j) ∧ Theme(e, answer))`

### VP Ellipsis Output (Phase 10a)

**Input:** "John runs. Mary does too."
**Output:** `Run(j) ∧ Run(m)`

**Input:** "John can swim. Mary can too."
**Output:** `◇Swim(j) ∧ ◇Swim(m)`

**Input:** "John runs. Mary does not."
**Output:** `Run(j) ∧ ¬Run(m)`

**Input:** "John eats an apple. Mary does too."
**Output:** `∃e(Eat(e) ∧ Agent(e,j) ∧ Theme(e,apple)) ∧ ∃e(Eat(e) ∧ Agent(e,m) ∧ Theme(e,apple))`

### Sluicing Output (Phase 10b)

**Input:** "Someone left. I know who."
**Output:** `∃x(Leave(x)) ∧ Know(I, Question(y, Leave(y)))`

**Input:** "John ate something. I know what."
**Output:** `∃x(Eat(j,x)) ∧ Know(I, Question(y, Eat(j,y)))`

**Input:** "Someone called. I don't know who."
**Output:** `∃x(Call(x)) ∧ ¬Know(I, Question(y, Call(y)))`

**Input:** "Someone ran. I wonder who."
**Output:** `∃x(Run(x)) ∧ Wonder(I, Question(y, Run(y)))`

### Topicalization Output

**Input:** "The apple, John ate."
**Output:** `∃x(((Apple(x) ∧ ∀y((Apple(y) → y = x))) ∧ Eat(J, x)))`

**Input:** "The red apple, John ate."
**Output:** `∃x(((Red(x) ∧ Apple(x) ∧ ∀y((...) → y = x))) ∧ Eat(J, x)))`

**Input:** "A book, Mary read."
**Output:** `∃x((Book(x) ∧ Read(M, x)))` - indefinite topic

### Long-Distance Wh-Movement Output

**Input:** "Who did John say Mary loves?"
**Output:** `λx.Say(J, Love(M, x))` - gap filled in embedded clause

**Input:** "To whom did John give the book?"
**Output:** `λx.Give(J, book, x)` - pied-piped preposition

### Embedded Clause (Sentential Complement) Output

**Input:** "John said Mary runs."
**Output:** `Say(J, [Run(M)])` - embedded clause as argument with bracket notation

**Input:** "Who did John say Mary loves?"
**Output:** `λx.Past(Say(J, [Love(M, x)]))` - gap filled in embedded Proposition

**Input:** "John believes Mary won."
**Output:** `Believe(J, [Past(Win(M))])` - propositional attitude with clause argument

### Reichenbach Temporal Output

**Input:** "John had run." (Past Perfect)
**Output:** `Precedes(e, r) ∧ Precedes(r, S) ∧ Run(e, j)` - E < R < S

**Input:** "John will have run." (Future Perfect)
**Output:** `Precedes(S, r) ∧ Precedes(e, r) ∧ Run(e, j)` - S < R, E < R

**Input:** "John has run." (Present Perfect)
**Output:** `Precedes(e, r) ∧ Run(e, j)` - E < R (R = S implicit)

---

## Glossary

### First-Order Logic Terms

| Term | Definition |
|------|------------|
| **Predicate** | A property or relation: P(x), Loves(x,y) |
| **Quantifier** | Binds variables: ∀ (universal), ∃ (existential), Gen (generic) |
| **Generic Quantifier** | Law-like generalization over a kind: "Birds fly" → Gen x(Bird(x) → Fly(x)) |
| **Variable** | A placeholder: x, y, z |
| **Constant** | A named individual: socrates, fido |
| **Connective** | Logical operators: ∧ (and), ∨ (or), → (implies), ↔ (iff), ¬ (not) |
| **Formula** | A well-formed logical expression |
| **Scope** | The extent of a quantifier's binding |
| **Free Variable** | A variable not bound by any quantifier |
| **Bound Variable** | A variable within a quantifier's scope |

### Modal Logic Terms

| Term | Definition |
|------|------------|
| **Necessity (□)** | True in all possible worlds |
| **Possibility (◇)** | True in at least one possible world |
| **Alethic** | Concerning truth and necessity |
| **Deontic** | Concerning obligation and permission |
| **Epistemic** | Concerning knowledge and belief |

### Linguistic Terms

| Term | Definition |
|------|------------|
| **Noun Phrase** | A noun with modifiers: "the tall man" |
| **Verb Phrase** | A verb with complements: "loves Mary" |
| **Relative Clause** | A clause modifying a noun: "who runs" |
| **Anaphora** | Reference to a previous expression |
| **Definiteness** | Whether a noun is specific: "the" vs "a" |
| **Aspect** | Temporal structure of events |
| **Thematic Role** | Semantic role: agent, patient, theme |
| **Gapping** | Ellipsis of a verb in coordination: "John ate an apple, and Mary, a pear" |
| **PP-Attachment** | Where a prepositional phrase attaches: VP (instrument) or NP (modifier) |
| **Bare Plural** | Plural noun without determiner: "birds" (triggers generic reading) |
| **Collective Verb** | Verb requiring group action: "gather", "meet", "disperse" |
| **Distributive Verb** | Verb applying to each individual: "bark", "run", "sleep" |
| **Mereology** | Theory of parts and wholes; used for plural semantics |
| **Thematic Role** | Semantic role in event: Agent, Patient, Theme, Goal, etc. |
| **Control Verb** | Verb where embedded subject is controlled: "want", "try" |
| **Raising Verb** | Verb where subject raises from embedded clause: "seem" |
| **PRO** | Silent pronoun in infinitival clauses bound by controller |
| **Presupposition** | Background assumption triggered by certain expressions |
| **Focus Particle** | Word highlighting alternatives: "only", "even", "just" |
| **Counterfactual** | Conditional contrary to fact: "if...had...would" |
| **Deixis** | Contextual reference: "this/that" (proximal/distal), "here/there", "now/then" |
| **Ditransitive Verb** | Verb taking two objects: "give", "send", "tell" (Agent, Recipient, Theme) |
| **Gerund** | Verb form functioning as noun: "Running is fun", "I love swimming" |
| **Causal Connective** | Word linking cause to effect: "because" → Cause(antecedent, consequent) |
| **Mass Noun** | Uncountable noun: "water", "rice", "information" (quantified by "much"/"little") |
| **Reciprocal** | Bidirectional relation with "each other": P(x,y) ∧ P(y,x) |
| **NPI (Negative Polarity Item)** | Words like "any" requiring negative context for existential reading |
| **Free Choice Any** | Universal "any" in positive contexts: ∀x |
| **Garden Path** | Sentence requiring structural reanalysis due to initial misparse |
| **Reduced Relative** | Relative clause without "who/that": "the man seen" = "the man who was seen" |
| **Perfect Aspect** | Completed action with current relevance: "has eaten" → Perf(φ) |
| **Progressive Aspect** | Ongoing action: "is eating" → Prog(φ) |
| **Habitual Aspect** | Present tense activity/accomplishment/achievement interpretation: "runs" → HAB(Run(x)) |
| **Iterative Aspect** | Progressive semelfactive producing repeated event: "is knocking" → ITER(Knock) |
| **Aspect Chain** | Stacked aspect operators: modal + perfect + passive + progressive |
| **Contact Clause** | Relative clause without overt "who/that": "the man I saw" = "the man that I saw" |
| **Vendler Class** | Lexical aspect category: State, Activity, Accomplishment, Achievement, Semelfactive |
| **Stative** | Verb class feature (+static): no change over time (know, love, exist) |
| **Durative** | Verb class feature (+durative): extends over time (run, build) vs punctual (win, knock) |
| **Telic** | Verb class feature (+telic): has natural endpoint (build, win) vs atelic (run, know) |
| **Semelfactive** | Punctual, atelic verb class: single events (knock, blink, cough) |
| **Aktionsart** | German term for lexical aspect; verb-inherent temporal properties (synonym: Vendler class) |
| **Subsective Adjective** | Adjective whose meaning depends on noun class: "small" relative to elephants vs mice |
| **Intersective Adjective** | Adjective forming independent predicate: "red" applies regardless of noun |
| **Non-Intersective Adjective** | Adjective modifying the noun concept itself: "fake gun" |
| **Generalized Quantifier** | Quantifiers beyond ∀/∃: MANY, MOST, FEW with cardinality semantics |
| **Degree Phrase** | Measure expression modifying comparison: "2 inches" in "2 inches taller" |
| **Absolute Measurement** | Direct dimension attribution: "5 meters long" |
| **Symbolic Number** | Mathematical constant: aleph_0, omega for infinite cardinals |
| **Compound Identifier** | Noun followed by proper name or single letter label: "set A" → set_A |
| **Zero-Derivation** | Conversion of a word from one category to another without morphological change: "table" (noun) → "table" (verb) |
| **VP Ellipsis** | Omission of a verb phrase that is recoverable from context: "John runs. Mary does too." = Mary runs |
| **Sluicing** | Ellipsis of a wh-clause recoverable from context: "Someone left. I know who." = I know who left |

### Implementation Terms

| Term | Definition |
|------|------------|
| **Token** | A classified unit from the lexer |
| **Lexeme** | The actual text of a token |
| **AST** | Abstract Syntax Tree (arena-allocated with Copy semantics) |
| **Parse Forest** | Multiple AST trees for ambiguous sentences; returned by compile_ambiguous() |
| **Recursive Descent** | Top-down parsing strategy with backtracking for ellipsis |
| **Precedence** | Operator binding strength |
| **Interning** | Storing strings once, referencing by ID |
| **Arena Allocation** | Batch memory allocation via bumpalo; enables Copy AST nodes |
| **Beta Reduction** | Lambda calculus substitution |
| **Backtracking** | Parser technique for handling gapping by rewinding and retrying |
| **Sigma (σ)** | Term constructor for maximal sum of a predicate: σx.Dog(x) |
| **Distributive (*)** | Expression wrapper for distributive readings over plurals |
| **Group (⊕)** | Term constructor for sum of individuals: J ⊕ M |
| **NeoEvent** | Expression with event variable and thematic role assignments |
| **Control** | Expression for control/raising verb structures |
| **ThematicRole** | Enum: Agent, Patient, Theme, Goal, Source, Recipient, Instrument, Location, Time, Manner |
| **Recipient** | Thematic role for indirect object in ditransitive verbs |
| **Causal** | Expression variant representing cause-effect relationships: Cause(antecedent, consequent) |
| **MeasureKind** | Enum for quantity expressions: Much, Little (used with mass nouns) |
| **AstContext** | Unified struct holding all arena allocators for AST construction |
| **ParserCheckpoint** | RAII struct for parser backtracking with automatic restore |
| **ParserGuard** | RAII struct with Deref for transparent parser access; auto-restores on drop unless commit() called |
| **Visitor** | Trait for traversing AST nodes without manual recursion |
| **Fluent builders** | Inline methods on AstContext (binary, unary, quantifier, temporal, aspectual, modal) for ergonomic AST construction |
| **Semantic token sets** | Const arrays (WH_WORDS, MODALS) grouping related tokens for check_any() matching |
| **Zero-alloc transpile** | Output methods using Write trait to avoid String allocation |
| **Span** | Byte range (start, end) for source location tracking on tokens |
| **display_with_source()** | Renders ParseError with line numbers and underline markers pointing to error location |
| **assert_snapshot!** | Macro for golden master testing; compares output against stored snapshots in tests/snapshots/ |
| **Levenshtein distance** | Edit distance algorithm for finding similar words; used for 'did you mean?' suggestions |
| **find_similar()** | Finds closest vocabulary match within threshold for typo correction |
| **Style** | ANSI color wrapper with red(), blue(), cyan(), green(), bold_red() methods |
| **VoiceOperator** | Enum for voice handling in AST: Passive variant |
| **VerbClass** | Enum for Vendler categories: State, Activity, Accomplishment, Achievement, Semelfactive |
| **VerbEntry** | Struct with lemma, time, aspect, and class fields for verb dictionary entries |
| **is_stative()** | VerbClass method returning true for State class |
| **is_durative()** | VerbClass method returning true for State, Activity, Accomplishment |
| **is_telic()** | VerbClass method returning true for Accomplishment, Achievement |
| **is_negative_context()** | Parser method tracking negation depth for NPI licensing |
| **is_followed_by_gerund()** | Parser helper checking if presupposition trigger is followed by gerund; prevents false presupposition on bare "stopped" |
| **parse_aspect_chain()** | Parser method handling complex verb group stacking |
| **parse_aspect_chain_with_term()** | Parser method for aspect chains with variable subjects (used in relative clause + modal combinations) |
| **Stacked Relatives** | Multiple relative clauses modifying same head noun: "the book that X read that Y wrote" |
| **try_reduced_relative_interpretation()** | Parser method for garden path reanalysis |
| **is_contact_clause_pattern()** | Parser lookahead for NP+NP+Verb contact clause detection |
| **Island** | Scope boundary preventing quantifier extraction: if/and/or clauses |
| **island_id** | u32 field on Quantifier identifying its scope island |
| **enumerate_scopings()** | Function returning ScopeIterator over all quantifier scope readings |
| **ScopeIterator** | Lazy iterator implementing ExactSizeIterator for scope readings |
| **group_by_island()** | Groups quantifiers by island_id to constrain permutations |
| **De Re** | "Of the thing" - object exists, quantifier scopes wide |
| **De Dicto** | "Of the word" - intensional reading, quantifier scopes narrow |
| **Opaque Verb** | Verb creating intensional context: seek, want, believe, need, fear |
| **is_opaque_verb()** | Function checking if a verb creates an opaque context |
| **Intension (^)** | Montague up-arrow marking concept/property vs individual |
| **Term::Intension** | Term variant for intensional predicates: ^Unicorn |
| **Expr::Intensional** | Expression wrapper for opaque verb contexts |
| **substitute_respecting_opacity()** | Substitution that blocks inside intensional contexts |
| **enumerate_intensional_readings()** | Generates de re and de dicto readings for opaque verb sentences |
| **IntensionalContext** | Struct tracking opaque verb, quantifier variable, and restrictor |
| **compile_all_scopes()** | Public API returning all scope + intensionality readings |
| **Topicalization** | Object fronting with comma intonation break: "NP, Subject Verb" pattern |
| **filler_gap** | Parser field (Option<Symbol>) tracking wh-filler for long-distance dependencies |
| **Long-Distance Dependency** | Extraction across clause boundaries: "Who did John say Mary loves?" |
| **Pied-Piping** | P+wh fronting: "To whom" instead of "Who...to" |
| **wrap_with_definiteness_full()** | NounPhrase wrapper preserving adjectives during topicalization |
| **Phase 4 Movement Tests** | tests/phase4_movement.rs: topicalization, adjective preservation, pronoun subjects |
| **Term::Proposition** | Term variant wrapping embedded Expr for sentential complements |
| **Sentential Complement** | Clause serving as argument: "John said [Mary runs]" |
| **Bracket Notation [expr]** | Transpilation format for embedded clauses to distinguish from conjunction |
| **Phase 5 Wh-Movement Tests** | tests/phase5_wh_movement.rs: long-distance extraction, embedded clauses, double embedding |
| **Reichenbach Semantics** | Three-point temporal model with E (event), R (reference), S (speech) |
| **Event Point (E)** | When the event occurs in Reichenbach model |
| **Reference Point (R)** | Temporal vantage point for viewing event |
| **Speech Point (S)** | Time of utterance |
| **Precedes(x, y)** | Temporal ordering predicate: x before y |
| **Phase 6 Complex Tense Tests** | tests/phase6_complex_tense.rs: Reichenbach E/R/S temporal constraints |
| **is_subsective()** | Generated function checking if adjective is subsective (relative to class) |
| **QuantifierKind::Many** | AST variant for generalized "many" quantifier |
| **QuantifierKind::Most** | AST variant for generalized "most" quantifier |
| **QuantifierKind::Few** | AST variant for generalized "few" quantifier |
| **Term::Intension** | Term variant for Montague up-arrow notation (^Noun) in subsective contexts |
| **Dimension** | Enum for measurement categories: Length, Time, Weight, Temperature, Cardinality |
| **NumberKind** | Enum for numeric types: Real(f64), Integer(i64), Symbolic(Symbol) |
| **Term::Value** | Term variant storing numeric value with optional unit Symbol and Dimension |
| **Comparative.difference** | Optional field for measure phrase in comparative expressions |
| **TokenType::Number** | Token variant storing numeric literal as interned Symbol |
| **parse_measure()** | Parser method for measure phrase expressions |
| **Phase 8 Degree Tests** | tests/phase8_degrees.rs: numeric measurement and degree semantics |
| **check_proper_name_or_label()** | Parser helper detecting proper names or single uppercase letter labels for compound identifier parsing |
| **Passive Agent Extraction** | Pattern matching "by X" after passive "been" to identify the semantic agent in passive constructions |
| **Consonant Cluster Heuristic** | Morphological rule: vowel + consonant + l/r at word end suggests silent-e lemma recovery (tabl → table) |
| **Phase 9 Zero-Derivation Tests** | tests/phase9_conversion.rs: noun→verb conversion with silent-e recovery |
| **EventTemplate** | Struct storing verb + non-agent thematic roles + modifiers for VP ellipsis reconstruction |
| **Phase 10a VP Ellipsis Tests** | tests/phase10_ellipsis.rs: VP ellipsis with does too, modal too, negation, and objects |
| **Contraction Expansion** | Lexer splits negative contractions: don't→do+not, won't→will+not, can't→cannot |
| **Phase 10b Sluicing Tests** | tests/phase10b_sluicing.rs: sluicing with who/what, negation, embedding verbs |
| **Verb-First Priority** | Classification order: verbs checked before nouns in lexer. Parser safety net via consume_content_word() accepts Verb tokens in noun positions. |
| **disambiguation_not_verbs** | Lexicon list of words that should NOT be classified as verbs despite having verb forms (ring, bus). Returns Noun if also in nouns list. |
| **Polysemy Resolution** | Handling words with multiple parts of speech. Verb-first + parser safety net enables "I love you" and "Love is real" from same token type. |
| **compile_forest()** | Phase 12 API returning Vec<String> of all valid parse readings for ambiguous sentences. |
| **MAX_FOREST_READINGS** | Constant (12) limiting parse forest size to prevent exponential blowup. |
| **noun_priority_mode** | Parser flag that prefers noun interpretation for Ambiguous tokens; used for lexical ambiguity forking. |
| **TokenType::Ambiguous** | Token variant with primary interpretation and alternatives Vec for polysemous words (duck, bear, love). |
| **Sort** | Phase 11 ontological type category: Human, Animate, Celestial, Abstract, Physical, Value. |
| **lookup_sort()** | Returns Sort for proper names; used for semantic type checking. |
| **is_compatible_with()** | Sort method checking type subsumption (Human⊂Animate⊂Physical). |
| **Lexical Ambiguity** | Words with multiple parts of speech requiring parse forest (e.g., "duck" as Noun or Verb). |
| **Structural Ambiguity** | Syntactic attachment ambiguity (PP attachment, coordination scope) handled via pp_attachment_mode. |
| **MweTrie** | Trie data structure for multi-word expression pattern storage and efficient longest-match lookup. |
| **apply_mwe_pipeline()** | Post-tokenization function that collapses multi-token MWE sequences into single tokens. |
| **build_mwe_trie()** | Creates default MWE vocabulary trie with compound nouns, idioms, and phrasal verbs. |
| **find_bridging_wholes()** | Ontology function returning possible whole objects for a given part noun (e.g., "engine" → ["car", "plane"]). |
| **check_sort_compatibility()** | Validates predicate-subject sort match; returns true if compatible or no requirement exists. |
| **PartOf** | Term relation representing part-whole relationship in bridging anaphora (e.g., PartOf(engine, car)). |
| **Bridging Anaphora** | Pragmatic inference linking a definite NP to an antecedent's part (e.g., "a car... the engine" → engine is part of car). |
| **Copula Adjective Preference** | Parser heuristic: after copula (is/was), simple-aspect Verbs with Adjective alternative prefer Adjective reading. |
| **is_adjective_like()** | Lexer heuristic checking if word could be an adjective for ambiguity detection. |
| **is_noun_like()** | Lexer heuristic checking if word could be a noun for ambiguity detection. |
| **is_verb_like()** | Lexer heuristic checking if word could be a verb for disambiguation. |
| **NPI (Negative Polarity Item)** | Words like "any", "ever", "anything" that require negative context for existential interpretation. |
| **Free Choice Any** | "Any" in affirmative contexts producing universal quantification: "Any cat hunts" → ∀x. |
| **Negative Quantifier** | Inherently negative quantifiers (nobody, nothing, no one) that produce ∀x(R(x) → ¬P(x)). |
| **NPI Licensing** | Process by which negative context triggers existential interpretation of NPIs. |

---

## Integration Tests

Comprehensive test suite validating parsing and transpilation across 15 linguistic phases.

**Location:** `tests/`

#### Phase 1: Garden Path

**File:** `tests/phase1_garden_path.rs`

Garden path sentences requiring structural reanalysis. Parser detects reduced relatives via backtracking when initial parse leaves unparsed tokens.

**Example:** "The horse raced past the barn fell." → ∃x(Horse(x) ∧ RacedPast(x, barn) ∧ Fell(x))

---

#### Phase 2: Polarity Items

**File:** `tests/phase2_polarity.rs`

Negative Polarity Items (NPIs). 'any' is existential in negative/conditional contexts, universal in positive contexts. Parser tracks negative_depth for NPI licensing.

**Example:** "Not any dogs run." → ¬∃x(D(x) ∧ R(x)) vs "Any dog runs." → ∀x(D(x) → R(x))

---

#### Phase 3: Temporal Logic

**File:** `tests/phase3_time.rs`

Reichenbach temporal semantics with Event (E), Reference (R), and Speech (S) points. Tests simple tense, perfect aspect, and temporal anchoring.

**Example:** "John had run." (past perfect) → Precedes(e, r) ∧ Precedes(r, S)

---

#### Phase 3: Aspect & Aktionsart

**File:** `tests/phase3_aspect.rs`

Vendler aspectual classes (State/Activity/Accomplishment/Achievement/Semelfactive) and grammatical aspect interaction. Habitual for present-tense activities.

**Example:** "John is knocking." (semelfactive+prog) → ITER(Knock(j))

---

#### Phase 4: Topicalization

**File:** `tests/phase4_movement.rs`

Filler-gap dependencies and object fronting. Tests NP-fronting with adjective preservation and pronoun subjects.

**Example:** "The apple, John ate." → Eat(J, apple) with fronted Theme

---

#### Phase 4: Reciprocals

**File:** `tests/phase4_reciprocals.rs`

Reciprocal 'each other' expands to bidirectional predicate conjunction for plural subjects.

**Example:** "John and Mary love each other." → Love(j,m) ∧ Love(m,j)

---

#### Phase 5: Wh-Movement

**File:** `tests/phase5_wh_movement.rs`

Long-distance wh-dependencies across embedded clauses. Filler-gap binding through subordinate clauses with Term::Proposition wrapping.

**Example:** "Who did John say Mary loves?" → λx.Say(J, [Love(M, x)])

---

#### Phase 6: Complex Tense

**File:** `tests/phase6_complex_tense.rs`

Reichenbach temporal constraints with explicit E/R/S point relations. Verifies Precedes() predicate output.

**Example:** Past perfect: E < R < S; Future perfect: S < R, E < R

---

#### Phase 7: Intensional Semantics

**File:** `tests/phase7_semantics.rs`

Subsective adjectives (S(x, ^E) format) and generalized quantifiers (MANY, MOST, FEW with cardinality semantics).

**Example:** "A small elephant ran." → ∃x(S(x, ^E) ∧ E(x) ∧ Run(x))

---

#### Phase 8: Degrees & Comparatives

**File:** `tests/phase8_degrees.rs`

Numeric measurements and degree semantics. Tests comparatives with measure phrases, absolute measurements, and symbolic cardinality.

**Example:** "John is 2 inches taller than Mary." → Taller(j, m, 2 inches)

---

#### Phase 8.5 & 8.6: Zone System

**File:** `tests/phase85_zones.rs`

Region-based memory management. Heap zones via bumpalo (Inside a zone called X of size N KB/MB:), memory-mapped files (mapped from 'file.bin'), escape analysis for 'Hotel California' rule (values cannot escape zones), O(1) allocation and bulk deallocation.

**Example:** Inside a zone called "Scratch" of size 2 MB: Let x be 5. → Zone::new_heap(2097152)

---

#### Phase 9: Noun/Verb Conversion

**File:** `tests/phase9_conversion.rs`

Zero-derivation (noun→verb): tabled, emailed, googled. Morphological heuristics for silent-e lemma recovery.

**Example:** "The committee tabled the motion." → Table(committee, motion)

---

#### Phase 9.5: Structured Concurrency

**File:** `tests/phase9_structured_concurrency.rs`

Concurrent and parallel execution blocks. 'Attempt all of the following:' generates tokio::join! (async, I/O-bound). 'Simultaneously:' generates rayon::join (CPU-bound, 2 tasks) or thread::spawn (3+ tasks). Let bindings destructure into tuples.

**Example:** Simultaneously: Let a be 1. Let b be 2. → let (a, b) = rayon::join(|| 1, || 2);

---

#### Phase 10a: VP Ellipsis

**File:** `tests/phase10_ellipsis.rs`

VP ellipsis reconstruction via EventTemplate. Handles 'does too', modal ellipsis, negative ellipsis, and ellipsis with objects.

**Example:** "John runs. Mary does too." → Run(j) ∧ Run(m)

---

#### Phase 10b: Sluicing

**File:** `tests/phase10b_sluicing.rs`

Sluicing reconstruction: wh-words at sentence boundary after embedding verbs. Handles contractions (don't know who).

**Example:** "Someone left. I know who." → ∃x(Leave(x)) ∧ Know(I, ?y[Leave(y)])

---

#### Phase 11: Ontological Sorts

**File:** `tests/phase11_sorts.rs`

Sort system with type hierarchy (Human⊂Animate⊂Physical). Sort compatibility checking for semantic validation.

**Example:** Sort::Human.is_compatible_with(Sort::Animate) → true

---

#### Phase 11: Metaphor Detection

**File:** `tests/phase11_metaphor.rs`

Metaphor detection via sort violations. Distinguishes literal copula from metaphorical assertions.

**Example:** "The king is bald." → literal; "Juliet is the sun." → sort violation → metaphor

---

#### Phase 12: Parse Forest

**File:** `tests/phase12_ambiguity.rs`

Lexical and structural ambiguity handling. compile_forest() returns Vec of all valid readings for ambiguous sentences.

**Example:** "I saw her duck." → 2 readings (duck=Noun vs duck=Verb)

---

#### Phase 13: Multi-Word Expressions

**File:** `tests/phase13_mwe.rs`

MWE processing: compound nouns (fire engine → FireEngine), idioms (kicked the bucket → Die), phrasal verbs (gave up → Surrender). Trie-based pipeline collapses multi-token sequences into single semantic units.

**Example:** "John kicked the bucket." → Die(j)

---

#### Phase 14: Ontology & Bridging

**File:** `tests/phase14_ontology.rs`

Bridging anaphora for part-whole inference (PartOf relation). Metaphor detection via sort violations. Sort compatibility checking for predicates.

**Example:** "I bought a car. The engine smoked." → PartOf(engine, car)

---

#### Phase 15: Negation & Polarity

**File:** `tests/phase15_negation.rs`

NPI processing: free choice 'any' (universal), NPI 'any' with negation (existential), negative quantifiers (nobody/nothing/no one), temporal NPIs (never/ever), scope interactions. Licensing determines existential vs universal interpretation.

**Example:** "Any cat hunts." → ∀x(Cat(x) → Hunt(x)); "John did not see any cat." → ¬∃x(Cat(x) ∧ See(j,x))

---

#### Phase 16: Aspect Stack

**File:** `tests/phase16_aspect.rs`

Complex aspect operator combinations: Perfect+Progressive, Perfect+Passive, Modal+Perfect+Progressive. Tests proper operator nesting without conflation (e.g., Perfect+Progressive should NOT imply Passive).

**Example:** "John has been eating apples." → Perf(Prog(Eat(j, apples)))

---

#### Phase 17: Comparatives & Superlatives

**File:** `tests/phase17_degrees.rs`

Extended degree semantics: comparatives with measure phrases, clausal comparative ellipsis, and superlatives with domain restriction. Superlatives expand to universal quantification over the comparison class.

**Example:** "John climbed the highest mountain." → ∀x((Mountain(x) ∧ x ≠ m) → Higher(m, x))

---

#### Phase 18: Plurality

**File:** `tests/phase18_plurality.rs`

Collective vs distributive verb semantics. Mixed verbs fork readings for plural subjects (lifted → collective OR distributive). Collective verbs (gathered) force group reading. Distributive verbs (slept) force individual reading.

**Example:** "The boys lifted the piano." → Collective: Lift(σB, piano) OR Distributive: *Lift(σB, piano)

---

#### Phase 19: Group Plurals

**File:** `tests/phase19_group_plurals.rs`

Group existential quantification for cardinal indefinites with collective readings. Cardinal + mixed verb forks into distributive (∃=n) and collective (Group/Count/Member) readings. Collective verbs force group reading.

**Example:** "Two boys lifted a rock." → Collective: ∃g(Group(g) ∧ Count(g, 2) ∧ ∀x(Member(x, g) → B(x)) ∧ Lift(g, rock))

---

#### Phase 20: Axiom Layer

**File:** `tests/phase20_axioms.rs`

Semantic axiom expansion for meaning postulates. Bachelor→Unmarried∧Male∧Adult, privative adjectives (fake→¬N∧Resembles(^N)), verb entailments (murder→kill), and hypernym chains (dog→animal→mammal). Pipeline position: Parser→Axioms→Pragmatics.

**Example:** "John is a bachelor." → B(J) ∧ Unmarried(J) ∧ Male(J) ∧ Adult(J)

---

#### Phase 21: Block Headers

**File:** `tests/phase21_block_headers.rs`

Parsing ## Main and other block headers that trigger imperative mode. Block headers mark the transition from declarative logic to executable code.

**Example:** "## Main" triggers imperative parsing mode

---

#### Phase 21: Imperative Verbs

**File:** `tests/phase21_imperative_verbs.rs`

Let/Set/Return statement parsing in imperative blocks. Let binds values, Set mutates, Return exits functions.

**Example:** "Let x be 5." → let x = 5;

---

#### Phase 21: Ownership

**File:** `tests/phase21_ownership.rs`

Rust-style ownership semantics via natural language verbs. Give performs moves, Show performs immutable borrows. Tracks owned/moved/borrowed states.

**Example:** "Give x to f." → f(x) // x is moved

---

#### Phase 22: Equality

**File:** `tests/phase22_equals.rs`

Identity predicates and equality relations. Handles 'is equal to', 'is identical to', and numeric equality.

**Example:** "x is equal to y" → x = y

---

#### Phase 22: Indexing

**File:** `tests/phase22_index.rs`

Array and collection indexing operations. Supports numeric indices and slice syntax.

**Example:** "the third element of xs" → xs[2]

---

#### Phase 22: Is-Rejection

**File:** `tests/phase22_is_rejection.rs`

Filtering non-predicate uses of 'is' copula in imperative context. Distinguishes identity from predication.

**Example:** "x is large" vs "x is 5"

---

#### Phase 22: Resolution

**File:** `tests/phase22_resolution.rs`

Anaphora and reference resolution in imperative blocks. Resolves pronouns and definite descriptions to bound variables.

**Example:** "Let x be 5. Return it." → it resolves to x

---

#### Phase 22: Scope

**File:** `tests/phase22_scope.rs`

Variable scope and quantifier interactions in imperative code. Handles block scoping and shadowing.

**Example:** Block-level variable scoping

---

#### Phase 23: Blocks

**File:** `tests/phase23_blocks.rs`

Indentation-based block structure parsing. Python-style significant whitespace with Colon/Indent/Dedent tokens.

**Example:** Indent → block body → Dedent

---

#### Phase 23: Parsing

**File:** `tests/phase23_parsing.rs`

Parser internals and mode switching between declarative and imperative modes. Tests ParserMode enum.

**Example:** Declarative mode ↔ Imperative mode

---

#### Phase 23: Statements

**File:** `tests/phase23_stmt.rs`

Stmt enum variants: Let, Set, Call, If, While, Return, Assert, Give, Show. The imperative AST types.

**Example:** Stmt::Let { name, value }

---

#### Phase 23: Tokens

**File:** `tests/phase23_tokens.rs`

Token type verification for imperative constructs. Tests Give, Show, Let, Set, Return, Assert token recognition.

**Example:** TokenType::Give, TokenType::Show

---

#### Phase 23: Types

**File:** `tests/phase23_types.rs`

TypeRegistry and DiscoveryPass for two-pass compilation. First pass discovers type definitions, second pass resolves references.

**Example:** ## Definition blocks → TypeRegistry

---

#### Phase 24: Code Generation

**File:** `tests/phase24_codegen.rs`

Rust code emission for literals and expressions. Converts imperative AST to valid Rust source code.

**Example:** Stmt → fn main() { ... }

---

#### Phase 24: Pipeline Wiring

**File:** `tests/phase24_wired_types.rs`

Two-pass compilation pipeline integration. DiscoveryPass runs before parser to build TypeRegistry. Parser uses registry for type vs predicate disambiguation.

**Example:** Stack of Integers → Generic type when Stack is defined

---

#### Phase 25: Type Expressions

**File:** `tests/phase25_type_expr.rs`

Type annotations for Let statements. Supports primitives (Int→i64, Nat→u64, Text→String), generics (List of Int→Vec<i64>), multi-param generics (Result of Int and Text), nested generics, and mutable bindings.

**Example:** Let x: Int be 5. → let x: i64 = 5;

---

#### Phase 25: Assertions

**File:** `tests/phase25_assertions.rs`

Logic kernel assertions via Assert statements. Bridges imperative code to declarative verification using debug_assert! macros.

**Example:** "Assert that x is positive." → debug_assert!(x > 0)

---

#### Phase 25: Smoke Tests

**File:** `tests/phase25_smoke_tests.rs`

Aspirational tests for advanced linguistic phenomena. Covers scopal adverbs (almost/barely wrapping events), negation scope ambiguity, donkey anaphora, intensional identity, performatives, distanced phrasal verbs, and double focus operators. Some tests expected to fail until features implemented.

**Example:** "John almost killed Mary." → Almost(∃e(Kill(e) ∧ Agent(e, J) ∧ Theme(e, M)))

---

#### Phase 26: End-to-End

**File:** `tests/phase26_e2e.rs`

Full pipeline tests: English → AST → Rust code. Tests compile_to_rust output for complete programs.

**Example:** English source → executable Rust

---

#### Phase 27: Guards

**File:** `tests/phase27_guards.rs`

Guard clauses and conditional patterns. Handles 'if' conditions and pattern guards in function definitions.

**Example:** "If x is negative, return 0." → guard clause

---

#### Phase 28: Precedence

**File:** `tests/phase28_precedence.rs`

Operator precedence and associativity. Ensures correct parsing of complex expressions with mixed operators.

**Example:** a + b * c → a + (b * c)

---

#### Phase 29: Runtime Injection

**File:** `tests/phase29_runtime.rs`

Embeds logos_core/ runtime into compiled programs. Type aliases (Nat, Int, Real, Text, Bool, Unit) and IO functions (show, read_line) per Spec §10.5 and §10.6.1.

**Example:** use logos_core::prelude::*; // Auto-injected

---

#### Phase 30: Collections & Iteration

**File:** `tests/phase30_iteration.rs`

Seq<T> generic type, list literals [1, 2, 3], repeat loops (for x in list:), range syntax (from N to M), and Showable trait. Mode-dependent 'in' keyword handling.

**Example:** Repeat for x in [1, 2, 3]: → for x in vec![1, 2, 3]

---

#### Phase 31: User-Defined Types

**File:** `tests/phase31_structs.rs`

Struct definitions with encapsulation. Syntax: 'A TypeName has: a [public] field, which is Type.' Constructor generation (new Type), field access (var's field), field mutations (Set var's field to value), and visibility modifiers (pub/private fields).

**Example:** A Point has: a public x, which is Int.

---

#### Phase 32: Function Definitions & Inference

**File:** `tests/phase32_functions.rs`

User-defined functions with ## To [verb] syntax. Call expression syntax f(x, y) for use in expressions, return type inference from body, and dual call syntax (Call f with x. for statements, f(x) for expressions).

**Example:** ## To add (a: Int) and (b: Int): → fn add(a: i64, b: i64) -> i64

---

#### Phase 33: Sum Types & Pattern Matching

**File:** `tests/phase33_enums.rs`

Algebraic data types with 'A Type is either:' syntax. Variant constructors with optional payloads (A Circle with radius value.), pattern matching via 'Inspect expr:' with match arms, and field bindings in patterns (When Circle (radius: r):).

**Example:** A Shape is either: A Circle with a radius, which is Int.

---

#### Phase 34: User-Defined Generics

**File:** `tests/phase34_generics.rs`

Generic type parameters with 'of [T]' syntax. Single-param (A Box of [T] has:), multi-param (A Pair of [A] and [B] has:), generic enums (A Maybe of [T] is either:), and turbofish instantiation (new Box of Int → Box::<i64>::default()).

**Example:** A Box of [T] has: a value, which is T.

---

#### Phase 35: The Proof Bridge

**File:** `tests/phase35_proofs.rs`

Proof assertions with 'Trust that P because "reason".' syntax. Generates debug_assert! with justification comment. Includes variable 'a' disambiguation, number literals in propositions, irregular comparatives (less/more/better/worse), and because-string lookahead guards.

**Example:** Trust that n is greater than 0 because "precondition".

---

#### Phase 35: Respectively Coordination

**File:** `tests/phase35_respectively.rs`

Pairwise coordination with 'respectively' adverb. Matches coordinated subjects with coordinated objects pairwise (John and Mary saw Tom and Jane respectively → See(J,T) ∧ See(M,J)). Includes RespectivelyLengthMismatch error for mismatched counts, dual code paths for pronoun and noun phrase subjects.

**Example:** John and Mary saw Tom and Jane respectively.

---

#### Phase 36: Module System

**File:** `tests/phase36_modules.rs`

Multi-file projects with Use statements. Import syntax (Use Math.), module discovery, and cross-file type/function resolution.

**Example:** Use Math.

---

#### Phase 37: Project Manifest & Build Tool

**File:** `tests/phase37_cli.rs`

CLI build system with Largo.toml manifest. Commands: largo new <name>, largo build [--release], largo run, largo check. Manifest parsing with [package] and [dependencies] sections, project discovery via find_project_root().

**Example:** largo new my_game && largo build

---

#### Phase 38: Standard Library (IO & System)

**File:** `tests/phase38_stdlib.rs`

Native function bindings with 'To native fn -> Type' syntax. Standard library modules: File (read/write), Time (now/sleep), Random (randomInt/randomFloat), Env (get/args). Wrapper generation for logos_core Rust functions.

**Example:** ## To native read (path: Text) -> Result of Text and Text

---

#### Phase 41: Event Adjectives

**File:** `tests/phase41_event_adjectives.rs`

Event-modifying adjectives with agentive nouns. Dual readings: intersective (B(O) ∧ D(O)) and event-modifying (∃e((D(e) ∧ A(e,O)) ∧ B(e))). Lexicon Feature::EventModifier for beautiful/graceful/skillful. Agentive noun mappings (dancer→Dance).

**Example:** Olga is a beautiful dancer. → Intersective + Event readings

---

#### Phase 42: Discourse Representation Structures

**File:** `tests/phase42_drs.rs`

Implements Kamp's DRT for donkey anaphora. Indefinites in conditional antecedents and universal restrictors get UNIVERSAL (not existential) force. Tests binding accessibility across scope boundaries.

**Example:** Every farmer who owns a donkey beats it. → ∀x∀y((Farmer(x) ∧ Donkey(y) ∧ Own(x,y)) → Beat(x,y))

---

#### Phase 42b: Z3 Static Verification

**File:** `tests/phase_verification.rs`

Z3 SMT solver tests for static verification. Tests tautology/contradiction checking, integer bounds (>, <, ==), and LicensePlan access control. Verifier uses validity check: P is valid iff NOT(P) is UNSAT. Requires verification feature.

**Example:** Assert x > 5 (with x = 10) → Z3 proves valid

---

#### Phase 42c: Refinement Verification

**File:** `tests/phase_verification_refinement.rs`

Static verification of refinement type constraints. Tests valid/invalid literals (-5 rejected for 'it > 0'), variable tracking through Let bindings, compound predicates (it > 0 and it < 100), boundary conditions (>= 0 allows 0), and comparison operators (>, <, >=, <=, ==). verify_with_binding() proves constraints.

**Example:** Let x: Int where it > 0 be -5. → Verification failed: refinement predicate not satisfied

---

#### Phase 43B: Type Checking

**File:** `tests/phase43_type_check.rs`

Static type checking for LOGOS. Detects type mismatches between annotations and literals. TypeMismatch error reports expected vs found types.

**Example:** Let x: Int be "hello". → Error: TypeMismatch { expected: Int, found: Text }

---

#### Phase 43C: Refinement Types

**File:** `tests/phase43_refinement.rs`

Refinement types with predicate constraints. Parser handles 'Type where predicate' syntax. Codegen generates debug_assert!() checks at Let bindings and re-emits on Set mutations. RefinementContext tracks constraints across scopes for mutation enforcement.

**Example:** Let x: Int where x > 0 be 5. → let x: i64 = 5; debug_assert!((x > 0));

---

#### Phase 43D: Collection Operations

**File:** `tests/phase43_collections.rs`

Stack-like collection operations for LOGOS. Push/Pop statements, length/copy expressions, 1-based indexing with 'at', slice syntax with 'through'. Runtime helpers logos_index() and logos_index_mut().

**Example:** Push 4 to items. Pop from items into x. length of items. items at 2. items 1 through 3.

---

#### Phase 46: Agent System

**File:** `tests/phase46_agents.rs`

Autonomous agent definitions with goals and behaviors. Agent blocks define reactive entities that respond to events.

**Example:** ## Agent called Greeter: When receiving a Message: Respond with greeting.

---

#### Phase 48: Network Primitives

**File:** `tests/phase48_network.rs`

Low-level networking operations. File chunking with FileSipper, FileManifest for resumable transfers, SHA256 chunk verification.

**Example:** Fetch from url. Send data to endpoint.

---

#### Phase 49: CRDT (Conflict-free Replicated Data Types)

**File:** `tests/phase49_crdt.rs`

Distributed state synchronization without conflicts. Shared structs with ConvergentCount (GCounter) and LastWriteWins of T (LWWRegister) field types. Merge trait with commutative, associative, idempotent properties. Increase statement for counter operations.

**Example:** ## Shared Counter { count: ConvergentCount, name: LastWriteWins of Text } → impl Merge with per-field merge

---

#### Phase 50: Policy-based Security

**File:** `tests/phase50_security.rs`

Declarative security policies with predicates and capabilities. Predicate definitions (is admin if role equals 'admin'), capability definitions (can publish Document if...), Check statement for mandatory runtime enforcement (never optimized), Assert for debug-only. Logical composition with AND/OR.

**Example:** ## Policy { A User is admin if the user's role equals 'admin'. } Check that user is admin.

---

#### Phase 51: P2P Mesh Networking

**File:** `tests/phase51_mesh.rs`

Distributed peer-to-peer networking with libp2p. Listen statement binds to multiaddr, Connect to dials remote peer, PeerAgent represents remote endpoint, Send to transmits Portable messages. QUIC-first transport with TCP fallback, Noise encryption, mDNS discovery.

**Example:** Listen on '/ip4/0.0.0.0/tcp/8000'. Connect to remote_addr. Let peer be a PeerAgent at addr. Send msg to peer.

---

#### Phase 52: The Sync (GossipSub)

**File:** `tests/phase52_sync.rs`

Automatic CRDT synchronization over GossipSub. Sync binds a CRDT variable to a pub/sub topic for auto-replication. Synced<T> wrapper auto-publishes on mutation, auto-merges on receive.

**Example:** Let mutable c be a new Counter. Sync c on "room". Increase c's clicks by 5.

---

#### Phase 54: Go-like Concurrency

**File:** `tests/phase54_concurrency.rs`

Green threads and channel primitives. 'Launch a task to fn' generates tokio::spawn. 'Let ch be a Pipe of T' creates mpsc::channel. 'Send x into ch' for tx.send(). 'Receive x from ch' for rx.recv(). 'Await the first of:' generates tokio::select!. 'Stop handle' for handle.abort(). Non-blocking Try variants.

**Example:** Launch a task to worker. Let ch be a Pipe of Int. Send 42 into ch.

---

#### E2E: Collections

**File:** `tests/e2e_collections.rs`

Runtime verification of collection operations: list literals [1, 2, 3], Push/Pop, length, 1-based indexing with 'item X of', and slicing with 'through'. Tests actual execution output.

**Example:** Let items be [1, 2, 3]. Push 4 to items. Let v be item 2 of items.

---

#### E2E: Comparisons

**File:** `tests/e2e_comparisons.rs`

Runtime verification of comparison operators: equals (is), not equals (is not), less than (<), greater than (>), at most (<=), at least (>=). Both English and symbolic forms.

**Example:** If x is less than 10. If x > 5. If x is at most n.

---

#### E2E: Control Flow

**File:** `tests/e2e_control_flow.rs`

Runtime verification of control flow: If/Then/Otherwise conditionals, While loops with conditions, Return statements, nested control structures.

**Example:** If x > 0: Return true. Otherwise: Return false. While i <= n: Set i to i + 1.

---

#### E2E: Edge Cases

**File:** `tests/e2e_edge_cases.rs`

Boundary condition tests: empty collections, zero values, single-element operations, edge indices, integer overflow guards.

**Example:** Edge cases for robustness testing

---

#### E2E: Enums

**File:** `tests/e2e_enums.rs`

Runtime verification of sum types: enum instantiation with 'a new Variant', field access, pattern matching with Inspect statement.

**Example:** Let shape be a new Circle with radius 5. Inspect shape: Circle: ... Square: ...

---

#### E2E: Expressions

**File:** `tests/e2e_expressions.rs`

Runtime verification of expressions: arithmetic (+, -, *, /), Boolean operations, operator precedence, parenthesized grouping.

**Example:** Let result be (a + b) * c. Let flag be x > 0 and y < 10.

---

#### E2E: Functions

**File:** `tests/e2e_functions.rs`

Runtime verification of function definitions and calls: typed parameters, return types, recursive calls, multi-parameter functions.

**Example:** ## To Double (n: Int) -> Int: Return n * 2. Let x be Double(5).

---

#### E2E: Integration

**File:** `tests/e2e_integration.rs`

Multi-function programs testing cross-function calls, shared state, complex control flow across function boundaries.

**Example:** Complex programs with multiple interacting functions

---

#### E2E: Iteration

**File:** `tests/e2e_iteration.rs`

Runtime verification of loops: Repeat/For each iteration, While loops with index variables, collection iteration patterns.

**Example:** Repeat for each item in items: ... While i <= n: ...

---

#### E2E: Logical Operators

**File:** `tests/e2e_logical.rs`

Runtime verification of Boolean logic: AND (and/&&), OR (or/||), NOT (not), compound conditions, short-circuit evaluation.

**Example:** If a and b: ... If x or y: ... If not flag: ...

---

#### E2E: Structs

**File:** `tests/e2e_structs.rs`

Runtime verification of product types: struct instantiation with 'a new Type', field access with possessive (point's x), field mutation with Set.

**Example:** Let p be a new Point with x 10 and y 20. Set p's x to 15.

---

#### E2E: Types

**File:** `tests/e2e_types.rs`

Runtime verification of type system: type annotations (Let x: Int), type coercion rules, generic type instantiation.

**Example:** Let x: Int be 5. Let items: Seq of Int be a new Seq of Int.

---

#### E2E: Variables

**File:** `tests/e2e_variables.rs`

Runtime verification of variable operations: Let bindings, Set mutation, scoping rules, shadowing behavior.

**Example:** Let x be 5. Set x to 10. Let x be 20. (shadowing)

---

#### E2E: CRDT Runtime

**File:** `tests/e2e_crdt.rs`

Runtime verification of CRDT operations: GCounter increment, LWWRegister updates, struct-level and field-level merge operations.

**Example:** Increase counter's count. Merge replica1 with replica2.

---

#### E2E: Policy Enforcement

**File:** `tests/e2e_policy.rs`

Runtime verification of security policies: predicate evaluation, capability checks, Check statement failure behavior with meaningful error messages.

**Example:** Check that user can publish the document. → RuntimeError: Security check failed

---

#### E2E: Mesh Networking

**File:** `tests/e2e_mesh.rs`

Runtime verification of P2P mesh: node connection, message exchange, peer discovery.

**Example:** Listen, Connect, Send messages between peers.

---

#### E2E: Refinement Types

**File:** `tests/e2e_refinement.rs`

Runtime verification of refinement type constraints and debug_assert enforcement.

**Example:** Let x: Int where x > 0 be 5.

---

#### E2E: Zone Memory

**File:** `tests/e2e_zones.rs`

Runtime verification of zone-based memory: allocation, bulk deallocation, escape prevention.

**Example:** Inside a zone: allocate and use memory.

---

#### E2E: Set Collection

**File:** `tests/e2e_sets.rs`

Runtime verification of Set operations: creation with 'new Set of T', Add/Remove statements, contains check, deduplication, union/intersection algebra, iteration, length.

**Example:** Let s be a new Set of Int. Add 1 to s. If s contains 1: Show found.

---

#### E2E: Tuple Type

**File:** `tests/e2e_tuples.rs`

Runtime verification of heterogeneous tuples: creation with (a, b, c) syntax, dual access via brackets t[1] and natural language 'item 1 of t', length, mixed types (Int, Text, Float), arithmetic on elements.

**Example:** Let t be (42, hello, 5.9). Show t[1]. Show item 2 of t.

---

#### E2E: Map Collection

**File:** `tests/e2e_maps.rs`

Runtime verification of Map operations: creation with 'new Map of K to V', key-value access via 'item key of map', mutation with Set, multiple keys, key overwriting.

**Example:** Let prices be a new Map of Text to Int. Set item iron of prices to 100.

---

#### Phase 10: I/O Operations

**File:** `tests/phase10_io.rs`

Input/output operations for LOGOS programs.

**Example:** Read from file. Write to output.

---

#### Ownership Analysis

**File:** `tests/phase_ownership.rs`

Rust-style ownership tracking: moves, borrows, lifetimes.

**Example:** Give x to f. Show x to g.

---

#### Totality Analysis

**File:** `tests/phase_totality.rs`

Function totality checking for termination guarantees.

**Example:** Verify recursive functions terminate.

---

#### Lexer Refactoring Tests

**File:** `tests/phase_lexer_refactor.rs`

Tests for lexer improvements and edge cases.

**Example:** Lexer stress tests and edge cases.

---

## Statistics

### By Compiler Stage
```
Lexer (token.rs, lexer.rs):           2458 lines
Parser (ast/, parser/):               15122 lines
Transpilation:                        1385 lines
Code Generation:                      2904 lines
Semantics (lambda, context, view):    2889 lines
Type Analysis (analysis/):            2834 lines
Support Infrastructure:               4411 lines
Desktop UI:                              17930 lines
CRDT (logos_core/src/crdt/):          1854 lines
Network (logos_core/src/network/):    1596 lines
VFS (logos_core/src/fs/):             511 lines
Entry Point:                                16 lines
```

### Totals
```
Source lines:        59370
Test lines:          26823
Total Rust lines: 86193
```

### File Counts
```
Source files: 121
Test files:   143
```
## Lexicon Data

The lexicon defines all vocabulary entries that drive the lexer and parser behavior.

**File:** `assets/lexicon.json`

**Contents:**
- **Keywords** (44 entries): quantifiers, connectives, modals
- **Pronouns** (9 entries): with gender/number/case features
- **Verbs** (252 entries): lemma, Vendler class, irregular forms, features (Ditransitive, SubjectControl, ObjectControl, Raising, Opaque, Factive, Performative, Collective)
- **Nouns** (113 entries): lemma, plural forms, features (Proper, Masculine, Feminine)
- **Adjectives** (65 entries): lemma, features (Intersective, NonIntersective, Gradable)
- **Closed classes**: prepositions, adverbs, scopal/temporal adverbs
- **Morphology rules**: needs_e_ing, needs_e_ed, stemming_exceptions

```json
{
  "keywords": {
    "all": "All",
    "every": "All",
    "no": "No",
    "some": "Some",
    "any": "Any",
    "both": "Both",
    "most": "Most",
    "few": "Few",
    "many": "Many",
    "and": "And",
    "but": "And",
    "or": "Or",
    "if": "If",
    "then": "Then",
    "not": "Not",
    "is": "Is",
    "are": "Are",
    "was": "Was",
    "were": "Were",
    "that": "That",
    "who": "Who",
    "whom": "Who",
    "what": "What",
    "where": "Where",
    "when": "When",
    "why": "Why",
    "does": "Does",
    "do": "Do",
    "must": "Must",
    "shall": "Shall",
    "should": "Should",
    "can": "Can",
    "may": "May",
    "cannot": "Cannot",
    "would": "Would",
    "could": "Could",
    "might": "Might",
    "had": "Had",
    "than": "Than",
    "itself": "Reflexive",
    "himself": "Reflexive",
    "herself": "Reflexive",
    "themselves": "Reflexive",
    "because": "Because",
    "anything": "Anything",
    "anyone": "Anyone",
    "anybody": "Anyone",
    "nothing": "Nothing",
    "nobody": "Nobody",
    "nowhere": "Nowhere",
    "ever": "Ever",
    "never": "Never",
    "repeat": "Repeat",
    "for": "For",
    "from": "From",
    "trust": "Trust",
    "respectively": "Respectively",
    "decrease": "Decrease",
    "tally": "Tally",
    "sharedset": "SharedSet",
    "sharedsequence": "SharedSequence",
    "sharedmap": "SharedMap",
    "divergent": "Divergent",
    "append": "Append",
    "resolve": "Resolve",
    "removewins": "RemoveWins",
    "addwins": "AddWins",
    "yata": "YATA",
    "values": "Values"
  },
  "pronouns": [
    { "word": "i", "gender": "Unknown", "number": "Singular", "case": "Subject" },
    { "word": "he", "gender": "Male", "number": "Singular", "case": "Subject" },
    { "word": "she", "gender": "Female", "number": "Singular", "case": "Subject" },
    { "word": "it", "gender": "Neuter", "number": "Singular", "case": "Subject" },
    { "word": "they", "gender": "Unknown", "number": "Plural", "case": "Subject" },
    { "word": "you", "gender": "Unknown", "number": "Singular", "case": "Subject" },
    { "word": "him", "gender": "Male", "number": "Singular", "case": "Object" },
    { "word": "her", "gender": "Female", "number": "Singular", "case": "Object" },
    { "word": "her", "gender": "Female", "number": "Singular", "case": "Possessive" },
    { "word": "his", "gender": "Male", "number": "Singular", "case": "Possessive" },
    { "word": "its", "gender": "Neuter", "number": "Singular", "case": "Possessive" },
    { "word": "my", "gender": "Unknown", "number": "Singular", "case": "Possessive" },
    { "word": "their", "gender": "Unknown", "number": "Plural", "case": "Possessive" },
    { "word": "them", "gender": "Unknown", "number": "Plural", "case": "Object" }
  ],
  "articles": {
    "the": "Definite",
    "a": "Indefinite",
    "an": "Indefinite",
    "this": "Proximal",
    "these": "Proximal",
    "those": "Distal"
  },
  "auxiliaries": {
    "will": "Future",
    "did": "Past"
  },
  "presupposition_triggers": {
    "stop": "Stop",
    "start": "Start",
    "begin": "Start",
    "regret": "Regret",
    "continue": "Continue",
    "realize": "Realize",
    "realise": "Realize",
    "know": "Know"
  },
  "number_words": {
    "one": 1, "two": 2, "three": 3, "four": 4, "five": 5,
    "six": 6, "seven": 7, "eight": 8, "nine": 9, "ten": 10
  },
  "verbs": [
    { "lemma": "Be", "class": "State", "forms": { "past": "was", "participle": "been", "gerund": "being" } },
    { "lemma": "Have", "class": "State", "forms": { "present3s": "has", "past": "had", "participle": "had", "gerund": "having" }, "synonyms": ["possess", "own", "hold"], "antonyms": ["lack", "miss"] },
    { "lemma": "Run", "class": "Activity", "forms": { "past": "ran", "gerund": "running" } },
    { "lemma": "See", "class": "State", "forms": { "past": "saw", "participle": "seen", "gerund": "seeing" } },
    { "lemma": "Give", "class": "Achievement", "forms": { "past": "gave", "participle": "given", "gerund": "giving" }, "features": ["Ditransitive"] },
    { "lemma": "Take", "class": "Achievement", "forms": { "past": "took", "participle": "taken", "gerund": "taking" } },
    { "lemma": "Go", "class": "Activity", "forms": { "past": "went", "participle": "gone", "gerund": "going" } },
    { "lemma": "Come", "class": "Achievement", "forms": { "past": "came", "participle": "come", "gerund": "coming" } },
    { "lemma": "Make", "class": "Accomplishment", "forms": { "past": "made", "gerund": "making" } },
    { "lemma": "Say", "class": "Activity", "forms": { "past": "said", "gerund": "saying" } },
    { "lemma": "Know", "class": "State", "forms": { "past": "knew", "participle": "known", "gerund": "knowing" }, "features": ["Opaque", "Factive"] },
    { "lemma": "Wonder", "class": "State", "forms": { "past": "wondered", "gerund": "wondering" }, "features": ["Opaque"] },
    { "lemma": "Think", "class": "State", "forms": { "past": "thought", "gerund": "thinking" }, "features": ["Opaque"] },
    { "lemma": "Tell", "class": "Activity", "forms": { "past": "told", "gerund": "telling" }, "features": ["Ditransitive", "ObjectControl"] },
    { "lemma": "Find", "class": "Achievement", "forms": { "past": "found", "gerund": "finding" } },
    { "lemma": "Put", "class": "Achievement", "forms": { "past": "put", "gerund": "putting" } },
    { "lemma": "Leave", "class": "Achievement", "forms": { "past": "left", "gerund": "leaving" } },
    { "lemma": "Bring", "class": "Activity", "forms": { "past": "brought", "gerund": "bringing" }, "features": ["Ditransitive"] },
    { "lemma": "Send", "class": "Achievement", "forms": { "past": "sent", "gerund": "sending" }, "features": ["Ditransitive"] },
    { "lemma": "Build", "class": "Accomplishment", "forms": { "past": "built", "gerund": "building" } },
    { "lemma": "Speak", "class": "Activity", "forms": { "past": "spoke", "participle": "spoken", "gerund": "speaking" } },
    { "lemma": "Write", "class": "Accomplishment", "forms": { "past": "wrote", "participle": "written", "gerund": "writing" } },
    { "lemma": "Hold", "class": "Activity", "forms": { "past": "held", "gerund": "holding" } },
    { "lemma": "Meet", "class": "Achievement", "forms": { "past": "met", "gerund": "meeting" }, "features": ["Collective"] },
    { "lemma": "Read", "class": "Activity", "forms": { "past": "read", "gerund": "reading" } },
    { "lemma": "Keep", "class": "State", "forms": { "past": "kept", "gerund": "keeping" } },
    { "lemma": "Set", "class": "Achievement", "forms": { "past": "set", "gerund": "setting" } },
    { "lemma": "Hear", "class": "State", "forms": { "past": "heard", "gerund": "hearing" } },
    { "lemma": "Mean", "class": "State", "forms": { "past": "meant", "gerund": "meaning" } },
    { "lemma": "Show", "class": "Achievement", "forms": { "past": "shown", "gerund": "showing" }, "features": ["Ditransitive"] },
    { "lemma": "Eat", "class": "Activity", "forms": { "past": "ate", "participle": "eaten", "gerund": "eating" } },
    { "lemma": "Sleep", "class": "Activity", "forms": { "past": "slept", "gerund": "sleeping" } },
    { "lemma": "Drink", "class": "Activity", "forms": { "past": "drank", "participle": "drunk", "gerund": "drinking" } },
    { "lemma": "Die", "class": "Achievement", "forms": { "past": "died", "gerund": "dying" } },
    { "lemma": "Grow", "class": "Accomplishment", "forms": { "past": "grew", "participle": "grown", "gerund": "growing" } },
    { "lemma": "Blow", "class": "Activity", "forms": { "past": "blew", "participle": "blown", "gerund": "blowing" } },
    { "lemma": "Throw", "class": "Activity", "forms": { "past": "threw", "participle": "thrown", "gerund": "throwing" } },
    { "lemma": "Draw", "class": "Accomplishment", "forms": { "past": "drew", "participle": "drawn", "gerund": "drawing" } },
    { "lemma": "Drive", "class": "Activity", "forms": { "past": "drove", "participle": "driven", "gerund": "driving" } },
    { "lemma": "Fight", "class": "Activity", "forms": { "past": "fought", "gerund": "fighting" } },
    { "lemma": "Hide", "class": "Achievement", "forms": { "past": "hid", "participle": "hidden", "gerund": "hiding" } },
    { "lemma": "Ride", "class": "Activity", "forms": { "past": "rode", "participle": "ridden", "gerund": "riding" } },
    { "lemma": "Rise", "class": "Achievement", "forms": { "past": "rose", "participle": "risen", "gerund": "rising" } },
    { "lemma": "Shake", "class": "Activity", "forms": { "past": "shook", "participle": "shaken", "gerund": "shaking" } },
    { "lemma": "Steal", "class": "Achievement", "forms": { "past": "stole", "participle": "stolen", "gerund": "stealing" } },
    { "lemma": "Wake", "class": "Achievement", "forms": { "past": "woke", "participle": "woken", "gerund": "waking" } },
    { "lemma": "Wear", "class": "Activity", "forms": { "past": "wore", "participle": "worn", "gerund": "wearing" } },
    { "lemma": "Break", "class": "Achievement", "forms": { "past": "broke", "participle": "broken", "gerund": "breaking" }, "features": ["Unaccusative"] },
    { "lemma": "Choose", "class": "Achievement", "forms": { "past": "chose", "participle": "chosen", "gerund": "choosing" } },
    { "lemma": "Freeze", "class": "Accomplishment", "forms": { "past": "froze", "participle": "frozen", "gerund": "freezing" }, "features": ["Unaccusative"] },
    { "lemma": "Bite", "class": "Semelfactive", "forms": { "past": "bit", "participle": "bitten", "gerund": "biting" } },
    { "lemma": "Begin", "class": "Achievement", "forms": { "past": "began", "participle": "begun", "gerund": "beginning" }, "features": ["SubjectControl"] },
    { "lemma": "Sing", "class": "Activity", "forms": { "past": "sang", "participle": "sung", "gerund": "singing" } },
    { "lemma": "Swim", "class": "Activity", "forms": { "past": "swam", "participle": "swum", "gerund": "swimming" } },
    { "lemma": "Fly", "class": "Activity", "forms": { "past": "flew", "participle": "flown", "gerund": "flying" } },
    { "lemma": "Get", "class": "Achievement", "forms": { "past": "got", "participle": "gotten", "gerund": "getting" } },
    { "lemma": "Fall", "class": "Achievement", "forms": { "past": "fell", "participle": "fallen", "gerund": "falling" } },
    { "lemma": "Feel", "class": "State", "forms": { "past": "felt", "gerund": "feeling" } },
    { "lemma": "Sit", "class": "Activity", "forms": { "past": "sat", "gerund": "sitting" } },
    { "lemma": "Stand", "class": "Activity", "forms": { "past": "stood", "gerund": "standing" } },
    { "lemma": "Lose", "class": "Achievement", "forms": { "past": "lost", "gerund": "losing" } },
    { "lemma": "Win", "class": "Achievement", "forms": { "past": "won", "gerund": "winning" } },
    { "lemma": "Catch", "class": "Achievement", "forms": { "past": "caught", "gerund": "catching" } },
    { "lemma": "Teach", "class": "Accomplishment", "forms": { "past": "taught", "gerund": "teaching" }, "features": ["Ditransitive", "ObjectControl"] },
    { "lemma": "Buy", "class": "Achievement", "forms": { "past": "bought", "gerund": "buying" } },
    { "lemma": "Sell", "class": "Achievement", "forms": { "past": "sold", "gerund": "selling" } },
    { "lemma": "Pay", "class": "Achievement", "forms": { "past": "paid", "gerund": "paying" }, "features": ["Ditransitive"] },
    { "lemma": "Cut", "class": "Achievement", "forms": { "past": "cut", "gerund": "cutting" } },
    { "lemma": "Hit", "class": "Semelfactive", "forms": { "past": "hit", "gerund": "hitting" } },
    { "lemma": "Let", "class": "Achievement", "forms": { "past": "let", "gerund": "letting" } },
    { "lemma": "Shut", "class": "Achievement", "forms": { "past": "shut", "gerund": "shutting" } },
    { "lemma": "Cost", "class": "State", "forms": { "past": "cost", "gerund": "costing" } },
    { "lemma": "Hurt", "class": "Achievement", "forms": { "past": "hurt", "gerund": "hurting" } },
    { "lemma": "Chase", "class": "Activity", "forms": { "past": "chased", "gerund": "chasing" } },
    { "lemma": "Wag", "class": "Semelfactive", "forms": { "past": "wagged", "gerund": "wagging" } },
    { "lemma": "Push", "class": "Semelfactive", "forms": { "past": "pushed", "gerund": "pushing" } },
    { "lemma": "Stop", "class": "Achievement", "forms": { "past": "stopped", "gerund": "stopping" } },
    { "lemma": "Smoke", "class": "Activity", "forms": { "past": "smoked", "gerund": "smoking" } },
    { "lemma": "Open", "class": "Achievement", "forms": { "past": "opened", "gerund": "opening" }, "features": ["Unaccusative"] },
    { "lemma": "Rain", "class": "Activity", "regular": true, "features": ["Weather"] },
    { "lemma": "Snow", "class": "Activity", "regular": true, "features": ["Weather"] },
    { "lemma": "Hail", "class": "Semelfactive", "regular": true, "features": ["Weather"] },
    { "lemma": "Thunder", "class": "Activity", "regular": true, "features": ["Weather"] },
    { "lemma": "Pour", "class": "Activity", "regular": true, "features": ["Weather"] },
    { "lemma": "Gather", "class": "Activity", "regular": true, "features": ["Collective"] },
    { "lemma": "Assemble", "class": "Accomplishment", "regular": true, "features": ["Collective"] },
    { "lemma": "Convene", "class": "Activity", "regular": true, "features": ["Collective"] },
    { "lemma": "Want", "class": "State", "regular": true, "features": ["SubjectControl", "Opaque"] },
    { "lemma": "Hope", "class": "State", "regular": true, "features": ["SubjectControl", "Opaque"] },
    { "lemma": "Decide", "class": "Activity", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Try", "class": "Activity", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Intend", "class": "State", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Refuse", "class": "Activity", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Agree", "class": "Activity", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Threaten", "class": "Activity", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Prefer", "class": "State", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Manage", "class": "Accomplishment", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Fail", "class": "Achievement", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Tend", "class": "State", "regular": true, "features": ["SubjectControl", "Raising"] },
    { "lemma": "Continue", "class": "Activity", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Start", "class": "Achievement", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Promise", "class": "Activity", "regular": true, "features": ["SubjectControl", "Performative"] },
    { "lemma": "Swear", "class": "Activity", "regular": true, "features": ["SubjectControl", "Performative"] },
    { "lemma": "Vow", "class": "Activity", "regular": true, "features": ["SubjectControl", "Performative"] },
    { "lemma": "Expect", "class": "State", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Plan", "class": "Activity", "regular": true, "features": ["SubjectControl"] },
    { "lemma": "Seem", "class": "State", "regular": true, "features": ["Raising"] },
    { "lemma": "Appear", "class": "State", "regular": true, "features": ["Raising"] },
    { "lemma": "Happen", "class": "Achievement", "regular": true, "features": ["Raising"] },
    { "lemma": "Turn", "class": "Activity", "regular": true, "features": ["Raising"] },
    { "lemma": "Persuade", "class": "Accomplishment", "regular": true, "features": ["ObjectControl"] },
    { "lemma": "Convince", "class": "Accomplishment", "regular": true, "features": ["ObjectControl"] },
    { "lemma": "Force", "class": "Accomplishment", "regular": true, "features": ["ObjectControl"] },
    { "lemma": "Order", "class": "Activity", "regular": true, "features": ["ObjectControl", "Performative"] },
    { "lemma": "Command", "class": "Activity", "regular": true, "features": ["ObjectControl", "Performative"] },
    { "lemma": "Ask", "class": "Activity", "regular": true, "features": ["ObjectControl"] },
    { "lemma": "Advise", "class": "Activity", "regular": true, "features": ["ObjectControl", "Performative"] },
    { "lemma": "Encourage", "class": "Activity", "regular": true, "features": ["ObjectControl"] },
    { "lemma": "Allow", "class": "State", "regular": true, "features": ["ObjectControl"] },
    { "lemma": "Permit", "class": "State", "regular": true, "features": ["ObjectControl"] },
    { "lemma": "Forbid", "class": "State", "regular": true, "features": ["ObjectControl", "Performative"] },
    { "lemma": "Cause", "class": "Accomplishment", "regular": true, "features": ["ObjectControl"] },
    { "lemma": "Help", "class": "Activity", "regular": true, "features": ["ObjectControl"] },
    { "lemma": "Invite", "class": "Activity", "regular": true, "features": ["ObjectControl"] },
    { "lemma": "Remind", "class": "Activity", "regular": true, "features": ["ObjectControl"] },
    { "lemma": "Warn", "class": "Activity", "regular": true, "features": ["ObjectControl", "Performative"] },
    { "lemma": "Believe", "class": "State", "regular": true, "features": ["Opaque"] },
    { "lemma": "Wish", "class": "State", "regular": true, "features": ["Opaque"] },
    { "lemma": "Seek", "class": "State", "forms": {"past": "sought", "participle": "sought"}, "features": ["Opaque"] },
    { "lemma": "Fear", "class": "State", "regular": true, "features": ["Opaque"] },
    { "lemma": "Imagine", "class": "State", "regular": true, "features": ["Opaque"] },
    { "lemma": "Dream", "class": "Activity", "regular": true, "features": ["Opaque"] },
    { "lemma": "Pretend", "class": "Activity", "regular": true, "features": ["Opaque"] },
    { "lemma": "Bark", "class": "Activity", "regular": true },
    { "lemma": "Hunt", "class": "Activity", "regular": true },
    { "lemma": "Happen", "class": "Achievement", "regular": true },
    { "lemma": "Flow", "class": "Activity", "regular": true },
    { "lemma": "Remain", "class": "State", "regular": true },
    { "lemma": "Examine", "class": "Activity", "regular": true },
    { "lemma": "Walk", "class": "Activity", "regular": true },
    { "lemma": "Talk", "class": "Activity", "regular": true },
    { "lemma": "Jump", "class": "Activity", "regular": true },
    { "lemma": "Duck", "class": "Activity", "regular": true },
    { "lemma": "Love", "class": "State", "regular": true },
    { "lemma": "Hate", "class": "State", "regular": true },
    { "lemma": "Like", "class": "State", "regular": true },
    { "lemma": "Need", "class": "State", "regular": true, "features": ["Opaque"] },
    { "lemma": "Touch", "class": "Activity", "regular": true },
    { "lemma": "Smell", "class": "State", "regular": true },
    { "lemma": "Look", "class": "Activity", "regular": true },
    { "lemma": "Own", "class": "State", "regular": true },
    { "lemma": "Lack", "class": "State", "regular": true },
    { "lemma": "Enter", "class": "Activity", "regular": true },
    { "lemma": "Trigger", "class": "Achievement", "regular": true, "features": ["Unaccusative"] },
    { "lemma": "Beat", "class": "Activity", "regular": true },
    { "lemma": "Marry", "class": "Achievement", "regular": true },
    { "lemma": "Kill", "class": "Achievement", "regular": true },
    { "lemma": "Stay", "class": "Activity", "regular": true },
    { "lemma": "Work", "class": "Activity", "regular": true },
    { "lemma": "Play", "class": "Activity", "regular": true },
    { "lemma": "Pass", "class": "Activity", "regular": true, "features": ["Ditransitive"] },
    { "lemma": "Hand", "class": "Activity", "regular": true, "features": ["Ditransitive"] },
    { "lemma": "Carry", "class": "Activity", "regular": true, "features": ["Mixed"] },
    { "lemma": "Lift", "class": "Activity", "regular": true, "features": ["Mixed"] },
    { "lemma": "Move", "class": "Activity", "regular": true, "features": ["Mixed"] },
    { "lemma": "Push", "class": "Activity", "regular": true, "features": ["Mixed"] },
    { "lemma": "Pull", "class": "Activity", "regular": true, "features": ["Mixed"] },
    { "lemma": "Deliver", "class": "Accomplishment", "regular": true },
    { "lemma": "Exist", "class": "State", "regular": true },
    { "lemma": "Knock", "class": "Semelfactive", "regular": true },
    { "lemma": "Kick", "class": "Semelfactive", "regular": true },
    { "lemma": "Tap", "class": "Semelfactive", "regular": true },
    { "lemma": "Cough", "class": "Semelfactive", "regular": true },
    { "lemma": "Blink", "class": "Semelfactive", "regular": true },
    { "lemma": "Sneeze", "class": "Semelfactive", "regular": true },
    { "lemma": "Hiccup", "class": "Semelfactive", "regular": true },
    { "lemma": "Flash", "class": "Semelfactive", "regular": true },
    { "lemma": "Click", "class": "Semelfactive", "regular": true },
    { "lemma": "Beep", "class": "Semelfactive", "regular": true },
    { "lemma": "Honk", "class": "Semelfactive", "regular": true },
    { "lemma": "Slap", "class": "Semelfactive", "regular": true },
    { "lemma": "Punch", "class": "Semelfactive", "regular": true },
    { "lemma": "Poke", "class": "Semelfactive", "regular": true },
    { "lemma": "Flap", "class": "Semelfactive", "regular": true },
    { "lemma": "Nod", "class": "Semelfactive", "regular": true },
    { "lemma": "Wink", "class": "Semelfactive", "regular": true },
    { "lemma": "Create", "class": "Accomplishment", "regular": true },
    { "lemma": "Construct", "class": "Accomplishment", "regular": true },
    { "lemma": "Paint", "class": "Accomplishment", "regular": true },
    { "lemma": "Repair", "class": "Accomplishment", "regular": true },
    { "lemma": "Fix", "class": "Accomplishment", "regular": true },
    { "lemma": "Melt", "class": "Accomplishment", "regular": true, "features": ["Unaccusative"] },
    { "lemma": "Close", "class": "Achievement", "regular": true, "features": ["Unaccusative"] },
    { "lemma": "Sink", "class": "Achievement", "forms": { "past": "sank", "participle": "sunk", "gerund": "sinking" }, "features": ["Unaccusative"] },
    { "lemma": "Dry", "class": "Accomplishment", "regular": true, "features": ["Unaccusative"] },
    { "lemma": "Burn", "class": "Accomplishment", "regular": true, "features": ["Unaccusative"] },
    { "lemma": "Explode", "class": "Achievement", "regular": true, "features": ["Unaccusative"] },
    { "lemma": "Collapse", "class": "Achievement", "regular": true, "features": ["Unaccusative"] },
    { "lemma": "Evaporate", "class": "Accomplishment", "regular": true, "features": ["Unaccusative"] },
    { "lemma": "Destroy", "class": "Accomplishment", "regular": true },
    { "lemma": "Demolish", "class": "Accomplishment", "regular": true },
    { "lemma": "Dissolve", "class": "Accomplishment", "regular": true },
    { "lemma": "Recover", "class": "Accomplishment", "regular": true },
    { "lemma": "Heal", "class": "Accomplishment", "regular": true },
    { "lemma": "Cross", "class": "Accomplishment", "regular": true },
    { "lemma": "Fill", "class": "Accomplishment", "regular": true },
    { "lemma": "Empty", "class": "Accomplishment", "regular": true },
    { "lemma": "Arrive", "class": "Achievement", "regular": true },
    { "lemma": "Notice", "class": "Achievement", "regular": true },
    { "lemma": "Recognize", "class": "Achievement", "regular": true },
    { "lemma": "Realize", "class": "Achievement", "regular": true },
    { "lemma": "Discover", "class": "Achievement", "regular": true },
    { "lemma": "Reach", "class": "Achievement", "regular": true },
    { "lemma": "Born", "class": "Achievement", "regular": true },
    { "lemma": "Divorce", "class": "Achievement", "regular": true },
    { "lemma": "Graduate", "class": "Achievement", "regular": true },
    { "lemma": "Finish", "class": "Achievement", "regular": true },
    { "lemma": "Complete", "class": "Achievement", "regular": true },
    { "lemma": "Understand", "class": "State", "regular": true },
    { "lemma": "Remember", "class": "State", "regular": true },
    { "lemma": "Forget", "class": "State", "regular": true },
    { "lemma": "Deserve", "class": "State", "regular": true },
    { "lemma": "Contain", "class": "State", "regular": true },
    { "lemma": "Consist", "class": "State", "regular": true },
    { "lemma": "Belong", "class": "State", "regular": true },
    { "lemma": "Matter", "class": "State", "regular": true },
    { "lemma": "Resemble", "class": "State", "regular": true },
    { "lemma": "Dance", "class": "Activity", "regular": true },
    { "lemma": "Study", "class": "Activity", "regular": true },
    { "lemma": "Search", "class": "Activity", "regular": true },
    { "lemma": "Listen", "class": "Activity", "regular": true },
    { "lemma": "Watch", "class": "Activity", "regular": true },
    { "lemma": "Wait", "class": "Activity", "regular": true },
    { "lemma": "Lie", "class": "Activity", "regular": true },
    { "lemma": "Live", "class": "Activity", "regular": true },
    { "lemma": "Travel", "class": "Activity", "regular": true },
    { "lemma": "Move", "class": "Activity", "regular": true },
    { "lemma": "Climb", "class": "Activity", "regular": true },
    { "lemma": "Crawl", "class": "Activity", "regular": true },
    { "lemma": "Roll", "class": "Activity", "regular": true },
    { "lemma": "Spin", "class": "Activity", "regular": true },
    { "lemma": "Turn", "class": "Activity", "regular": true },
    { "lemma": "Pull", "class": "Activity", "regular": true },
    { "lemma": "Drag", "class": "Activity", "regular": true },
    { "lemma": "Lend", "class": "Activity", "regular": true, "features": ["Ditransitive"] },
    { "lemma": "Owe", "class": "Activity", "regular": true, "features": ["Ditransitive"] },
    { "lemma": "Award", "class": "Activity", "regular": true, "features": ["Ditransitive"] },
    { "lemma": "Grant", "class": "Activity", "regular": true, "features": ["Ditransitive"] },
    { "lemma": "Offer", "class": "Activity", "regular": true, "features": ["Ditransitive"] },
    { "lemma": "Bet", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Guarantee", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Pledge", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Declare", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Pronounce", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Announce", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Proclaim", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Request", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Demand", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Apologize", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Thank", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Congratulate", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Welcome", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Suggest", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Recommend", "class": "Activity", "regular": true, "features": ["Performative"] },
    { "lemma": "Surround", "class": "Activity", "regular": true, "features": ["Collective"] },
    { "lemma": "Disperse", "class": "Achievement", "regular": true, "features": ["Collective"] },
    { "lemma": "Scatter", "class": "Achievement", "regular": true, "features": ["Collective"] },
    { "lemma": "Congregate", "class": "Activity", "regular": true, "features": ["Collective"] },
    { "lemma": "Unite", "class": "Achievement", "regular": true, "features": ["Collective"] },
    { "lemma": "Merge", "class": "Achievement", "regular": true, "features": ["Collective"] },
    { "lemma": "Combine", "class": "Achievement", "regular": true, "features": ["Collective"] },
    { "lemma": "Collaborate", "class": "Activity", "regular": true, "features": ["Collective"] },
    { "lemma": "Cooperate", "class": "Activity", "regular": true, "features": ["Collective"] },
    { "lemma": "Conspire", "class": "Activity", "regular": true, "features": ["Collective"] }
  ],
  "nouns": [
    { "lemma": "Man", "forms": { "plural": "men" }, "features": ["Masculine"], "sort": "Human" },
    { "lemma": "Woman", "forms": { "plural": "women" }, "features": ["Feminine"], "sort": "Human" },
    { "lemma": "Child", "forms": { "plural": "children" }, "sort": "Human" },
    { "lemma": "Person", "forms": { "plural": "people" }, "sort": "Human" },
    { "lemma": "Mouse", "forms": { "plural": "mice" } },
    { "lemma": "Tooth", "forms": { "plural": "teeth" } },
    { "lemma": "Foot", "forms": { "plural": "feet" } },
    { "lemma": "Goose", "forms": { "plural": "geese" } },
    { "lemma": "Fish", "forms": { "plural": "fish" } },
    { "lemma": "Deer", "forms": { "plural": "deer" } },
    { "lemma": "Sheep", "forms": { "plural": "sheep" } },
    { "lemma": "Species", "forms": { "plural": "species" } },
    { "lemma": "Series", "forms": { "plural": "series" } },
    { "lemma": "Car", "sort": "Physical" },
    { "lemma": "Engine", "sort": "Physical" },
    { "lemma": "Wheel", "sort": "Physical" },
    { "lemma": "Door", "sort": "Physical" },
    { "lemma": "Alarm", "sort": "Physical" },
    { "lemma": "Window", "sort": "Physical" },
    { "lemma": "Tire", "sort": "Physical" },
    { "lemma": "House", "sort": "Physical" },
    { "lemma": "Roof", "sort": "Physical" },
    { "lemma": "Room", "sort": "Physical" },
    { "lemma": "Wall", "sort": "Physical" },
    { "lemma": "Floor", "sort": "Physical" },
    { "lemma": "Ceiling", "sort": "Physical" },
    { "lemma": "Bike", "sort": "Physical" },
    { "lemma": "Pedal", "sort": "Physical" },
    { "lemma": "Chain", "sort": "Physical" },
    { "lemma": "Seat", "sort": "Physical" },
    { "lemma": "Rock", "sort": "Physical", "features": ["Inanimate"] },
    { "lemma": "Stone", "sort": "Physical", "features": ["Inanimate"] },
    { "lemma": "John", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "James", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Bob", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Bill", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Tom", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Mike", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "David", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Peter", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Paul", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Jack", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Joe", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Jim", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Steve", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Mark", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Chris", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Dan", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Sam", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Alex", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Romeo", "features": ["Proper", "Masculine"], "sort": "Human" },
    { "lemma": "Mary", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Jane", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Susan", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Sarah", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Alice", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Lisa", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Anna", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Emily", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Emma", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Kate", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Amy", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Lucy", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Rachel", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Laura", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Helen", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Nancy", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Betty", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Juliet", "features": ["Proper", "Feminine"], "sort": "Human" },
    { "lemma": "Boy", "features": ["Masculine"], "sort": "Human" },
    { "lemma": "King", "features": ["Masculine"], "sort": "Human" },
    { "lemma": "Prince", "features": ["Masculine"], "sort": "Human" },
    { "lemma": "Father", "features": ["Masculine"], "sort": "Human" },
    { "lemma": "Brother", "features": ["Masculine"], "sort": "Human" },
    { "lemma": "Son", "features": ["Masculine"], "sort": "Human" },
    { "lemma": "Husband", "features": ["Masculine"], "sort": "Human" },
    { "lemma": "Actor", "features": ["Masculine"], "sort": "Human" },
    { "lemma": "Waiter", "features": ["Masculine"], "sort": "Human" },
    { "lemma": "Girl", "features": ["Feminine"], "sort": "Human" },
    { "lemma": "Queen", "features": ["Feminine"], "sort": "Human" },
    { "lemma": "Princess", "features": ["Feminine"], "sort": "Human" },
    { "lemma": "Mother", "features": ["Feminine"], "sort": "Human" },
    { "lemma": "Sister", "features": ["Feminine"], "sort": "Human" },
    { "lemma": "Daughter", "features": ["Feminine"], "sort": "Human" },
    { "lemma": "Wife", "features": ["Feminine"], "sort": "Human" },
    { "lemma": "Actress", "features": ["Feminine"], "sort": "Human" },
    { "lemma": "Waitress", "features": ["Feminine"], "sort": "Human" },
    { "lemma": "Ring" }, { "lemma": "Thing" }, { "lemma": "Spring" }, { "lemma": "String" },
    { "lemma": "Swing" }, { "lemma": "Wing" }, { "lemma": "Bus" }, { "lemma": "Gas" },
    { "lemma": "Focus" }, { "lemma": "Campus" }, { "lemma": "Status" }, { "lemma": "Bonus" },
    { "lemma": "Set", "forms": { "plural": "sets" } },
    { "lemma": "Cardinality" },
    { "lemma": "Dog", "sort": "Animate" }, { "lemma": "Cat", "sort": "Animate" }, { "lemma": "Bird", "sort": "Animate" }, { "lemma": "Student", "sort": "Human" },
    { "lemma": "Hunter", "sort": "Human" }, { "lemma": "Book", "sort": "Information" }, { "lemma": "House", "sort": "Physical" }, { "lemma": "Code" },
    { "lemma": "User", "sort": "Human" }, { "lemma": "Logic", "sort": "Abstract" }, { "lemma": "Time", "sort": "Abstract" }, { "lemma": "Letter" },
    { "lemma": "Logician", "sort": "Human" }, { "lemma": "Philosopher", "sort": "Human" }, { "lemma": "Teacher", "sort": "Human" }, { "lemma": "Writer", "sort": "Human" },
    { "lemma": "Athlete", "sort": "Human" }, { "lemma": "World" }, { "lemma": "Unicorn", "sort": "Animate" }, { "lemma": "Toast", "sort": "Physical" },
    { "lemma": "Bathroom", "sort": "Place" }, { "lemma": "Knife", "sort": "Physical" }, { "lemma": "Gun", "sort": "Physical" }, { "lemma": "Thief", "sort": "Human" },
    { "lemma": "Senator", "sort": "Human" }, { "lemma": "Ball", "sort": "Physical" }, { "lemma": "President", "sort": "Human" }, { "lemma": "Hero", "sort": "Human" },
    { "lemma": "Friend", "sort": "Human" }, { "lemma": "Story", "sort": "Information" }, { "lemma": "Horse", "sort": "Animate" }, { "lemma": "Water", "sort": "Physical" },
    { "lemma": "Money", "sort": "Value" }, { "lemma": "Apple", "sort": "Physical" }, { "lemma": "Rat", "sort": "Animate" }, { "lemma": "Tail", "sort": "Physical" },
    { "lemma": "Door", "sort": "Physical" }, { "lemma": "Key", "sort": "Physical" }, { "lemma": "Glass", "sort": "Physical" }, { "lemma": "Ice", "sort": "Physical" },
    { "lemma": "Sun", "sort": "Celestial" }, { "lemma": "Moon", "sort": "Celestial" }, { "lemma": "Star", "sort": "Celestial" },
    { "lemma": "Rock", "sort": "Physical" }, { "lemma": "Justice", "sort": "Abstract" }, { "lemma": "Love", "sort": "Abstract" },
    { "lemma": "Team", "features": ["Collective"], "sort": "Group" }, { "lemma": "Army", "features": ["Collective"], "sort": "Group" },
    { "lemma": "Animal", "sort": "Animate" },
    { "lemma": "Duck", "sort": "Animate" }
  ],
  "adjectives": [
    { "lemma": "Red", "regular": true, "features": ["Intersective"] },
    { "lemma": "Blue", "regular": true, "features": ["Intersective"] },
    { "lemma": "Green", "regular": true, "features": ["Intersective"] },
    { "lemma": "Black", "regular": true, "features": ["Intersective"] },
    { "lemma": "White", "regular": true, "features": ["Intersective"] },
    { "lemma": "Happy", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Sad", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Great", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Dangerous", "regular": true, "features": ["Intersective"] },
    { "lemma": "Open", "regular": true, "features": ["Intersective"] },
    { "lemma": "Closed", "regular": true, "features": ["Intersective"] },
    { "lemma": "Flat", "regular": true, "features": ["Intersective"] },
    { "lemma": "Fake", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Former", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Alleged", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Counterfeit", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Would-Be", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Putative", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Supposed", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "So-Called", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Pseudo", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Quasi", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Potential", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Possible", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Future", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Imaginary", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Fictional", "regular": true, "features": ["NonIntersective"] },
    { "lemma": "Tall", "regular": true, "features": ["Subsective", "Gradable"] },
    { "lemma": "Short", "regular": true, "features": ["Subsective", "Gradable"] },
    { "lemma": "Big", "regular": true, "features": ["Subsective", "Gradable"] },
    { "lemma": "Large", "regular": true, "features": ["Subsective", "Gradable"] },
    { "lemma": "Small", "regular": true, "features": ["Subsective", "Gradable"] },
    { "lemma": "Fast", "regular": true, "features": ["Subsective", "Gradable", "EventModifier"] },
    { "lemma": "Slow", "regular": true, "features": ["Subsective", "Gradable", "EventModifier"] },
    { "lemma": "Old", "regular": true, "features": ["Subsective", "Gradable"] },
    { "lemma": "Young", "regular": true, "features": ["Subsective", "Gradable"] },
    { "lemma": "Strong", "regular": true, "features": ["Subsective", "Gradable"] },
    { "lemma": "Weak", "regular": true, "features": ["Subsective", "Gradable"] },
    { "lemma": "Loud", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Quiet", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Smart", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Dumb", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Rich", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Poor", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "High", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Low", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Long", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Wide", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Deep", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Thick", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Thin", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Hot", "regular": true, "features": ["Intersective", "Gradable", "Weather"] },
    { "lemma": "Cold", "regular": true, "features": ["Intersective", "Gradable", "Weather"] },
    { "lemma": "Warm", "regular": true, "features": ["Intersective", "Gradable", "Weather"] },
    { "lemma": "Cool", "regular": true, "features": ["Intersective", "Gradable", "Weather"] },
    { "lemma": "Hard", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Soft", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Dark", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Light", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Clean", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Dirty", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Dry", "regular": true, "features": ["Intersective", "Gradable", "Weather"] },
    { "lemma": "Wet", "regular": true, "features": ["Intersective", "Gradable", "Weather"] },
    { "lemma": "Sunny", "regular": true, "features": ["Intersective", "Weather"] },
    { "lemma": "Cloudy", "regular": true, "features": ["Intersective", "Weather"] },
    { "lemma": "Foggy", "regular": true, "features": ["Intersective", "Weather"] },
    { "lemma": "Humid", "regular": true, "features": ["Intersective", "Gradable", "Weather"] },
    { "lemma": "Windy", "regular": true, "features": ["Intersective", "Gradable", "Weather"] },
    { "lemma": "New", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Bright", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Sweet", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Sour", "regular": true, "features": ["Intersective", "Gradable"] },
    { "lemma": "Good", "regular": true, "features": ["Subsective"] },
    { "lemma": "Bad", "regular": true, "features": ["Subsective"] },
    { "lemma": "Beautiful", "regular": true, "features": ["Intersective", "Gradable", "EventModifier"] },
    { "lemma": "Graceful", "regular": true, "features": ["Intersective", "Gradable", "EventModifier"] },
    { "lemma": "Skillful", "regular": true, "features": ["Intersective", "Gradable", "EventModifier"] },
    { "lemma": "Clumsy", "regular": true, "features": ["Intersective", "Gradable", "EventModifier"] },
    { "lemma": "Elegant", "regular": true, "features": ["Intersective", "Gradable", "EventModifier"] },
    { "lemma": "Awkward", "regular": true, "features": ["Intersective", "Gradable", "EventModifier"] },
    { "lemma": "Careful", "regular": true, "features": ["Intersective", "Gradable", "EventModifier"] },
    { "lemma": "Careless", "regular": true, "features": ["Intersective", "Gradable", "EventModifier"] }
  ],
  "agentive_nouns": {
    "dancer": "Dance",
    "runner": "Run",
    "singer": "Sing",
    "driver": "Drive",
    "teacher": "Teach",
    "writer": "Write",
    "speaker": "Speak",
    "player": "Play",
    "worker": "Work",
    "swimmer": "Swim",
    "jumper": "Jump",
    "walker": "Walk",
    "thinker": "Think",
    "reader": "Read",
    "fighter": "Fight",
    "painter": "Paint",
    "builder": "Build",
    "baker": "Bake",
    "catcher": "Catch"
  },
  "prepositions": [
    "from", "with", "for", "by", "of", "in", "on", "at", "into", "onto",
    "under", "over", "through", "about", "around", "between", "among",
    "behind", "before", "after", "near", "beside", "beneath", "above",
    "below", "inside", "outside", "within", "without", "against",
    "toward", "towards", "across", "along", "during", "until", "upon", "past"
  ],
  "adverbs": [
    "quickly", "slowly", "loudly", "quietly", "happily", "sadly",
    "carefully", "carelessly", "easily", "hardly", "barely",
    "passionately", "angrily", "gently", "roughly", "softly",
    "suddenly", "gradually", "immediately", "finally", "eventually",
    "really", "truly", "certainly", "probably", "possibly",
    "always", "never", "often", "sometimes", "rarely", "usually",
    "please"
  ],
  "scopal_adverbs": [
    "almost", "nearly", "barely", "hardly", "just",
    "merely", "still", "already",
    "allegedly", "probably", "possibly", "certainly"
  ],
  "temporal_adverbs": ["yesterday", "today", "tomorrow", "now"],
  "particles": ["up", "down", "out", "in", "off", "on", "away", "over", "back", "through", "apart", "about", "around", "along", "by"],
  "phrasal_verbs": {
    "give_up": { "lemma": "Surrender", "class": "Activity" },
    "break_down": { "lemma": "Malfunction", "class": "Achievement" },
    "pick_up": { "lemma": "Collect", "class": "Achievement" },
    "put_down": { "lemma": "Place", "class": "Activity" },
    "take_off": { "lemma": "Remove", "class": "Achievement" },
    "turn_on": { "lemma": "Activate", "class": "Achievement" },
    "turn_off": { "lemma": "Deactivate", "class": "Achievement" },
    "carry_out": { "lemma": "Execute", "class": "Activity" },
    "figure_out": { "lemma": "Understand", "class": "Achievement" },
    "find_out": { "lemma": "Discover", "class": "Achievement" },
    "give_away": { "lemma": "Donate", "class": "Activity" },
    "throw_away": { "lemma": "Discard", "class": "Activity" },
    "bring_up": { "lemma": "Mention", "class": "Activity" },
    "call_off": { "lemma": "Cancel", "class": "Achievement" },
    "make_up": { "lemma": "Fabricate", "class": "Activity" },
    "set_up": { "lemma": "Arrange", "class": "Activity" },
    "shut_down": { "lemma": "Close", "class": "Achievement" }
  },
  "not_adverbs": [
    "friendly", "lovely", "ugly", "silly", "holy", "lonely", "deadly",
    "likely", "costly", "early", "only", "daily", "weekly", "monthly",
    "yearly", "orderly", "timely", "lively", "elderly", "brotherly",
    "fatherly", "motherly", "sisterly", "beastly", "ghostly", "princely"
  ],
  "noun_patterns": [
    "dog", "cat", "man", "bird", "book", "house", "person", "thing",
    "dogs", "cats", "men", "birds", "books", "houses", "persons", "things"
  ],
  "disambiguation_not_verbs": [
    "ring", "king", "thing", "spring", "string", "swing", "wing", "bring", "sing",
    "bus", "plus", "gas", "us", "thus", "focus", "campus", "status", "bonus",
    "red", "bed", "led", "shed", "sled", "wed",
    "tired", "bored", "excited", "interested", "blessed", "wicked",
    "mortal", "happy", "friendly", "loud", "black", "old", "wise", "bald",
    "tall", "short", "big", "small", "fast", "slow", "good", "bad", "lazy",
    "dangerous", "blue", "green", "yellow", "white", "free"
  ],
  "morphology": {
    "needs_e_ing": [
      "tak", "mak", "giv", "hav", "lov", "liv", "mov", "sav",
      "writ", "rid", "hid", "bit", "driv", "shak", "wak",
      "hat", "lik", "nam", "shar", "hop", "danc", "chas"
    ],
    "needs_e_ed": [
      "persuad", "forc", "convinc", "reduc", "produc", "induc",
      "lov", "mov", "sav", "liv", "giv", "hav", "mak", "tak",
      "chas", "danc", "hop", "lik", "hat", "nam", "shar",
      "chang", "manag", "arrang", "enclos", "clos", "rais",
      "prais", "paus", "caus", "us", "refus", "excus", "abus",
      "accus", "amus", "confus", "advis", "devis", "revis",
      "promis", "compromis", "exercis", "practis", "realis",
      "organis", "recognis", "surpris", "disguis",
      "decid", "provid", "divid", "guid", "resid", "collid",
      "examin"
    ],
    "stemming_exceptions": [
      "themselves", "ourselves", "yourselves", "himself", "herself",
      "itself", "myself", "yourself", "this", "thus", "plus", "minus",
      "always", "sometimes", "perhaps", "yes", "is", "as", "was", "has",
      "does", "his", "hers", "its", "ours", "yours", "theirs", "us"
    ]
  },
  "units": {
    "inch": "Length",
    "inches": "Length",
    "meter": "Length",
    "meters": "Length",
    "foot": "Length",
    "feet": "Length",
    "yard": "Length",
    "yards": "Length",
    "mile": "Length",
    "miles": "Length",
    "second": "Time",
    "seconds": "Time",
    "minute": "Time",
    "minutes": "Time",
    "hour": "Time",
    "hours": "Time",
    "day": "Time",
    "days": "Time",
    "year": "Time",
    "years": "Time",
    "pound": "Weight",
    "pounds": "Weight",
    "kilogram": "Weight",
    "kilograms": "Weight",
    "gram": "Weight",
    "grams": "Weight",
    "ounce": "Weight",
    "ounces": "Weight",
    "degree": "Temperature",
    "degrees": "Temperature",
    "child": "Cardinality",
    "children": "Cardinality",
    "item": "Cardinality",
    "items": "Cardinality"
  },
  "multi_word_expressions": [
    { "pattern": ["fire", "engine"], "lemma": "FireEngine", "pos": "Noun" },
    { "pattern": ["ice", "cream"], "lemma": "IceCream", "pos": "Noun" },
    { "pattern": ["credit", "card"], "lemma": "CreditCard", "pos": "Noun" },
    { "pattern": ["black", "hole"], "lemma": "BlackHole", "pos": "Noun" },
    { "pattern": ["high", "school"], "lemma": "HighSchool", "pos": "Noun" },
    { "pattern": ["new", "york"], "lemma": "NewYork", "pos": "Noun", "features": ["Proper"] },
    { "pattern": ["united", "states"], "lemma": "UnitedStates", "pos": "Noun", "features": ["Proper"] },
    { "pattern": ["san", "francisco"], "lemma": "SanFrancisco", "pos": "Noun", "features": ["Proper"] },
    { "pattern": ["kick", "the", "bucket"], "lemma": "Die", "pos": "Verb", "class": "Achievement" },
    { "pattern": ["give", "up"], "lemma": "Surrender", "pos": "Verb", "class": "Activity" },
    { "pattern": ["break", "down"], "lemma": "Malfunction", "pos": "Verb", "class": "Achievement" },
    { "pattern": ["in", "front", "of"], "lemma": "InFrontOf", "pos": "Preposition" },
    { "pattern": ["as", "well", "as"], "lemma": "And", "pos": "Conjunction" },
    { "pattern": ["no", "one"], "lemma": "NoOne", "pos": "Quantifier" }
  ],
  "ontology": {
    "part_whole": [
      { "whole": "Car", "parts": ["Engine", "Wheel", "Door", "Window", "Tire"] },
      { "whole": "Bike", "parts": ["Wheel", "Pedal", "Chain", "Seat"] },
      { "whole": "House", "parts": ["Door", "Window", "Roof", "Room", "Wall"] },
      { "whole": "Body", "parts": ["Head", "Arm", "Leg", "Hand", "Foot"] },
      { "whole": "Computer", "parts": ["Screen", "Keyboard", "Mouse"] },
      { "whole": "Book", "parts": ["Page", "Cover", "Chapter"] },
      { "whole": "Tree", "parts": ["Branch", "Leaf", "Root"] },
      { "whole": "Room", "parts": ["Floor", "Ceiling", "Wall"] },
      { "whole": "Paper", "parts": ["Author", "Abstract", "Conclusion"] }
    ],
    "predicate_sorts": {
      "happy": "Animate",
      "sad": "Animate",
      "angry": "Animate",
      "hungry": "Animate",
      "tired": "Animate",
      "alive": "Animate",
      "dead": "Animate",
      "think": "Animate",
      "believe": "Animate",
      "remember": "Animate",
      "know": "Animate",
      "want": "Animate",
      "hope": "Animate",
      "fear": "Animate"
    }
  },
  "axioms": {
    "nouns": {
      "bachelor": { "entails": ["Unmarried", "Male", "Adult"] },
      "spinster": { "entails": ["Unmarried", "Female", "Adult"] },
      "widow": { "entails": ["Female", "WasMarried"] },
      "widower": { "entails": ["Male", "WasMarried"] },
      "orphan": { "entails": ["Child", "ParentsDeceased"] },
      "dog": { "hypernyms": ["Animal", "Mammal"] },
      "cat": { "hypernyms": ["Animal", "Mammal"] },
      "bird": { "hypernyms": ["Animal"] },
      "sparrow": { "hypernyms": ["Bird", "Animal"] },
      "eagle": { "hypernyms": ["Bird", "Animal"] },
      "fish": { "hypernyms": ["Animal"] },
      "salmon": { "hypernyms": ["Fish", "Animal"] },
      "human": { "hypernyms": ["Animal", "Mammal"] },
      "car": { "hypernyms": ["Vehicle"] },
      "truck": { "hypernyms": ["Vehicle"] },
      "bicycle": { "hypernyms": ["Vehicle"] }
    },
    "adjectives": {
      "fake": { "type": "Privative" },
      "counterfeit": { "type": "Privative" },
      "former": { "type": "Privative" },
      "alleged": { "type": "Privative" },
      "would-be": { "type": "Privative" },
      "imaginary": { "type": "Privative" },
      "fictional": { "type": "Privative" }
    },
    "verbs": {
      "murder": { "entails": "Kill", "manner": ["Intentional"] },
      "assassinate": { "entails": "Kill", "manner": ["Intentional", "Political"] },
      "slaughter": { "entails": "Kill", "manner": ["Violent"] },
      "execute": { "entails": "Kill", "manner": ["Legal", "Intentional"] }
    }
  }
}
```

---

## Lexer & Tokenization

The lexer transforms English text into a stream of classified tokens using dictionary lookups and heuristic fallbacks for unknown words.

**Location:** `src/token.rs`, `src/lexer.rs`

### Token Definitions

**File:** `src/token.rs`

Token type taxonomy including quantifiers, modal operators, connectives (Because for causal), pronouns, prepositions, demonstratives (This/That/These/Those), Reciprocal (each other), and performatives. Supports presupposition triggers, focus particles, and measure words (MeasureKind: Much/Little). Number(Symbol) stores numeric literals as interned strings for prover-ready symbolic math. Includes semantic token sets (WH_WORDS, MODALS) as const arrays for pattern matching. Span struct (start/end byte positions) for source location tracking. **Phase 12:** TokenType::Ambiguous { primary: Box<TokenType>, alternatives: Vec<TokenType> } for polysemous words that have multiple valid interpretations (e.g., 'duck' as Noun or Verb).

```rust
use crate::context::{Case, Gender, Number};
use crate::intern::Symbol;
use crate::lexicon::{Aspect, Definiteness, Time, VerbClass};

#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
pub struct Span {
    pub start: usize,
    pub end: usize,
}

impl Span {
    pub fn new(start: usize, end: usize) -> Self {
        Self { start, end }
    }
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum PresupKind {
    Stop,
    Start,
    Regret,
    Continue,
    Realize,
    Know,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum FocusKind {
    Only,
    Even,
    Just,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum MeasureKind {
    Much,
    Little,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum BlockType {
    Theorem,
    Main,
    Definition,
    Proof,
    Example,
    Logic,
    Note,
    Function,  // Phase 32: ## To blocks
    TypeDef,   // Inline type definitions: ## A Point has:, ## A Color is one of:
    Policy,    // Phase 50: ## Policy blocks for security rules
}

#[derive(Debug, Clone, PartialEq, Eq)]
pub enum TokenType {
    // Document Structure
    BlockHeader { block_type: BlockType },

    // Quantifiers
    All,
    No,
    Some,
    Any,
    Both, // Correlative conjunction marker: "both X and Y"
    Most,
    Few,
    Many,
    Cardinal(u32),
    AtLeast(u32),
    AtMost(u32),

    // Negative Polarity Items (NPIs)
    Anything,
    Anyone,
    Nothing,
    Nobody,
    NoOne,
    Nowhere,
    Ever,
    Never,

    // Logical Connectives
    And,
    Or,
    If,
    Then,
    Not,
    Iff,
    Because,

    // Modal Operators
    Must,
    Shall,
    Should,
    Can,
    May,
    Cannot,
    Would,
    Could,
    Might,
    Had,

    // Imperative Statement Keywords
    Let,
    Set,
    Return,
    Be,
    While,
    Repeat,
    For,
    In,
    From,
    Assert,
    Trust,    // Phase 35: Documented assertion with justification
    Otherwise,
    Call,
    New,      // Phase 31: Constructor keyword
    Either,   // Phase 33: Sum type definition
    Inspect,  // Phase 33: Pattern matching
    Native,   // Phase 38: Native function modifier

    // Phase 10: IO Keywords
    Read,     // "Read input from..."
    Write,    // "Write x to file..."
    Console,  // "...from the console"
    File,     // "...from file..." or "...to file..."

    // Ownership Keywords (Move/Borrow Semantics)
    Give,  // Move ownership: "Give x to processor"
    Show,  // Immutable borrow: "Show x to console"

    // Phase 43D: Collection Operations
    Push,     // "Push x to items"
    Pop,      // "Pop from items"
    Copy,     // "copy of slice" → slice.to_vec()
    Through,  // "items 1 through 3" → inclusive slice
    Length,   // "length of items" → items.len()
    At,       // "items at i" → items[i]

    // Set Operations
    Add,          // "Add x to set" (insert)
    Remove,       // "Remove x from set"
    Contains,     // "set contains x"
    Union,        // "a union b"
    Intersection, // "a intersection b"

    // Phase 8.5: Memory Management (Zones)
    Inside,   // "Inside a new zone..."
    Zone,     // "...zone called..."
    Called,   // "...called 'Scratch'"
    Size,     // "...of size 1 MB"
    Mapped,   // "...mapped from 'file.bin'"

    // Phase 9: Structured Concurrency
    Attempt,        // "Attempt all of the following:" -> concurrent (async, I/O-bound)
    Following,      // "the following"
    Simultaneously, // "Simultaneously:" -> parallel (CPU-bound)

    // Phase 46: Agent System (Actor Model)
    Spawn,    // "Spawn a Worker called 'w1'" -> create agent
    Send,     // "Send Ping to 'agent'" -> send message to agent
    Await,    // "Await response from 'agent' into result" -> receive message

    // Phase 47: Serialization
    Portable, // "A Message is Portable and has:" -> serde derives

    // Phase 48: Sipping Protocol
    Manifest, // "the manifest of Zone" -> FileSipper manifest
    Chunk,    // "the chunk at N in Zone" -> FileSipper chunk

    // Phase 49: CRDT Keywords
    Shared,   // "A Counter is Shared and has:" -> CRDT struct
    Merge,    // "Merge remote into local" -> CRDT merge
    Increase, // "Increase x's count by 10" -> GCounter increment

    // Phase 49b: Extended CRDT Keywords (Wave 5)
    Decrease,       // "Decrease x's count by 5" -> PNCounter decrement
    Tally,          // "which is a Tally" -> PNCounter type
    SharedSet,      // "which is a SharedSet of T" -> ORSet type
    SharedSequence, // "which is a SharedSequence of T" -> RGA type
    CollaborativeSequence, // "which is a CollaborativeSequence of T" -> YATA type
    SharedMap,      // "which is a SharedMap from K to V" -> ORMap type
    Divergent,      // "which is a Divergent T" -> MVRegister type
    Append,         // "Append x to seq" -> RGA append
    Resolve,        // "Resolve x to value" -> MVRegister resolve
    RemoveWins,     // "(RemoveWins)" -> ORSet bias
    AddWins,        // "(AddWins)" -> ORSet bias (default)
    YATA,           // "(YATA)" -> Sequence algorithm
    Values,         // "x's values" -> MVRegister values accessor

    // Phase 50: Security Keywords
    Check,    // "Check that user is admin" -> mandatory runtime guard

    // Phase 51: P2P Networking Keywords
    Listen,   // "Listen on [addr]" -> bind to network address
    NetConnect,  // "Connect to [addr]" -> dial a peer (NetConnect to avoid conflict)
    Sleep,    // "Sleep N." -> pause execution for N milliseconds

    // Phase 52: GossipSub Keywords
    Sync,     // "Sync x on 'topic'" -> automatic CRDT replication

    // Phase 53: Persistence Keywords
    Mount,      // "Mount x at [path]" -> load/create persistent CRDT from journal
    Persistent, // "Persistent Counter" -> type wrapped with journaling
    Combined,   // "x combined with y" -> string concatenation

    // Phase 54: Go-like Concurrency Keywords
    Launch,     // "Launch a task to..." -> spawn green thread
    Task,       // "a task" -> identifier for task context
    Pipe,       // "Pipe of Type" -> channel creation
    Receive,    // "Receive from pipe" -> recv from channel
    Stop,       // "Stop handle" -> abort task
    Try,        // "Try to send/receive" -> non-blocking variant
    Into,       // "Send value into pipe" -> channel send
    First,      // "Await the first of:" -> select statement
    After,      // "After N seconds:" -> timeout branch

    // Block Scoping
    Colon,
    Indent,
    Dedent,
    Newline,

    // Content Words
    Noun(Symbol),
    Adjective(Symbol),
    NonIntersectiveAdjective(Symbol),
    Adverb(Symbol),
    ScopalAdverb(Symbol),
    TemporalAdverb(Symbol),
    Verb {
        lemma: Symbol,
        time: Time,
        aspect: Aspect,
        class: VerbClass,
    },
    ProperName(Symbol),

    // Lexical Ambiguity (Phase 12: Parse Forest)
    Ambiguous {
        primary: Box<TokenType>,
        alternatives: Vec<TokenType>,
    },

    // Speech Acts (Performatives)
    Performative(Symbol),
    Exclamation,

    // Articles (Definiteness)
    Article(Definiteness),

    // Temporal Auxiliaries
    Auxiliary(Time),

    // Copula & Functional
    Is,
    Are,
    Was,
    Were,
    That,
    Who,
    What,
    Where,
    When,
    Why,
    Does,
    Do,

    // Identity & Reflexive (FOL)
    Identity,
    Equals,
    Reflexive,
    Reciprocal,
    Respectively,  // Phase 35: Pairwise list coordination

    // Pronouns (Discourse)
    Pronoun {
        gender: Gender,
        number: Number,
        case: Case,
    },

    // Prepositions (for N-ary relations)
    Preposition(Symbol),

    // Phrasal Verb Particles (up, down, out, in, off, on, away)
    Particle(Symbol),

    // Comparatives & Superlatives (Pillar 3 - Degree Semantics)
    Comparative(Symbol),
    Superlative(Symbol),
    Than,

    // Control Verbs (Chomsky's Control Theory)
    To,

    // Presupposition Triggers (Austin/Strawson)
    PresupTrigger(PresupKind),

    // Focus Particles (Rooth)
    Focus(FocusKind),

    // Mass Noun Measure
    Measure(MeasureKind),

    // Numeric Literals (prover-ready: stores raw string for symbolic math)
    Number(Symbol),

    // Phase 33: String literals "hello world"
    StringLiteral(Symbol),

    // Character literal: `x` (backtick syntax)
    CharLiteral(Symbol),

    // Index Access (1-indexed)
    Item,
    Items,

    // Possession (Genitive Case)
    Possessive,

    // Punctuation
    LParen,
    RParen,
    LBracket,
    RBracket,
    Comma,
    Period,

    // Arithmetic Operators
    Plus,
    Minus,
    Star,
    Slash,
    Percent,  // Modulo operator

    // Grand Challenge: Comparison Operators
    Lt,        // <
    Gt,        // >
    LtEq,      // <=
    GtEq,      // >=
    EqEq,      // ==
    NotEq,     // !=

    // Phase 38: Arrow for return type syntax
    Arrow,  // ->

    EOF,
}

#[derive(Debug, Clone)]
pub struct Token {
    pub kind: TokenType,
    pub lexeme: Symbol,
    pub span: Span,
}

impl Token {
    pub fn new(kind: TokenType, lexeme: Symbol, span: Span) -> Self {
        Token { kind, lexeme, span }
    }
}

impl TokenType {
    pub const WH_WORDS: &'static [TokenType] = &[
        TokenType::Who,
        TokenType::What,
        TokenType::Where,
        TokenType::When,
        TokenType::Why,
    ];

    pub const MODALS: &'static [TokenType] = &[
        TokenType::Must,
        TokenType::Shall,
        TokenType::Should,
        TokenType::Can,
        TokenType::May,
        TokenType::Cannot,
        TokenType::Would,
        TokenType::Could,
        TokenType::Might,
    ];
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn span_new_stores_positions() {
        let span = Span::new(5, 10);
        assert_eq!(span.start, 5);
        assert_eq!(span.end, 10);
    }

    #[test]
    fn span_default_is_zero() {
        let span = Span::default();
        assert_eq!(span.start, 0);
        assert_eq!(span.end, 0);
    }

    #[test]
    fn token_has_span_field() {
        use crate::intern::Interner;
        let mut interner = Interner::new();
        let lexeme = interner.intern("test");
        let token = Token::new(TokenType::Noun(lexeme), lexeme, Span::new(0, 4));
        assert_eq!(token.span.start, 0);
        assert_eq!(token.span.end, 4);
    }

    #[test]
    fn wh_words_contains_all_wh_tokens() {
        assert_eq!(TokenType::WH_WORDS.len(), 5);
        assert!(TokenType::WH_WORDS.contains(&TokenType::Who));
        assert!(TokenType::WH_WORDS.contains(&TokenType::What));
        assert!(TokenType::WH_WORDS.contains(&TokenType::Where));
        assert!(TokenType::WH_WORDS.contains(&TokenType::When));
        assert!(TokenType::WH_WORDS.contains(&TokenType::Why));
    }

    #[test]
    fn modals_contains_all_modal_tokens() {
        assert_eq!(TokenType::MODALS.len(), 9);
        assert!(TokenType::MODALS.contains(&TokenType::Must));
        assert!(TokenType::MODALS.contains(&TokenType::Shall));
        assert!(TokenType::MODALS.contains(&TokenType::Should));
        assert!(TokenType::MODALS.contains(&TokenType::Can));
        assert!(TokenType::MODALS.contains(&TokenType::May));
        assert!(TokenType::MODALS.contains(&TokenType::Cannot));
        assert!(TokenType::MODALS.contains(&TokenType::Would));
        assert!(TokenType::MODALS.contains(&TokenType::Could));
        assert!(TokenType::MODALS.contains(&TokenType::Might));
    }
}

```

---

### Lexer Implementation

**File:** `src/lexer.rs`

Dictionary-based tokenization with heuristic word classification. **Verb-First Priority:** Word classification checks verbs before nouns (lines 573-594), enabling the parser safety net where consume_content_word() accepts Verb tokens in noun positions. Disambiguation: words in disambiguation_not_verbs that are also common nouns return Noun; otherwise Adjective. **Verb/Adjective Ambiguity:** Extended ambiguity detection to include Verb AND Adjective overlap (e.g., 'open'); returns TokenType::Ambiguous{Verb, [Adj]} for words that can be either. **Content Word Classifiers:** Heuristic helpers is_noun_like(), is_verb_like(), is_adjective_like() for disambiguating unknown words. **Capitalized Article Disambiguation:** Sentence-initial 'A'/'An' uses lookahead heuristics: followed by logical keyword (if, and, or) → ProperName; followed by verb (not gerund) → ProperName; followed by noun/adjective or lowercase word → Article(Indefinite). Examples: 'A dog ran.' → Article; 'A if B.' → ProperName; 'A red ball.' → Article. Handles contractions, punctuation, unknown word fallbacks, gerund detection (-ing forms as nouns), and mass noun quantifiers (much/little). Enhanced number recognition with word_to_number() for spelled-out numerals and lookahead for compound numbers (twenty five, two and a half). Returns Number(Symbol) tokens for prover-ready symbolic math. UTF-8 safe byte position tracking via char_indices() for span generation. **Contraction Expansion:** Negative contractions split to separate tokens: don't→do+not, doesn't→does+not, didn't→did+not, won't→will+not, can't→cannot. Uses skip_count for character skipping after expansion.

```rust
use crate::intern::Interner;
use crate::lexicon::{self, Aspect, Definiteness, Lexicon, Time};
use crate::token::{BlockType, FocusKind, MeasureKind, Span, Token, TokenType};

// ============================================================================
// Stage 1: Line Lexer (Spec §2.5.2)
// ============================================================================

/// Tokens emitted by the LineLexer (Stage 1).
/// Handles structural tokens (Indent, Dedent, Newline) while treating
/// all other content as opaque for Stage 2 word classification.
#[derive(Debug, Clone, PartialEq)]
pub enum LineToken {
    /// Block increased indentation
    Indent,
    /// Block decreased indentation
    Dedent,
    /// Logical newline (statement boundary) - reserved for future use
    Newline,
    /// Content to be further tokenized (line content, trimmed)
    Content { text: String, start: usize, end: usize },
}

/// Stage 1 Lexer: Handles only lines, indentation, and structural tokens.
/// Treats all other text as opaque `Content` for the Stage 2 WordLexer.
pub struct LineLexer<'a> {
    source: &'a str,
    bytes: &'a [u8],
    indent_stack: Vec<usize>,
    pending_dedents: usize,
    position: usize,
    /// True if we need to emit Content for current line
    has_pending_content: bool,
    pending_content_start: usize,
    pending_content_end: usize,
    pending_content_text: String,
    /// True after we've finished processing all lines
    finished_lines: bool,
    /// True if we've emitted at least one Indent (need to emit Dedents at EOF)
    emitted_indent: bool,
}

impl<'a> LineLexer<'a> {
    pub fn new(source: &'a str) -> Self {
        Self {
            source,
            bytes: source.as_bytes(),
            indent_stack: vec![0],
            pending_dedents: 0,
            position: 0,
            has_pending_content: false,
            pending_content_start: 0,
            pending_content_end: 0,
            pending_content_text: String::new(),
            finished_lines: false,
            emitted_indent: false,
        }
    }

    /// Calculate indentation level at current position (at start of line).
    /// Returns (indent_level, content_start_pos).
    fn measure_indent(&self, line_start: usize) -> (usize, usize) {
        let mut indent = 0;
        let mut pos = line_start;

        while pos < self.bytes.len() {
            match self.bytes[pos] {
                b' ' => {
                    indent += 1;
                    pos += 1;
                }
                b'\t' => {
                    indent += 4; // Tab = 4 spaces
                    pos += 1;
                }
                _ => break,
            }
        }

        (indent, pos)
    }

    /// Read content from current position until end of line or EOF.
    /// Returns (content_text, content_start, content_end, next_line_start).
    fn read_line_content(&self, content_start: usize) -> (String, usize, usize, usize) {
        let mut pos = content_start;

        // Find end of line
        while pos < self.bytes.len() && self.bytes[pos] != b'\n' {
            pos += 1;
        }

        let content_end = pos;
        let text = self.source[content_start..content_end].trim_end().to_string();

        // Move past newline if present
        let next_line_start = if pos < self.bytes.len() && self.bytes[pos] == b'\n' {
            pos + 1
        } else {
            pos
        };

        (text, content_start, content_end, next_line_start)
    }

    /// Check if the line starting at `pos` is blank (only whitespace).
    fn is_blank_line(&self, line_start: usize) -> bool {
        let mut pos = line_start;
        while pos < self.bytes.len() {
            match self.bytes[pos] {
                b' ' | b'\t' => pos += 1,
                b'\n' => return true,
                _ => return false,
            }
        }
        true // EOF counts as blank
    }

    /// Process the next line and update internal state.
    /// Returns true if we have tokens to emit, false if we're done.
    fn process_next_line(&mut self) -> bool {
        // Skip blank lines
        while self.position < self.bytes.len() && self.is_blank_line(self.position) {
            // Skip to next line
            while self.position < self.bytes.len() && self.bytes[self.position] != b'\n' {
                self.position += 1;
            }
            if self.position < self.bytes.len() {
                self.position += 1; // Skip the newline
            }
        }

        // Check if we've reached EOF
        if self.position >= self.bytes.len() {
            self.finished_lines = true;
            // Emit remaining dedents at EOF
            if self.indent_stack.len() > 1 {
                self.pending_dedents = self.indent_stack.len() - 1;
                self.indent_stack.truncate(1);
            }
            return self.pending_dedents > 0;
        }

        // Measure indentation of current line
        let (line_indent, content_start) = self.measure_indent(self.position);

        // Read line content
        let (text, start, end, next_pos) = self.read_line_content(content_start);

        // Skip if content is empty (shouldn't happen after blank line skip, but be safe)
        if text.is_empty() {
            self.position = next_pos;
            return self.process_next_line();
        }

        let current_indent = *self.indent_stack.last().unwrap();

        // Handle indentation changes
        if line_indent > current_indent {
            // Indent: push new level
            self.indent_stack.push(line_indent);
            self.emitted_indent = true;
            // Store content to emit after Indent
            self.has_pending_content = true;
            self.pending_content_text = text;
            self.pending_content_start = start;
            self.pending_content_end = end;
            self.position = next_pos;
            // We'll emit Indent first, then Content
            return true;
        } else if line_indent < current_indent {
            // Dedent: pop until we match
            while self.indent_stack.len() > 1 {
                let top = *self.indent_stack.last().unwrap();
                if line_indent < top {
                    self.indent_stack.pop();
                    self.pending_dedents += 1;
                } else {
                    break;
                }
            }
            // Store content to emit after Dedents
            self.has_pending_content = true;
            self.pending_content_text = text;
            self.pending_content_start = start;
            self.pending_content_end = end;
            self.position = next_pos;
            return true;
        } else {
            // Same indentation level
            self.has_pending_content = true;
            self.pending_content_text = text;
            self.pending_content_start = start;
            self.pending_content_end = end;
            self.position = next_pos;
            return true;
        }
    }
}

impl<'a> Iterator for LineLexer<'a> {
    type Item = LineToken;

    fn next(&mut self) -> Option<LineToken> {
        // 1. Emit pending dedents first
        if self.pending_dedents > 0 {
            self.pending_dedents -= 1;
            return Some(LineToken::Dedent);
        }

        // 2. Emit pending content
        if self.has_pending_content {
            self.has_pending_content = false;
            let text = std::mem::take(&mut self.pending_content_text);
            let start = self.pending_content_start;
            let end = self.pending_content_end;
            return Some(LineToken::Content { text, start, end });
        }

        // 3. Check if we need to emit Indent (after pushing to stack)
        // This happens when we detected an indent but haven't emitted the token yet
        // We need to check if indent_stack was just modified

        // 4. Process next line
        if !self.finished_lines {
            let had_indent = self.indent_stack.len();
            if self.process_next_line() {
                // Check if we added an indent level
                if self.indent_stack.len() > had_indent {
                    return Some(LineToken::Indent);
                }
                // Check if we have pending dedents
                if self.pending_dedents > 0 {
                    self.pending_dedents -= 1;
                    return Some(LineToken::Dedent);
                }
                // Otherwise emit content
                if self.has_pending_content {
                    self.has_pending_content = false;
                    let text = std::mem::take(&mut self.pending_content_text);
                    let start = self.pending_content_start;
                    let end = self.pending_content_end;
                    return Some(LineToken::Content { text, start, end });
                }
            } else if self.pending_dedents > 0 {
                // EOF with pending dedents
                self.pending_dedents -= 1;
                return Some(LineToken::Dedent);
            }
        }

        // 5. Emit any remaining dedents at EOF
        if self.pending_dedents > 0 {
            self.pending_dedents -= 1;
            return Some(LineToken::Dedent);
        }

        None
    }
}

// ============================================================================
// Stage 2: Word Lexer (existing Lexer)
// ============================================================================

#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
pub enum LexerMode {
    #[default]
    Declarative, // Logic, Theorems, Definitions
    Imperative,  // Main, Functions, Code
}

pub struct Lexer<'a> {
    words: Vec<WordItem>,
    pos: usize,
    lexicon: Lexicon,
    interner: &'a mut Interner,
    input_len: usize,
    in_let_context: bool,
    mode: LexerMode,
    source: String,
}

struct WordItem {
    word: String,
    trailing_punct: Option<char>,
    start: usize,
    end: usize,
    punct_pos: Option<usize>,
}

impl<'a> Lexer<'a> {
    pub fn new(input: &str, interner: &'a mut Interner) -> Self {
        let words = Self::split_into_words(input);
        let input_len = input.len();

        Lexer {
            words,
            pos: 0,
            lexicon: Lexicon::new(),
            interner,
            input_len,
            in_let_context: false,
            mode: LexerMode::Declarative,
            source: input.to_string(),
        }
    }

    fn split_into_words(input: &str) -> Vec<WordItem> {
        let mut items = Vec::new();
        let mut current_word = String::new();
        let mut word_start = 0;
        let chars: Vec<char> = input.chars().collect();
        let mut char_idx = 0;
        let mut skip_count = 0;

        for (i, c) in input.char_indices() {
            if skip_count > 0 {
                skip_count -= 1;
                char_idx += 1;
                continue;
            }
            let next_pos = i + c.len_utf8();
            match c {
                ' ' | '\t' | '\n' | '\r' => {
                    if !current_word.is_empty() {
                        items.push(WordItem {
                            word: std::mem::take(&mut current_word),
                            trailing_punct: None,
                            start: word_start,
                            end: i,
                            punct_pos: None,
                        });
                    }
                    word_start = next_pos;
                }
                '.' => {
                    // Check if this is a decimal point (digit before and after)
                    let prev_is_digit = !current_word.is_empty()
                        && current_word.chars().last().map_or(false, |ch| ch.is_ascii_digit());
                    let next_is_digit = char_idx + 1 < chars.len()
                        && chars[char_idx + 1].is_ascii_digit();

                    if prev_is_digit && next_is_digit {
                        // This is a decimal point, include it in the current word
                        current_word.push(c);
                    } else {
                        // This is a sentence period
                        if !current_word.is_empty() {
                            items.push(WordItem {
                                word: std::mem::take(&mut current_word),
                                trailing_punct: Some(c),
                                start: word_start,
                                end: i,
                                punct_pos: Some(i),
                            });
                        } else {
                            items.push(WordItem {
                                word: String::new(),
                                trailing_punct: Some(c),
                                start: i,
                                end: next_pos,
                                punct_pos: Some(i),
                            });
                        }
                        word_start = next_pos;
                    }
                }
                '#' => {
                    // Check for ## block header (markdown-style)
                    if char_idx + 1 < chars.len() && chars[char_idx + 1] == '#' {
                        // This is a ## block header
                        // Skip the second # and capture the next word as a block header
                        if !current_word.is_empty() {
                            items.push(WordItem {
                                word: std::mem::take(&mut current_word),
                                trailing_punct: None,
                                start: word_start,
                                end: i,
                                punct_pos: None,
                            });
                        }
                        // Skip whitespace after ##
                        let header_start = i;
                        let mut j = char_idx + 2;
                        while j < chars.len() && (chars[j] == ' ' || chars[j] == '\t') {
                            j += 1;
                        }
                        // Capture the block type word
                        let mut block_word = String::from("##");
                        while j < chars.len() && chars[j].is_alphabetic() {
                            block_word.push(chars[j]);
                            j += 1;
                        }
                        if block_word.len() > 2 {
                            items.push(WordItem {
                                word: block_word,
                                trailing_punct: None,
                                start: header_start,
                                end: header_start + (j - char_idx),
                                punct_pos: None,
                            });
                        }
                        skip_count = j - char_idx - 1;
                        word_start = header_start + (j - char_idx);
                    } else {
                        // Single # - treat as comment, skip to end of line
                        // Count how many chars to skip (without modifying char_idx here -
                        // the main loop's skip handler will increment it)
                        let mut look_ahead = char_idx + 1;
                        while look_ahead < chars.len() && chars[look_ahead] != '\n' {
                            skip_count += 1;
                            look_ahead += 1;
                        }
                        if !current_word.is_empty() {
                            items.push(WordItem {
                                word: std::mem::take(&mut current_word),
                                trailing_punct: None,
                                start: word_start,
                                end: i,
                                punct_pos: None,
                            });
                        }
                        word_start = look_ahead + 1; // Start after the newline
                    }
                }
                // Phase 33: String literals "hello world"
                '"' => {
                    // Push any pending word
                    if !current_word.is_empty() {
                        items.push(WordItem {
                            word: std::mem::take(&mut current_word),
                            trailing_punct: None,
                            start: word_start,
                            end: i,
                            punct_pos: None,
                        });
                    }

                    // Scan until closing quote
                    let string_start = i;
                    let mut j = char_idx + 1;
                    let mut string_content = String::new();
                    while j < chars.len() && chars[j] != '"' {
                        if chars[j] == '\\' && j + 1 < chars.len() {
                            // Escape sequence - skip backslash, include next char
                            j += 1;
                            if j < chars.len() {
                                string_content.push(chars[j]);
                            }
                        } else {
                            string_content.push(chars[j]);
                        }
                        j += 1;
                    }

                    // Create a special marker for string literals
                    // We prefix with a special character to identify in tokenize()
                    items.push(WordItem {
                        word: format!("\x00STR:{}", string_content),
                        trailing_punct: None,
                        start: string_start,
                        end: if j < chars.len() { j + 1 } else { j },
                        punct_pos: None,
                    });

                    // Skip past the closing quote
                    if j < chars.len() {
                        skip_count = j - char_idx;
                    } else {
                        skip_count = j - char_idx - 1;
                    }
                    word_start = if j < chars.len() { j + 1 } else { j };
                }
                // Character literals with backticks: `x`
                '`' => {
                    // Push any pending word
                    if !current_word.is_empty() {
                        items.push(WordItem {
                            word: std::mem::take(&mut current_word),
                            trailing_punct: None,
                            start: word_start,
                            end: i,
                            punct_pos: None,
                        });
                    }

                    // Scan for character content and closing backtick
                    let char_start = i;
                    let mut j = char_idx + 1;
                    let mut char_content = String::new();

                    if j < chars.len() {
                        if chars[j] == '\\' && j + 1 < chars.len() {
                            // Escape sequence
                            j += 1;
                            let escaped_char = match chars[j] {
                                'n' => '\n',
                                't' => '\t',
                                'r' => '\r',
                                '\\' => '\\',
                                '`' => '`',
                                '0' => '\0',
                                c => c,
                            };
                            char_content.push(escaped_char);
                            j += 1;
                        } else if chars[j] != '`' {
                            // Regular character
                            char_content.push(chars[j]);
                            j += 1;
                        }
                    }

                    // Expect closing backtick
                    if j < chars.len() && chars[j] == '`' {
                        j += 1; // skip closing backtick
                    }

                    // Create a special marker for char literals
                    items.push(WordItem {
                        word: format!("\x00CHAR:{}", char_content),
                        trailing_punct: None,
                        start: char_start,
                        end: if j <= chars.len() { char_start + (j - char_idx) } else { char_start + 1 },
                        punct_pos: None,
                    });

                    if j > char_idx + 1 {
                        skip_count = j - char_idx - 1;
                    }
                    word_start = char_start + (j - char_idx);
                }
                // Phase 38: Handle -> as a single token for return type syntax
                '-' if char_idx + 1 < chars.len() && chars[char_idx + 1] == '>' => {
                    // Push any pending word first
                    if !current_word.is_empty() {
                        items.push(WordItem {
                            word: std::mem::take(&mut current_word),
                            trailing_punct: None,
                            start: word_start,
                            end: i,
                            punct_pos: None,
                        });
                    }
                    // Push -> as its own word
                    items.push(WordItem {
                        word: "->".to_string(),
                        trailing_punct: None,
                        start: i,
                        end: i + 2,
                        punct_pos: None,
                    });
                    skip_count = 1; // Skip the '>' character
                    word_start = i + 2;
                }
                // Grand Challenge: Handle <= as a single token
                '<' if char_idx + 1 < chars.len() && chars[char_idx + 1] == '=' => {
                    if !current_word.is_empty() {
                        items.push(WordItem {
                            word: std::mem::take(&mut current_word),
                            trailing_punct: None,
                            start: word_start,
                            end: i,
                            punct_pos: None,
                        });
                    }
                    items.push(WordItem {
                        word: "<=".to_string(),
                        trailing_punct: None,
                        start: i,
                        end: i + 2,
                        punct_pos: None,
                    });
                    skip_count = 1;
                    word_start = i + 2;
                }
                // Grand Challenge: Handle >= as a single token
                '>' if char_idx + 1 < chars.len() && chars[char_idx + 1] == '=' => {
                    if !current_word.is_empty() {
                        items.push(WordItem {
                            word: std::mem::take(&mut current_word),
                            trailing_punct: None,
                            start: word_start,
                            end: i,
                            punct_pos: None,
                        });
                    }
                    items.push(WordItem {
                        word: ">=".to_string(),
                        trailing_punct: None,
                        start: i,
                        end: i + 2,
                        punct_pos: None,
                    });
                    skip_count = 1;
                    word_start = i + 2;
                }
                // Handle == as a single token
                '=' if char_idx + 1 < chars.len() && chars[char_idx + 1] == '=' => {
                    if !current_word.is_empty() {
                        items.push(WordItem {
                            word: std::mem::take(&mut current_word),
                            trailing_punct: None,
                            start: word_start,
                            end: i,
                            punct_pos: None,
                        });
                    }
                    items.push(WordItem {
                        word: "==".to_string(),
                        trailing_punct: None,
                        start: i,
                        end: i + 2,
                        punct_pos: None,
                    });
                    skip_count = 1;
                    word_start = i + 2;
                }
                // Handle != as a single token
                '!' if char_idx + 1 < chars.len() && chars[char_idx + 1] == '=' => {
                    if !current_word.is_empty() {
                        items.push(WordItem {
                            word: std::mem::take(&mut current_word),
                            trailing_punct: None,
                            start: word_start,
                            end: i,
                            punct_pos: None,
                        });
                    }
                    items.push(WordItem {
                        word: "!=".to_string(),
                        trailing_punct: None,
                        start: i,
                        end: i + 2,
                        punct_pos: None,
                    });
                    skip_count = 1;
                    word_start = i + 2;
                }
                '(' | ')' | '[' | ']' | ',' | '?' | '!' | ':' | '+' | '-' | '*' | '/' | '%' | '<' | '>' | '=' => {
                    if !current_word.is_empty() {
                        items.push(WordItem {
                            word: std::mem::take(&mut current_word),
                            trailing_punct: Some(c),
                            start: word_start,
                            end: i,
                            punct_pos: Some(i),
                        });
                    } else {
                        items.push(WordItem {
                            word: String::new(),
                            trailing_punct: Some(c),
                            start: i,
                            end: next_pos,
                            punct_pos: Some(i),
                        });
                    }
                    word_start = next_pos;
                }
                '\'' => {
                    // Handle contractions: expand "don't" → "do" + "not", etc.
                    let remaining: String = chars[char_idx + 1..].iter().collect();
                    let remaining_lower = remaining.to_lowercase();

                    if remaining_lower.starts_with("t ") || remaining_lower.starts_with("t.") ||
                       remaining_lower.starts_with("t,") || remaining_lower == "t" ||
                       (char_idx + 1 < chars.len() && chars[char_idx + 1] == 't' &&
                        (char_idx + 2 >= chars.len() || !chars[char_idx + 2].is_alphabetic())) {
                        // This is a contraction ending in 't (don't, doesn't, won't, can't, etc.)
                        let word_lower = current_word.to_lowercase();
                        if word_lower == "don" || word_lower == "doesn" || word_lower == "didn" {
                            // do/does/did + not
                            let base = if word_lower == "don" { "do" }
                                      else if word_lower == "doesn" { "does" }
                                      else { "did" };
                            items.push(WordItem {
                                word: base.to_string(),
                                trailing_punct: None,
                                start: word_start,
                                end: i,
                                punct_pos: None,
                            });
                            items.push(WordItem {
                                word: "not".to_string(),
                                trailing_punct: None,
                                start: i,
                                end: i + 2,
                                punct_pos: None,
                            });
                            current_word.clear();
                            word_start = next_pos + 1;
                            skip_count = 1;
                        } else if word_lower == "won" {
                            // will + not
                            items.push(WordItem {
                                word: "will".to_string(),
                                trailing_punct: None,
                                start: word_start,
                                end: i,
                                punct_pos: None,
                            });
                            items.push(WordItem {
                                word: "not".to_string(),
                                trailing_punct: None,
                                start: i,
                                end: i + 2,
                                punct_pos: None,
                            });
                            current_word.clear();
                            word_start = next_pos + 1;
                            skip_count = 1;
                        } else if word_lower == "can" {
                            // cannot
                            items.push(WordItem {
                                word: "cannot".to_string(),
                                trailing_punct: None,
                                start: word_start,
                                end: i + 2,
                                punct_pos: None,
                            });
                            current_word.clear();
                            word_start = next_pos + 1;
                            skip_count = 1;
                        } else {
                            // Unknown contraction, split normally
                            if !current_word.is_empty() {
                                items.push(WordItem {
                                    word: std::mem::take(&mut current_word),
                                    trailing_punct: Some('\''),
                                    start: word_start,
                                    end: i,
                                    punct_pos: Some(i),
                                });
                            }
                            word_start = next_pos;
                        }
                    } else {
                        // Not a 't contraction, handle normally
                        if !current_word.is_empty() {
                            items.push(WordItem {
                                word: std::mem::take(&mut current_word),
                                trailing_punct: Some('\''),
                                start: word_start,
                                end: i,
                                punct_pos: Some(i),
                            });
                        }
                        word_start = next_pos;
                    }
                }
                c if c.is_alphabetic() || c.is_ascii_digit() || (c == '.' && !current_word.is_empty() && current_word.chars().all(|ch| ch.is_ascii_digit())) || c == '_' => {
                    if current_word.is_empty() {
                        word_start = i;
                    }
                    current_word.push(c);
                }
                _ => {
                    word_start = next_pos;
                }
            }
            char_idx += 1;
        }

        if !current_word.is_empty() {
            items.push(WordItem {
                word: current_word,
                trailing_punct: None,
                start: word_start,
                end: input.len(),
                punct_pos: None,
            });
        }

        items
    }

    fn peek_word(&self, offset: usize) -> Option<&str> {
        self.words.get(self.pos + offset).map(|w| w.word.as_str())
    }

    fn peek_sequence(&self, expected: &[&str]) -> bool {
        for (i, &exp) in expected.iter().enumerate() {
            match self.peek_word(i + 1) {
                Some(w) if w.to_lowercase() == exp => continue,
                _ => return false,
            }
        }
        true
    }

    fn consume_words(&mut self, count: usize) {
        self.pos += count;
    }

    pub fn tokenize(&mut self) -> Vec<Token> {
        let mut tokens = Vec::new();

        while self.pos < self.words.len() {
            let item = &self.words[self.pos];
            let word = item.word.clone();
            let trailing_punct = item.trailing_punct;
            let word_start = item.start;
            let word_end = item.end;
            let punct_pos = item.punct_pos;

            if word.is_empty() {
                if let Some(punct) = trailing_punct {
                    let kind = match punct {
                        '(' => TokenType::LParen,
                        ')' => TokenType::RParen,
                        '[' => TokenType::LBracket,
                        ']' => TokenType::RBracket,
                        ',' => TokenType::Comma,
                        ':' => TokenType::Colon,
                        '.' | '?' => {
                            self.in_let_context = false;
                            TokenType::Period
                        }
                        '!' => TokenType::Exclamation,
                        '+' => TokenType::Plus,
                        '-' => TokenType::Minus,
                        '*' => TokenType::Star,
                        '/' => TokenType::Slash,
                        '%' => TokenType::Percent,
                        '<' => TokenType::Lt,
                        '>' => TokenType::Gt,
                        _ => {
                            self.pos += 1;
                            continue;
                        }
                    };
                    let lexeme = self.interner.intern(&punct.to_string());
                    let span = Span::new(word_start, word_end);
                    tokens.push(Token::new(kind, lexeme, span));
                }
                self.pos += 1;
                continue;
            }

            // Phase 33: Check for string literal marker
            if word.starts_with("\x00STR:") {
                let content = &word[5..]; // Skip the marker prefix
                let sym = self.interner.intern(content);
                let span = Span::new(word_start, word_end);
                tokens.push(Token::new(TokenType::StringLiteral(sym), sym, span));
                self.pos += 1;
                continue;
            }

            // Check for character literal marker
            if word.starts_with("\x00CHAR:") {
                let content = &word[6..]; // Skip the marker prefix
                let sym = self.interner.intern(content);
                let span = Span::new(word_start, word_end);
                tokens.push(Token::new(TokenType::CharLiteral(sym), sym, span));
                self.pos += 1;
                continue;
            }

            let kind = self.classify_with_lookahead(&word);
            let lexeme = self.interner.intern(&word);
            let span = Span::new(word_start, word_end);
            tokens.push(Token::new(kind, lexeme, span));

            if let Some(punct) = trailing_punct {
                if punct == '\'' {
                    if let Some(next_item) = self.words.get(self.pos + 1) {
                        if next_item.word.to_lowercase() == "s" {
                            let poss_lexeme = self.interner.intern("'s");
                            let poss_start = punct_pos.unwrap_or(word_end);
                            let poss_end = next_item.end;
                            tokens.push(Token::new(TokenType::Possessive, poss_lexeme, Span::new(poss_start, poss_end)));
                            self.pos += 1;
                            if let Some(s_punct) = next_item.trailing_punct {
                                let kind = match s_punct {
                                    '(' => TokenType::LParen,
                                    ')' => TokenType::RParen,
                                    '[' => TokenType::LBracket,
                                    ']' => TokenType::RBracket,
                                    ',' => TokenType::Comma,
                                    ':' => TokenType::Colon,
                                    '.' | '?' => TokenType::Period,
                                    '!' => TokenType::Exclamation,
                                    '+' => TokenType::Plus,
                                    '-' => TokenType::Minus,
                                    '*' => TokenType::Star,
                                    '/' => TokenType::Slash,
                                    '%' => TokenType::Percent,
                                    '<' => TokenType::Lt,
                                    '>' => TokenType::Gt,
                                    _ => {
                                        self.pos += 1;
                                        continue;
                                    }
                                };
                                let s_punct_pos = next_item.punct_pos.unwrap_or(next_item.end);
                                let lexeme = self.interner.intern(&s_punct.to_string());
                                tokens.push(Token::new(kind, lexeme, Span::new(s_punct_pos, s_punct_pos + 1)));
                            }
                            self.pos += 1;
                            continue;
                        }
                    }
                    self.pos += 1;
                    continue;
                }

                let kind = match punct {
                    '(' => TokenType::LParen,
                    ')' => TokenType::RParen,
                    '[' => TokenType::LBracket,
                    ']' => TokenType::RBracket,
                    ',' => TokenType::Comma,
                    ':' => TokenType::Colon,
                    '.' | '?' => {
                        self.in_let_context = false;
                        TokenType::Period
                    }
                    '!' => TokenType::Exclamation,
                    '+' => TokenType::Plus,
                    '-' => TokenType::Minus,
                    '*' => TokenType::Star,
                    '/' => TokenType::Slash,
                    '%' => TokenType::Percent,
                    '<' => TokenType::Lt,
                    '>' => TokenType::Gt,
                    _ => {
                        self.pos += 1;
                        continue;
                    }
                };
                let p_start = punct_pos.unwrap_or(word_end);
                let lexeme = self.interner.intern(&punct.to_string());
                tokens.push(Token::new(kind, lexeme, Span::new(p_start, p_start + 1)));
            }

            self.pos += 1;
        }

        let eof_lexeme = self.interner.intern("");
        let eof_span = Span::new(self.input_len, self.input_len);
        tokens.push(Token::new(TokenType::EOF, eof_lexeme, eof_span));

        self.insert_indentation_tokens(tokens)
    }

    /// Insert Indent/Dedent tokens using LineLexer's two-pass architecture (Spec §2.5.2).
    ///
    /// Phase 1: LineLexer determines the structural layout (where indents/dedents occur)
    /// Phase 2: We correlate these with word token positions
    fn insert_indentation_tokens(&mut self, tokens: Vec<Token>) -> Vec<Token> {
        let mut result = Vec::new();
        let empty_sym = self.interner.intern("");

        // Phase 1: Run LineLexer to determine structural positions
        let line_lexer = LineLexer::new(&self.source);
        let line_tokens: Vec<LineToken> = line_lexer.collect();

        // Build a list of (byte_position, is_indent) for structural tokens
        // Position is where the NEXT Content starts after the Indent/Dedent
        let mut structural_events: Vec<(usize, bool)> = Vec::new(); // (byte_pos, true=Indent, false=Dedent)
        let mut pending_indents = 0usize;
        let mut pending_dedents = 0usize;

        for line_token in &line_tokens {
            match line_token {
                LineToken::Indent => {
                    pending_indents += 1;
                }
                LineToken::Dedent => {
                    pending_dedents += 1;
                }
                LineToken::Content { start, .. } => {
                    // Emit pending dedents first (they come BEFORE the content)
                    for _ in 0..pending_dedents {
                        structural_events.push((*start, false)); // false = Dedent
                    }
                    pending_dedents = 0;

                    // Emit pending indents (they also come BEFORE the content)
                    for _ in 0..pending_indents {
                        structural_events.push((*start, true)); // true = Indent
                    }
                    pending_indents = 0;
                }
                LineToken::Newline => {}
            }
        }

        // Handle any remaining dedents at EOF
        for _ in 0..pending_dedents {
            structural_events.push((self.input_len, false));
        }

        // Sort events by position, with dedents before indents at same position
        structural_events.sort_by(|a, b| {
            if a.0 != b.0 {
                a.0.cmp(&b.0)
            } else {
                // Dedents (false) before Indents (true) at same position
                a.1.cmp(&b.1)
            }
        });

        // Phase 2: Insert structural tokens at the right positions
        // Strategy: For each word token, check if any structural events should be inserted
        // before it (based on byte position)

        let mut event_idx = 0;
        let mut last_colon_pos: Option<usize> = None;

        for token in tokens.iter() {
            let token_start = token.span.start;

            // Insert any structural tokens that should come BEFORE this token
            while event_idx < structural_events.len() {
                let (event_pos, is_indent) = structural_events[event_idx];

                // Insert structural tokens before this token if the event position <= token start
                if event_pos <= token_start {
                    let span = if is_indent {
                        // Indent is inserted after the preceding Colon
                        Span::new(last_colon_pos.unwrap_or(event_pos), last_colon_pos.unwrap_or(event_pos))
                    } else {
                        Span::new(event_pos, event_pos)
                    };
                    let kind = if is_indent { TokenType::Indent } else { TokenType::Dedent };
                    result.push(Token::new(kind, empty_sym, span));
                    event_idx += 1;
                } else {
                    break;
                }
            }

            result.push(token.clone());

            // Track colon positions for Indent span calculation
            if token.kind == TokenType::Colon && self.is_end_of_line(token.span.end) {
                last_colon_pos = Some(token.span.end);
            }
        }

        // Insert any remaining structural tokens (typically Dedents at EOF)
        while event_idx < structural_events.len() {
            let (event_pos, is_indent) = structural_events[event_idx];
            let span = Span::new(event_pos, event_pos);
            let kind = if is_indent { TokenType::Indent } else { TokenType::Dedent };
            result.push(Token::new(kind, empty_sym, span));
            event_idx += 1;
        }

        // Ensure EOF is at the end
        let eof_pos = result.iter().position(|t| t.kind == TokenType::EOF);
        if let Some(pos) = eof_pos {
            let eof = result.remove(pos);
            result.push(eof);
        }

        result
    }

    /// Check if position is at end of line (only whitespace until newline)
    fn is_end_of_line(&self, from_pos: usize) -> bool {
        let bytes = self.source.as_bytes();
        let mut pos = from_pos;
        while pos < bytes.len() {
            match bytes[pos] {
                b' ' | b'\t' => pos += 1,
                b'\n' => return true,
                _ => return false,
            }
        }
        true // End of input is also end of line
    }

    fn measure_next_line_indent(&self, from_pos: usize) -> Option<usize> {
        let bytes = self.source.as_bytes();
        let mut pos = from_pos;

        while pos < bytes.len() && bytes[pos] != b'\n' {
            pos += 1;
        }

        if pos >= bytes.len() {
            return None;
        }

        pos += 1;

        let mut indent = 0;
        while pos < bytes.len() {
            match bytes[pos] {
                b' ' => indent += 1,
                b'\t' => indent += 4,
                b'\n' => {
                    indent = 0;
                }
                _ => break,
            }
            pos += 1;
        }

        if pos >= bytes.len() {
            return None;
        }

        Some(indent)
    }

    fn word_to_number(word: &str) -> Option<u32> {
        lexicon::word_to_number(&word.to_lowercase())
    }

    fn is_numeric_literal(word: &str) -> bool {
        if word.is_empty() {
            return false;
        }
        let chars: Vec<char> = word.chars().collect();
        let first = chars[0];
        if first.is_ascii_digit() {
            // Numeric literal: starts with digit (may have underscore separators like 1_000)
            return true;
        }
        // Symbolic numbers: only recognize known mathematical symbols
        // (aleph, omega, beth) followed by underscore and digits
        if let Some(underscore_pos) = word.rfind('_') {
            let before_underscore = &word[..underscore_pos];
            let after_underscore = &word[underscore_pos + 1..];
            // Must be a known mathematical symbol prefix AND digits after underscore
            let is_math_symbol = matches!(
                before_underscore.to_lowercase().as_str(),
                "aleph" | "omega" | "beth"
            );
            if is_math_symbol
                && !after_underscore.is_empty()
                && after_underscore.chars().all(|c| c.is_ascii_digit())
            {
                return true;
            }
        }
        false
    }

    fn classify_with_lookahead(&mut self, word: &str) -> TokenType {
        // Handle block headers (##Theorem, ##Main, etc.)
        if word.starts_with("##") {
            let block_name = &word[2..];
            let block_type = match block_name.to_lowercase().as_str() {
                "theorem" => BlockType::Theorem,
                "main" => BlockType::Main,
                "definition" => BlockType::Definition,
                "proof" => BlockType::Proof,
                "example" => BlockType::Example,
                "logic" => BlockType::Logic,
                "note" => BlockType::Note,
                "to" => BlockType::Function,  // Phase 32: ## To blocks
                "a" | "an" => BlockType::TypeDef,  // Inline type definitions: ## A Point has:
                "policy" => BlockType::Policy,  // Phase 50: Security policy definitions
                _ => BlockType::Note, // Default unknown block types to Note
            };

            // Update lexer mode based on block type
            self.mode = match block_type {
                BlockType::Main | BlockType::Function => LexerMode::Imperative,
                _ => LexerMode::Declarative,
            };

            return TokenType::BlockHeader { block_type };
        }

        let lower = word.to_lowercase();

        if lower == "each" && self.peek_sequence(&["other"]) {
            self.consume_words(1);
            return TokenType::Reciprocal;
        }

        if lower == "to" {
            if let Some(next) = self.peek_word(1) {
                if self.is_verb_like(next) {
                    return TokenType::To;
                }
            }
            let sym = self.interner.intern("to");
            return TokenType::Preposition(sym);
        }

        if lower == "at" {
            if let Some(next) = self.peek_word(1) {
                let next_lower = next.to_lowercase();
                if next_lower == "least" {
                    if let Some(num_word) = self.peek_word(2) {
                        if let Some(n) = Self::word_to_number(num_word) {
                            self.consume_words(2);
                            return TokenType::AtLeast(n);
                        }
                    }
                }
                if next_lower == "most" {
                    if let Some(num_word) = self.peek_word(2) {
                        if let Some(n) = Self::word_to_number(num_word) {
                            self.consume_words(2);
                            return TokenType::AtMost(n);
                        }
                    }
                }
            }
        }

        if let Some(n) = Self::word_to_number(&lower) {
            return TokenType::Cardinal(n);
        }

        if Self::is_numeric_literal(word) {
            let sym = self.interner.intern(word);
            return TokenType::Number(sym);
        }

        if lower == "if" && self.peek_sequence(&["and", "only", "if"]) {
            self.consume_words(3);
            return TokenType::Iff;
        }

        if lower == "is" {
            if self.peek_sequence(&["equal", "to"]) {
                self.consume_words(2);
                return TokenType::Identity;
            }
            if self.peek_sequence(&["identical", "to"]) {
                self.consume_words(2);
                return TokenType::Identity;
            }
        }

        if (lower == "a" || lower == "an") && word.chars().next().unwrap().is_uppercase() {
            // Capitalized "A" or "An" - disambiguate article vs proper name
            // Heuristic: articles are followed by nouns/adjectives, not verbs or keywords
            if let Some(next) = self.peek_word(1) {
                let next_lower = next.to_lowercase();
                let next_starts_lowercase = next.chars().next().map(|c| c.is_lowercase()).unwrap_or(false);

                // If followed by logical keyword, treat as proper name (propositional variable)
                if matches!(next_lower.as_str(), "if" | "and" | "or" | "implies" | "iff") {
                    let sym = self.interner.intern(word);
                    return TokenType::ProperName(sym);
                }

                // If next word is a verb (like "has", "is", "ran"), A is likely a name
                // Exception: gerunds (like "running") can follow articles
                // Exception: words in disambiguation_not_verbs (like "red") are not verbs
                let is_verb = self.lexicon.lookup_verb(&next_lower).is_some()
                    && !lexicon::is_disambiguation_not_verb(&next_lower);
                let is_gerund = next_lower.ends_with("ing");
                if is_verb && !is_gerund {
                    let sym = self.interner.intern(word);
                    return TokenType::ProperName(sym);
                }

                // Definition pattern: "A [TypeName] is a..." or "A [TypeName] has:" - treat A as article
                // even when TypeName is capitalized and unknown
                if let Some(third) = self.peek_word(2) {
                    let third_lower = third.to_lowercase();
                    // Phase 31: Added "has" for struct definitions
                    if third_lower == "is" || third_lower == "are" || third_lower == "has" {
                        return TokenType::Article(Definiteness::Indefinite);
                    }
                }

                // It's an article if next word is:
                // - A known noun or adjective, or
                // - Lowercase (likely a common word we don't recognize)
                let is_content_word = self.is_noun_like(&next_lower) || self.is_adjective_like(&next_lower);
                if is_content_word || next_starts_lowercase {
                    return TokenType::Article(Definiteness::Indefinite);
                }
            }
            let sym = self.interner.intern(word);
            return TokenType::ProperName(sym);
        }

        self.classify_word(word)
    }

    fn is_noun_like(&self, word: &str) -> bool {
        if lexicon::is_noun_pattern(word) || lexicon::is_common_noun(word) {
            return true;
        }
        if word.ends_with("er") || word.ends_with("ian") || word.ends_with("ist") {
            return true;
        }
        false
    }

    fn is_adjective_like(&self, word: &str) -> bool {
        lexicon::is_adjective(word) || lexicon::is_non_intersective(word)
    }

    fn classify_word(&mut self, word: &str) -> TokenType {
        let lower = word.to_lowercase();
        let first_char = word.chars().next().unwrap();

        // Disambiguate "that" as determiner vs complementizer
        // "that dog" → Article(Distal), "I know that he ran" → That (complementizer)
        if lower == "that" {
            if let Some(next) = self.peek_word(1) {
                let next_lower = next.to_lowercase();
                if self.is_noun_like(&next_lower) || self.is_adjective_like(&next_lower) {
                    return TokenType::Article(Definiteness::Distal);
                }
            }
        }

        // Phase 38: Arrow token for return type syntax
        if word == "->" {
            return TokenType::Arrow;
        }

        // Grand Challenge: Comparison operator tokens
        if word == "<=" {
            return TokenType::LtEq;
        }
        if word == ">=" {
            return TokenType::GtEq;
        }
        if word == "==" {
            return TokenType::EqEq;
        }
        if word == "!=" {
            return TokenType::NotEq;
        }
        if word == "<" {
            return TokenType::Lt;
        }
        if word == ">" {
            return TokenType::Gt;
        }

        if let Some(kind) = lexicon::lookup_keyword(&lower) {
            return kind;
        }

        if let Some(kind) = lexicon::lookup_pronoun(&lower) {
            return kind;
        }

        if let Some(def) = lexicon::lookup_article(&lower) {
            return TokenType::Article(def);
        }

        if let Some(time) = lexicon::lookup_auxiliary(&lower) {
            return TokenType::Auxiliary(time);
        }

        // Handle imperative keywords that might conflict with prepositions
        match lower.as_str() {
            "call" => return TokenType::Call,
            "in" if self.mode == LexerMode::Imperative => return TokenType::In,
            // Phase 8.5: Zone keywords (must come before is_preposition check)
            "inside" if self.mode == LexerMode::Imperative => return TokenType::Inside,
            // Phase 48: "at" for chunk access (must come before is_preposition check)
            "at" if self.mode == LexerMode::Imperative => return TokenType::At,
            // Phase 54: "into" for pipe send (must come before is_preposition check)
            "into" if self.mode == LexerMode::Imperative => return TokenType::Into,
            _ => {}
        }

        if lexicon::is_preposition(&lower) {
            let sym = self.interner.intern(&lower);
            return TokenType::Preposition(sym);
        }

        match lower.as_str() {
            "equals" => return TokenType::Equals,
            "item" => return TokenType::Item,
            "items" => return TokenType::Items,
            "let" => {
                self.in_let_context = true;
                return TokenType::Let;
            }
            "set" => {
                // Check if "set" is used as a type (followed by "of") - "Set of Int"
                // This takes priority over the assignment keyword
                if self.peek_word(1).map_or(false, |w| w.to_lowercase() == "of") {
                    // It's a type like "Set of Int" - don't return keyword, let it be a noun
                } else if self.mode == LexerMode::Imperative {
                    // In Imperative mode, treat "set" as the assignment keyword
                    return TokenType::Set;
                } else {
                    // Phase 31: In Declarative mode, check positions 2-5 for "to"
                    // (handles field access like "set p's x to")
                    for offset in 2..=5 {
                        if self.peek_word(offset).map_or(false, |w| w.to_lowercase() == "to") {
                            return TokenType::Set;
                        }
                    }
                }
            }
            "return" => return TokenType::Return,
            "be" if self.in_let_context => {
                self.in_let_context = false;
                return TokenType::Be;
            }
            "while" => return TokenType::While,
            "assert" => return TokenType::Assert,
            "trust" => return TokenType::Trust,  // Phase 35: Trust statement
            "check" => return TokenType::Check,  // Phase 50: Security check
            // Phase 51: P2P Networking keywords (Imperative mode only)
            "listen" if self.mode == LexerMode::Imperative => return TokenType::Listen,
            "connect" if self.mode == LexerMode::Imperative => return TokenType::NetConnect,
            "sleep" if self.mode == LexerMode::Imperative => return TokenType::Sleep,
            // Phase 52: GossipSub keywords (Imperative mode only)
            "sync" if self.mode == LexerMode::Imperative => return TokenType::Sync,
            // Phase 53: Persistence keywords
            "mount" if self.mode == LexerMode::Imperative => return TokenType::Mount,
            "persistent" => return TokenType::Persistent,  // Works in type expressions
            "combined" if self.mode == LexerMode::Imperative => return TokenType::Combined,
            // Phase 54: Go-like Concurrency keywords (Imperative mode only)
            // Note: "first" and "after" are NOT keywords - they're checked via lookahead in parser
            // to avoid conflicting with their use as variable names
            "launch" if self.mode == LexerMode::Imperative => return TokenType::Launch,
            "task" if self.mode == LexerMode::Imperative => return TokenType::Task,
            "pipe" if self.mode == LexerMode::Imperative => return TokenType::Pipe,
            "receive" if self.mode == LexerMode::Imperative => return TokenType::Receive,
            "stop" if self.mode == LexerMode::Imperative => return TokenType::Stop,
            "try" if self.mode == LexerMode::Imperative => return TokenType::Try,
            "into" if self.mode == LexerMode::Imperative => return TokenType::Into,
            "native" => return TokenType::Native,  // Phase 38: Native function modifier
            "from" => return TokenType::From,  // Phase 36: Module qualification
            "otherwise" => return TokenType::Otherwise,
            // Phase 33: Sum type definition (Declarative mode only - for enum "either...or...")
            "either" if self.mode == LexerMode::Declarative => return TokenType::Either,
            // Phase 33: Pattern matching statement
            "inspect" if self.mode == LexerMode::Imperative => return TokenType::Inspect,
            // Phase 31: Constructor keyword (Imperative mode only)
            "new" if self.mode == LexerMode::Imperative => return TokenType::New,
            // Only emit Give/Show as keywords in Imperative mode
            // In Declarative mode, they fall through to lexicon lookup as verbs
            "give" if self.mode == LexerMode::Imperative => return TokenType::Give,
            "show" if self.mode == LexerMode::Imperative => return TokenType::Show,
            // Phase 43D: Collection operation keywords (Imperative mode only)
            "push" if self.mode == LexerMode::Imperative => return TokenType::Push,
            "pop" if self.mode == LexerMode::Imperative => return TokenType::Pop,
            "copy" if self.mode == LexerMode::Imperative => return TokenType::Copy,
            "through" if self.mode == LexerMode::Imperative => return TokenType::Through,
            "length" if self.mode == LexerMode::Imperative => return TokenType::Length,
            "at" if self.mode == LexerMode::Imperative => return TokenType::At,
            // Set operation keywords (Imperative mode only)
            "add" if self.mode == LexerMode::Imperative => return TokenType::Add,
            "remove" if self.mode == LexerMode::Imperative => return TokenType::Remove,
            "contains" if self.mode == LexerMode::Imperative => return TokenType::Contains,
            "union" if self.mode == LexerMode::Imperative => return TokenType::Union,
            "intersection" if self.mode == LexerMode::Imperative => return TokenType::Intersection,
            // Phase 8.5: Zone keywords (Imperative mode only)
            "inside" if self.mode == LexerMode::Imperative => return TokenType::Inside,
            "zone" if self.mode == LexerMode::Imperative => return TokenType::Zone,
            "called" if self.mode == LexerMode::Imperative => return TokenType::Called,
            "size" if self.mode == LexerMode::Imperative => return TokenType::Size,
            "mapped" if self.mode == LexerMode::Imperative => return TokenType::Mapped,
            // Phase 9: Structured Concurrency keywords (Imperative mode only)
            "attempt" if self.mode == LexerMode::Imperative => return TokenType::Attempt,
            "following" if self.mode == LexerMode::Imperative => return TokenType::Following,
            "simultaneously" if self.mode == LexerMode::Imperative => return TokenType::Simultaneously,
            // Phase 10: IO keywords (Imperative mode only)
            "read" if self.mode == LexerMode::Imperative => return TokenType::Read,
            "write" if self.mode == LexerMode::Imperative => return TokenType::Write,
            "console" if self.mode == LexerMode::Imperative => return TokenType::Console,
            "file" if self.mode == LexerMode::Imperative => return TokenType::File,
            // Phase 46: Agent System keywords (Imperative mode only)
            "spawn" if self.mode == LexerMode::Imperative => return TokenType::Spawn,
            "send" if self.mode == LexerMode::Imperative => return TokenType::Send,
            "await" if self.mode == LexerMode::Imperative => return TokenType::Await,
            // Phase 47: Serialization keyword (works in Definition blocks too)
            "portable" => return TokenType::Portable,
            // Phase 48: Sipping Protocol keywords (Imperative mode only)
            "manifest" if self.mode == LexerMode::Imperative => return TokenType::Manifest,
            "chunk" if self.mode == LexerMode::Imperative => return TokenType::Chunk,
            // Phase 49: CRDT keywords
            "shared" => return TokenType::Shared,  // Works in Definition blocks like Portable
            "merge" if self.mode == LexerMode::Imperative => return TokenType::Merge,
            "increase" if self.mode == LexerMode::Imperative => return TokenType::Increase,
            // Phase 49b: Extended CRDT keywords (Wave 5)
            "decrease" if self.mode == LexerMode::Imperative => return TokenType::Decrease,
            "append" if self.mode == LexerMode::Imperative => return TokenType::Append,
            "resolve" if self.mode == LexerMode::Imperative => return TokenType::Resolve,
            "values" if self.mode == LexerMode::Imperative => return TokenType::Values,
            // Type keywords (work in both modes like "Shared"):
            "tally" => return TokenType::Tally,
            "sharedset" => return TokenType::SharedSet,
            "sharedsequence" => return TokenType::SharedSequence,
            "collaborativesequence" => return TokenType::CollaborativeSequence,
            "sharedmap" => return TokenType::SharedMap,
            "divergent" => return TokenType::Divergent,
            "removewins" => return TokenType::RemoveWins,
            "addwins" => return TokenType::AddWins,
            "yata" => return TokenType::YATA,
            "if" => return TokenType::If,
            "only" => return TokenType::Focus(FocusKind::Only),
            "even" => return TokenType::Focus(FocusKind::Even),
            "just" if self.peek_word(1).map_or(false, |w| {
                !self.is_verb_like(w) || w.to_lowercase() == "john" || w.chars().next().map_or(false, |c| c.is_uppercase())
            }) => return TokenType::Focus(FocusKind::Just),
            "much" => return TokenType::Measure(MeasureKind::Much),
            "little" => return TokenType::Measure(MeasureKind::Little),
            _ => {}
        }

        if lexicon::is_scopal_adverb(&lower) {
            let sym = self.interner.intern(&Self::capitalize(&lower));
            return TokenType::ScopalAdverb(sym);
        }

        if lexicon::is_temporal_adverb(&lower) {
            let sym = self.interner.intern(&Self::capitalize(&lower));
            return TokenType::TemporalAdverb(sym);
        }

        if lexicon::is_non_intersective(&lower) {
            let sym = self.interner.intern(&Self::capitalize(&lower));
            return TokenType::NonIntersectiveAdjective(sym);
        }

        if lexicon::is_adverb(&lower) {
            let sym = self.interner.intern(&Self::capitalize(&lower));
            return TokenType::Adverb(sym);
        }
        if lower.ends_with("ly") && !lexicon::is_not_adverb(&lower) && lower.len() > 4 {
            let sym = self.interner.intern(&Self::capitalize(&lower));
            return TokenType::Adverb(sym);
        }

        if let Some(base) = self.try_parse_superlative(&lower) {
            let sym = self.interner.intern(&base);
            return TokenType::Superlative(sym);
        }

        // Phase 35: Handle irregular comparatives (less, more, better, worse)
        let irregular_comparative = match lower.as_str() {
            "less" => Some("Little"),
            "more" => Some("Much"),
            "better" => Some("Good"),
            "worse" => Some("Bad"),
            _ => None,
        };
        if let Some(base) = irregular_comparative {
            let sym = self.interner.intern(base);
            return TokenType::Comparative(sym);
        }

        if let Some(base) = self.try_parse_comparative(&lower) {
            let sym = self.interner.intern(&base);
            return TokenType::Comparative(sym);
        }

        if lexicon::is_performative(&lower) {
            let sym = self.interner.intern(&Self::capitalize(&lower));
            return TokenType::Performative(sym);
        }

        if lexicon::is_base_verb_early(&lower) {
            let sym = self.interner.intern(&Self::capitalize(&lower));
            let class = lexicon::lookup_verb_class(&lower);
            return TokenType::Verb {
                lemma: sym,
                time: Time::Present,
                aspect: Aspect::Simple,
                class,
            };
        }

        // Check for gerunds/progressive verbs BEFORE ProperName check
        // "Running" at start of sentence should be Verb, not ProperName
        if lower.ends_with("ing") && lower.len() > 4 {
            if let Some(entry) = self.lexicon.lookup_verb(&lower) {
                let sym = self.interner.intern(&entry.lemma);
                return TokenType::Verb {
                    lemma: sym,
                    time: entry.time,
                    aspect: entry.aspect,
                    class: entry.class,
                };
            }
        }

        if first_char.is_uppercase() {
            let sym = self.interner.intern(word);
            return TokenType::ProperName(sym);
        }

        let verb_entry = self.lexicon.lookup_verb(&lower);
        let is_noun = lexicon::is_common_noun(&lower);
        let is_adj = self.is_adjective_like(&lower);
        let is_disambiguated = lexicon::is_disambiguation_not_verb(&lower);

        // Ambiguous: word is Verb AND (Noun OR Adjective), not disambiguated
        if verb_entry.is_some() && (is_noun || is_adj) && !is_disambiguated {
            let entry = verb_entry.unwrap();
            let verb_token = TokenType::Verb {
                lemma: self.interner.intern(&entry.lemma),
                time: entry.time,
                aspect: entry.aspect,
                class: entry.class,
            };

            let mut alternatives = Vec::new();
            if is_noun {
                alternatives.push(TokenType::Noun(self.interner.intern(word)));
            }
            if is_adj {
                alternatives.push(TokenType::Adjective(self.interner.intern(word)));
            }

            return TokenType::Ambiguous {
                primary: Box::new(verb_token),
                alternatives,
            };
        }

        // Disambiguated to noun/adjective (not verb)
        if let Some(_) = &verb_entry {
            if is_disambiguated {
                let sym = self.interner.intern(word);
                if is_noun {
                    return TokenType::Noun(sym);
                }
                return TokenType::Adjective(sym);
            }
        }

        // Pure verb
        if let Some(entry) = verb_entry {
            let sym = self.interner.intern(&entry.lemma);
            return TokenType::Verb {
                lemma: sym,
                time: entry.time,
                aspect: entry.aspect,
                class: entry.class,
            };
        }

        // Pure noun
        if is_noun {
            let sym = self.interner.intern(word);
            return TokenType::Noun(sym);
        }

        if lexicon::is_base_verb(&lower) {
            let sym = self.interner.intern(&Self::capitalize(&lower));
            let class = lexicon::lookup_verb_class(&lower);
            return TokenType::Verb {
                lemma: sym,
                time: Time::Present,
                aspect: Aspect::Simple,
                class,
            };
        }

        if lower.ends_with("ian")
            || lower.ends_with("er")
            || lower == "logic"
            || lower == "time"
            || lower == "men"
            || lower == "book"
            || lower == "house"
            || lower == "code"
            || lower == "user"
        {
            let sym = self.interner.intern(word);
            return TokenType::Noun(sym);
        }

        if lexicon::is_particle(&lower) {
            let sym = self.interner.intern(&lower);
            return TokenType::Particle(sym);
        }

        let sym = self.interner.intern(word);
        TokenType::Adjective(sym)
    }

    fn capitalize(s: &str) -> String {
        let mut chars = s.chars();
        match chars.next() {
            None => String::new(),
            Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
        }
    }

    pub fn is_collective_verb(lemma: &str) -> bool {
        lexicon::is_collective_verb(&lemma.to_lowercase())
    }

    pub fn is_mixed_verb(lemma: &str) -> bool {
        lexicon::is_mixed_verb(&lemma.to_lowercase())
    }

    pub fn is_ditransitive_verb(lemma: &str) -> bool {
        lexicon::is_ditransitive_verb(&lemma.to_lowercase())
    }

    fn is_verb_like(&self, word: &str) -> bool {
        let lower = word.to_lowercase();
        if lexicon::is_infinitive_verb(&lower) {
            return true;
        }
        if let Some(entry) = self.lexicon.lookup_verb(&lower) {
            return entry.lemma.len() > 0;
        }
        false
    }

    pub fn is_subject_control_verb(lemma: &str) -> bool {
        lexicon::is_subject_control_verb(&lemma.to_lowercase())
    }

    pub fn is_raising_verb(lemma: &str) -> bool {
        lexicon::is_raising_verb(&lemma.to_lowercase())
    }

    pub fn is_object_control_verb(lemma: &str) -> bool {
        lexicon::is_object_control_verb(&lemma.to_lowercase())
    }

    pub fn is_weather_verb(lemma: &str) -> bool {
        matches!(
            lemma.to_lowercase().as_str(),
            "rain" | "snow" | "hail" | "thunder" | "pour"
        )
    }

    fn try_parse_superlative(&self, word: &str) -> Option<String> {
        if !word.ends_with("est") || word.len() < 5 {
            return None;
        }

        let base = &word[..word.len() - 3];

        if base.len() >= 2 {
            let chars: Vec<char> = base.chars().collect();
            let last = chars[chars.len() - 1];
            let second_last = chars[chars.len() - 2];
            if last == second_last && !"aeiou".contains(last) {
                let stem = &base[..base.len() - 1];
                if lexicon::is_gradable_adjective(stem) {
                    return Some(Self::capitalize(stem));
                }
            }
        }

        if base.ends_with("i") {
            let stem = format!("{}y", &base[..base.len() - 1]);
            if lexicon::is_gradable_adjective(&stem) {
                return Some(Self::capitalize(&stem));
            }
        }

        if lexicon::is_gradable_adjective(base) {
            return Some(Self::capitalize(base));
        }

        None
    }

    fn try_parse_comparative(&self, word: &str) -> Option<String> {
        if !word.ends_with("er") || word.len() < 4 {
            return None;
        }

        let base = &word[..word.len() - 2];

        if base.len() >= 2 {
            let chars: Vec<char> = base.chars().collect();
            let last = chars[chars.len() - 1];
            let second_last = chars[chars.len() - 2];
            if last == second_last && !"aeiou".contains(last) {
                let stem = &base[..base.len() - 1];
                if lexicon::is_gradable_adjective(stem) {
                    return Some(Self::capitalize(stem));
                }
            }
        }

        if base.ends_with("i") {
            let stem = format!("{}y", &base[..base.len() - 1]);
            if lexicon::is_gradable_adjective(&stem) {
                return Some(Self::capitalize(&stem));
            }
        }

        if lexicon::is_gradable_adjective(base) {
            return Some(Self::capitalize(base));
        }

        None
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn lexer_handles_apostrophe() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("it's raining", &mut interner);
        let tokens = lexer.tokenize();
        assert!(!tokens.is_empty());
    }

    #[test]
    fn lexer_handles_question_mark() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("Is it raining?", &mut interner);
        let tokens = lexer.tokenize();
        assert!(!tokens.is_empty());
    }

    #[test]
    fn ring_is_not_verb() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("ring", &mut interner);
        let tokens = lexer.tokenize();
        assert!(matches!(tokens[0].kind, TokenType::Noun(_)));
    }

    #[test]
    fn debug_that_token() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("The cat that runs", &mut interner);
        let tokens = lexer.tokenize();
        for (i, t) in tokens.iter().enumerate() {
            let lex = interner.resolve(t.lexeme);
            eprintln!("Token[{}]: {:?} -> {:?}", i, lex, t.kind);
        }
        let that_token = tokens.iter().find(|t| interner.resolve(t.lexeme) == "that");
        if let Some(t) = that_token {
            // Verify discriminant comparison works
            let check = std::mem::discriminant(&t.kind) == std::mem::discriminant(&TokenType::That);
            eprintln!("Discriminant check for That: {}", check);
            assert!(matches!(t.kind, TokenType::That), "'that' should be TokenType::That, got {:?}", t.kind);
        } else {
            panic!("No 'that' token found");
        }
    }

    #[test]
    fn bus_is_not_verb() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("bus", &mut interner);
        let tokens = lexer.tokenize();
        assert!(matches!(tokens[0].kind, TokenType::Noun(_)));
    }

    #[test]
    fn lowercase_a_is_article() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("a car", &mut interner);
        let tokens = lexer.tokenize();
        for (i, t) in tokens.iter().enumerate() {
            let lex = interner.resolve(t.lexeme);
            eprintln!("Token[{}]: {:?} -> {:?}", i, lex, t.kind);
        }
        assert_eq!(tokens[0].kind, TokenType::Article(Definiteness::Indefinite));
        assert!(matches!(tokens[1].kind, TokenType::Noun(_)), "Expected Noun, got {:?}", tokens[1].kind);
    }

    #[test]
    fn open_is_ambiguous() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("open", &mut interner);
        let tokens = lexer.tokenize();

        if let TokenType::Ambiguous { primary, alternatives } = &tokens[0].kind {
            assert!(matches!(**primary, TokenType::Verb { .. }), "Primary should be Verb");
            assert!(alternatives.iter().any(|t| matches!(t, TokenType::Adjective(_))),
                "Should have Adjective alternative");
        } else {
            panic!("Expected Ambiguous token for 'open', got {:?}", tokens[0].kind);
        }
    }

    #[test]
    fn basic_tokenization() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("All men are mortal.", &mut interner);
        let tokens = lexer.tokenize();
        assert_eq!(tokens[0].kind, TokenType::All);
        assert!(matches!(tokens[1].kind, TokenType::Noun(_)));
        assert_eq!(tokens[2].kind, TokenType::Are);
    }

    #[test]
    fn iff_tokenizes_as_single_token() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("A if and only if B", &mut interner);
        let tokens = lexer.tokenize();
        assert!(
            tokens.iter().any(|t| t.kind == TokenType::Iff),
            "should contain Iff token: got {:?}",
            tokens
        );
    }

    #[test]
    fn is_equal_to_tokenizes_as_identity() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("Socrates is equal to Socrates", &mut interner);
        let tokens = lexer.tokenize();
        assert!(
            tokens.iter().any(|t| t.kind == TokenType::Identity),
            "should contain Identity token: got {:?}",
            tokens
        );
    }

    #[test]
    fn is_identical_to_tokenizes_as_identity() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("Clark is identical to Superman", &mut interner);
        let tokens = lexer.tokenize();
        assert!(
            tokens.iter().any(|t| t.kind == TokenType::Identity),
            "should contain Identity token: got {:?}",
            tokens
        );
    }

    #[test]
    fn itself_tokenizes_as_reflexive() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("John loves itself", &mut interner);
        let tokens = lexer.tokenize();
        assert!(
            tokens.iter().any(|t| t.kind == TokenType::Reflexive),
            "should contain Reflexive token: got {:?}",
            tokens
        );
    }

    #[test]
    fn himself_tokenizes_as_reflexive() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("John sees himself", &mut interner);
        let tokens = lexer.tokenize();
        assert!(
            tokens.iter().any(|t| t.kind == TokenType::Reflexive),
            "should contain Reflexive token: got {:?}",
            tokens
        );
    }

    #[test]
    fn to_stay_tokenizes_correctly() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("to stay", &mut interner);
        let tokens = lexer.tokenize();
        assert!(
            tokens.iter().any(|t| t.kind == TokenType::To),
            "should contain To token: got {:?}",
            tokens
        );
        assert!(
            tokens.iter().any(|t| matches!(t.kind, TokenType::Verb { .. })),
            "should contain Verb token for stay: got {:?}",
            tokens
        );
    }

    #[test]
    fn possessive_apostrophe_s() {
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("John's dog", &mut interner);
        let tokens = lexer.tokenize();
        assert!(
            tokens.iter().any(|t| t.kind == TokenType::Possessive),
            "should contain Possessive token: got {:?}",
            tokens
        );
        assert!(
            tokens.iter().any(|t| matches!(&t.kind, TokenType::ProperName(_))),
            "should have John as proper name: got {:?}",
            tokens
        );
    }

    #[test]
    fn lexer_produces_valid_spans() {
        let input = "All men are mortal.";
        let mut interner = Interner::new();
        let mut lexer = Lexer::new(input, &mut interner);
        let tokens = lexer.tokenize();

        // "All" at 0..3
        assert_eq!(tokens[0].span.start, 0);
        assert_eq!(tokens[0].span.end, 3);
        assert_eq!(&input[tokens[0].span.start..tokens[0].span.end], "All");

        // "men" at 4..7
        assert_eq!(tokens[1].span.start, 4);
        assert_eq!(tokens[1].span.end, 7);
        assert_eq!(&input[tokens[1].span.start..tokens[1].span.end], "men");

        // "are" at 8..11
        assert_eq!(tokens[2].span.start, 8);
        assert_eq!(tokens[2].span.end, 11);
        assert_eq!(&input[tokens[2].span.start..tokens[2].span.end], "are");

        // "mortal" at 12..18
        assert_eq!(tokens[3].span.start, 12);
        assert_eq!(tokens[3].span.end, 18);
        assert_eq!(&input[tokens[3].span.start..tokens[3].span.end], "mortal");

        // "." at 18..19
        assert_eq!(tokens[4].span.start, 18);
        assert_eq!(tokens[4].span.end, 19);

        // EOF at end
        assert_eq!(tokens[5].span.start, input.len());
        assert_eq!(tokens[5].kind, TokenType::EOF);
    }
}

```

---

## Parser & AST

The parser builds an Abstract Syntax Tree from the token stream using recursive descent with operator precedence handling. The AST is split into two modules: declarative logic expressions and imperative statements.

**Location:** `src/ast/` (module), `src/parser/`

### AST Module

**File:** `src/ast/mod.rs`

Module exports for the dual-AST architecture. Re-exports logic.rs (declarative) and stmt.rs (imperative) types.

```rust
pub mod logic;
pub mod stmt;

pub use logic::*;
pub use stmt::{Stmt, Expr, Literal, Block, BinaryOpKind, TypeExpr, MatchArm};

```

---

### Logic AST (Declarative)

**File:** `src/ast/logic.rs`

Arena-allocated AST with Copy semantics for first-order logic. Boxed large variants (CategoricalData, RelationData, NeoEventData) reduce Expr size from 112 to 32 bytes. Includes compile-time size assertions. **Expression types:** Predicate, Identity, Quantifier (with Generic and island_id for scope constraints), Modal, Temporal, Aspectual, NeoEvent (thematic roles), Event, Control (raising/control verbs), Presupposition, Focus, SpeechAct, Imperative, Comparative (with difference field for measure phrases), Superlative, Counterfactual, Distributive, Scopal, TemporalAnchor, Causal, Intensional (opaque verb wrapper). **Term types:** Constants, Variables, Functions, Sigma, Group, Possessed, Intension (Montague up-arrow ^P for de dicto), Proposition (sentential complement), Value (numeric with kind/unit/dimension). **Intensionality Support:** Term::Intension(Symbol) for de dicto readings; Expr::Intensional { operator, content } for opaque verb contexts. **Sentential Complements:** Term::Proposition(&Expr) wraps embedded clauses as term arguments for verbs like 'say', 'believe', 'think'. Transpiles to bracket notation [expr]. **Scope Tracking:** Expr::Quantifier.island_id: u32 identifies scope boundaries for constraining quantifier movement. **Degree Semantics (Phase 8):** Dimension enum (Length, Time, Weight, Temperature, Cardinality) for measurement categories. NumberKind enum (Real, Integer, Symbolic) for prover-ready numeric types. Term::Value stores numeric value with optional unit Symbol and Dimension. Expr::Comparative.difference field holds optional measure phrase ('2 inches' in 'taller'). ThematicRole enum: Agent, Patient, Theme, Goal, Source, Recipient, Instrument, Location, Time, Manner. VoiceOperator enum (Passive) for voice handling. AspectOperator enum (Progressive, Perfect, Habitual, Iterative) for grammatical aspect. Habitual for present-tense non-stative verbs; Iterative for progressive semelfactives.

```rust
use crate::arena::Arena;
use crate::intern::Symbol;
use crate::lexicon::Definiteness;
use crate::token::TokenType;

// ═══════════════════════════════════════════════════════════════════
// Semantic Types (Montague Grammar)
// ═══════════════════════════════════════════════════════════════════

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum LogicalType {
    Entity,      // e (individuals: John, the ball)
    TruthValue,  // t (propositions)
    Property,    // <e,t> (predicates: Unicorn, Water)
    Quantifier,  // <<e,t>,t> (every man, a woman)
}

// ═══════════════════════════════════════════════════════════════════
// Degree Semantics (Prover-Ready Number System)
// ═══════════════════════════════════════════════════════════════════

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum Dimension {
    Length,
    Time,
    Weight,
    Temperature,
    Cardinality,
}

#[derive(Debug, Clone, Copy, PartialEq)]
pub enum NumberKind {
    Real(f64),
    Integer(i64),
    Symbolic(Symbol),
}

// ═══════════════════════════════════════════════════════════════════
// First-Order Logic Types (FOL Upgrade)
// ═══════════════════════════════════════════════════════════════════

#[derive(Debug, Clone, Copy)]
pub enum Term<'a> {
    Constant(Symbol),
    Variable(Symbol),
    Function(Symbol, &'a [Term<'a>]),
    Group(&'a [Term<'a>]),
    Possessed { possessor: &'a Term<'a>, possessed: Symbol },
    Sigma(Symbol),
    Intension(Symbol),  // ^Predicate (Montague up-arrow for de dicto)
    Proposition(&'a LogicExpr<'a>),  // Sentential complement (embedded clause)
    Value {
        kind: NumberKind,
        unit: Option<Symbol>,
        dimension: Option<Dimension>,
    },
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum QuantifierKind {
    Universal,
    Existential,
    Most,
    Few,
    Many,
    Cardinal(u32),
    AtLeast(u32),
    AtMost(u32),
    Generic,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum BinaryOpKind {
    And,
    Or,
    Implies,
    Iff,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum UnaryOpKind {
    Not,
}

// ═══════════════════════════════════════════════════════════════════
// Temporal & Aspect Operators (Arthur Prior's Tense Logic)
// ═══════════════════════════════════════════════════════════════════

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum TemporalOperator {
    Past,
    Future,
}

// ═══════════════════════════════════════════════════════════════════
// Event Semantics (Neo-Davidsonian)
// ═══════════════════════════════════════════════════════════════════

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum ThematicRole {
    Agent,
    Patient,
    Theme,
    Recipient,
    Goal,
    Source,
    Instrument,
    Location,
    Time,
    Manner,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum AspectOperator {
    Progressive,
    Perfect,
    Habitual,
    Iterative,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum VoiceOperator {
    Passive,
}

// ═══════════════════════════════════════════════════════════════════
// Legacy Types (kept during transition)
// ═══════════════════════════════════════════════════════════════════

#[derive(Debug)]
pub struct NounPhrase<'a> {
    pub definiteness: Option<Definiteness>,
    pub adjectives: &'a [Symbol],
    pub noun: Symbol,
    pub possessor: Option<&'a NounPhrase<'a>>,
    pub pps: &'a [&'a LogicExpr<'a>],
    pub superlative: Option<Symbol>,
}

// ═══════════════════════════════════════════════════════════════════
// Boxed Variant Data (keeps LogicExpr enum small)
// ═══════════════════════════════════════════════════════════════════

#[derive(Debug)]
pub struct CategoricalData<'a> {
    pub quantifier: TokenType,
    pub subject: NounPhrase<'a>,
    pub copula_negative: bool,
    pub predicate: NounPhrase<'a>,
}

#[derive(Debug)]
pub struct RelationData<'a> {
    pub subject: NounPhrase<'a>,
    pub verb: Symbol,
    pub object: NounPhrase<'a>,
}

#[derive(Debug)]
pub struct NeoEventData<'a> {
    pub event_var: Symbol,
    pub verb: Symbol,
    pub roles: &'a [(ThematicRole, Term<'a>)],
    pub modifiers: &'a [Symbol],
    /// When true, suppress local ∃e quantification (DRT: event var will be bound by outer ∀)
    pub suppress_existential: bool,
}

impl<'a> NounPhrase<'a> {
    pub fn simple(noun: Symbol) -> Self {
        NounPhrase {
            definiteness: None,
            adjectives: &[],
            noun,
            possessor: None,
            pps: &[],
            superlative: None,
        }
    }

    pub fn with_definiteness(definiteness: Definiteness, noun: Symbol) -> Self {
        NounPhrase {
            definiteness: Some(definiteness),
            adjectives: &[],
            noun,
            possessor: None,
            pps: &[],
            superlative: None,
        }
    }
}

#[derive(Debug, Clone, Copy, PartialEq)]
pub enum ModalDomain {
    Alethic,
    Deontic,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum ModalFlavor {
    /// Root modals (ability, obligation): can, must, should, shall, could, would
    /// These get NARROW scope (de re) - modal attaches to the predicate inside quantifier
    Root,
    /// Epistemic modals (possibility, deduction): might, may
    /// These get WIDE scope (de dicto) - modal wraps the entire quantifier
    Epistemic,
}

#[derive(Debug, Clone, Copy, PartialEq)]
pub struct ModalVector {
    pub domain: ModalDomain,
    pub force: f32,
    pub flavor: ModalFlavor,
}

// ═══════════════════════════════════════════════════════════════════
// Expression Enum (hybrid: old + new variants)
// ═══════════════════════════════════════════════════════════════════

#[derive(Debug)]
pub enum LogicExpr<'a> {
    Predicate {
        name: Symbol,
        args: &'a [Term<'a>],
    },

    Identity {
        left: &'a Term<'a>,
        right: &'a Term<'a>,
    },

    Metaphor {
        tenor: &'a Term<'a>,
        vehicle: &'a Term<'a>,
    },

    Quantifier {
        kind: QuantifierKind,
        variable: Symbol,
        body: &'a LogicExpr<'a>,
        island_id: u32,
    },

    Categorical(Box<CategoricalData<'a>>),

    Relation(Box<RelationData<'a>>),

    Modal {
        vector: ModalVector,
        operand: &'a LogicExpr<'a>,
    },

    Temporal {
        operator: TemporalOperator,
        body: &'a LogicExpr<'a>,
    },

    Aspectual {
        operator: AspectOperator,
        body: &'a LogicExpr<'a>,
    },

    Voice {
        operator: VoiceOperator,
        body: &'a LogicExpr<'a>,
    },

    BinaryOp {
        left: &'a LogicExpr<'a>,
        op: TokenType,
        right: &'a LogicExpr<'a>,
    },

    UnaryOp {
        op: TokenType,
        operand: &'a LogicExpr<'a>,
    },

    Question {
        wh_variable: Symbol,
        body: &'a LogicExpr<'a>,
    },

    YesNoQuestion {
        body: &'a LogicExpr<'a>,
    },

    Atom(Symbol),

    Lambda {
        variable: Symbol,
        body: &'a LogicExpr<'a>,
    },

    App {
        function: &'a LogicExpr<'a>,
        argument: &'a LogicExpr<'a>,
    },

    Intensional {
        operator: Symbol,
        content: &'a LogicExpr<'a>,
    },

    Event {
        predicate: &'a LogicExpr<'a>,
        adverbs: &'a [Symbol],
    },

    NeoEvent(Box<NeoEventData<'a>>),

    Imperative {
        action: &'a LogicExpr<'a>,
    },

    SpeechAct {
        performer: Symbol,
        act_type: Symbol,
        content: &'a LogicExpr<'a>,
    },

    Counterfactual {
        antecedent: &'a LogicExpr<'a>,
        consequent: &'a LogicExpr<'a>,
    },

    Causal {
        effect: &'a LogicExpr<'a>,
        cause: &'a LogicExpr<'a>,
    },

    Comparative {
        adjective: Symbol,
        subject: &'a Term<'a>,
        object: &'a Term<'a>,
        difference: Option<&'a Term<'a>>,
    },

    Superlative {
        adjective: Symbol,
        subject: &'a Term<'a>,
        domain: Symbol,
    },

    Scopal {
        operator: Symbol,
        body: &'a LogicExpr<'a>,
    },

    Control {
        verb: Symbol,
        subject: &'a Term<'a>,
        object: Option<&'a Term<'a>>,
        infinitive: &'a LogicExpr<'a>,
    },

    Presupposition {
        assertion: &'a LogicExpr<'a>,
        presupposition: &'a LogicExpr<'a>,
    },

    Focus {
        kind: crate::token::FocusKind,
        focused: &'a Term<'a>,
        scope: &'a LogicExpr<'a>,
    },

    TemporalAnchor {
        anchor: Symbol,
        body: &'a LogicExpr<'a>,
    },

    Distributive {
        predicate: &'a LogicExpr<'a>,
    },

    /// Group existential for collective readings of cardinals
    /// ∃g(Group(g) ∧ Count(g,n) ∧ ∀x(Member(x,g) → Restriction(x)) ∧ Body(g))
    GroupQuantifier {
        group_var: Symbol,
        count: u32,
        member_var: Symbol,
        restriction: &'a LogicExpr<'a>,
        body: &'a LogicExpr<'a>,
    },
}

impl<'a> LogicExpr<'a> {
    pub fn lambda(var: Symbol, body: &'a LogicExpr<'a>, arena: &'a Arena<LogicExpr<'a>>) -> &'a LogicExpr<'a> {
        arena.alloc(LogicExpr::Lambda {
            variable: var,
            body,
        })
    }

    pub fn app(func: &'a LogicExpr<'a>, arg: &'a LogicExpr<'a>, arena: &'a Arena<LogicExpr<'a>>) -> &'a LogicExpr<'a> {
        arena.alloc(LogicExpr::App {
            function: func,
            argument: arg,
        })
    }
}

#[cfg(test)]
mod size_tests {
    use super::*;
    use std::mem::size_of;

    #[test]
    fn test_ast_node_sizes() {
        println!("LogicExpr size: {} bytes", size_of::<LogicExpr>());
        println!("Term size: {} bytes", size_of::<Term>());
        println!("NounPhrase size: {} bytes", size_of::<NounPhrase>());

        assert!(
            size_of::<LogicExpr>() <= 48,
            "LogicExpr is {} bytes - consider boxing large variants",
            size_of::<LogicExpr>()
        );
        assert!(
            size_of::<Term>() <= 32,
            "Term is {} bytes",
            size_of::<Term>()
        );
    }
}

```

---

### Statement AST (Imperative)

**File:** `src/ast/stmt.rs`

Imperative AST for executable code blocks. **Stmt enum variants:** Let (variable binding), Set (mutation), Call (function invocation), If (conditional with then/else blocks), While (loops), Return (with optional value), Assert (bridge to logic kernel - embeds Expr for verification), Give (ownership transfer/move semantics), Show (immutable borrow). **Expr enum (imperative):** Literal (Number, Text, Boolean, Nothing), Identifier, BinaryOp (arithmetic and comparison), Call, Index, Slice. **BinaryOpKind:** Add, Subtract, Multiply, Divide, Eq, NotEq, Lt, Gt, LtEq, GtEq. The Assert statement connects imperative code to the declarative logic kernel, enabling runtime verification via debug_assert! macros in generated Rust.

```rust
use super::logic::LogicExpr;
use crate::intern::Symbol;

/// Type expression for explicit type annotations.
///
/// Represents type syntax like:
/// - `Int` → Primitive(Int)
/// - `User` → Named(User)
/// - `List of Int` → Generic { base: List, params: [Primitive(Int)] }
/// - `List of List of Int` → Generic { base: List, params: [Generic { base: List, params: [Primitive(Int)] }] }
/// - `Result of Int and Text` → Generic { base: Result, params: [Primitive(Int), Primitive(Text)] }
#[derive(Debug, Clone)]
pub enum TypeExpr<'a> {
    /// Primitive type: Int, Nat, Text, Bool
    Primitive(Symbol),
    /// Named type (user-defined): User, Point
    Named(Symbol),
    /// Generic type: List of Int, Option of Text, Result of Int and Text
    Generic {
        base: Symbol,
        params: &'a [TypeExpr<'a>],
    },
    /// Function type: fn(A, B) -> C (for higher-order functions)
    Function {
        inputs: &'a [TypeExpr<'a>],
        output: &'a TypeExpr<'a>,
    },
    /// Phase 43C: Refinement type with predicate constraint
    /// Example: `Int where it > 0`
    Refinement {
        /// The base type being refined
        base: &'a TypeExpr<'a>,
        /// The bound variable (usually "it")
        var: Symbol,
        /// The predicate constraint (from Logic Kernel)
        predicate: &'a LogicExpr<'a>,
    },
    /// Phase 53: Persistent storage wrapper type
    /// Example: `Persistent Counter`
    /// Semantics: Wraps a Shared type with journal-backed storage
    Persistent {
        /// The inner type (must be a Shared/CRDT type)
        inner: &'a TypeExpr<'a>,
    },
}

/// Phase 10: Source for Read statements
#[derive(Debug, Clone, Copy)]
pub enum ReadSource<'a> {
    /// Read from console (stdin)
    Console,
    /// Read from file at given path
    File(&'a Expr<'a>),
}

/// Binary operation kinds for imperative expressions.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum BinaryOpKind {
    Add,
    Subtract,
    Multiply,
    Divide,
    Modulo,
    Eq,
    NotEq,
    Lt,
    Gt,
    LtEq,
    GtEq,
    // Grand Challenge: Logical operators for compound conditions
    And,
    Or,
    // Phase 53: String concatenation ("X combined with Y")
    Concat,
}

/// Block is a sequence of statements.
pub type Block<'a> = &'a [Stmt<'a>];

/// Phase 33: Match arm for Inspect statement
#[derive(Debug)]
pub struct MatchArm<'a> {
    pub enum_name: Option<Symbol>,          // The enum type (e.g., Shape)
    pub variant: Option<Symbol>,            // None = Otherwise (wildcard)
    pub bindings: Vec<(Symbol, Symbol)>,    // (field_name, binding_name)
    pub body: Block<'a>,
}

/// Imperative statement AST (LOGOS §15.0.0).
///
/// Stmt is the primary AST node for imperative code blocks like `## Main`
/// and function bodies. The Assert variant bridges to the Logic Kernel.
#[derive(Debug)]
pub enum Stmt<'a> {
    /// Variable binding: `Let x be 5.` or `Let x: Int be 5.`
    Let {
        var: Symbol,
        ty: Option<&'a TypeExpr<'a>>,
        value: &'a Expr<'a>,
        mutable: bool,
    },

    /// Mutation: `Set x to 10.`
    Set {
        target: Symbol,
        value: &'a Expr<'a>,
    },

    /// Function call as statement: `Call process with data.`
    Call {
        function: Symbol,
        args: Vec<&'a Expr<'a>>,
    },

    /// Conditional: `If condition: ... Otherwise: ...`
    If {
        cond: &'a Expr<'a>,
        then_block: Block<'a>,
        else_block: Option<Block<'a>>,
    },

    /// Loop: `While condition: ...` or `While condition (decreasing expr): ...`
    While {
        cond: &'a Expr<'a>,
        body: Block<'a>,
        /// Phase 44: Optional decreasing variant for termination proof
        decreasing: Option<&'a Expr<'a>>,
    },

    /// Iteration: `Repeat for x in list: ...` or `Repeat for i from 1 to 10: ...`
    Repeat {
        var: Symbol,
        iterable: &'a Expr<'a>,
        body: Block<'a>,
    },

    /// Return: `Return x.` or `Return.`
    Return {
        value: Option<&'a Expr<'a>>,
    },

    /// Bridge to Logic Kernel: `Assert that P.`
    Assert {
        proposition: &'a LogicExpr<'a>,
    },

    /// Phase 35: Documented assertion with justification
    /// `Trust that P because "reason".`
    /// Semantics: Documented runtime check that could be verified statically.
    Trust {
        proposition: &'a LogicExpr<'a>,
        justification: Symbol,
    },

    /// Runtime assertion with imperative condition
    /// `Assert that condition.` (for imperative mode)
    RuntimeAssert {
        condition: &'a Expr<'a>,
    },

    /// Ownership transfer (move): `Give x to processor.`
    /// Semantics: Move ownership of `object` to `recipient`.
    Give {
        object: &'a Expr<'a>,
        recipient: &'a Expr<'a>,
    },

    /// Immutable borrow: `Show x to console.`
    /// Semantics: Immutable borrow of `object` passed to `recipient`.
    Show {
        object: &'a Expr<'a>,
        recipient: &'a Expr<'a>,
    },

    /// Phase 31: Field mutation: `Set p's x to 10.`
    SetField {
        object: &'a Expr<'a>,
        field: Symbol,
        value: &'a Expr<'a>,
    },

    /// Phase 31: Struct definition for codegen
    /// Phase 47: Added is_portable for serde derives
    StructDef {
        name: Symbol,
        fields: Vec<(Symbol, Symbol, bool)>, // (name, type_name, is_public)
        is_portable: bool,                    // Phase 47: Derives Serialize/Deserialize
    },

    /// Phase 32/38: Function definition
    /// Phase 38: Updated for native functions and TypeExpr types
    FunctionDef {
        name: Symbol,
        params: Vec<(Symbol, &'a TypeExpr<'a>)>, // Phase 38: Changed to TypeExpr
        body: Block<'a>,
        return_type: Option<&'a TypeExpr<'a>>,   // Phase 38: Changed to TypeExpr
        is_native: bool,                          // Phase 38: Native function flag
    },

    /// Phase 33: Pattern matching on sum types
    Inspect {
        target: &'a Expr<'a>,
        arms: Vec<MatchArm<'a>>,
        has_otherwise: bool,            // For exhaustiveness tracking
    },

    /// Phase 43D: Push to collection: `Push x to items.`
    Push {
        value: &'a Expr<'a>,
        collection: &'a Expr<'a>,
    },

    /// Phase 43D: Pop from collection: `Pop from items.` or `Pop from items into y.`
    Pop {
        collection: &'a Expr<'a>,
        into: Option<Symbol>,
    },

    /// Add to set: `Add x to set.`
    Add {
        value: &'a Expr<'a>,
        collection: &'a Expr<'a>,
    },

    /// Remove from set: `Remove x from set.`
    Remove {
        value: &'a Expr<'a>,
        collection: &'a Expr<'a>,
    },

    /// Index assignment: `Set item N of X to Y.`
    SetIndex {
        collection: &'a Expr<'a>,
        index: &'a Expr<'a>,
        value: &'a Expr<'a>,
    },

    /// Phase 8.5: Memory arena block (Zone)
    /// "Inside a new zone called 'Scratch':"
    /// "Inside a zone called 'Buffer' of size 1 MB:"
    /// "Inside a zone called 'Data' mapped from 'file.bin':"
    Zone {
        /// The variable name for the arena handle (e.g., "Scratch")
        name: Symbol,
        /// Optional pre-allocated capacity in bytes (Heap zones only)
        capacity: Option<usize>,
        /// Optional file path for memory-mapped zones (Mapped zones only)
        source_file: Option<Symbol>,
        /// The code block executed within this memory context
        body: Block<'a>,
    },

    /// Phase 9: Concurrent execution block (async, I/O-bound)
    /// "Attempt all of the following:"
    /// Semantics: All tasks run concurrently via tokio::join!
    /// Best for: network requests, file I/O, waiting operations
    Concurrent {
        /// The statements to execute concurrently
        tasks: Block<'a>,
    },

    /// Phase 9: Parallel execution block (CPU-bound)
    /// "Simultaneously:"
    /// Semantics: True parallelism via rayon::join or thread::spawn
    /// Best for: computation, data processing, number crunching
    Parallel {
        /// The statements to execute in parallel
        tasks: Block<'a>,
    },

    /// Phase 10: Read from console or file
    /// `Read input from the console.` or `Read data from file "path.txt".`
    ReadFrom {
        var: Symbol,
        source: ReadSource<'a>,
    },

    /// Phase 10: Write to file
    /// `Write "content" to file "output.txt".`
    WriteFile {
        content: &'a Expr<'a>,
        path: &'a Expr<'a>,
    },

    /// Phase 46: Spawn an agent
    /// `Spawn a Worker called "w1".`
    Spawn {
        agent_type: Symbol,
        name: Symbol,
    },

    /// Phase 46: Send message to agent
    /// `Send Ping to "agent".`
    SendMessage {
        message: &'a Expr<'a>,
        destination: &'a Expr<'a>,
    },

    /// Phase 46: Await response from agent
    /// `Await response from "agent" into result.`
    AwaitMessage {
        source: &'a Expr<'a>,
        into: Symbol,
    },

    /// Phase 49: Merge CRDT state
    /// `Merge remote into local.` or `Merge remote's field into local's field.`
    MergeCrdt {
        source: &'a Expr<'a>,
        target: &'a Expr<'a>,
    },

    /// Phase 49: Increment GCounter
    /// `Increase local's points by 10.`
    IncreaseCrdt {
        object: &'a Expr<'a>,
        field: Symbol,
        amount: &'a Expr<'a>,
    },

    /// Phase 49b: Decrement PNCounter (Tally)
    /// `Decrease game's score by 5.`
    DecreaseCrdt {
        object: &'a Expr<'a>,
        field: Symbol,
        amount: &'a Expr<'a>,
    },

    /// Phase 49b: Append to SharedSequence (RGA)
    /// `Append "Hello" to doc's lines.`
    AppendToSequence {
        sequence: &'a Expr<'a>,
        value: &'a Expr<'a>,
    },

    /// Phase 49b: Resolve MVRegister conflicts
    /// `Resolve page's title to "Final".`
    ResolveConflict {
        object: &'a Expr<'a>,
        field: Symbol,
        value: &'a Expr<'a>,
    },

    /// Phase 50: Security check - mandatory runtime guard
    /// `Check that user is admin.`
    /// `Check that user can publish the document.`
    /// Semantics: NEVER optimized out. Panics if condition is false.
    Check {
        /// The subject being checked (e.g., "user")
        subject: Symbol,
        /// The predicate name (e.g., "admin") or action (e.g., "publish")
        predicate: Symbol,
        /// True if this is a capability check (can [action])
        is_capability: bool,
        /// For capabilities: the object being acted on (e.g., "document")
        object: Option<Symbol>,
        /// Original English text for error message
        source_text: String,
        /// Source location for error reporting
        span: crate::token::Span,
    },

    /// Phase 51: Listen on network address
    /// `Listen on "/ip4/127.0.0.1/tcp/8000".`
    /// Semantics: Bind to address, start accepting connections via libp2p
    Listen {
        address: &'a Expr<'a>,
    },

    /// Phase 51: Connect to remote peer
    /// `Connect to "/ip4/127.0.0.1/tcp/8000".`
    /// Semantics: Dial peer via libp2p
    ConnectTo {
        address: &'a Expr<'a>,
    },

    /// Phase 51: Create PeerAgent remote handle
    /// `Let remote be a PeerAgent at "/ip4/127.0.0.1/tcp/8000".`
    /// Semantics: Create handle for remote agent communication
    LetPeerAgent {
        var: Symbol,
        address: &'a Expr<'a>,
    },

    /// Phase 51: Sleep for milliseconds
    /// `Sleep 1000.` or `Sleep delay.`
    /// Semantics: Pause execution for N milliseconds (async)
    Sleep {
        milliseconds: &'a Expr<'a>,
    },

    /// Phase 52: Sync CRDT variable on topic
    /// `Sync x on "topic".`
    /// Semantics: Subscribe to GossipSub topic, auto-publish on mutation, auto-merge on receive
    Sync {
        var: Symbol,
        topic: &'a Expr<'a>,
    },

    /// Phase 53: Mount persistent CRDT from journal file
    /// `Mount counter at "data/counter.journal".`
    /// Semantics: Load or create journal, replay operations to reconstruct state
    Mount {
        /// The variable name for the mounted value
        var: Symbol,
        /// The path expression for the journal file
        path: &'a Expr<'a>,
    },

    // =========================================================================
    // Phase 54: Go-like Concurrency (Green Threads, Channels, Select)
    // =========================================================================

    /// Phase 54: Launch a fire-and-forget task (green thread)
    /// `Launch a task to process(data).`
    /// Semantics: tokio::spawn with no handle capture
    LaunchTask {
        /// The function to call
        function: Symbol,
        /// Arguments to pass
        args: Vec<&'a Expr<'a>>,
    },

    /// Phase 54: Launch a task with handle for control
    /// `Let worker be Launch a task to process(data).`
    /// Semantics: tokio::spawn returning JoinHandle
    LaunchTaskWithHandle {
        /// Variable to bind the handle
        handle: Symbol,
        /// The function to call
        function: Symbol,
        /// Arguments to pass
        args: Vec<&'a Expr<'a>>,
    },

    /// Phase 54: Create a bounded channel (pipe)
    /// `Let jobs be a new Pipe of Int.`
    /// Semantics: tokio::sync::mpsc::channel(32)
    CreatePipe {
        /// Variable for the pipe
        var: Symbol,
        /// Type of values in the pipe
        element_type: Symbol,
        /// Optional capacity (defaults to 32)
        capacity: Option<u32>,
    },

    /// Phase 54: Blocking send into pipe
    /// `Send value into pipe.`
    /// Semantics: pipe_tx.send(value).await
    SendPipe {
        /// The value to send
        value: &'a Expr<'a>,
        /// The pipe to send into
        pipe: &'a Expr<'a>,
    },

    /// Phase 54: Blocking receive from pipe
    /// `Receive x from pipe.`
    /// Semantics: let x = pipe_rx.recv().await
    ReceivePipe {
        /// Variable to bind the received value
        var: Symbol,
        /// The pipe to receive from
        pipe: &'a Expr<'a>,
    },

    /// Phase 54: Non-blocking send (try)
    /// `Try to send value into pipe.`
    /// Semantics: pipe_tx.try_send(value) - returns immediately
    TrySendPipe {
        /// The value to send
        value: &'a Expr<'a>,
        /// The pipe to send into
        pipe: &'a Expr<'a>,
        /// Variable to bind the result (true/false)
        result: Option<Symbol>,
    },

    /// Phase 54: Non-blocking receive (try)
    /// `Try to receive x from pipe.`
    /// Semantics: pipe_rx.try_recv() - returns Option
    TryReceivePipe {
        /// Variable to bind the received value (if any)
        var: Symbol,
        /// The pipe to receive from
        pipe: &'a Expr<'a>,
    },

    /// Phase 54: Cancel a spawned task
    /// `Stop worker.`
    /// Semantics: handle.abort()
    StopTask {
        /// The handle to cancel
        handle: &'a Expr<'a>,
    },

    /// Phase 54: Select on multiple channels/timeouts
    /// `Await the first of:`
    ///     `Receive x from ch:`
    ///         `...`
    ///     `After 5 seconds:`
    ///         `...`
    /// Semantics: tokio::select! with auto-cancel
    Select {
        /// The branches to select from
        branches: Vec<SelectBranch<'a>>,
    },
}

/// Phase 54: A branch in a Select statement
#[derive(Debug)]
pub enum SelectBranch<'a> {
    /// Receive from a pipe: `Receive x from ch:`
    Receive {
        var: Symbol,
        pipe: &'a Expr<'a>,
        body: Block<'a>,
    },
    /// Timeout: `After N seconds:` or `After N milliseconds:`
    Timeout {
        milliseconds: &'a Expr<'a>,
        body: Block<'a>,
    },
}

/// Shared expression type for pure computations (LOGOS §15.0.0).
///
/// Expr is used by both LogicExpr (as terms) and Stmt (as values).
/// These are pure computations without side effects.
#[derive(Debug)]
pub enum Expr<'a> {
    /// Literal value: 42, "hello", true, nothing
    Literal(Literal),

    /// Variable reference: x
    Identifier(Symbol),

    /// Binary operation: x plus y
    BinaryOp {
        op: BinaryOpKind,
        left: &'a Expr<'a>,
        right: &'a Expr<'a>,
    },

    /// Function call as expression: f(x, y)
    Call {
        function: Symbol,
        args: Vec<&'a Expr<'a>>,
    },

    /// Phase 43D: Dynamic index access: `items at i` (1-indexed)
    Index {
        collection: &'a Expr<'a>,
        index: &'a Expr<'a>,
    },

    /// Phase 43D: Dynamic slice access: `items 1 through mid` (1-indexed, inclusive)
    Slice {
        collection: &'a Expr<'a>,
        start: &'a Expr<'a>,
        end: &'a Expr<'a>,
    },

    /// Phase 43D: Copy expression: `copy of slice` → slice.to_vec()
    Copy {
        expr: &'a Expr<'a>,
    },

    /// Phase 43D: Length expression: `length of items` → items.len()
    Length {
        collection: &'a Expr<'a>,
    },

    /// Set contains: `set contains x` or `x in set`
    Contains {
        collection: &'a Expr<'a>,
        value: &'a Expr<'a>,
    },

    /// Set union: `a union b`
    Union {
        left: &'a Expr<'a>,
        right: &'a Expr<'a>,
    },

    /// Set intersection: `a intersection b`
    Intersection {
        left: &'a Expr<'a>,
        right: &'a Expr<'a>,
    },

    /// Phase 48: Get manifest of a zone
    /// `the manifest of Zone` → FileSipper::from_zone(&zone).manifest()
    ManifestOf {
        zone: &'a Expr<'a>,
    },

    /// Phase 48: Get chunk at index from a zone
    /// `the chunk at N in Zone` → FileSipper::from_zone(&zone).get_chunk(N)
    ChunkAt {
        index: &'a Expr<'a>,
        zone: &'a Expr<'a>,
    },

    /// List literal: [1, 2, 3]
    List(Vec<&'a Expr<'a>>),

    /// Tuple literal: (1, "hello", true)
    Tuple(Vec<&'a Expr<'a>>),

    /// Range: 1 to 10 (inclusive)
    Range {
        start: &'a Expr<'a>,
        end: &'a Expr<'a>,
    },

    /// Phase 31: Field access: `p's x` or `the x of p`
    FieldAccess {
        object: &'a Expr<'a>,
        field: Symbol,
    },

    /// Phase 31: Constructor: `a new Point` or `a new Point with x 10 and y 20`
    /// Phase 34: Extended for generics: `a new Box of Int`
    New {
        type_name: Symbol,
        type_args: Vec<Symbol>,  // Empty for non-generic types
        init_fields: Vec<(Symbol, &'a Expr<'a>)>,  // Optional field initialization
    },

    /// Phase 33: Enum variant constructor: `a new Circle with radius 10`
    NewVariant {
        enum_name: Symbol,                      // Shape (resolved from registry)
        variant: Symbol,                        // Circle
        fields: Vec<(Symbol, &'a Expr<'a>)>,    // [(radius, 10)]
    },
}

/// Literal values in LOGOS.
#[derive(Debug, Clone, PartialEq)]
pub enum Literal {
    /// Integer literal
    Number(i64),
    /// Float literal
    Float(f64),
    /// Text literal
    Text(Symbol),
    /// Boolean literal
    Boolean(bool),
    /// The nothing literal (unit type)
    Nothing,
    /// Character literal
    Char(char),
}

```

---

### Parser Core

**File:** `src/parser/mod.rs`

Core Parser struct with token stream, cursor, and context management. **Topicalization:** Detects 'NP + Comma' pattern at sentence start (lines 401-473), stores fronted NP, injects as object with adjective preservation via wrap_with_definiteness_full(). Handles pronoun subjects ('The book, he read.') and full NP subjects ('The apple, John ate.'). **Filler-Gap:** filler_gap: Option<Symbol> field tracks wh-fillers across clause boundaries for long-distance dependencies in relative clauses and wh-questions. **Garden Path Optimization:** Skips reanalysis when auxiliary is present (pending_time.is_some()) since auxiliaries disambiguate structure. ParserGuard RAII struct with guard()/commit() pattern and Deref for transparent parser access with automatic rollback. Entry point for recursive descent parsing. **VP Ellipsis Support:** EventTemplate struct stores verb + non-agent thematic roles + modifiers. capture_event_template() extracts template at NeoEvent creation. last_event_template field persists template for cross-sentence reconstruction. **Phase 12 Parse Forest:** noun_priority_mode: bool field enables lexical ambiguity forking. set_noun_priority_mode() toggles noun-first interpretation for Ambiguous tokens. check_pronoun() respects noun_priority_mode for possessive pronoun handling ('her' as determiner vs object). **Copula Adjective Preference:** After copula (is/was/are/were), simple-aspect Verbs with Adjective alternative prefer Adjective reading via prefer_adjective check (lines 870-884). E.g., 'The door is open' → Adjective(open) rather than Verb. **NPI Handling (Phase 15):** check_npi_quantifier() detects anything/anyone/nobody/nothing; check_npi_object() handles NPI objects in negative contexts; check_temporal_npi() handles ever/never; parse_npi_quantified() produces appropriate quantifier structure based on licensing.

```rust
mod clause;
mod common;
mod modal;
mod noun;
mod pragmatics;
mod quantifier;
mod question;
mod verb;

#[cfg(test)]
mod tests;

pub use clause::ClauseParsing;
pub use modal::ModalParsing;
pub use noun::NounParsing;
pub use pragmatics::PragmaticsParsing;
pub use quantifier::QuantifierParsing;
pub use question::QuestionParsing;
pub use verb::{LogicVerbParsing, ImperativeVerbParsing};

use crate::analysis::TypeRegistry;
use crate::arena_ctx::AstContext;
use crate::ast::{AspectOperator, LogicExpr, NeoEventData, NumberKind, QuantifierKind, TemporalOperator, Term, ThematicRole, Stmt, Expr, Literal, TypeExpr, BinaryOpKind, MatchArm};
use crate::ast::stmt::ReadSource;
use crate::context::{Case, DiscourseContext, Entity, Gender, Number};
use crate::drs::{Drs, BoxType};
use crate::error::{ParseError, ParseErrorKind};
use crate::intern::{Interner, Symbol, SymbolEq};
use crate::lexer::Lexer;
use crate::lexicon::{self, Aspect, Definiteness, Time, VerbClass};
use crate::token::{BlockType, FocusKind, Token, TokenType};

pub(super) type ParseResult<T> = Result<T, ParseError>;

use std::ops::{Deref, DerefMut};

/// Determines how the parser interprets sentences.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
pub enum ParserMode {
    /// Logicaffeine mode: propositions, NeoEvents, ambiguity allowed.
    #[default]
    Declarative,
    /// LOGOS mode: statements, strict scoping, deterministic.
    Imperative,
}

/// Controls scope of negation for lexically negative verbs (lacks, miss).
/// "user who lacks a key" can mean:
///   - Wide:   ¬∃y(Key(y) ∧ Have(x,y)) - "has NO keys" (natural reading)
///   - Narrow: ∃y(Key(y) ∧ ¬Have(x,y)) - "missing SOME key" (literal reading)
#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
pub enum NegativeScopeMode {
    /// Narrow scope negation (literal reading): ∃y(Key(y) ∧ ¬Have(x,y))
    /// "User is missing some key" - need all keys (default/traditional reading)
    #[default]
    Narrow,
    /// Wide scope negation (natural reading): ¬∃y(Key(y) ∧ Have(x,y))
    /// "User has no keys" - need at least one key
    Wide,
}

#[derive(Clone)]
struct ParserCheckpoint {
    pos: usize,
    var_counter: usize,
    bindings_len: usize,
    island: u32,
    time: Option<Time>,
    negative_depth: u32,
}

pub struct ParserGuard<'p, 'a, 'ctx, 'int> {
    parser: &'p mut Parser<'a, 'ctx, 'int>,
    checkpoint: ParserCheckpoint,
    committed: bool,
}

impl<'p, 'a, 'ctx, 'int> ParserGuard<'p, 'a, 'ctx, 'int> {
    pub fn commit(mut self) {
        self.committed = true;
    }
}

impl<'p, 'a, 'ctx, 'int> Drop for ParserGuard<'p, 'a, 'ctx, 'int> {
    fn drop(&mut self) {
        if !self.committed {
            self.parser.restore(self.checkpoint.clone());
        }
    }
}

impl<'p, 'a, 'ctx, 'int> Deref for ParserGuard<'p, 'a, 'ctx, 'int> {
    type Target = Parser<'a, 'ctx, 'int>;
    fn deref(&self) -> &Self::Target {
        self.parser
    }
}

impl<'p, 'a, 'ctx, 'int> DerefMut for ParserGuard<'p, 'a, 'ctx, 'int> {
    fn deref_mut(&mut self) -> &mut Self::Target {
        self.parser
    }
}

#[derive(Clone, Debug)]
pub struct EventTemplate<'a> {
    pub verb: Symbol,
    pub non_agent_roles: Vec<(ThematicRole, Term<'a>)>,
    pub modifiers: Vec<Symbol>,
}

pub struct Parser<'a, 'ctx, 'int> {
    pub(super) tokens: Vec<Token>,
    pub(super) current: usize,
    pub(super) var_counter: usize,
    pub(super) pending_time: Option<Time>,
    pub(super) context: Option<&'ctx mut DiscourseContext>,
    /// Donkey bindings: (noun, var, is_donkey_used, wide_scope_negation)
    /// The 4th field tracks if this binding's existential needs negation wrapping (for "lacks" scope)
    pub(super) donkey_bindings: Vec<(Symbol, Symbol, bool, bool)>,
    pub(super) interner: &'int mut Interner,
    pub(super) ctx: AstContext<'a>,
    pub(super) current_island: u32,
    pub(super) pp_attach_to_noun: bool,
    pub(super) filler_gap: Option<Symbol>,
    pub(super) negative_depth: u32,
    pub(super) discourse_event_var: Option<Symbol>,
    pub(super) last_event_template: Option<EventTemplate<'a>>,
    pub(super) noun_priority_mode: bool,
    pub(super) collective_mode: bool,
    pub(super) pending_cardinal: Option<u32>,
    pub(super) mode: ParserMode,
    pub(super) type_registry: Option<TypeRegistry>,
    pub(super) event_reading_mode: bool,
    pub(super) drs: Drs,
    pub(super) negative_scope_mode: NegativeScopeMode,
}

impl<'a, 'ctx, 'int> Parser<'a, 'ctx, 'int> {
    pub fn new(
        tokens: Vec<Token>,
        interner: &'int mut Interner,
        ctx: AstContext<'a>,
    ) -> Self {
        Parser {
            tokens,
            current: 0,
            var_counter: 0,
            pending_time: None,
            context: None,
            donkey_bindings: Vec::new(),
            interner,
            ctx,
            current_island: 0,
            pp_attach_to_noun: false,
            filler_gap: None,
            negative_depth: 0,
            discourse_event_var: None,
            last_event_template: None,
            noun_priority_mode: false,
            collective_mode: false,
            pending_cardinal: None,
            mode: ParserMode::Declarative,
            type_registry: None,
            event_reading_mode: false,
            drs: Drs::new(),
            negative_scope_mode: NegativeScopeMode::default(),
        }
    }

    pub fn set_noun_priority_mode(&mut self, mode: bool) {
        self.noun_priority_mode = mode;
    }

    pub fn set_collective_mode(&mut self, mode: bool) {
        self.collective_mode = mode;
    }

    pub fn set_event_reading_mode(&mut self, mode: bool) {
        self.event_reading_mode = mode;
    }

    pub fn set_negative_scope_mode(&mut self, mode: NegativeScopeMode) {
        self.negative_scope_mode = mode;
    }

    pub fn with_context(
        tokens: Vec<Token>,
        context: &'ctx mut DiscourseContext,
        interner: &'int mut Interner,
        ctx: AstContext<'a>,
    ) -> Self {
        Parser {
            tokens,
            current: 0,
            var_counter: 0,
            pending_time: None,
            context: Some(context),
            donkey_bindings: Vec::new(),
            interner,
            ctx,
            current_island: 0,
            pp_attach_to_noun: false,
            filler_gap: None,
            negative_depth: 0,
            discourse_event_var: None,
            last_event_template: None,
            noun_priority_mode: false,
            collective_mode: false,
            pending_cardinal: None,
            mode: ParserMode::Declarative,
            type_registry: None,
            event_reading_mode: false,
            drs: Drs::new(),
            negative_scope_mode: NegativeScopeMode::default(),
        }
    }

    /// Create a parser with type registry for two-pass compilation.
    /// The type registry enables disambiguation of "Stack of Integers" (generic)
    /// vs "Owner of House" (possessive).
    pub fn with_types(
        tokens: Vec<Token>,
        context: &'ctx mut DiscourseContext,
        interner: &'int mut Interner,
        ctx: AstContext<'a>,
        types: TypeRegistry,
    ) -> Self {
        Parser {
            tokens,
            current: 0,
            var_counter: 0,
            pending_time: None,
            context: Some(context),
            donkey_bindings: Vec::new(),
            interner,
            ctx,
            current_island: 0,
            pp_attach_to_noun: false,
            filler_gap: None,
            negative_depth: 0,
            discourse_event_var: None,
            last_event_template: None,
            noun_priority_mode: false,
            collective_mode: false,
            pending_cardinal: None,
            mode: ParserMode::Declarative,
            type_registry: Some(types),
            event_reading_mode: false,
            drs: Drs::new(),
            negative_scope_mode: NegativeScopeMode::default(),
        }
    }

    pub fn set_discourse_event_var(&mut self, var: Symbol) {
        self.discourse_event_var = Some(var);
    }

    pub fn mode(&self) -> ParserMode {
        self.mode
    }

    /// Check if a symbol is a known type in the registry.
    /// Used to disambiguate "Stack of Integers" (generic type) vs "Owner of House" (possessive).
    pub fn is_known_type(&self, sym: Symbol) -> bool {
        self.type_registry
            .as_ref()
            .map(|r| r.is_type(sym))
            .unwrap_or(false)
    }

    /// Check if a symbol is a known generic type (takes type parameters).
    /// Used to parse "Stack of Integers" as generic instantiation.
    pub fn is_generic_type(&self, sym: Symbol) -> bool {
        self.type_registry
            .as_ref()
            .map(|r| r.is_generic(sym))
            .unwrap_or(false)
    }

    /// Get the parameter count for a generic type.
    fn get_generic_param_count(&self, sym: Symbol) -> Option<usize> {
        use crate::analysis::TypeDef;
        self.type_registry.as_ref().and_then(|r| {
            match r.get(sym) {
                Some(TypeDef::Generic { param_count }) => Some(*param_count),
                _ => None,
            }
        })
    }

    /// Phase 33: Check if a symbol is a known enum variant and return the enum name.
    fn find_variant(&self, sym: Symbol) -> Option<Symbol> {
        self.type_registry
            .as_ref()
            .and_then(|r| r.find_variant(sym).map(|(enum_name, _)| enum_name))
    }

    /// Consume a type name token (doesn't check entity registration).
    fn consume_type_name(&mut self) -> ParseResult<Symbol> {
        let t = self.advance().clone();
        match t.kind {
            TokenType::Noun(s) | TokenType::Adjective(s) => Ok(s),
            TokenType::ProperName(s) => Ok(s),
            // Phase 49b: CRDT type keywords are valid type names
            TokenType::Tally => Ok(self.interner.intern("Tally")),
            TokenType::SharedSet => Ok(self.interner.intern("SharedSet")),
            TokenType::SharedSequence => Ok(self.interner.intern("SharedSequence")),
            TokenType::CollaborativeSequence => Ok(self.interner.intern("CollaborativeSequence")),
            TokenType::SharedMap => Ok(self.interner.intern("SharedMap")),
            TokenType::Divergent => Ok(self.interner.intern("Divergent")),
            other => Err(ParseError {
                kind: ParseErrorKind::ExpectedContentWord { found: other },
                span: self.current_span(),
            }),
        }
    }

    /// Parse a type expression: Int, Text, List of Int, Result of Int and Text.
    /// Phase 36: Also supports "Type from Module" for qualified imports.
    /// Uses TypeRegistry to distinguish primitives from generics.
    fn parse_type_expression(&mut self) -> ParseResult<TypeExpr<'a>> {
        use noun::NounParsing;

        // Phase 53: Handle "Persistent T" type modifier
        if self.check(&TokenType::Persistent) {
            self.advance(); // consume "Persistent"
            let inner = self.parse_type_expression()?;
            let inner_ref = self.ctx.alloc_type_expr(inner);
            return Ok(TypeExpr::Persistent { inner: inner_ref });
        }

        // Get the base type name (must be a noun or proper name - type names bypass entity check)
        let mut base = self.consume_type_name()?;

        // Phase 49c: Check for bias modifier on SharedSet: "SharedSet (RemoveWins) of T"
        let base_name = self.interner.resolve(base);
        if base_name == "SharedSet" || base_name == "ORSet" {
            if self.check(&TokenType::LParen) {
                self.advance(); // consume "("
                if self.check(&TokenType::RemoveWins) {
                    self.advance(); // consume "RemoveWins"
                    base = self.interner.intern("SharedSet_RemoveWins");
                } else if self.check(&TokenType::AddWins) {
                    self.advance(); // consume "AddWins"
                    // AddWins is default, but we can be explicit
                    base = self.interner.intern("SharedSet_AddWins");
                }
                if !self.check(&TokenType::RParen) {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedKeyword { keyword: ")".to_string() },
                        span: self.current_span(),
                    });
                }
                self.advance(); // consume ")"
            }
        }

        // Phase 49c: Check for algorithm modifier on SharedSequence: "SharedSequence (YATA) of T"
        let base_name = self.interner.resolve(base);
        if base_name == "SharedSequence" || base_name == "RGA" {
            if self.check(&TokenType::LParen) {
                self.advance(); // consume "("
                if self.check(&TokenType::YATA) {
                    self.advance(); // consume "YATA"
                    base = self.interner.intern("SharedSequence_YATA");
                }
                if !self.check(&TokenType::RParen) {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedKeyword { keyword: ")".to_string() },
                        span: self.current_span(),
                    });
                }
                self.advance(); // consume ")"
            }
        }

        // Phase 36: Check for "from Module" qualification
        let base_type = if self.check(&TokenType::From) {
            self.advance(); // consume "from"
            let module_name = self.consume_type_name()?;
            let module_str = self.interner.resolve(module_name);
            let base_str = self.interner.resolve(base);
            let qualified = format!("{}::{}", module_str, base_str);
            let qualified_sym = self.interner.intern(&qualified);
            TypeExpr::Named(qualified_sym)
        } else {
            // Phase 38: Get param count from registry OR from built-in std types
            let base_name = self.interner.resolve(base);
            let param_count = self.get_generic_param_count(base)
                .or_else(|| match base_name {
                    // Built-in generic types for Phase 38 std library
                    "Result" => Some(2),    // Result of T and E
                    "Option" => Some(1),    // Option of T
                    "Seq" | "List" | "Vec" => Some(1),  // Seq of T
                    "Set" | "HashSet" => Some(1), // Set of T
                    "Map" | "HashMap" => Some(2), // Map of K and V
                    "Pair" => Some(2),      // Pair of A and B
                    "Triple" => Some(3),    // Triple of A and B and C
                    // Phase 49b: CRDT generic types
                    "SharedSet" | "ORSet" | "SharedSet_AddWins" | "SharedSet_RemoveWins" => Some(1),
                    "SharedSequence" | "RGA" | "SharedSequence_YATA" | "CollaborativeSequence" => Some(1),
                    "SharedMap" | "ORMap" => Some(2),      // SharedMap from K to V
                    "Divergent" | "MVRegister" => Some(1), // Divergent T
                    _ => None,
                });

            // Check if it's a known generic type with parameters
            if let Some(count) = param_count {
                if self.check_of_preposition() || self.check_preposition_is("from") {
                    self.advance(); // consume "of" or "from"

                    let mut params = Vec::new();
                    for i in 0..count {
                        if i > 0 {
                            // Expect separator for params > 1: "and", "to", or ","
                            if self.check(&TokenType::And) || self.check_to_preposition() || self.check(&TokenType::Comma) {
                                self.advance();
                            }
                        }
                        let param = self.parse_type_expression()?;
                        params.push(param);
                    }

                    let params_slice = self.ctx.alloc_type_exprs(params);
                    TypeExpr::Generic { base, params: params_slice }
                } else {
                    // Generic type without parameters - treat as primitive or named
                    let is_primitive = self.type_registry.as_ref().map(|r| r.is_type(base)).unwrap_or(false)
                        || matches!(base_name, "Int" | "Nat" | "Text" | "Bool" | "Boolean" | "Real" | "Unit");
                    if is_primitive {
                        TypeExpr::Primitive(base)
                    } else {
                        TypeExpr::Named(base)
                    }
                }
            } else {
                // Check if it's a known primitive type (Int, Nat, Text, Bool, Real, Unit)
                let is_primitive = self.type_registry.as_ref().map(|r| r.is_type(base)).unwrap_or(false)
                    || matches!(base_name, "Int" | "Nat" | "Text" | "Bool" | "Boolean" | "Real" | "Unit");
                if is_primitive {
                    TypeExpr::Primitive(base)
                } else {
                    // User-defined or unknown type
                    TypeExpr::Named(base)
                }
            }
        };

        // Phase 43C: Check for refinement "where" clause
        if self.check(&TokenType::Where) {
            self.advance(); // consume "where"

            // Parse the predicate expression (supports compound: `x > 0 and x < 100`)
            let predicate_expr = self.parse_condition()?;

            // Extract bound variable from the left side of the expression
            let bound_var = self.extract_bound_var(&predicate_expr)
                .unwrap_or_else(|| self.interner.intern("it"));

            // Convert imperative Expr to logic LogicExpr
            let predicate = self.expr_to_logic_predicate(&predicate_expr, bound_var)
                .ok_or_else(|| ParseError {
                    kind: ParseErrorKind::InvalidRefinementPredicate,
                    span: self.peek().span,
                })?;

            // Allocate the base type
            let base_alloc = self.ctx.alloc_type_expr(base_type);

            return Ok(TypeExpr::Refinement { base: base_alloc, var: bound_var, predicate });
        }

        Ok(base_type)
    }

    /// Extracts the leftmost identifier from an expression as the bound variable.
    fn extract_bound_var(&self, expr: &Expr<'a>) -> Option<Symbol> {
        match expr {
            Expr::Identifier(sym) => Some(*sym),
            Expr::BinaryOp { left, .. } => self.extract_bound_var(left),
            _ => None,
        }
    }

    /// Converts an imperative comparison Expr to a Logic Kernel LogicExpr.
    /// Used for refinement type predicates: `Int where x > 0`
    fn expr_to_logic_predicate(&mut self, expr: &Expr<'a>, bound_var: Symbol) -> Option<&'a LogicExpr<'a>> {
        match expr {
            Expr::BinaryOp { op, left, right } => {
                // Map BinaryOpKind to predicate name
                let pred_name = match op {
                    BinaryOpKind::Gt => "Greater",
                    BinaryOpKind::Lt => "Less",
                    BinaryOpKind::GtEq => "GreaterEqual",
                    BinaryOpKind::LtEq => "LessEqual",
                    BinaryOpKind::Eq => "Equal",
                    BinaryOpKind::NotEq => "NotEqual",
                    BinaryOpKind::And => {
                        // Handle compound `x > 0 and x < 100`
                        let left_logic = self.expr_to_logic_predicate(left, bound_var)?;
                        let right_logic = self.expr_to_logic_predicate(right, bound_var)?;
                        return Some(self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: left_logic,
                            op: TokenType::And,
                            right: right_logic,
                        }));
                    }
                    BinaryOpKind::Or => {
                        let left_logic = self.expr_to_logic_predicate(left, bound_var)?;
                        let right_logic = self.expr_to_logic_predicate(right, bound_var)?;
                        return Some(self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: left_logic,
                            op: TokenType::Or,
                            right: right_logic,
                        }));
                    }
                    _ => return None, // Arithmetic ops not valid as predicates
                };
                let pred_sym = self.interner.intern(pred_name);

                // Convert operands to Terms
                let left_term = self.expr_to_term(left)?;
                let right_term = self.expr_to_term(right)?;

                let args = self.ctx.terms.alloc_slice([left_term, right_term]);
                Some(self.ctx.exprs.alloc(LogicExpr::Predicate { name: pred_sym, args }))
            }
            _ => None,
        }
    }

    /// Converts an imperative Expr to a logic Term.
    fn expr_to_term(&mut self, expr: &Expr<'a>) -> Option<Term<'a>> {
        match expr {
            Expr::Identifier(sym) => Some(Term::Variable(*sym)),
            Expr::Literal(lit) => {
                match lit {
                    Literal::Number(n) => Some(Term::Value {
                        kind: NumberKind::Integer(*n),
                        unit: None,
                        dimension: None,
                    }),
                    Literal::Boolean(b) => {
                        let sym = self.interner.intern(if *b { "true" } else { "false" });
                        Some(Term::Constant(sym))
                    }
                    _ => None, // Text, Nothing not supported in predicates
                }
            }
            _ => None,
        }
    }

    pub fn process_block_headers(&mut self) {
        use crate::token::BlockType;

        while self.current < self.tokens.len() {
            if let TokenType::BlockHeader { block_type } = &self.tokens[self.current].kind {
                self.mode = match block_type {
                    BlockType::Main | BlockType::Function => ParserMode::Imperative,
                    BlockType::Theorem | BlockType::Definition | BlockType::Proof |
                    BlockType::Example | BlockType::Logic | BlockType::Note | BlockType::TypeDef |
                    BlockType::Policy => ParserMode::Declarative,
                };
                self.current += 1;
            } else {
                break;
            }
        }
    }

    pub fn get_event_var(&mut self) -> Symbol {
        self.discourse_event_var.unwrap_or_else(|| self.interner.intern("e"))
    }

    pub fn capture_event_template(&mut self, verb: Symbol, roles: &[(ThematicRole, Term<'a>)], modifiers: &[Symbol]) {
        let non_agent_roles: Vec<_> = roles.iter()
            .filter(|(role, _)| *role != ThematicRole::Agent)
            .cloned()
            .collect();
        self.last_event_template = Some(EventTemplate {
            verb,
            non_agent_roles,
            modifiers: modifiers.to_vec(),
        });
    }

    fn parse_embedded_wh_clause(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        // Parse embedded question body: "who runs", "what John ate"
        let var_name = self.interner.intern("x");
        let var_term = Term::Variable(var_name);

        if self.check_verb() {
            // "who runs" pattern
            let verb = self.consume_verb();
            let body = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice([var_term]),
            });
            return Ok(body);
        }

        if self.check_content_word() || self.check_article() {
            // "what John ate" pattern
            let subject = self.parse_noun_phrase(true)?;
            if self.check_verb() {
                let verb = self.consume_verb();
                let body = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb,
                    args: self.ctx.terms.alloc_slice([
                        Term::Constant(subject.noun),
                        var_term,
                    ]),
                });
                return Ok(body);
            }
        }

        // Fallback: just the wh-variable
        Ok(self.ctx.exprs.alloc(LogicExpr::Atom(var_name)))
    }

    pub fn set_pp_attachment_mode(&mut self, attach_to_noun: bool) {
        self.pp_attach_to_noun = attach_to_noun;
    }

    fn checkpoint(&self) -> ParserCheckpoint {
        ParserCheckpoint {
            pos: self.current,
            var_counter: self.var_counter,
            bindings_len: self.donkey_bindings.len(),
            island: self.current_island,
            time: self.pending_time,
            negative_depth: self.negative_depth,
        }
    }

    fn restore(&mut self, cp: ParserCheckpoint) {
        self.current = cp.pos;
        self.var_counter = cp.var_counter;
        self.donkey_bindings.truncate(cp.bindings_len);
        self.current_island = cp.island;
        self.pending_time = cp.time;
        self.negative_depth = cp.negative_depth;
    }

    fn is_negative_context(&self) -> bool {
        self.negative_depth % 2 == 1
    }

    pub fn guard(&mut self) -> ParserGuard<'_, 'a, 'ctx, 'int> {
        ParserGuard {
            checkpoint: self.checkpoint(),
            parser: self,
            committed: false,
        }
    }

    pub(super) fn try_parse<F, T>(&mut self, op: F) -> Option<T>
    where
        F: FnOnce(&mut Self) -> ParseResult<T>,
    {
        let cp = self.checkpoint();
        match op(self) {
            Ok(res) => Some(res),
            Err(_) => {
                self.restore(cp);
                None
            }
        }
    }

    fn register_entity(&mut self, symbol: &str, noun_class: &str, gender: Gender, number: Number) {
        use crate::context::OwnershipState;
        if let Some(ref mut ctx) = self.context {
            ctx.register(Entity {
                symbol: symbol.to_string(),
                gender,
                number,
                noun_class: noun_class.to_string(),
                ownership: OwnershipState::Owned,
            });
        }
    }

    fn resolve_pronoun(&mut self, gender: Gender, number: Number) -> Option<Symbol> {
        self.context
            .as_ref()
            .and_then(|ctx| ctx.resolve_pronoun(gender, number))
            .map(|e| e.symbol.clone())
            .map(|s| self.interner.intern(&s))
    }

    fn resolve_donkey_pronoun(&mut self, gender: Gender) -> Option<Symbol> {
        for (noun_class, var_name, used, _wide_neg) in self.donkey_bindings.iter_mut().rev() {
            let noun_str = self.interner.resolve(*noun_class);
            let noun_gender = Self::infer_noun_gender(noun_str);
            if noun_gender == gender || gender == Gender::Neuter || noun_gender == Gender::Unknown {
                *used = true; // Mark as used by a pronoun (donkey anaphor)
                return Some(*var_name);
            }
        }
        None
    }

    fn infer_noun_gender(noun: &str) -> Gender {
        let lower = noun.to_lowercase();
        if lexicon::is_female_noun(&lower) {
            Gender::Female
        } else if lexicon::is_male_noun(&lower) {
            Gender::Male
        } else {
            Gender::Unknown
        }
    }

    fn is_plural_noun(noun: &str) -> bool {
        let lower = noun.to_lowercase();
        if lexicon::is_irregular_plural(&lower) {
            return true;
        }
        lower.ends_with('s') && !lower.ends_with("ss") && lower.len() > 2
    }

    fn singularize_noun(noun: &str) -> String {
        let lower = noun.to_lowercase();
        if let Some(singular) = lexicon::singularize(&lower) {
            return singular.to_string();
        }
        if lower.ends_with('s') && !lower.ends_with("ss") && lower.len() > 2 {
            let base = &lower[..lower.len() - 1];
            let mut chars: Vec<char> = base.chars().collect();
            if !chars.is_empty() {
                chars[0] = chars[0].to_uppercase().next().unwrap();
            }
            return chars.into_iter().collect();
        }
        let mut chars: Vec<char> = lower.chars().collect();
        if !chars.is_empty() {
            chars[0] = chars[0].to_uppercase().next().unwrap();
        }
        chars.into_iter().collect()
    }

    fn infer_gender(name: &str) -> Gender {
        let lower = name.to_lowercase();
        if lexicon::is_male_name(&lower) {
            Gender::Male
        } else if lexicon::is_female_name(&lower) {
            Gender::Female
        } else {
            Gender::Unknown
        }
    }


    fn next_var_name(&mut self) -> Symbol {
        const VARS: &[&str] = &["x", "y", "z", "w", "v", "u"];
        let idx = self.var_counter;
        self.var_counter += 1;
        if idx < VARS.len() {
            self.interner.intern(VARS[idx])
        } else {
            let name = format!("x{}", idx - VARS.len() + 1);
            self.interner.intern(&name)
        }
    }

    pub fn parse(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let mut result = self.parse_sentence()?;

        // Loop: handle ANY number of additional sentences (unlimited)
        // Handle all sentence terminators: . ? !
        while self.check(&TokenType::Period) || self.check(&TokenType::Exclamation) {
            self.advance(); // consume terminator
            if !self.is_at_end() {
                let next = self.parse_sentence()?;
                result = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: result,
                    op: TokenType::And,
                    right: next,
                });
            }
        }

        Ok(result)
    }

    pub fn parse_program(&mut self) -> ParseResult<Vec<Stmt<'a>>> {
        let mut statements = Vec::new();
        let mut in_definition_block = false;

        // Check if we started in a Definition block (from process_block_headers)
        if self.mode == ParserMode::Declarative {
            // Check if the previous token was a Definition header
            // For now, assume Definition blocks should be skipped
            // We'll detect them by checking the content pattern
        }

        while !self.is_at_end() {
            // Handle block headers
            if let Some(Token { kind: TokenType::BlockHeader { block_type }, .. }) = self.tokens.get(self.current) {
                match block_type {
                    BlockType::Definition => {
                        in_definition_block = true;
                        self.mode = ParserMode::Declarative;
                        self.advance();
                        continue;
                    }
                    BlockType::Main => {
                        in_definition_block = false;
                        self.mode = ParserMode::Imperative;
                        self.advance();
                        continue;
                    }
                    BlockType::Function => {
                        in_definition_block = false;
                        self.mode = ParserMode::Imperative;
                        self.advance();
                        // Parse function definition
                        let func_def = self.parse_function_def()?;
                        statements.push(func_def);
                        continue;
                    }
                    BlockType::TypeDef => {
                        // Type definitions are handled by DiscoveryPass
                        // Skip content until next block header
                        self.advance();
                        self.skip_type_def_content();
                        continue;
                    }
                    BlockType::Policy => {
                        // Phase 50: Policy definitions are handled by DiscoveryPass
                        // Skip content until next block header
                        in_definition_block = true;  // Reuse flag to skip content
                        self.mode = ParserMode::Declarative;
                        self.advance();
                        continue;
                    }
                    _ => {
                        in_definition_block = false;
                        self.mode = ParserMode::Declarative;
                        self.advance();
                        continue;
                    }
                }
            }

            // Skip Definition block content - handled by DiscoveryPass
            if in_definition_block {
                self.advance();
                continue;
            }

            // Skip indent/dedent/newline tokens at program level
            if self.check(&TokenType::Indent) || self.check(&TokenType::Dedent) || self.check(&TokenType::Newline) {
                self.advance();
                continue;
            }

            // In imperative mode, parse statements
            if self.mode == ParserMode::Imperative {
                let stmt = self.parse_statement()?;
                statements.push(stmt);

                if self.check(&TokenType::Period) {
                    self.advance();
                }
            } else {
                // In declarative mode (Theorem, etc.), skip for now
                self.advance();
            }
        }

        Ok(statements)
    }

    fn parse_statement(&mut self) -> ParseResult<Stmt<'a>> {
        // Phase 32: Function definitions can appear inside Main block
        // Handle both TokenType::To and Preposition("to")
        if self.check(&TokenType::To) || self.check_preposition_is("to") {
            return self.parse_function_def();
        }
        if self.check(&TokenType::Let) {
            return self.parse_let_statement();
        }
        if self.check(&TokenType::Set) {
            return self.parse_set_statement();
        }
        if self.check(&TokenType::Return) {
            return self.parse_return_statement();
        }
        if self.check(&TokenType::If) {
            return self.parse_if_statement();
        }
        if self.check(&TokenType::Assert) {
            return self.parse_assert_statement();
        }
        // Phase 35: Trust statement
        if self.check(&TokenType::Trust) {
            return self.parse_trust_statement();
        }
        // Phase 50: Security Check statement
        if self.check(&TokenType::Check) {
            return self.parse_check_statement();
        }
        // Phase 51: P2P Networking statements
        if self.check(&TokenType::Listen) {
            return self.parse_listen_statement();
        }
        if self.check(&TokenType::NetConnect) {
            return self.parse_connect_statement();
        }
        if self.check(&TokenType::Sleep) {
            return self.parse_sleep_statement();
        }
        // Phase 52: GossipSub sync statement
        if self.check(&TokenType::Sync) {
            return self.parse_sync_statement();
        }
        // Phase 53: Persistent storage mount statement
        if self.check(&TokenType::Mount) {
            return self.parse_mount_statement();
        }
        if self.check(&TokenType::While) {
            return self.parse_while_statement();
        }
        if self.check(&TokenType::Repeat) {
            return self.parse_repeat_statement();
        }
        if self.check(&TokenType::Call) {
            return self.parse_call_statement();
        }
        if self.check(&TokenType::Give) {
            return self.parse_give_statement();
        }
        if self.check(&TokenType::Show) {
            return self.parse_show_statement();
        }
        // Phase 33: Pattern matching on sum types
        if self.check(&TokenType::Inspect) {
            return self.parse_inspect_statement();
        }

        // Phase 43D: Collection operations
        if self.check(&TokenType::Push) {
            return self.parse_push_statement();
        }
        if self.check(&TokenType::Pop) {
            return self.parse_pop_statement();
        }
        // Set operations
        if self.check(&TokenType::Add) {
            return self.parse_add_statement();
        }
        if self.check(&TokenType::Remove) {
            return self.parse_remove_statement();
        }

        // Phase 8.5: Memory zone block
        if self.check(&TokenType::Inside) {
            return self.parse_zone_statement();
        }

        // Phase 9: Structured Concurrency blocks
        if self.check(&TokenType::Attempt) {
            return self.parse_concurrent_block();
        }
        if self.check(&TokenType::Simultaneously) {
            return self.parse_parallel_block();
        }

        // Phase 10: IO statements
        if self.check(&TokenType::Read) {
            return self.parse_read_statement();
        }
        if self.check(&TokenType::Write) {
            return self.parse_write_statement();
        }

        // Phase 46: Agent System statements
        if self.check(&TokenType::Spawn) {
            return self.parse_spawn_statement();
        }
        if self.check(&TokenType::Send) {
            // Phase 54: Disambiguate "Send x into pipe" vs "Send x to agent"
            if self.lookahead_contains_into() {
                return self.parse_send_pipe_statement();
            }
            return self.parse_send_statement();
        }
        if self.check(&TokenType::Await) {
            // Phase 54: Disambiguate "Await the first of:" vs "Await response from agent"
            if self.lookahead_is_first_of() {
                return self.parse_select_statement();
            }
            return self.parse_await_statement();
        }

        // Phase 49: CRDT statements
        if self.check(&TokenType::Merge) {
            return self.parse_merge_statement();
        }
        if self.check(&TokenType::Increase) {
            return self.parse_increase_statement();
        }
        // Phase 49b: Extended CRDT statements
        if self.check(&TokenType::Decrease) {
            return self.parse_decrease_statement();
        }
        if self.check(&TokenType::Append) {
            return self.parse_append_statement();
        }
        if self.check(&TokenType::Resolve) {
            return self.parse_resolve_statement();
        }

        // Phase 54: Go-like Concurrency statements
        if self.check(&TokenType::Launch) {
            return self.parse_launch_statement();
        }
        if self.check(&TokenType::Stop) {
            return self.parse_stop_statement();
        }
        if self.check(&TokenType::Try) {
            return self.parse_try_statement();
        }
        if self.check(&TokenType::Receive) {
            return self.parse_receive_pipe_statement();
        }

        // Expression-statement: function call without "Call" keyword
        // e.g., `greet("Alice").` instead of `Call greet with "Alice".`
        // Check if next token is LParen (indicating a function call)
        if self.tokens.get(self.current + 1)
            .map(|t| matches!(t.kind, TokenType::LParen))
            .unwrap_or(false)
        {
            // Get the function name from current token
            let function = self.peek().lexeme;
            self.advance(); // consume function name

            // Parse the call expression (starts from LParen)
            let expr = self.parse_call_expr(function)?;
            if let Expr::Call { function, args } = expr {
                return Ok(Stmt::Call { function: *function, args: args.clone() });
            }
        }

        Err(ParseError {
            kind: ParseErrorKind::ExpectedStatement,
            span: self.current_span(),
        })
    }

    fn parse_if_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "If"

        // Parse condition expression (simple: identifier equals value)
        let cond = self.parse_condition()?;

        // Expect colon
        if !self.check(&TokenType::Colon) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume ":"

        // Expect indent
        if !self.check(&TokenType::Indent) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedStatement,
                span: self.current_span(),
            });
        }
        self.advance(); // consume Indent

        // Parse then block
        let mut then_stmts = Vec::new();
        while !self.check(&TokenType::Dedent) && !self.is_at_end() {
            let stmt = self.parse_statement()?;
            then_stmts.push(stmt);
            if self.check(&TokenType::Period) {
                self.advance();
            }
        }

        // Consume dedent
        if self.check(&TokenType::Dedent) {
            self.advance();
        }

        // Allocate then_block in arena
        let then_block = self.ctx.stmts.expect("imperative arenas not initialized")
            .alloc_slice(then_stmts.into_iter());

        // Check for Otherwise: block
        let else_block = if self.check(&TokenType::Otherwise) {
            self.advance(); // consume "Otherwise"

            if !self.check(&TokenType::Colon) {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance(); // consume ":"

            if !self.check(&TokenType::Indent) {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedStatement,
                    span: self.current_span(),
                });
            }
            self.advance(); // consume Indent

            let mut else_stmts = Vec::new();
            while !self.check(&TokenType::Dedent) && !self.is_at_end() {
                let stmt = self.parse_statement()?;
                else_stmts.push(stmt);
                if self.check(&TokenType::Period) {
                    self.advance();
                }
            }

            if self.check(&TokenType::Dedent) {
                self.advance();
            }

            Some(self.ctx.stmts.expect("imperative arenas not initialized")
                .alloc_slice(else_stmts.into_iter()))
        } else {
            None
        };

        Ok(Stmt::If {
            cond,
            then_block,
            else_block,
        })
    }

    fn parse_while_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "While"

        let cond = self.parse_condition()?;

        // Phase 44: Parse optional (decreasing expr)
        let decreasing = if self.check(&TokenType::LParen) {
            self.advance(); // consume '('

            // Expect "decreasing" keyword
            if !self.check_word("decreasing") {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: "decreasing".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance(); // consume "decreasing"

            let variant = self.parse_imperative_expr()?;

            if !self.check(&TokenType::RParen) {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: ")".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance(); // consume ')'

            Some(variant)
        } else {
            None
        };

        if !self.check(&TokenType::Colon) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume ":"

        if !self.check(&TokenType::Indent) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedStatement,
                span: self.current_span(),
            });
        }
        self.advance(); // consume Indent

        let mut body_stmts = Vec::new();
        while !self.check(&TokenType::Dedent) && !self.is_at_end() {
            let stmt = self.parse_statement()?;
            body_stmts.push(stmt);
            if self.check(&TokenType::Period) {
                self.advance();
            }
        }

        if self.check(&TokenType::Dedent) {
            self.advance();
        }

        let body = self.ctx.stmts.expect("imperative arenas not initialized")
            .alloc_slice(body_stmts.into_iter());

        Ok(Stmt::While { cond, body, decreasing })
    }

    fn parse_repeat_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Repeat"

        // Optional "for"
        if self.check(&TokenType::For) {
            self.advance();
        }

        // Parse loop variable (using context-aware identifier parsing)
        let var = self.expect_identifier()?;

        // Determine iteration type: "in" for collection, "from" for range
        let iterable = if self.check(&TokenType::From) || self.check_preposition_is("from") {
            self.advance(); // consume "from"
            let start = self.parse_imperative_expr()?;

            // Expect "to" (can be keyword or preposition)
            if !self.check(&TokenType::To) && !self.check_preposition_is("to") {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: "to".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance();

            let end = self.parse_imperative_expr()?;
            self.ctx.alloc_imperative_expr(Expr::Range { start, end })
        } else if self.check(&TokenType::In) || self.check_preposition_is("in") {
            self.advance(); // consume "in"
            self.parse_imperative_expr()?
        } else {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "in or from".to_string() },
                span: self.current_span(),
            });
        };

        // Expect colon
        if !self.check(&TokenType::Colon) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                span: self.current_span(),
            });
        }
        self.advance();

        // Expect indent
        if !self.check(&TokenType::Indent) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedStatement,
                span: self.current_span(),
            });
        }
        self.advance();

        // Parse body statements
        let mut body_stmts = Vec::new();
        while !self.check(&TokenType::Dedent) && !self.is_at_end() {
            let stmt = self.parse_statement()?;
            body_stmts.push(stmt);
            if self.check(&TokenType::Period) {
                self.advance();
            }
        }

        if self.check(&TokenType::Dedent) {
            self.advance();
        }

        let body = self.ctx.stmts.expect("imperative arenas not initialized")
            .alloc_slice(body_stmts.into_iter());

        Ok(Stmt::Repeat { var, iterable, body })
    }

    fn parse_call_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Call"

        // Parse function name (identifier)
        // Function names can be nouns, adjectives, or verbs (e.g., "work", "process")
        // Use the token's lexeme to match function definition casing
        let function = match &self.peek().kind {
            TokenType::Noun(sym) | TokenType::Adjective(sym) => {
                let s = *sym;
                self.advance();
                s
            }
            TokenType::Verb { .. } => {
                // Use lexeme (actual text) not lemma to preserve casing
                let s = self.peek().lexeme;
                self.advance();
                s
            }
            _ => {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedIdentifier,
                    span: self.current_span(),
                });
            }
        };

        // Expect "with" followed by arguments
        let args = if self.check_preposition_is("with") {
            self.advance(); // consume "with"
            self.parse_call_arguments()?
        } else {
            Vec::new()
        };

        Ok(Stmt::Call { function, args })
    }

    fn parse_call_arguments(&mut self) -> ParseResult<Vec<&'a Expr<'a>>> {
        let mut args = Vec::new();

        // Parse first argument
        let arg = self.parse_imperative_expr()?;
        args.push(arg);

        // Parse additional comma-separated arguments
        while self.check(&TokenType::Comma) {
            self.advance(); // consume ","
            let arg = self.parse_imperative_expr()?;
            args.push(arg);
        }

        Ok(args)
    }

    fn parse_condition(&mut self) -> ParseResult<&'a Expr<'a>> {
        // Grand Challenge: Parse compound conditions with "and" and "or"
        // "or" has lower precedence than "and"
        self.parse_or_condition()
    }

    /// Parse "or" conditions (lower precedence than "and")
    fn parse_or_condition(&mut self) -> ParseResult<&'a Expr<'a>> {
        let mut left = self.parse_and_condition()?;

        while self.check(&TokenType::Or) || self.check_word("or") {
            self.advance();
            let right = self.parse_and_condition()?;
            left = self.ctx.alloc_imperative_expr(Expr::BinaryOp {
                op: BinaryOpKind::Or,
                left,
                right,
            });
        }

        Ok(left)
    }

    /// Parse "and" conditions (higher precedence than "or")
    fn parse_and_condition(&mut self) -> ParseResult<&'a Expr<'a>> {
        let mut left = self.parse_comparison()?;

        while self.check(&TokenType::And) || self.check_word("and") {
            self.advance();
            let right = self.parse_comparison()?;
            left = self.ctx.alloc_imperative_expr(Expr::BinaryOp {
                op: BinaryOpKind::And,
                left,
                right,
            });
        }

        Ok(left)
    }

    /// Grand Challenge: Parse a single comparison expression
    fn parse_comparison(&mut self) -> ParseResult<&'a Expr<'a>> {
        // Handle unary "not" operator: "not a" or "not (x > 5)"
        if self.check(&TokenType::Not) || self.check_word("not") {
            self.advance(); // consume "not"
            let operand = self.parse_comparison()?; // recursive to handle "not not x"
            // Implement as: operand == false (since we don't have UnaryNot)
            return Ok(self.ctx.alloc_imperative_expr(Expr::BinaryOp {
                op: BinaryOpKind::Eq,
                left: operand,
                right: self.ctx.alloc_imperative_expr(Expr::Literal(Literal::Boolean(false))),
            }));
        }

        let left = self.parse_imperative_expr()?;

        // Check for comparison operators
        let op = if self.check(&TokenType::Equals) {
            self.advance();
            Some(BinaryOpKind::Eq)
        } else if self.check(&TokenType::Identity) {
            // "is equal to" was tokenized as TokenType::Identity
            self.advance();
            Some(BinaryOpKind::Eq)
        } else if self.check_word("is") {
            // Peek ahead to determine which comparison
            let saved_pos = self.current;
            self.advance(); // consume "is"

            if self.check_word("greater") {
                self.advance(); // consume "greater"
                if self.check_word("than") || self.check_preposition_is("than") {
                    self.advance(); // consume "than"
                    Some(BinaryOpKind::Gt)
                } else {
                    self.current = saved_pos;
                    None
                }
            } else if self.check_word("less") {
                self.advance(); // consume "less"
                if self.check_word("than") || self.check_preposition_is("than") {
                    self.advance(); // consume "than"
                    Some(BinaryOpKind::Lt)
                } else {
                    self.current = saved_pos;
                    None
                }
            } else if self.check_word("at") {
                self.advance(); // consume "at"
                if self.check_word("least") {
                    self.advance(); // consume "least"
                    Some(BinaryOpKind::GtEq)
                } else if self.check_word("most") {
                    self.advance(); // consume "most"
                    Some(BinaryOpKind::LtEq)
                } else {
                    self.current = saved_pos;
                    None
                }
            } else if self.check_word("not") || self.check(&TokenType::Not) {
                // "is not X" → NotEq
                self.advance(); // consume "not"
                Some(BinaryOpKind::NotEq)
            } else if self.check_word("equal") {
                // "is equal to X" → Eq
                self.advance(); // consume "equal"
                if self.check_preposition_is("to") {
                    self.advance(); // consume "to"
                    Some(BinaryOpKind::Eq)
                } else {
                    self.current = saved_pos;
                    None
                }
            } else {
                self.current = saved_pos;
                None
            }
        } else if self.check(&TokenType::Lt) {
            self.advance();
            Some(BinaryOpKind::Lt)
        } else if self.check(&TokenType::Gt) {
            self.advance();
            Some(BinaryOpKind::Gt)
        } else if self.check(&TokenType::LtEq) {
            self.advance();
            Some(BinaryOpKind::LtEq)
        } else if self.check(&TokenType::GtEq) {
            self.advance();
            Some(BinaryOpKind::GtEq)
        } else if self.check(&TokenType::EqEq) {
            self.advance();
            Some(BinaryOpKind::Eq)
        } else if self.check(&TokenType::NotEq) {
            self.advance();
            Some(BinaryOpKind::NotEq)
        } else {
            None
        };

        if let Some(op) = op {
            let right = self.parse_imperative_expr()?;
            Ok(self.ctx.alloc_imperative_expr(Expr::BinaryOp { op, left, right }))
        } else {
            Ok(left)
        }
    }

    fn parse_let_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Let"

        // Check for "mutable" keyword
        let mutable = if self.check_mutable_keyword() {
            self.advance();
            true
        } else {
            false
        };

        // Get identifier
        let var = self.expect_identifier()?;

        // Check for optional type annotation: `: Type`
        let ty = if self.check(&TokenType::Colon) {
            self.advance(); // consume ":"
            let type_expr = self.parse_type_expression()?;
            Some(self.ctx.alloc_type_expr(type_expr))
        } else {
            None
        };

        // Expect "be"
        if !self.check(&TokenType::Be) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "be".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "be"

        // Phase 53: Check for "mounted at [path]" pattern (for Persistent types)
        if self.check_word("mounted") {
            self.advance(); // consume "mounted"
            if !self.check(&TokenType::At) && !self.check_preposition_is("at") {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: "at".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance(); // consume "at"
            let path = self.parse_imperative_expr()?;
            return Ok(Stmt::Mount { var, path });
        }

        // Phase 51: Check for "a PeerAgent at [addr]" pattern
        if self.check_article() {
            let saved_pos = self.current;
            self.advance(); // consume article

            // Check if next word is "PeerAgent" (case insensitive)
            if let TokenType::Noun(sym) | TokenType::ProperName(sym) = self.peek().kind {
                let word = self.interner.resolve(sym).to_lowercase();
                if word == "peeragent" {
                    self.advance(); // consume "PeerAgent"

                    // Check for "at" keyword
                    if self.check(&TokenType::At) || self.check_preposition_is("at") {
                        self.advance(); // consume "at"

                        // Parse address expression
                        let address = self.parse_imperative_expr()?;

                        // Bind in ScopeStack if context available
                        if let Some(ctx) = self.context.as_mut() {
                            use crate::context::{Entity, Gender, Number, OwnershipState};
                            let var_name = self.interner.resolve(var).to_string();
                            ctx.register(Entity {
                                symbol: var_name.clone(),
                                gender: Gender::Neuter,
                                number: Number::Singular,
                                noun_class: var_name,
                                ownership: OwnershipState::Owned,
                            });
                        }

                        return Ok(Stmt::LetPeerAgent { var, address });
                    }
                }
            }
            // Not a PeerAgent, backtrack
            self.current = saved_pos;
        }

        // Phase 54: Check for "a Pipe of Type" pattern
        if self.check_article() {
            let saved_pos = self.current;
            self.advance(); // consume article

            if self.check(&TokenType::Pipe) {
                self.advance(); // consume "Pipe"

                // Expect "of"
                if !self.check_word("of") {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedKeyword { keyword: "of".to_string() },
                        span: self.current_span(),
                    });
                }
                self.advance(); // consume "of"

                // Parse element type
                let element_type = self.expect_identifier()?;

                // Register variable in scope
                if let Some(ctx) = self.context.as_mut() {
                    use crate::context::{Entity, Gender, Number, OwnershipState};
                    let var_name = self.interner.resolve(var).to_string();
                    ctx.register(Entity {
                        symbol: var_name.clone(),
                        gender: Gender::Neuter,
                        number: Number::Singular,
                        noun_class: "Pipe".to_string(),
                        ownership: OwnershipState::Owned,
                    });
                }

                return Ok(Stmt::CreatePipe { var, element_type, capacity: None });
            }
            // Not a Pipe, backtrack
            self.current = saved_pos;
        }

        // Phase 54: Check for "Launch a task to..." pattern (for task handles)
        if self.check(&TokenType::Launch) {
            self.advance(); // consume "Launch"

            // Expect "a"
            if !self.check_article() {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: "a".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance();

            // Expect "task"
            if !self.check(&TokenType::Task) {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: "task".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance();

            // Expect "to"
            if !self.check(&TokenType::To) && !self.check_word("to") {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: "to".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance();

            // Parse function name
            let function = self.expect_identifier()?;

            // Parse optional arguments: "with arg1, arg2"
            let args = if self.check_word("with") {
                self.advance();
                self.parse_call_arguments()?
            } else {
                vec![]
            };

            return Ok(Stmt::LaunchTaskWithHandle { handle: var, function, args });
        }

        // Parse expression value (simple: just a number for now)
        let value = self.parse_imperative_expr()?;

        // Phase 43B: Type check - verify declared type matches value type
        if let Some(declared_ty) = &ty {
            if let Some(inferred) = self.infer_literal_type(value) {
                if !self.check_type_compatibility(declared_ty, inferred) {
                    let expected = match declared_ty {
                        TypeExpr::Primitive(sym) | TypeExpr::Named(sym) => {
                            self.interner.resolve(*sym).to_string()
                        }
                        _ => "unknown".to_string(),
                    };
                    return Err(ParseError {
                        kind: ParseErrorKind::TypeMismatch {
                            expected,
                            found: inferred.to_string(),
                        },
                        span: self.current_span(),
                    });
                }
            }
        }

        // Bind in ScopeStack if context available
        if let Some(ctx) = self.context.as_mut() {
            use crate::context::{Entity, Gender, Number, OwnershipState};
            let var_name = self.interner.resolve(var).to_string();
            ctx.register(Entity {
                symbol: var_name.clone(),
                gender: Gender::Neuter,
                number: Number::Singular,
                noun_class: var_name,
                ownership: OwnershipState::Owned,
            });
        }

        Ok(Stmt::Let { var, ty, value, mutable })
    }

    fn check_mutable_keyword(&self) -> bool {
        if let TokenType::Noun(sym) | TokenType::Adjective(sym) = self.peek().kind {
            let word = self.interner.resolve(sym).to_lowercase();
            word == "mutable" || word == "mut"
        } else {
            false
        }
    }

    /// Phase 43B: Infer the type of a literal expression
    fn infer_literal_type(&self, expr: &Expr<'_>) -> Option<&'static str> {
        match expr {
            Expr::Literal(lit) => match lit {
                crate::ast::Literal::Number(_) => Some("Int"),
                crate::ast::Literal::Float(_) => Some("Real"),
                crate::ast::Literal::Text(_) => Some("Text"),
                crate::ast::Literal::Boolean(_) => Some("Bool"),
                crate::ast::Literal::Nothing => Some("Unit"),
                crate::ast::Literal::Char(_) => Some("Char"),
            },
            _ => None, // Can't infer type for non-literals yet
        }
    }

    /// Phase 43B: Check if declared type matches inferred type
    fn check_type_compatibility(&self, declared: &TypeExpr<'_>, inferred: &str) -> bool {
        match declared {
            TypeExpr::Primitive(sym) | TypeExpr::Named(sym) => {
                let declared_name = self.interner.resolve(*sym);
                // Nat and Byte are compatible with Int literals
                declared_name.eq_ignore_ascii_case(inferred)
                    || (declared_name.eq_ignore_ascii_case("Nat") && inferred == "Int")
                    || (declared_name.eq_ignore_ascii_case("Byte") && inferred == "Int")
            }
            _ => true, // For generics/functions, skip check for now
        }
    }

    fn parse_set_statement(&mut self) -> ParseResult<Stmt<'a>> {
        use crate::ast::Expr;
        self.advance(); // consume "Set"

        // Parse target - can be identifier or field access expression
        let target_expr = self.parse_imperative_expr()?;

        // Expect "to" - can be TokenType::To or Preposition("to")
        let is_to = self.check(&TokenType::To) || matches!(
            &self.peek().kind,
            TokenType::Preposition(sym) if self.interner.resolve(*sym) == "to"
        );
        if !is_to {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "to".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "to"

        // Parse expression value
        let value = self.parse_imperative_expr()?;

        // Phase 31: Handle field access targets
        // Also handle index targets: Set item N of X to Y
        match target_expr {
            Expr::FieldAccess { object, field } => {
                Ok(Stmt::SetField { object, field: *field, value })
            }
            Expr::Identifier(target) => {
                Ok(Stmt::Set { target: *target, value })
            }
            Expr::Index { collection, index } => {
                Ok(Stmt::SetIndex { collection, index, value })
            }
            _ => Err(ParseError {
                kind: ParseErrorKind::ExpectedIdentifier,
                span: self.current_span(),
            })
        }
    }

    fn parse_return_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Return"

        // Check if there's a value or just "Return."
        if self.check(&TokenType::Period) || self.is_at_end() {
            return Ok(Stmt::Return { value: None });
        }

        // Use parse_comparison to support returning comparison results like "n equals 5"
        let value = self.parse_comparison()?;
        Ok(Stmt::Return { value: Some(value) })
    }

    fn parse_assert_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Assert"

        // Optionally consume "that"
        if self.check(&TokenType::That) {
            self.advance();
        }

        // Parse condition using imperative expression parser
        // This allows syntax like "Assert that b is not 0."
        let condition = self.parse_condition()?;

        Ok(Stmt::RuntimeAssert { condition })
    }

    /// Phase 35: Parse Trust statement
    /// Syntax: Trust [that] [proposition] because [justification].
    fn parse_trust_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Trust"

        // Optionally consume "that"
        if self.check(&TokenType::That) {
            self.advance();
        }

        // Save current mode and switch to declarative for proposition parsing
        let saved_mode = self.mode;
        self.mode = ParserMode::Declarative;

        // Parse the proposition using the Logic Kernel
        let proposition = self.parse()?;

        // Restore mode
        self.mode = saved_mode;

        // Expect "because"
        if !self.check(&TokenType::Because) {
            return Err(ParseError {
                kind: ParseErrorKind::UnexpectedToken {
                    expected: TokenType::Because,
                    found: self.peek().kind.clone(),
                },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "because"

        // Parse justification (string literal)
        let justification = match &self.peek().kind {
            TokenType::StringLiteral(sym) => {
                let s = *sym;
                self.advance();
                s
            }
            _ => {
                return Err(ParseError {
                    kind: ParseErrorKind::UnexpectedToken {
                        expected: TokenType::StringLiteral(self.interner.intern("")),
                        found: self.peek().kind.clone(),
                    },
                    span: self.current_span(),
                });
            }
        };

        Ok(Stmt::Trust { proposition, justification })
    }

    /// Phase 50: Parse Check statement - mandatory security guard
    /// Syntax: Check that [subject] is [predicate].
    /// Syntax: Check that [subject] can [action] the [object].
    fn parse_check_statement(&mut self) -> ParseResult<Stmt<'a>> {
        let start_span = self.current_span();
        self.advance(); // consume "Check"

        // Optionally consume "that"
        if self.check(&TokenType::That) {
            self.advance();
        }

        // Consume optional "the"
        if matches!(self.peek().kind, TokenType::Article(_)) {
            self.advance();
        }

        // Parse subject identifier (e.g., "user")
        let subject = match &self.peek().kind {
            TokenType::Noun(sym) | TokenType::Adjective(sym) | TokenType::ProperName(sym) => {
                let s = *sym;
                self.advance();
                s
            }
            _ => {
                // Try to get an identifier
                let tok = self.peek();
                let s = tok.lexeme;
                self.advance();
                s
            }
        };

        // Determine if this is a predicate check ("is admin") or capability check ("can publish")
        let is_capability;
        let predicate;
        let object;

        if self.check(&TokenType::Is) || self.check(&TokenType::Are) {
            // Predicate check: "user is admin"
            is_capability = false;
            self.advance(); // consume "is" / "are"

            // Parse predicate name (e.g., "admin")
            predicate = match &self.peek().kind {
                TokenType::Noun(sym) | TokenType::Adjective(sym) | TokenType::ProperName(sym) => {
                    let s = *sym;
                    self.advance();
                    s
                }
                _ => {
                    let tok = self.peek();
                    let s = tok.lexeme;
                    self.advance();
                    s
                }
            };
            object = None;
        } else if self.check(&TokenType::Can) {
            // Capability check: "user can publish the document"
            is_capability = true;
            self.advance(); // consume "can"

            // Parse action (e.g., "publish", "edit", "delete")
            predicate = match &self.peek().kind {
                TokenType::Verb { lemma, .. } => {
                    let s = *lemma;
                    self.advance();
                    s
                }
                TokenType::Noun(sym) | TokenType::Adjective(sym) | TokenType::ProperName(sym) => {
                    let s = *sym;
                    self.advance();
                    s
                }
                _ => {
                    let tok = self.peek();
                    let s = tok.lexeme;
                    self.advance();
                    s
                }
            };

            // Consume optional "the"
            if matches!(self.peek().kind, TokenType::Article(_)) {
                self.advance();
            }

            // Parse object (e.g., "document")
            let obj = match &self.peek().kind {
                TokenType::Noun(sym) | TokenType::Adjective(sym) | TokenType::ProperName(sym) => {
                    let s = *sym;
                    self.advance();
                    s
                }
                _ => {
                    let tok = self.peek();
                    let s = tok.lexeme;
                    self.advance();
                    s
                }
            };
            object = Some(obj);
        } else {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "is/can".to_string() },
                span: self.current_span(),
            });
        }

        // Build source text for error message
        let source_text = if is_capability {
            let obj_name = self.interner.resolve(object.unwrap());
            let pred_name = self.interner.resolve(predicate);
            let subj_name = self.interner.resolve(subject);
            format!("{} can {} the {}", subj_name, pred_name, obj_name)
        } else {
            let pred_name = self.interner.resolve(predicate);
            let subj_name = self.interner.resolve(subject);
            format!("{} is {}", subj_name, pred_name)
        };

        Ok(Stmt::Check {
            subject,
            predicate,
            is_capability,
            object,
            source_text,
            span: start_span,
        })
    }

    /// Phase 51: Parse Listen statement - bind to network address
    /// Syntax: Listen on [address].
    fn parse_listen_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Listen"

        // Expect "on" preposition
        if !self.check_preposition_is("on") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "on".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "on"

        // Parse address expression (string literal or variable)
        let address = self.parse_imperative_expr()?;

        Ok(Stmt::Listen { address })
    }

    /// Phase 51: Parse Connect statement - dial remote peer
    /// Syntax: Connect to [address].
    fn parse_connect_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Connect"

        // Expect "to" (can be TokenType::To or preposition)
        if !self.check(&TokenType::To) && !self.check_preposition_is("to") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "to".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "to"

        // Parse address expression
        let address = self.parse_imperative_expr()?;

        Ok(Stmt::ConnectTo { address })
    }

    /// Phase 51: Parse Sleep statement - pause execution
    /// Syntax: Sleep [milliseconds].
    fn parse_sleep_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Sleep"

        // Parse milliseconds expression (number or variable)
        let milliseconds = self.parse_imperative_expr()?;

        Ok(Stmt::Sleep { milliseconds })
    }

    /// Phase 52: Parse Sync statement - automatic CRDT replication
    /// Syntax: Sync [var] on [topic].
    fn parse_sync_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Sync"

        // Parse variable name (must be an identifier)
        let var = match &self.tokens[self.current].kind {
            TokenType::ProperName(sym) | TokenType::Noun(sym) | TokenType::Adjective(sym) => {
                let s = *sym;
                self.advance();
                s
            }
            _ => {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: "variable name".to_string() },
                    span: self.current_span(),
                });
            }
        };

        // Expect "on" preposition
        if !self.check_preposition_is("on") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "on".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "on"

        // Parse topic expression (string literal or variable)
        let topic = self.parse_imperative_expr()?;

        Ok(Stmt::Sync { var, topic })
    }

    /// Phase 53: Parse Mount statement
    /// Syntax: Mount [var] at [path].
    /// Example: Mount counter at "data/counter.journal".
    fn parse_mount_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Mount"

        // Parse variable name (must be an identifier)
        let var = match &self.tokens[self.current].kind {
            TokenType::ProperName(sym) | TokenType::Noun(sym) | TokenType::Adjective(sym) => {
                let s = *sym;
                self.advance();
                s
            }
            _ => {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: "variable name".to_string() },
                    span: self.current_span(),
                });
            }
        };

        // Expect "at" keyword (TokenType::At in imperative mode)
        if !self.check(&TokenType::At) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "at".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "at"

        // Parse path expression (string literal or variable)
        let path = self.parse_imperative_expr()?;

        Ok(Stmt::Mount { var, path })
    }

    // =========================================================================
    // Phase 54: Go-like Concurrency Parser Methods
    // =========================================================================

    /// Helper: Check if lookahead contains "into" (for Send...into pipe disambiguation)
    fn lookahead_contains_into(&self) -> bool {
        for i in self.current..std::cmp::min(self.current + 5, self.tokens.len()) {
            if matches!(self.tokens[i].kind, TokenType::Into) {
                return true;
            }
        }
        false
    }

    /// Helper: Check if lookahead is "the first of" (for Await select disambiguation)
    fn lookahead_is_first_of(&self) -> bool {
        // Check for "Await the first of:"
        self.current + 3 < self.tokens.len()
            && matches!(self.tokens.get(self.current + 1), Some(t) if matches!(t.kind, TokenType::Article(_)))
            && self.tokens.get(self.current + 2)
                .map(|t| self.interner.resolve(t.lexeme).to_lowercase() == "first")
                .unwrap_or(false)
    }

    /// Phase 54: Parse Launch statement - spawn a task
    /// Syntax: Launch a task to verb(args).
    fn parse_launch_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Launch"

        // Expect "a"
        if !self.check_article() {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "a".to_string() },
                span: self.current_span(),
            });
        }
        self.advance();

        // Expect "task"
        if !self.check(&TokenType::Task) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "task".to_string() },
                span: self.current_span(),
            });
        }
        self.advance();

        // Expect "to"
        if !self.check(&TokenType::To) && !self.check_preposition_is("to") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "to".to_string() },
                span: self.current_span(),
            });
        }
        self.advance();

        // Parse function name
        let function = match &self.tokens[self.current].kind {
            TokenType::ProperName(sym) | TokenType::Noun(sym) | TokenType::Adjective(sym) => {
                let s = *sym;
                self.advance();
                s
            }
            _ => {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: "function name".to_string() },
                    span: self.current_span(),
                });
            }
        };

        // Optional arguments in parentheses or with "with" keyword
        let args = if self.check(&TokenType::LParen) {
            self.parse_call_arguments()?
        } else if self.check_word("with") {
            self.advance(); // consume "with"
            let mut args = Vec::new();
            let arg = self.parse_imperative_expr()?;
            args.push(arg);
            // Handle additional args separated by "and"
            while self.check(&TokenType::And) {
                self.advance();
                let arg = self.parse_imperative_expr()?;
                args.push(arg);
            }
            args
        } else {
            Vec::new()
        };

        Ok(Stmt::LaunchTask { function, args })
    }

    /// Phase 54: Parse Send into pipe statement
    /// Syntax: Send value into pipe.
    fn parse_send_pipe_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Send"

        // Parse value expression
        let value = self.parse_imperative_expr()?;

        // Expect "into"
        if !self.check(&TokenType::Into) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "into".to_string() },
                span: self.current_span(),
            });
        }
        self.advance();

        // Parse pipe expression
        let pipe = self.parse_imperative_expr()?;

        Ok(Stmt::SendPipe { value, pipe })
    }

    /// Phase 54: Parse Receive from pipe statement
    /// Syntax: Receive x from pipe.
    fn parse_receive_pipe_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Receive"

        // Get variable name - use expect_identifier which handles various token types
        let var = self.expect_identifier()?;

        // Expect "from"
        if !self.check(&TokenType::From) && !self.check_preposition_is("from") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "from".to_string() },
                span: self.current_span(),
            });
        }
        self.advance();

        // Parse pipe expression
        let pipe = self.parse_imperative_expr()?;

        Ok(Stmt::ReceivePipe { var, pipe })
    }

    /// Phase 54: Parse Try statement (non-blocking send/receive)
    /// Syntax: Try to send x into pipe. OR Try to receive x from pipe.
    fn parse_try_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Try"

        // Expect "to"
        if !self.check(&TokenType::To) && !self.check_preposition_is("to") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "to".to_string() },
                span: self.current_span(),
            });
        }
        self.advance();

        // Check if send or receive
        if self.check(&TokenType::Send) {
            self.advance(); // consume "Send"
            let value = self.parse_imperative_expr()?;

            if !self.check(&TokenType::Into) {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: "into".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance();

            let pipe = self.parse_imperative_expr()?;
            Ok(Stmt::TrySendPipe { value, pipe, result: None })
        } else if self.check(&TokenType::Receive) {
            self.advance(); // consume "Receive"

            let var = self.expect_identifier()?;

            if !self.check(&TokenType::From) && !self.check_preposition_is("from") {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: "from".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance();

            let pipe = self.parse_imperative_expr()?;
            Ok(Stmt::TryReceivePipe { var, pipe })
        } else {
            Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "send or receive".to_string() },
                span: self.current_span(),
            })
        }
    }

    /// Phase 54: Parse Stop statement
    /// Syntax: Stop handle.
    fn parse_stop_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Stop"

        let handle = self.parse_imperative_expr()?;

        Ok(Stmt::StopTask { handle })
    }

    /// Phase 54: Parse Select statement
    /// Syntax:
    /// Await the first of:
    ///     Receive x from pipe:
    ///         ...
    ///     After N seconds:
    ///         ...
    fn parse_select_statement(&mut self) -> ParseResult<Stmt<'a>> {
        use crate::ast::stmt::SelectBranch;

        self.advance(); // consume "Await"

        // Expect "the"
        if !self.check_article() {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "the".to_string() },
                span: self.current_span(),
            });
        }
        self.advance();

        // Expect "first"
        if !self.check_word("first") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "first".to_string() },
                span: self.current_span(),
            });
        }
        self.advance();

        // Expect "of"
        if !self.check_preposition_is("of") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "of".to_string() },
                span: self.current_span(),
            });
        }
        self.advance();

        // Expect colon
        if !self.check(&TokenType::Colon) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                span: self.current_span(),
            });
        }
        self.advance();

        // Expect indent
        if !self.check(&TokenType::Indent) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedStatement,
                span: self.current_span(),
            });
        }
        self.advance();

        // Parse branches
        let mut branches = Vec::new();
        while !self.check(&TokenType::Dedent) && !self.is_at_end() {
            let branch = self.parse_select_branch()?;
            branches.push(branch);
        }

        // Consume dedent
        if self.check(&TokenType::Dedent) {
            self.advance();
        }

        Ok(Stmt::Select { branches })
    }

    /// Phase 54: Parse a single select branch
    fn parse_select_branch(&mut self) -> ParseResult<crate::ast::stmt::SelectBranch<'a>> {
        use crate::ast::stmt::SelectBranch;

        if self.check(&TokenType::Receive) {
            self.advance(); // consume "Receive"

            let var = match &self.tokens[self.current].kind {
                TokenType::ProperName(sym) | TokenType::Noun(sym) | TokenType::Adjective(sym) => {
                    let s = *sym;
                    self.advance();
                    s
                }
                _ => {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedKeyword { keyword: "variable name".to_string() },
                        span: self.current_span(),
                    });
                }
            };

            if !self.check(&TokenType::From) && !self.check_preposition_is("from") {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: "from".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance();

            let pipe = self.parse_imperative_expr()?;

            // Expect colon
            if !self.check(&TokenType::Colon) {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance();

            // Parse body
            let body = self.parse_indented_block()?;

            Ok(SelectBranch::Receive { var, pipe, body })
        } else if self.check_word("after") {
            self.advance(); // consume "After"

            let milliseconds = self.parse_imperative_expr()?;

            // Skip "seconds" or "milliseconds" if present
            if self.check_word("seconds") || self.check_word("milliseconds") {
                self.advance();
            }

            // Expect colon
            if !self.check(&TokenType::Colon) {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance();

            // Parse body
            let body = self.parse_indented_block()?;

            Ok(SelectBranch::Timeout { milliseconds, body })
        } else {
            Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "Receive or After".to_string() },
                span: self.current_span(),
            })
        }
    }

    /// Phase 54: Parse an indented block of statements
    fn parse_indented_block(&mut self) -> ParseResult<crate::ast::stmt::Block<'a>> {
        // Expect indent
        if !self.check(&TokenType::Indent) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedStatement,
                span: self.current_span(),
            });
        }
        self.advance();

        let mut stmts = Vec::new();
        while !self.check(&TokenType::Dedent) && !self.is_at_end() {
            let stmt = self.parse_statement()?;
            stmts.push(stmt);
            if self.check(&TokenType::Period) {
                self.advance();
            }
        }

        // Consume dedent
        if self.check(&TokenType::Dedent) {
            self.advance();
        }

        let block = self.ctx.stmts.expect("imperative arenas not initialized")
            .alloc_slice(stmts.into_iter());

        Ok(block)
    }

    fn parse_give_statement(&mut self) -> ParseResult<Stmt<'a>> {
        use crate::context::OwnershipState;

        self.advance(); // consume "Give"

        // Parse the object being given: "x" or "the data"
        let object = self.parse_imperative_expr()?;

        // Expect "to" preposition
        if !self.check_preposition_is("to") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "to".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "to"

        // Parse the recipient: "processor" or "the console"
        let recipient = self.parse_imperative_expr()?;

        // CRITICAL: Mark the object as Moved in the ownership tracker
        if let Expr::Identifier(sym) = *object {
            if let Some(ctx) = self.context.as_mut() {
                let name = self.interner.resolve(sym);
                ctx.set_ownership(name, OwnershipState::Moved);
            }
        }

        Ok(Stmt::Give { object, recipient })
    }

    fn parse_show_statement(&mut self) -> ParseResult<Stmt<'a>> {
        use crate::context::OwnershipState;

        self.advance(); // consume "Show"

        // Parse the object being shown - use parse_condition to support
        // comparisons (x is less than y) and boolean operators (a and b)
        let object = self.parse_condition()?;

        // Optional "to" preposition - if not present, default to "show" function
        let recipient = if self.check_preposition_is("to") {
            self.advance(); // consume "to"

            // Phase 10: "Show x to console." or "Show x to the console."
            // is idiomatic for printing to stdout - use default show function
            if self.check_article() {
                self.advance(); // skip "the"
            }
            if self.check(&TokenType::Console) {
                self.advance(); // consume "console"
                let show_sym = self.interner.intern("show");
                self.ctx.alloc_imperative_expr(Expr::Identifier(show_sym))
            } else {
                // Parse the recipient: custom function
                self.parse_imperative_expr()?
            }
        } else {
            // Default recipient: the runtime "show" function
            let show_sym = self.interner.intern("show");
            self.ctx.alloc_imperative_expr(Expr::Identifier(show_sym))
        };

        // Mark the object as Borrowed (NOT Moved - still accessible)
        if let Expr::Identifier(sym) = *object {
            if let Some(ctx) = self.context.as_mut() {
                let name = self.interner.resolve(sym);
                ctx.set_ownership(name, OwnershipState::Borrowed);
            }
        }

        Ok(Stmt::Show { object, recipient })
    }

    /// Phase 43D: Parse Push statement for collection operations
    /// Syntax: Push x to items.
    fn parse_push_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Push"

        // Parse the value being pushed
        let value = self.parse_imperative_expr()?;

        // Expect "to" preposition
        if !self.check_preposition_is("to") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "to".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "to"

        // Parse the collection
        let collection = self.parse_imperative_expr()?;

        Ok(Stmt::Push { value, collection })
    }

    /// Phase 43D: Parse Pop statement for collection operations
    /// Syntax: Pop from items. OR Pop from items into y.
    fn parse_pop_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Pop"

        // Expect "from" - can be keyword token or preposition
        if !self.check(&TokenType::From) && !self.check_preposition_is("from") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "from".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "from"

        // Parse the collection
        let collection = self.parse_imperative_expr()?;

        // Check for optional "into" binding (can be Into keyword or preposition)
        let into = if self.check(&TokenType::Into) || self.check_preposition_is("into") {
            self.advance(); // consume "into"

            // Parse variable name
            if let TokenType::Noun(sym) | TokenType::ProperName(sym) = &self.peek().kind {
                let sym = *sym;
                self.advance();
                Some(sym)
            } else if let Some(token) = self.tokens.get(self.current) {
                // Also handle identifier-like tokens
                let sym = token.lexeme;
                self.advance();
                Some(sym)
            } else {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedIdentifier,
                    span: self.current_span(),
                });
            }
        } else {
            None
        };

        Ok(Stmt::Pop { collection, into })
    }

    /// Parse Add statement for Set insertion
    /// Syntax: Add x to set.
    fn parse_add_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Add"

        // Parse the value to add
        let value = self.parse_imperative_expr()?;

        // Expect "to" preposition
        if !self.check_preposition_is("to") && !self.check(&TokenType::To) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "to".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "to"

        // Parse the collection expression
        let collection = self.parse_imperative_expr()?;

        Ok(Stmt::Add { value, collection })
    }

    /// Parse Remove statement for Set deletion
    /// Syntax: Remove x from set.
    fn parse_remove_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Remove"

        // Parse the value to remove
        let value = self.parse_imperative_expr()?;

        // Expect "from" preposition
        if !self.check(&TokenType::From) && !self.check_preposition_is("from") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "from".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "from"

        // Parse the collection expression
        let collection = self.parse_imperative_expr()?;

        Ok(Stmt::Remove { value, collection })
    }

    /// Phase 10: Parse Read statement for console/file input
    /// Syntax: Read <var> from the console.
    ///         Read <var> from file <path>.
    fn parse_read_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Read"

        // Get the variable name
        let var = self.expect_identifier()?;

        // Expect "from" preposition
        if !self.check(&TokenType::From) && !self.check_preposition_is("from") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "from".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "from"

        // Skip optional article "the"
        if self.check_article() {
            self.advance();
        }

        // Determine source: console or file
        let source = if self.check(&TokenType::Console) {
            self.advance(); // consume "console"
            ReadSource::Console
        } else if self.check(&TokenType::File) {
            self.advance(); // consume "file"
            let path = self.parse_imperative_expr()?;
            ReadSource::File(path)
        } else {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "console or file".to_string() },
                span: self.current_span(),
            });
        };

        Ok(Stmt::ReadFrom { var, source })
    }

    /// Phase 10: Parse Write statement for file output
    /// Syntax: Write <content> to file <path>.
    fn parse_write_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Write"

        // Parse the content expression
        let content = self.parse_imperative_expr()?;

        // Expect "to" preposition
        if !self.check_preposition_is("to") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "to".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "to"

        // Expect "file" keyword
        if !self.check(&TokenType::File) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "file".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "file"

        // Parse the path expression
        let path = self.parse_imperative_expr()?;

        Ok(Stmt::WriteFile { content, path })
    }

    /// Phase 8.5: Parse Zone statement for memory arena blocks
    /// Syntax variants:
    ///   - Inside a new zone called "Scratch":
    ///   - Inside a zone called "Buffer" of size 1 MB:
    ///   - Inside a zone called "Data" mapped from "file.bin":
    fn parse_zone_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Inside"

        // Optional article "a"
        if self.check_article() {
            self.advance();
        }

        // Optional "new"
        if self.check(&TokenType::New) {
            self.advance();
        }

        // Expect "zone"
        if !self.check(&TokenType::Zone) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "zone".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "zone"

        // Expect "called"
        if !self.check(&TokenType::Called) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "called".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "called"

        // Parse zone name (can be string literal or identifier)
        let name = match &self.peek().kind {
            TokenType::StringLiteral(sym) => {
                let s = *sym;
                self.advance();
                s
            }
            TokenType::ProperName(sym) | TokenType::Noun(sym) | TokenType::Adjective(sym) => {
                let s = *sym;
                self.advance();
                s
            }
            _ => {
                // Try to use the lexeme directly as an identifier
                let token = self.peek().clone();
                self.advance();
                token.lexeme
            }
        };

        let mut capacity = None;
        let mut source_file = None;

        // Check for "mapped from" (file-backed zone)
        if self.check(&TokenType::Mapped) {
            self.advance(); // consume "mapped"

            // Expect "from"
            if !self.check(&TokenType::From) && !self.check_preposition_is("from") {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: "from".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance(); // consume "from"

            // Parse file path (must be string literal)
            if let TokenType::StringLiteral(path) = &self.peek().kind {
                source_file = Some(*path);
                self.advance();
            } else {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: "file path string".to_string() },
                    span: self.current_span(),
                });
            }
        }
        // Check for "of size N Unit" (sized heap zone)
        else if self.check_of_preposition() {
            self.advance(); // consume "of"

            // Expect "size"
            if !self.check(&TokenType::Size) {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: "size".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance(); // consume "size"

            // Parse size number
            let size_value = match &self.peek().kind {
                TokenType::Number(sym) => {
                    let num_str = self.interner.resolve(*sym);
                    let val = num_str.replace('_', "").parse::<usize>().unwrap_or(0);
                    self.advance();
                    val
                }
                TokenType::Cardinal(n) => {
                    let val = *n as usize;
                    self.advance();
                    val
                }
                _ => {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedNumber,
                        span: self.current_span(),
                    });
                }
            };

            // Parse unit (KB, MB, GB, or B)
            let unit_multiplier = self.parse_size_unit()?;
            capacity = Some(size_value * unit_multiplier);
        }

        // Expect colon
        if !self.check(&TokenType::Colon) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume ":"

        // Expect indent
        if !self.check(&TokenType::Indent) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedStatement,
                span: self.current_span(),
            });
        }
        self.advance(); // consume Indent

        // Parse body statements
        let mut body_stmts = Vec::new();
        while !self.check(&TokenType::Dedent) && !self.is_at_end() {
            let stmt = self.parse_statement()?;
            body_stmts.push(stmt);
            if self.check(&TokenType::Period) {
                self.advance();
            }
        }

        // Consume dedent
        if self.check(&TokenType::Dedent) {
            self.advance();
        }

        let body = self.ctx.stmts.expect("imperative arenas not initialized")
            .alloc_slice(body_stmts.into_iter());

        Ok(Stmt::Zone { name, capacity, source_file, body })
    }

    /// Parse size unit (B, KB, MB, GB) and return multiplier
    fn parse_size_unit(&mut self) -> ParseResult<usize> {
        let token = self.peek().clone();
        let unit_str = self.interner.resolve(token.lexeme).to_uppercase();
        self.advance();

        match unit_str.as_str() {
            "B" | "BYTES" | "BYTE" => Ok(1),
            "KB" | "KILOBYTE" | "KILOBYTES" => Ok(1024),
            "MB" | "MEGABYTE" | "MEGABYTES" => Ok(1024 * 1024),
            "GB" | "GIGABYTE" | "GIGABYTES" => Ok(1024 * 1024 * 1024),
            _ => Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword {
                    keyword: "size unit (B, KB, MB, GB)".to_string(),
                },
                span: token.span,
            }),
        }
    }

    /// Phase 9: Parse concurrent execution block (async, I/O-bound)
    ///
    /// Syntax:
    /// ```logos
    /// Attempt all of the following:
    ///     Call fetch_user with id.
    ///     Call fetch_orders with id.
    /// ```
    fn parse_concurrent_block(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Attempt"

        // Expect "all"
        if !self.check(&TokenType::All) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "all".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "all"

        // Expect "of" (preposition)
        if !self.check_of_preposition() {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "of".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "of"

        // Expect "the"
        if !self.check_article() {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "the".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "the"

        // Expect "following"
        if !self.check(&TokenType::Following) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "following".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "following"

        // Expect colon
        if !self.check(&TokenType::Colon) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume ":"

        // Expect indent
        if !self.check(&TokenType::Indent) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedStatement,
                span: self.current_span(),
            });
        }
        self.advance(); // consume Indent

        // Parse body statements
        let mut task_stmts = Vec::new();
        while !self.check(&TokenType::Dedent) && !self.is_at_end() {
            let stmt = self.parse_statement()?;
            task_stmts.push(stmt);
            if self.check(&TokenType::Period) {
                self.advance();
            }
        }

        // Consume dedent
        if self.check(&TokenType::Dedent) {
            self.advance();
        }

        let tasks = self.ctx.stmts.expect("imperative arenas not initialized")
            .alloc_slice(task_stmts.into_iter());

        Ok(Stmt::Concurrent { tasks })
    }

    /// Phase 9: Parse parallel execution block (CPU-bound)
    ///
    /// Syntax:
    /// ```logos
    /// Simultaneously:
    ///     Call compute_hash with data1.
    ///     Call compute_hash with data2.
    /// ```
    fn parse_parallel_block(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Simultaneously"

        // Expect colon
        if !self.check(&TokenType::Colon) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume ":"

        // Expect indent
        if !self.check(&TokenType::Indent) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedStatement,
                span: self.current_span(),
            });
        }
        self.advance(); // consume Indent

        // Parse body statements
        let mut task_stmts = Vec::new();
        while !self.check(&TokenType::Dedent) && !self.is_at_end() {
            let stmt = self.parse_statement()?;
            task_stmts.push(stmt);
            if self.check(&TokenType::Period) {
                self.advance();
            }
        }

        // Consume dedent
        if self.check(&TokenType::Dedent) {
            self.advance();
        }

        let tasks = self.ctx.stmts.expect("imperative arenas not initialized")
            .alloc_slice(task_stmts.into_iter());

        Ok(Stmt::Parallel { tasks })
    }

    /// Phase 33: Parse Inspect statement for pattern matching
    /// Syntax: Inspect target:
    ///             If it is a Variant [(bindings)]:
    ///                 body...
    ///             Otherwise:
    ///                 body...
    fn parse_inspect_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Inspect"

        // Parse target expression
        let target = self.parse_imperative_expr()?;

        // Expect colon
        if !self.check(&TokenType::Colon) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume ":"

        // Expect indent
        if !self.check(&TokenType::Indent) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedStatement,
                span: self.current_span(),
            });
        }
        self.advance(); // consume Indent

        let mut arms = Vec::new();
        let mut has_otherwise = false;

        // Parse match arms until dedent
        while !self.check(&TokenType::Dedent) && !self.is_at_end() {
            if self.check(&TokenType::Otherwise) {
                // Parse "Otherwise:" default arm
                self.advance(); // consume "Otherwise"

                if !self.check(&TokenType::Colon) {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                        span: self.current_span(),
                    });
                }
                self.advance(); // consume ":"

                // Handle both inline (Otherwise: stmt.) and block body
                let body_stmts = if self.check(&TokenType::Indent) {
                    self.advance(); // consume Indent
                    let mut stmts = Vec::new();
                    while !self.check(&TokenType::Dedent) && !self.is_at_end() {
                        let stmt = self.parse_statement()?;
                        stmts.push(stmt);
                        if self.check(&TokenType::Period) {
                            self.advance();
                        }
                    }
                    if self.check(&TokenType::Dedent) {
                        self.advance();
                    }
                    stmts
                } else {
                    // Inline body: "Otherwise: Show x."
                    let stmt = self.parse_statement()?;
                    if self.check(&TokenType::Period) {
                        self.advance();
                    }
                    vec![stmt]
                };

                let body = self.ctx.stmts.expect("imperative arenas not initialized")
                    .alloc_slice(body_stmts.into_iter());

                arms.push(MatchArm { enum_name: None, variant: None, bindings: vec![], body });
                has_otherwise = true;
                break;
            }

            if self.check(&TokenType::If) {
                // Parse "If it is a VariantName [(bindings)]:"
                let arm = self.parse_match_arm()?;
                arms.push(arm);
            } else if self.check(&TokenType::When) || self.check_word("When") {
                // Parse "When Variant [(bindings)]:" (concise syntax)
                let arm = self.parse_when_arm()?;
                arms.push(arm);
            } else if self.check(&TokenType::Newline) {
                // Skip newlines between arms
                self.advance();
            } else {
                // Skip unexpected tokens
                self.advance();
            }
        }

        // Consume final dedent
        if self.check(&TokenType::Dedent) {
            self.advance();
        }

        Ok(Stmt::Inspect { target, arms, has_otherwise })
    }

    /// Parse a single match arm: "If it is a Variant [(field: binding)]:"
    fn parse_match_arm(&mut self) -> ParseResult<MatchArm<'a>> {
        self.advance(); // consume "If"

        // Expect "it"
        if !self.check_word("it") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "it".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "it"

        // Expect "is"
        if !self.check(&TokenType::Is) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "is".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "is"

        // Consume article "a" or "an"
        if self.check_article() {
            self.advance();
        }

        // Get variant name
        let variant = self.expect_identifier()?;

        // Look up the enum name for this variant
        let enum_name = self.find_variant(variant);

        // Optional: "(field)" or "(field: binding)" or "(f1, f2: b2)"
        let bindings = if self.check(&TokenType::LParen) {
            self.parse_pattern_bindings()?
        } else {
            vec![]
        };

        // Expect colon
        if !self.check(&TokenType::Colon) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume ":"

        // Expect indent
        if !self.check(&TokenType::Indent) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedStatement,
                span: self.current_span(),
            });
        }
        self.advance(); // consume Indent

        // Parse body statements
        let mut body_stmts = Vec::new();
        while !self.check(&TokenType::Dedent) && !self.is_at_end() {
            let stmt = self.parse_statement()?;
            body_stmts.push(stmt);
            if self.check(&TokenType::Period) {
                self.advance();
            }
        }

        // Consume dedent
        if self.check(&TokenType::Dedent) {
            self.advance();
        }

        let body = self.ctx.stmts.expect("imperative arenas not initialized")
            .alloc_slice(body_stmts.into_iter());

        Ok(MatchArm { enum_name, variant: Some(variant), bindings, body })
    }

    /// Parse a concise match arm: "When Variant [(bindings)]:" or "When Variant: stmt."
    fn parse_when_arm(&mut self) -> ParseResult<MatchArm<'a>> {
        self.advance(); // consume "When"

        // Get variant name
        let variant = self.expect_identifier()?;

        // Look up the enum name and variant definition for this variant
        let (enum_name, variant_fields) = self.type_registry
            .as_ref()
            .and_then(|r| r.find_variant(variant).map(|(enum_name, vdef)| {
                let fields: Vec<_> = vdef.fields.iter().map(|f| f.name).collect();
                (Some(enum_name), fields)
            }))
            .unwrap_or((None, vec![]));

        // Optional: "(binding)" or "(b1, b2)" - positional bindings
        let bindings = if self.check(&TokenType::LParen) {
            let raw_bindings = self.parse_when_bindings()?;
            // Map positional bindings to actual field names
            raw_bindings.into_iter().enumerate().map(|(i, binding)| {
                let field = variant_fields.get(i).copied().unwrap_or(binding);
                (field, binding)
            }).collect()
        } else {
            vec![]
        };

        // Expect colon
        if !self.check(&TokenType::Colon) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume ":"

        // Handle both inline body (When Variant: stmt.) and block body
        let body_stmts = if self.check(&TokenType::Indent) {
            self.advance(); // consume Indent
            let mut stmts = Vec::new();
            while !self.check(&TokenType::Dedent) && !self.is_at_end() {
                let stmt = self.parse_statement()?;
                stmts.push(stmt);
                if self.check(&TokenType::Period) {
                    self.advance();
                }
            }
            if self.check(&TokenType::Dedent) {
                self.advance();
            }
            stmts
        } else {
            // Inline body: "When Red: Show x."
            let stmt = self.parse_statement()?;
            if self.check(&TokenType::Period) {
                self.advance();
            }
            vec![stmt]
        };

        let body = self.ctx.stmts.expect("imperative arenas not initialized")
            .alloc_slice(body_stmts.into_iter());

        Ok(MatchArm { enum_name, variant: Some(variant), bindings, body })
    }

    /// Parse concise When bindings: "(r)" or "(w, h)" - just binding variable names
    fn parse_when_bindings(&mut self) -> ParseResult<Vec<Symbol>> {
        self.advance(); // consume '('
        let mut bindings = Vec::new();

        loop {
            let binding = self.expect_identifier()?;
            bindings.push(binding);

            if !self.check(&TokenType::Comma) {
                break;
            }
            self.advance(); // consume ','
        }

        if !self.check(&TokenType::RParen) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ")".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume ')'

        Ok(bindings)
    }

    /// Parse pattern bindings: "(field)" or "(field: binding)" or "(f1, f2: b2)"
    fn parse_pattern_bindings(&mut self) -> ParseResult<Vec<(Symbol, Symbol)>> {
        self.advance(); // consume '('
        let mut bindings = Vec::new();

        loop {
            let field = self.expect_identifier()?;
            let binding = if self.check(&TokenType::Colon) {
                self.advance(); // consume ":"
                self.expect_identifier()?
            } else {
                field // field name = binding name
            };
            bindings.push((field, binding));

            if !self.check(&TokenType::Comma) {
                break;
            }
            self.advance(); // consume ','
        }

        if !self.check(&TokenType::RParen) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ")".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume ')'

        Ok(bindings)
    }

    /// Parse constructor fields: "with field1 value1 [and field2 value2]..."
    /// Example: "with radius 10" or "with x 10 and y 20"
    /// Used for both variant constructors and struct initialization
    fn parse_constructor_fields(&mut self) -> ParseResult<Vec<(Symbol, &'a Expr<'a>)>> {
        use crate::ast::Expr;
        let mut fields = Vec::new();

        // Consume "with"
        self.advance();

        loop {
            // Parse field name
            let field_name = self.expect_identifier()?;

            // Parse field value expression
            let value = self.parse_imperative_expr()?;

            fields.push((field_name, value));

            // Check for "and" to continue
            if self.check(&TokenType::And) {
                self.advance(); // consume "and"
                continue;
            }
            break;
        }

        Ok(fields)
    }

    /// Alias for variant constructors (backwards compat)
    fn parse_variant_constructor_fields(&mut self) -> ParseResult<Vec<(Symbol, &'a Expr<'a>)>> {
        self.parse_constructor_fields()
    }

    /// Alias for struct initialization
    fn parse_struct_init_fields(&mut self) -> ParseResult<Vec<(Symbol, &'a Expr<'a>)>> {
        self.parse_constructor_fields()
    }

    /// Phase 34: Parse generic type arguments for constructor instantiation
    /// Parses "of Int" or "of Int and Text" after a generic type name
    /// Returns empty Vec for non-generic types
    fn parse_generic_type_args(&mut self, type_name: Symbol) -> ParseResult<Vec<Symbol>> {
        // Only parse type args if the type is a known generic
        if !self.is_generic_type(type_name) {
            return Ok(vec![]);
        }

        // Expect "of" preposition
        if !self.check_preposition_is("of") {
            return Ok(vec![]);  // Generic type without arguments - will use defaults
        }
        self.advance(); // consume "of"

        let mut type_args = Vec::new();
        loop {
            // Parse type argument (e.g., "Int", "Text", "User")
            let type_arg = self.expect_identifier()?;
            type_args.push(type_arg);

            // Check for "and" or "to" to continue (for multi-param generics like "Map of Text to Int")
            if self.check(&TokenType::And) || self.check_to_preposition() {
                self.advance(); // consume separator
                continue;
            }
            break;
        }

        Ok(type_args)
    }

    /// Skip type definition content until next block header
    /// Used for TypeDef blocks (## A Point has:, ## A Color is one of:)
    /// The actual parsing is done by DiscoveryPass
    fn skip_type_def_content(&mut self) {
        while !self.is_at_end() {
            // Stop at next block header
            if matches!(
                self.tokens.get(self.current),
                Some(Token { kind: TokenType::BlockHeader { .. }, .. })
            ) {
                break;
            }
            self.advance();
        }
    }

    /// Phase 32: Parse function definition after `## To` header
    /// Phase 32/38: Parse function definition
    /// Syntax: [To] [native] name (a: Type) [and (b: Type)] [-> ReturnType]
    ///         body statements... (only if not native)
    fn parse_function_def(&mut self) -> ParseResult<Stmt<'a>> {
        // Consume "To" if present (when called from parse_statement)
        if self.check(&TokenType::To) || self.check_preposition_is("to") {
            self.advance();
        }

        // Phase 38: Check for native modifier
        let is_native = if self.check(&TokenType::Native) {
            self.advance(); // consume "native"
            true
        } else {
            false
        };

        // Parse function name (first identifier after ## To [native])
        let name = self.expect_identifier()?;

        // Parse parameters: (name: Type) groups separated by "and", or comma-separated in one group
        let mut params = Vec::new();
        while self.check(&TokenType::LParen) {
            self.advance(); // consume (

            // Parse parameters in this group (possibly comma-separated)
            loop {
                let param_name = self.expect_identifier()?;

                // Expect colon
                if !self.check(&TokenType::Colon) {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                        span: self.current_span(),
                    });
                }
                self.advance(); // consume :

                // Phase 38: Parse full type expression instead of simple identifier
                let param_type_expr = self.parse_type_expression()?;
                let param_type = self.ctx.alloc_type_expr(param_type_expr);

                params.push((param_name, param_type));

                // Check for comma (more params in this group) or ) (end of group)
                if self.check(&TokenType::Comma) {
                    self.advance(); // consume ,
                    continue;
                }
                break;
            }

            // Expect )
            if !self.check(&TokenType::RParen) {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: ")".to_string() },
                    span: self.current_span(),
                });
            }
            self.advance(); // consume )

            // Check for "and", preposition, or "from" between parameter groups
            // Allows: "## To withdraw (amount: Int) from (balance: Int)"
            if self.check_word("and") || self.check_preposition() || self.check(&TokenType::From) {
                self.advance();
            }
        }

        // Phase 38: Parse optional return type -> Type
        let return_type = if self.check(&TokenType::Arrow) {
            self.advance(); // consume ->
            let ret_type_expr = self.parse_type_expression()?;
            Some(self.ctx.alloc_type_expr(ret_type_expr))
        } else {
            None
        };

        // Phase 38: Native functions have no body
        if is_native {
            // Consume trailing period or newline if present
            if self.check(&TokenType::Period) {
                self.advance();
            }
            if self.check(&TokenType::Newline) {
                self.advance();
            }

            // Return with empty body
            let empty_body = self.ctx.stmts.expect("imperative arenas not initialized")
                .alloc_slice(std::iter::empty());

            return Ok(Stmt::FunctionDef {
                name,
                params,
                body: empty_body,
                return_type,
                is_native: true,
            });
        }

        // Non-native: expect colon after parameter list / return type
        if !self.check(&TokenType::Colon) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ":".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume :

        // Expect indent for function body
        if !self.check(&TokenType::Indent) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedStatement,
                span: self.current_span(),
            });
        }
        self.advance(); // consume Indent

        // Parse body statements
        let mut body_stmts = Vec::new();
        while !self.check(&TokenType::Dedent) && !self.is_at_end() {
            // Skip newlines between statements
            if self.check(&TokenType::Newline) {
                self.advance();
                continue;
            }
            // Stop if we hit another block header
            if matches!(self.peek().kind, TokenType::BlockHeader { .. }) {
                break;
            }
            let stmt = self.parse_statement()?;
            body_stmts.push(stmt);
            if self.check(&TokenType::Period) {
                self.advance();
            }
        }

        // Consume dedent if present
        if self.check(&TokenType::Dedent) {
            self.advance();
        }

        // Allocate body in arena
        let body = self.ctx.stmts.expect("imperative arenas not initialized")
            .alloc_slice(body_stmts.into_iter());

        Ok(Stmt::FunctionDef {
            name,
            params,
            body,
            return_type,
            is_native: false,
        })
    }

    /// Parse a primary expression (literal, identifier, index, slice, list, etc.)
    fn parse_primary_expr(&mut self) -> ParseResult<&'a Expr<'a>> {
        use crate::ast::{Expr, Literal};

        let token = self.peek().clone();
        match &token.kind {
            // Phase 31: Constructor expression "new TypeName" or "a new TypeName"
            // Phase 33: Extended for variant constructors "new Circle with radius 10"
            // Phase 34: Extended for generic instantiation "new Box of Int"
            TokenType::New => {
                self.advance(); // consume "new"
                let base_type_name = self.expect_identifier()?;

                // Phase 36: Check for "from Module" qualification
                let type_name = if self.check(&TokenType::From) {
                    self.advance(); // consume "from"
                    let module_name = self.expect_identifier()?;
                    let module_str = self.interner.resolve(module_name);
                    let base_str = self.interner.resolve(base_type_name);
                    let qualified = format!("{}::{}", module_str, base_str);
                    self.interner.intern(&qualified)
                } else {
                    base_type_name
                };

                // Phase 33: Check if this is a variant constructor
                if let Some(enum_name) = self.find_variant(type_name) {
                    // Parse optional "with field value" pairs
                    let fields = if self.check_word("with") {
                        self.parse_variant_constructor_fields()?
                    } else {
                        vec![]
                    };
                    let base = self.ctx.alloc_imperative_expr(Expr::NewVariant {
                        enum_name,
                        variant: type_name,
                        fields,
                    });
                    return self.parse_field_access_chain(base);
                }

                // Phase 34: Parse generic type arguments "of Int" or "of Int and Text"
                let type_args = self.parse_generic_type_args(type_name)?;

                // Parse optional "with field value" pairs for struct initialization
                let init_fields = if self.check_word("with") {
                    self.parse_struct_init_fields()?
                } else {
                    vec![]
                };

                let base = self.ctx.alloc_imperative_expr(Expr::New { type_name, type_args, init_fields });
                return self.parse_field_access_chain(base);
            }

            // Phase 31: Handle "a new TypeName" pattern OR single-letter identifier
            // Phase 33: Extended for variant constructors "a new Circle with radius 10"
            // Phase 34: Extended for generic instantiation "a new Box of Int"
            TokenType::Article(_) => {
                // Phase 48: Check if followed by Manifest or Chunk token
                // Pattern: "the manifest of Zone" or "the chunk at N in Zone"
                if let Some(next) = self.tokens.get(self.current + 1) {
                    if matches!(next.kind, TokenType::Manifest) {
                        self.advance(); // consume "the"
                        // Delegate to Manifest handling
                        return self.parse_primary_expr();
                    }
                    if matches!(next.kind, TokenType::Chunk) {
                        self.advance(); // consume "the"
                        // Delegate to Chunk handling
                        return self.parse_primary_expr();
                    }
                }
                // Check if followed by New token
                if let Some(next) = self.tokens.get(self.current + 1) {
                    if matches!(next.kind, TokenType::New) {
                        self.advance(); // consume article "a"/"an"
                        self.advance(); // consume "new"
                        let base_type_name = self.expect_identifier()?;

                        // Phase 36: Check for "from Module" qualification
                        let type_name = if self.check(&TokenType::From) {
                            self.advance(); // consume "from"
                            let module_name = self.expect_identifier()?;
                            let module_str = self.interner.resolve(module_name);
                            let base_str = self.interner.resolve(base_type_name);
                            let qualified = format!("{}::{}", module_str, base_str);
                            self.interner.intern(&qualified)
                        } else {
                            base_type_name
                        };

                        // Phase 33: Check if this is a variant constructor
                        if let Some(enum_name) = self.find_variant(type_name) {
                            // Parse optional "with field value" pairs
                            let fields = if self.check_word("with") {
                                self.parse_variant_constructor_fields()?
                            } else {
                                vec![]
                            };
                            let base = self.ctx.alloc_imperative_expr(Expr::NewVariant {
                                enum_name,
                                variant: type_name,
                                fields,
                            });
                            return self.parse_field_access_chain(base);
                        }

                        // Phase 34: Parse generic type arguments "of Int" or "of Int and Text"
                        let type_args = self.parse_generic_type_args(type_name)?;

                        // Parse optional "with field value" pairs for struct initialization
                        let init_fields = if self.check_word("with") {
                            self.parse_struct_init_fields()?
                        } else {
                            vec![]
                        };

                        let base = self.ctx.alloc_imperative_expr(Expr::New { type_name, type_args, init_fields });
                        return self.parse_field_access_chain(base);
                    }
                }
                // Phase 32: Treat as identifier (single-letter var like "a", "b")
                let sym = token.lexeme;
                self.advance();
                let base = self.ctx.alloc_imperative_expr(Expr::Identifier(sym));
                return self.parse_field_access_chain(base);
            }

            // Index access: "item N of collection" or "item i of collection"
            TokenType::Item => {
                self.advance(); // consume "item"

                // Grand Challenge: Parse index as expression (number, identifier, or parenthesized)
                let index = if let TokenType::Number(sym) = &self.peek().kind {
                    // Literal number - check for zero index at compile time
                    let sym = *sym;
                    self.advance();
                    let num_str = self.interner.resolve(sym);
                    let index_val = num_str.parse::<i64>().unwrap_or(0);

                    // Index 0 Guard: LOGOS uses 1-based indexing
                    if index_val == 0 {
                        return Err(ParseError {
                            kind: ParseErrorKind::ZeroIndex,
                            span: self.current_span(),
                        });
                    }

                    self.ctx.alloc_imperative_expr(
                        Expr::Literal(crate::ast::Literal::Number(index_val))
                    )
                } else if self.check(&TokenType::LParen) {
                    // Parenthesized expression like (mid + 1)
                    self.advance(); // consume '('
                    let inner = self.parse_imperative_expr()?;
                    if !self.check(&TokenType::RParen) {
                        return Err(ParseError {
                            kind: ParseErrorKind::ExpectedKeyword { keyword: ")".to_string() },
                            span: self.current_span(),
                        });
                    }
                    self.advance(); // consume ')'
                    inner
                } else if let TokenType::StringLiteral(sym) = self.peek().kind {
                    // Phase 57B: String literal key for Map access like item "iron" of prices
                    let sym = sym;
                    self.advance();
                    self.ctx.alloc_imperative_expr(Expr::Literal(crate::ast::Literal::Text(sym)))
                } else if !self.check_preposition_is("of") {
                    // Variable identifier like i, j, idx (any token that's not "of")
                    let sym = self.peek().lexeme;
                    self.advance();
                    self.ctx.alloc_imperative_expr(Expr::Identifier(sym))
                } else {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedExpression,
                        span: self.current_span(),
                    });
                };

                // Expect "of"
                if !self.check_preposition_is("of") {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedKeyword { keyword: "of".to_string() },
                        span: self.current_span(),
                    });
                }
                self.advance(); // consume "of"

                // Parse collection as primary expression (identifier or field chain)
                // Using primary_expr instead of imperative_expr prevents consuming operators
                let collection = self.parse_primary_expr()?;

                Ok(self.ctx.alloc_imperative_expr(Expr::Index {
                    collection,
                    index,
                }))
            }

            // Slice access: "items N through M of collection"
            // OR variable named "items" - disambiguate by checking if next token starts an expression
            TokenType::Items => {
                // Peek ahead to determine if this is slice syntax or variable usage
                // Slice syntax: "items" followed by number or paren (clear indicators of index)
                // Variable: "items" followed by something else (operator, dot, etc.)
                let is_slice_syntax = if let Some(next) = self.tokens.get(self.current + 1) {
                    matches!(next.kind, TokenType::Number(_) | TokenType::LParen)
                } else {
                    false
                };

                if !is_slice_syntax {
                    // Treat "items" as a variable identifier
                    let sym = token.lexeme;
                    self.advance();
                    let base = self.ctx.alloc_imperative_expr(Expr::Identifier(sym));
                    return self.parse_field_access_chain(base);
                }

                self.advance(); // consume "items"

                // Grand Challenge: Parse start index as expression (number, identifier, or parenthesized)
                let start = if let TokenType::Number(sym) = &self.peek().kind {
                    // Literal number - check for zero index at compile time
                    let sym = *sym;
                    self.advance();
                    let num_str = self.interner.resolve(sym);
                    let start_val = num_str.parse::<i64>().unwrap_or(0);

                    // Index 0 Guard for start
                    if start_val == 0 {
                        return Err(ParseError {
                            kind: ParseErrorKind::ZeroIndex,
                            span: self.current_span(),
                        });
                    }

                    self.ctx.alloc_imperative_expr(
                        Expr::Literal(crate::ast::Literal::Number(start_val))
                    )
                } else if self.check(&TokenType::LParen) {
                    // Parenthesized expression like (mid + 1)
                    self.advance(); // consume '('
                    let inner = self.parse_imperative_expr()?;
                    if !self.check(&TokenType::RParen) {
                        return Err(ParseError {
                            kind: ParseErrorKind::ExpectedKeyword { keyword: ")".to_string() },
                            span: self.current_span(),
                        });
                    }
                    self.advance(); // consume ')'
                    inner
                } else if !self.check_preposition_is("through") {
                    // Variable identifier like mid, idx
                    let sym = self.peek().lexeme;
                    self.advance();
                    self.ctx.alloc_imperative_expr(Expr::Identifier(sym))
                } else {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedExpression,
                        span: self.current_span(),
                    });
                };

                // Expect "through"
                if !self.check_preposition_is("through") {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedKeyword { keyword: "through".to_string() },
                        span: self.current_span(),
                    });
                }
                self.advance(); // consume "through"

                // Grand Challenge: Parse end index as expression (number, identifier, or parenthesized)
                let end = if let TokenType::Number(sym) = &self.peek().kind {
                    // Literal number - check for zero index at compile time
                    let sym = *sym;
                    self.advance();
                    let num_str = self.interner.resolve(sym);
                    let end_val = num_str.parse::<i64>().unwrap_or(0);

                    // Index 0 Guard for end
                    if end_val == 0 {
                        return Err(ParseError {
                            kind: ParseErrorKind::ZeroIndex,
                            span: self.current_span(),
                        });
                    }

                    self.ctx.alloc_imperative_expr(
                        Expr::Literal(crate::ast::Literal::Number(end_val))
                    )
                } else if self.check(&TokenType::LParen) {
                    // Parenthesized expression like (mid + 1)
                    self.advance(); // consume '('
                    let inner = self.parse_imperative_expr()?;
                    if !self.check(&TokenType::RParen) {
                        return Err(ParseError {
                            kind: ParseErrorKind::ExpectedKeyword { keyword: ")".to_string() },
                            span: self.current_span(),
                        });
                    }
                    self.advance(); // consume ')'
                    inner
                } else if !self.check_preposition_is("of") {
                    // Variable identifier like n, length
                    let sym = self.peek().lexeme;
                    self.advance();
                    self.ctx.alloc_imperative_expr(Expr::Identifier(sym))
                } else {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedExpression,
                        span: self.current_span(),
                    });
                };

                // "of collection" is now optional - collection can be inferred from context
                // (e.g., "items 1 through mid" when items is the local variable)
                let collection = if self.check_preposition_is("of") {
                    self.advance(); // consume "of"
                    self.parse_imperative_expr()?
                } else {
                    // The variable is the collection itself (already consumed as "items")
                    // Re-intern "items" to use as the collection identifier
                    let items_sym = self.interner.intern("items");
                    self.ctx.alloc_imperative_expr(Expr::Identifier(items_sym))
                };

                Ok(self.ctx.alloc_imperative_expr(Expr::Slice {
                    collection,
                    start,
                    end,
                }))
            }

            // List literal: [1, 2, 3]
            TokenType::LBracket => {
                self.advance(); // consume "["

                let mut items = Vec::new();
                if !self.check(&TokenType::RBracket) {
                    loop {
                        items.push(self.parse_imperative_expr()?);
                        if !self.check(&TokenType::Comma) {
                            break;
                        }
                        self.advance(); // consume ","
                    }
                }

                if !self.check(&TokenType::RBracket) {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedKeyword { keyword: "]".to_string() },
                        span: self.current_span(),
                    });
                }
                self.advance(); // consume "]"

                // Check for typed empty list: [] of Int
                if items.is_empty() && self.check_word("of") {
                    self.advance(); // consume "of"
                    let type_name = self.expect_identifier()?;
                    // Generate: Seq::<Type>::default()
                    let seq_sym = self.interner.intern("Seq");
                    return Ok(self.ctx.alloc_imperative_expr(Expr::New {
                        type_name: seq_sym,
                        type_args: vec![type_name],
                        init_fields: vec![],
                    }));
                }

                Ok(self.ctx.alloc_imperative_expr(Expr::List(items)))
            }

            TokenType::Number(sym) => {
                self.advance();
                let num_str = self.interner.resolve(*sym);
                // Check if it's a float (contains decimal point)
                if num_str.contains('.') {
                    let num = num_str.parse::<f64>().unwrap_or(0.0);
                    Ok(self.ctx.alloc_imperative_expr(Expr::Literal(Literal::Float(num))))
                } else {
                    let num = num_str.parse::<i64>().unwrap_or(0);
                    Ok(self.ctx.alloc_imperative_expr(Expr::Literal(Literal::Number(num))))
                }
            }

            // Phase 33: String literals
            TokenType::StringLiteral(sym) => {
                self.advance();
                Ok(self.ctx.alloc_imperative_expr(Expr::Literal(Literal::Text(*sym))))
            }

            // Character literals
            TokenType::CharLiteral(sym) => {
                let char_str = self.interner.resolve(*sym);
                let ch = char_str.chars().next().unwrap_or('\0');
                self.advance();
                Ok(self.ctx.alloc_imperative_expr(Expr::Literal(Literal::Char(ch))))
            }

            // Handle 'nothing' literal
            TokenType::Nothing => {
                self.advance();
                Ok(self.ctx.alloc_imperative_expr(Expr::Literal(Literal::Nothing)))
            }

            // Phase 43D: Length expression: "length of items" or "length(items)"
            TokenType::Length => {
                let func_name = self.peek().lexeme;

                // Check for function call syntax: length(x)
                if self.tokens.get(self.current + 1)
                    .map(|t| matches!(t.kind, TokenType::LParen))
                    .unwrap_or(false)
                {
                    self.advance(); // consume "length"
                    return self.parse_call_expr(func_name);
                }

                self.advance(); // consume "length"

                // Expect "of" for natural syntax
                if !self.check_preposition_is("of") {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedKeyword { keyword: "of".to_string() },
                        span: self.current_span(),
                    });
                }
                self.advance(); // consume "of"

                let collection = self.parse_imperative_expr()?;
                Ok(self.ctx.alloc_imperative_expr(Expr::Length { collection }))
            }

            // Phase 43D: Copy expression: "copy of slice" or "copy(slice)"
            TokenType::Copy => {
                let func_name = self.peek().lexeme;

                // Check for function call syntax: copy(x)
                if self.tokens.get(self.current + 1)
                    .map(|t| matches!(t.kind, TokenType::LParen))
                    .unwrap_or(false)
                {
                    self.advance(); // consume "copy"
                    return self.parse_call_expr(func_name);
                }

                self.advance(); // consume "copy"

                // Expect "of" for natural syntax
                if !self.check_preposition_is("of") {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedKeyword { keyword: "of".to_string() },
                        span: self.current_span(),
                    });
                }
                self.advance(); // consume "of"

                let expr = self.parse_imperative_expr()?;
                Ok(self.ctx.alloc_imperative_expr(Expr::Copy { expr }))
            }

            // Phase 48: Manifest expression: "manifest of Zone"
            TokenType::Manifest => {
                self.advance(); // consume "manifest"

                // Expect "of"
                if !self.check_preposition_is("of") {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedKeyword { keyword: "of".to_string() },
                        span: self.current_span(),
                    });
                }
                self.advance(); // consume "of"

                let zone = self.parse_imperative_expr()?;
                Ok(self.ctx.alloc_imperative_expr(Expr::ManifestOf { zone }))
            }

            // Phase 48: Chunk expression: "chunk at N in Zone"
            TokenType::Chunk => {
                self.advance(); // consume "chunk"

                // Expect "at"
                if !self.check(&TokenType::At) {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedKeyword { keyword: "at".to_string() },
                        span: self.current_span(),
                    });
                }
                self.advance(); // consume "at"

                let index = self.parse_imperative_expr()?;

                // Expect "in"
                if !self.check_preposition_is("in") && !self.check(&TokenType::In) {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedKeyword { keyword: "in".to_string() },
                        span: self.current_span(),
                    });
                }
                self.advance(); // consume "in"

                let zone = self.parse_imperative_expr()?;
                Ok(self.ctx.alloc_imperative_expr(Expr::ChunkAt { index, zone }))
            }

            // Handle verbs in expression context:
            // - "empty" is a literal Nothing
            // - Other verbs can be function names (e.g., read, write)
            TokenType::Verb { lemma, .. } => {
                let word = self.interner.resolve(*lemma).to_lowercase();
                if word == "empty" {
                    self.advance();
                    return Ok(self.ctx.alloc_imperative_expr(Expr::Literal(Literal::Nothing)));
                }
                // Phase 38: Allow verbs to be used as function calls
                let sym = token.lexeme;
                self.advance();
                if self.check(&TokenType::LParen) {
                    return self.parse_call_expr(sym);
                }
                // Treat as identifier reference
                self.verify_identifier_access(sym)?;
                let base = self.ctx.alloc_imperative_expr(Expr::Identifier(sym));
                self.parse_field_access_chain(base)
            }

            // Phase 38: Adverbs as identifiers (e.g., "now" for time functions)
            TokenType::TemporalAdverb(_) | TokenType::ScopalAdverb(_) | TokenType::Adverb(_) => {
                let sym = token.lexeme;
                self.advance();
                if self.check(&TokenType::LParen) {
                    return self.parse_call_expr(sym);
                }
                // Treat as identifier reference (e.g., "Let t be now.")
                self.verify_identifier_access(sym)?;
                let base = self.ctx.alloc_imperative_expr(Expr::Identifier(sym));
                self.parse_field_access_chain(base)
            }

            // Phase 10: IO keywords as function calls (e.g., "read", "write", "file")
            // Phase 57: Add/Remove keywords as function calls
            TokenType::Read | TokenType::Write | TokenType::File | TokenType::Console |
            TokenType::Add | TokenType::Remove => {
                let sym = token.lexeme;
                self.advance();
                if self.check(&TokenType::LParen) {
                    return self.parse_call_expr(sym);
                }
                // Treat as identifier reference
                self.verify_identifier_access(sym)?;
                let base = self.ctx.alloc_imperative_expr(Expr::Identifier(sym));
                self.parse_field_access_chain(base)
            }

            // Unified identifier handling - all identifier-like tokens get verified
            // First check for boolean/special literals before treating as variable
            TokenType::Noun(sym) | TokenType::ProperName(sym) | TokenType::Adjective(sym) => {
                let sym = *sym;
                let word = self.interner.resolve(sym);

                // Check for boolean literals
                if word == "true" {
                    self.advance();
                    return Ok(self.ctx.alloc_imperative_expr(Expr::Literal(Literal::Boolean(true))));
                }
                if word == "false" {
                    self.advance();
                    return Ok(self.ctx.alloc_imperative_expr(Expr::Literal(Literal::Boolean(false))));
                }

                // Check for 'empty' - treat as unit value for collections
                if word == "empty" {
                    self.advance();
                    return Ok(self.ctx.alloc_imperative_expr(Expr::Literal(Literal::Nothing)));
                }

                // Don't verify as variable - might be a function call or enum variant
                self.advance();

                // Phase 32: Check for function call: identifier(args)
                if self.check(&TokenType::LParen) {
                    return self.parse_call_expr(sym);
                }

                // Phase 33: Check if this is a bare enum variant (e.g., "North" for Direction)
                if let Some(enum_name) = self.find_variant(sym) {
                    let base = self.ctx.alloc_imperative_expr(Expr::NewVariant {
                        enum_name,
                        variant: sym,
                        fields: vec![],
                    });
                    return self.parse_field_access_chain(base);
                }

                // Centralized verification for undefined/moved checks (only for variables)
                self.verify_identifier_access(sym)?;
                let base = self.ctx.alloc_imperative_expr(Expr::Identifier(sym));
                // Phase 31: Check for field access via possessive
                self.parse_field_access_chain(base)
            }

            // Pronouns can be variable names in code context ("i", "it")
            TokenType::Pronoun { .. } => {
                let sym = token.lexeme;
                self.advance();
                let base = self.ctx.alloc_imperative_expr(Expr::Identifier(sym));
                // Phase 31: Check for field access via possessive
                self.parse_field_access_chain(base)
            }

            // Phase 49: CRDT keywords can be function names (Merge, Increase)
            TokenType::Merge | TokenType::Increase => {
                let sym = token.lexeme;
                self.advance();

                // Check for function call: Merge(args)
                if self.check(&TokenType::LParen) {
                    return self.parse_call_expr(sym);
                }

                let base = self.ctx.alloc_imperative_expr(Expr::Identifier(sym));
                self.parse_field_access_chain(base)
            }

            // Handle ambiguous tokens that might be identifiers
            TokenType::Ambiguous { primary, alternatives } => {
                let sym = match &**primary {
                    TokenType::Noun(s) | TokenType::Adjective(s) | TokenType::ProperName(s) => Some(*s),
                    _ => alternatives.iter().find_map(|t| match t {
                        TokenType::Noun(s) | TokenType::Adjective(s) | TokenType::ProperName(s) => Some(*s),
                        _ => None
                    })
                };

                if let Some(s) = sym {
                    self.verify_identifier_access(s)?;
                    self.advance();
                    let base = self.ctx.alloc_imperative_expr(Expr::Identifier(s));
                    // Phase 31: Check for field access via possessive
                    self.parse_field_access_chain(base)
                } else {
                    Err(ParseError {
                        kind: ParseErrorKind::ExpectedExpression,
                        span: self.current_span(),
                    })
                }
            }

            // Parenthesized expression: (expr) or Tuple literal: (expr, expr, ...)
            TokenType::LParen => {
                self.advance(); // consume '('
                let first = self.parse_imperative_expr()?;

                // Check if this is a tuple (has comma) or just grouping
                if self.check(&TokenType::Comma) {
                    // It's a tuple - parse remaining elements
                    let mut items = vec![first];
                    while self.check(&TokenType::Comma) {
                        self.advance(); // consume ","
                        items.push(self.parse_imperative_expr()?);
                    }

                    if !self.check(&TokenType::RParen) {
                        return Err(ParseError {
                            kind: ParseErrorKind::ExpectedKeyword { keyword: ")".to_string() },
                            span: self.current_span(),
                        });
                    }
                    self.advance(); // consume ')'

                    let base = self.ctx.alloc_imperative_expr(Expr::Tuple(items));
                    self.parse_field_access_chain(base)
                } else {
                    // Just a parenthesized expression
                    if !self.check(&TokenType::RParen) {
                        return Err(ParseError {
                            kind: ParseErrorKind::ExpectedKeyword { keyword: ")".to_string() },
                            span: self.current_span(),
                        });
                    }
                    self.advance(); // consume ')'
                    Ok(first)
                }
            }

            _ => {
                Err(ParseError {
                    kind: ParseErrorKind::ExpectedExpression,
                    span: self.current_span(),
                })
            }
        }
    }

    /// Parse a complete imperative expression including binary operators.
    /// Uses precedence climbing for correct associativity and precedence.
    fn parse_imperative_expr(&mut self) -> ParseResult<&'a Expr<'a>> {
        self.parse_additive_expr()
    }

    /// Parse additive expressions (+, -, combined with, union, intersection, contains) - left-to-right associative
    fn parse_additive_expr(&mut self) -> ParseResult<&'a Expr<'a>> {
        let mut left = self.parse_multiplicative_expr()?;

        loop {
            match &self.peek().kind {
                TokenType::Plus => {
                    self.advance();
                    let right = self.parse_multiplicative_expr()?;
                    left = self.ctx.alloc_imperative_expr(Expr::BinaryOp {
                        op: BinaryOpKind::Add,
                        left,
                        right,
                    });
                }
                TokenType::Minus => {
                    self.advance();
                    let right = self.parse_multiplicative_expr()?;
                    left = self.ctx.alloc_imperative_expr(Expr::BinaryOp {
                        op: BinaryOpKind::Subtract,
                        left,
                        right,
                    });
                }
                // Phase 53: "combined with" for string concatenation
                TokenType::Combined => {
                    self.advance(); // consume "combined"
                    // Expect "with" (preposition)
                    if !self.check_preposition_is("with") {
                        return Err(ParseError {
                            kind: ParseErrorKind::ExpectedKeyword { keyword: "with".to_string() },
                            span: self.current_span(),
                        });
                    }
                    self.advance(); // consume "with"
                    let right = self.parse_multiplicative_expr()?;
                    left = self.ctx.alloc_imperative_expr(Expr::BinaryOp {
                        op: BinaryOpKind::Concat,
                        left,
                        right,
                    });
                }
                // Set operations: union, intersection
                TokenType::Union => {
                    self.advance(); // consume "union"
                    let right = self.parse_multiplicative_expr()?;
                    left = self.ctx.alloc_imperative_expr(Expr::Union {
                        left,
                        right,
                    });
                }
                TokenType::Intersection => {
                    self.advance(); // consume "intersection"
                    let right = self.parse_multiplicative_expr()?;
                    left = self.ctx.alloc_imperative_expr(Expr::Intersection {
                        left,
                        right,
                    });
                }
                // Set membership: "set contains value"
                TokenType::Contains => {
                    self.advance(); // consume "contains"
                    let value = self.parse_multiplicative_expr()?;
                    left = self.ctx.alloc_imperative_expr(Expr::Contains {
                        collection: left,
                        value,
                    });
                }
                _ => break,
            }
        }

        Ok(left)
    }

    /// Parse unary expressions (currently just unary minus)
    fn parse_unary_expr(&mut self) -> ParseResult<&'a Expr<'a>> {
        use crate::ast::{Expr, Literal};

        if self.check(&TokenType::Minus) {
            self.advance(); // consume '-'
            let operand = self.parse_unary_expr()?; // recursive for --5
            // Implement as 0 - operand (no UnaryOp variant in Expr)
            return Ok(self.ctx.alloc_imperative_expr(Expr::BinaryOp {
                op: BinaryOpKind::Subtract,
                left: self.ctx.alloc_imperative_expr(Expr::Literal(Literal::Number(0))),
                right: operand,
            }));
        }
        self.parse_primary_expr()
    }

    /// Parse multiplicative expressions (*, /, %) - left-to-right associative
    fn parse_multiplicative_expr(&mut self) -> ParseResult<&'a Expr<'a>> {
        let mut left = self.parse_unary_expr()?;

        loop {
            let op = match &self.peek().kind {
                TokenType::Star => {
                    self.advance();
                    BinaryOpKind::Multiply
                }
                TokenType::Slash => {
                    self.advance();
                    BinaryOpKind::Divide
                }
                TokenType::Percent => {
                    self.advance();
                    BinaryOpKind::Modulo
                }
                _ => break,
            };
            let right = self.parse_unary_expr()?;
            left = self.ctx.alloc_imperative_expr(Expr::BinaryOp {
                op,
                left,
                right,
            });
        }

        Ok(left)
    }

    /// Try to parse a binary operator (+, -, *, /)
    fn try_parse_binary_op(&mut self) -> Option<BinaryOpKind> {
        match &self.peek().kind {
            TokenType::Plus => {
                self.advance();
                Some(BinaryOpKind::Add)
            }
            TokenType::Minus => {
                self.advance();
                Some(BinaryOpKind::Subtract)
            }
            TokenType::Star => {
                self.advance();
                Some(BinaryOpKind::Multiply)
            }
            TokenType::Slash => {
                self.advance();
                Some(BinaryOpKind::Divide)
            }
            _ => None,
        }
    }

    /// Phase 32: Parse function call expression: f(x, y, ...)
    fn parse_call_expr(&mut self, function: Symbol) -> ParseResult<&'a Expr<'a>> {
        use crate::ast::Expr;

        self.advance(); // consume '('

        let mut args = Vec::new();
        if !self.check(&TokenType::RParen) {
            loop {
                args.push(self.parse_imperative_expr()?);
                if !self.check(&TokenType::Comma) {
                    break;
                }
                self.advance(); // consume ','
            }
        }

        if !self.check(&TokenType::RParen) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: ")".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume ')'

        Ok(self.ctx.alloc_imperative_expr(Expr::Call { function, args }))
    }

    /// Phase 31: Parse field access chain via possessive ('s) and bracket indexing
    /// Handles patterns like: p's x, p's x's y, items[1], items[i]'s field
    fn parse_field_access_chain(&mut self, base: &'a Expr<'a>) -> ParseResult<&'a Expr<'a>> {
        use crate::ast::Expr;

        let mut result = base;

        // Keep parsing field accesses and bracket indexing
        loop {
            if self.check(&TokenType::Possessive) {
                // Field access: p's x
                self.advance(); // consume "'s"
                let field = self.expect_identifier()?;
                result = self.ctx.alloc_imperative_expr(Expr::FieldAccess {
                    object: result,
                    field,
                });
            } else if self.check(&TokenType::LBracket) {
                // Bracket indexing: items[1], items[i]
                self.advance(); // consume "["
                let index = self.parse_imperative_expr()?;

                if !self.check(&TokenType::RBracket) {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedKeyword { keyword: "]".to_string() },
                        span: self.current_span(),
                    });
                }
                self.advance(); // consume "]"

                result = self.ctx.alloc_imperative_expr(Expr::Index {
                    collection: result,
                    index,
                });
            } else {
                break;
            }
        }

        Ok(result)
    }

    /// Centralized verification for identifier access in imperative mode.
    /// Checks for use-after-move errors on known variables.
    fn verify_identifier_access(&self, sym: Symbol) -> ParseResult<()> {
        if self.mode != ParserMode::Imperative {
            return Ok(());
        }

        use crate::context::OwnershipState;
        let name = self.interner.resolve(sym);

        // Check for Use-After-Move on variables we're tracking
        let ownership = self.context.as_ref()
            .and_then(|ctx| ctx.get_ownership(name));

        if ownership == Some(OwnershipState::Moved) {
            return Err(ParseError {
                kind: ParseErrorKind::UseAfterMove { name: name.to_string() },
                span: self.current_span(),
            });
        }

        Ok(())
    }

    fn expect_identifier(&mut self) -> ParseResult<Symbol> {
        let token = self.peek().clone();
        match &token.kind {
            // Standard identifiers
            TokenType::Noun(sym) | TokenType::ProperName(sym) | TokenType::Adjective(sym) => {
                self.advance();
                Ok(*sym)
            }
            // Verbs can be variable names in code context ("empty", "run", etc.)
            // Use raw lexeme to preserve original casing
            TokenType::Verb { .. } => {
                let sym = token.lexeme;
                self.advance();
                Ok(sym)
            }
            // Phase 32: Articles can be single-letter identifiers (a, an)
            TokenType::Article(_) => {
                let sym = token.lexeme;
                self.advance();
                Ok(sym)
            }
            // Overloaded tokens that are valid identifiers in code context
            TokenType::Pronoun { .. } |  // "i", "it"
            TokenType::Items |           // "items"
            TokenType::Values |          // "values"
            TokenType::Item |            // "item"
            TokenType::Nothing |         // "nothing"
            // Phase 38: Adverbs can be function names (now, sleep, etc.)
            TokenType::TemporalAdverb(_) |
            TokenType::ScopalAdverb(_) |
            TokenType::Adverb(_) |
            // Phase 10: IO keywords can be function names (read, write, file, console)
            TokenType::Read |
            TokenType::Write |
            TokenType::File |
            TokenType::Console |
            // Phase 49: CRDT keywords can be function names (Merge, Increase)
            TokenType::Merge |
            TokenType::Increase |
            // Phase 54: "first", "second", etc. can be variable names
            // Phase 57: "add", "remove" can be function names
            TokenType::Add |
            TokenType::Remove |
            TokenType::First => {
                // Use the raw lexeme (interned string) as the symbol
                let sym = token.lexeme;
                self.advance();
                Ok(sym)
            }
            TokenType::Ambiguous { primary, .. } => {
                // For ambiguous tokens, extract symbol from primary
                let sym = match &**primary {
                    TokenType::Noun(s) | TokenType::Adjective(s) | TokenType::ProperName(s) => *s,
                    TokenType::Verb { lemma, .. } => *lemma,
                    _ => token.lexeme,
                };
                self.advance();
                Ok(sym)
            }
            _ => Err(ParseError {
                kind: ParseErrorKind::ExpectedIdentifier,
                span: self.current_span(),
            }),
        }
    }

    fn consume_content_word_for_relative(&mut self) -> ParseResult<Symbol> {
        let t = self.advance().clone();
        match t.kind {
            TokenType::Noun(s) | TokenType::Adjective(s) => Ok(s),
            TokenType::ProperName(s) => Ok(s),
            TokenType::Verb { lemma, .. } => Ok(lemma),
            other => Err(ParseError {
                kind: ParseErrorKind::ExpectedContentWord { found: other },
                span: self.current_span(),
            }),
        }
    }

    fn check_modal(&self) -> bool {
        matches!(
            self.peek().kind,
            TokenType::Must
                | TokenType::Shall
                | TokenType::Should
                | TokenType::Can
                | TokenType::May
                | TokenType::Cannot
                | TokenType::Could
                | TokenType::Would
                | TokenType::Might
        )
    }

    fn check_pronoun(&self) -> bool {
        match &self.peek().kind {
            TokenType::Pronoun { case, .. } => {
                // In noun_priority_mode, possessive pronouns start NPs, not standalone objects
                if self.noun_priority_mode && matches!(case, Case::Possessive) {
                    return false;
                }
                true
            }
            TokenType::Ambiguous { primary, alternatives } => {
                // In noun_priority_mode, if there's a possessive alternative, prefer noun path
                if self.noun_priority_mode {
                    let has_possessive = matches!(**primary, TokenType::Pronoun { case: Case::Possessive, .. })
                        || alternatives.iter().any(|t| matches!(t, TokenType::Pronoun { case: Case::Possessive, .. }));
                    if has_possessive {
                        return false;
                    }
                }
                matches!(**primary, TokenType::Pronoun { .. })
                    || alternatives.iter().any(|t| matches!(t, TokenType::Pronoun { .. }))
            }
            _ => false,
        }
    }

    fn parse_atom(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        // Handle Focus particles: "Only John loves Mary", "Even John ran"
        if self.check_focus() {
            return self.parse_focus();
        }

        // Handle mass noun measure: "Much water flows", "Little time remains"
        if self.check_measure() {
            return self.parse_measure();
        }

        if self.check_quantifier() {
            self.advance();
            return self.parse_quantified();
        }

        if self.check_npi_quantifier() {
            return self.parse_npi_quantified();
        }

        if self.check_temporal_npi() {
            return self.parse_temporal_npi();
        }

        if self.match_token(&[TokenType::LParen]) {
            let expr = self.parse_sentence()?;
            self.consume(TokenType::RParen)?;
            return Ok(expr);
        }

        // Handle pronoun as subject
        if self.check_pronoun() {
            let token = self.advance().clone();
            let (gender, number) = match &token.kind {
                TokenType::Pronoun { gender, number, .. } => (*gender, *number),
                TokenType::Ambiguous { primary, alternatives } => {
                    if let TokenType::Pronoun { gender, number, .. } = **primary {
                        (gender, number)
                    } else {
                        alternatives.iter().find_map(|t| {
                            if let TokenType::Pronoun { gender, number, .. } = t {
                                Some((*gender, *number))
                            } else {
                                None
                            }
                        }).unwrap_or((Gender::Unknown, Number::Singular))
                    }
                }
                _ => (Gender::Unknown, Number::Singular),
            };

            let token_text = self.interner.resolve(token.lexeme);

            // Weather verb + expletive "it" detection: "it rains" → ∃e(Rain(e))
            // Must check BEFORE pronoun resolution since "it" resolves to "?"
            if token_text.eq_ignore_ascii_case("it") && self.check_verb() {
                if let TokenType::Verb { lemma, time, .. } = &self.peek().kind {
                    let lemma_str = self.interner.resolve(*lemma);
                    if Lexer::is_weather_verb(lemma_str) {
                        let verb = *lemma;
                        let verb_time = *time;
                        self.advance(); // consume the weather verb

                        let event_var = self.get_event_var();
                        let suppress_existential = self.drs.in_conditional_antecedent();
                        if suppress_existential {
                            let event_class = self.interner.intern("Event");
                            self.drs.introduce_referent(event_var, event_class, crate::context::Gender::Neuter);
                        }
                        let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                            event_var,
                            verb,
                            roles: self.ctx.roles.alloc_slice(vec![]), // No thematic roles
                            modifiers: self.ctx.syms.alloc_slice(vec![]),
                            suppress_existential,
                        })));

                        return Ok(match verb_time {
                            Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                                operator: TemporalOperator::Past,
                                body: neo_event,
                            }),
                            Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                                operator: TemporalOperator::Future,
                                body: neo_event,
                            }),
                            _ => neo_event,
                        });
                    }
                }
            }

            // Handle deictic pronouns that don't need discourse resolution
            let resolved = if token_text.eq_ignore_ascii_case("i") {
                self.interner.intern("Speaker")
            } else if token_text.eq_ignore_ascii_case("you") {
                self.interner.intern("Addressee")
            } else {
                // Try discourse resolution for anaphoric pronouns
                let unknown = self.interner.intern("?");
                self.resolve_pronoun(gender, number).unwrap_or(unknown)
            };

            // Check for performative: "I promise that..." or "I promise to..."
            if self.check_performative() {
                if let TokenType::Performative(act) = self.advance().kind.clone() {
                    // Check for infinitive complement: "I promise to come"
                    if self.check(&TokenType::To) {
                        self.advance(); // consume "to"

                        if self.check_verb() {
                            let infinitive_verb = self.consume_verb();

                            let content = self.ctx.exprs.alloc(LogicExpr::Predicate {
                                name: infinitive_verb,
                                args: self.ctx.terms.alloc_slice([Term::Constant(resolved)]),
                            });

                            return Ok(self.ctx.exprs.alloc(LogicExpr::SpeechAct {
                                performer: resolved,
                                act_type: act,
                                content,
                            }));
                        }
                    }

                    // Skip "that" if present
                    if self.check(&TokenType::That) {
                        self.advance();
                    }
                    let content = self.parse_sentence()?;
                    return Ok(self.ctx.exprs.alloc(LogicExpr::SpeechAct {
                        performer: resolved,
                        act_type: act,
                        content,
                    }));
                }
            }

            // Continue parsing verb phrase with resolved subject
            return self.parse_predicate_with_subject(resolved);
        }

        // Consume "both" correlative marker if present: "both X and Y"
        // The existing try_parse_plural_subject will handle the "X and Y" pattern
        let _had_both = self.match_token(&[TokenType::Both]);

        let subject = self.parse_noun_phrase(true)?;

        // Handle plural subjects: "John and Mary verb"
        if self.check(&TokenType::And) {
            match self.try_parse_plural_subject(&subject) {
                Ok(Some(result)) => return Ok(result),
                Ok(None) => {} // Not a plural subject, continue
                Err(e) => return Err(e), // Semantic error (e.g., respectively mismatch)
            }
        }

        // Handle scopal adverbs: "John almost died"
        if self.check_scopal_adverb() {
            return self.parse_scopal_adverb(&subject);
        }

        // Handle topicalization: "The cake, John ate." - first NP is object, not subject
        if self.check(&TokenType::Comma) {
            let saved_pos = self.current;
            self.advance(); // consume comma

            // Check if followed by pronoun subject (e.g., "The book, he read.")
            if self.check_pronoun() {
                let topic_attempt = self.try_parse(|p| {
                    let token = p.peek().clone();
                    let pronoun_features = match &token.kind {
                        TokenType::Pronoun { gender, number, .. } => Some((*gender, *number)),
                        TokenType::Ambiguous { primary, alternatives } => {
                            if let TokenType::Pronoun { gender, number, .. } = **primary {
                                Some((gender, number))
                            } else {
                                alternatives.iter().find_map(|t| {
                                    if let TokenType::Pronoun { gender, number, .. } = t {
                                        Some((*gender, *number))
                                    } else {
                                        None
                                    }
                                })
                            }
                        }
                        _ => None,
                    };

                    if let Some((gender, number)) = pronoun_features {
                        p.advance(); // consume pronoun
                        let unknown = p.interner.intern("?");
                        let resolved = p.resolve_pronoun(gender, number).unwrap_or(unknown);

                        if p.check_verb() {
                            let verb = p.consume_verb();
                            let predicate = p.ctx.exprs.alloc(LogicExpr::Predicate {
                                name: verb,
                                args: p.ctx.terms.alloc_slice([
                                    Term::Constant(resolved),
                                    Term::Constant(subject.noun),
                                ]),
                            });
                            p.wrap_with_definiteness_full(&subject, predicate)
                        } else {
                            Err(ParseError {
                                kind: ParseErrorKind::ExpectedVerb { found: p.peek().kind.clone() },
                                span: p.current_span(),
                            })
                        }
                    } else {
                        Err(ParseError {
                            kind: ParseErrorKind::ExpectedContentWord { found: token.kind },
                            span: p.current_span(),
                        })
                    }
                });

                if let Some(result) = topic_attempt {
                    return Ok(result);
                }
            }

            // Check if followed by another NP and then a verb (topicalization pattern)
            if self.check_content_word() {
                let topic_attempt = self.try_parse(|p| {
                    let real_subject = p.parse_noun_phrase(true)?;
                    if p.check_verb() {
                        let verb = p.consume_verb();
                        let predicate = p.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: verb,
                            args: p.ctx.terms.alloc_slice([
                                Term::Constant(real_subject.noun),
                                Term::Constant(subject.noun),
                            ]),
                        });
                        p.wrap_with_definiteness_full(&subject, predicate)
                    } else {
                        Err(ParseError {
                            kind: ParseErrorKind::ExpectedVerb { found: p.peek().kind.clone() },
                            span: p.current_span(),
                        })
                    }
                });

                if let Some(result) = topic_attempt {
                    return Ok(result);
                }
            }

            // Restore position if topicalization didn't match
            self.current = saved_pos;
        }

        // Handle relative clause after subject: "The cat that the dog chased ran."
        let mut relative_clause: Option<(Symbol, &'a LogicExpr<'a>)> = None;
        if self.check(&TokenType::That) || self.check(&TokenType::Who) {
            self.advance();
            let var_name = self.next_var_name();
            let rel_pred = self.parse_relative_clause(var_name)?;
            relative_clause = Some((var_name, rel_pred));
        } else if matches!(self.peek().kind, TokenType::Article(_)) && self.is_contact_clause_pattern() {
            // Contact clause (reduced relative): "The cat the dog chased ran."
            // NP + NP + Verb pattern indicates embedded relative without explicit "that"
            let var_name = self.next_var_name();
            let rel_pred = self.parse_relative_clause(var_name)?;
            relative_clause = Some((var_name, rel_pred));
        }

        // Handle main verb after relative clause: "The cat that the dog chased ran."
        if let Some((var_name, rel_clause)) = relative_clause {
            if self.check_verb() {
                let (verb, verb_time, _, _) = self.consume_verb_with_metadata();
                let var_term = Term::Variable(var_name);

                let event_var = self.get_event_var();
                let suppress_existential = self.drs.in_conditional_antecedent();
                let mut modifiers = vec![];
                if verb_time == Time::Past {
                    modifiers.push(self.interner.intern("Past"));
                }
                let main_pred = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                    event_var,
                    verb,
                    roles: self.ctx.roles.alloc_slice(vec![
                        (ThematicRole::Agent, var_term),
                    ]),
                    modifiers: self.ctx.syms.alloc_slice(modifiers),
                    suppress_existential,
                })));

                let type_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: subject.noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                });

                let inner = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: type_pred,
                    op: TokenType::And,
                    right: rel_clause,
                });

                let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: inner,
                    op: TokenType::And,
                    right: main_pred,
                });

                return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: var_name,
                    body,
                    island_id: self.current_island,
                }));
            }

            // No main verb - just the relative clause: "The cat that runs" as a complete NP
            // Build: ∃x(Cat(x) ∧ Runs(x) ∧ ∀y(Cat(y) → y=x))
            if self.is_at_end() || self.check(&TokenType::Period) || self.check(&TokenType::Comma) {
                let type_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: subject.noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                });

                let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: type_pred,
                    op: TokenType::And,
                    right: rel_clause,
                });

                // Add uniqueness for definite description
                let uniqueness_body = if subject.definiteness == Some(Definiteness::Definite) {
                    let y_var = self.next_var_name();
                    let type_pred_y = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: subject.noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(y_var)]),
                    });
                    let identity = self.ctx.exprs.alloc(LogicExpr::Identity {
                        left: self.ctx.terms.alloc(Term::Variable(y_var)),
                        right: self.ctx.terms.alloc(Term::Variable(var_name)),
                    });
                    let uniqueness_cond = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: type_pred_y,
                        op: TokenType::If,
                        right: identity,
                    });
                    let uniqueness = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                        kind: QuantifierKind::Universal,
                        variable: y_var,
                        body: uniqueness_cond,
                        island_id: self.current_island,
                    });
                    self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: body,
                        op: TokenType::And,
                        right: uniqueness,
                    })
                } else {
                    body
                };

                return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: var_name,
                    body: uniqueness_body,
                    island_id: self.current_island,
                }));
            }

            // Re-store for copula handling below
            relative_clause = Some((var_name, rel_clause));
        }

        // Identity check: "Clark is equal to Superman"
        if self.check(&TokenType::Identity) {
            self.advance();
            let right = self.consume_content_word()?;
            return Ok(self.ctx.exprs.alloc(LogicExpr::Identity {
                left: self.ctx.terms.alloc(Term::Constant(subject.noun)),
                right: self.ctx.terms.alloc(Term::Constant(right)),
            }));
        }

        if self.check_modal() {
            if let Some((var_name, rel_clause)) = relative_clause {
                let modal_pred = self.parse_aspect_chain_with_term(Term::Variable(var_name))?;

                let type_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: subject.noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                });

                let inner = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: type_pred,
                    op: TokenType::And,
                    right: rel_clause,
                });

                let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: inner,
                    op: TokenType::And,
                    right: modal_pred,
                });

                return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: var_name,
                    body,
                    island_id: self.current_island,
                }));
            }

            let modal_pred = self.parse_aspect_chain(subject.noun)?;
            return self.wrap_with_definiteness_full(&subject, modal_pred);
        }

        if self.check(&TokenType::Is) || self.check(&TokenType::Are)
            || self.check(&TokenType::Was) || self.check(&TokenType::Were)
        {
            let copula_time = if self.check(&TokenType::Was) || self.check(&TokenType::Were) {
                Time::Past
            } else {
                Time::Present
            };
            self.advance();

            // Check for Number token (measure phrase) before comparative or adjective
            // "John is 2 inches taller than Mary" or "The rope is 5 meters long"
            if self.check_number() {
                let measure = self.parse_measure_phrase()?;

                // Check if followed by comparative: "2 inches taller than"
                if self.check_comparative() {
                    return self.parse_comparative(&subject, copula_time, Some(measure));
                }

                // Check for dimensional adjective: "5 meters long"
                if self.check_content_word() {
                    let adj = self.consume_content_word()?;
                    let result = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: adj,
                        args: self.ctx.terms.alloc_slice([
                            Term::Constant(subject.noun),
                            *measure,
                        ]),
                    });
                    return self.wrap_with_definiteness_full(&subject, result);
                }

                // Bare measure phrase: "The temperature is 98.6 degrees."
                // Output: Identity(subject, measure)
                if self.check(&TokenType::Period) || self.is_at_end() {
                    // In imperative mode, reject "x is 5" - suggest "x equals 5"
                    if self.mode == ParserMode::Imperative {
                        let variable = self.interner.resolve(subject.noun).to_string();
                        let value = if let Term::Value { kind, .. } = measure {
                            format!("{:?}", kind)
                        } else {
                            "value".to_string()
                        };
                        return Err(ParseError {
                            kind: ParseErrorKind::IsValueEquality { variable, value },
                            span: self.current_span(),
                        });
                    }
                    let result = self.ctx.exprs.alloc(LogicExpr::Identity {
                        left: self.ctx.terms.alloc(Term::Constant(subject.noun)),
                        right: measure,
                    });
                    return self.wrap_with_definiteness_full(&subject, result);
                }
            }

            // Check for comparative: "is taller than"
            if self.check_comparative() {
                return self.parse_comparative(&subject, copula_time, None);
            }

            // Check for existential "is": "God is." - bare copula followed by period/EOF
            if self.check(&TokenType::Period) || self.is_at_end() {
                let var = self.next_var_name();
                let body = self.ctx.exprs.alloc(LogicExpr::Identity {
                    left: self.ctx.terms.alloc(Term::Variable(var)),
                    right: self.ctx.terms.alloc(Term::Constant(subject.noun)),
                });
                return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: var,
                    body,
                    island_id: self.current_island,
                }));
            }

            // Check for superlative: "is the tallest man"
            if self.check(&TokenType::Article(Definiteness::Definite)) {
                let saved_pos = self.current;
                self.advance();
                if self.check_superlative() {
                    return self.parse_superlative(&subject);
                }
                self.current = saved_pos;
            }

            // Check for predicate NP: "Juliet is the sun" or "John is a man"
            if self.check_article() {
                let predicate_np = self.parse_noun_phrase(true)?;
                let predicate_noun = predicate_np.noun;

                // Phase 41: Event adjective reading
                // "beautiful dancer" in event mode → ∃e(Dance(e) ∧ Agent(e, x) ∧ Beautiful(e))
                if self.event_reading_mode {
                    let noun_str = self.interner.resolve(predicate_noun);
                    if let Some(base_verb) = lexicon::lookup_agentive_noun(noun_str) {
                        // Check if any adjective can modify events
                        let event_adj = predicate_np.adjectives.iter().find(|adj| {
                            lexicon::is_event_modifier_adjective(self.interner.resolve(**adj))
                        });

                        if let Some(&adj_sym) = event_adj {
                            // Build event reading: ∃e(Verb(e) ∧ Agent(e, subject) ∧ Adj(e))
                            let verb_sym = self.interner.intern(base_verb);
                            let event_var = self.get_event_var();

                            let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                                name: verb_sym,
                                args: self.ctx.terms.alloc_slice([Term::Variable(event_var)]),
                            });

                            let agent_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                                name: self.interner.intern("Agent"),
                                args: self.ctx.terms.alloc_slice([
                                    Term::Variable(event_var),
                                    Term::Constant(subject.noun),
                                ]),
                            });

                            let adj_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                                name: adj_sym,
                                args: self.ctx.terms.alloc_slice([Term::Variable(event_var)]),
                            });

                            // Conjoin: Verb(e) ∧ Agent(e, x)
                            let verb_agent = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                left: verb_pred,
                                op: TokenType::And,
                                right: agent_pred,
                            });

                            // Conjoin: (Verb(e) ∧ Agent(e, x)) ∧ Adj(e)
                            let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                left: verb_agent,
                                op: TokenType::And,
                                right: adj_pred,
                            });

                            // Wrap in existential: ∃e(...)
                            let event_reading = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                                kind: QuantifierKind::Existential,
                                variable: event_var,
                                body,
                                island_id: self.current_island,
                            });

                            return self.wrap_with_definiteness(subject.definiteness, subject.noun, event_reading);
                        }
                    }
                }

                let subject_sort = lexicon::lookup_sort(self.interner.resolve(subject.noun));
                let predicate_sort = lexicon::lookup_sort(self.interner.resolve(predicate_noun));

                if let (Some(s_sort), Some(p_sort)) = (subject_sort, predicate_sort) {
                    if !s_sort.is_compatible_with(p_sort) && !p_sort.is_compatible_with(s_sort) {
                        let metaphor = self.ctx.exprs.alloc(LogicExpr::Metaphor {
                            tenor: self.ctx.terms.alloc(Term::Constant(subject.noun)),
                            vehicle: self.ctx.terms.alloc(Term::Constant(predicate_noun)),
                        });
                        return self.wrap_with_definiteness(subject.definiteness, subject.noun, metaphor);
                    }
                }

                // Default: intersective reading for adjectives
                // Build Adj1(x) ∧ Adj2(x) ∧ ... ∧ Noun(x)
                let mut predicates: Vec<&'a LogicExpr<'a>> = Vec::new();

                // Add adjective predicates
                for &adj_sym in predicate_np.adjectives {
                    let adj_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: adj_sym,
                        args: self.ctx.terms.alloc_slice([Term::Constant(subject.noun)]),
                    });
                    predicates.push(adj_pred);
                }

                // Add noun predicate
                let noun_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: predicate_noun,
                    args: self.ctx.terms.alloc_slice([Term::Constant(subject.noun)]),
                });
                predicates.push(noun_pred);

                // Conjoin all predicates
                let result = if predicates.len() == 1 {
                    predicates[0]
                } else {
                    let mut combined = predicates[0];
                    for pred in &predicates[1..] {
                        combined = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: combined,
                            op: TokenType::And,
                            right: *pred,
                        });
                    }
                    combined
                };

                return self.wrap_with_definiteness(subject.definiteness, subject.noun, result);
            }

            // After copula, prefer Adjective over simple-aspect Verb for ambiguous tokens
            // "is open" (Adj: state) is standard; "is open" (Verb: habitual) is ungrammatical here
            let prefer_adjective = if let TokenType::Ambiguous { primary, alternatives } = &self.peek().kind {
                let is_simple_verb = if let TokenType::Verb { aspect, .. } = **primary {
                    aspect == Aspect::Simple
                } else {
                    false
                };
                let has_adj_alt = alternatives.iter().any(|t| matches!(t, TokenType::Adjective(_)));
                is_simple_verb && has_adj_alt
            } else {
                false
            };

            if !prefer_adjective && self.check_verb() {
                let (verb, _verb_time, verb_aspect, verb_class) = self.consume_verb_with_metadata();

                // Stative verbs cannot be progressive
                if verb_class.is_stative() && verb_aspect == Aspect::Progressive {
                    return Err(ParseError {
                        kind: ParseErrorKind::StativeProgressiveConflict,
                        span: self.current_span(),
                    });
                }

                // Collect any prepositional phrases before "by" (for ditransitives)
                // "given to Mary by John" → goal = Mary, then agent = John
                let mut goal_args: Vec<Term<'a>> = Vec::new();
                while self.check_to_preposition() {
                    self.advance(); // consume "to"
                    let goal = self.parse_noun_phrase(true)?;
                    goal_args.push(self.noun_phrase_to_term(&goal));
                }

                // Check for passive: "was loved by John" or "was given to Mary by John"
                if self.check_by_preposition() {
                    self.advance(); // consume "by"
                    let agent = self.parse_noun_phrase(true)?;

                    // Build args: agent, theme (subject), then any goals
                    let mut args = vec![
                        self.noun_phrase_to_term(&agent),
                        self.noun_phrase_to_term(&subject),
                    ];
                    args.extend(goal_args);

                    let predicate = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: verb,
                        args: self.ctx.terms.alloc_slice(args),
                    });

                    let with_time = if copula_time == Time::Past {
                        self.ctx.exprs.alloc(LogicExpr::Temporal {
                            operator: TemporalOperator::Past,
                            body: predicate,
                        })
                    } else {
                        predicate
                    };

                    return self.wrap_with_definiteness(subject.definiteness, subject.noun, with_time);
                }

                // Agentless passive: "The book was read" → ∃x.Read(x, Book)
                if copula_time == Time::Past && verb_aspect == Aspect::Simple {
                    // Could be agentless passive - treat as existential
                    let var_name = self.next_var_name();
                    let predicate = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: verb,
                        args: self.ctx.terms.alloc_slice([
                            Term::Variable(var_name),
                            Term::Constant(subject.noun),
                        ]),
                    });

                    let type_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: subject.noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                    });

                    let temporal = self.ctx.exprs.alloc(LogicExpr::Temporal {
                        operator: TemporalOperator::Past,
                        body: predicate,
                    });

                    let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: type_pred,
                        op: TokenType::And,
                        right: temporal,
                    });

                    return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                        kind: QuantifierKind::Existential,
                        variable: var_name,
                        body,
                        island_id: self.current_island,
                    }));
                }

                let predicate = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb,
                    args: self.ctx.terms.alloc_slice([Term::Constant(subject.noun)]),
                });

                let with_aspect = if verb_aspect == Aspect::Progressive {
                    // Semelfactive + Progressive → Iterative
                    let operator = if verb_class == VerbClass::Semelfactive {
                        AspectOperator::Iterative
                    } else {
                        AspectOperator::Progressive
                    };
                    self.ctx.exprs.alloc(LogicExpr::Aspectual {
                        operator,
                        body: predicate,
                    })
                } else {
                    predicate
                };

                let with_time = if copula_time == Time::Past {
                    self.ctx.exprs.alloc(LogicExpr::Temporal {
                        operator: TemporalOperator::Past,
                        body: with_aspect,
                    })
                } else {
                    with_aspect
                };

                return self.wrap_with_definiteness(subject.definiteness, subject.noun, with_time);
            }

            // Handle relative clause with copula: "The book that John read is good."
            if let Some((var_name, rel_clause)) = relative_clause {
                let var_term = Term::Variable(var_name);
                let pred_word = self.consume_content_word()?;

                let main_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: pred_word,
                    args: self.ctx.terms.alloc_slice([var_term]),
                });

                let type_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: subject.noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                });

                let inner = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: type_pred,
                    op: TokenType::And,
                    right: rel_clause,
                });

                let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: inner,
                    op: TokenType::And,
                    right: main_pred,
                });

                return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: var_name,
                    body,
                    island_id: self.current_island,
                }));
            }

            // Handle "The king is bald" - NP copula ADJ/NOUN
            // Also handles bare noun predicates like "Time is money"
            let predicate_name = self.consume_content_word()?;

            // Check for sort violation (metaphor detection)
            let subject_sort = lexicon::lookup_sort(self.interner.resolve(subject.noun));
            let predicate_str = self.interner.resolve(predicate_name);

            // Check ontology's predicate sort requirements (for adjectives like "happy")
            if let Some(s_sort) = subject_sort {
                if !crate::ontology::check_sort_compatibility(predicate_str, s_sort) {
                    let metaphor = self.ctx.exprs.alloc(LogicExpr::Metaphor {
                        tenor: self.ctx.terms.alloc(Term::Constant(subject.noun)),
                        vehicle: self.ctx.terms.alloc(Term::Constant(predicate_name)),
                    });
                    return self.wrap_with_definiteness(subject.definiteness, subject.noun, metaphor);
                }
            }

            // Check copular NP predicate sort compatibility (for "Time is money")
            let predicate_sort = lexicon::lookup_sort(predicate_str);
            if let (Some(s_sort), Some(p_sort)) = (subject_sort, predicate_sort) {
                if s_sort != p_sort && !s_sort.is_compatible_with(p_sort) && !p_sort.is_compatible_with(s_sort) {
                    let metaphor = self.ctx.exprs.alloc(LogicExpr::Metaphor {
                        tenor: self.ctx.terms.alloc(Term::Constant(subject.noun)),
                        vehicle: self.ctx.terms.alloc(Term::Constant(predicate_name)),
                    });
                    return self.wrap_with_definiteness(subject.definiteness, subject.noun, metaphor);
                }
            }

            let predicate = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: predicate_name,
                args: self.ctx.terms.alloc_slice([Term::Constant(subject.noun)]),
            });
            return self.wrap_with_definiteness(subject.definiteness, subject.noun, predicate);
        }

        // Handle auxiliary: set pending_time, handle negation
        if self.check_auxiliary() {
            let aux_time = if let TokenType::Auxiliary(time) = self.advance().kind {
                time
            } else {
                Time::None
            };
            self.pending_time = Some(aux_time);

            // Handle negation: "John did not see dogs"
            if self.match_token(&[TokenType::Not]) {
                self.negative_depth += 1;

                // Skip "ever" if present: "John did not ever run"
                if self.check(&TokenType::Ever) {
                    self.advance();
                }

                if self.check_verb() {
                    let verb = self.consume_verb();
                    let subject_term = self.noun_phrase_to_term(&subject);

                    // Check for NPI object first: "John did not see anything"
                    if self.check_npi_object() {
                        let npi_token = self.advance().kind.clone();
                        let obj_var = self.next_var_name();

                        let restriction_name = match npi_token {
                            TokenType::Anything => "Thing",
                            TokenType::Anyone => "Person",
                            _ => "Thing",
                        };

                        let restriction_sym = self.interner.intern(restriction_name);
                        let obj_restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: restriction_sym,
                            args: self.ctx.terms.alloc_slice([Term::Variable(obj_var)]),
                        });

                        let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: verb,
                            args: self.ctx.terms.alloc_slice([subject_term.clone(), Term::Variable(obj_var)]),
                        });

                        let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: obj_restriction,
                            op: TokenType::And,
                            right: verb_pred,
                        });

                        let quantified = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                            kind: QuantifierKind::Existential,
                            variable: obj_var,
                            body,
                            island_id: self.current_island,
                        });

                        let effective_time = self.pending_time.take().unwrap_or(Time::None);
                        let with_time = match effective_time {
                            Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                                operator: TemporalOperator::Past,
                                body: quantified,
                            }),
                            Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                                operator: TemporalOperator::Future,
                                body: quantified,
                            }),
                            _ => quantified,
                        };

                        self.negative_depth -= 1;
                        return Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                            op: TokenType::Not,
                            operand: with_time,
                        }));
                    }

                    // Check for quantifier object: "John did not see any dogs"
                    if self.check_quantifier() {
                        let quantifier_token = self.advance().kind.clone();
                        let object_np = self.parse_noun_phrase(false)?;
                        let obj_var = self.next_var_name();

                        let obj_restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: object_np.noun,
                            args: self.ctx.terms.alloc_slice([Term::Variable(obj_var)]),
                        });

                        let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: verb,
                            args: self.ctx.terms.alloc_slice([subject_term.clone(), Term::Variable(obj_var)]),
                        });

                        let (kind, body) = match quantifier_token {
                            TokenType::Any => {
                                if self.is_negative_context() {
                                    (
                                        QuantifierKind::Existential,
                                        self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                            left: obj_restriction,
                                            op: TokenType::And,
                                            right: verb_pred,
                                        }),
                                    )
                                } else {
                                    (
                                        QuantifierKind::Universal,
                                        self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                            left: obj_restriction,
                                            op: TokenType::If,
                                            right: verb_pred,
                                        }),
                                    )
                                }
                            }
                            TokenType::Some => (
                                QuantifierKind::Existential,
                                self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                    left: obj_restriction,
                                    op: TokenType::And,
                                    right: verb_pred,
                                }),
                            ),
                            TokenType::All => (
                                QuantifierKind::Universal,
                                self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                    left: obj_restriction,
                                    op: TokenType::If,
                                    right: verb_pred,
                                }),
                            ),
                            _ => (
                                QuantifierKind::Existential,
                                self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                    left: obj_restriction,
                                    op: TokenType::And,
                                    right: verb_pred,
                                }),
                            ),
                        };

                        let quantified = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                            kind,
                            variable: obj_var,
                            body,
                            island_id: self.current_island,
                        });

                        let effective_time = self.pending_time.take().unwrap_or(Time::None);
                        let with_time = match effective_time {
                            Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                                operator: TemporalOperator::Past,
                                body: quantified,
                            }),
                            Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                                operator: TemporalOperator::Future,
                                body: quantified,
                            }),
                            _ => quantified,
                        };

                        self.negative_depth -= 1;
                        return Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                            op: TokenType::Not,
                            operand: with_time,
                        }));
                    }

                    let mut roles: Vec<(ThematicRole, Term<'a>)> = vec![(ThematicRole::Agent, subject_term)];

                    // Add temporal modifier from pending_time
                    let effective_time = self.pending_time.take().unwrap_or(Time::None);
                    let mut modifiers: Vec<Symbol> = vec![];
                    match effective_time {
                        Time::Past => modifiers.push(self.interner.intern("Past")),
                        Time::Future => modifiers.push(self.interner.intern("Future")),
                        _ => {}
                    }

                    // Check for object
                    if self.check_content_word() || self.check_article() {
                        let object = self.parse_noun_phrase(false)?;
                        let object_term = self.noun_phrase_to_term(&object);
                        roles.push((ThematicRole::Theme, object_term));
                    }

                    let event_var = self.get_event_var();
                    let suppress_existential = self.drs.in_conditional_antecedent();
                    if suppress_existential {
                        let event_class = self.interner.intern("Event");
                        self.drs.introduce_referent(event_var, event_class, crate::context::Gender::Neuter);
                    }
                    let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                        event_var,
                        verb,
                        roles: self.ctx.roles.alloc_slice(roles),
                        modifiers: self.ctx.syms.alloc_slice(modifiers),
                        suppress_existential,
                    })));

                    self.negative_depth -= 1;
                    return Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                        op: TokenType::Not,
                        operand: neo_event,
                    }));
                }

                self.negative_depth -= 1;
            }
            // Non-negated auxiliary: pending_time is set, fall through to normal verb handling
        }

        // Check for presupposition triggers: "stopped", "started", "regrets", "knows"
        // Factive verbs like "know" only trigger presupposition with clausal complements
        // "John knows that..." → presupposition, "John knows Mary" → regular verb
        // Only trigger presupposition if followed by a gerund (e.g., "stopped smoking")
        // "John stopped." alone should parse as intransitive verb, not presupposition
        if self.check_presup_trigger() && !self.is_followed_by_np_object() && self.is_followed_by_gerund() {
            let presup_kind = match self.advance().kind {
                TokenType::PresupTrigger(kind) => kind,
                TokenType::Verb { lemma, .. } => {
                    let s = self.interner.resolve(lemma).to_lowercase();
                    crate::lexicon::lookup_presup_trigger(&s)
                        .expect("Lexicon mismatch: Verb flagged as trigger but lookup failed")
                }
                _ => panic!("Expected presupposition trigger"),
            };
            return self.parse_presupposition(&subject, presup_kind);
        }

        // Handle bare plurals: "Birds fly." → Gen x. Bird(x) → Fly(x)
        let noun_str = self.interner.resolve(subject.noun);
        let is_bare_plural = subject.definiteness.is_none()
            && subject.possessor.is_none()
            && Self::is_plural_noun(noun_str)
            && self.check_verb();

        if is_bare_plural {
            let var_name = self.next_var_name();
            let (verb, verb_time, verb_aspect, _) = self.consume_verb_with_metadata();

            let type_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: subject.noun,
                args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
            });

            let mut args = vec![Term::Variable(var_name)];
            if self.check_content_word() {
                let object = self.parse_noun_phrase(false)?;
                args.push(self.noun_phrase_to_term(&object));
            }

            let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice(args),
            });

            let effective_time = self.pending_time.take().unwrap_or(verb_time);
            let with_time = match effective_time {
                Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                    operator: TemporalOperator::Past,
                    body: verb_pred,
                }),
                Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                    operator: TemporalOperator::Future,
                    body: verb_pred,
                }),
                _ => verb_pred,
            };

            let with_aspect = if verb_aspect == Aspect::Progressive {
                self.ctx.exprs.alloc(LogicExpr::Aspectual {
                    operator: AspectOperator::Progressive,
                    body: with_time,
                })
            } else {
                with_time
            };

            let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: type_pred,
                op: TokenType::If,
                right: with_aspect,
            });

            return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                kind: QuantifierKind::Generic,
                variable: var_name,
                body,
                island_id: self.current_island,
            }));
        }

        // Handle do-support: "John does not exist" or "John does run"
        if self.check(&TokenType::Does) || self.check(&TokenType::Do) {
            self.advance(); // consume does/do
            let is_negated = self.match_token(&[TokenType::Not]);

            if self.check_verb() {
                let verb = self.consume_verb();
                let verb_lemma = self.interner.resolve(verb).to_lowercase();

                // Check for embedded wh-clause with negation: "I don't know who"
                if self.check_wh_word() {
                    let wh_token = self.advance().kind.clone();
                    let is_who = matches!(wh_token, TokenType::Who);
                    let is_what = matches!(wh_token, TokenType::What);

                    let is_sluicing = self.is_at_end() ||
                        self.check(&TokenType::Period) ||
                        self.check(&TokenType::Comma);

                    if is_sluicing {
                        if let Some(template) = self.last_event_template.clone() {
                            let wh_var = self.next_var_name();
                            let subject_term = self.noun_phrase_to_term(&subject);

                            let roles: Vec<_> = if is_who {
                                std::iter::once((ThematicRole::Agent, Term::Variable(wh_var)))
                                    .chain(template.non_agent_roles.iter().cloned())
                                    .collect()
                            } else if is_what {
                                vec![
                                    (ThematicRole::Agent, subject_term.clone()),
                                    (ThematicRole::Theme, Term::Variable(wh_var)),
                                ]
                            } else {
                                std::iter::once((ThematicRole::Agent, Term::Variable(wh_var)))
                                    .chain(template.non_agent_roles.iter().cloned())
                                    .collect()
                            };

                            let event_var = self.get_event_var();
                            let suppress_existential = self.drs.in_conditional_antecedent();
                            if suppress_existential {
                                let event_class = self.interner.intern("Event");
                                self.drs.introduce_referent(event_var, event_class, crate::context::Gender::Neuter);
                            }
                            let reconstructed = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                                event_var,
                                verb: template.verb,
                                roles: self.ctx.roles.alloc_slice(roles),
                                modifiers: self.ctx.syms.alloc_slice(template.modifiers.clone()),
                                suppress_existential,
                            })));

                            let question = self.ctx.exprs.alloc(LogicExpr::Question {
                                wh_variable: wh_var,
                                body: reconstructed,
                            });

                            let know_event_var = self.get_event_var();
                            let suppress_existential2 = self.drs.in_conditional_antecedent();
                            if suppress_existential2 {
                                let event_class = self.interner.intern("Event");
                                self.drs.introduce_referent(know_event_var, event_class, crate::context::Gender::Neuter);
                            }
                            let know_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                                event_var: know_event_var,
                                verb,
                                roles: self.ctx.roles.alloc_slice(vec![
                                    (ThematicRole::Agent, subject_term),
                                    (ThematicRole::Theme, Term::Proposition(question)),
                                ]),
                                modifiers: self.ctx.syms.alloc_slice(vec![]),
                                suppress_existential: suppress_existential2,
                            })));

                            let result = if is_negated {
                                self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                                    op: TokenType::Not,
                                    operand: know_event,
                                })
                            } else {
                                know_event
                            };

                            return self.wrap_with_definiteness_full(&subject, result);
                        }
                    }
                }

                // Special handling for "exist" with negation
                if verb_lemma == "exist" && is_negated {
                    // "The King of France does not exist" -> ¬∃x(KingOfFrance(x))
                    let var_name = self.next_var_name();
                    let restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: subject.noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                    });
                    let exists = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                        kind: QuantifierKind::Existential,
                        variable: var_name,
                        body: restriction,
                        island_id: self.current_island,
                    });
                    return Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                        op: TokenType::Not,
                        operand: exists,
                    }));
                }

                // Regular do-support: "John does run" or "John does not run"
                let subject_term = self.noun_phrase_to_term(&subject);
                let roles: Vec<(ThematicRole, Term<'a>)> = vec![(ThematicRole::Agent, subject_term)];
                let modifiers: Vec<Symbol> = vec![];
                let event_var = self.get_event_var();
                let suppress_existential = self.drs.in_conditional_antecedent();
                if suppress_existential {
                    let event_class = self.interner.intern("Event");
                    self.drs.introduce_referent(event_var, event_class, crate::context::Gender::Neuter);
                }

                let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                    event_var,
                    verb,
                    roles: self.ctx.roles.alloc_slice(roles),
                    modifiers: self.ctx.syms.alloc_slice(modifiers),
                    suppress_existential,
                })));

                if is_negated {
                    return Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                        op: TokenType::Not,
                        operand: neo_event,
                    }));
                }
                return Ok(neo_event);
            }
        }

        // Garden path detection: "The horse raced past the barn fell."
        // If we have a definite NP + past verb + more content + another verb,
        // try reduced relative interpretation
        // Skip if pending_time is set (auxiliary like "will" was just consumed)
        // Skip if verb is has/have/had (perfect aspect, not reduced relative)
        let is_perfect_aux = if self.check_verb() {
            let word = self.interner.resolve(self.peek().lexeme).to_lowercase();
            word == "has" || word == "have" || word == "had"
        } else {
            false
        };
        if subject.definiteness == Some(Definiteness::Definite) && self.check_verb() && self.pending_time.is_none() && !is_perfect_aux {
            let saved_pos = self.current;

            // Try parsing as reduced relative: first verb is modifier, look for main verb after
            if let Some(garden_path_result) = self.try_parse(|p| {
                let (modifier_verb, _modifier_time, _, _) = p.consume_verb_with_metadata();

                // Collect any PP modifiers on the reduced relative
                let mut pp_mods: Vec<&'a LogicExpr<'a>> = Vec::new();
                while p.check_preposition() {
                    let prep = if let TokenType::Preposition(prep) = p.advance().kind {
                        prep
                    } else {
                        break;
                    };
                    if p.check_article() || p.check_content_word() {
                        let pp_obj = p.parse_noun_phrase(false)?;
                        let pp_pred = p.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: prep,
                            args: p.ctx.terms.alloc_slice([Term::Variable(p.interner.intern("x")), Term::Constant(pp_obj.noun)]),
                        });
                        pp_mods.push(pp_pred);
                    }
                }

                // Now check if there's ANOTHER verb (the real main verb)
                if !p.check_verb() {
                    return Err(ParseError {
                        kind: ParseErrorKind::ExpectedVerb { found: p.peek().kind.clone() },
                        span: p.current_span(),
                    });
                }

                let (main_verb, main_time, _, _) = p.consume_verb_with_metadata();

                // Build: ∃x((Horse(x) ∧ ∀y(Horse(y) → y=x)) ∧ Raced(x) ∧ Past(x, Barn) ∧ Fell(x))
                let var = p.interner.intern("x");

                // Type predicate
                let type_pred = p.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: subject.noun,
                    args: p.ctx.terms.alloc_slice([Term::Variable(var)]),
                });

                // Modifier verb predicate (reduced relative)
                let mod_pred = p.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: modifier_verb,
                    args: p.ctx.terms.alloc_slice([Term::Variable(var)]),
                });

                // Main verb predicate
                let main_pred = p.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: main_verb,
                    args: p.ctx.terms.alloc_slice([Term::Variable(var)]),
                });

                // Combine type + modifier
                let mut body = p.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: type_pred,
                    op: TokenType::And,
                    right: mod_pred,
                });

                // Add PP modifiers
                for pp in pp_mods {
                    body = p.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: body,
                        op: TokenType::And,
                        right: pp,
                    });
                }

                // Add main predicate
                body = p.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: body,
                    op: TokenType::And,
                    right: main_pred,
                });

                // Wrap with temporal if needed
                let with_time = match main_time {
                    Time::Past => p.ctx.exprs.alloc(LogicExpr::Temporal {
                        operator: TemporalOperator::Past,
                        body,
                    }),
                    Time::Future => p.ctx.exprs.alloc(LogicExpr::Temporal {
                        operator: TemporalOperator::Future,
                        body,
                    }),
                    _ => body,
                };

                // Wrap in existential quantifier for definite
                Ok(p.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: var,
                    body: with_time,
                    island_id: p.current_island,
                }))
            }) {
                return Ok(garden_path_result);
            }

            // Restore position if garden path didn't work
            self.current = saved_pos;
        }

        if self.check_modal() {
            return self.parse_aspect_chain(subject.noun);
        }

        // Handle "has/have/had" perfect aspect: "John has run"
        if self.check_content_word() {
            let word = self.interner.resolve(self.peek().lexeme).to_lowercase();
            if word == "has" || word == "have" || word == "had" {
                // Lookahead to distinguish perfect aspect ("has eaten") from possession ("has 3 children")
                let is_perfect_aspect = if self.current + 1 < self.tokens.len() {
                    let next_token = &self.tokens[self.current + 1].kind;
                    matches!(
                        next_token,
                        TokenType::Verb { .. } | TokenType::Not
                    ) && !matches!(next_token, TokenType::Number(_))
                } else {
                    false
                };
                if is_perfect_aspect {
                    return self.parse_aspect_chain(subject.noun);
                }
                // Otherwise fall through to verb parsing below
            }
        }

        // Handle TokenType::Had for past perfect: "John had run"
        if self.check(&TokenType::Had) {
            return self.parse_aspect_chain(subject.noun);
        }

        // Handle "never" temporal negation: "John never runs"
        if self.check(&TokenType::Never) {
            self.advance();
            let verb = self.consume_verb();
            let subject_term = self.noun_phrase_to_term(&subject);
            let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice([subject_term]),
            });
            let result = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                op: TokenType::Not,
                operand: verb_pred,
            });
            return self.wrap_with_definiteness_full(&subject, result);
        }

        if self.check_verb() {
            let (mut verb, verb_time, verb_aspect, verb_class) = self.consume_verb_with_metadata();

            // Check for verb sort violation (metaphor detection)
            let subject_sort = lexicon::lookup_sort(self.interner.resolve(subject.noun));
            let verb_str = self.interner.resolve(verb);
            if let Some(s_sort) = subject_sort {
                if !crate::ontology::check_sort_compatibility(verb_str, s_sort) {
                    let metaphor = self.ctx.exprs.alloc(LogicExpr::Metaphor {
                        tenor: self.ctx.terms.alloc(Term::Constant(subject.noun)),
                        vehicle: self.ctx.terms.alloc(Term::Constant(verb)),
                    });
                    return self.wrap_with_definiteness(subject.definiteness, subject.noun, metaphor);
                }
            }

            // Check for control verb + infinitive
            if self.is_control_verb(verb) {
                return self.parse_control_structure(&subject, verb, verb_time);
            }

            // If we have a relative clause, use variable binding
            if let Some((var_name, rel_clause)) = relative_clause {
                let main_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                });

                let effective_time = self.pending_time.take().unwrap_or(verb_time);
                let with_time = match effective_time {
                    Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                        operator: TemporalOperator::Past,
                        body: main_pred,
                    }),
                    Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                        operator: TemporalOperator::Future,
                        body: main_pred,
                    }),
                    _ => main_pred,
                };

                // Build: ∃x(Type(x) ∧ RelClause(x) ∧ MainPred(x))
                let type_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: subject.noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                });

                let inner = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: type_pred,
                    op: TokenType::And,
                    right: rel_clause,
                });

                let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: inner,
                    op: TokenType::And,
                    right: with_time,
                });

                return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: var_name,
                    body,
                    island_id: self.current_island,
                }));
            }

            let subject_term = self.noun_phrase_to_term(&subject);
            let mut args = vec![subject_term.clone()];

            let unknown = self.interner.intern("?");

            // Check for embedded wh-clause: "I know who/what"
            if self.check_wh_word() {
                let wh_token = self.advance().kind.clone();

                // Determine wh-type for slot matching
                let is_who = matches!(wh_token, TokenType::Who);
                let is_what = matches!(wh_token, TokenType::What);

                // Check for sluicing: wh-word followed by terminator
                let is_sluicing = self.is_at_end() ||
                    self.check(&TokenType::Period) ||
                    self.check(&TokenType::Comma);

                if is_sluicing {
                    // Reconstruct from template
                    if let Some(template) = self.last_event_template.clone() {
                        let wh_var = self.next_var_name();

                        // Build roles with wh-variable in appropriate slot
                        let roles: Vec<_> = if is_who {
                            // "who" replaces Agent
                            std::iter::once((ThematicRole::Agent, Term::Variable(wh_var)))
                                .chain(template.non_agent_roles.iter().cloned())
                                .collect()
                        } else if is_what {
                            // "what" replaces Theme - use Agent from context, Theme is variable
                            vec![
                                (ThematicRole::Agent, subject_term.clone()),
                                (ThematicRole::Theme, Term::Variable(wh_var)),
                            ]
                        } else {
                            // Default: wh-variable as Agent
                            std::iter::once((ThematicRole::Agent, Term::Variable(wh_var)))
                                .chain(template.non_agent_roles.iter().cloned())
                                .collect()
                        };

                        let event_var = self.get_event_var();
                        let suppress_existential = self.drs.in_conditional_antecedent();
                        if suppress_existential {
                            let event_class = self.interner.intern("Event");
                            self.drs.introduce_referent(event_var, event_class, crate::context::Gender::Neuter);
                        }
                        let reconstructed = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                            event_var,
                            verb: template.verb,
                            roles: self.ctx.roles.alloc_slice(roles),
                            modifiers: self.ctx.syms.alloc_slice(template.modifiers.clone()),
                            suppress_existential,
                        })));

                        let question = self.ctx.exprs.alloc(LogicExpr::Question {
                            wh_variable: wh_var,
                            body: reconstructed,
                        });

                        // Build: Know(subject, question)
                        let know_event_var = self.get_event_var();
                        let suppress_existential2 = self.drs.in_conditional_antecedent();
                        if suppress_existential2 {
                            let event_class = self.interner.intern("Event");
                            self.drs.introduce_referent(know_event_var, event_class, crate::context::Gender::Neuter);
                        }
                        let know_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                            event_var: know_event_var,
                            verb,
                            roles: self.ctx.roles.alloc_slice(vec![
                                (ThematicRole::Agent, subject_term),
                                (ThematicRole::Theme, Term::Proposition(question)),
                            ]),
                            modifiers: self.ctx.syms.alloc_slice(vec![]),
                            suppress_existential: suppress_existential2,
                        })));

                        return self.wrap_with_definiteness_full(&subject, know_event);
                    }
                }

                // Non-sluicing embedded question: "I know who runs"
                let embedded = self.parse_embedded_wh_clause()?;
                let question = self.ctx.exprs.alloc(LogicExpr::Question {
                    wh_variable: self.interner.intern("x"),
                    body: embedded,
                });

                // Build: Know(subject, question)
                let know_event_var = self.get_event_var();
                let suppress_existential = self.drs.in_conditional_antecedent();
                if suppress_existential {
                    let event_class = self.interner.intern("Event");
                    self.drs.introduce_referent(know_event_var, event_class, crate::context::Gender::Neuter);
                }
                let know_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                    event_var: know_event_var,
                    verb,
                    roles: self.ctx.roles.alloc_slice(vec![
                        (ThematicRole::Agent, subject_term),
                        (ThematicRole::Theme, Term::Proposition(question)),
                    ]),
                    modifiers: self.ctx.syms.alloc_slice(vec![]),
                    suppress_existential,
                })));

                return self.wrap_with_definiteness_full(&subject, know_event);
            }

            let mut object_term: Option<Term<'a>> = None;
            let mut second_object_term: Option<Term<'a>> = None;
            let mut object_superlative: Option<(Symbol, Symbol)> = None; // (adjective, noun)
            if self.check(&TokenType::Reflexive) {
                self.advance();
                let term = self.noun_phrase_to_term(&subject);
                object_term = Some(term.clone());
                args.push(term);

                // Check for distanced phrasal verb particle: "gave himself up"
                if let TokenType::Particle(particle_sym) = self.peek().kind {
                    let verb_str = self.interner.resolve(verb).to_lowercase();
                    let particle_str = self.interner.resolve(particle_sym).to_lowercase();
                    if let Some((phrasal_lemma, _class)) = crate::lexicon::lookup_phrasal_verb(&verb_str, &particle_str) {
                        self.advance();
                        verb = self.interner.intern(phrasal_lemma);
                    }
                }
            } else if self.check_pronoun() {
                let token = self.advance().clone();
                if let TokenType::Pronoun { gender, number, .. } = token.kind {
                    let resolved = self.resolve_pronoun(gender, number)
                        .unwrap_or(unknown);
                    let term = Term::Constant(resolved);
                    object_term = Some(term.clone());
                    args.push(term);

                    // Check for distanced phrasal verb particle: "gave it up"
                    if let TokenType::Particle(particle_sym) = self.peek().kind {
                        let verb_str = self.interner.resolve(verb).to_lowercase();
                        let particle_str = self.interner.resolve(particle_sym).to_lowercase();
                        if let Some((phrasal_lemma, _class)) = crate::lexicon::lookup_phrasal_verb(&verb_str, &particle_str) {
                            self.advance();
                            verb = self.interner.intern(phrasal_lemma);
                        }
                    }
                }
            } else if self.check_quantifier() || self.check_article() {
                // Quantified object: "John loves every woman" or "John saw a dog"
                let obj_quantifier = if self.check_quantifier() {
                    Some(self.advance().kind.clone())
                } else {
                    let art = self.advance().kind.clone();
                    if let TokenType::Article(def) = art {
                        if def == Definiteness::Indefinite {
                            Some(TokenType::Some)
                        } else {
                            None
                        }
                    } else {
                        None
                    }
                };

                let object_np = self.parse_noun_phrase(false)?;

                // Capture superlative info for constraint generation
                if let Some(adj) = object_np.superlative {
                    object_superlative = Some((adj, object_np.noun));
                }

                // Check for distanced phrasal verb particle: "gave the book up"
                if let TokenType::Particle(particle_sym) = self.peek().kind {
                    let verb_str = self.interner.resolve(verb).to_lowercase();
                    let particle_str = self.interner.resolve(particle_sym).to_lowercase();
                    if let Some((phrasal_lemma, _class)) = crate::lexicon::lookup_phrasal_verb(&verb_str, &particle_str) {
                        self.advance(); // consume the particle
                        verb = self.interner.intern(phrasal_lemma);
                    }
                }

                if let Some(obj_q) = obj_quantifier {
                    // Check for opaque verb with indefinite object (de dicto reading)
                    // For verbs like "seek", "want", "believe" with indefinite objects,
                    // use Term::Intension to represent the intensional (concept) reading
                    let verb_str = self.interner.resolve(verb).to_lowercase();
                    let is_opaque = lexicon::lookup_verb_db(&verb_str)
                        .map(|meta| meta.features.contains(&lexicon::Feature::Opaque))
                        .unwrap_or(false);

                    if is_opaque && matches!(obj_q, TokenType::Some) {
                        // De dicto reading: use Term::Intension for the theme
                        let intension_term = Term::Intension(object_np.noun);

                        // Register intensional entity for anaphora resolution
                        let noun_str = self.interner.resolve(object_np.noun).to_string();
                        let first_char = noun_str.chars().next().unwrap_or('X');
                        if first_char.is_alphabetic() {
                            // Use full noun name with ^ prefix for intensional terms
                            let symbol = format!("^{}", crate::transpile::capitalize_first(&noun_str));
                            self.register_entity(&symbol, &noun_str, Gender::Neuter, Number::Singular);
                        }

                        let event_var = self.get_event_var();
                        let mut modifiers = self.collect_adverbs();
                        let effective_time = self.pending_time.take().unwrap_or(verb_time);
                        match effective_time {
                            Time::Past => modifiers.push(self.interner.intern("Past")),
                            Time::Future => modifiers.push(self.interner.intern("Future")),
                            _ => {}
                        }

                        let subject_term_for_event = self.noun_phrase_to_term(&subject);
                        let roles = vec![
                            (ThematicRole::Agent, subject_term_for_event),
                            (ThematicRole::Theme, intension_term),
                        ];

                        let suppress_existential = self.drs.in_conditional_antecedent();
                        if suppress_existential {
                            let event_class = self.interner.intern("Event");
                            self.drs.introduce_referent(event_var, event_class, crate::context::Gender::Neuter);
                        }
                        let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                            event_var,
                            verb,
                            roles: self.ctx.roles.alloc_slice(roles),
                            modifiers: self.ctx.syms.alloc_slice(modifiers),
                            suppress_existential,
                        })));

                        return self.wrap_with_definiteness_full(&subject, neo_event);
                    }

                    let obj_var = self.next_var_name();
                    let type_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: object_np.noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(obj_var)]),
                    });

                    let obj_restriction = if self.check(&TokenType::That) || self.check(&TokenType::Who) {
                        self.advance();
                        let rel_clause = self.parse_relative_clause(obj_var)?;
                        self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: type_pred,
                            op: TokenType::And,
                            right: rel_clause,
                        })
                    } else {
                        type_pred
                    };

                    let event_var = self.get_event_var();
                    let mut modifiers = self.collect_adverbs();
                    let effective_time = self.pending_time.take().unwrap_or(verb_time);
                    match effective_time {
                        Time::Past => modifiers.push(self.interner.intern("Past")),
                        Time::Future => modifiers.push(self.interner.intern("Future")),
                        _ => {}
                    }

                    let subject_term_for_event = self.noun_phrase_to_term(&subject);
                    let roles = vec![
                        (ThematicRole::Agent, subject_term_for_event),
                        (ThematicRole::Theme, Term::Variable(obj_var)),
                    ];

                    // Capture template with object type for ellipsis reconstruction
                    // Use the object noun type instead of variable for reconstruction
                    let template_roles = vec![
                        (ThematicRole::Agent, subject_term_for_event),
                        (ThematicRole::Theme, Term::Constant(object_np.noun)),
                    ];
                    self.capture_event_template(verb, &template_roles, &modifiers);

                    let suppress_existential = self.drs.in_conditional_antecedent();
                    if suppress_existential {
                        let event_class = self.interner.intern("Event");
                        self.drs.introduce_referent(event_var, event_class, crate::context::Gender::Neuter);
                    }
                    let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                        event_var,
                        verb,
                        roles: self.ctx.roles.alloc_slice(roles),
                        modifiers: self.ctx.syms.alloc_slice(modifiers),
                        suppress_existential,
                    })));

                    let obj_kind = match obj_q {
                        TokenType::All => QuantifierKind::Universal,
                        TokenType::Some => QuantifierKind::Existential,
                        TokenType::No => QuantifierKind::Universal,
                        TokenType::Most => QuantifierKind::Most,
                        TokenType::Few => QuantifierKind::Few,
                        TokenType::Many => QuantifierKind::Many,
                        TokenType::Cardinal(n) => QuantifierKind::Cardinal(n),
                        TokenType::AtLeast(n) => QuantifierKind::AtLeast(n),
                        TokenType::AtMost(n) => QuantifierKind::AtMost(n),
                        _ => QuantifierKind::Existential,
                    };

                    let obj_body = match obj_q {
                        TokenType::All => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: obj_restriction,
                            op: TokenType::If,
                            right: neo_event,
                        }),
                        TokenType::No => {
                            let neg = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                                op: TokenType::Not,
                                operand: neo_event,
                            });
                            self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                left: obj_restriction,
                                op: TokenType::If,
                                right: neg,
                            })
                        }
                        _ => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: obj_restriction,
                            op: TokenType::And,
                            right: neo_event,
                        }),
                    };

                    return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                        kind: obj_kind,
                        variable: obj_var,
                        body: obj_body,
                        island_id: self.current_island,
                    }));
                } else {
                    let term = self.noun_phrase_to_term(&object_np);
                    object_term = Some(term.clone());
                    args.push(term);
                }
            } else if self.check_focus() {
                let focus_kind = if let TokenType::Focus(k) = self.advance().kind {
                    k
                } else {
                    FocusKind::Only
                };

                let event_var = self.get_event_var();
                let mut modifiers = self.collect_adverbs();
                let effective_time = self.pending_time.take().unwrap_or(verb_time);
                match effective_time {
                    Time::Past => modifiers.push(self.interner.intern("Past")),
                    Time::Future => modifiers.push(self.interner.intern("Future")),
                    _ => {}
                }

                let subject_term_for_event = self.noun_phrase_to_term(&subject);

                if self.check_preposition() {
                    let prep_token = self.advance().clone();
                    let prep_name = if let TokenType::Preposition(sym) = prep_token.kind {
                        sym
                    } else {
                        self.interner.intern("to")
                    };
                    let pp_obj = self.parse_noun_phrase(false)?;
                    let pp_obj_term = Term::Constant(pp_obj.noun);

                    let roles = vec![(ThematicRole::Agent, subject_term_for_event)];
                    let suppress_existential = self.drs.in_conditional_antecedent();
                    if suppress_existential {
                        let event_class = self.interner.intern("Event");
                        self.drs.introduce_referent(event_var, event_class, crate::context::Gender::Neuter);
                    }
                    let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                        event_var,
                        verb,
                        roles: self.ctx.roles.alloc_slice(roles),
                        modifiers: self.ctx.syms.alloc_slice(modifiers),
                        suppress_existential,
                    })));

                    let pp_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: prep_name,
                        args: self.ctx.terms.alloc_slice([Term::Variable(event_var), pp_obj_term]),
                    });

                    let with_pp = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: neo_event,
                        op: TokenType::And,
                        right: pp_pred,
                    });

                    let focused_ref = self.ctx.terms.alloc(pp_obj_term);
                    return Ok(self.ctx.exprs.alloc(LogicExpr::Focus {
                        kind: focus_kind,
                        focused: focused_ref,
                        scope: with_pp,
                    }));
                }

                let focused_np = self.parse_noun_phrase(false)?;
                let focused_term = self.noun_phrase_to_term(&focused_np);
                args.push(focused_term.clone());

                let roles = vec![
                    (ThematicRole::Agent, subject_term_for_event),
                    (ThematicRole::Theme, focused_term.clone()),
                ];

                let suppress_existential = self.drs.in_conditional_antecedent();
                if suppress_existential {
                    let event_class = self.interner.intern("Event");
                    self.drs.introduce_referent(event_var, event_class, crate::context::Gender::Neuter);
                }
                let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                    event_var,
                    verb,
                    roles: self.ctx.roles.alloc_slice(roles),
                    modifiers: self.ctx.syms.alloc_slice(modifiers),
                    suppress_existential,
                })));

                let focused_ref = self.ctx.terms.alloc(focused_term);
                return Ok(self.ctx.exprs.alloc(LogicExpr::Focus {
                    kind: focus_kind,
                    focused: focused_ref,
                    scope: neo_event,
                }));
            } else if self.check_number() {
                // Handle "has 3 children" or "has cardinality aleph_0"
                let measure = self.parse_measure_phrase()?;

                // If there's a noun after the measure (for "3 children" where children wasn't a unit)
                if self.check_content_word() {
                    let noun_sym = self.consume_content_word()?;
                    // Build: Has(Subject, 3, Children) where 3 is the count
                    let count_term = *measure;
                    object_term = Some(count_term.clone());
                    args.push(count_term);
                    second_object_term = Some(Term::Constant(noun_sym));
                    args.push(Term::Constant(noun_sym));
                } else {
                    // Just the measure: "has cardinality 5"
                    object_term = Some(*measure);
                    args.push(*measure);
                }
            } else if self.check_content_word() || self.check_article() {
                let object = self.parse_noun_phrase(false)?;
                if let Some(adj) = object.superlative {
                    object_superlative = Some((adj, object.noun));
                }

                // Collect all objects for potential "respectively" handling
                let mut all_objects: Vec<Symbol> = vec![object.noun];

                // Check for coordinated objects: "Tom and Jerry and Bob"
                while self.check(&TokenType::And) {
                    let saved = self.current;
                    self.advance(); // consume "and"
                    if self.check_content_word() || self.check_article() {
                        let next_obj = match self.parse_noun_phrase(false) {
                            Ok(np) => np,
                            Err(_) => {
                                self.current = saved;
                                break;
                            }
                        };
                        all_objects.push(next_obj.noun);
                    } else {
                        self.current = saved;
                        break;
                    }
                }

                // Check for "respectively" with single subject
                if self.check(&TokenType::Respectively) {
                    let respectively_span = self.peek().span;
                    // Single subject with multiple objects + respectively = error
                    if all_objects.len() > 1 {
                        return Err(ParseError {
                            kind: ParseErrorKind::RespectivelyLengthMismatch {
                                subject_count: 1,
                                object_count: all_objects.len(),
                            },
                            span: respectively_span,
                        });
                    }
                    // Single subject, single object + respectively is valid (trivially pairwise)
                    self.advance(); // consume "respectively"
                }

                // Use the first object (or only object) for normal processing
                let term = self.noun_phrase_to_term(&object);
                object_term = Some(term.clone());
                args.push(term.clone());

                // For multiple objects without "respectively", use group semantics
                if all_objects.len() > 1 {
                    let obj_members: Vec<Term<'a>> = all_objects.iter()
                        .map(|o| Term::Constant(*o))
                        .collect();
                    let obj_group = Term::Group(self.ctx.terms.alloc_slice(obj_members));
                    // Replace the single object with the group
                    args.pop();
                    args.push(obj_group);
                }

                // Check for distanced phrasal verb particle: "gave the book up"
                if let TokenType::Particle(particle_sym) = self.peek().kind {
                    let verb_str = self.interner.resolve(verb).to_lowercase();
                    let particle_str = self.interner.resolve(particle_sym).to_lowercase();
                    if let Some((phrasal_lemma, _class)) = crate::lexicon::lookup_phrasal_verb(&verb_str, &particle_str) {
                        self.advance(); // consume the particle
                        verb = self.interner.intern(phrasal_lemma);
                    }
                }

                // Check for "has cardinality aleph_0" pattern: noun followed by number
                if self.check_number() {
                    let measure = self.parse_measure_phrase()?;
                    second_object_term = Some(*measure);
                    args.push(*measure);
                }
                // Check for ditransitive: "John gave Mary a book"
                else {
                    let verb_str = self.interner.resolve(verb);
                    if Lexer::is_ditransitive_verb(verb_str) && (self.check_content_word() || self.check_article()) {
                        let second_np = self.parse_noun_phrase(false)?;
                        let second_term = self.noun_phrase_to_term(&second_np);
                        second_object_term = Some(second_term.clone());
                        args.push(second_term);
                    }
                }
            }

            let mut pp_predicates: Vec<&'a LogicExpr<'a>> = Vec::new();
            while self.check_preposition() || self.check_to() {
                let prep_token = self.advance().clone();
                let prep_name = if let TokenType::Preposition(sym) = prep_token.kind {
                    sym
                } else if matches!(prep_token.kind, TokenType::To) {
                    self.interner.intern("To")
                } else {
                    continue;
                };

                let pp_obj_term = if self.check(&TokenType::Reflexive) {
                    self.advance();
                    self.noun_phrase_to_term(&subject)
                } else if self.check_pronoun() {
                    let token = self.advance().clone();
                    if let TokenType::Pronoun { gender, number, .. } = token.kind {
                        let resolved = self.resolve_pronoun(gender, number)
                            .unwrap_or(unknown);
                        Term::Constant(resolved)
                    } else {
                        continue;
                    }
                } else if self.check_content_word() || self.check_article() {
                    let prep_obj = self.parse_noun_phrase(false)?;
                    self.noun_phrase_to_term(&prep_obj)
                } else {
                    continue;
                };

                if self.pp_attach_to_noun {
                    if let Some(ref obj) = object_term {
                        // NP-attachment: PP modifies the object noun
                        let pp_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: prep_name,
                            args: self.ctx.terms.alloc_slice([obj.clone(), pp_obj_term]),
                        });
                        pp_predicates.push(pp_pred);
                    } else {
                        args.push(pp_obj_term);
                    }
                } else {
                    // VP-attachment: PP modifies the event (instrument/manner)
                    let event_sym = self.get_event_var();
                    let pp_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: prep_name,
                        args: self.ctx.terms.alloc_slice([Term::Variable(event_sym), pp_obj_term]),
                    });
                    pp_predicates.push(pp_pred);
                }
            }

            // Check for trailing relative clause on object NP: "the girl with the telescope that laughed"
            if self.check(&TokenType::That) || self.check(&TokenType::Who) {
                self.advance();
                let rel_var = self.next_var_name();
                let rel_pred = self.parse_relative_clause(rel_var)?;
                pp_predicates.push(rel_pred);
            }

            // Collect any trailing adverbs FIRST (before building NeoEvent)
            let mut modifiers = self.collect_adverbs();

            // Add temporal modifier as part of event semantics
            let effective_time = self.pending_time.take().unwrap_or(verb_time);
            match effective_time {
                Time::Past => modifiers.push(self.interner.intern("Past")),
                Time::Future => modifiers.push(self.interner.intern("Future")),
                _ => {}
            }

            // Add aspect modifier if applicable
            if verb_aspect == Aspect::Progressive {
                modifiers.push(self.interner.intern("Progressive"));
            } else if verb_aspect == Aspect::Perfect {
                modifiers.push(self.interner.intern("Perfect"));
            }

            // Build thematic roles for Neo-Davidsonian event semantics
            let mut roles: Vec<(ThematicRole, Term<'a>)> = Vec::new();

            // Check if verb is unaccusative (intransitive subject is Theme, not Agent)
            let verb_str_for_check = self.interner.resolve(verb).to_lowercase();
            let is_unaccusative = crate::lexicon::lookup_verb_db(&verb_str_for_check)
                .map(|meta| meta.features.contains(&crate::lexicon::Feature::Unaccusative))
                .unwrap_or(false);

            // Unaccusative verbs used intransitively: subject is Theme
            let has_object = object_term.is_some() || second_object_term.is_some();
            let subject_role = if is_unaccusative && !has_object {
                ThematicRole::Theme
            } else {
                ThematicRole::Agent
            };

            roles.push((subject_role, subject_term));
            if let Some(second_obj) = second_object_term {
                // Ditransitive: first object is Recipient, second is Theme
                if let Some(first_obj) = object_term {
                    roles.push((ThematicRole::Recipient, first_obj));
                }
                roles.push((ThematicRole::Theme, second_obj));
            } else if let Some(obj) = object_term {
                // Normal transitive: object is Theme
                roles.push((ThematicRole::Theme, obj));
            }

            // Create event variable
            let event_var = self.get_event_var();

            // Capture template for ellipsis reconstruction before consuming roles
            self.capture_event_template(verb, &roles, &modifiers);

            // Create NeoEvent structure with all modifiers including time/aspect
            let suppress_existential = self.drs.in_conditional_antecedent();
            if suppress_existential {
                let event_class = self.interner.intern("Event");
                self.drs.introduce_referent(event_var, event_class, crate::context::Gender::Neuter);
            }
            let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                event_var,
                verb,
                roles: self.ctx.roles.alloc_slice(roles),
                modifiers: self.ctx.syms.alloc_slice(modifiers),
                suppress_existential,
            })));

            // Combine with PP predicates if any
            let with_pps = if pp_predicates.is_empty() {
                neo_event
            } else {
                let mut combined = neo_event;
                for pp in pp_predicates {
                    combined = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: combined,
                        op: TokenType::And,
                        right: pp,
                    });
                }
                combined
            };

            // Apply aspectual operators based on verb class
            let with_aspect = if verb_aspect == Aspect::Progressive {
                // Semelfactive + Progressive → Iterative
                if verb_class == crate::lexicon::VerbClass::Semelfactive {
                    self.ctx.exprs.alloc(LogicExpr::Aspectual {
                        operator: AspectOperator::Iterative,
                        body: with_pps,
                    })
                } else {
                    // Other verbs + Progressive → Progressive
                    self.ctx.exprs.alloc(LogicExpr::Aspectual {
                        operator: AspectOperator::Progressive,
                        body: with_pps,
                    })
                }
            } else if verb_aspect == Aspect::Perfect {
                self.ctx.exprs.alloc(LogicExpr::Aspectual {
                    operator: AspectOperator::Perfect,
                    body: with_pps,
                })
            } else if effective_time == Time::Present && verb_aspect == Aspect::Simple {
                // Non-state verbs in simple present get Habitual reading
                if !verb_class.is_stative() {
                    self.ctx.exprs.alloc(LogicExpr::Aspectual {
                        operator: AspectOperator::Habitual,
                        body: with_pps,
                    })
                } else {
                    // State verbs in present: direct predication
                    with_pps
                }
            } else {
                with_pps
            };

            let with_adverbs = with_aspect;

            // Check for temporal anchor adverb at end of sentence
            let with_temporal = if self.check_temporal_adverb() {
                let anchor = if let TokenType::TemporalAdverb(adv) = self.advance().kind.clone() {
                    adv
                } else {
                    panic!("Expected temporal adverb");
                };
                self.ctx.exprs.alloc(LogicExpr::TemporalAnchor {
                    anchor,
                    body: with_adverbs,
                })
            } else {
                with_adverbs
            };

            let wrapped = self.wrap_with_definiteness_full(&subject, with_temporal)?;

            // Add superlative constraint for object NP if applicable
            if let Some((adj, noun)) = object_superlative {
                let superlative_expr = self.ctx.exprs.alloc(LogicExpr::Superlative {
                    adjective: adj,
                    subject: self.ctx.terms.alloc(Term::Constant(noun)),
                    domain: noun,
                });
                return Ok(self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: wrapped,
                    op: TokenType::And,
                    right: superlative_expr,
                }));
            }

            return Ok(wrapped);
        }

        Ok(self.ctx.exprs.alloc(LogicExpr::Atom(subject.noun)))
    }

    fn check_preposition(&self) -> bool {
        matches!(self.peek().kind, TokenType::Preposition(_))
    }

    fn check_by_preposition(&self) -> bool {
        if let TokenType::Preposition(p) = self.peek().kind {
            p.is(self.interner, "by")
        } else {
            false
        }
    }

    fn check_preposition_is(&self, word: &str) -> bool {
        if let TokenType::Preposition(p) = self.peek().kind {
            p.is(self.interner, word)
        } else {
            false
        }
    }

    /// Check if current token is a word (noun/adj/verb lexeme) matching the given string
    fn check_word(&self, word: &str) -> bool {
        let token = self.peek();
        let lexeme = self.interner.resolve(token.lexeme);
        lexeme.eq_ignore_ascii_case(word)
    }

    fn check_to_preposition(&self) -> bool {
        if let TokenType::Preposition(p) = self.peek().kind {
            p.is(self.interner, "to")
        } else {
            false
        }
    }

    fn check_content_word(&self) -> bool {
        match &self.peek().kind {
            TokenType::Noun(_)
            | TokenType::Adjective(_)
            | TokenType::NonIntersectiveAdjective(_)
            | TokenType::Verb { .. }
            | TokenType::ProperName(_)
            | TokenType::Article(_) => true,
            TokenType::Ambiguous { primary, alternatives } => {
                Self::is_content_word_type(primary)
                    || alternatives.iter().any(Self::is_content_word_type)
            }
            _ => false,
        }
    }

    fn is_content_word_type(t: &TokenType) -> bool {
        matches!(
            t,
            TokenType::Noun(_)
                | TokenType::Adjective(_)
                | TokenType::NonIntersectiveAdjective(_)
                | TokenType::Verb { .. }
                | TokenType::ProperName(_)
                | TokenType::Article(_)
        )
    }

    fn check_verb(&self) -> bool {
        match &self.peek().kind {
            TokenType::Verb { .. } => true,
            TokenType::Ambiguous { primary, alternatives } => {
                if self.noun_priority_mode {
                    return false;
                }
                matches!(**primary, TokenType::Verb { .. })
                    || alternatives.iter().any(|t| matches!(t, TokenType::Verb { .. }))
            }
            _ => false,
        }
    }

    fn check_adverb(&self) -> bool {
        matches!(self.peek().kind, TokenType::Adverb(_))
    }

    fn check_performative(&self) -> bool {
        matches!(self.peek().kind, TokenType::Performative(_))
    }

    fn collect_adverbs(&mut self) -> Vec<Symbol> {
        let mut adverbs = Vec::new();
        while self.check_adverb() {
            if let TokenType::Adverb(adv) = self.advance().kind.clone() {
                adverbs.push(adv);
            }
            // Skip "and" between adverbs
            if self.check(&TokenType::And) {
                self.advance();
            }
        }
        adverbs
    }

    fn check_auxiliary(&self) -> bool {
        matches!(self.peek().kind, TokenType::Auxiliary(_))
    }

    fn check_to(&self) -> bool {
        matches!(self.peek().kind, TokenType::To)
    }


    fn consume_verb(&mut self) -> Symbol {
        let t = self.advance().clone();
        match t.kind {
            TokenType::Verb { lemma, .. } => lemma,
            TokenType::Ambiguous { primary, .. } => match *primary {
                TokenType::Verb { lemma, .. } => lemma,
                _ => panic!("Expected verb in Ambiguous primary, got {:?}", primary),
            },
            _ => panic!("Expected verb, got {:?}", t.kind),
        }
    }

    fn consume_verb_with_metadata(&mut self) -> (Symbol, Time, Aspect, VerbClass) {
        let t = self.advance().clone();
        match t.kind {
            TokenType::Verb { lemma, time, aspect, class } => (lemma, time, aspect, class),
            TokenType::Ambiguous { primary, .. } => match *primary {
                TokenType::Verb { lemma, time, aspect, class } => (lemma, time, aspect, class),
                _ => panic!("Expected verb in Ambiguous primary, got {:?}", primary),
            },
            _ => panic!("Expected verb, got {:?}", t.kind),
        }
    }

    fn match_token(&mut self, types: &[TokenType]) -> bool {
        for t in types {
            if self.check(t) {
                self.advance();
                return true;
            }
        }
        false
    }

    fn check_quantifier(&self) -> bool {
        matches!(
            self.peek().kind,
            TokenType::All
                | TokenType::No
                | TokenType::Some
                | TokenType::Any
                | TokenType::Most
                | TokenType::Few
                | TokenType::Many
                | TokenType::Cardinal(_)
                | TokenType::AtLeast(_)
                | TokenType::AtMost(_)
        )
    }

    fn check_npi_quantifier(&self) -> bool {
        matches!(
            self.peek().kind,
            TokenType::Nobody | TokenType::Nothing | TokenType::NoOne
        )
    }

    fn check_npi_object(&self) -> bool {
        matches!(
            self.peek().kind,
            TokenType::Anything | TokenType::Anyone
        )
    }

    fn check_temporal_npi(&self) -> bool {
        matches!(
            self.peek().kind,
            TokenType::Ever | TokenType::Never
        )
    }

    fn parse_npi_quantified(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let npi_token = self.advance().kind.clone();
        let var_name = self.next_var_name();

        let (restriction_name, is_person) = match npi_token {
            TokenType::Nobody | TokenType::NoOne => ("Person", true),
            TokenType::Nothing => ("Thing", false),
            _ => ("Thing", false),
        };

        let restriction_sym = self.interner.intern(restriction_name);
        let subject_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
            name: restriction_sym,
            args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
        });

        self.negative_depth += 1;

        let verb = self.consume_verb();

        if self.check_npi_object() {
            let obj_npi_token = self.advance().kind.clone();
            let obj_var = self.next_var_name();

            let obj_restriction_name = match obj_npi_token {
                TokenType::Anything => "Thing",
                TokenType::Anyone => "Person",
                _ => "Thing",
            };

            let obj_restriction_sym = self.interner.intern(obj_restriction_name);
            let obj_restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: obj_restriction_sym,
                args: self.ctx.terms.alloc_slice([Term::Variable(obj_var)]),
            });

            let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice([Term::Variable(var_name), Term::Variable(obj_var)]),
            });

            let verb_and_obj = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: obj_restriction,
                op: TokenType::And,
                right: verb_pred,
            });

            let inner_existential = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                kind: crate::ast::QuantifierKind::Existential,
                variable: obj_var,
                body: verb_and_obj,
                island_id: self.current_island,
            });

            self.negative_depth -= 1;

            let negated = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                op: TokenType::Not,
                operand: inner_existential,
            });

            let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: subject_pred,
                op: TokenType::If,
                right: negated,
            });

            return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                kind: crate::ast::QuantifierKind::Universal,
                variable: var_name,
                body,
                island_id: self.current_island,
            }));
        }

        let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
            name: verb,
            args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
        });

        self.negative_depth -= 1;

        let negated_verb = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
            op: TokenType::Not,
            operand: verb_pred,
        });

        let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
            left: subject_pred,
            op: TokenType::If,
            right: negated_verb,
        });

        Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
            kind: crate::ast::QuantifierKind::Universal,
            variable: var_name,
            body,
            island_id: self.current_island,
        }))
    }

    fn parse_temporal_npi(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let npi_token = self.advance().kind.clone();
        let is_never = matches!(npi_token, TokenType::Never);

        let subject = self.parse_noun_phrase(true)?;

        if is_never {
            self.negative_depth += 1;
        }

        let verb = self.consume_verb();
        let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
            name: verb,
            args: self.ctx.terms.alloc_slice([Term::Constant(subject.noun)]),
        });

        if is_never {
            self.negative_depth -= 1;
            Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                op: TokenType::Not,
                operand: verb_pred,
            }))
        } else {
            Ok(verb_pred)
        }
    }

    fn check(&self, kind: &TokenType) -> bool {
        if self.is_at_end() {
            return false;
        }
        std::mem::discriminant(&self.peek().kind) == std::mem::discriminant(kind)
    }

    fn check_any(&self, kinds: &[TokenType]) -> bool {
        if self.is_at_end() {
            return false;
        }
        let current = std::mem::discriminant(&self.peek().kind);
        kinds.iter().any(|k| std::mem::discriminant(k) == current)
    }

    fn check_article(&self) -> bool {
        matches!(self.peek().kind, TokenType::Article(_))
    }

    fn advance(&mut self) -> &Token {
        if !self.is_at_end() {
            self.current += 1;
        }
        self.previous()
    }

    fn is_at_end(&self) -> bool {
        self.peek().kind == TokenType::EOF
    }

    fn peek(&self) -> &Token {
        &self.tokens[self.current]
    }

    /// Phase 35: Check if the next token (after current) is a string literal.
    /// Used to distinguish causal `because` from Trust's `because "reason"`.
    fn peek_next_is_string_literal(&self) -> bool {
        self.tokens.get(self.current + 1)
            .map(|t| matches!(t.kind, TokenType::StringLiteral(_)))
            .unwrap_or(false)
    }

    fn previous(&self) -> &Token {
        &self.tokens[self.current - 1]
    }

    fn current_span(&self) -> crate::token::Span {
        self.peek().span
    }

    fn consume(&mut self, kind: TokenType) -> ParseResult<&Token> {
        if self.check(&kind) {
            Ok(self.advance())
        } else {
            Err(ParseError {
                kind: ParseErrorKind::UnexpectedToken {
                    expected: kind,
                    found: self.peek().kind.clone(),
                },
                span: self.current_span(),
            })
        }
    }

    fn consume_content_word(&mut self) -> ParseResult<Symbol> {
        let t = self.advance().clone();
        match t.kind {
            TokenType::Noun(s) | TokenType::Adjective(s) | TokenType::NonIntersectiveAdjective(s) => Ok(s),
            // Phase 35: Allow single-letter articles (a, an) to be used as variable names
            TokenType::Article(_) => Ok(t.lexeme),
            // Phase 35: Allow numeric literals as content words (e.g., "equal to 42")
            TokenType::Number(s) => Ok(s),
            TokenType::ProperName(s) => {
                let s_str = self.interner.resolve(s);

                // In imperative mode, reject unknown or moved entities
                if self.mode == ParserMode::Imperative {
                    use crate::context::OwnershipState;

                    let is_known = self.context.as_ref()
                        .map(|ctx| ctx.has_entity_by_noun_class(s_str))
                        .unwrap_or(false);

                    if !is_known {
                        return Err(ParseError {
                            kind: ParseErrorKind::UndefinedVariable { name: s_str.to_string() },
                            span: self.current_span(),
                        });
                    }

                    // Check for use-after-move
                    let ownership = self.context.as_ref()
                        .and_then(|ctx| ctx.get_ownership(s_str));

                    if ownership == Some(OwnershipState::Moved) {
                        return Err(ParseError {
                            kind: ParseErrorKind::UseAfterMove { name: s_str.to_string() },
                            span: self.current_span(),
                        });
                    }
                }

                let gender = Self::infer_gender(s_str);
                // Use full name as symbol for consistent output in Full mode
                let symbol_str = crate::transpile::capitalize_first(s_str);
                let noun_class = s_str.to_string();
                self.register_entity(&symbol_str, &noun_class, gender, Number::Singular);
                Ok(s)
            }
            TokenType::Verb { lemma, .. } => Ok(lemma),
            TokenType::Ambiguous { primary, .. } => {
                match *primary {
                    TokenType::Noun(s) | TokenType::Adjective(s) | TokenType::NonIntersectiveAdjective(s) => Ok(s),
                    TokenType::Verb { lemma, .. } => Ok(lemma),
                    TokenType::ProperName(s) => Ok(s),
                    _ => Err(ParseError {
                        kind: ParseErrorKind::ExpectedContentWord { found: *primary },
                        span: self.current_span(),
                    }),
                }
            }
            other => Err(ParseError {
                kind: ParseErrorKind::ExpectedContentWord { found: other },
                span: self.current_span(),
            }),
        }
    }

    fn consume_copula(&mut self) -> ParseResult<()> {
        if self.match_token(&[TokenType::Is, TokenType::Are, TokenType::Was, TokenType::Were]) {
            Ok(())
        } else {
            Err(ParseError {
                kind: ParseErrorKind::ExpectedCopula,
                span: self.current_span(),
            })
        }
    }

    fn check_comparative(&self) -> bool {
        matches!(self.peek().kind, TokenType::Comparative(_))
    }

    fn is_contact_clause_pattern(&self) -> bool {
        // Detect "The cat [the dog chased] ran" pattern
        // Also handles nested: "The rat [the cat [the dog chased] ate] died"
        let mut pos = self.current;

        // Skip the article we're at
        if pos < self.tokens.len() && matches!(self.tokens[pos].kind, TokenType::Article(_)) {
            pos += 1;
        } else {
            return false;
        }

        // Skip adjectives
        while pos < self.tokens.len() && matches!(self.tokens[pos].kind, TokenType::Adjective(_)) {
            pos += 1;
        }

        // Must have noun/proper name (embedded subject)
        if pos < self.tokens.len() && matches!(self.tokens[pos].kind, TokenType::Noun(_) | TokenType::ProperName(_) | TokenType::Adjective(_)) {
            pos += 1;
        } else {
            return false;
        }

        // Must have verb OR another article (nested contact clause) after
        pos < self.tokens.len() && matches!(self.tokens[pos].kind, TokenType::Verb { .. } | TokenType::Article(_))
    }

    fn check_superlative(&self) -> bool {
        matches!(self.peek().kind, TokenType::Superlative(_))
    }

    fn check_scopal_adverb(&self) -> bool {
        matches!(self.peek().kind, TokenType::ScopalAdverb(_))
    }

    fn check_temporal_adverb(&self) -> bool {
        matches!(self.peek().kind, TokenType::TemporalAdverb(_))
    }

    fn check_non_intersective_adjective(&self) -> bool {
        matches!(self.peek().kind, TokenType::NonIntersectiveAdjective(_))
    }

    fn check_focus(&self) -> bool {
        matches!(self.peek().kind, TokenType::Focus(_))
    }

    fn check_measure(&self) -> bool {
        matches!(self.peek().kind, TokenType::Measure(_))
    }

    fn check_presup_trigger(&self) -> bool {
        match &self.peek().kind {
            TokenType::PresupTrigger(_) => true,
            TokenType::Verb { lemma, .. } => {
                let s = self.interner.resolve(*lemma).to_lowercase();
                crate::lexicon::lookup_presup_trigger(&s).is_some()
            }
            _ => false,
        }
    }

    fn is_followed_by_np_object(&self) -> bool {
        if self.current + 1 >= self.tokens.len() {
            return false;
        }
        let next = &self.tokens[self.current + 1].kind;
        matches!(next,
            TokenType::ProperName(_) |
            TokenType::Article(_) |
            TokenType::Noun(_) |
            TokenType::Pronoun { .. } |
            TokenType::Reflexive |
            TokenType::Who |
            TokenType::What |
            TokenType::Where |
            TokenType::When |
            TokenType::Why
        )
    }

    fn is_followed_by_gerund(&self) -> bool {
        if self.current + 1 >= self.tokens.len() {
            return false;
        }
        matches!(self.tokens[self.current + 1].kind, TokenType::Verb { .. })
    }

    // =========================================================================
    // Phase 46: Agent System Parsing
    // =========================================================================

    /// Parse spawn statement: "Spawn a Worker called 'w1'."
    fn parse_spawn_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Spawn"

        // Expect article (a/an)
        if !self.check_article() {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "a/an".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume article

        // Get agent type name (Noun or ProperName)
        let agent_type = match &self.tokens[self.current].kind {
            TokenType::Noun(sym) | TokenType::ProperName(sym) => {
                let s = *sym;
                self.advance();
                s
            }
            _ => {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: "agent type".to_string() },
                    span: self.current_span(),
                });
            }
        };

        // Expect "called"
        if !self.check(&TokenType::Called) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "called".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "called"

        // Get agent name (string literal)
        let name = if let TokenType::StringLiteral(sym) = &self.tokens[self.current].kind {
            let s = *sym;
            self.advance();
            s
        } else {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "agent name".to_string() },
                span: self.current_span(),
            });
        };

        Ok(Stmt::Spawn { agent_type, name })
    }

    /// Parse send statement: "Send Ping to 'agent'."
    fn parse_send_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Send"

        // Parse message expression
        let message = self.parse_imperative_expr()?;

        // Expect "to"
        if !self.check_preposition_is("to") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "to".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "to"

        // Parse destination expression
        let destination = self.parse_imperative_expr()?;

        Ok(Stmt::SendMessage { message, destination })
    }

    /// Parse await statement: "Await response from 'agent' into result."
    fn parse_await_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Await"

        // Skip optional "response" word
        if self.check_word("response") {
            self.advance();
        }

        // Expect "from" (can be keyword or preposition)
        if !self.check(&TokenType::From) && !self.check_preposition_is("from") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "from".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "from"

        // Parse source expression
        let source = self.parse_imperative_expr()?;

        // Expect "into"
        if !self.check_word("into") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "into".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "into"

        // Get variable name (Noun, ProperName, or Adjective - can be any content word)
        let into = match &self.tokens[self.current].kind {
            TokenType::Noun(sym) | TokenType::ProperName(sym) | TokenType::Adjective(sym) => {
                let s = *sym;
                self.advance();
                s
            }
            // Also accept lexemes from other token types if they look like identifiers
            _ if self.check_content_word() => {
                let sym = self.tokens[self.current].lexeme;
                self.advance();
                sym
            }
            _ => {
                return Err(ParseError {
                    kind: ParseErrorKind::ExpectedKeyword { keyword: "variable name".to_string() },
                    span: self.current_span(),
                });
            }
        };

        Ok(Stmt::AwaitMessage { source, into })
    }

    // =========================================================================
    // Phase 49: CRDT Statement Parsing
    // =========================================================================

    /// Parse merge statement: "Merge remote into local." or "Merge remote's field into local's field."
    fn parse_merge_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Merge"

        // Parse source expression
        let source = self.parse_imperative_expr()?;

        // Expect "into"
        if !self.check_word("into") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "into".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "into"

        // Parse target expression
        let target = self.parse_imperative_expr()?;

        Ok(Stmt::MergeCrdt { source, target })
    }

    /// Parse increase statement: "Increase local's points by 10."
    fn parse_increase_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Increase"

        // Parse object with field access (e.g., "local's points")
        let expr = self.parse_imperative_expr()?;

        // Must be a field access
        let (object, field) = if let Expr::FieldAccess { object, field } = expr {
            (object, field)
        } else {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "field access (e.g., 'x's count')".to_string() },
                span: self.current_span(),
            });
        };

        // Expect "by"
        if !self.check_preposition_is("by") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "by".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "by"

        // Parse amount
        let amount = self.parse_imperative_expr()?;

        Ok(Stmt::IncreaseCrdt { object, field: *field, amount })
    }

    /// Parse decrease statement: "Decrease game's score by 5."
    fn parse_decrease_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Decrease"

        // Parse object with field access (e.g., "game's score")
        let expr = self.parse_imperative_expr()?;

        // Must be a field access
        let (object, field) = if let Expr::FieldAccess { object, field } = expr {
            (object, field)
        } else {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "field access (e.g., 'x's count')".to_string() },
                span: self.current_span(),
            });
        };

        // Expect "by"
        if !self.check_preposition_is("by") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "by".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "by"

        // Parse amount
        let amount = self.parse_imperative_expr()?;

        Ok(Stmt::DecreaseCrdt { object, field: *field, amount })
    }

    /// Parse append statement: "Append value to sequence."
    fn parse_append_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Append"

        // Parse value to append
        let value = self.parse_imperative_expr()?;

        // Expect "to" (can be TokenType::To or a preposition)
        if !self.check(&TokenType::To) && !self.check_preposition_is("to") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "to".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "to"

        // Parse sequence expression
        let sequence = self.parse_imperative_expr()?;

        Ok(Stmt::AppendToSequence { sequence, value })
    }

    /// Parse resolve statement: "Resolve page's title to value."
    fn parse_resolve_statement(&mut self) -> ParseResult<Stmt<'a>> {
        self.advance(); // consume "Resolve"

        // Parse object with field access (e.g., "page's title")
        let expr = self.parse_imperative_expr()?;

        // Must be a field access
        let (object, field) = if let Expr::FieldAccess { object, field } = expr {
            (object, field)
        } else {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "field access (e.g., 'x's title')".to_string() },
                span: self.current_span(),
            });
        };

        // Expect "to" (can be TokenType::To or a preposition)
        if !self.check(&TokenType::To) && !self.check_preposition_is("to") {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedKeyword { keyword: "to".to_string() },
                span: self.current_span(),
            });
        }
        self.advance(); // consume "to"

        // Parse value
        let value = self.parse_imperative_expr()?;

        Ok(Stmt::ResolveConflict { object, field: *field, value })
    }

}


```

---

### ClauseParsing Trait

**File:** `src/parser/clause.rs`

Extension trait for sentence-level parsing: conditionals (if/then), conjunctions (and/or/but), relative clauses (who/that/which), gapped clauses (ellipsis via verb borrowing), counterfactual antecedents/consequents. Handles complete clause detection and verb extraction. **VP Ellipsis:** try_parse_ellipsis() detects pattern: Subject + Auxiliary (does/do/can/could/would/may/must/should) + (not)? + Terminator (too/also/period/EOF). Reconstructs NeoEvent with new Agent but preserves verb and non-agent roles from last_event_template. Applies modal wrapper and negation as needed.

```rust
use super::modal::ModalParsing;
use super::noun::NounParsing;
use super::pragmatics::PragmaticsParsing;
use super::quantifier::QuantifierParsing;
use super::question::QuestionParsing;
use super::verb::LogicVerbParsing;
use super::{ParseResult, Parser};
use crate::ast::{LogicExpr, NeoEventData, NounPhrase, QuantifierKind, TemporalOperator, Term, ThematicRole};
use crate::lexer::Lexer;
use crate::lexicon::Time;
use crate::drs::BoxType;
use crate::error::{ParseError, ParseErrorKind};
use crate::intern::Symbol;
use crate::lexicon::Definiteness;
use crate::token::TokenType;

pub trait ClauseParsing<'a, 'ctx, 'int> {
    fn parse_sentence(&mut self) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_conditional(&mut self) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_disjunction(&mut self) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_conjunction(&mut self) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_relative_clause(&mut self, gap_var: Symbol) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_gapped_clause(&mut self, borrowed_verb: Symbol) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_counterfactual_antecedent(&mut self) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_counterfactual_consequent(&mut self) -> ParseResult<&'a LogicExpr<'a>>;
    fn check_wh_word(&self) -> bool;
    fn is_counterfactual_context(&self) -> bool;
    fn is_complete_clause(&self, expr: &LogicExpr<'a>) -> bool;
    fn extract_verb_from_expr(&self, expr: &LogicExpr<'a>) -> Option<Symbol>;
    fn try_parse_ellipsis(&mut self) -> Option<ParseResult<&'a LogicExpr<'a>>>;
    fn check_ellipsis_auxiliary(&self) -> bool;
    fn check_ellipsis_terminator(&self) -> bool;
}

impl<'a, 'ctx, 'int> ClauseParsing<'a, 'ctx, 'int> for Parser<'a, 'ctx, 'int> {
    fn parse_sentence(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        // Check for ellipsis pattern: "Mary does too." / "Mary can too."
        if let Some(result) = self.try_parse_ellipsis() {
            return result;
        }

        if self.check_verb() {
            let verb_pos = self.current;
            let mut temp_pos = self.current + 1;
            while temp_pos < self.tokens.len() {
                if matches!(self.tokens[temp_pos].kind, TokenType::Exclamation) {
                    self.current = verb_pos;
                    let verb = self.consume_verb();
                    while !matches!(self.peek().kind, TokenType::Exclamation | TokenType::EOF) {
                        self.advance();
                    }
                    if self.check(&TokenType::Exclamation) {
                        self.advance();
                    }
                    let addressee = self.interner.intern("addressee");
                    let action = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: verb,
                        args: self.ctx.terms.alloc_slice([Term::Variable(addressee)]),
                    });
                    return Ok(self.ctx.exprs.alloc(LogicExpr::Imperative { action }));
                }
                if matches!(self.tokens[temp_pos].kind, TokenType::Period | TokenType::EOF) {
                    break;
                }
                temp_pos += 1;
            }
        }

        if self.check_wh_word() {
            return self.parse_wh_question();
        }

        if self.check(&TokenType::Does)
            || self.check(&TokenType::Do)
            || self.check(&TokenType::Is)
            || self.check(&TokenType::Are)
            || self.check(&TokenType::Was)
            || self.check(&TokenType::Were)
            || self.check(&TokenType::Would)
            || self.check(&TokenType::Could)
            || self.check(&TokenType::Can)
        {
            return self.parse_yes_no_question();
        }

        if self.match_token(&[TokenType::If]) {
            return self.parse_conditional();
        }

        if self.check_modal() {
            self.advance();
            return self.parse_modal();
        }

        if self.match_token(&[TokenType::Not]) {
            self.negative_depth += 1;
            let inner = self.parse_sentence()?;
            self.negative_depth -= 1;
            return Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                op: TokenType::Not,
                operand: inner,
            }));
        }

        self.parse_disjunction()
    }

    fn check_wh_word(&self) -> bool {
        if matches!(
            self.peek().kind,
            TokenType::Who
                | TokenType::What
                | TokenType::Where
                | TokenType::When
                | TokenType::Why
        ) {
            return true;
        }
        if self.check_preposition() && self.current + 1 < self.tokens.len() {
            matches!(
                self.tokens[self.current + 1].kind,
                TokenType::Who
                    | TokenType::What
                    | TokenType::Where
                    | TokenType::When
                    | TokenType::Why
            )
        } else {
            false
        }
    }

    fn parse_conditional(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let is_counterfactual = self.is_counterfactual_context();

        // Enter DRS antecedent box - indefinites here get universal force
        self.drs.enter_box(BoxType::ConditionalAntecedent);
        let antecedent = self.parse_counterfactual_antecedent()?;
        self.drs.exit_box();

        if self.check(&TokenType::Comma) {
            self.advance();
        }

        if self.check(&TokenType::Then) {
            self.advance();
        }

        // Enter DRS consequent box - can access antecedent referents
        self.drs.enter_box(BoxType::ConditionalConsequent);
        let consequent = self.parse_counterfactual_consequent()?;
        self.drs.exit_box();

        // Get DRS referents that need universal quantification
        let universal_refs = self.drs.get_universal_referents();

        // Build the conditional expression
        let conditional = if is_counterfactual {
            self.ctx.exprs.alloc(LogicExpr::Counterfactual {
                antecedent,
                consequent,
            })
        } else {
            self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: antecedent,
                op: TokenType::If,
                right: consequent,
            })
        };

        // Wrap with universal quantifiers for DRS referents
        let mut result = conditional;
        for var in universal_refs.into_iter().rev() {
            result = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                kind: QuantifierKind::Universal,
                variable: var,
                body: result,
                island_id: self.current_island,
            });
        }

        Ok(result)
    }

    fn is_counterfactual_context(&self) -> bool {
        for i in 0..5 {
            if self.current + i >= self.tokens.len() {
                break;
            }
            let token = &self.tokens[self.current + i];
            if matches!(token.kind, TokenType::Were | TokenType::Had) {
                return true;
            }
            if matches!(token.kind, TokenType::Comma | TokenType::Period) {
                break;
            }
        }
        false
    }

    fn parse_counterfactual_antecedent(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let unknown = self.interner.intern("?");
        if self.check_content_word() || self.check_pronoun() || self.check_article() {
            // Weather verb detection: "if it rains" → ∃e(Rain(e))
            // Must check BEFORE pronoun resolution since "it" would resolve to "?"
            if self.check_pronoun() {
                let token = self.peek();
                let token_text = self.interner.resolve(token.lexeme);
                if token_text.eq_ignore_ascii_case("it") {
                    // Look ahead for weather verb
                    if self.current + 1 < self.tokens.len() {
                        if let TokenType::Verb { lemma, time, .. } = &self.tokens[self.current + 1].kind {
                            let lemma_str = self.interner.resolve(*lemma);
                            if Lexer::is_weather_verb(lemma_str) {
                                let verb = *lemma;
                                let verb_time = *time;
                                self.advance(); // consume "it"
                                self.advance(); // consume weather verb

                                let event_var = self.get_event_var();

                                // DRT: Register event var for universal quantification in conditionals
                                let suppress_existential = self.drs.in_conditional_antecedent();
                                if suppress_existential {
                                    let event_class = self.interner.intern("Event");
                                    self.drs.introduce_referent(event_var, event_class, crate::context::Gender::Neuter);
                                }

                                let mut result: &'a LogicExpr<'a> = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                                    event_var,
                                    verb,
                                    roles: self.ctx.roles.alloc_slice(vec![]),
                                    modifiers: self.ctx.syms.alloc_slice(vec![]),
                                    suppress_existential,
                                })));

                                // Handle coordinated weather verbs: "rains and thunders" or "rains or thunders"
                                // SHARE the same event_var for all coordinated verbs
                                while self.check(&TokenType::And) || self.check(&TokenType::Or) {
                                    let is_disjunction = self.check(&TokenType::Or);
                                    self.advance(); // consume "and" or "or"

                                    if let TokenType::Verb { lemma: lemma2, .. } = &self.peek().kind.clone() {
                                        let lemma2_str = self.interner.resolve(*lemma2);
                                        if Lexer::is_weather_verb(lemma2_str) {
                                            let verb2 = *lemma2;
                                            self.advance(); // consume second weather verb

                                            // REUSE same event_var - no new variable, no DRS registration
                                            let neo_event2 = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                                                event_var,  // Same variable as first weather verb
                                                verb: verb2,
                                                roles: self.ctx.roles.alloc_slice(vec![]),
                                                modifiers: self.ctx.syms.alloc_slice(vec![]),
                                                suppress_existential,
                                            })));

                                            let op = if is_disjunction { TokenType::Or } else { TokenType::And };
                                            result = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                                left: result,
                                                op,
                                                right: neo_event2,
                                            });
                                        } else {
                                            break; // Not a weather verb, stop coordination
                                        }
                                    } else {
                                        break;
                                    }
                                }

                                return Ok(match verb_time {
                                    Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                                        operator: TemporalOperator::Past,
                                        body: result,
                                    }),
                                    Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                                        operator: TemporalOperator::Future,
                                        body: result,
                                    }),
                                    _ => result,
                                });
                            }
                        }
                    }
                }
            }

            // Track if subject is an indefinite that needs DRS registration
            let (subject, subject_type_pred) = if self.check_pronoun() {
                let token = self.advance().clone();
                let resolved = if let TokenType::Pronoun { gender, number, .. } = token.kind {
                    self.resolve_pronoun(gender, number).unwrap_or(unknown)
                } else {
                    unknown
                };
                (resolved, None)
            } else {
                let np = self.parse_noun_phrase(true)?;

                // Check if this is an indefinite NP that should introduce a DRS referent
                if np.definiteness == Some(Definiteness::Indefinite) {
                    let var = self.next_var_name();
                    let gender = Self::infer_noun_gender(self.interner.resolve(np.noun));

                    // Register in DRS - will get universal force from ConditionalAntecedent box
                    self.drs.introduce_referent(var, np.noun, gender);

                    // Create type predicate: Farmer(x)
                    let type_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: np.noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(var)]),
                    });

                    (var, Some(type_pred))
                } else {
                    // Definite or proper name - use as constant
                    (np.noun, None)
                }
            };

            // Determine the subject term type
            let subject_term = if subject_type_pred.is_some() {
                Term::Variable(subject)
            } else {
                Term::Constant(subject)
            };

            // Handle presupposition triggers in antecedent: "If John stopped smoking, ..."
            // Only trigger if followed by gerund complement
            if self.check_presup_trigger() && self.is_followed_by_gerund() {
                let presup_kind = match self.advance().kind {
                    TokenType::PresupTrigger(kind) => kind,
                    TokenType::Verb { lemma, .. } => {
                        let s = self.interner.resolve(lemma).to_lowercase();
                        crate::lexicon::lookup_presup_trigger(&s)
                            .expect("Lexicon mismatch: Verb flagged as trigger but lookup failed")
                    }
                    _ => panic!("Expected presupposition trigger"),
                };
                let np = NounPhrase {
                    noun: subject,
                    definiteness: None,
                    adjectives: &[],
                    possessor: None,
                    pps: &[],
                    superlative: None,
                };
                return self.parse_presupposition(&np, presup_kind);
            }

            if self.check(&TokenType::Were) {
                self.advance();
                let predicate = if self.check_pronoun() {
                    let token = self.advance().clone();
                    if let TokenType::Pronoun { gender, number, .. } = token.kind {
                        let token_text = self.interner.resolve(token.lexeme);
                        if token_text.eq_ignore_ascii_case("i") {
                            self.interner.intern("Speaker")
                        } else if token_text.eq_ignore_ascii_case("you") {
                            self.interner.intern("Addressee")
                        } else {
                            self.resolve_pronoun(gender, number).unwrap_or(unknown)
                        }
                    } else {
                        unknown
                    }
                } else {
                    self.consume_content_word()?
                };
                let be = self.interner.intern("Be");
                let be_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: be,
                    args: self.ctx.terms.alloc_slice([
                        subject_term,
                        Term::Constant(predicate),
                    ]),
                });
                // Combine with type predicate if indefinite subject
                return Ok(if let Some(type_pred) = subject_type_pred {
                    self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: type_pred,
                        op: TokenType::And,
                        right: be_pred,
                    })
                } else {
                    be_pred
                });
            }

            if self.check(&TokenType::Had) {
                self.advance();
                let verb = self.consume_content_word()?;
                let main_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb,
                    args: self.ctx.terms.alloc_slice([subject_term]),
                });

                // Handle "because" causal clause in antecedent
                // Phase 35: Do NOT consume if followed by string literal (Trust justification)
                if self.check(&TokenType::Because) && !self.peek_next_is_string_literal() {
                    self.advance();
                    let cause = self.parse_atom()?;
                    let causal = self.ctx.exprs.alloc(LogicExpr::Causal {
                        effect: main_pred,
                        cause,
                    });
                    // Combine with type predicate if indefinite subject
                    return Ok(if let Some(type_pred) = subject_type_pred {
                        self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: type_pred,
                            op: TokenType::And,
                            right: causal,
                        })
                    } else {
                        causal
                    });
                }

                // Combine with type predicate if indefinite subject
                return Ok(if let Some(type_pred) = subject_type_pred {
                    self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: type_pred,
                        op: TokenType::And,
                        right: main_pred,
                    })
                } else {
                    main_pred
                });
            }

            // Parse verb phrase with subject
            // Use variable term for indefinite subjects, constant for definites/proper names
            let verb_phrase = if subject_type_pred.is_some() {
                self.parse_predicate_with_subject_as_var(subject)?
            } else {
                self.parse_predicate_with_subject(subject)?
            };

            // Combine with type predicate if indefinite subject
            return Ok(if let Some(type_pred) = subject_type_pred {
                self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: type_pred,
                    op: TokenType::And,
                    right: verb_phrase,
                })
            } else {
                verb_phrase
            });
        }

        self.parse_sentence()
    }

    fn parse_counterfactual_consequent(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let unknown = self.interner.intern("?");
        if self.check_content_word() || self.check_pronoun() {
            // Check for grammatically incorrect "its" + weather adjective
            // "its" is possessive, "it's" is contraction - common typo
            if self.check_pronoun() {
                let token = self.peek();
                let token_text = self.interner.resolve(token.lexeme).to_lowercase();
                if token_text == "its" {
                    // Check if followed by weather adjective
                    if self.current + 1 < self.tokens.len() {
                        let next_token = &self.tokens[self.current + 1];
                        let next_str = self.interner.resolve(next_token.lexeme).to_lowercase();
                        if let Some(meta) = crate::lexicon::lookup_adjective_db(&next_str) {
                            if meta.features.contains(&crate::lexicon::Feature::Weather) {
                                return Err(ParseError {
                                    kind: ParseErrorKind::GrammarError(
                                        "Did you mean 'it's' (it is)? 'its' is a possessive pronoun.".to_string()
                                    ),
                                    span: self.current_span(),
                                });
                            }
                        }
                    }
                }
            }

            // Check for expletive "it" + copula + weather adjective: "it's wet" → Wet
            if self.check_pronoun() {
                let token_text = self.interner.resolve(self.peek().lexeme).to_lowercase();
                if token_text == "it" {
                    // Look ahead for copula + weather adjective
                    // Handle both "it is wet" and "it's wet" (where 's is Possessive token)
                    if self.current + 2 < self.tokens.len() {
                        let next = &self.tokens[self.current + 1].kind;
                        if matches!(next, TokenType::Is | TokenType::Was | TokenType::Possessive) {
                            // Check if followed by weather adjective
                            let adj_token = &self.tokens[self.current + 2];
                            let adj_sym = adj_token.lexeme;
                            let adj_str = self.interner.resolve(adj_sym).to_lowercase();
                            if let Some(meta) = crate::lexicon::lookup_adjective_db(&adj_str) {
                                if meta.features.contains(&crate::lexicon::Feature::Weather) {
                                    self.advance(); // consume "it"
                                    self.advance(); // consume copula
                                    self.advance(); // consume adjective token

                                    // Use the canonical lemma from lexicon (e.g., "Wet" not "wet")
                                    let adj_lemma = self.interner.intern(meta.lemma);

                                    // Get event variable from DRS (introduced in antecedent)
                                    let event_var = self.drs.get_last_event_referent(self.interner)
                                        .unwrap_or_else(|| self.interner.intern("e"));

                                    // First weather adjective predicate
                                    let mut result: &'a LogicExpr<'a> = self.ctx.exprs.alloc(LogicExpr::Predicate {
                                        name: adj_lemma,
                                        args: self.ctx.terms.alloc_slice([Term::Variable(event_var)]),
                                    });

                                    // Handle coordinated adjectives: "wet and cold"
                                    while self.check(&TokenType::And) {
                                        self.advance(); // consume "and"
                                        if self.check_content_word() {
                                            let adj2_lexeme = self.peek().lexeme;
                                            let adj2_str = self.interner.resolve(adj2_lexeme).to_lowercase();

                                            // Check if it's also a weather adjective
                                            if let Some(meta2) = crate::lexicon::lookup_adjective_db(&adj2_str) {
                                                if meta2.features.contains(&crate::lexicon::Feature::Weather) {
                                                    self.advance(); // consume adjective token
                                                    // Use the canonical lemma from lexicon (e.g., "Cold" not "cold")
                                                    let adj2_lemma = self.interner.intern(meta2.lemma);
                                                    let pred2 = self.ctx.exprs.alloc(LogicExpr::Predicate {
                                                        name: adj2_lemma,
                                                        args: self.ctx.terms.alloc_slice([Term::Variable(event_var)]),
                                                    });
                                                    result = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                                        left: result,
                                                        op: TokenType::And,
                                                        right: pred2,
                                                    });
                                                    continue;
                                                }
                                            }
                                        }
                                        break;
                                    }

                                    return Ok(result);
                                }
                            }
                        }
                    }
                }
            }

            let subject = if self.check_pronoun() {
                let token = self.advance().clone();
                if let TokenType::Pronoun { gender, number, .. } = token.kind {
                    self.resolve_pronoun(gender, number).unwrap_or(unknown)
                } else {
                    unknown
                }
            } else {
                self.parse_noun_phrase(true)?.noun
            };

            if self.check(&TokenType::Would) {
                self.advance();
                if self.check_content_word() {
                    let next_word = self.interner.resolve(self.peek().lexeme).to_lowercase();
                    if next_word == "have" {
                        self.advance();
                    }
                }
                let verb = self.consume_content_word()?;
                return Ok(self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb,
                    args: self.ctx.terms.alloc_slice([Term::Constant(subject)]),
                }));
            }

            return self.parse_predicate_with_subject(subject);
        }

        self.parse_sentence()
    }

    fn extract_verb_from_expr(&self, expr: &LogicExpr<'a>) -> Option<Symbol> {
        match expr {
            LogicExpr::Predicate { name, .. } => Some(*name),
            LogicExpr::NeoEvent(data) => Some(data.verb),
            LogicExpr::BinaryOp { right, .. } => self.extract_verb_from_expr(right),
            LogicExpr::Modal { operand, .. } => self.extract_verb_from_expr(operand),
            LogicExpr::Presupposition { assertion, .. } => self.extract_verb_from_expr(assertion),
            LogicExpr::Control { verb, .. } => Some(*verb),
            LogicExpr::Temporal { body, .. } => self.extract_verb_from_expr(body),
            LogicExpr::TemporalAnchor { body, .. } => self.extract_verb_from_expr(body),
            LogicExpr::Aspectual { body, .. } => self.extract_verb_from_expr(body),
            LogicExpr::Quantifier { body, .. } => self.extract_verb_from_expr(body),
            _ => None,
        }
    }

    fn parse_gapped_clause(&mut self, borrowed_verb: Symbol) -> ParseResult<&'a LogicExpr<'a>> {
        let subject = self.parse_noun_phrase(true)?;

        if self.check(&TokenType::Comma) {
            self.advance();
        }

        let subject_term = self.noun_phrase_to_term(&subject);
        let event_var = self.get_event_var();
        let suppress_existential = self.drs.in_conditional_antecedent();

        // Check if next token is temporal adverb (gapping with adjunct only)
        if self.check_temporal_adverb() {
            let adv_sym = if let TokenType::TemporalAdverb(sym) = self.advance().kind {
                sym
            } else {
                self.interner.intern("?")
            };

            return Ok(self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                event_var,
                verb: borrowed_verb,
                roles: self.ctx.roles.alloc_slice(vec![
                    (ThematicRole::Agent, subject_term),
                ]),
                modifiers: self.ctx.syms.alloc_slice(vec![adv_sym]),
                suppress_existential,
            }))));
        }

        // Standard gapping: subject + object
        let object = self.parse_noun_phrase(false)?;
        let object_term = self.noun_phrase_to_term(&object);

        let roles = vec![
            (ThematicRole::Agent, subject_term),
            (ThematicRole::Theme, object_term),
        ];

        Ok(self
            .ctx
            .exprs
            .alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                event_var,
                verb: borrowed_verb,
                roles: self.ctx.roles.alloc_slice(roles),
                modifiers: self.ctx.syms.alloc_slice(vec![]),
                suppress_existential,
            }))))
    }

    fn is_complete_clause(&self, expr: &LogicExpr<'a>) -> bool {
        match expr {
            LogicExpr::Atom(_) => false,
            LogicExpr::Predicate { .. } => true,
            LogicExpr::Quantifier { .. } => true,
            LogicExpr::Modal { .. } => true,
            LogicExpr::Temporal { .. } => true,
            LogicExpr::Aspectual { .. } => true,
            LogicExpr::BinaryOp { .. } => true,
            LogicExpr::UnaryOp { .. } => true,
            LogicExpr::Control { .. } => true,
            LogicExpr::Presupposition { .. } => true,
            LogicExpr::Categorical(_) => true,
            LogicExpr::Relation(_) => true,
            _ => true,
        }
    }

    /// Parse disjunction (Or/Iff) - lowest precedence logical connectives.
    /// Calls parse_conjunction for operands to ensure And binds tighter.
    fn parse_disjunction(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let mut expr = self.parse_conjunction()?;

        while self.check(&TokenType::Comma)
            || self.check(&TokenType::Or)
            || self.check(&TokenType::Iff)
        {
            if self.check(&TokenType::Comma) {
                self.advance();
            }
            if !self.match_token(&[TokenType::Or, TokenType::Iff]) {
                break;
            }
            let operator = self.previous().kind.clone();
            self.current_island += 1;

            let saved_pos = self.current;
            let standard_attempt = self.try_parse(|p| p.parse_conjunction());

            let use_gapping = match &standard_attempt {
                Some(right) => {
                    !self.is_complete_clause(right)
                        && (self.check(&TokenType::Comma) || self.check_content_word())
                }
                None => true,
            };

            if !use_gapping {
                if let Some(right) = standard_attempt {
                    expr = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: expr,
                        op: operator,
                        right,
                    });
                }
            } else {
                self.current = saved_pos;

                let borrowed_verb = self.extract_verb_from_expr(expr).ok_or(ParseError {
                    kind: ParseErrorKind::GappingResolutionFailed,
                    span: self.current_span(),
                })?;

                let right = self.parse_gapped_clause(borrowed_verb)?;

                expr = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: expr,
                    op: operator,
                    right,
                });
            }
        }

        Ok(expr)
    }

    /// Parse conjunction (And) - higher precedence than Or.
    /// Calls parse_atom for operands.
    fn parse_conjunction(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let mut expr = self.parse_atom()?;

        // Handle causal "because" at conjunction level
        // Phase 35: Do NOT consume if followed by string literal (Trust justification)
        if self.check(&TokenType::Because) && !self.peek_next_is_string_literal() {
            self.advance();
            let cause = self.parse_atom()?;
            return Ok(self.ctx.exprs.alloc(LogicExpr::Causal {
                effect: expr,
                cause,
            }));
        }

        while self.check(&TokenType::Comma) || self.check(&TokenType::And) {
            if self.check(&TokenType::Comma) {
                self.advance();
            }
            if !self.match_token(&[TokenType::And]) {
                break;
            }
            let operator = self.previous().kind.clone();
            self.current_island += 1;

            let saved_pos = self.current;
            let standard_attempt = self.try_parse(|p| p.parse_atom());

            let use_gapping = match &standard_attempt {
                Some(right) => {
                    !self.is_complete_clause(right)
                        && (self.check(&TokenType::Comma) || self.check_content_word())
                }
                None => true,
            };

            if !use_gapping {
                if let Some(right) = standard_attempt {
                    expr = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: expr,
                        op: operator,
                        right,
                    });
                }
            } else {
                self.current = saved_pos;

                let borrowed_verb = self.extract_verb_from_expr(expr).ok_or(ParseError {
                    kind: ParseErrorKind::GappingResolutionFailed,
                    span: self.current_span(),
                })?;

                let right = self.parse_gapped_clause(borrowed_verb)?;

                expr = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: expr,
                    op: operator,
                    right,
                });
            }
        }

        Ok(expr)
    }

    fn parse_relative_clause(&mut self, gap_var: Symbol) -> ParseResult<&'a LogicExpr<'a>> {
        if self.check_verb() {
            return self.parse_verb_phrase_for_restriction(gap_var);
        }

        if self.check_content_word() || self.check_article() {
            let rel_subject = self.parse_noun_phrase_for_relative()?;

            let nested_relative = if matches!(self.peek().kind, TokenType::Article(_)) {
                let nested_var = self.next_var_name();
                Some((nested_var, self.parse_relative_clause(nested_var)?))
            } else {
                None
            };

            if self.check_verb() {
                let verb = self.consume_verb();

                let mut roles: Vec<(ThematicRole, Term<'a>)> = vec![
                    (ThematicRole::Agent, Term::Constant(rel_subject.noun)),
                    (ThematicRole::Theme, Term::Variable(gap_var)),
                ];

                while self.check_to_preposition() {
                    self.advance();
                    if self.check_content_word() || self.check_article() {
                        let recipient = self.parse_noun_phrase(false)?;
                        roles.push((ThematicRole::Recipient, Term::Constant(recipient.noun)));
                    }
                }

                let event_var = self.get_event_var();
                let suppress_existential = self.drs.in_conditional_antecedent();
                let this_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                    event_var,
                    verb,
                    roles: self.ctx.roles.alloc_slice(roles),
                    modifiers: self.ctx.syms.alloc_slice(vec![]),
                    suppress_existential,
                })));

                if let Some((nested_var, nested_clause)) = nested_relative {
                    let type_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: rel_subject.noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(nested_var)]),
                    });

                    let inner = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: type_pred,
                        op: TokenType::And,
                        right: nested_clause,
                    });

                    let combined = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: inner,
                        op: TokenType::And,
                        right: this_event,
                    });

                    return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                        kind: crate::ast::QuantifierKind::Existential,
                        variable: nested_var,
                        body: combined,
                        island_id: self.current_island,
                    }));
                }

                return Ok(this_event);
            }
        }

        if self.check_verb() {
            return self.parse_verb_phrase_for_restriction(gap_var);
        }

        let unknown = self.interner.intern("?");
        Ok(self.ctx.exprs.alloc(LogicExpr::Atom(unknown)))
    }

    fn check_ellipsis_auxiliary(&self) -> bool {
        matches!(
            self.peek().kind,
            TokenType::Does | TokenType::Do |
            TokenType::Can | TokenType::Could | TokenType::Would |
            TokenType::May | TokenType::Must | TokenType::Should
        )
    }

    fn check_ellipsis_terminator(&self) -> bool {
        if self.is_at_end() || self.check(&TokenType::Period) {
            return true;
        }
        if self.check_content_word() {
            let word = self.interner.resolve(self.peek().lexeme).to_lowercase();
            return word == "too" || word == "also";
        }
        false
    }

    fn try_parse_ellipsis(&mut self) -> Option<ParseResult<&'a LogicExpr<'a>>> {
        // Need a stored template to reconstruct from
        if self.last_event_template.is_none() {
            return None;
        }

        let saved_pos = self.current;

        // Pattern: Subject + Auxiliary + (not)? + Terminator
        // Subject must be proper name or pronoun
        let subject_sym = if matches!(self.peek().kind, TokenType::ProperName(_)) {
            if let TokenType::ProperName(sym) = self.advance().kind {
                sym
            } else {
                self.current = saved_pos;
                return None;
            }
        } else if self.check_pronoun() {
            let token = self.advance().clone();
            if let TokenType::Pronoun { gender, number, .. } = token.kind {
                self.resolve_pronoun(gender, number)
                    .unwrap_or_else(|| self.interner.intern("?"))
            } else {
                self.current = saved_pos;
                return None;
            }
        } else {
            return None;
        };

        // Must be followed by ellipsis auxiliary
        if !self.check_ellipsis_auxiliary() {
            self.current = saved_pos;
            return None;
        }
        let aux_token = self.advance().kind.clone();

        // Check for negation
        let is_negated = self.match_token(&[TokenType::Not]);

        // Must end with terminator
        if !self.check_ellipsis_terminator() {
            self.current = saved_pos;
            return None;
        }

        // Consume "too"/"also" if present
        if self.check_content_word() {
            let word = self.interner.resolve(self.peek().lexeme).to_lowercase();
            if word == "too" || word == "also" {
                self.advance();
            }
        }

        // Reconstruct from template
        let template = self.last_event_template.clone().unwrap();
        let event_var = self.get_event_var();
        let suppress_existential = self.drs.in_conditional_antecedent();

        // Build roles with new subject as Agent
        let mut roles: Vec<(ThematicRole, Term<'a>)> = vec![
            (ThematicRole::Agent, Term::Constant(subject_sym))
        ];
        roles.extend(template.non_agent_roles.iter().cloned());

        let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
            event_var,
            verb: template.verb,
            roles: self.ctx.roles.alloc_slice(roles),
            modifiers: self.ctx.syms.alloc_slice(template.modifiers.clone()),
            suppress_existential,
        })));

        // Apply modal if auxiliary is modal
        let with_modal = match aux_token {
            TokenType::Can | TokenType::Could => {
                let vector = self.token_to_vector(&aux_token);
                self.ctx.modal(vector, neo_event)
            }
            TokenType::Would | TokenType::May | TokenType::Must | TokenType::Should => {
                let vector = self.token_to_vector(&aux_token);
                self.ctx.modal(vector, neo_event)
            }
            _ => neo_event,
        };

        // Apply negation if present
        let result = if is_negated {
            self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                op: TokenType::Not,
                operand: with_modal,
            })
        } else {
            with_modal
        };

        Some(Ok(result))
    }
}

```

---

### QuantifierParsing Trait

**File:** `src/parser/quantifier.rs`

Extension trait for quantified expressions: universal (all/every/each), existential (some/a/an), generic (bare plurals), negative (no/none). Handles restrictions, verb phrase parsing for restrictions, definiteness wrapping (with adjectives and PPs), donkey anaphora binding, PP placeholder substitution, and stacked relative clauses ('the book that John read that Mary wrote').

```rust
use super::clause::ClauseParsing;
use super::modal::ModalParsing;
use super::noun::NounParsing;
use super::{NegativeScopeMode, ParseResult, Parser};
use crate::ast::{LogicExpr, NounPhrase, QuantifierKind, Term};
use crate::context::Number;
use crate::error::{ParseError, ParseErrorKind};
use crate::intern::Symbol;
use crate::lexer::Lexer;
use crate::lexicon::{get_canonical_verb, is_subsective, Definiteness, Time};
use crate::token::{PresupKind, TokenType};

pub trait QuantifierParsing<'a, 'ctx, 'int> {
    fn parse_quantified(&mut self) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_restriction(&mut self, var_name: Symbol) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_verb_phrase_for_restriction(&mut self, var_name: Symbol) -> ParseResult<&'a LogicExpr<'a>>;
    fn combine_with_and(&self, exprs: Vec<&'a LogicExpr<'a>>) -> ParseResult<&'a LogicExpr<'a>>;
    fn wrap_with_definiteness_full(
        &mut self,
        np: &NounPhrase<'a>,
        predicate: &'a LogicExpr<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>>;
    fn wrap_with_definiteness(
        &mut self,
        definiteness: Option<Definiteness>,
        noun: Symbol,
        predicate: &'a LogicExpr<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>>;
    fn wrap_with_definiteness_and_adjectives(
        &mut self,
        definiteness: Option<Definiteness>,
        noun: Symbol,
        adjectives: &[Symbol],
        predicate: &'a LogicExpr<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>>;
    fn wrap_with_definiteness_and_adjectives_and_pps(
        &mut self,
        definiteness: Option<Definiteness>,
        noun: Symbol,
        adjectives: &[Symbol],
        pps: &[&'a LogicExpr<'a>],
        predicate: &'a LogicExpr<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>>;
    fn wrap_with_definiteness_for_object(
        &mut self,
        definiteness: Option<Definiteness>,
        noun: Symbol,
        predicate: &'a LogicExpr<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>>;
    fn substitute_pp_placeholder(&mut self, pp: &'a LogicExpr<'a>, var: Symbol) -> &'a LogicExpr<'a>;
    fn substitute_constant_with_var(
        &self,
        expr: &'a LogicExpr<'a>,
        constant_name: Symbol,
        var_name: Symbol,
    ) -> ParseResult<&'a LogicExpr<'a>>;
    fn substitute_constant_with_var_sym(
        &self,
        expr: &'a LogicExpr<'a>,
        constant_name: Symbol,
        var_name: Symbol,
    ) -> ParseResult<&'a LogicExpr<'a>>;
    fn substitute_constant_with_sigma(
        &self,
        expr: &'a LogicExpr<'a>,
        constant_name: Symbol,
        sigma_term: Term<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>>;
    fn find_main_verb_name(&self, expr: &LogicExpr<'a>) -> Option<Symbol>;
    fn transform_cardinal_to_group(&mut self, expr: &'a LogicExpr<'a>) -> ParseResult<&'a LogicExpr<'a>>;
}

impl<'a, 'ctx, 'int> QuantifierParsing<'a, 'ctx, 'int> for Parser<'a, 'ctx, 'int> {
    fn parse_quantified(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let quantifier_token = self.previous().kind.clone();
        let var_name = self.next_var_name();

        let subject_pred = self.parse_restriction(var_name)?;

        if self.check_modal() {
            use crate::ast::ModalFlavor;

            self.advance();
            let vector = self.token_to_vector(&self.previous().kind.clone());
            let verb = self.consume_content_word()?;

            // Parse object if present (e.g., "can enter the room" -> room is object)
            let verb_args = if self.check_content_word() || self.check_article() {
                let obj_np = self.parse_noun_phrase(false)?;
                let obj_term = self.noun_phrase_to_term(&obj_np);
                self.ctx.terms.alloc_slice([Term::Variable(var_name), obj_term])
            } else {
                self.ctx.terms.alloc_slice([Term::Variable(var_name)])
            };

            let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: verb_args,
            });

            // Determine quantifier kind first (shared by both branches)
            let kind = match quantifier_token {
                TokenType::All | TokenType::No => QuantifierKind::Universal,
                TokenType::Any => {
                    if self.is_negative_context() {
                        QuantifierKind::Existential
                    } else {
                        QuantifierKind::Universal
                    }
                }
                TokenType::Some => QuantifierKind::Existential,
                TokenType::Most => QuantifierKind::Most,
                TokenType::Few => QuantifierKind::Few,
                TokenType::Many => QuantifierKind::Many,
                TokenType::Cardinal(n) => QuantifierKind::Cardinal(n),
                TokenType::AtLeast(n) => QuantifierKind::AtLeast(n),
                TokenType::AtMost(n) => QuantifierKind::AtMost(n),
                _ => {
                    return Err(ParseError {
                        kind: ParseErrorKind::UnknownQuantifier {
                            found: quantifier_token.clone(),
                        },
                        span: self.current_span(),
                    })
                }
            };

            // Branch on modal flavor for scope handling
            if vector.flavor == ModalFlavor::Root {
                // === NARROW SCOPE (De Re) ===
                // Root modals (can, must, should) attach to the predicate inside the quantifier
                // "Some birds can fly" → ∃x(Bird(x) ∧ ◇Fly(x))

                // Wrap the verb predicate in the modal
                let modal_verb = self.ctx.exprs.alloc(LogicExpr::Modal {
                    vector,
                    operand: verb_pred,
                });

                let body = match quantifier_token {
                    TokenType::All => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: subject_pred,
                        op: TokenType::If,
                        right: modal_verb,
                    }),
                    TokenType::Any => {
                        if self.is_negative_context() {
                            self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                left: subject_pred,
                                op: TokenType::And,
                                right: modal_verb,
                            })
                        } else {
                            self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                left: subject_pred,
                                op: TokenType::If,
                                right: modal_verb,
                            })
                        }
                    }
                    TokenType::Some
                    | TokenType::Most
                    | TokenType::Few
                    | TokenType::Many
                    | TokenType::Cardinal(_)
                    | TokenType::AtLeast(_)
                    | TokenType::AtMost(_) => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: subject_pred,
                        op: TokenType::And,
                        right: modal_verb,
                    }),
                    TokenType::No => {
                        let neg = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                            op: TokenType::Not,
                            operand: modal_verb,
                        });
                        self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: subject_pred,
                            op: TokenType::If,
                            right: neg,
                        })
                    }
                    _ => {
                        return Err(ParseError {
                            kind: ParseErrorKind::UnknownQuantifier {
                                found: quantifier_token.clone(),
                            },
                            span: self.current_span(),
                        })
                    }
                };

                // Build quantifier (modal is inside)
                let mut result = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind,
                    variable: var_name,
                    body,
                    island_id: self.current_island,
                });

                // Process donkey bindings for indefinites in restrictions (e.g., "who lacks a key")
                for (_noun, donkey_var, used, wide_neg) in self.donkey_bindings.iter().rev() {
                    if *used {
                        // Donkey anaphora: wrap with ∀ at outer scope
                        result = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                            kind: QuantifierKind::Universal,
                            variable: *donkey_var,
                            body: result,
                            island_id: self.current_island,
                        });
                    } else {
                        // Non-donkey: wrap with ∃ INSIDE the restriction
                        result = self.wrap_donkey_in_restriction(result, *donkey_var, *wide_neg);
                    }
                }
                self.donkey_bindings.clear();

                return Ok(result);

            } else {
                // === WIDE SCOPE (De Dicto) ===
                // Epistemic modals (might, may) wrap the entire quantifier
                // "Some unicorns might exist" → ◇∃x(Unicorn(x) ∧ Exist(x))

                let body = match quantifier_token {
                    TokenType::All => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: subject_pred,
                        op: TokenType::If,
                        right: verb_pred,
                    }),
                    TokenType::Any => {
                        if self.is_negative_context() {
                            self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                left: subject_pred,
                                op: TokenType::And,
                                right: verb_pred,
                            })
                        } else {
                            self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                left: subject_pred,
                                op: TokenType::If,
                                right: verb_pred,
                            })
                        }
                    }
                    TokenType::Some
                    | TokenType::Most
                    | TokenType::Few
                    | TokenType::Many
                    | TokenType::Cardinal(_)
                    | TokenType::AtLeast(_)
                    | TokenType::AtMost(_) => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: subject_pred,
                        op: TokenType::And,
                        right: verb_pred,
                    }),
                    TokenType::No => {
                        let neg = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                            op: TokenType::Not,
                            operand: verb_pred,
                        });
                        self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: subject_pred,
                            op: TokenType::If,
                            right: neg,
                        })
                    }
                    _ => {
                        return Err(ParseError {
                            kind: ParseErrorKind::UnknownQuantifier {
                                found: quantifier_token.clone(),
                            },
                            span: self.current_span(),
                        })
                    }
                };

                let mut result = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind,
                    variable: var_name,
                    body,
                    island_id: self.current_island,
                });

                // Process donkey bindings for indefinites in restrictions (e.g., "who lacks a key")
                for (_noun, donkey_var, used, wide_neg) in self.donkey_bindings.iter().rev() {
                    if *used {
                        // Donkey anaphora: wrap with ∀ at outer scope
                        result = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                            kind: QuantifierKind::Universal,
                            variable: *donkey_var,
                            body: result,
                            island_id: self.current_island,
                        });
                    } else {
                        // Non-donkey: wrap with ∃ INSIDE the restriction
                        result = self.wrap_donkey_in_restriction(result, *donkey_var, *wide_neg);
                    }
                }
                self.donkey_bindings.clear();

                // Wrap the entire quantifier in the modal
                return Ok(self.ctx.exprs.alloc(LogicExpr::Modal {
                    vector,
                    operand: result,
                }));
            }
        }

        if self.check_auxiliary() {
            let aux_token = self.advance();
            let aux_time = if let TokenType::Auxiliary(time) = aux_token.kind.clone() {
                time
            } else {
                Time::None
            };
            self.pending_time = Some(aux_time);

            let is_negated = self.match_token(&[TokenType::Not]);
            if is_negated {
                self.negative_depth += 1;
            }

            if self.check_verb() {
                let verb = self.consume_verb();
                let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                });

                let maybe_negated = if is_negated {
                    self.negative_depth -= 1;
                    self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                        op: TokenType::Not,
                        operand: verb_pred,
                    })
                } else {
                    verb_pred
                };

                let body = match quantifier_token {
                    TokenType::All | TokenType::Any => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: subject_pred,
                        op: TokenType::If,
                        right: maybe_negated,
                    }),
                    _ => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: subject_pred,
                        op: TokenType::And,
                        right: maybe_negated,
                    }),
                };

                let kind = match quantifier_token {
                    TokenType::All | TokenType::No => QuantifierKind::Universal,
                    TokenType::Some => QuantifierKind::Existential,
                    TokenType::Most => QuantifierKind::Most,
                    TokenType::Few => QuantifierKind::Few,
                    TokenType::Cardinal(n) => QuantifierKind::Cardinal(n),
                    TokenType::AtLeast(n) => QuantifierKind::AtLeast(n),
                    TokenType::AtMost(n) => QuantifierKind::AtMost(n),
                    _ => QuantifierKind::Universal,
                };

                return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind,
                    variable: var_name,
                    body,
                    island_id: self.current_island,
                }));
            }
        }

        // Only trigger presupposition if followed by gerund complement
        if self.check_presup_trigger() && self.is_followed_by_gerund() {
            let presup_kind = match self.advance().kind {
                TokenType::PresupTrigger(kind) => kind,
                TokenType::Verb { lemma, .. } => {
                    let s = self.interner.resolve(lemma).to_lowercase();
                    crate::lexicon::lookup_presup_trigger(&s)
                        .expect("Lexicon mismatch: Verb flagged as trigger but lookup failed")
                }
                _ => panic!("Expected presupposition trigger"),
            };

            let complement = if self.check_verb() {
                let verb = self.consume_verb();
                self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                })
            } else {
                let unknown = self.interner.intern("?");
                self.ctx.exprs.alloc(LogicExpr::Atom(unknown))
            };

            let verb_pred = match presup_kind {
                PresupKind::Stop => self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                    op: TokenType::Not,
                    operand: complement,
                }),
                PresupKind::Start | PresupKind::Continue => complement,
                PresupKind::Regret | PresupKind::Realize | PresupKind::Know => complement,
            };

            let body = match quantifier_token {
                TokenType::All | TokenType::Any => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: subject_pred,
                    op: TokenType::If,
                    right: verb_pred,
                }),
                _ => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: subject_pred,
                    op: TokenType::And,
                    right: verb_pred,
                }),
            };

            let kind = match quantifier_token {
                TokenType::All | TokenType::No => QuantifierKind::Universal,
                TokenType::Some => QuantifierKind::Existential,
                TokenType::Most => QuantifierKind::Most,
                TokenType::Few => QuantifierKind::Few,
                TokenType::Many => QuantifierKind::Many,
                TokenType::Cardinal(n) => QuantifierKind::Cardinal(n),
                TokenType::AtLeast(n) => QuantifierKind::AtLeast(n),
                TokenType::AtMost(n) => QuantifierKind::AtMost(n),
                _ => QuantifierKind::Universal,
            };

            return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                kind,
                variable: var_name,
                body,
                island_id: self.current_island,
            }));
        }

        if self.check_verb() {
            let verb = self.consume_verb();
            let mut args = vec![Term::Variable(var_name)];

            if self.check_pronoun() {
                let token = self.peek().clone();
                if let TokenType::Pronoun { gender, .. } = token.kind {
                    self.advance();
                    if let Some(donkey_var) = self.resolve_donkey_pronoun(gender) {
                        args.push(Term::Variable(donkey_var));
                    } else {
                        let unknown = self.interner.intern("?");
                        let resolved = self
                            .resolve_pronoun(gender, Number::Singular)
                            .unwrap_or(unknown);
                        args.push(Term::Constant(resolved));
                    }
                }
            } else if self.check_npi_object() {
                let npi_token = self.advance().kind.clone();
                let obj_var = self.next_var_name();

                let restriction_name = match npi_token {
                    TokenType::Anything => "Thing",
                    TokenType::Anyone => "Person",
                    _ => "Thing",
                };

                let restriction_sym = self.interner.intern(restriction_name);
                let obj_restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: restriction_sym,
                    args: self.ctx.terms.alloc_slice([Term::Variable(obj_var)]),
                });

                let verb_with_obj = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb,
                    args: self.ctx.terms.alloc_slice([
                        Term::Variable(var_name),
                        Term::Variable(obj_var),
                    ]),
                });

                let npi_body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: obj_restriction,
                    op: TokenType::And,
                    right: verb_with_obj,
                });

                let npi_quantified = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: obj_var,
                    body: npi_body,
                    island_id: self.current_island,
                });

                let negated_npi = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                    op: TokenType::Not,
                    operand: npi_quantified,
                });

                let body = match quantifier_token {
                    TokenType::All | TokenType::No => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: subject_pred,
                        op: TokenType::If,
                        right: negated_npi,
                    }),
                    _ => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: subject_pred,
                        op: TokenType::And,
                        right: negated_npi,
                    }),
                };

                let kind = match quantifier_token {
                    TokenType::All | TokenType::No => QuantifierKind::Universal,
                    TokenType::Some => QuantifierKind::Existential,
                    TokenType::Most => QuantifierKind::Most,
                    TokenType::Few => QuantifierKind::Few,
                    TokenType::Many => QuantifierKind::Many,
                    TokenType::Cardinal(n) => QuantifierKind::Cardinal(n),
                    TokenType::AtLeast(n) => QuantifierKind::AtLeast(n),
                    TokenType::AtMost(n) => QuantifierKind::AtMost(n),
                    _ => QuantifierKind::Universal,
                };

                return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind,
                    variable: var_name,
                    body,
                    island_id: self.current_island,
                }));
            } else if self.check_quantifier() || self.check_article() {
                let obj_quantifier = if self.check_quantifier() {
                    Some(self.advance().kind.clone())
                } else {
                    let art = self.advance().kind.clone();
                    if let TokenType::Article(def) = art {
                        if def == Definiteness::Indefinite {
                            Some(TokenType::Some)
                        } else {
                            None
                        }
                    } else {
                        None
                    }
                };

                let object = self.parse_noun_phrase(false)?;

                if let Some(obj_q) = obj_quantifier {
                    let obj_var = self.next_var_name();
                    let obj_restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: object.noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(obj_var)]),
                    });

                    let verb_with_obj = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: verb,
                        args: self.ctx.terms.alloc_slice([
                            Term::Variable(var_name),
                            Term::Variable(obj_var),
                        ]),
                    });

                    let obj_kind = match obj_q {
                        TokenType::All => QuantifierKind::Universal,
                        TokenType::Some => QuantifierKind::Existential,
                        TokenType::No => QuantifierKind::Universal,
                        TokenType::Most => QuantifierKind::Most,
                        TokenType::Few => QuantifierKind::Few,
                        TokenType::Many => QuantifierKind::Many,
                        TokenType::Cardinal(n) => QuantifierKind::Cardinal(n),
                        TokenType::AtLeast(n) => QuantifierKind::AtLeast(n),
                        TokenType::AtMost(n) => QuantifierKind::AtMost(n),
                        _ => QuantifierKind::Existential,
                    };

                    let obj_body = match obj_q {
                        TokenType::All => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: obj_restriction,
                            op: TokenType::If,
                            right: verb_with_obj,
                        }),
                        TokenType::No => {
                            let neg = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                                op: TokenType::Not,
                                operand: verb_with_obj,
                            });
                            self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                left: obj_restriction,
                                op: TokenType::If,
                                right: neg,
                            })
                        }
                        _ => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: obj_restriction,
                            op: TokenType::And,
                            right: verb_with_obj,
                        }),
                    };

                    let obj_quantified = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                        kind: obj_kind,
                        variable: obj_var,
                        body: obj_body,
                        island_id: self.current_island,
                    });

                    let subj_kind = match quantifier_token {
                        TokenType::All | TokenType::No => QuantifierKind::Universal,
                        TokenType::Any => {
                            if self.is_negative_context() {
                                QuantifierKind::Existential
                            } else {
                                QuantifierKind::Universal
                            }
                        }
                        TokenType::Some => QuantifierKind::Existential,
                        TokenType::Most => QuantifierKind::Most,
                        TokenType::Few => QuantifierKind::Few,
                        TokenType::Many => QuantifierKind::Many,
                        TokenType::Cardinal(n) => QuantifierKind::Cardinal(n),
                        TokenType::AtLeast(n) => QuantifierKind::AtLeast(n),
                        TokenType::AtMost(n) => QuantifierKind::AtMost(n),
                        _ => QuantifierKind::Universal,
                    };

                    let subj_body = match quantifier_token {
                        TokenType::All => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: subject_pred,
                            op: TokenType::If,
                            right: obj_quantified,
                        }),
                        TokenType::No => {
                            let neg = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                                op: TokenType::Not,
                                operand: obj_quantified,
                            });
                            self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                left: subject_pred,
                                op: TokenType::If,
                                right: neg,
                            })
                        }
                        _ => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: subject_pred,
                            op: TokenType::And,
                            right: obj_quantified,
                        }),
                    };

                    return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                        kind: subj_kind,
                        variable: var_name,
                        body: subj_body,
                        island_id: self.current_island,
                    }));
                } else {
                    args.push(Term::Constant(object.noun));
                }
            } else if self.check_content_word() {
                let object = self.parse_noun_phrase(false)?;
                args.push(Term::Constant(object.noun));
            }

            let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice(args),
            });

            let body = match quantifier_token {
                TokenType::All => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: subject_pred,
                    op: TokenType::If,
                    right: verb_pred,
                }),
                TokenType::Any => {
                    if self.is_negative_context() {
                        self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: subject_pred,
                            op: TokenType::And,
                            right: verb_pred,
                        })
                    } else {
                        self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: subject_pred,
                            op: TokenType::If,
                            right: verb_pred,
                        })
                    }
                }
                TokenType::Some
                | TokenType::Most
                | TokenType::Few
                | TokenType::Many
                | TokenType::Cardinal(_)
                | TokenType::AtLeast(_)
                | TokenType::AtMost(_) => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: subject_pred,
                    op: TokenType::And,
                    right: verb_pred,
                }),
                TokenType::No => {
                    let neg = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                        op: TokenType::Not,
                        operand: verb_pred,
                    });
                    self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: subject_pred,
                        op: TokenType::If,
                        right: neg,
                    })
                }
                _ => {
                    return Err(ParseError {
                        kind: ParseErrorKind::UnknownQuantifier {
                            found: quantifier_token.clone(),
                        },
                        span: self.current_span(),
                    })
                }
            };

            let kind = match quantifier_token {
                TokenType::All | TokenType::No => QuantifierKind::Universal,
                TokenType::Any => {
                    if self.is_negative_context() {
                        QuantifierKind::Existential
                    } else {
                        QuantifierKind::Universal
                    }
                }
                TokenType::Some => QuantifierKind::Existential,
                TokenType::Most => QuantifierKind::Most,
                TokenType::Few => QuantifierKind::Few,
                TokenType::Many => QuantifierKind::Many,
                TokenType::Cardinal(n) => QuantifierKind::Cardinal(n),
                TokenType::AtLeast(n) => QuantifierKind::AtLeast(n),
                TokenType::AtMost(n) => QuantifierKind::AtMost(n),
                _ => {
                    return Err(ParseError {
                        kind: ParseErrorKind::UnknownQuantifier {
                            found: quantifier_token.clone(),
                        },
                        span: self.current_span(),
                    })
                }
            };

            let mut result = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                kind,
                variable: var_name,
                body,
                island_id: self.current_island,
            });

            for (_noun, donkey_var, used, wide_neg) in self.donkey_bindings.iter().rev() {
                if *used {
                    // Donkey anaphora: wrap with ∀ at outer scope
                    result = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                        kind: QuantifierKind::Universal,
                        variable: *donkey_var,
                        body: result,
                        island_id: self.current_island,
                    });
                } else {
                    // Non-donkey: wrap with ∃ INSIDE the restriction
                    result = self.wrap_donkey_in_restriction(result, *donkey_var, *wide_neg);
                }
            }
            self.donkey_bindings.clear();

            return Ok(result);
        }

        self.consume_copula()?;

        let negative = self.match_token(&[TokenType::Not]);
        let predicate_np = self.parse_noun_phrase(true)?;

        let predicate_expr = self.ctx.exprs.alloc(LogicExpr::Predicate {
            name: predicate_np.noun,
            args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
        });

        let final_predicate = if negative {
            self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                op: TokenType::Not,
                operand: predicate_expr,
            })
        } else {
            predicate_expr
        };

        let body = match quantifier_token {
            TokenType::All => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: subject_pred,
                op: TokenType::If,
                right: final_predicate,
            }),
            TokenType::Any => {
                if self.is_negative_context() {
                    self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: subject_pred,
                        op: TokenType::And,
                        right: final_predicate,
                    })
                } else {
                    self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: subject_pred,
                        op: TokenType::If,
                        right: final_predicate,
                    })
                }
            }
            TokenType::Some
            | TokenType::Most
            | TokenType::Few
            | TokenType::Many
            | TokenType::Cardinal(_)
            | TokenType::AtLeast(_)
            | TokenType::AtMost(_) => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: subject_pred,
                op: TokenType::And,
                right: final_predicate,
            }),
            TokenType::No => {
                let neg_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: predicate_np.noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                });
                let neg = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                    op: TokenType::Not,
                    operand: neg_pred,
                });
                self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: subject_pred,
                    op: TokenType::If,
                    right: neg,
                })
            }
            _ => {
                return Err(ParseError {
                    kind: ParseErrorKind::UnknownQuantifier {
                        found: quantifier_token.clone(),
                    },
                    span: self.current_span(),
                })
            }
        };

        let kind = match quantifier_token {
            TokenType::All | TokenType::No => QuantifierKind::Universal,
            TokenType::Any => {
                if self.is_negative_context() {
                    QuantifierKind::Existential
                } else {
                    QuantifierKind::Universal
                }
            }
            TokenType::Some => QuantifierKind::Existential,
            TokenType::Most => QuantifierKind::Most,
            TokenType::Few => QuantifierKind::Few,
            TokenType::Many => QuantifierKind::Many,
            TokenType::Cardinal(n) => QuantifierKind::Cardinal(n),
            TokenType::AtLeast(n) => QuantifierKind::AtLeast(n),
            TokenType::AtMost(n) => QuantifierKind::AtMost(n),
            _ => {
                return Err(ParseError {
                    kind: ParseErrorKind::UnknownQuantifier {
                        found: quantifier_token.clone(),
                    },
                    span: self.current_span(),
                })
            }
        };

        let mut result = self.ctx.exprs.alloc(LogicExpr::Quantifier {
            kind,
            variable: var_name,
            body,
            island_id: self.current_island,
        });

        for (_noun, donkey_var, used, wide_neg) in self.donkey_bindings.iter().rev() {
            if *used {
                // Donkey anaphora: wrap with ∀ at outer scope
                result = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Universal,
                    variable: *donkey_var,
                    body: result,
                    island_id: self.current_island,
                });
            } else {
                // Non-donkey: wrap with ∃ INSIDE the restriction
                result = self.wrap_donkey_in_restriction(result, *donkey_var, *wide_neg);
            }
        }
        self.donkey_bindings.clear();

        Ok(result)
    }

    fn parse_restriction(&mut self, var_name: Symbol) -> ParseResult<&'a LogicExpr<'a>> {
        let mut conditions: Vec<&'a LogicExpr<'a>> = Vec::new();

        loop {
            if self.is_at_end() {
                break;
            }

            let is_adjective = matches!(self.peek().kind, TokenType::Adjective(_));
            if !is_adjective {
                break;
            }

            let next_is_content = if self.current + 1 < self.tokens.len() {
                matches!(
                    self.tokens[self.current + 1].kind,
                    TokenType::Noun(_) | TokenType::Adjective(_) | TokenType::ProperName(_)
                )
            } else {
                false
            };

            if next_is_content {
                if let TokenType::Adjective(adj) = self.advance().kind.clone() {
                    conditions.push(self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: adj,
                        args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                    }));
                }
            } else {
                break;
            }
        }

        let noun = self.consume_content_word()?;
        conditions.push(self.ctx.exprs.alloc(LogicExpr::Predicate {
            name: noun,
            args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
        }));

        while self.check(&TokenType::That) || self.check(&TokenType::Who) {
            self.advance();
            let clause_pred = self.parse_relative_clause(var_name)?;
            conditions.push(clause_pred);
        }

        self.combine_with_and(conditions)
    }

    fn parse_verb_phrase_for_restriction(&mut self, var_name: Symbol) -> ParseResult<&'a LogicExpr<'a>> {
        let var_term = Term::Variable(var_name);
        let verb = self.consume_verb();
        let verb_str_owned = self.interner.resolve(verb).to_string();

        // Check EARLY if verb is lexically negative (e.g., "lacks" -> "Have" with negation)
        // This determines whether donkey bindings need wide scope negation
        let (canonical_verb, is_negative) = get_canonical_verb(&verb_str_owned.to_lowercase())
            .map(|(lemma, neg)| (self.interner.intern(lemma), neg))
            .unwrap_or((verb, false));

        // Determine if this binding needs wide scope negation wrapping
        let needs_wide_scope = is_negative && self.negative_scope_mode == NegativeScopeMode::Wide;

        if Lexer::is_raising_verb(&verb_str_owned) && self.check_to() {
            self.advance();
            if self.check_verb() {
                let inf_verb = self.consume_verb();
                let inf_verb_str = self.interner.resolve(inf_verb).to_lowercase();

                if inf_verb_str == "be" && self.check_content_word() {
                    let adj = self.consume_content_word()?;
                    let embedded = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: adj,
                        args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                    });
                    return Ok(self.ctx.exprs.alloc(LogicExpr::Scopal {
                        operator: verb,
                        body: embedded,
                    }));
                }

                let embedded = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: inf_verb,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                });
                return Ok(self.ctx.exprs.alloc(LogicExpr::Scopal {
                    operator: verb,
                    body: embedded,
                }));
            } else if self.check(&TokenType::Is) || self.check(&TokenType::Are) {
                self.advance();
                if self.check_content_word() {
                    let adj = self.consume_content_word()?;
                    let embedded = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: adj,
                        args: self.ctx.terms.alloc_slice([Term::Variable(var_name)]),
                    });
                    return Ok(self.ctx.exprs.alloc(LogicExpr::Scopal {
                        operator: verb,
                        body: embedded,
                    }));
                }
            }
        }

        let mut args = vec![var_term];
        let mut extra_conditions: Vec<&'a LogicExpr<'a>> = Vec::new();

        if self.check(&TokenType::Reflexive) {
            self.advance();
            args.push(Term::Variable(var_name));
        } else if (self.check_content_word() || self.check_article()) && !self.check_verb() {
            if matches!(
                self.peek().kind,
                TokenType::Article(Definiteness::Indefinite)
            ) {
                self.advance();
                let noun = self.consume_content_word()?;
                let donkey_var = self.next_var_name();

                if needs_wide_scope {
                    // === WIDE SCOPE MODE ===
                    // Build ¬∃y(Key(y) ∧ Have(x,y)) directly instead of leaking binding
                    //
                    // We capture the binding HERE and return the complete structure.
                    // DO NOT push to donkey_bindings - that would leak y to outer scope.

                    // Build: Key(y)
                    let restriction_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(donkey_var)]),
                    });

                    // Build: Have(x, y)  (using canonical_verb determined earlier)
                    let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: canonical_verb,
                        args: self.ctx.terms.alloc_slice([var_term, Term::Variable(donkey_var)]),
                    });

                    // Build: Key(y) ∧ Have(x,y)
                    let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: restriction_pred,
                        op: TokenType::And,
                        right: verb_pred,
                    });

                    // Build: ∃y(Key(y) ∧ Have(x,y))
                    let existential = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                        kind: QuantifierKind::Existential,
                        variable: donkey_var,
                        body,
                        island_id: self.current_island,
                    });

                    // Build: ¬∃y(Key(y) ∧ Have(x,y))
                    let negated_existential = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                        op: TokenType::Not,
                        operand: existential,
                    });

                    // Return the complete wide-scope structure directly
                    return Ok(negated_existential);
                }

                // === NARROW SCOPE MODE ===
                // Push binding for later processing (normal donkey binding flow)
                self.donkey_bindings.push((noun, donkey_var, false, false));

                extra_conditions.push(self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(donkey_var)]),
                }));

                args.push(Term::Variable(donkey_var));
            } else {
                let object = self.parse_noun_phrase(false)?;

                if self.check(&TokenType::That) || self.check(&TokenType::Who) {
                    self.advance();
                    let nested_var = self.next_var_name();
                    let nested_rel = self.parse_relative_clause(nested_var)?;

                    extra_conditions.push(self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: object.noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(nested_var)]),
                    }));
                    extra_conditions.push(nested_rel);
                    args.push(Term::Variable(nested_var));
                } else {
                    args.push(Term::Constant(object.noun));
                }
            }
        }

        while self.check_preposition() {
            self.advance();
            if self.check(&TokenType::Reflexive) {
                self.advance();
                args.push(Term::Variable(var_name));
            } else if self.check_content_word() || self.check_article() {
                let object = self.parse_noun_phrase(false)?;

                if self.check(&TokenType::That) || self.check(&TokenType::Who) {
                    self.advance();
                    let nested_var = self.next_var_name();
                    let nested_rel = self.parse_relative_clause(nested_var)?;
                    extra_conditions.push(self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: object.noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(nested_var)]),
                    }));
                    extra_conditions.push(nested_rel);
                    args.push(Term::Variable(nested_var));
                } else {
                    args.push(Term::Constant(object.noun));
                }
            }
        }

        // Use the canonical verb determined at top of function
        let base_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
            name: canonical_verb,
            args: self.ctx.terms.alloc_slice(args),
        });

        // Wrap in negation only for NARROW scope mode (de re reading)
        // Wide scope mode: negation handled via donkey binding flag in wrap_donkey_in_restriction
        // - Narrow: ∃y(Key(y) ∧ ¬Have(x,y)) - "missing ANY key"
        // - Wide:   ¬∃y(Key(y) ∧ Have(x,y)) - "has NO keys"
        let verb_pred = if is_negative && self.negative_scope_mode == NegativeScopeMode::Narrow {
            self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                op: TokenType::Not,
                operand: base_pred,
            })
        } else {
            base_pred
        };

        if extra_conditions.is_empty() {
            Ok(verb_pred)
        } else {
            extra_conditions.push(verb_pred);
            self.combine_with_and(extra_conditions)
        }
    }

    fn combine_with_and(&self, mut exprs: Vec<&'a LogicExpr<'a>>) -> ParseResult<&'a LogicExpr<'a>> {
        if exprs.is_empty() {
            return Err(ParseError {
                kind: ParseErrorKind::EmptyRestriction,
                span: self.current_span(),
            });
        }
        if exprs.len() == 1 {
            return Ok(exprs.remove(0));
        }
        let mut root = exprs.remove(0);
        for expr in exprs {
            root = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: root,
                op: TokenType::And,
                right: expr,
            });
        }
        Ok(root)
    }

    fn wrap_with_definiteness_full(
        &mut self,
        np: &NounPhrase<'a>,
        predicate: &'a LogicExpr<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        let result = self.wrap_with_definiteness_and_adjectives_and_pps(
            np.definiteness,
            np.noun,
            np.adjectives,
            np.pps,
            predicate,
        )?;

        // If NP has a superlative, add the superlative constraint
        if let Some(adj) = np.superlative {
            let superlative_expr = self.ctx.exprs.alloc(LogicExpr::Superlative {
                adjective: adj,
                subject: self.ctx.terms.alloc(Term::Constant(np.noun)),
                domain: np.noun,
            });
            Ok(self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: result,
                op: TokenType::And,
                right: superlative_expr,
            }))
        } else {
            Ok(result)
        }
    }

    fn wrap_with_definiteness(
        &mut self,
        definiteness: Option<Definiteness>,
        noun: Symbol,
        predicate: &'a LogicExpr<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        self.wrap_with_definiteness_and_adjectives_and_pps(definiteness, noun, &[], &[], predicate)
    }

    fn wrap_with_definiteness_and_adjectives(
        &mut self,
        definiteness: Option<Definiteness>,
        noun: Symbol,
        adjectives: &[Symbol],
        predicate: &'a LogicExpr<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        self.wrap_with_definiteness_and_adjectives_and_pps(
            definiteness,
            noun,
            adjectives,
            &[],
            predicate,
        )
    }

    fn wrap_with_definiteness_and_adjectives_and_pps(
        &mut self,
        definiteness: Option<Definiteness>,
        noun: Symbol,
        adjectives: &[Symbol],
        pps: &[&'a LogicExpr<'a>],
        predicate: &'a LogicExpr<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        match definiteness {
            Some(Definiteness::Indefinite) => {
                let var = self.next_var_name();

                let mut restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var)]),
                });

                for adj in adjectives {
                    let adj_str = self.interner.resolve(*adj).to_lowercase();
                    let adj_pred = if is_subsective(&adj_str) {
                        self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: *adj,
                            args: self.ctx.terms.alloc_slice([
                                Term::Variable(var),
                                Term::Intension(noun),
                            ]),
                        })
                    } else {
                        self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: *adj,
                            args: self.ctx.terms.alloc_slice([Term::Variable(var)]),
                        })
                    };
                    restriction = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: restriction,
                        op: TokenType::And,
                        right: adj_pred,
                    });
                }

                for pp in pps {
                    let substituted_pp = self.substitute_pp_placeholder(pp, var);
                    restriction = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: restriction,
                        op: TokenType::And,
                        right: substituted_pp,
                    });
                }

                let substituted = self.substitute_constant_with_var_sym(predicate, noun, var)?;
                let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: restriction,
                    op: TokenType::And,
                    right: substituted,
                });
                Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: var,
                    body,
                    island_id: self.current_island,
                }))
            }
            Some(Definiteness::Definite) => {
                let noun_str = self.interner.resolve(noun).to_string();

                if Self::is_plural_noun(&noun_str) {
                    let singular = Self::singularize_noun(&noun_str);
                    let singular_sym = self.interner.intern(&singular);
                    let sigma_term = Term::Sigma(singular_sym);

                    let substituted =
                        self.substitute_constant_with_sigma(predicate, noun, sigma_term)?;

                    let verb_name = self.find_main_verb_name(predicate);
                    let is_collective = verb_name
                        .map(|v| {
                            let lemma = self.interner.resolve(v);
                            Lexer::is_collective_verb(lemma)
                                || (Lexer::is_mixed_verb(lemma) && self.collective_mode)
                        })
                        .unwrap_or(false);

                    if is_collective {
                        Ok(substituted)
                    } else {
                        Ok(self.ctx.exprs.alloc(LogicExpr::Distributive {
                            predicate: substituted,
                        }))
                    }
                } else {
                    let x = self.next_var_name();
                    let y = self.next_var_name();

                    let mut restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(x)]),
                    });

                    for adj in adjectives {
                        let adj_str = self.interner.resolve(*adj).to_lowercase();
                        let adj_pred = if is_subsective(&adj_str) {
                            self.ctx.exprs.alloc(LogicExpr::Predicate {
                                name: *adj,
                                args: self.ctx.terms.alloc_slice([
                                    Term::Variable(x),
                                    Term::Intension(noun),
                                ]),
                            })
                        } else {
                            self.ctx.exprs.alloc(LogicExpr::Predicate {
                                name: *adj,
                                args: self.ctx.terms.alloc_slice([Term::Variable(x)]),
                            })
                        };
                        restriction = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: restriction,
                            op: TokenType::And,
                            right: adj_pred,
                        });
                    }

                    for pp in pps {
                        let substituted_pp = self.substitute_pp_placeholder(pp, x);
                        restriction = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: restriction,
                            op: TokenType::And,
                            right: substituted_pp,
                        });
                    }

                    // Bridging anaphora: check if this noun is a part of a previously mentioned whole
                    if let Some(ref mut ctx) = self.context {
                        // Use full name for symbol comparison (matches discourse context storage)
                        let our_symbol = crate::transpile::capitalize_first(&noun_str);
                        let has_prior_antecedent = ctx.resolve_definite(&noun_str)
                            .map(|e| e.symbol != our_symbol)
                            .unwrap_or(false);

                        if !has_prior_antecedent {
                            let bridging_matches = ctx.resolve_bridging(&noun_str);
                            if let Some((entity, _whole_name)) = bridging_matches.first() {
                                let whole_sym = self.interner.intern(&entity.symbol);
                                let part_of_sym = self.interner.intern("PartOf");
                                let part_of_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                                    name: part_of_sym,
                                    args: self.ctx.terms.alloc_slice([
                                        Term::Variable(x),
                                        Term::Constant(whole_sym),
                                    ]),
                                });
                                restriction = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                    left: restriction,
                                    op: TokenType::And,
                                    right: part_of_pred,
                                });
                            }
                        }
                    }

                    let mut y_restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(y)]),
                    });
                    for adj in adjectives {
                        let adj_str = self.interner.resolve(*adj).to_lowercase();
                        let adj_pred = if is_subsective(&adj_str) {
                            self.ctx.exprs.alloc(LogicExpr::Predicate {
                                name: *adj,
                                args: self.ctx.terms.alloc_slice([
                                    Term::Variable(y),
                                    Term::Intension(noun),
                                ]),
                            })
                        } else {
                            self.ctx.exprs.alloc(LogicExpr::Predicate {
                                name: *adj,
                                args: self.ctx.terms.alloc_slice([Term::Variable(y)]),
                            })
                        };
                        y_restriction = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: y_restriction,
                            op: TokenType::And,
                            right: adj_pred,
                        });
                    }

                    for pp in pps {
                        let substituted_pp = self.substitute_pp_placeholder(pp, y);
                        y_restriction = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: y_restriction,
                            op: TokenType::And,
                            right: substituted_pp,
                        });
                    }

                    let identity = self.ctx.exprs.alloc(LogicExpr::Identity {
                        left: self.ctx.terms.alloc(Term::Variable(y)),
                        right: self.ctx.terms.alloc(Term::Variable(x)),
                    });
                    let uniqueness_body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: y_restriction,
                        op: TokenType::If,
                        right: identity,
                    });
                    let uniqueness = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                        kind: QuantifierKind::Universal,
                        variable: y,
                        body: uniqueness_body,
                        island_id: self.current_island,
                    });

                    let main_pred = self.substitute_constant_with_var_sym(predicate, noun, x)?;

                    let inner = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: restriction,
                        op: TokenType::And,
                        right: uniqueness,
                    });
                    let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: inner,
                        op: TokenType::And,
                        right: main_pred,
                    });

                    Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                        kind: QuantifierKind::Existential,
                        variable: x,
                        body,
                        island_id: self.current_island,
                    }))
                }
            }
            Some(Definiteness::Proximal) | Some(Definiteness::Distal) => {
                let var = self.next_var_name();

                let mut restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var)]),
                });

                let deictic_name = if matches!(definiteness, Some(Definiteness::Proximal)) {
                    self.interner.intern("Proximal")
                } else {
                    self.interner.intern("Distal")
                };
                let deictic_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: deictic_name,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var)]),
                });
                restriction = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: restriction,
                    op: TokenType::And,
                    right: deictic_pred,
                });

                for adj in adjectives {
                    let adj_str = self.interner.resolve(*adj).to_lowercase();
                    let adj_pred = if is_subsective(&adj_str) {
                        self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: *adj,
                            args: self.ctx.terms.alloc_slice([
                                Term::Variable(var),
                                Term::Intension(noun),
                            ]),
                        })
                    } else {
                        self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: *adj,
                            args: self.ctx.terms.alloc_slice([Term::Variable(var)]),
                        })
                    };
                    restriction = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: restriction,
                        op: TokenType::And,
                        right: adj_pred,
                    });
                }

                for pp in pps {
                    let substituted_pp = self.substitute_pp_placeholder(pp, var);
                    restriction = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: restriction,
                        op: TokenType::And,
                        right: substituted_pp,
                    });
                }

                let substituted = self.substitute_constant_with_var_sym(predicate, noun, var)?;
                let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: restriction,
                    op: TokenType::And,
                    right: substituted,
                });
                Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: var,
                    body,
                    island_id: self.current_island,
                }))
            }
            None => Ok(predicate),
        }
    }

    fn wrap_with_definiteness_for_object(
        &mut self,
        definiteness: Option<Definiteness>,
        noun: Symbol,
        predicate: &'a LogicExpr<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        match definiteness {
            Some(Definiteness::Indefinite) => {
                let var = self.next_var_name();
                let type_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var)]),
                });
                let substituted = self.substitute_constant_with_var(predicate, noun, var)?;
                let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: type_pred,
                    op: TokenType::And,
                    right: substituted,
                });
                Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: var,
                    body,
                    island_id: self.current_island,
                }))
            }
            Some(Definiteness::Definite) => {
                let x = self.next_var_name();
                let y = self.next_var_name();

                let type_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(x)]),
                });

                let identity = self.ctx.exprs.alloc(LogicExpr::Identity {
                    left: self.ctx.terms.alloc(Term::Variable(y)),
                    right: self.ctx.terms.alloc(Term::Variable(x)),
                });
                let inner_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(y)]),
                });
                let uniqueness_body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: inner_pred,
                    op: TokenType::If,
                    right: identity,
                });
                let uniqueness = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Universal,
                    variable: y,
                    body: uniqueness_body,
                    island_id: self.current_island,
                });

                let main_pred = self.substitute_constant_with_var(predicate, noun, x)?;

                let type_and_unique = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: type_pred,
                    op: TokenType::And,
                    right: uniqueness,
                });
                let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: type_and_unique,
                    op: TokenType::And,
                    right: main_pred,
                });

                Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: x,
                    body,
                    island_id: self.current_island,
                }))
            }
            Some(Definiteness::Proximal) | Some(Definiteness::Distal) => {
                let var = self.next_var_name();

                let mut restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: noun,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var)]),
                });

                let deictic_name = if matches!(definiteness, Some(Definiteness::Proximal)) {
                    self.interner.intern("Proximal")
                } else {
                    self.interner.intern("Distal")
                };
                let deictic_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: deictic_name,
                    args: self.ctx.terms.alloc_slice([Term::Variable(var)]),
                });
                restriction = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: restriction,
                    op: TokenType::And,
                    right: deictic_pred,
                });

                let substituted = self.substitute_constant_with_var(predicate, noun, var)?;
                let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: restriction,
                    op: TokenType::And,
                    right: substituted,
                });
                Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: var,
                    body,
                    island_id: self.current_island,
                }))
            }
            None => Ok(predicate),
        }
    }

    fn substitute_pp_placeholder(&mut self, pp: &'a LogicExpr<'a>, var: Symbol) -> &'a LogicExpr<'a> {
        let placeholder = self.interner.intern("_PP_SELF_");
        match pp {
            LogicExpr::Predicate { name, args } => {
                let new_args: Vec<Term<'a>> = args
                    .iter()
                    .map(|arg| match arg {
                        Term::Variable(v) if *v == placeholder => Term::Variable(var),
                        other => *other,
                    })
                    .collect();
                self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: *name,
                    args: self.ctx.terms.alloc_slice(new_args),
                })
            }
            _ => pp,
        }
    }

    fn substitute_constant_with_var(
        &self,
        expr: &'a LogicExpr<'a>,
        constant_name: Symbol,
        var_name: Symbol,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        match expr {
            LogicExpr::Predicate { name, args } => {
                let new_args: Vec<Term<'a>> = args
                    .iter()
                    .map(|arg| match arg {
                        Term::Constant(c) if *c == constant_name => Term::Variable(var_name),
                        Term::Constant(c) => Term::Constant(*c),
                        Term::Variable(v) => Term::Variable(*v),
                        Term::Function(n, a) => Term::Function(*n, *a),
                        Term::Group(m) => Term::Group(*m),
                        Term::Possessed { possessor, possessed } => Term::Possessed {
                            possessor: *possessor,
                            possessed: *possessed,
                        },
                        Term::Sigma(p) => Term::Sigma(*p),
                        Term::Intension(p) => Term::Intension(*p),
                        Term::Proposition(e) => Term::Proposition(*e),
                        Term::Value { kind, unit, dimension } => Term::Value {
                            kind: *kind,
                            unit: *unit,
                            dimension: *dimension,
                        },
                    })
                    .collect();
                Ok(self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: *name,
                    args: self.ctx.terms.alloc_slice(new_args),
                }))
            }
            LogicExpr::Temporal { operator, body } => Ok(self.ctx.exprs.alloc(LogicExpr::Temporal {
                operator: *operator,
                body: self.substitute_constant_with_var(body, constant_name, var_name)?,
            })),
            LogicExpr::Aspectual { operator, body } => Ok(self.ctx.exprs.alloc(LogicExpr::Aspectual {
                operator: *operator,
                body: self.substitute_constant_with_var(body, constant_name, var_name)?,
            })),
            LogicExpr::UnaryOp { op, operand } => Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                op: op.clone(),
                operand: self.substitute_constant_with_var(operand, constant_name, var_name)?,
            })),
            LogicExpr::BinaryOp { left, op, right } => Ok(self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: self.substitute_constant_with_var(left, constant_name, var_name)?,
                op: op.clone(),
                right: self.substitute_constant_with_var(right, constant_name, var_name)?,
            })),
            LogicExpr::Event { predicate, adverbs } => Ok(self.ctx.exprs.alloc(LogicExpr::Event {
                predicate: self.substitute_constant_with_var(predicate, constant_name, var_name)?,
                adverbs: *adverbs,
            })),
            LogicExpr::TemporalAnchor { anchor, body } => {
                Ok(self.ctx.exprs.alloc(LogicExpr::TemporalAnchor {
                    anchor: *anchor,
                    body: self.substitute_constant_with_var(body, constant_name, var_name)?,
                }))
            }
            _ => Ok(expr),
        }
    }

    fn substitute_constant_with_var_sym(
        &self,
        expr: &'a LogicExpr<'a>,
        constant_name: Symbol,
        var_name: Symbol,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        self.substitute_constant_with_var(expr, constant_name, var_name)
    }

    fn substitute_constant_with_sigma(
        &self,
        expr: &'a LogicExpr<'a>,
        constant_name: Symbol,
        sigma_term: Term<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        match expr {
            LogicExpr::Predicate { name, args } => {
                let new_args: Vec<Term<'a>> = args
                    .iter()
                    .map(|arg| match arg {
                        Term::Constant(c) if *c == constant_name => sigma_term.clone(),
                        Term::Constant(c) => Term::Constant(*c),
                        Term::Variable(v) => Term::Variable(*v),
                        Term::Function(n, a) => Term::Function(*n, *a),
                        Term::Group(m) => Term::Group(*m),
                        Term::Possessed { possessor, possessed } => Term::Possessed {
                            possessor: *possessor,
                            possessed: *possessed,
                        },
                        Term::Sigma(p) => Term::Sigma(*p),
                        Term::Intension(p) => Term::Intension(*p),
                        Term::Proposition(e) => Term::Proposition(*e),
                        Term::Value { kind, unit, dimension } => Term::Value {
                            kind: *kind,
                            unit: *unit,
                            dimension: *dimension,
                        },
                    })
                    .collect();
                Ok(self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: *name,
                    args: self.ctx.terms.alloc_slice(new_args),
                }))
            }
            LogicExpr::Temporal { operator, body } => Ok(self.ctx.exprs.alloc(LogicExpr::Temporal {
                operator: *operator,
                body: self.substitute_constant_with_sigma(body, constant_name, sigma_term)?,
            })),
            LogicExpr::Aspectual { operator, body } => Ok(self.ctx.exprs.alloc(LogicExpr::Aspectual {
                operator: *operator,
                body: self.substitute_constant_with_sigma(body, constant_name, sigma_term)?,
            })),
            LogicExpr::UnaryOp { op, operand } => Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                op: op.clone(),
                operand: self.substitute_constant_with_sigma(operand, constant_name, sigma_term)?,
            })),
            LogicExpr::BinaryOp { left, op, right } => Ok(self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: self.substitute_constant_with_sigma(
                    left,
                    constant_name,
                    sigma_term.clone(),
                )?,
                op: op.clone(),
                right: self.substitute_constant_with_sigma(right, constant_name, sigma_term)?,
            })),
            LogicExpr::Event { predicate, adverbs } => Ok(self.ctx.exprs.alloc(LogicExpr::Event {
                predicate: self.substitute_constant_with_sigma(
                    predicate,
                    constant_name,
                    sigma_term,
                )?,
                adverbs: *adverbs,
            })),
            LogicExpr::TemporalAnchor { anchor, body } => {
                Ok(self.ctx.exprs.alloc(LogicExpr::TemporalAnchor {
                    anchor: *anchor,
                    body: self.substitute_constant_with_sigma(body, constant_name, sigma_term)?,
                }))
            }
            LogicExpr::NeoEvent(data) => {
                let new_roles: Vec<(crate::ast::ThematicRole, Term<'a>)> = data
                    .roles
                    .iter()
                    .map(|(role, term)| {
                        let new_term = match term {
                            Term::Constant(c) if *c == constant_name => sigma_term.clone(),
                            Term::Constant(c) => Term::Constant(*c),
                            Term::Variable(v) => Term::Variable(*v),
                            Term::Function(n, a) => Term::Function(*n, *a),
                            Term::Group(m) => Term::Group(*m),
                            Term::Possessed { possessor, possessed } => Term::Possessed {
                                possessor: *possessor,
                                possessed: *possessed,
                            },
                            Term::Sigma(p) => Term::Sigma(*p),
                            Term::Intension(p) => Term::Intension(*p),
                            Term::Proposition(e) => Term::Proposition(*e),
                            Term::Value { kind, unit, dimension } => Term::Value {
                                kind: *kind,
                                unit: *unit,
                                dimension: *dimension,
                            },
                        };
                        (*role, new_term)
                    })
                    .collect();
                Ok(self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(crate::ast::NeoEventData {
                    event_var: data.event_var,
                    verb: data.verb,
                    roles: self.ctx.roles.alloc_slice(new_roles),
                    modifiers: data.modifiers,
                    suppress_existential: data.suppress_existential,
                }))))
            }
            LogicExpr::Distributive { predicate } => Ok(self.ctx.exprs.alloc(LogicExpr::Distributive {
                predicate: self.substitute_constant_with_sigma(predicate, constant_name, sigma_term)?,
            })),
            _ => Ok(expr),
        }
    }

    fn find_main_verb_name(&self, expr: &LogicExpr<'a>) -> Option<Symbol> {
        match expr {
            LogicExpr::Predicate { name, .. } => Some(*name),
            LogicExpr::NeoEvent(data) => Some(data.verb),
            LogicExpr::Temporal { body, .. } => self.find_main_verb_name(body),
            LogicExpr::Aspectual { body, .. } => self.find_main_verb_name(body),
            LogicExpr::Event { predicate, .. } => self.find_main_verb_name(predicate),
            LogicExpr::TemporalAnchor { body, .. } => self.find_main_verb_name(body),
            LogicExpr::UnaryOp { operand, .. } => self.find_main_verb_name(operand),
            LogicExpr::BinaryOp { left, .. } => self.find_main_verb_name(left),
            _ => None,
        }
    }

    fn transform_cardinal_to_group(&mut self, expr: &'a LogicExpr<'a>) -> ParseResult<&'a LogicExpr<'a>> {
        match expr {
            LogicExpr::Quantifier { kind: QuantifierKind::Cardinal(n), variable, body, .. } => {
                let group_var = self.interner.intern("g");
                let member_var = *variable;

                // Extract the restriction (first conjunct) and the body (rest)
                // The structure is: restriction ∧ body_rest
                let (restriction, body_rest) = match body {
                    LogicExpr::BinaryOp { left, op: TokenType::And, right } => (*left, *right),
                    _ => return Ok(expr),
                };

                // Substitute the member variable with the group variable in the body
                let transformed_body = self.substitute_constant_with_var_sym(body_rest, member_var, group_var)?;

                Ok(self.ctx.exprs.alloc(LogicExpr::GroupQuantifier {
                    group_var,
                    count: *n,
                    member_var,
                    restriction,
                    body: transformed_body,
                }))
            }
            // Recursively transform nested expressions
            LogicExpr::Temporal { operator, body } => {
                let transformed = self.transform_cardinal_to_group(body)?;
                Ok(self.ctx.exprs.alloc(LogicExpr::Temporal {
                    operator: *operator,
                    body: transformed,
                }))
            }
            LogicExpr::Aspectual { operator, body } => {
                let transformed = self.transform_cardinal_to_group(body)?;
                Ok(self.ctx.exprs.alloc(LogicExpr::Aspectual {
                    operator: *operator,
                    body: transformed,
                }))
            }
            LogicExpr::UnaryOp { op, operand } => {
                let transformed = self.transform_cardinal_to_group(operand)?;
                Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                    op: op.clone(),
                    operand: transformed,
                }))
            }
            LogicExpr::BinaryOp { left, op, right } => {
                let transformed_left = self.transform_cardinal_to_group(left)?;
                let transformed_right = self.transform_cardinal_to_group(right)?;
                Ok(self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: transformed_left,
                    op: op.clone(),
                    right: transformed_right,
                }))
            }
            LogicExpr::Distributive { predicate } => {
                let transformed = self.transform_cardinal_to_group(predicate)?;
                Ok(self.ctx.exprs.alloc(LogicExpr::Distributive {
                    predicate: transformed,
                }))
            }
            LogicExpr::Quantifier { kind, variable, body, island_id } => {
                let transformed = self.transform_cardinal_to_group(body)?;
                Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: kind.clone(),
                    variable: *variable,
                    body: transformed,
                    island_id: *island_id,
                }))
            }
            _ => Ok(expr),
        }
    }
}

// Helper methods for donkey binding scope handling
impl<'a, 'ctx, 'int> Parser<'a, 'ctx, 'int> {
    /// Check if an expression mentions a specific variable
    fn expr_mentions_var(&self, expr: &LogicExpr<'a>, var: Symbol) -> bool {
        match expr {
            LogicExpr::Predicate { args, .. } => {
                args.iter().any(|term| self.term_mentions_var(term, var))
            }
            LogicExpr::BinaryOp { left, right, .. } => {
                self.expr_mentions_var(left, var) || self.expr_mentions_var(right, var)
            }
            LogicExpr::UnaryOp { operand, .. } => self.expr_mentions_var(operand, var),
            LogicExpr::Quantifier { body, .. } => self.expr_mentions_var(body, var),
            LogicExpr::NeoEvent(data) => {
                data.roles.iter().any(|(_, term)| self.term_mentions_var(term, var))
            }
            LogicExpr::Temporal { body, .. } => self.expr_mentions_var(body, var),
            LogicExpr::Aspectual { body, .. } => self.expr_mentions_var(body, var),
            LogicExpr::Event { predicate, .. } => self.expr_mentions_var(predicate, var),
            LogicExpr::Modal { operand, .. } => self.expr_mentions_var(operand, var),
            LogicExpr::Scopal { body, .. } => self.expr_mentions_var(body, var),
            _ => false,
        }
    }

    fn term_mentions_var(&self, term: &Term<'a>, var: Symbol) -> bool {
        match term {
            Term::Variable(v) => *v == var,
            Term::Function(_, args) => args.iter().any(|t| self.term_mentions_var(t, var)),
            _ => false,
        }
    }

    /// Collect all conjuncts from a conjunction tree
    fn collect_conjuncts(&self, expr: &'a LogicExpr<'a>) -> Vec<&'a LogicExpr<'a>> {
        match expr {
            LogicExpr::BinaryOp { left, op: TokenType::And, right } => {
                let mut result = self.collect_conjuncts(left);
                result.extend(self.collect_conjuncts(right));
                result
            }
            _ => vec![expr],
        }
    }

    /// Wrap unused donkey bindings inside the restriction/body of a quantifier structure.
    ///
    /// For universals (implications):
    ///   Transform: ∀x((P(x) ∧ Q(y)) → R(x)) with unused y
    ///   Into:      ∀x((P(x) ∧ ∃y(Q(y))) → R(x))
    ///
    /// For existentials (conjunctions):
    ///   Transform: ∃x(P(x) ∧ Q(y) ∧ R(x)) with unused y
    ///   Into:      ∃x(P(x) ∧ ∃y(Q(y)) ∧ R(x))
    ///
    /// If wide_scope_negation is true, wrap the existential in negation:
    ///   Into:      ∀x((P(x) ∧ ¬∃y(Q(y))) → R(x))
    fn wrap_donkey_in_restriction(
        &self,
        body: &'a LogicExpr<'a>,
        donkey_var: Symbol,
        wide_scope_negation: bool,
    ) -> &'a LogicExpr<'a> {
        // Handle Quantifier wrapping first
        if let LogicExpr::Quantifier { kind, variable, body: inner_body, island_id } = body {
            let transformed = self.wrap_donkey_in_restriction(inner_body, donkey_var, wide_scope_negation);
            return self.ctx.exprs.alloc(LogicExpr::Quantifier {
                kind: kind.clone(),
                variable: *variable,
                body: transformed,
                island_id: *island_id,
            });
        }

        // Handle implication (universal quantifiers)
        if let LogicExpr::BinaryOp { left, op: TokenType::If, right } = body {
            return self.wrap_in_implication(*left, *right, donkey_var, wide_scope_negation);
        }

        // Handle conjunction (existential quantifiers)
        if let LogicExpr::BinaryOp { left: _, op: TokenType::And, right: _ } = body {
            return self.wrap_in_conjunction(body, donkey_var, wide_scope_negation);
        }

        // Not a structure we can process
        body
    }

    /// Wrap donkey binding in an implication structure (∀x(P(x) → Q(x)))
    fn wrap_in_implication(
        &self,
        restriction: &'a LogicExpr<'a>,
        consequent: &'a LogicExpr<'a>,
        donkey_var: Symbol,
        wide_scope_negation: bool,
    ) -> &'a LogicExpr<'a> {
        // Collect all conjuncts in the restriction
        let conjuncts = self.collect_conjuncts(restriction);

        // Partition into those mentioning the donkey var and those not
        let (with_var, without_var): (Vec<_>, Vec<_>) = conjuncts
            .into_iter()
            .partition(|c| self.expr_mentions_var(c, donkey_var));

        if with_var.is_empty() {
            // Variable not found in restriction, return original implication
            return self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: restriction,
                op: TokenType::If,
                right: consequent,
            });
        }

        // Combine the "with var" conjuncts
        let with_var_combined = self.combine_conjuncts(&with_var);

        // Wrap with existential
        let existential = self.ctx.exprs.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Existential,
            variable: donkey_var,
            body: with_var_combined,
            island_id: self.current_island,
        });

        // For wide scope negation (de dicto reading of "lacks"), wrap ∃ in ¬
        let wrapped = if wide_scope_negation {
            self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                op: TokenType::Not,
                operand: existential,
            })
        } else {
            existential
        };

        // Combine with "without var" conjuncts
        let new_restriction = if without_var.is_empty() {
            wrapped
        } else {
            let without_combined = self.combine_conjuncts(&without_var);
            self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: without_combined,
                op: TokenType::And,
                right: wrapped,
            })
        };

        // Rebuild the implication
        self.ctx.exprs.alloc(LogicExpr::BinaryOp {
            left: new_restriction,
            op: TokenType::If,
            right: consequent,
        })
    }

    /// Wrap donkey binding in a conjunction structure (∃x(P(x) ∧ Q(x)))
    fn wrap_in_conjunction(
        &self,
        body: &'a LogicExpr<'a>,
        donkey_var: Symbol,
        wide_scope_negation: bool,
    ) -> &'a LogicExpr<'a> {
        // Collect all conjuncts
        let conjuncts = self.collect_conjuncts(body);

        // Partition into those mentioning the donkey var and those not
        let (with_var, without_var): (Vec<_>, Vec<_>) = conjuncts
            .into_iter()
            .partition(|c| self.expr_mentions_var(c, donkey_var));

        if with_var.is_empty() {
            // Variable not found, return unchanged
            return body;
        }

        // Combine the "with var" conjuncts
        let with_var_combined = self.combine_conjuncts(&with_var);

        // Wrap with existential
        let existential = self.ctx.exprs.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Existential,
            variable: donkey_var,
            body: with_var_combined,
            island_id: self.current_island,
        });

        // For wide scope negation (de dicto reading of "lacks"), wrap ∃ in ¬
        let wrapped = if wide_scope_negation {
            self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                op: TokenType::Not,
                operand: existential,
            })
        } else {
            existential
        };

        // Combine with "without var" conjuncts
        if without_var.is_empty() {
            wrapped
        } else {
            let without_combined = self.combine_conjuncts(&without_var);
            self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: without_combined,
                op: TokenType::And,
                right: wrapped,
            })
        }
    }

    fn combine_conjuncts(&self, conjuncts: &[&'a LogicExpr<'a>]) -> &'a LogicExpr<'a> {
        if conjuncts.is_empty() {
            panic!("Cannot combine empty conjuncts");
        }
        if conjuncts.len() == 1 {
            return conjuncts[0];
        }
        let mut result = conjuncts[0];
        for c in &conjuncts[1..] {
            result = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: result,
                op: TokenType::And,
                right: *c,
            });
        }
        result
    }
}

```

---

### VerbParsing Trait

**File:** `src/parser/verb.rs`

Extension trait for predicate parsing: subject-verb agreement, aspect chains (progressive/perfect/passive), control structures (want to, try to, seem to), plural subject coordination, thematic role assignment for Neo-Davidsonian events, ditransitive verbs (give/send/tell with Recipient role). **Embedded Clauses:** When filler_gap is set and a verb follows a noun phrase, wraps subordinate clause in Term::Proposition and passes as argument. Enables 'Who did John say Mary loves?' with structure Say(J, [Love(M, x)]). **Do-Support:** Handles do/does/did + (not)? + verb patterns for emphasis and negation. **Sluicing:** Detects wh-word at sentence boundary after embedding verbs (know, wonder); reconstructs event from last_event_template with wh-variable as Agent (who) or Theme (what); wraps in Expr::Question.

```rust
use super::clause::ClauseParsing;
use super::modal::ModalParsing;
use super::noun::NounParsing;
use super::pragmatics::PragmaticsParsing;
use super::{ParseResult, Parser};
use crate::ast::{
    AspectOperator, LogicExpr, NeoEventData, NounPhrase, QuantifierKind, TemporalOperator, Term,
    ThematicRole,
};
use crate::context::{Gender, Number};
use crate::error::{ParseError, ParseErrorKind};
use crate::intern::Symbol;
use crate::lexer::Lexer;
use crate::lexicon::{Aspect, Definiteness, Time};
use crate::token::{FocusKind, Span, TokenType};

use crate::ast::Stmt;

pub trait LogicVerbParsing<'a, 'ctx, 'int> {
    fn parse_predicate_with_subject(&mut self, subject_symbol: Symbol)
        -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_predicate_with_subject_as_var(&mut self, subject_symbol: Symbol)
        -> ParseResult<&'a LogicExpr<'a>>;
    /// Try to parse a plural subject construction like "John and Mary verb".
    /// Returns Ok(Some(expr)) if successful, Ok(None) if not a plural subject (backtrack),
    /// or Err if there's a semantic error (e.g., "respectively" with mismatched lengths).
    fn try_parse_plural_subject(&mut self, first_subject: &NounPhrase<'a>)
        -> Result<Option<&'a LogicExpr<'a>>, ParseError>;
    fn parse_control_structure(
        &mut self,
        subject: &NounPhrase<'a>,
        verb: Symbol,
        verb_time: Time,
    ) -> ParseResult<&'a LogicExpr<'a>>;
    fn is_control_verb(&self, verb: Symbol) -> bool;
    /// Build a group predicate for intransitive verbs with multiple subjects
    fn build_group_predicate(
        &mut self,
        subjects: &[Symbol],
        verb: Symbol,
        verb_time: Time,
    ) -> &'a LogicExpr<'a>;
    /// Build a transitive predicate with group subject and group object
    fn build_group_transitive(
        &mut self,
        subjects: &[Symbol],
        objects: &[Symbol],
        verb: Symbol,
        verb_time: Time,
    ) -> &'a LogicExpr<'a>;
}

pub trait ImperativeVerbParsing<'a, 'ctx, 'int> {
    fn parse_statement_with_subject(&mut self, subject_symbol: Symbol)
        -> ParseResult<Stmt<'a>>;
}

impl<'a, 'ctx, 'int> Parser<'a, 'ctx, 'int> {
    fn parse_predicate_impl(
        &mut self,
        subject_symbol: Symbol,
        as_variable: bool,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        let subject_term = if as_variable {
            Term::Variable(subject_symbol)
        } else {
            Term::Constant(subject_symbol)
        };

        // Weather verb + expletive "it" detection: "it rains" → ∃e(Rain(e))
        let subject_str = self.interner.resolve(subject_symbol).to_lowercase();
        if subject_str == "it" && self.check_verb() {
            if let TokenType::Verb { lemma, time, .. } = &self.peek().kind {
                let lemma_str = self.interner.resolve(*lemma);
                if Lexer::is_weather_verb(lemma_str) {
                    let verb = *lemma;
                    let verb_time = *time;
                    self.advance(); // consume the weather verb

                    let event_var = self.get_event_var();
                    let suppress_existential = self.drs.in_conditional_antecedent();
                    if suppress_existential {
                        let event_class = self.interner.intern("Event");
                        self.drs.introduce_referent(event_var, event_class, crate::context::Gender::Neuter);
                    }
                    let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                        event_var,
                        verb,
                        roles: self.ctx.roles.alloc_slice(vec![]), // No thematic roles
                        modifiers: self.ctx.syms.alloc_slice(vec![]),
                        suppress_existential,
                    })));

                    return Ok(match verb_time {
                        Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                            operator: TemporalOperator::Past,
                            body: neo_event,
                        }),
                        Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                            operator: TemporalOperator::Future,
                            body: neo_event,
                        }),
                        _ => neo_event,
                    });
                }
            }
        }

        // Weather adjective + expletive "it" detection: "it is wet" → Wet
        // Also handle "it's wet" where 's is Possessive token
        if subject_str == "it" && (self.check(&TokenType::Is) || self.check(&TokenType::Was) || self.check(&TokenType::Possessive)) {
            let saved_pos = self.current;
            self.advance(); // consume copula

            if self.check_content_word() {
                let adj_lexeme = self.peek().lexeme;
                let adj_str = self.interner.resolve(adj_lexeme).to_lowercase();

                if let Some(meta) = crate::lexicon::lookup_adjective_db(&adj_str) {
                    if meta.features.contains(&crate::lexicon::Feature::Weather) {
                        let adj_sym = self.consume_content_word().unwrap_or(adj_lexeme);
                        // Atmospheric predicate: "it is wet" → Wet
                        return Ok(self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: adj_sym,
                            args: self.ctx.terms.alloc_slice([]),
                        }));
                    }
                }
            }
            // Not a weather adjective, restore position
            self.current = saved_pos;
        }

        if self.check(&TokenType::Never) {
            self.advance();
            let verb = self.consume_verb();
            let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice([subject_term]),
            });
            return Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                op: TokenType::Not,
                operand: verb_pred,
            }));
        }

        if self.check_modal() {
            return self.parse_aspect_chain(subject_symbol);
        }

        if self.check_content_word() {
            let next_word = self.interner.resolve(self.peek().lexeme).to_lowercase();
            if next_word == "has" || next_word == "have" || next_word == "had" {
                // Look ahead to distinguish perfect aspect ("has eaten") from possession ("has 3 children")
                // Perfect aspect: has/have/had + verb
                // Possession: has/have/had + number/noun
                let is_perfect_aspect = if self.current + 1 < self.tokens.len() {
                    let next_token = &self.tokens[self.current + 1].kind;
                    matches!(
                        next_token,
                        TokenType::Verb { .. } | TokenType::Not
                    ) && !matches!(next_token, TokenType::Number(_))
                } else {
                    false
                };
                if is_perfect_aspect {
                    return self.parse_aspect_chain(subject_symbol);
                }
                // Otherwise, treat "has" as a main verb (possession) and continue below
            }
        }

        if self.check(&TokenType::Had) {
            return self.parse_aspect_chain(subject_symbol);
        }

        // Handle do-support: "I do/don't know who"
        if self.check(&TokenType::Does) || self.check(&TokenType::Do) {
            self.advance();
            let is_negated = self.match_token(&[TokenType::Not]);

            if self.check(&TokenType::Ever) {
                self.advance();
            }

            if self.check_verb() {
                let verb = self.consume_verb();

                // Check for embedded wh-clause with sluicing: "I don't know who"
                if self.check_wh_word() {
                    let wh_token = self.advance().kind.clone();
                    let is_who = matches!(wh_token, TokenType::Who);
                    let is_what = matches!(wh_token, TokenType::What);

                    let is_sluicing = self.is_at_end() ||
                        self.check(&TokenType::Period) ||
                        self.check(&TokenType::Comma);

                    if is_sluicing {
                        if let Some(template) = self.last_event_template.clone() {
                            let wh_var = self.next_var_name();

                            let roles: Vec<_> = if is_who {
                                std::iter::once((ThematicRole::Agent, Term::Variable(wh_var)))
                                    .chain(template.non_agent_roles.iter().cloned())
                                    .collect()
                            } else if is_what {
                                vec![
                                    (ThematicRole::Agent, subject_term.clone()),
                                    (ThematicRole::Theme, Term::Variable(wh_var)),
                                ]
                            } else {
                                std::iter::once((ThematicRole::Agent, Term::Variable(wh_var)))
                                    .chain(template.non_agent_roles.iter().cloned())
                                    .collect()
                            };

                            let event_var = self.get_event_var();
                            let suppress_existential = self.drs.in_conditional_antecedent();
                            let reconstructed = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                                event_var,
                                verb: template.verb,
                                roles: self.ctx.roles.alloc_slice(roles),
                                modifiers: self.ctx.syms.alloc_slice(template.modifiers.clone()),
                                suppress_existential,
                            })));

                            let question = self.ctx.exprs.alloc(LogicExpr::Question {
                                wh_variable: wh_var,
                                body: reconstructed,
                            });

                            let know_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                                event_var: self.get_event_var(),
                                verb,
                                roles: self.ctx.roles.alloc_slice(vec![
                                    (ThematicRole::Agent, subject_term.clone()),
                                    (ThematicRole::Theme, Term::Proposition(question)),
                                ]),
                                modifiers: self.ctx.syms.alloc_slice(vec![]),
                                suppress_existential,
                            })));

                            let result = if is_negated {
                                self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                                    op: TokenType::Not,
                                    operand: know_event,
                                })
                            } else {
                                know_event
                            };

                            return Ok(result);
                        }
                    }
                }

                // Regular do-support: "I do run" or "I don't run"
                let roles: Vec<(ThematicRole, Term<'a>)> = vec![(ThematicRole::Agent, subject_term.clone())];
                let modifiers: Vec<Symbol> = vec![];
                let event_var = self.get_event_var();
                let suppress_existential = self.drs.in_conditional_antecedent();

                let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                    event_var,
                    verb,
                    roles: self.ctx.roles.alloc_slice(roles),
                    modifiers: self.ctx.syms.alloc_slice(modifiers),
                    suppress_existential,
                })));

                if is_negated {
                    return Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                        op: TokenType::Not,
                        operand: neo_event,
                    }));
                }
                return Ok(neo_event);
            }
        }

        if self.check_auxiliary() {
            let aux_time = if let TokenType::Auxiliary(time) = self.advance().kind {
                time
            } else {
                Time::None
            };
            self.pending_time = Some(aux_time);

            if self.match_token(&[TokenType::Not]) {
                self.negative_depth += 1;

                if self.check_verb() {
                    let verb = self.consume_verb();

                    if self.check_quantifier() {
                        let quantifier_token = self.advance().kind.clone();
                        let object_np = self.parse_noun_phrase(false)?;
                        let obj_var = self.next_var_name();

                        let obj_restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: object_np.noun,
                            args: self.ctx.terms.alloc_slice([Term::Variable(obj_var)]),
                        });

                        let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: verb,
                            args: self
                                .ctx
                                .terms
                                .alloc_slice([subject_term, Term::Variable(obj_var)]),
                        });

                        let (kind, body) = match quantifier_token {
                            TokenType::Any => {
                                if self.is_negative_context() {
                                    (
                                        QuantifierKind::Existential,
                                        self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                            left: obj_restriction,
                                            op: TokenType::And,
                                            right: verb_pred,
                                        }),
                                    )
                                } else {
                                    (
                                        QuantifierKind::Universal,
                                        self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                            left: obj_restriction,
                                            op: TokenType::If,
                                            right: verb_pred,
                                        }),
                                    )
                                }
                            }
                            TokenType::Some => (
                                QuantifierKind::Existential,
                                self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                    left: obj_restriction,
                                    op: TokenType::And,
                                    right: verb_pred,
                                }),
                            ),
                            TokenType::All => (
                                QuantifierKind::Universal,
                                self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                    left: obj_restriction,
                                    op: TokenType::If,
                                    right: verb_pred,
                                }),
                            ),
                            _ => (
                                QuantifierKind::Existential,
                                self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                    left: obj_restriction,
                                    op: TokenType::And,
                                    right: verb_pred,
                                }),
                            ),
                        };

                        let quantified = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                            kind,
                            variable: obj_var,
                            body,
                            island_id: self.current_island,
                        });

                        let effective_time = self.pending_time.take().unwrap_or(Time::None);
                        let with_time = match effective_time {
                            Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                                operator: TemporalOperator::Past,
                                body: quantified,
                            }),
                            Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                                operator: TemporalOperator::Future,
                                body: quantified,
                            }),
                            _ => quantified,
                        };

                        self.negative_depth -= 1;
                        return Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                            op: TokenType::Not,
                            operand: with_time,
                        }));
                    }

                    if self.check_npi_object() {
                        let npi_token = self.advance().kind.clone();
                        let obj_var = self.next_var_name();

                        let restriction_name = match npi_token {
                            TokenType::Anything => "Thing",
                            TokenType::Anyone => "Person",
                            _ => "Thing",
                        };

                        let restriction_sym = self.interner.intern(restriction_name);
                        let obj_restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: restriction_sym,
                            args: self.ctx.terms.alloc_slice([Term::Variable(obj_var)]),
                        });

                        let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: verb,
                            args: self.ctx.terms.alloc_slice([subject_term, Term::Variable(obj_var)]),
                        });

                        let body = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: obj_restriction,
                            op: TokenType::And,
                            right: verb_pred,
                        });

                        let quantified = self.ctx.exprs.alloc(LogicExpr::Quantifier {
                            kind: QuantifierKind::Existential,
                            variable: obj_var,
                            body,
                            island_id: self.current_island,
                        });

                        let effective_time = self.pending_time.take().unwrap_or(Time::None);
                        let with_time = match effective_time {
                            Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                                operator: TemporalOperator::Past,
                                body: quantified,
                            }),
                            Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                                operator: TemporalOperator::Future,
                                body: quantified,
                            }),
                            _ => quantified,
                        };

                        self.negative_depth -= 1;
                        return Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                            op: TokenType::Not,
                            operand: with_time,
                        }));
                    }

                    let mut roles: Vec<(ThematicRole, Term<'a>)> =
                        vec![(ThematicRole::Agent, subject_term)];

                    if self.check_content_word() || self.check_article() {
                        let object = self.parse_noun_phrase(false)?;
                        let object_term = self.noun_phrase_to_term(&object);
                        roles.push((ThematicRole::Theme, object_term));
                    }

                    let event_var = self.get_event_var();
                    let suppress_existential = self.drs.in_conditional_antecedent();
                    let effective_time = self.pending_time.take().unwrap_or(Time::None);
                    let mut modifiers = Vec::new();
                    match effective_time {
                        Time::Past => modifiers.push(self.interner.intern("Past")),
                        Time::Future => modifiers.push(self.interner.intern("Future")),
                        _ => {}
                    }

                    let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                        event_var,
                        verb,
                        roles: self.ctx.roles.alloc_slice(roles),
                        modifiers: self.ctx.syms.alloc_slice(modifiers),
                        suppress_existential,
                    })));

                    self.negative_depth -= 1;
                    return Ok(self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                        op: TokenType::Not,
                        operand: neo_event,
                    }));
                }

                self.negative_depth -= 1;
            }
        }

        if self.check(&TokenType::Is)
            || self.check(&TokenType::Are)
            || self.check(&TokenType::Was)
            || self.check(&TokenType::Were)
        {
            let copula_time = if self.check(&TokenType::Was) || self.check(&TokenType::Were) {
                Time::Past
            } else {
                Time::Present
            };
            self.advance();

            if self.check_verb() {
                let (verb, _verb_time, verb_aspect, verb_class) = self.consume_verb_with_metadata();

                // Stative verbs cannot be progressive
                if verb_class.is_stative() && verb_aspect == Aspect::Progressive {
                    return Err(crate::error::ParseError {
                        kind: crate::error::ParseErrorKind::StativeProgressiveConflict,
                        span: self.current_span(),
                    });
                }

                let predicate = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb,
                    args: self.ctx.terms.alloc_slice([subject_term]),
                });

                let with_aspect = if verb_aspect == Aspect::Progressive {
                    // Semelfactive + Progressive → Iterative
                    let operator = if verb_class == crate::lexicon::VerbClass::Semelfactive {
                        AspectOperator::Iterative
                    } else {
                        AspectOperator::Progressive
                    };
                    self.ctx.exprs.alloc(LogicExpr::Aspectual {
                        operator,
                        body: predicate,
                    })
                } else {
                    predicate
                };

                return Ok(if copula_time == Time::Past {
                    self.ctx.exprs.alloc(LogicExpr::Temporal {
                        operator: TemporalOperator::Past,
                        body: with_aspect,
                    })
                } else {
                    with_aspect
                });
            }

            let predicate = self.consume_content_word()?;
            return Ok(self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: predicate,
                args: self.ctx.terms.alloc_slice([subject_term]),
            }));
        }

        if self.check_verb() {
            let (mut verb, verb_time, verb_aspect, verb_class) = self.consume_verb_with_metadata();
            let mut args = vec![subject_term.clone()];

            // Check for embedded wh-clause: "I know who/what"
            if self.check_wh_word() {
                let wh_token = self.advance().kind.clone();

                let is_who = matches!(wh_token, TokenType::Who);
                let is_what = matches!(wh_token, TokenType::What);

                // Check for sluicing: wh-word followed by terminator
                let is_sluicing = self.is_at_end() ||
                    self.check(&TokenType::Period) ||
                    self.check(&TokenType::Comma);

                if is_sluicing {
                    if let Some(template) = self.last_event_template.clone() {
                        let wh_var = self.next_var_name();

                        let roles: Vec<_> = if is_who {
                            std::iter::once((ThematicRole::Agent, Term::Variable(wh_var)))
                                .chain(template.non_agent_roles.iter().cloned())
                                .collect()
                        } else if is_what {
                            vec![
                                (ThematicRole::Agent, subject_term.clone()),
                                (ThematicRole::Theme, Term::Variable(wh_var)),
                            ]
                        } else {
                            std::iter::once((ThematicRole::Agent, Term::Variable(wh_var)))
                                .chain(template.non_agent_roles.iter().cloned())
                                .collect()
                        };

                        let event_var = self.get_event_var();
                        let suppress_existential = self.drs.in_conditional_antecedent();
                        let reconstructed = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                            event_var,
                            verb: template.verb,
                            roles: self.ctx.roles.alloc_slice(roles),
                            modifiers: self.ctx.syms.alloc_slice(template.modifiers.clone()),
                            suppress_existential,
                        })));

                        let question = self.ctx.exprs.alloc(LogicExpr::Question {
                            wh_variable: wh_var,
                            body: reconstructed,
                        });

                        let know_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                            event_var: self.get_event_var(),
                            verb,
                            roles: self.ctx.roles.alloc_slice(vec![
                                (ThematicRole::Agent, subject_term),
                                (ThematicRole::Theme, Term::Proposition(question)),
                            ]),
                            modifiers: self.ctx.syms.alloc_slice(vec![]),
                            suppress_existential,
                        })));

                        return Ok(know_event);
                    }
                }

                // Non-sluicing: "I know who runs"
                let embedded = self.parse_embedded_wh_clause()?;
                let question = self.ctx.exprs.alloc(LogicExpr::Question {
                    wh_variable: self.interner.intern("x"),
                    body: embedded,
                });

                let suppress_existential = self.drs.in_conditional_antecedent();
                let know_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                    event_var: self.get_event_var(),
                    verb,
                    roles: self.ctx.roles.alloc_slice(vec![
                        (ThematicRole::Agent, subject_term),
                        (ThematicRole::Theme, Term::Proposition(question)),
                    ]),
                    modifiers: self.ctx.syms.alloc_slice(vec![]),
                    suppress_existential,
                })));

                return Ok(know_event);
            }

            let mut object_term: Option<Term<'a>> = None;
            let mut second_object_term: Option<Term<'a>> = None;
            if self.check(&TokenType::Reflexive) {
                self.advance();
                let term = Term::Constant(subject_symbol);
                object_term = Some(term);
                args.push(term);
            } else if self.check_pronoun() {
                let token = self.advance().clone();
                let (gender, number) = match &token.kind {
                    TokenType::Pronoun { gender, number, .. } => (*gender, *number),
                    TokenType::Ambiguous { primary, alternatives } => {
                        if let TokenType::Pronoun { gender, number, .. } = **primary {
                            (gender, number)
                        } else {
                            alternatives.iter().find_map(|t| {
                                if let TokenType::Pronoun { gender, number, .. } = t {
                                    Some((*gender, *number))
                                } else {
                                    None
                                }
                            }).unwrap_or((Gender::Unknown, Number::Singular))
                        }
                    }
                    _ => (Gender::Unknown, Number::Singular),
                };

                let resolved = self
                    .resolve_pronoun(gender, number)
                    .unwrap_or_else(|| self.interner.intern("?"));
                let term = Term::Constant(resolved);
                object_term = Some(term);
                args.push(term);

                let verb_str = self.interner.resolve(verb);
                if Lexer::is_ditransitive_verb(verb_str)
                    && (self.check_content_word() || self.check_article())
                {
                    let second_np = self.parse_noun_phrase(false)?;
                    let second_term = Term::Constant(second_np.noun);
                    second_object_term = Some(second_term);
                    args.push(second_term);
                }
            } else if self.check_quantifier() || self.check_article() {
                let obj_quantifier = if self.check_quantifier() {
                    Some(self.advance().kind.clone())
                } else {
                    let art = self.advance().kind.clone();
                    if let TokenType::Article(def) = art {
                        if def == Definiteness::Indefinite {
                            Some(TokenType::Some)
                        } else {
                            None
                        }
                    } else {
                        None
                    }
                };

                let object_np = self.parse_noun_phrase(false)?;

                if let Some(obj_q) = obj_quantifier {
                    let obj_var = self.next_var_name();
                    let obj_restriction = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: object_np.noun,
                        args: self.ctx.terms.alloc_slice([Term::Variable(obj_var)]),
                    });

                    let event_var = self.get_event_var();
                    let mut modifiers = self.collect_adverbs();
                    let effective_time = self.pending_time.take().unwrap_or(verb_time);
                    match effective_time {
                        Time::Past => modifiers.push(self.interner.intern("Past")),
                        Time::Future => modifiers.push(self.interner.intern("Future")),
                        _ => {}
                    }

                    let roles = vec![
                        (ThematicRole::Agent, subject_term),
                        (ThematicRole::Theme, Term::Variable(obj_var)),
                    ];

                    let suppress_existential = self.drs.in_conditional_antecedent();
                    let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                        event_var,
                        verb,
                        roles: self.ctx.roles.alloc_slice(roles),
                        modifiers: self.ctx.syms.alloc_slice(modifiers),
                        suppress_existential,
                    })));

                    let obj_kind = match obj_q {
                        TokenType::All => QuantifierKind::Universal,
                        TokenType::Some => QuantifierKind::Existential,
                        TokenType::No => QuantifierKind::Universal,
                        TokenType::Most => QuantifierKind::Most,
                        TokenType::Few => QuantifierKind::Few,
                        TokenType::Many => QuantifierKind::Many,
                        TokenType::Cardinal(n) => QuantifierKind::Cardinal(n),
                        TokenType::AtLeast(n) => QuantifierKind::AtLeast(n),
                        TokenType::AtMost(n) => QuantifierKind::AtMost(n),
                        _ => QuantifierKind::Existential,
                    };

                    let obj_body = match obj_q {
                        TokenType::All => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: obj_restriction,
                            op: TokenType::If,
                            right: neo_event,
                        }),
                        TokenType::No => {
                            let neg = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                                op: TokenType::Not,
                                operand: neo_event,
                            });
                            self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                                left: obj_restriction,
                                op: TokenType::If,
                                right: neg,
                            })
                        }
                        _ => self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                            left: obj_restriction,
                            op: TokenType::And,
                            right: neo_event,
                        }),
                    };

                    return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                        kind: obj_kind,
                        variable: obj_var,
                        body: obj_body,
                        island_id: self.current_island,
                    }));
                } else {
                    let term = Term::Constant(object_np.noun);
                    object_term = Some(term);
                    args.push(term);
                }
            } else if self.check_focus() {
                let focus_kind = if let TokenType::Focus(k) = self.advance().kind {
                    k
                } else {
                    FocusKind::Only
                };

                let event_var = self.get_event_var();
                let mut modifiers = self.collect_adverbs();
                let effective_time = self.pending_time.take().unwrap_or(verb_time);
                match effective_time {
                    Time::Past => modifiers.push(self.interner.intern("Past")),
                    Time::Future => modifiers.push(self.interner.intern("Future")),
                    _ => {}
                }

                if self.check_preposition() {
                    let prep_token = self.advance().clone();
                    let prep_name = if let TokenType::Preposition(sym) = prep_token.kind {
                        sym
                    } else {
                        self.interner.intern("to")
                    };
                    let pp_obj = self.parse_noun_phrase(false)?;
                    let pp_obj_term = Term::Constant(pp_obj.noun);

                    let roles = vec![(ThematicRole::Agent, subject_term)];
                    let suppress_existential = self.drs.in_conditional_antecedent();
                    let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                        event_var,
                        verb,
                        roles: self.ctx.roles.alloc_slice(roles),
                        modifiers: self.ctx.syms.alloc_slice(modifiers),
                        suppress_existential,
                    })));

                    let pp_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: prep_name,
                        args: self.ctx.terms.alloc_slice([Term::Variable(event_var), pp_obj_term]),
                    });

                    let with_pp = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: neo_event,
                        op: TokenType::And,
                        right: pp_pred,
                    });

                    let focused_ref = self.ctx.terms.alloc(pp_obj_term);
                    return Ok(self.ctx.exprs.alloc(LogicExpr::Focus {
                        kind: focus_kind,
                        focused: focused_ref,
                        scope: with_pp,
                    }));
                }

                let focused_np = self.parse_noun_phrase(false)?;
                let focused_term = Term::Constant(focused_np.noun);
                args.push(focused_term);

                let roles = vec![
                    (ThematicRole::Agent, subject_term),
                    (ThematicRole::Theme, focused_term),
                ];

                let suppress_existential = self.drs.in_conditional_antecedent();
                let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                    event_var,
                    verb,
                    roles: self.ctx.roles.alloc_slice(roles),
                    modifiers: self.ctx.syms.alloc_slice(modifiers),
                    suppress_existential,
                })));

                let focused_ref = self.ctx.terms.alloc(focused_term);
                return Ok(self.ctx.exprs.alloc(LogicExpr::Focus {
                    kind: focus_kind,
                    focused: focused_ref,
                    scope: neo_event,
                }));
            } else if self.check_number() {
                let measure = self.parse_measure_phrase()?;
                if self.check_content_word() {
                    let noun_sym = self.consume_content_word()?;
                    args.push(*measure);
                    args.push(Term::Constant(noun_sym));
                } else {
                    args.push(*measure);
                }
            } else if self.check_content_word() {
                let potential_object = self.parse_noun_phrase(false)?;

                if self.check_verb() && self.filler_gap.is_some() {
                    let embedded_subject = potential_object.noun;
                    let embedded_pred = self.parse_predicate_with_subject(embedded_subject)?;

                    let embedded_term = Term::Proposition(embedded_pred);
                    let main_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: verb,
                        args: self.ctx.terms.alloc_slice([subject_term, embedded_term]),
                    });

                    let effective_time = self.pending_time.take().unwrap_or(verb_time);
                    return Ok(if effective_time == Time::Past {
                        self.ctx.exprs.alloc(LogicExpr::Temporal {
                            operator: TemporalOperator::Past,
                            body: main_pred,
                        })
                    } else {
                        main_pred
                    });
                }

                // Collect all objects for potential "respectively" handling
                let mut all_objects: Vec<Symbol> = vec![potential_object.noun];

                // Check for coordinated objects: "Tom and Jerry and Bob"
                while self.check(&TokenType::And) {
                    let saved = self.current;
                    self.advance(); // consume "and"
                    if self.check_content_word() || self.check_article() {
                        let next_obj = match self.parse_noun_phrase(false) {
                            Ok(np) => np,
                            Err(_) => {
                                self.current = saved;
                                break;
                            }
                        };
                        all_objects.push(next_obj.noun);
                    } else {
                        self.current = saved;
                        break;
                    }
                }

                // Check for "respectively" with single subject
                if self.check(&TokenType::Respectively) {
                    let respectively_span = self.peek().span;
                    // Single subject with multiple objects + respectively = error
                    if all_objects.len() > 1 {
                        return Err(ParseError {
                            kind: ParseErrorKind::RespectivelyLengthMismatch {
                                subject_count: 1,
                                object_count: all_objects.len(),
                            },
                            span: respectively_span,
                        });
                    }
                    // Single subject, single object + respectively is valid (trivially pairwise)
                    self.advance(); // consume "respectively"
                }

                // Use the first object (or only object) for normal processing
                let term = Term::Constant(all_objects[0]);
                object_term = Some(term);
                args.push(term);

                // For multiple objects without "respectively", use group semantics
                if all_objects.len() > 1 {
                    let obj_members: Vec<Term<'a>> = all_objects.iter()
                        .map(|o| Term::Constant(*o))
                        .collect();
                    let obj_group = Term::Group(self.ctx.terms.alloc_slice(obj_members));
                    // Replace the single object with the group
                    args.pop();
                    args.push(obj_group);
                }

                let verb_str = self.interner.resolve(verb);
                if Lexer::is_ditransitive_verb(verb_str)
                    && (self.check_content_word() || self.check_article())
                {
                    let second_np = self.parse_noun_phrase(false)?;
                    let second_term = Term::Constant(second_np.noun);
                    second_object_term = Some(second_term);
                    args.push(second_term);
                }
            } else if self.filler_gap.is_some() && !self.check_content_word() && !self.check_pronoun()
            {
                let gap_var = self.filler_gap.take().unwrap();
                let term = Term::Variable(gap_var);
                object_term = Some(term);
                args.push(term);
            }

            // Check for distanced phrasal verb particle: "gave the book up"
            if let TokenType::Particle(particle_sym) = self.peek().kind {
                let verb_str = self.interner.resolve(verb).to_lowercase();
                let particle_str = self.interner.resolve(particle_sym).to_lowercase();
                if let Some((phrasal_lemma, _class)) = crate::lexicon::lookup_phrasal_verb(&verb_str, &particle_str) {
                    self.advance(); // consume the particle
                    verb = self.interner.intern(phrasal_lemma);
                }
            }

            let unknown = self.interner.intern("?");
            let mut pp_predicates: Vec<&'a LogicExpr<'a>> = Vec::new();
            while self.check_preposition() || self.check_to() {
                let prep_token = self.advance().clone();
                let prep_name = if let TokenType::Preposition(sym) = prep_token.kind {
                    sym
                } else if matches!(prep_token.kind, TokenType::To) {
                    self.interner.intern("To")
                } else {
                    continue;
                };

                let pp_obj_term = if self.check(&TokenType::Reflexive) {
                    self.advance();
                    Term::Constant(subject_symbol)
                } else if self.check_pronoun() {
                    let token = self.advance().clone();
                    let (gender, number) = match &token.kind {
                        TokenType::Pronoun { gender, number, .. } => (*gender, *number),
                        TokenType::Ambiguous { primary, alternatives } => {
                            if let TokenType::Pronoun { gender, number, .. } = **primary {
                                (gender, number)
                            } else {
                                alternatives.iter().find_map(|t| {
                                    if let TokenType::Pronoun { gender, number, .. } = t {
                                        Some((*gender, *number))
                                    } else {
                                        None
                                    }
                                }).unwrap_or((Gender::Unknown, Number::Singular))
                            }
                        }
                        _ => (Gender::Unknown, Number::Singular),
                    };
                    let resolved = self.resolve_pronoun(gender, number).unwrap_or(unknown);
                    Term::Constant(resolved)
                } else if self.check_content_word() || self.check_article() {
                    let prep_obj = self.parse_noun_phrase(false)?;
                    Term::Constant(prep_obj.noun)
                } else {
                    continue;
                };

                if self.pp_attach_to_noun {
                    if let Some(obj) = object_term {
                        let pp_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                            name: prep_name,
                            args: self.ctx.terms.alloc_slice([obj, pp_obj_term]),
                        });
                        pp_predicates.push(pp_pred);
                    } else {
                        args.push(pp_obj_term);
                    }
                } else {
                    let event_sym = self.get_event_var();
                    let pp_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: prep_name,
                        args: self
                            .ctx
                            .terms
                            .alloc_slice([Term::Variable(event_sym), pp_obj_term]),
                    });
                    pp_predicates.push(pp_pred);
                }
            }

            if self.check(&TokenType::That) || self.check(&TokenType::Who) {
                self.advance();
                let rel_var = self.next_var_name();
                let rel_pred = self.parse_relative_clause(rel_var)?;
                pp_predicates.push(rel_pred);
            }

            let mut modifiers = self.collect_adverbs();

            let effective_time = self.pending_time.take().unwrap_or(verb_time);
            match effective_time {
                Time::Past => modifiers.push(self.interner.intern("Past")),
                Time::Future => modifiers.push(self.interner.intern("Future")),
                _ => {}
            }

            if verb_aspect == Aspect::Progressive {
                modifiers.push(self.interner.intern("Progressive"));
            } else if verb_aspect == Aspect::Perfect {
                modifiers.push(self.interner.intern("Perfect"));
            }

            let mut roles: Vec<(ThematicRole, Term<'a>)> = Vec::new();

            // Check if verb is unaccusative (intransitive subject is Theme, not Agent)
            let verb_str = self.interner.resolve(verb).to_lowercase();
            let is_unaccusative = crate::lexicon::lookup_verb_db(&verb_str)
                .map(|meta| meta.features.contains(&crate::lexicon::Feature::Unaccusative))
                .unwrap_or(false);

            // Unaccusative verbs used intransitively: subject is Theme
            // E.g., "The alarm triggers" → Theme(e, Alarm), not Agent(e, Alarm)
            let has_object = object_term.is_some() || second_object_term.is_some();
            let subject_role = if is_unaccusative && !has_object {
                ThematicRole::Theme
            } else {
                ThematicRole::Agent
            };

            roles.push((subject_role, subject_term));
            if let Some(second_obj) = second_object_term {
                if let Some(first_obj) = object_term {
                    roles.push((ThematicRole::Recipient, first_obj));
                }
                roles.push((ThematicRole::Theme, second_obj));
            } else if let Some(obj) = object_term {
                roles.push((ThematicRole::Theme, obj));
            }

            let event_var = self.get_event_var();
            let suppress_existential = self.drs.in_conditional_antecedent();
            if suppress_existential {
                let event_class = self.interner.intern("Event");
                self.drs.introduce_referent(event_var, event_class, crate::context::Gender::Neuter);
            }
            let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                event_var,
                verb,
                roles: self.ctx.roles.alloc_slice(roles.clone()),
                modifiers: self.ctx.syms.alloc_slice(modifiers.clone()),
                suppress_existential,
            })));

            // Capture template for ellipsis reconstruction
            self.capture_event_template(verb, &roles, &modifiers);

            let with_pps = if pp_predicates.is_empty() {
                neo_event
            } else {
                let mut combined = neo_event;
                for pp in pp_predicates {
                    combined = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: combined,
                        op: TokenType::And,
                        right: pp,
                    });
                }
                combined
            };

            // Apply aspectual operators based on verb class
            let with_aspect = if verb_aspect == Aspect::Simple && effective_time == Time::Present {
                // Non-state verbs in simple present get Habitual reading
                if !verb_class.is_stative() {
                    self.ctx.exprs.alloc(LogicExpr::Aspectual {
                        operator: AspectOperator::Habitual,
                        body: with_pps,
                    })
                } else {
                    with_pps
                }
            } else if verb_aspect == Aspect::Progressive {
                // Semelfactive + Progressive → Iterative
                if verb_class == crate::lexicon::VerbClass::Semelfactive {
                    self.ctx.exprs.alloc(LogicExpr::Aspectual {
                        operator: AspectOperator::Iterative,
                        body: with_pps,
                    })
                } else {
                    with_pps
                }
            } else {
                with_pps
            };

            Ok(with_aspect)
        } else {
            Ok(self.ctx.exprs.alloc(LogicExpr::Atom(subject_symbol)))
        }
    }
}

impl<'a, 'ctx, 'int> LogicVerbParsing<'a, 'ctx, 'int> for Parser<'a, 'ctx, 'int> {
    fn parse_predicate_with_subject(&mut self, subject_symbol: Symbol) -> ParseResult<&'a LogicExpr<'a>> {
        self.parse_predicate_impl(subject_symbol, false)
    }

    fn parse_predicate_with_subject_as_var(&mut self, subject_symbol: Symbol) -> ParseResult<&'a LogicExpr<'a>> {
        self.parse_predicate_impl(subject_symbol, true)
    }

    fn try_parse_plural_subject(
        &mut self,
        first_subject: &NounPhrase<'a>,
    ) -> Result<Option<&'a LogicExpr<'a>>, ParseError> {
        let saved_pos = self.current;

        // Consume the 'and' we already peeked
        self.advance();

        if !self.check_content_word() {
            self.current = saved_pos;
            return Ok(None);
        }

        // Collect all subjects: "John and Mary and Sue"
        let mut subjects: Vec<Symbol> = vec![first_subject.noun];

        loop {
            if !self.check_content_word() {
                break;
            }
            let next_subject = match self.parse_noun_phrase(true) {
                Ok(np) => np,
                Err(_) => {
                    self.current = saved_pos;
                    return Ok(None);
                }
            };
            subjects.push(next_subject.noun);

            if self.check(&TokenType::And) {
                self.advance();
            } else {
                break;
            }
        }

        // Check for copula (is/are/was/were) with predicate nominative
        // "Both Socrates and Plato are men" -> M(s) ∧ M(p)
        if self.check(&TokenType::Is) || self.check(&TokenType::Are)
            || self.check(&TokenType::Was) || self.check(&TokenType::Were)
        {
            let copula_time = if self.check(&TokenType::Was) || self.check(&TokenType::Were) {
                Time::Past
            } else {
                Time::Present
            };
            self.advance(); // consume the copula

            // Parse the predicate nominative (e.g., "men" in "are men")
            if !self.check_content_word() && !self.check_article() {
                self.current = saved_pos;
                return Ok(None);
            }

            let predicate_np = match self.parse_noun_phrase(false) {
                Ok(np) => np,
                Err(_) => {
                    self.current = saved_pos;
                    return Ok(None);
                }
            };
            let predicate = predicate_np.noun;

            // Build distributed predicate: P(s1) ∧ P(s2) ∧ ...
            let mut conjuncts: Vec<&'a LogicExpr<'a>> = Vec::new();
            for subj in &subjects {
                let pred_expr = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: predicate,
                    args: self.ctx.terms.alloc_slice([Term::Constant(*subj)]),
                });
                conjuncts.push(pred_expr);
            }

            // Fold conjuncts into binary conjunction tree
            let mut result = conjuncts[0];
            for conjunct in &conjuncts[1..] {
                result = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: result,
                    op: TokenType::And,
                    right: *conjunct,
                });
            }

            // Apply temporal modifier for past tense
            let with_time = match copula_time {
                Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                    operator: TemporalOperator::Past,
                    body: result,
                }),
                _ => result,
            };

            return Ok(Some(with_time));
        }

        if !self.check_verb() {
            self.current = saved_pos;
            return Ok(None);
        }

        // Register the coordinated subjects as a plural entity for pronoun resolution
        {
            use crate::context::{Gender, Number};
            let group_name = subjects.iter()
                .map(|s| self.interner.resolve(*s))
                .collect::<Vec<_>>()
                .join("⊕");
            self.register_entity(&group_name, "group", Gender::Unknown, Number::Plural);
        }

        let (verb, verb_time, _verb_aspect, _) = self.consume_verb_with_metadata();

        // Check for reciprocal: "John and Mary kicked each other"
        if self.check(&TokenType::Reciprocal) {
            self.advance();
            if subjects.len() != 2 {
                self.current = saved_pos;
                return Ok(None);
            }
            let pred1 = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice([
                    Term::Constant(subjects[0]),
                    Term::Constant(subjects[1]),
                ]),
            });
            let pred2 = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice([
                    Term::Constant(subjects[1]),
                    Term::Constant(subjects[0]),
                ]),
            });
            let expr = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: pred1,
                op: TokenType::And,
                right: pred2,
            });

            let with_time = match verb_time {
                Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                    operator: TemporalOperator::Past,
                    body: expr,
                }),
                Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                    operator: TemporalOperator::Future,
                    body: expr,
                }),
                _ => expr,
            };
            return Ok(Some(with_time));
        }

        // Check for objects (for transitive verbs with "respectively")
        let mut objects: Vec<Symbol> = Vec::new();
        if self.check_content_word() || self.check_article() {
            // Parse first object
            let first_obj = match self.parse_noun_phrase(false) {
                Ok(np) => np,
                Err(_) => {
                    // No objects, continue with intransitive
                    return Ok(Some(self.build_group_predicate(&subjects, verb, verb_time)));
                }
            };
            objects.push(first_obj.noun);

            // Parse additional objects: "Tom and Jerry and Bob"
            while self.check(&TokenType::And) {
                self.advance();
                if self.check_content_word() || self.check_article() {
                    let next_obj = match self.parse_noun_phrase(false) {
                        Ok(np) => np,
                        Err(_) => break,
                    };
                    objects.push(next_obj.noun);
                } else {
                    break;
                }
            }
        }

        // Check for "respectively" - triggers pairwise interpretation
        if self.check(&TokenType::Respectively) {
            let respectively_span = self.peek().span;
            self.advance(); // consume "respectively"

            if subjects.len() != objects.len() {
                return Err(ParseError {
                    kind: ParseErrorKind::RespectivelyLengthMismatch {
                        subject_count: subjects.len(),
                        object_count: objects.len(),
                    },
                    span: respectively_span,
                });
            }

            // Build pairwise predicates: See(J,T) ∧ See(M,J) ∧ ...
            let mut conjuncts: Vec<&'a LogicExpr<'a>> = Vec::new();
            let suppress_existential = self.drs.in_conditional_antecedent();
            for (subj, obj) in subjects.iter().zip(objects.iter()) {
                let event_var = self.get_event_var();
                let roles = vec![
                    (ThematicRole::Agent, Term::Constant(*subj)),
                    (ThematicRole::Theme, Term::Constant(*obj)),
                ];
                let neo_event = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
                    event_var,
                    verb,
                    roles: self.ctx.roles.alloc_slice(roles),
                    modifiers: self.ctx.syms.alloc_slice(vec![]),
                    suppress_existential,
                })));
                conjuncts.push(neo_event);
            }

            // Fold conjuncts into binary conjunction tree
            let mut result = conjuncts[0];
            for conjunct in &conjuncts[1..] {
                result = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: result,
                    op: TokenType::And,
                    right: *conjunct,
                });
            }

            // Apply temporal modifier
            let with_time = match verb_time {
                Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                    operator: TemporalOperator::Past,
                    body: result,
                }),
                Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                    operator: TemporalOperator::Future,
                    body: result,
                }),
                _ => result,
            };

            return Ok(Some(with_time));
        }

        // No "respectively" - use group semantics
        if objects.is_empty() {
            // Intransitive: group subject
            Ok(Some(self.build_group_predicate(&subjects, verb, verb_time)))
        } else {
            // Transitive without "respectively": group subject, group object
            Ok(Some(self.build_group_transitive(&subjects, &objects, verb, verb_time)))
        }
    }

    /// Build a group predicate for intransitive verbs
    fn build_group_predicate(
        &mut self,
        subjects: &[Symbol],
        verb: Symbol,
        verb_time: Time,
    ) -> &'a LogicExpr<'a> {
        let group_members: Vec<Term<'a>> = subjects.iter()
            .map(|s| Term::Constant(*s))
            .collect();
        let group_members_slice = self.ctx.terms.alloc_slice(group_members);

        let expr = self.ctx.exprs.alloc(LogicExpr::Predicate {
            name: verb,
            args: self.ctx.terms.alloc_slice([Term::Group(group_members_slice)]),
        });

        match verb_time {
            Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                operator: TemporalOperator::Past,
                body: expr,
            }),
            Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                operator: TemporalOperator::Future,
                body: expr,
            }),
            _ => expr,
        }
    }

    /// Build a transitive predicate with group subject and group object
    fn build_group_transitive(
        &mut self,
        subjects: &[Symbol],
        objects: &[Symbol],
        verb: Symbol,
        verb_time: Time,
    ) -> &'a LogicExpr<'a> {
        let subj_members: Vec<Term<'a>> = subjects.iter()
            .map(|s| Term::Constant(*s))
            .collect();
        let obj_members: Vec<Term<'a>> = objects.iter()
            .map(|o| Term::Constant(*o))
            .collect();

        let subj_group = Term::Group(self.ctx.terms.alloc_slice(subj_members));
        let obj_group = Term::Group(self.ctx.terms.alloc_slice(obj_members));

        let expr = self.ctx.exprs.alloc(LogicExpr::Predicate {
            name: verb,
            args: self.ctx.terms.alloc_slice([subj_group, obj_group]),
        });

        match verb_time {
            Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                operator: TemporalOperator::Past,
                body: expr,
            }),
            Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                operator: TemporalOperator::Future,
                body: expr,
            }),
            _ => expr,
        }
    }

    fn parse_control_structure(
        &mut self,
        subject: &NounPhrase<'a>,
        verb: Symbol,
        verb_time: Time,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        let subject_sym = subject.noun;
        let verb_str = self.interner.resolve(verb);

        if Lexer::is_raising_verb(verb_str) {
            if !self.check_to() {
                return Ok(self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb,
                    args: self.ctx.terms.alloc_slice([Term::Constant(subject_sym)]),
                }));
            }
            self.advance();

            if !self.check_verb() {
                return Ok(self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb,
                    args: self.ctx.terms.alloc_slice([Term::Constant(subject_sym)]),
                }));
            }

            let inf_verb = self.consume_verb();

            let embedded = if self.is_control_verb(inf_verb) {
                let raised_np = NounPhrase {
                    noun: subject_sym,
                    definiteness: None,
                    adjectives: &[],
                    possessor: None,
                    pps: &[],
                    superlative: None,
                };
                self.parse_control_structure(&raised_np, inf_verb, Time::None)?
            } else {
                self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: inf_verb,
                    args: self.ctx.terms.alloc_slice([Term::Constant(subject_sym)]),
                })
            };

            let result = self.ctx.exprs.alloc(LogicExpr::Scopal {
                operator: verb,
                body: embedded,
            });

            return Ok(match verb_time {
                Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                    operator: TemporalOperator::Past,
                    body: result,
                }),
                Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                    operator: TemporalOperator::Future,
                    body: result,
                }),
                _ => result,
            });
        }

        let is_object_control = Lexer::is_object_control_verb(self.interner.resolve(verb));
        let (object_term, pro_controller_sym) = if self.check_to() {
            (None, subject_sym)
        } else if self.check_content_word() {
            let object_np = self.parse_noun_phrase(false)?;
            let obj_sym = object_np.noun;

            let controller = if is_object_control {
                obj_sym
            } else {
                subject_sym
            };
            (
                Some(self.ctx.terms.alloc(Term::Constant(obj_sym))),
                controller,
            )
        } else {
            (None, subject_sym)
        };

        if !self.check_to() {
            return Ok(self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: match object_term {
                    Some(obj) => self.ctx.terms.alloc_slice([
                        Term::Constant(subject_sym),
                        Term::Constant(match obj {
                            Term::Constant(s) => *s,
                            _ => subject_sym,
                        }),
                    ]),
                    None => self.ctx.terms.alloc_slice([Term::Constant(subject_sym)]),
                },
            }));
        }
        self.advance();

        if !self.check_verb() {
            return Ok(self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice([Term::Constant(subject_sym)]),
            }));
        }

        let inf_verb = self.consume_verb();
        let inf_verb_str = self.interner.resolve(inf_verb).to_lowercase();

        let infinitive = if inf_verb_str == "be" && self.check_verb() {
            let passive_verb = self.consume_verb();
            let passive_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: passive_verb,
                args: self
                    .ctx
                    .terms
                    .alloc_slice([Term::Constant(pro_controller_sym)]),
            });
            self.ctx.voice(crate::ast::VoiceOperator::Passive, passive_pred)
        } else if self.is_control_verb(inf_verb) {
            let controller_np = NounPhrase {
                noun: pro_controller_sym,
                definiteness: None,
                adjectives: &[],
                possessor: None,
                pps: &[],
                superlative: None,
            };
            self.parse_control_structure(&controller_np, inf_verb, Time::None)?
        } else {
            self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: inf_verb,
                args: self
                    .ctx
                    .terms
                    .alloc_slice([Term::Constant(pro_controller_sym)]),
            })
        };

        let control = self.ctx.exprs.alloc(LogicExpr::Control {
            verb,
            subject: self.ctx.terms.alloc(Term::Constant(subject_sym)),
            object: object_term,
            infinitive,
        });

        Ok(match verb_time {
            Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                operator: TemporalOperator::Past,
                body: control,
            }),
            Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                operator: TemporalOperator::Future,
                body: control,
            }),
            _ => control,
        })
    }

    fn is_control_verb(&self, verb: Symbol) -> bool {
        let lemma = self.interner.resolve(verb);
        Lexer::is_subject_control_verb(lemma)
            || Lexer::is_object_control_verb(lemma)
            || Lexer::is_raising_verb(lemma)
    }
}

```

---

### NounParsing Trait

**File:** `src/parser/noun.rs`

Extension trait for noun phrase parsing: articles, intersective/non-intersective adjectives (with compound interning), proper names, possessives ('s and 'of' forms), and PP attachment. Includes check_proper_name_or_label() for compound identifiers (set_A, function_F). Registers definite NPs for anaphora with gender/number inference. Provides parse_noun_phrase_for_relative() for relative clause contexts. Converts NounPhrase to Term for predicate arguments.

```rust
use super::clause::ClauseParsing;
use super::{ParseResult, Parser};
use crate::ast::{LogicExpr, NounPhrase, Term};
use crate::context::{Case, Gender, Number};
use crate::intern::SymbolEq;
use crate::lexicon::Definiteness;
use crate::token::TokenType;
use crate::transpile::capitalize_first;

pub trait NounParsing<'a, 'ctx, 'int> {
    fn parse_noun_phrase(&mut self, greedy: bool) -> ParseResult<NounPhrase<'a>>;
    fn parse_noun_phrase_for_relative(&mut self) -> ParseResult<NounPhrase<'a>>;
    fn noun_phrase_to_term(&self, np: &NounPhrase<'a>) -> Term<'a>;
    fn check_possessive(&self) -> bool;
    fn check_of_preposition(&self) -> bool;
    fn check_proper_name_or_label(&self) -> bool;
    fn check_possessive_pronoun(&self) -> bool;
}

impl<'a, 'ctx, 'int> NounParsing<'a, 'ctx, 'int> for Parser<'a, 'ctx, 'int> {
    fn parse_noun_phrase(&mut self, greedy: bool) -> ParseResult<NounPhrase<'a>> {
        let mut definiteness = None;
        let mut adjectives = Vec::new();
        let mut non_intersective_prefix: Option<crate::intern::Symbol> = None;
        let mut possessor_from_pronoun: Option<&'a NounPhrase<'a>> = None;
        let mut superlative_adj: Option<crate::intern::Symbol> = None;

        // Phase 35: Support numeric literals as noun phrases (e.g., "equal to 42")
        if let TokenType::Number(sym) = self.peek().kind {
            self.advance();
            return Ok(NounPhrase {
                definiteness: None,
                adjectives: &[],
                noun: sym,
                possessor: None,
                pps: &[],
                superlative: None,
            });
        }

        if self.check_possessive_pronoun() {
            let token = self.advance().clone();
            let (gender, number) = match &token.kind {
                TokenType::Pronoun { gender, number, case: Case::Possessive } => (*gender, *number),
                TokenType::Ambiguous { primary, alternatives } => {
                    let mut found = None;
                    if let TokenType::Pronoun { gender, number, case: Case::Possessive } = **primary {
                        found = Some((gender, number));
                    }
                    if found.is_none() {
                        for alt in alternatives {
                            if let TokenType::Pronoun { gender, number, case: Case::Possessive } = alt {
                                found = Some((*gender, *number));
                                break;
                            }
                        }
                    }
                    found.unwrap_or((Gender::Unknown, Number::Singular))
                }
                _ => (Gender::Unknown, Number::Singular),
            };

            let resolved = self.resolve_pronoun(gender, number)
                .unwrap_or_else(|| self.interner.intern("?"));

            let possessor_np = NounPhrase {
                definiteness: None,
                adjectives: &[],
                noun: resolved,
                possessor: None,
                pps: &[],
                superlative: None,
            };
            possessor_from_pronoun = Some(self.ctx.nps.alloc(possessor_np));
            definiteness = Some(Definiteness::Definite);
        } else if let TokenType::Article(def) = self.peek().kind {
            // Phase 35: Disambiguate "a" as variable vs article
            // If "a" or "an" is followed by a verb/copula/modal, it's a variable name, not an article
            let is_variable_a = {
                let lexeme = self.interner.resolve(self.peek().lexeme).to_lowercase();
                if lexeme == "a" || lexeme == "an" {
                    if let Some(next) = self.tokens.get(self.current + 1) {
                        matches!(next.kind,
                            TokenType::Is | TokenType::Are | TokenType::Was | TokenType::Were | // Copula
                            TokenType::Verb { .. } | // Main verb
                            TokenType::Auxiliary(_) | // will, did
                            TokenType::Must | TokenType::Can | TokenType::Should | TokenType::May | // Modals
                            TokenType::Could | TokenType::Would | TokenType::Shall |
                            TokenType::Identity | TokenType::Equals // "a = b"
                        )
                    } else {
                        false
                    }
                } else {
                    false
                }
            };

            if !is_variable_a {
                definiteness = Some(def);
                self.advance();
            }
        }

        if self.check_superlative() {
            if let TokenType::Superlative(adj) = self.advance().kind {
                superlative_adj = Some(adj);
            }
        }

        if self.check_non_intersective_adjective() {
            if let TokenType::NonIntersectiveAdjective(adj) = self.advance().kind {
                non_intersective_prefix = Some(adj);
            }
        }

        loop {
            if self.is_at_end() {
                break;
            }

            let is_adjective = matches!(self.peek().kind, TokenType::Adjective(_));
            if !is_adjective {
                break;
            }

            let next_is_content = if self.current + 1 < self.tokens.len() {
                matches!(
                    self.tokens[self.current + 1].kind,
                    TokenType::Noun(_)
                        | TokenType::Adjective(_)
                        | TokenType::ProperName(_)
                )
            } else {
                false
            };

            if next_is_content {
                if let TokenType::Adjective(adj) = self.advance().kind {
                    adjectives.push(adj);
                }
            } else {
                break;
            }
        }

        let base_noun = self.consume_content_word()?;

        let noun = if let Some(prefix) = non_intersective_prefix {
            let prefix_str = self.interner.resolve(prefix);
            let base_str = self.interner.resolve(base_noun);
            let compound = format!("{}-{}", prefix_str, base_str);
            self.interner.intern(&compound)
        } else {
            base_noun
        };

        let noun = if self.check_proper_name_or_label() {
            let label = self.consume_content_word()?;
            let label_str = self.interner.resolve(label);
            let base_str = self.interner.resolve(noun);
            let compound = format!("{}_{}", base_str, label_str);
            self.interner.intern(&compound)
        } else {
            noun
        };

        if self.check_possessive() {
            self.advance();

            let possessor = self.ctx.nps.alloc(NounPhrase {
                definiteness,
                adjectives: self.ctx.syms.alloc_slice(adjectives.clone()),
                noun,
                possessor: None,
                pps: &[],
                superlative: superlative_adj,
            });

            let possessed_noun = self.consume_content_word()?;

            return Ok(NounPhrase {
                definiteness: None,
                adjectives: &[],
                noun: possessed_noun,
                possessor: Some(possessor),
                pps: &[],
                superlative: None,
            });
        }

        let should_attach_pps = greedy || self.pp_attach_to_noun;

        let mut pps: Vec<&'a LogicExpr<'a>> = Vec::new();
        if should_attach_pps {
            while self.check_preposition() && !self.check_of_preposition() {
                let prep_token = self.advance().clone();
                let prep_name = if let TokenType::Preposition(sym) = prep_token.kind {
                    sym
                } else {
                    break;
                };

                if self.check_content_word() || matches!(self.peek().kind, TokenType::Article(_)) {
                    let pp_object = self.parse_noun_phrase(true)?;
                    let placeholder_var = self.interner.intern("_PP_SELF_");
                    let pp_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                        name: prep_name,
                        args: self.ctx.terms.alloc_slice([
                            Term::Variable(placeholder_var),
                            Term::Constant(pp_object.noun),
                        ]),
                    });
                    pps.push(pp_pred);
                }
            }
        }
        let pps_slice = self.ctx.pps.alloc_slice(pps);

        if self.check_of_preposition() {
            // Two-Pass Type Disambiguation:
            // If the noun is a known generic type (e.g., "Stack", "List"),
            // then "X of Y" is a type instantiation, not a possessive.
            // For now, we still parse it as possessive structurally, but
            // the type_registry enables future AST extensions for type annotations.
            let is_generic = self.is_generic_type(noun);

            if !is_generic {
                // Standard possessive: "owner of house" → possessor relationship
                self.advance();

                let possessor_np = self.parse_noun_phrase(true)?;
                let possessor = self.ctx.nps.alloc(possessor_np);

                return Ok(NounPhrase {
                    definiteness,
                    adjectives: self.ctx.syms.alloc_slice(adjectives),
                    noun,
                    possessor: Some(possessor),
                    pps: pps_slice,
                    superlative: superlative_adj,
                });
            }
            // If generic type, fall through to regular noun phrase handling.
            // The "of [Type]" will be left unparsed for now.
            // Future: Parse as GenericType { base: noun, params: [...] }
        }

        // Register ALL noun phrases as discourse entities, not just definite ones.
        // This is needed for bridging anaphora: "I bought a car. The engine smoked."
        // The indefinite "a car" must be in discourse history for "the engine" to link to it.
        let noun_str = self.interner.resolve(noun);
        let first_char = noun_str.chars().next().unwrap_or('X');
        if first_char.is_alphabetic() {
            // Use full noun name as symbol for consistent output in Full mode
            let symbol = capitalize_first(noun_str);
            let number = if noun_str.ends_with('s') && !noun_str.ends_with("ss") {
                Number::Plural
            } else {
                Number::Singular
            };
            let noun_class = noun_str.to_string();
            self.register_entity(&symbol, &noun_class, Gender::Neuter, number);
        }

        Ok(NounPhrase {
            definiteness,
            adjectives: self.ctx.syms.alloc_slice(adjectives),
            noun,
            possessor: possessor_from_pronoun,
            pps: pps_slice,
            superlative: superlative_adj,
        })
    }

    fn parse_noun_phrase_for_relative(&mut self) -> ParseResult<NounPhrase<'a>> {
        let mut definiteness = None;
        let mut adjectives = Vec::new();

        if let TokenType::Article(def) = self.peek().kind {
            definiteness = Some(def);
            self.advance();
        }

        loop {
            if self.is_at_end() {
                break;
            }

            let is_adjective = matches!(self.peek().kind, TokenType::Adjective(_));
            if !is_adjective {
                break;
            }

            let next_is_content = if self.current + 1 < self.tokens.len() {
                matches!(
                    self.tokens[self.current + 1].kind,
                    TokenType::Noun(_)
                        | TokenType::Adjective(_)
                        | TokenType::Verb { .. }
                        | TokenType::ProperName(_)
                )
            } else {
                false
            };

            if next_is_content {
                if let TokenType::Adjective(adj) = self.advance().kind.clone() {
                    adjectives.push(adj);
                }
            } else {
                break;
            }
        }

        let noun = self.consume_content_word_for_relative()?;

        if self.check(&TokenType::That) || self.check(&TokenType::Who) {
            self.advance();
            let var_name = self.interner.intern(&format!("r{}", self.var_counter));
            self.var_counter += 1;
            let _nested_clause = self.parse_relative_clause(var_name)?;
        }

        Ok(NounPhrase {
            definiteness,
            adjectives: self.ctx.syms.alloc_slice(adjectives),
            noun,
            possessor: None,
            pps: &[],
            superlative: None,
        })
    }

    fn noun_phrase_to_term(&self, np: &NounPhrase<'a>) -> Term<'a> {
        if let Some(possessor) = np.possessor {
            let possessor_term = self.noun_phrase_to_term(possessor);
            Term::Possessed {
                possessor: self.ctx.terms.alloc(possessor_term),
                possessed: np.noun,
            }
        } else {
            Term::Constant(np.noun)
        }
    }

    fn check_possessive(&self) -> bool {
        matches!(self.peek().kind, TokenType::Possessive)
    }

    fn check_of_preposition(&self) -> bool {
        if let TokenType::Preposition(p) = self.peek().kind {
            p.is(self.interner, "of")
        } else {
            false
        }
    }

    fn check_proper_name_or_label(&self) -> bool {
        match &self.peek().kind {
            TokenType::ProperName(_) => true,
            TokenType::Noun(s) => {
                let str_val = self.interner.resolve(*s);
                str_val.len() == 1 && str_val.chars().next().unwrap().is_uppercase()
            }
            _ => false,
        }
    }

    fn check_possessive_pronoun(&self) -> bool {
        match &self.peek().kind {
            TokenType::Pronoun { case: Case::Possessive, .. } => true,
            TokenType::Ambiguous { primary, alternatives } => {
                if self.noun_priority_mode {
                    if let TokenType::Pronoun { case: Case::Possessive, .. } = **primary {
                        return true;
                    }
                    for alt in alternatives {
                        if let TokenType::Pronoun { case: Case::Possessive, .. } = alt {
                            return true;
                        }
                    }
                }
                false
            }
            _ => false,
        }
    }
}

```

---

### QuestionParsing Trait

**File:** `src/parser/question.rs`

Extension trait for interrogatives: wh-questions (who/what/where/when/why/how), pied-piping prepositions, yes/no questions with auxiliary inversion, modal-to-vector conversion for question semantics.

```rust
use super::noun::NounParsing;
use super::quantifier::QuantifierParsing;
use super::verb::LogicVerbParsing;
use super::{ParseResult, Parser};
use crate::ast::{AspectOperator, LogicExpr, ModalDomain, ModalVector, TemporalOperator, Term};
use crate::lexicon::{Aspect, Time};
use crate::token::TokenType;

pub trait QuestionParsing<'a, 'ctx, 'int> {
    fn parse_wh_question(&mut self) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_yes_no_question(&mut self) -> ParseResult<&'a LogicExpr<'a>>;
    fn aux_token_to_modal_vector(&self, token: &TokenType) -> ModalVector;
}

impl<'a, 'ctx, 'int> QuestionParsing<'a, 'ctx, 'int> for Parser<'a, 'ctx, 'int> {
    fn parse_wh_question(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let pied_piping_prep = if self.check_preposition() {
            let prep = self.advance().kind.clone();
            Some(prep)
        } else {
            None
        };

        let wh_token = self.advance().kind.clone();
        let var_name = self.interner.intern("x");
        let var_term = Term::Variable(var_name);

        if pied_piping_prep.is_some() && self.check_auxiliary() {
            let aux_token = self.advance().clone();
            if let TokenType::Auxiliary(time) = aux_token.kind {
                self.pending_time = Some(time);
            }

            let subject = self.parse_noun_phrase(true)?;
            let verb = self.consume_verb();

            let mut args = vec![Term::Constant(subject.noun)];
            if self.check_content_word() || self.check_article() {
                let object = self.parse_noun_phrase(false)?;
                args.push(Term::Constant(object.noun));
            }
            args.push(var_term);

            let body = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice(args),
            });
            return Ok(self.ctx.exprs.alloc(LogicExpr::Question {
                wh_variable: var_name,
                body,
            }));
        }

        if self.check_verb() {
            let verb = self.consume_verb();
            let mut args = vec![var_term];

            if self.check_content_word() {
                let object = self.parse_noun_phrase(false)?;
                args.push(Term::Constant(object.noun));
            }

            let body = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice(args),
            });
            return Ok(self.ctx.exprs.alloc(LogicExpr::Question {
                wh_variable: var_name,
                body,
            }));
        }

        if self.check(&TokenType::Does) || self.check(&TokenType::Do) {
            self.advance();
            let subject = self.parse_noun_phrase(true)?;
            let verb = self.consume_verb();

            let body = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice([Term::Constant(subject.noun), var_term]),
            });
            return Ok(self.ctx.exprs.alloc(LogicExpr::Question {
                wh_variable: var_name,
                body,
            }));
        }

        if self.check_auxiliary() {
            let aux_token = self.advance().clone();
            if let TokenType::Auxiliary(time) = aux_token.kind {
                self.pending_time = Some(time);
            }

            self.filler_gap = Some(var_name);

            let subject = self.parse_noun_phrase(true)?;
            let body = self.parse_predicate_with_subject(subject.noun)?;

            self.filler_gap = None;

            return Ok(self.ctx.exprs.alloc(LogicExpr::Question {
                wh_variable: var_name,
                body,
            }));
        }

        let unknown = self.interner.intern(&format!("{:?}", wh_token));
        Ok(self.ctx.exprs.alloc(LogicExpr::Atom(unknown)))
    }

    fn parse_yes_no_question(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let aux_token = self.advance().kind.clone();

        let is_modal = matches!(aux_token, TokenType::Can | TokenType::Could | TokenType::Would | TokenType::May | TokenType::Must | TokenType::Should);
        let is_copula = matches!(aux_token, TokenType::Is | TokenType::Are | TokenType::Was | TokenType::Were);
        let copula_time = if matches!(aux_token, TokenType::Was | TokenType::Were) {
            Time::Past
        } else {
            Time::Present
        };

        if self.check_quantifier() {
            self.advance();
            let quantified = self.parse_quantified()?;
            let wrapped = if is_modal {
                let vector = self.aux_token_to_modal_vector(&aux_token);
                self.ctx.exprs.alloc(LogicExpr::Modal {
                    vector,
                    operand: quantified,
                })
            } else {
                quantified
            };
            return Ok(self.ctx.exprs.alloc(LogicExpr::YesNoQuestion { body: wrapped }));
        }

        let subject_symbol = if self.check_pronoun() {
            let token = self.advance().clone();
            if let TokenType::Pronoun { gender, number, .. } = token.kind {
                let token_text = self.interner.resolve(token.lexeme);
                if token_text.eq_ignore_ascii_case("you") {
                    self.interner.intern("Addressee")
                } else {
                    self.resolve_pronoun(gender, number)
                        .unwrap_or_else(|| self.interner.intern("?"))
                }
            } else {
                self.interner.intern("?")
            }
        } else {
            self.parse_noun_phrase(true)?.noun
        };

        let please_sym = self.interner.intern("please");
        self.match_token(&[TokenType::Adverb(please_sym)]);

        if is_copula {
            let body = if self.check_verb() {
                let (verb, _, verb_aspect, _) = self.consume_verb_with_metadata();
                let predicate = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb,
                    args: self.ctx.terms.alloc_slice([Term::Constant(subject_symbol)]),
                });
                let with_aspect = if verb_aspect == Aspect::Progressive {
                    self.ctx.exprs.alloc(LogicExpr::Aspectual {
                        operator: AspectOperator::Progressive,
                        body: predicate,
                    })
                } else {
                    predicate
                };
                if copula_time == Time::Past {
                    self.ctx.exprs.alloc(LogicExpr::Temporal {
                        operator: TemporalOperator::Past,
                        body: with_aspect,
                    })
                } else {
                    with_aspect
                }
            } else if self.check_content_word() {
                let adj = self.consume_content_word()?;
                self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: adj,
                    args: self.ctx.terms.alloc_slice([Term::Constant(subject_symbol)]),
                })
            } else {
                self.ctx.exprs.alloc(LogicExpr::Atom(subject_symbol))
            };
            return Ok(self.ctx.exprs.alloc(LogicExpr::YesNoQuestion { body }));
        }

        let body = self.parse_predicate_with_subject(subject_symbol)?;

        let wrapped_body = if is_modal {
            let vector = self.aux_token_to_modal_vector(&aux_token);
            self.ctx.exprs.alloc(LogicExpr::Modal {
                vector,
                operand: body,
            })
        } else {
            body
        };

        Ok(self.ctx.exprs.alloc(LogicExpr::YesNoQuestion { body: wrapped_body }))
    }

    fn aux_token_to_modal_vector(&self, token: &TokenType) -> ModalVector {
        use crate::ast::ModalFlavor;
        match token {
            // Root modals (narrow scope)
            TokenType::Can => ModalVector {
                domain: ModalDomain::Alethic,
                force: 0.5,
                flavor: ModalFlavor::Root,
            },
            TokenType::Could => ModalVector {
                domain: ModalDomain::Alethic,
                force: 0.4,
                flavor: ModalFlavor::Root,
            },
            TokenType::Would => ModalVector {
                domain: ModalDomain::Alethic,
                force: 0.6,
                flavor: ModalFlavor::Root,
            },
            TokenType::Must => ModalVector {
                domain: ModalDomain::Alethic,
                force: 1.0,
                flavor: ModalFlavor::Root,
            },
            TokenType::Should => ModalVector {
                domain: ModalDomain::Deontic,
                force: 0.6,
                flavor: ModalFlavor::Root,
            },
            // Epistemic modals (wide scope)
            TokenType::May => ModalVector {
                domain: ModalDomain::Deontic,
                force: 0.5,
                flavor: ModalFlavor::Epistemic,
            },
            TokenType::Might => ModalVector {
                domain: ModalDomain::Alethic,
                force: 0.3,
                flavor: ModalFlavor::Epistemic,
            },
            _ => ModalVector {
                domain: ModalDomain::Alethic,
                force: 0.5,
                flavor: ModalFlavor::Root,
            },
        }
    }
}

```

---

### ModalParsing Trait

**File:** `src/parser/modal.rs`

Extension trait for modal expressions: necessity/possibility (must/can/might/would/should/cannot), aspect chains (parse_aspect_chain() and parse_aspect_chain_with_term() for perfect/progressive/passive/modal stacking with constant or variable subjects), modal vector construction (domain + force). **Passive Agent Extraction:** Detects 'by X' after passive 'been' to extract agent argument for proper thematic role assignment. **NeoEvent Output:** Creates Expr::NeoEvent with thematic roles for consistent event semantics; adds tense modifiers from pending_time. All modals route through aspect chain parsing for uniform handling of negation and auxiliaries.

```rust
use super::clause::ClauseParsing;
use super::noun::NounParsing;
use super::{ParseResult, Parser};
use crate::ast::{AspectOperator, LogicExpr, ModalDomain, ModalVector, NeoEventData, ThematicRole, VoiceOperator, Term};
use crate::context::TimeRelation;
use crate::error::{ParseError, ParseErrorKind};
use crate::intern::Symbol;
use crate::lexicon::{Time, Aspect};
use crate::token::TokenType;

pub trait ModalParsing<'a, 'ctx, 'int> {
    fn parse_modal(&mut self) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_aspect_chain(&mut self, subject_symbol: Symbol) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_aspect_chain_with_term(&mut self, subject_term: Term<'a>) -> ParseResult<&'a LogicExpr<'a>>;
    fn token_to_vector(&self, token: &TokenType) -> ModalVector;
}

impl<'a, 'ctx, 'int> ModalParsing<'a, 'ctx, 'int> for Parser<'a, 'ctx, 'int> {
    fn parse_modal(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let vector = self.token_to_vector(&self.previous().kind.clone());

        if self.check(&TokenType::That) {
            self.advance();
        }

        let content = self.parse_sentence()?;

        Ok(self.ctx.exprs.alloc(LogicExpr::Modal {
            vector,
            operand: content,
        }))
    }

    fn parse_aspect_chain(&mut self, subject_symbol: Symbol) -> ParseResult<&'a LogicExpr<'a>> {
        self.parse_aspect_chain_with_term(Term::Constant(subject_symbol))
    }

    fn parse_aspect_chain_with_term(&mut self, subject_term: Term<'a>) -> ParseResult<&'a LogicExpr<'a>> {
        let mut has_modal = false;
        let mut modal_vector = None;
        let mut has_negation = false;
        let mut has_perfect = false;
        let mut has_passive = false;
        let mut has_progressive = false;

        if self.check(&TokenType::Would) || self.check(&TokenType::Could)
            || self.check(&TokenType::Must) || self.check(&TokenType::Can)
            || self.check(&TokenType::Should) || self.check(&TokenType::May)
            || self.check(&TokenType::Cannot) {
            let modal_token = self.peek().kind.clone();
            self.advance();
            has_modal = true;
            modal_vector = Some(self.token_to_vector(&modal_token));
        }

        if self.check(&TokenType::Not) {
            self.advance();
            has_negation = true;
        }

        if self.check_content_word() {
            let word = self.interner.resolve(self.peek().lexeme).to_lowercase();
            if word == "have" || word == "has" || word == "had" {
                self.advance();
                has_perfect = true;
            }
        }

        if self.check(&TokenType::Had) {
            self.advance();
            has_perfect = true;
            // "had" = past perfect: R < S (past reference time)
            if let Some(ref mut context) = self.context {
                let r_var = context.next_reference_time();
                context.add_time_constraint(r_var, TimeRelation::Precedes, "S".to_string());
            }
        }

        if self.check_content_word() {
            let word = self.interner.resolve(self.peek().lexeme).to_lowercase();
            if word == "been" {
                self.advance();

                if self.check_verb() {
                    match &self.peek().kind {
                        TokenType::Verb { aspect: Aspect::Progressive, .. } => {
                            has_progressive = true;
                        }
                        TokenType::Verb { .. } => {
                            let next_word = self.interner.resolve(self.peek().lexeme);
                            if next_word.ends_with("ing") {
                                has_progressive = true;
                            } else {
                                has_passive = true;
                            }
                        }
                        _ => {
                            has_passive = true;
                        }
                    }
                }
            }
        }

        if self.check_content_word() {
            let word = self.interner.resolve(self.peek().lexeme).to_lowercase();
            if word == "being" {
                self.advance();
                has_progressive = true;
            }
        }

        let verb = if self.check_verb() {
            self.consume_verb()
        } else if self.check_content_word() {
            self.consume_content_word()?
        } else {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedContentWord { found: self.peek().kind.clone() },
                span: self.peek().span.clone(),
            });
        };

        let subject_role = if has_passive {
            ThematicRole::Theme
        } else {
            ThematicRole::Agent
        };
        let mut roles: Vec<(ThematicRole, Term<'a>)> = vec![(subject_role, subject_term)];

        if has_passive && self.check_preposition() {
            if let TokenType::Preposition(sym) = self.peek().kind {
                if self.interner.resolve(sym) == "by" {
                    self.advance();
                    let agent_np = self.parse_noun_phrase(true)?;
                    let agent_term = self.noun_phrase_to_term(&agent_np);
                    roles.push((ThematicRole::Agent, agent_term));
                }
            }
        } else if !has_passive && (self.check_content_word() || self.check_article()) {
            let obj_np = self.parse_noun_phrase(false)?;
            let obj_term = self.noun_phrase_to_term(&obj_np);
            roles.push((ThematicRole::Theme, obj_term));
        }

        let event_var = self.get_event_var();
        let mut modifiers: Vec<Symbol> = Vec::new();
        if let Some(pending) = self.pending_time {
            match pending {
                Time::Past => modifiers.push(self.interner.intern("Past")),
                Time::Future => modifiers.push(self.interner.intern("Future")),
                _ => {}
            }
        }
        let suppress_existential = self.drs.in_conditional_antecedent();
        let base_pred = self.ctx.exprs.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
            event_var,
            verb,
            roles: self.ctx.roles.alloc_slice(roles.clone()),
            modifiers: self.ctx.syms.alloc_slice(modifiers.clone()),
            suppress_existential,
        })));

        // Capture template for ellipsis reconstruction
        self.capture_event_template(verb, &roles, &modifiers);

        let mut result: &'a LogicExpr<'a> = base_pred;

        if has_progressive {
            result = self.ctx.aspectual(AspectOperator::Progressive, result);
        }

        if has_passive {
            result = self.ctx.voice(VoiceOperator::Passive, result);
        }

        if has_perfect {
            result = self.ctx.aspectual(AspectOperator::Perfect, result);
            if let Some(ref mut context) = self.context {
                // Check pending_time to set up reference time for tense
                if let Some(pending) = self.pending_time.take() {
                    match pending {
                        Time::Future => {
                            let r_var = context.next_reference_time();
                            context.add_time_constraint("S".to_string(), TimeRelation::Precedes, r_var);
                        }
                        Time::Past => {
                            // Past tense with perfect (should be handled by "had" already, but as fallback)
                            if context.current_reference_time() == "S" {
                                let r_var = context.next_reference_time();
                                context.add_time_constraint(r_var, TimeRelation::Precedes, "S".to_string());
                            }
                        }
                        _ => {}
                    }
                }
                // Perfect: E < R
                let e_var = format!("e{}", context.event_history().len().max(1));
                let r_var = context.current_reference_time();
                context.add_time_constraint(e_var, TimeRelation::Precedes, r_var);
            }
        }

        if has_negation {
            result = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                op: TokenType::Not,
                operand: result,
            });
        }

        if has_modal {
            if let Some(vector) = modal_vector {
                result = self.ctx.modal(vector, result);
            }
        }

        Ok(result)
    }

    fn token_to_vector(&self, token: &TokenType) -> ModalVector {
        use crate::ast::ModalFlavor;

        match token {
            // Root modals → Narrow Scope (De Re)
            // These attach the modal to the predicate inside the quantifier
            TokenType::Must => ModalVector {
                domain: ModalDomain::Alethic,
                force: 1.0,
                flavor: ModalFlavor::Root,
            },
            TokenType::Cannot => ModalVector {
                domain: ModalDomain::Alethic,
                force: 0.0,
                flavor: ModalFlavor::Root,
            },
            TokenType::Can => ModalVector {
                domain: ModalDomain::Alethic,
                force: 0.5,
                flavor: ModalFlavor::Root,
            },
            TokenType::Could => ModalVector {
                domain: ModalDomain::Alethic,
                force: 0.5,
                flavor: ModalFlavor::Root,
            },
            TokenType::Would => ModalVector {
                domain: ModalDomain::Alethic,
                force: 0.5,
                flavor: ModalFlavor::Root,
            },
            TokenType::Shall => ModalVector {
                domain: ModalDomain::Deontic,
                force: 0.9,
                flavor: ModalFlavor::Root,
            },
            TokenType::Should => ModalVector {
                domain: ModalDomain::Deontic,
                force: 0.6,
                flavor: ModalFlavor::Root,
            },

            // Epistemic modals → Wide Scope (De Dicto)
            // These wrap the entire quantifier in the modal
            TokenType::Might => ModalVector {
                domain: ModalDomain::Alethic,
                force: 0.3,
                flavor: ModalFlavor::Epistemic,
            },
            TokenType::May => ModalVector {
                domain: ModalDomain::Deontic,
                force: 0.5,
                flavor: ModalFlavor::Epistemic,
            },

            _ => panic!("Unknown modal token: {:?}", token),
        }
    }
}

```

---

### PragmaticsParsing Trait

**File:** `src/parser/pragmatics.rs`

Extension trait for pragmatic phenomena: focus particles (only/even/just), measure expressions (much/little), presupposition triggers (factive verbs, aspectual verbs with gerund complement check via is_followed_by_gerund()), scopal adverbs, comparatives (taller than with optional difference measure phrase), superlatives (tallest). parse_measure() handles numeric measurement phrases and routes to comparative parsing when degree expressions are detected.

```rust
use super::noun::NounParsing;
use super::quantifier::QuantifierParsing;
use super::{ParseResult, Parser};
use crate::ast::{LogicExpr, NounPhrase, NumberKind, QuantifierKind, TemporalOperator, Term};
use crate::error::{ParseError, ParseErrorKind};
use crate::lexicon::{self, Time};
use crate::token::{MeasureKind, PresupKind, TokenType};

pub trait PragmaticsParsing<'a, 'ctx, 'int> {
    fn parse_focus(&mut self) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_measure(&mut self) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_presupposition(
        &mut self,
        subject: &NounPhrase<'a>,
        presup_kind: PresupKind,
    ) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_predicate_for_subject(&mut self, subject: &NounPhrase<'a>)
        -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_scopal_adverb(&mut self, subject: &NounPhrase<'a>) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_superlative(&mut self, subject: &NounPhrase<'a>) -> ParseResult<&'a LogicExpr<'a>>;
    fn parse_comparative(
        &mut self,
        subject: &NounPhrase<'a>,
        copula_time: Time,
        difference: Option<&'a Term<'a>>,
    ) -> ParseResult<&'a LogicExpr<'a>>;
    fn check_number(&self) -> bool;
    fn parse_measure_phrase(&mut self) -> ParseResult<&'a Term<'a>>;
}

impl<'a, 'ctx, 'int> PragmaticsParsing<'a, 'ctx, 'int> for Parser<'a, 'ctx, 'int> {
    fn parse_focus(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let kind = if let TokenType::Focus(k) = self.advance().kind {
            k
        } else {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedFocusParticle,
                span: self.current_span(),
            });
        };

        if self.check_quantifier() {
            self.advance();
            let quantified = self.parse_quantified()?;
            let focus_var = self.interner.intern("focus");
            let focused = self.ctx.terms.alloc(Term::Variable(focus_var));
            return Ok(self.ctx.exprs.alloc(LogicExpr::Focus {
                kind,
                focused,
                scope: quantified,
            }));
        }

        let focused_np = self.parse_noun_phrase(true)?;
        let focused = self.ctx.terms.alloc(Term::Constant(focused_np.noun));

        let scope = self.parse_predicate_for_subject(&focused_np)?;

        Ok(self.ctx.exprs.alloc(LogicExpr::Focus {
            kind,
            focused,
            scope,
        }))
    }

    fn parse_measure(&mut self) -> ParseResult<&'a LogicExpr<'a>> {
        let kind = if let TokenType::Measure(k) = self.advance().kind {
            k
        } else {
            return Err(ParseError {
                kind: ParseErrorKind::UnexpectedToken {
                    expected: TokenType::Measure(MeasureKind::Much),
                    found: self.peek().kind.clone(),
                },
                span: self.current_span(),
            });
        };

        let np = self.parse_noun_phrase(true)?;
        let var = self.next_var_name();

        let noun_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
            name: np.noun,
            args: self.ctx.terms.alloc_slice([Term::Variable(var)]),
        });

        let measure_sym = self.interner.intern("Measure");
        let kind_sym = self.interner.intern(match kind {
            MeasureKind::Much => "Much",
            MeasureKind::Little => "Little",
        });
        let measure_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
            name: measure_sym,
            args: self
                .ctx
                .terms
                .alloc_slice([Term::Variable(var), Term::Constant(kind_sym)]),
        });

        let (pred_expr, verb_time) = if self.check(&TokenType::Is) {
            let copula_time = if let TokenType::Is = self.advance().kind {
                Time::Present
            } else {
                Time::Present
            };

            // Check for comparative: "is colder than"
            if self.check_comparative() {
                let subj_np = NounPhrase {
                    noun: np.noun,
                    definiteness: None,
                    adjectives: &[],
                    possessor: None,
                    pps: &[],
                    superlative: None,
                };
                let comp_expr = self.parse_comparative(&subj_np, copula_time, None)?;

                let combined = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                    left: noun_pred,
                    op: TokenType::And,
                    right: self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                        left: measure_pred,
                        op: TokenType::And,
                        right: comp_expr,
                    }),
                });

                return Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
                    kind: QuantifierKind::Existential,
                    variable: var,
                    body: combined,
                    island_id: self.current_island,
                }));
            }

            let adj = self.consume_content_word()?;
            let adj_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: adj,
                args: self.ctx.terms.alloc_slice([Term::Variable(var)]),
            });
            (adj_pred, copula_time)
        } else {
            let (verb, verb_time, _, _) = self.consume_verb_with_metadata();
            let verb_pred = self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice([Term::Variable(var)]),
            });
            (verb_pred, verb_time)
        };

        let combined = self.ctx.exprs.alloc(LogicExpr::BinaryOp {
            left: noun_pred,
            op: TokenType::And,
            right: self.ctx.exprs.alloc(LogicExpr::BinaryOp {
                left: measure_pred,
                op: TokenType::And,
                right: pred_expr,
            }),
        });

        let with_time = match verb_time {
            Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                operator: TemporalOperator::Past,
                body: combined,
            }),
            Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                operator: TemporalOperator::Future,
                body: combined,
            }),
            _ => combined,
        };

        Ok(self.ctx.exprs.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Existential,
            variable: var,
            body: with_time,
            island_id: self.current_island,
        }))
    }

    fn parse_presupposition(
        &mut self,
        subject: &NounPhrase<'a>,
        presup_kind: PresupKind,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        let subject_noun = subject.noun;

        let unknown = self.interner.intern("?");
        let complement = if self.check_verb() {
            let verb = self.consume_verb();
            self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice([Term::Constant(subject_noun)]),
            })
        } else {
            self.ctx.exprs.alloc(LogicExpr::Atom(unknown))
        };

        let (assertion, presupposition) = match presup_kind {
            PresupKind::Stop => {
                let neg = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                    op: TokenType::Not,
                    operand: complement,
                });
                let past = self.ctx.exprs.alloc(LogicExpr::Temporal {
                    operator: TemporalOperator::Past,
                    body: complement,
                });
                (neg, past)
            }
            PresupKind::Start => {
                let past = self.ctx.exprs.alloc(LogicExpr::Temporal {
                    operator: TemporalOperator::Past,
                    body: complement,
                });
                let neg_past = self.ctx.exprs.alloc(LogicExpr::UnaryOp {
                    op: TokenType::Not,
                    operand: past,
                });
                (complement, neg_past)
            }
            PresupKind::Regret => {
                let regret_sym = self.interner.intern("Regret");
                let regret = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: regret_sym,
                    args: self.ctx.terms.alloc_slice([Term::Constant(subject_noun)]),
                });
                let past = self.ctx.exprs.alloc(LogicExpr::Temporal {
                    operator: TemporalOperator::Past,
                    body: complement,
                });
                (regret, past)
            }
            PresupKind::Continue | PresupKind::Realize | PresupKind::Know => {
                let verb_name = match presup_kind {
                    PresupKind::Continue => self.interner.intern("Continue"),
                    PresupKind::Realize => self.interner.intern("Realize"),
                    PresupKind::Know => self.interner.intern("Know"),
                    _ => unknown,
                };
                let main = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb_name,
                    args: self.ctx.terms.alloc_slice([Term::Constant(subject_noun)]),
                });
                (main, complement)
            }
        };

        Ok(self.ctx.exprs.alloc(LogicExpr::Presupposition {
            assertion,
            presupposition,
        }))
    }

    fn parse_predicate_for_subject(
        &mut self,
        subject: &NounPhrase<'a>,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        if self.check_verb() {
            let verb = self.consume_verb();

            // Check for focused object: "eats only rice"
            if self.check_focus() {
                let focus_kind = if let TokenType::Focus(k) = self.advance().kind {
                    k
                } else {
                    crate::token::FocusKind::Only
                };

                let object_np = self.parse_noun_phrase(false)?;
                let object_term = Term::Constant(object_np.noun);

                let predicate = self.ctx.exprs.alloc(LogicExpr::Predicate {
                    name: verb,
                    args: self.ctx.terms.alloc_slice([
                        Term::Constant(subject.noun),
                        object_term.clone(),
                    ]),
                });

                return Ok(self.ctx.exprs.alloc(LogicExpr::Focus {
                    kind: focus_kind,
                    focused: self.ctx.terms.alloc(object_term),
                    scope: predicate,
                }));
            }

            let mut args = vec![Term::Constant(subject.noun)];

            if self.check_content_word() || self.check_article() {
                let object = self.parse_noun_phrase(false)?;
                args.push(Term::Constant(object.noun));
            }

            Ok(self.ctx.exprs.alloc(LogicExpr::Predicate {
                name: verb,
                args: self.ctx.terms.alloc_slice(args),
            }))
        } else {
            Ok(self.ctx.exprs.alloc(LogicExpr::Atom(subject.noun)))
        }
    }

    fn parse_scopal_adverb(&mut self, subject: &NounPhrase<'a>) -> ParseResult<&'a LogicExpr<'a>> {
        let operator = if let TokenType::ScopalAdverb(adv) = self.advance().kind.clone() {
            adv
        } else {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedScopalAdverb,
                span: self.current_span(),
            });
        };

        if !self.check_verb() {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedVerb {
                    found: self.peek().kind.clone(),
                },
                span: self.current_span(),
            });
        }

        let (verb, verb_time, _verb_aspect, _) = self.consume_verb_with_metadata();

        let predicate = self.ctx.exprs.alloc(LogicExpr::Predicate {
            name: verb,
            args: self.ctx.terms.alloc_slice([Term::Constant(subject.noun)]),
        });

        let with_time = match verb_time {
            Time::Past => self.ctx.exprs.alloc(LogicExpr::Temporal {
                operator: TemporalOperator::Past,
                body: predicate,
            }),
            Time::Future => self.ctx.exprs.alloc(LogicExpr::Temporal {
                operator: TemporalOperator::Future,
                body: predicate,
            }),
            _ => predicate,
        };

        Ok(self.ctx.exprs.alloc(LogicExpr::Scopal {
            operator,
            body: with_time,
        }))
    }

    fn parse_superlative(&mut self, subject: &NounPhrase<'a>) -> ParseResult<&'a LogicExpr<'a>> {
        let adj = if let TokenType::Superlative(adj) = self.advance().kind.clone() {
            adj
        } else {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedSuperlativeAdjective,
                span: self.current_span(),
            });
        };

        let domain = self.consume_content_word()?;

        Ok(self.ctx.exprs.alloc(LogicExpr::Superlative {
            adjective: adj,
            subject: self.ctx.terms.alloc(Term::Constant(subject.noun)),
            domain,
        }))
    }

    fn parse_comparative(
        &mut self,
        subject: &NounPhrase<'a>,
        _copula_time: Time,
        difference: Option<&'a Term<'a>>,
    ) -> ParseResult<&'a LogicExpr<'a>> {
        let adj = if let TokenType::Comparative(adj) = self.advance().kind.clone() {
            adj
        } else {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedComparativeAdjective,
                span: self.current_span(),
            });
        };

        if !self.check(&TokenType::Than) {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedThan,
                span: self.current_span(),
            });
        }
        self.advance();

        // Check if the comparison target is a number (e.g., "greater than 0")
        let object_term = if self.check_number() {
            // Parse number as the comparison target
            let num_sym = if let TokenType::Number(sym) = self.advance().kind {
                sym
            } else {
                unreachable!()
            };
            let num_str = self.interner.resolve(num_sym);
            let num_val = num_str.parse::<i64>().unwrap_or(0);
            self.ctx.terms.alloc(Term::Value {
                kind: crate::ast::logic::NumberKind::Integer(num_val),
                unit: None,
                dimension: None,
            })
        } else {
            // Parse noun phrase as the comparison target
            let object = self.parse_noun_phrase(false)?;
            let obj_term = self.ctx.terms.alloc(Term::Constant(object.noun));

            let result = self.ctx.exprs.alloc(LogicExpr::Comparative {
                adjective: adj,
                subject: self.ctx.terms.alloc(Term::Constant(subject.noun)),
                object: obj_term,
                difference,
            });

            let result = self.wrap_with_definiteness(subject.definiteness, subject.noun, result)?;
            return self.wrap_with_definiteness_for_object(object.definiteness, object.noun, result);
        };

        // For number comparisons, create a simple Comparative expression
        Ok(self.ctx.exprs.alloc(LogicExpr::Comparative {
            adjective: adj,
            subject: self.ctx.terms.alloc(Term::Constant(subject.noun)),
            object: object_term,
            difference,
        }))
    }

    fn check_number(&self) -> bool {
        matches!(self.peek().kind, TokenType::Number(_))
    }

    fn parse_measure_phrase(&mut self) -> ParseResult<&'a Term<'a>> {
        let num_sym = if let TokenType::Number(sym) = self.advance().kind {
            sym
        } else {
            return Err(ParseError {
                kind: ParseErrorKind::ExpectedNumber,
                span: self.current_span(),
            });
        };

        let num_str = self.interner.resolve(num_sym);
        let kind = parse_number_kind(num_str, num_sym);

        let (unit, dimension) = if self.check_content_word() {
            let unit_word = self.consume_content_word()?;
            let unit_str = self.interner.resolve(unit_word).to_lowercase();
            let dim = lexicon::lookup_unit_dimension(&unit_str);
            (Some(unit_word), dim)
        } else {
            (None, None)
        };

        Ok(self.ctx.terms.alloc(Term::Value { kind, unit, dimension }))
    }
}

fn parse_number_kind(s: &str, sym: crate::intern::Symbol) -> NumberKind {
    if s.contains('.') {
        NumberKind::Real(s.parse().unwrap_or(0.0))
    } else if s.chars().all(|c| c.is_ascii_digit() || c == '-') {
        NumberKind::Integer(s.parse().unwrap_or(0))
    } else {
        NumberKind::Symbolic(sym)
    }
}

```

---

### Parser Constants

**File:** `src/parser/common.rs`

Shared constants for parser modules. COPULAS array defines copular verbs (is/are/was/were) for pattern matching.

```rust
use crate::token::TokenType;

pub const COPULAS: &[TokenType] = &[
    TokenType::Is,
    TokenType::Are,
    TokenType::Was,
    TokenType::Were,
];

```

---

### Parser Unit Tests

**File:** `src/parser/tests.rs`

Unit tests for parser internals: ParserGuard RAII behavior (guard_restores_all_fields_on_drop), check_any() semantic token matching. Tests verify checkpoint/restore mechanics and token set operations.

```rust
use super::*;
use crate::arena::Arena;
use crate::ast::NounPhrase;

#[test]
fn guard_restores_all_fields_on_drop() {
    let mut interner = Interner::new();
    let expr_arena: Arena<LogicExpr> = Arena::new();
    let term_arena: Arena<Term> = Arena::new();
    let np_arena: Arena<NounPhrase> = Arena::new();
    let sym_arena: Arena<Symbol> = Arena::new();
    let role_arena: Arena<(ThematicRole, Term)> = Arena::new();
    let pp_arena: Arena<&LogicExpr> = Arena::new();

    let ctx = AstContext::new(
        &expr_arena, &term_arena, &np_arena, &sym_arena, &role_arena, &pp_arena,
    );

    let mut lexer = Lexer::new("a b c d e", &mut interner);
    let tokens = lexer.tokenize();
    let mut parser = Parser::new(tokens, &mut interner, ctx);

    let initial_pos = parser.current;
    let initial_var_counter = parser.var_counter;
    let initial_bindings_len = parser.donkey_bindings.len();
    let initial_island = parser.current_island;
    let initial_time = parser.pending_time;

    {
        let mut guard = parser.guard();
        guard.current = 3;
        guard.var_counter = 99;
        guard.donkey_bindings.push((Symbol::EMPTY, Symbol::EMPTY, false, false));
        guard.current_island = 42;
        guard.pending_time = Some(Time::Past);
    }

    assert_eq!(parser.current, initial_pos, "position not restored");
    assert_eq!(parser.var_counter, initial_var_counter, "var_counter not restored");
    assert_eq!(parser.donkey_bindings.len(), initial_bindings_len, "bindings not restored");
    assert_eq!(parser.current_island, initial_island, "island not restored");
    assert_eq!(parser.pending_time, initial_time, "time not restored");
}

#[test]
fn guard_preserves_state_on_commit() {
    let mut interner = Interner::new();
    let expr_arena: Arena<LogicExpr> = Arena::new();
    let term_arena: Arena<Term> = Arena::new();
    let np_arena: Arena<NounPhrase> = Arena::new();
    let sym_arena: Arena<Symbol> = Arena::new();
    let role_arena: Arena<(ThematicRole, Term)> = Arena::new();
    let pp_arena: Arena<&LogicExpr> = Arena::new();

    let ctx = AstContext::new(
        &expr_arena, &term_arena, &np_arena, &sym_arena, &role_arena, &pp_arena,
    );

    let mut lexer = Lexer::new("a b c", &mut interner);
    let tokens = lexer.tokenize();
    let mut parser = Parser::new(tokens, &mut interner, ctx);

    {
        let mut guard = parser.guard();
        guard.current = 2;
        guard.var_counter = 50;
        guard.commit();
    }

    assert_eq!(parser.current, 2, "position should be preserved after commit");
    assert_eq!(parser.var_counter, 50, "var_counter should be preserved after commit");
}

#[test]
fn check_any_matches_wh_words() {
    let mut interner = Interner::new();
    let expr_arena: Arena<LogicExpr> = Arena::new();
    let term_arena: Arena<Term> = Arena::new();
    let np_arena: Arena<NounPhrase> = Arena::new();
    let sym_arena: Arena<Symbol> = Arena::new();
    let role_arena: Arena<(ThematicRole, Term)> = Arena::new();
    let pp_arena: Arena<&LogicExpr> = Arena::new();

    let ctx = AstContext::new(
        &expr_arena, &term_arena, &np_arena, &sym_arena, &role_arena, &pp_arena,
    );

    let mut lexer = Lexer::new("who what where", &mut interner);
    let tokens = lexer.tokenize();
    let mut parser = Parser::new(tokens, &mut interner, ctx);

    assert!(parser.check_any(TokenType::WH_WORDS));
    parser.current = 1;
    assert!(parser.check_any(TokenType::WH_WORDS));
    parser.current = 2;
    assert!(parser.check_any(TokenType::WH_WORDS));
}

#[test]
fn check_any_rejects_non_matching() {
    let mut interner = Interner::new();
    let expr_arena: Arena<LogicExpr> = Arena::new();
    let term_arena: Arena<Term> = Arena::new();
    let np_arena: Arena<NounPhrase> = Arena::new();
    let sym_arena: Arena<Symbol> = Arena::new();
    let role_arena: Arena<(ThematicRole, Term)> = Arena::new();
    let pp_arena: Arena<&LogicExpr> = Arena::new();

    let ctx = AstContext::new(
        &expr_arena, &term_arena, &np_arena, &sym_arena, &role_arena, &pp_arena,
    );

    let mut lexer = Lexer::new("if then", &mut interner);
    let tokens = lexer.tokenize();
    let parser = Parser::new(tokens, &mut interner, ctx);

    assert!(!parser.check_any(TokenType::WH_WORDS));
    assert!(!parser.check_any(TokenType::MODALS));
}

```

---

## Transpilation

The transpiler converts the AST into formal logical notation, supporting both Unicode mathematical symbols and LaTeX output.

**Location:** `src/transpile.rs`, `src/formatter.rs`, `src/registry.rs`

### Code Generation

**File:** `src/transpile.rs`

Converts AST to logical notation. Implements symbolic substitution, quantifier formatting, output mode selection (Unicode/LaTeX), Recipient thematic role rendering, and Causal expression transpilation. Term::Value output formats numeric values (Real/Integer/Symbolic) with optional unit strings. Comparative.difference renders measure phrases in degree expressions. Includes write_to() and write_logic() methods for zero-allocation output to any std::fmt::Write target.

```rust
use std::fmt::Write;

use crate::ast::{LogicExpr, NounPhrase, Term};
use crate::ast::logic::NumberKind;
use crate::formatter::{LatexFormatter, LogicFormatter, SimpleFOLFormatter, UnicodeFormatter};
use crate::intern::Interner;
use crate::registry::SymbolRegistry;
use crate::token::TokenType;
use crate::{OutputFormat, TranspileContext};

pub fn capitalize_first(s: &str) -> String {
    let mut chars = s.chars();
    match chars.next() {
        None => String::new(),
        Some(c) => c.to_uppercase().collect::<String>() + chars.as_str(),
    }
}

fn write_capitalized<W: Write>(w: &mut W, s: &str) -> std::fmt::Result {
    let mut chars = s.chars();
    match chars.next() {
        None => Ok(()),
        Some(c) => {
            for uc in c.to_uppercase() {
                write!(w, "{}", uc)?;
            }
            write!(w, "{}", chars.as_str())
        }
    }
}

impl<'a> NounPhrase<'a> {
    pub fn to_symbol(&self, registry: &mut SymbolRegistry, interner: &Interner) -> String {
        registry.get_symbol(self.noun, interner)
    }

    pub fn to_symbol_full(&self, registry: &SymbolRegistry, interner: &Interner) -> String {
        registry.get_symbol_full(self.noun, interner)
    }
}

impl<'a> Term<'a> {
    pub fn write_to<W: Write>(
        &self,
        w: &mut W,
        registry: &mut SymbolRegistry,
        interner: &Interner,
    ) -> std::fmt::Result {
        self.write_to_inner(w, registry, interner, false)
    }

    pub fn write_to_full<W: Write>(
        &self,
        w: &mut W,
        registry: &mut SymbolRegistry,
        interner: &Interner,
    ) -> std::fmt::Result {
        self.write_to_inner(w, registry, interner, true)
    }

    /// Write term preserving original case (for code generation)
    pub fn write_to_raw<W: Write>(
        &self,
        w: &mut W,
        interner: &Interner,
    ) -> std::fmt::Result {
        match self {
            Term::Constant(name) | Term::Variable(name) => {
                write!(w, "{}", interner.resolve(*name))
            }
            Term::Function(name, args) => {
                write!(w, "{}(", interner.resolve(*name))?;
                for (i, arg) in args.iter().enumerate() {
                    if i > 0 {
                        write!(w, ", ")?;
                    }
                    arg.write_to_raw(w, interner)?;
                }
                write!(w, ")")
            }
            Term::Group(members) => {
                write!(w, "(")?;
                for (i, m) in members.iter().enumerate() {
                    if i > 0 {
                        write!(w, ", ")?;
                    }
                    m.write_to_raw(w, interner)?;
                }
                write!(w, ")")
            }
            Term::Possessed { possessor, possessed } => {
                possessor.write_to_raw(w, interner)?;
                write!(w, ".{}", interner.resolve(*possessed))
            }
            Term::Value { kind, .. } => match kind {
                NumberKind::Integer(n) => write!(w, "{}", n),
                NumberKind::Real(f) => write!(w, "{}", f),
                NumberKind::Symbolic(s) => write!(w, "{}", interner.resolve(*s)),
            }
            Term::Sigma(predicate) => write!(w, "σ({})", interner.resolve(*predicate)),
            Term::Intension(predicate) => write!(w, "^{}", interner.resolve(*predicate)),
            Term::Proposition(expr) => write!(w, "[proposition]"),
        }
    }

    fn write_to_inner<W: Write>(
        &self,
        w: &mut W,
        registry: &mut SymbolRegistry,
        interner: &Interner,
        use_full_names: bool,
    ) -> std::fmt::Result {
        match self {
            Term::Constant(name) => {
                if use_full_names {
                    write!(w, "{}", registry.get_symbol_full(*name, interner))
                } else {
                    write!(w, "{}", registry.get_symbol(*name, interner))
                }
            }
            Term::Variable(name) => write!(w, "{}", interner.resolve(*name)),
            Term::Function(name, args) => {
                let fn_name = if use_full_names {
                    registry.get_symbol_full(*name, interner)
                } else {
                    registry.get_symbol(*name, interner)
                };
                write!(w, "{}(", fn_name)?;
                for (i, arg) in args.iter().enumerate() {
                    if i > 0 {
                        write!(w, ", ")?;
                    }
                    arg.write_to_inner(w, registry, interner, use_full_names)?;
                }
                write!(w, ")")
            }
            Term::Group(members) => {
                for (i, m) in members.iter().enumerate() {
                    if i > 0 {
                        write!(w, " ⊕ ")?;
                    }
                    m.write_to_inner(w, registry, interner, use_full_names)?;
                }
                Ok(())
            }
            Term::Possessed { possessor, possessed } => {
                let poss_name = if use_full_names {
                    registry.get_symbol_full(*possessed, interner)
                } else {
                    registry.get_symbol(*possessed, interner)
                };
                write!(w, "Poss(")?;
                possessor.write_to_inner(w, registry, interner, use_full_names)?;
                write!(w, ", {})", poss_name)
            }
            Term::Sigma(predicate) => {
                let pred_name = if use_full_names {
                    registry.get_symbol_full(*predicate, interner)
                } else {
                    registry.get_symbol(*predicate, interner)
                };
                write!(w, "σ{}", pred_name)
            }
            Term::Intension(predicate) => {
                // Use full word for intensional terms, not abbreviated symbol
                let word = interner.resolve(*predicate);
                let capitalized = word.chars().next()
                    .map(|c| c.to_uppercase().collect::<String>() + &word[1..])
                    .unwrap_or_default();
                write!(w, "^{}", capitalized)
            }
            Term::Proposition(expr) => {
                write!(w, "[")?;
                expr.write_logic(w, registry, interner, &UnicodeFormatter)?;
                write!(w, "]")
            }
            Term::Value { kind, unit, dimension: _ } => {
                use crate::ast::NumberKind;
                match kind {
                    NumberKind::Real(r) => write!(w, "{}", r)?,
                    NumberKind::Integer(i) => write!(w, "{}", i)?,
                    NumberKind::Symbolic(s) => write!(w, "{}", interner.resolve(*s))?,
                }
                if let Some(u) = unit {
                    write!(w, " {}", interner.resolve(*u))?;
                }
                Ok(())
            }
        }
    }

    pub fn transpile(&self, registry: &mut SymbolRegistry, interner: &Interner) -> String {
        let mut buf = String::new();
        let _ = self.write_to(&mut buf, registry, interner);
        buf
    }
}

impl<'a> LogicExpr<'a> {
    pub fn write_logic<W: Write, F: LogicFormatter>(
        &self,
        w: &mut W,
        registry: &mut SymbolRegistry,
        interner: &Interner,
        fmt: &F,
    ) -> std::fmt::Result {
        match self {
            LogicExpr::Predicate { name, args } => {
                let pred_name = if fmt.use_full_names() {
                    registry.get_symbol_full(*name, interner)
                } else {
                    registry.get_symbol(*name, interner)
                };
                fmt.write_predicate(w, &pred_name, args, registry, interner)
            }

            LogicExpr::Identity { left, right } => {
                if fmt.wrap_identity() {
                    write!(w, "(")?;
                }
                if fmt.preserve_case() {
                    left.write_to_raw(w, interner)?;
                } else if fmt.use_full_names() {
                    left.write_to_full(w, registry, interner)?;
                } else {
                    left.write_to(w, registry, interner)?;
                }
                write!(w, "{}", fmt.identity())?;
                if fmt.preserve_case() {
                    right.write_to_raw(w, interner)?;
                } else if fmt.use_full_names() {
                    right.write_to_full(w, registry, interner)?;
                } else {
                    right.write_to(w, registry, interner)?;
                }
                if fmt.wrap_identity() {
                    write!(w, ")")?;
                }
                Ok(())
            }

            LogicExpr::Metaphor { tenor, vehicle } => {
                write!(w, "Metaphor(")?;
                tenor.write_to(w, registry, interner)?;
                write!(w, ", ")?;
                vehicle.write_to(w, registry, interner)?;
                write!(w, ")")
            }

            LogicExpr::Quantifier { kind, variable, body, .. } => {
                let var_str = interner.resolve(*variable);

                // In SimpleFOL mode, skip event quantifiers (variables named "e" or starting with "e" followed by digits)
                if fmt.use_simple_events() && (var_str == "e" || var_str.starts_with("e") && var_str[1..].chars().all(|c| c.is_ascii_digit())) {
                    return body.write_logic(w, registry, interner, fmt);
                }

                let mut body_buf = String::new();
                body.write_logic(&mut body_buf, registry, interner, fmt)?;
                write!(w, "{}", fmt.quantifier(kind, var_str, &body_buf))
            }

            LogicExpr::Categorical(data) => {
                let s = if fmt.use_full_names() {
                    fmt.sanitize(&data.subject.to_symbol_full(registry, interner))
                } else {
                    fmt.sanitize(&data.subject.to_symbol(registry, interner))
                };
                let p = if fmt.use_full_names() {
                    fmt.sanitize(&data.predicate.to_symbol_full(registry, interner))
                } else {
                    fmt.sanitize(&data.predicate.to_symbol(registry, interner))
                };
                match (&data.quantifier, data.copula_negative) {
                    (TokenType::All, false) => write!(w, "{} {} is {}", fmt.categorical_all(), s, p),
                    (TokenType::No, false) => write!(w, "{} {} is {}", fmt.categorical_no(), s, p),
                    (TokenType::Some, false) => write!(w, "{} {} is {}", fmt.categorical_some(), s, p),
                    (TokenType::Some, true) => write!(w, "{} {} is {} {}", fmt.categorical_some(), s, fmt.categorical_not(), p),
                    (TokenType::All, true) => write!(w, "{} {} is {} {}", fmt.categorical_some(), s, fmt.categorical_not(), p),
                    _ => write!(w, "Invalid Syllogism"),
                }
            }

            LogicExpr::Relation(data) => {
                let s = if fmt.use_full_names() {
                    data.subject.to_symbol_full(registry, interner)
                } else {
                    data.subject.to_symbol(registry, interner)
                };
                let v = if fmt.use_full_names() {
                    fmt.sanitize(&registry.get_symbol_full(data.verb, interner))
                } else {
                    fmt.sanitize(&registry.get_symbol(data.verb, interner))
                };
                let o = if fmt.use_full_names() {
                    data.object.to_symbol_full(registry, interner)
                } else {
                    data.object.to_symbol(registry, interner)
                };
                write!(w, "{}({}, {})", v, s, o)
            }

            LogicExpr::Modal { vector, operand } => {
                let mut o = String::new();
                operand.write_logic(&mut o, registry, interner, fmt)?;
                write!(w, "{}", fmt.modal(vector.domain, vector.force, &o))
            }

            LogicExpr::BinaryOp { left, op, right } => {
                let mut l = String::new();
                let mut r = String::new();
                left.write_logic(&mut l, registry, interner, fmt)?;
                right.write_logic(&mut r, registry, interner, fmt)?;
                write!(w, "{}", fmt.binary_op(op, &l, &r))
            }

            LogicExpr::UnaryOp { op, operand } => {
                let mut o = String::new();
                operand.write_logic(&mut o, registry, interner, fmt)?;
                write!(w, "{}", fmt.unary_op(op, &o))
            }

            LogicExpr::Temporal { operator, body } => {
                let mut inner = String::new();
                body.write_logic(&mut inner, registry, interner, fmt)?;
                write!(w, "{}", fmt.temporal(operator, &inner))
            }

            LogicExpr::Aspectual { operator, body } => {
                let mut inner = String::new();
                body.write_logic(&mut inner, registry, interner, fmt)?;
                write!(w, "{}", fmt.aspectual(operator, &inner))
            }

            LogicExpr::Voice { operator, body } => {
                let mut inner = String::new();
                body.write_logic(&mut inner, registry, interner, fmt)?;
                write!(w, "{}", fmt.voice(operator, &inner))
            }

            LogicExpr::Question { wh_variable, body } => {
                let mut body_str = String::new();
                body.write_logic(&mut body_str, registry, interner, fmt)?;
                write!(w, "{}", fmt.lambda(interner.resolve(*wh_variable), &body_str))
            }

            LogicExpr::YesNoQuestion { body } => {
                write!(w, "?")?;
                body.write_logic(w, registry, interner, fmt)
            }

            LogicExpr::Atom(s) => {
                let name = if fmt.preserve_case() {
                    interner.resolve(*s).to_string()
                } else if fmt.use_full_names() {
                    registry.get_symbol_full(*s, interner)
                } else {
                    registry.get_symbol(*s, interner)
                };
                write!(w, "{}", fmt.sanitize(&name))
            }

            LogicExpr::Lambda { variable, body } => {
                let mut b = String::new();
                body.write_logic(&mut b, registry, interner, fmt)?;
                write!(w, "{}", fmt.lambda(interner.resolve(*variable), &b))
            }

            LogicExpr::App { function, argument } => {
                write!(w, "(")?;
                function.write_logic(w, registry, interner, fmt)?;
                write!(w, ")(")?;
                argument.write_logic(w, registry, interner, fmt)?;
                write!(w, ")")
            }

            LogicExpr::Intensional { operator, content } => {
                write!(w, "{}[", fmt.sanitize(&registry.get_symbol(*operator, interner)))?;
                content.write_logic(w, registry, interner, fmt)?;
                write!(w, "]")
            }

            LogicExpr::Event { predicate, adverbs } => {
                let mut pred_str = String::new();
                predicate.write_logic(&mut pred_str, registry, interner, fmt)?;
                let adverb_preds: Vec<String> = adverbs
                    .iter()
                    .map(|a| format!("{}(e)", fmt.sanitize(&registry.get_symbol(*a, interner))))
                    .collect();
                write!(w, "{}", fmt.event_quantifier(&pred_str, &adverb_preds))
            }

            LogicExpr::NeoEvent(data) => {
                use crate::ast::{QuantifierKind, ThematicRole};

                if fmt.use_simple_events() {
                    write!(w, "{}", registry.get_symbol_full(data.verb, interner))?;
                    write!(w, "(")?;
                    let mut first = true;
                    for (role, term) in data.roles.iter() {
                        // Include core thematic roles in SimpleFOL output
                        if matches!(role, ThematicRole::Agent | ThematicRole::Patient | ThematicRole::Theme | ThematicRole::Goal | ThematicRole::Location) {
                            if !first {
                                write!(w, ", ")?;
                            }
                            first = false;
                            term.write_to_full(w, registry, interner)?;
                        }
                    }
                    write!(w, ")")
                } else {
                    let e = interner.resolve(data.event_var);
                    let mut body = String::new();
                    write_capitalized(&mut body, interner.resolve(data.verb))?;
                    write!(body, "({})", e)?;
                    for (role, term) in data.roles.iter() {
                        let role_str = match role {
                            ThematicRole::Agent => "Agent",
                            ThematicRole::Patient => "Patient",
                            ThematicRole::Theme => "Theme",
                            ThematicRole::Recipient => "Recipient",
                            ThematicRole::Goal => "Goal",
                            ThematicRole::Source => "Source",
                            ThematicRole::Instrument => "Instrument",
                            ThematicRole::Location => "Location",
                            ThematicRole::Time => "Time",
                            ThematicRole::Manner => "Manner",
                        };
                        write!(body, " {} {}({}, ", fmt.and(), role_str, e)?;
                        if fmt.use_full_names() {
                            term.write_to_full(&mut body, registry, interner)?;
                        } else {
                            term.write_to(&mut body, registry, interner)?;
                        }
                        write!(body, ")")?;
                    }
                    for mod_sym in data.modifiers.iter() {
                        write!(body, " {} ", fmt.and())?;
                        write_capitalized(&mut body, interner.resolve(*mod_sym))?;
                        write!(body, "({})", e)?;
                    }
                    if data.suppress_existential {
                        // Event var will be bound by outer ∀ from DRS (generic conditionals)
                        write!(w, "{}", body)
                    } else {
                        // Normal case: emit ∃e(...)
                        write!(w, "{}", fmt.quantifier(&QuantifierKind::Existential, e, &body))
                    }
                }
            }

            LogicExpr::Imperative { action } => {
                write!(w, "!")?;
                action.write_logic(w, registry, interner, fmt)
            }

            LogicExpr::SpeechAct { performer, act_type, content } => {
                write!(w, "SpeechAct({}, {}, ", interner.resolve(*act_type), fmt.sanitize(&registry.get_symbol(*performer, interner)))?;
                content.write_logic(w, registry, interner, fmt)?;
                write!(w, ")")
            }

            LogicExpr::Counterfactual { antecedent, consequent } => {
                let mut a = String::new();
                let mut c = String::new();
                antecedent.write_logic(&mut a, registry, interner, fmt)?;
                consequent.write_logic(&mut c, registry, interner, fmt)?;
                write!(w, "{}", fmt.counterfactual(&a, &c))
            }

            LogicExpr::Causal { effect, cause } => {
                write!(w, "Cause(")?;
                cause.write_logic(w, registry, interner, fmt)?;
                write!(w, ", ")?;
                effect.write_logic(w, registry, interner, fmt)?;
                write!(w, ")")
            }

            LogicExpr::Comparative { adjective, subject, object, difference } => {
                let adj = interner.resolve(*adjective);
                let mut subj_buf = String::new();
                if fmt.preserve_case() {
                    subject.write_to_raw(&mut subj_buf, interner)?;
                } else {
                    subject.write_to(&mut subj_buf, registry, interner)?;
                }
                let mut obj_buf = String::new();
                if fmt.preserve_case() {
                    object.write_to_raw(&mut obj_buf, interner)?;
                } else {
                    object.write_to(&mut obj_buf, registry, interner)?;
                }
                let diff_str = if let Some(diff) = difference {
                    let mut diff_buf = String::new();
                    if fmt.preserve_case() {
                        diff.write_to_raw(&mut diff_buf, interner)?;
                    } else {
                        diff.write_to(&mut diff_buf, registry, interner)?;
                    }
                    Some(diff_buf)
                } else {
                    None
                };
                fmt.write_comparative(w, adj, &subj_buf, &obj_buf, diff_str.as_deref())
            }

            LogicExpr::Superlative { adjective, subject, domain } => {
                let mut s = String::new();
                subject.write_to(&mut s, registry, interner)?;
                let mut d = String::new();
                write_capitalized(&mut d, interner.resolve(*domain))?;
                let comp = format!("{}er", interner.resolve(*adjective));
                write!(w, "{}", fmt.superlative(&comp, &d, &s))
            }

            LogicExpr::Scopal { operator, body } => {
                write!(w, "{}(", interner.resolve(*operator))?;
                body.write_logic(w, registry, interner, fmt)?;
                write!(w, ")")
            }

            LogicExpr::TemporalAnchor { anchor, body } => {
                write!(w, "{}(", interner.resolve(*anchor))?;
                body.write_logic(w, registry, interner, fmt)?;
                write!(w, ")")
            }

            LogicExpr::Control { verb, subject, object, infinitive } => {
                write!(w, "{}(", fmt.sanitize(&registry.get_symbol(*verb, interner)))?;
                subject.write_to(w, registry, interner)?;
                if let Some(obj) = object {
                    write!(w, ", ")?;
                    obj.write_to(w, registry, interner)?;
                }
                write!(w, ", ")?;
                infinitive.write_logic(w, registry, interner, fmt)?;
                write!(w, ")")
            }

            LogicExpr::Presupposition { assertion, presupposition } => {
                assertion.write_logic(w, registry, interner, fmt)?;
                write!(w, " [Presup: ")?;
                presupposition.write_logic(w, registry, interner, fmt)?;
                write!(w, "]")
            }

            LogicExpr::Focus { kind, focused, scope } => {
                use crate::token::FocusKind;
                let prefix = match kind {
                    FocusKind::Only => "Only",
                    FocusKind::Even => "Even",
                    FocusKind::Just => "Just",
                };
                write!(w, "{}(", prefix)?;
                focused.write_to(w, registry, interner)?;
                write!(w, ", ")?;
                scope.write_logic(w, registry, interner, fmt)?;
                write!(w, ")")
            }

            LogicExpr::Distributive { predicate } => {
                write!(w, "*")?;
                predicate.write_logic(w, registry, interner, fmt)
            }

            LogicExpr::GroupQuantifier { group_var, count, member_var, restriction, body } => {
                let g = interner.resolve(*group_var);
                let x = interner.resolve(*member_var);

                // ∃g(Group(g) ∧ Count(g,n) ∧ ∀x(Member(x,g) → restriction) ∧ body)
                write!(w, "{}{}(Group({}) {} Count({}, {}) {} {}{}(Member({}, {}) {} ",
                    fmt.existential(), g, g,
                    fmt.and(), g, count,
                    fmt.and(), fmt.universal(), x, x, g, fmt.implies())?;

                restriction.write_logic(w, registry, interner, fmt)?;

                write!(w, ") {} ", fmt.and())?;

                body.write_logic(w, registry, interner, fmt)?;

                write!(w, ")")
            }
        }
    }

    pub fn transpile_with<F: LogicFormatter>(
        &self,
        registry: &mut SymbolRegistry,
        interner: &Interner,
        fmt: &F,
    ) -> String {
        let mut buf = String::new();
        let _ = self.write_logic(&mut buf, registry, interner, fmt);
        buf
    }

    pub fn transpile(
        &self,
        registry: &mut SymbolRegistry,
        interner: &Interner,
        format: OutputFormat,
    ) -> String {
        match format {
            OutputFormat::Unicode => self.transpile_with(registry, interner, &UnicodeFormatter),
            OutputFormat::LaTeX => self.transpile_with(registry, interner, &LatexFormatter),
            OutputFormat::SimpleFOL => self.transpile_with(registry, interner, &SimpleFOLFormatter),
        }
    }

    pub fn transpile_ctx<F: LogicFormatter>(
        &self,
        ctx: &mut TranspileContext<'_>,
        fmt: &F,
    ) -> String {
        self.transpile_with(ctx.registry, ctx.interner, fmt)
    }

    pub fn transpile_ctx_unicode(&self, ctx: &mut TranspileContext<'_>) -> String {
        self.transpile_ctx(ctx, &UnicodeFormatter)
    }

    pub fn transpile_ctx_latex(&self, ctx: &mut TranspileContext<'_>) -> String {
        self.transpile_ctx(ctx, &LatexFormatter)
    }
}

```

---

### Output Formatting

**File:** `src/formatter.rs`

LatexFormatter, UnicodeFormatter, and LogicFormatter traits. Handles symbol sanitization and operator rendering for clean output.

```rust
use std::fmt::Write;

use crate::ast::{AspectOperator, ModalDomain, QuantifierKind, TemporalOperator, Term, VoiceOperator};
use crate::intern::Interner;
use crate::registry::SymbolRegistry;
use crate::token::TokenType;

pub trait LogicFormatter {
    // Quantifiers
    fn quantifier(&self, kind: &QuantifierKind, var: &str, body: &str) -> String {
        let sym = match kind {
            QuantifierKind::Universal => self.universal(),
            QuantifierKind::Existential => self.existential(),
            QuantifierKind::Most => "MOST ".to_string(),
            QuantifierKind::Few => "FEW ".to_string(),
            QuantifierKind::Many => "MANY ".to_string(),
            QuantifierKind::Cardinal(n) => self.cardinal(*n),
            QuantifierKind::AtLeast(n) => self.at_least(*n),
            QuantifierKind::AtMost(n) => self.at_most(*n),
            QuantifierKind::Generic => "Gen ".to_string(),
        };
        format!("{}{}({})", sym, var, body)
    }

    fn universal(&self) -> String;
    fn existential(&self) -> String;
    fn cardinal(&self, n: u32) -> String;
    fn at_least(&self, n: u32) -> String;
    fn at_most(&self, n: u32) -> String;

    // Binary operators
    fn binary_op(&self, op: &TokenType, left: &str, right: &str) -> String {
        match op {
            TokenType::And => format!("({} {} {})", left, self.and(), right),
            TokenType::Or => format!("({} {} {})", left, self.or(), right),
            TokenType::If => format!("({} {} {})", left, self.implies(), right),
            TokenType::Iff => format!("({} {} {})", left, self.iff(), right),
            _ => String::new(),
        }
    }

    fn and(&self) -> &'static str;
    fn or(&self) -> &'static str;
    fn implies(&self) -> &'static str;
    fn iff(&self) -> &'static str;

    // Unary operators
    fn unary_op(&self, op: &TokenType, operand: &str) -> String {
        match op {
            TokenType::Not => format!("{}{}", self.not(), operand),
            _ => String::new(),
        }
    }

    fn not(&self) -> &'static str;

    // Identity operator (used in Identity expressions)
    fn identity(&self) -> &'static str {
        " = "
    }

    // Whether to wrap identity expressions in parentheses
    fn wrap_identity(&self) -> bool {
        false
    }

    // Modal operators
    fn modal(&self, domain: ModalDomain, force: f32, body: &str) -> String {
        let sym = match domain {
            ModalDomain::Alethic if force > 0.0 && force <= 0.5 => self.possibility(),
            ModalDomain::Alethic => self.necessity(),
            ModalDomain::Deontic if force <= 0.5 => "P",
            ModalDomain::Deontic => "O",
        };
        format!("{}_{{{:.1}}} {}", sym, force, body)
    }

    fn necessity(&self) -> &'static str;
    fn possibility(&self) -> &'static str;

    // Temporal operators
    fn temporal(&self, op: &TemporalOperator, body: &str) -> String {
        let sym = match op {
            TemporalOperator::Past => self.past(),
            TemporalOperator::Future => self.future(),
        };
        format!("{}({})", sym, body)
    }

    fn past(&self) -> &'static str;
    fn future(&self) -> &'static str;

    // Aspectual operators
    fn aspectual(&self, op: &AspectOperator, body: &str) -> String {
        let sym = match op {
            AspectOperator::Progressive => self.progressive(),
            AspectOperator::Perfect => self.perfect(),
            AspectOperator::Habitual => self.habitual(),
            AspectOperator::Iterative => self.iterative(),
        };
        format!("{}({})", sym, body)
    }

    fn progressive(&self) -> &'static str;
    fn perfect(&self) -> &'static str;
    fn habitual(&self) -> &'static str;
    fn iterative(&self) -> &'static str;

    // Voice operators
    fn voice(&self, op: &VoiceOperator, body: &str) -> String {
        let sym = match op {
            VoiceOperator::Passive => self.passive(),
        };
        format!("{}({})", sym, body)
    }

    fn passive(&self) -> &'static str;

    // Lambda
    fn lambda(&self, var: &str, body: &str) -> String;

    // Counterfactual
    fn counterfactual(&self, antecedent: &str, consequent: &str) -> String;

    // Superlative expansion
    fn superlative(&self, comp: &str, domain: &str, subject: &str) -> String;

    // Event quantification (uses existential + and)
    fn event_quantifier(&self, pred: &str, adverbs: &[String]) -> String {
        if adverbs.is_empty() {
            format!("{}e({})", self.existential(), pred)
        } else {
            let conj = self.and();
            format!(
                "{}e({} {} {})",
                self.existential(),
                pred,
                conj,
                adverbs.join(&format!(" {} ", conj))
            )
        }
    }

    // Categorical (legacy)
    fn categorical_all(&self) -> &'static str;
    fn categorical_no(&self) -> &'static str;
    fn categorical_some(&self) -> &'static str;
    fn categorical_not(&self) -> &'static str;

    // Sanitization hook for LaTeX special characters
    fn sanitize(&self, s: &str) -> String {
        s.to_string()
    }

    // Whether to use simple predicate form instead of event semantics
    fn use_simple_events(&self) -> bool {
        false
    }

    // Whether to use full predicate names instead of abbreviations
    fn use_full_names(&self) -> bool {
        false
    }

    // Whether to preserve original case (for code generation)
    fn preserve_case(&self) -> bool {
        false
    }

    /// Hook for customizing how comparatives are rendered.
    /// Default implementation uses standard logic notation: tallER(subj, obj) or tallER(subj, obj, diff)
    fn write_comparative<W: Write>(
        &self,
        w: &mut W,
        adjective: &str,
        subject: &str,
        object: &str,
        difference: Option<&str>,
    ) -> std::fmt::Result {
        if let Some(diff) = difference {
            write!(w, "{}er({}, {}, {})", adjective, subject, object, diff)
        } else {
            write!(w, "{}er({}, {})", adjective, subject, object)
        }
    }

    /// Hook for customizing how predicates are rendered.
    /// Default implementation uses standard logic notation: Name(Arg1, Arg2)
    fn write_predicate<W: Write>(
        &self,
        w: &mut W,
        name: &str,
        args: &[Term],
        registry: &mut SymbolRegistry,
        interner: &Interner,
    ) -> std::fmt::Result {
        write!(w, "{}(", self.sanitize(name))?;
        for (i, arg) in args.iter().enumerate() {
            if i > 0 {
                write!(w, ", ")?;
            }
            if self.use_full_names() {
                arg.write_to_full(w, registry, interner)?;
            } else {
                arg.write_to(w, registry, interner)?;
            }
        }
        write!(w, ")")
    }
}

pub struct UnicodeFormatter;

impl LogicFormatter for UnicodeFormatter {
    fn universal(&self) -> String { "∀".to_string() }
    fn existential(&self) -> String { "∃".to_string() }
    fn cardinal(&self, n: u32) -> String { format!("∃={}.", n) }
    fn at_least(&self, n: u32) -> String { format!("∃≥{}", n) }
    fn at_most(&self, n: u32) -> String { format!("∃≤{}", n) }

    fn and(&self) -> &'static str { "∧" }
    fn or(&self) -> &'static str { "∨" }
    fn implies(&self) -> &'static str { "→" }
    fn iff(&self) -> &'static str { "↔" }
    fn not(&self) -> &'static str { "¬" }

    fn necessity(&self) -> &'static str { "□" }
    fn possibility(&self) -> &'static str { "◇" }

    fn past(&self) -> &'static str { "P" }
    fn future(&self) -> &'static str { "F" }

    fn progressive(&self) -> &'static str { "Prog" }
    fn perfect(&self) -> &'static str { "Perf" }
    fn habitual(&self) -> &'static str { "HAB" }
    fn iterative(&self) -> &'static str { "ITER" }
    fn passive(&self) -> &'static str { "Pass" }

    fn lambda(&self, var: &str, body: &str) -> String {
        format!("λ{}.{}", var, body)
    }

    fn counterfactual(&self, antecedent: &str, consequent: &str) -> String {
        format!("({} □→ {})", antecedent, consequent)
    }

    fn superlative(&self, comp: &str, domain: &str, subject: &str) -> String {
        format!(
            "∀x(({}(x) ∧ x ≠ {}) → {}({}, x))",
            domain, subject, comp, subject
        )
    }

    fn categorical_all(&self) -> &'static str { "∀" }
    fn categorical_no(&self) -> &'static str { "∀¬" }
    fn categorical_some(&self) -> &'static str { "∃" }
    fn categorical_not(&self) -> &'static str { "¬" }

    // Use full predicate names (e.g., "Wet" not "W")
    fn use_full_names(&self) -> bool { true }
}

pub struct LatexFormatter;

impl LogicFormatter for LatexFormatter {
    fn universal(&self) -> String { "\\forall ".to_string() }
    fn existential(&self) -> String { "\\exists ".to_string() }
    fn cardinal(&self, n: u32) -> String { format!("\\exists_{{={}}} ", n) }
    fn at_least(&self, n: u32) -> String { format!("\\exists_{{\\geq {}}} ", n) }
    fn at_most(&self, n: u32) -> String { format!("\\exists_{{\\leq {}}} ", n) }

    fn and(&self) -> &'static str { "\\cdot" }
    fn or(&self) -> &'static str { "\\vee" }
    fn implies(&self) -> &'static str { "\\supset" }
    fn iff(&self) -> &'static str { "\\equiv" }
    fn not(&self) -> &'static str { "\\sim " }

    fn necessity(&self) -> &'static str { "\\Box" }
    fn possibility(&self) -> &'static str { "\\Diamond" }

    fn past(&self) -> &'static str { "\\mathsf{P}" }
    fn future(&self) -> &'static str { "\\mathsf{F}" }

    fn progressive(&self) -> &'static str { "\\mathsf{Prog}" }
    fn perfect(&self) -> &'static str { "\\mathsf{Perf}" }
    fn habitual(&self) -> &'static str { "\\mathsf{HAB}" }
    fn iterative(&self) -> &'static str { "\\mathsf{ITER}" }
    fn passive(&self) -> &'static str { "\\mathsf{Pass}" }

    fn lambda(&self, var: &str, body: &str) -> String {
        format!("\\lambda {}.{}", var, body)
    }

    fn counterfactual(&self, antecedent: &str, consequent: &str) -> String {
        format!("({} \\boxright {})", antecedent, consequent)
    }

    fn superlative(&self, comp: &str, domain: &str, subject: &str) -> String {
        format!(
            "\\forall x(({}(x) \\land x \\neq {}) \\supset {}({}, x))",
            domain, subject, comp, subject
        )
    }

    fn categorical_all(&self) -> &'static str { "All" }
    fn categorical_no(&self) -> &'static str { "No" }
    fn categorical_some(&self) -> &'static str { "Some" }
    fn categorical_not(&self) -> &'static str { "not" }

    fn sanitize(&self, s: &str) -> String {
        s.replace('_', r"\_")
            .replace('^', r"\^{}")
            .replace('&', r"\&")
            .replace('%', r"\%")
            .replace('#', r"\#")
            .replace('$', r"\$")
    }
}

pub struct SimpleFOLFormatter;

impl LogicFormatter for SimpleFOLFormatter {
    fn universal(&self) -> String { "∀".to_string() }
    fn existential(&self) -> String { "∃".to_string() }
    fn cardinal(&self, n: u32) -> String { format!("∃={}", n) }
    fn at_least(&self, n: u32) -> String { format!("∃≥{}", n) }
    fn at_most(&self, n: u32) -> String { format!("∃≤{}", n) }

    fn and(&self) -> &'static str { "∧" }
    fn or(&self) -> &'static str { "∨" }
    fn implies(&self) -> &'static str { "→" }
    fn iff(&self) -> &'static str { "↔" }
    fn not(&self) -> &'static str { "¬" }

    fn necessity(&self) -> &'static str { "□" }
    fn possibility(&self) -> &'static str { "◇" }

    fn past(&self) -> &'static str { "Past" }
    fn future(&self) -> &'static str { "Future" }

    fn progressive(&self) -> &'static str { "" }
    fn perfect(&self) -> &'static str { "" }
    fn habitual(&self) -> &'static str { "" }
    fn iterative(&self) -> &'static str { "" }
    fn passive(&self) -> &'static str { "" }

    fn lambda(&self, var: &str, body: &str) -> String {
        format!("λ{}.{}", var, body)
    }

    fn counterfactual(&self, antecedent: &str, consequent: &str) -> String {
        format!("({} □→ {})", antecedent, consequent)
    }

    fn superlative(&self, comp: &str, domain: &str, subject: &str) -> String {
        format!(
            "∀x(({}(x) ∧ x ≠ {}) → {}({}, x))",
            domain, subject, comp, subject
        )
    }

    fn categorical_all(&self) -> &'static str { "∀" }
    fn categorical_no(&self) -> &'static str { "∀¬" }
    fn categorical_some(&self) -> &'static str { "∃" }
    fn categorical_not(&self) -> &'static str { "¬" }

    fn modal(&self, _domain: ModalDomain, _force: f32, body: &str) -> String {
        body.to_string()
    }

    fn aspectual(&self, _op: &AspectOperator, body: &str) -> String {
        body.to_string()
    }

    fn use_simple_events(&self) -> bool {
        true
    }

    fn use_full_names(&self) -> bool {
        true
    }
}

/// Formatter that produces Rust boolean expressions for runtime assertions.
/// Used by codegen to convert LogicExpr into debug_assert!() compatible code.
pub struct RustFormatter;

impl LogicFormatter for RustFormatter {
    // Operators map to Rust boolean operators
    fn and(&self) -> &'static str { "&&" }
    fn or(&self) -> &'static str { "||" }
    fn not(&self) -> &'static str { "!" }
    fn implies(&self) -> &'static str { "||" } // Handled via binary_op override
    fn iff(&self) -> &'static str { "==" }
    fn identity(&self) -> &'static str { " == " } // Rust equality
    fn wrap_identity(&self) -> bool { true } // Wrap in parens for valid Rust

    // Use full variable names, not abbreviations
    fn use_full_names(&self) -> bool { true }
    fn preserve_case(&self) -> bool { true } // Keep original variable case

    // Quantifiers: runtime can't check universal quantification, emit comments
    fn universal(&self) -> String { "/* ∀ */".to_string() }
    fn existential(&self) -> String { "/* ∃ */".to_string() }
    fn cardinal(&self, n: u32) -> String { format!("/* ∃={} */", n) }
    fn at_least(&self, n: u32) -> String { format!("/* ∃≥{} */", n) }
    fn at_most(&self, n: u32) -> String { format!("/* ∃≤{} */", n) }

    // Modal/Temporal operators are stripped for runtime (not checkable)
    fn necessity(&self) -> &'static str { "" }
    fn possibility(&self) -> &'static str { "" }
    fn past(&self) -> &'static str { "" }
    fn future(&self) -> &'static str { "" }
    fn progressive(&self) -> &'static str { "" }
    fn perfect(&self) -> &'static str { "" }
    fn habitual(&self) -> &'static str { "" }
    fn iterative(&self) -> &'static str { "" }
    fn passive(&self) -> &'static str { "" }
    fn categorical_all(&self) -> &'static str { "" }
    fn categorical_no(&self) -> &'static str { "" }
    fn categorical_some(&self) -> &'static str { "" }
    fn categorical_not(&self) -> &'static str { "" }

    fn lambda(&self, var: &str, body: &str) -> String {
        format!("|{}| {{ {} }}", var, body)
    }

    fn counterfactual(&self, a: &str, c: &str) -> String {
        format!("/* if {} then {} */", a, c)
    }

    fn superlative(&self, _: &str, _: &str, _: &str) -> String {
        "/* superlative */".to_string()
    }

    // Override comparative for Rust: map adjectives to comparison operators
    fn write_comparative<W: Write>(
        &self,
        w: &mut W,
        adjective: &str,
        subject: &str,
        object: &str,
        _difference: Option<&str>,
    ) -> std::fmt::Result {
        let adj_lower = adjective.to_lowercase();
        match adj_lower.as_str() {
            "great" | "big" | "large" | "tall" | "old" | "high" | "more" | "greater" => {
                write!(w, "({} > {})", subject, object)
            }
            "small" | "little" | "short" | "young" | "low" | "less" | "fewer" => {
                write!(w, "({} < {})", subject, object)
            }
            _ => write!(w, "({} > {})", subject, object) // default to greater-than
        }
    }

    // Override unary_op to wrap in parens for valid Rust
    fn unary_op(&self, op: &TokenType, operand: &str) -> String {
        match op {
            TokenType::Not => format!("(!{})", operand),
            _ => format!("/* unknown unary */({})", operand),
        }
    }

    // Override binary_op for implication desugaring: A → B = !A || B
    fn binary_op(&self, op: &TokenType, left: &str, right: &str) -> String {
        match op {
            TokenType::If | TokenType::Then => format!("(!({}) || ({}))", left, right),
            TokenType::And => format!("({} && {})", left, right),
            TokenType::Or => format!("({} || {})", left, right),
            TokenType::Iff => format!("({} == {})", left, right),
            _ => "/* unknown op */".to_string(),
        }
    }

    // Core predicate mapping: semantic interpretation of predicates to Rust operators
    fn write_predicate<W: Write>(
        &self,
        w: &mut W,
        name: &str,
        args: &[Term],
        _registry: &mut SymbolRegistry,
        interner: &Interner,
    ) -> std::fmt::Result {
        // Helper to render a term at given index to a string, preserving original case
        let render = |idx: usize| -> String {
            let mut buf = String::new();
            if let Some(arg) = args.get(idx) {
                let _ = arg.write_to_raw(&mut buf, interner);
            }
            buf
        };

        match name.to_lowercase().as_str() {
            // Comparisons
            "greater" if args.len() == 2 => write!(w, "({} > {})", render(0), render(1)),
            "less" if args.len() == 2 => write!(w, "({} < {})", render(0), render(1)),
            "equal" | "equals" if args.len() == 2 => write!(w, "({} == {})", render(0), render(1)),
            "notequal" | "not_equal" if args.len() == 2 => write!(w, "({} != {})", render(0), render(1)),
            "greaterequal" | "atleast" | "at_least" if args.len() == 2 => write!(w, "({} >= {})", render(0), render(1)),
            "lessequal" | "atmost" | "at_most" if args.len() == 2 => write!(w, "({} <= {})", render(0), render(1)),

            // Unary checks
            "positive" if args.len() == 1 => write!(w, "({} > 0)", render(0)),
            "negative" if args.len() == 1 => write!(w, "({} < 0)", render(0)),
            "zero" if args.len() == 1 => write!(w, "({} == 0)", render(0)),
            "empty" if args.len() == 1 => write!(w, "{}.is_empty()", render(0)),

            // Collection membership
            "in" if args.len() == 2 => write!(w, "{}.contains(&{})", render(1), render(0)),
            "contains" if args.len() == 2 => write!(w, "{}.contains(&{})", render(0), render(1)),

            // Fallback: method call for 1 arg, function call for N args
            _ if args.len() == 1 => write!(w, "{}.is_{}()", render(0), name.to_lowercase()),
            _ => {
                write!(w, "{}(", name.to_lowercase())?;
                for i in 0..args.len() {
                    if i > 0 { write!(w, ", ")?; }
                    write!(w, "{}", render(i))?;
                }
                write!(w, ")")
            }
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn unicode_binary_operators() {
        let f = UnicodeFormatter;
        assert_eq!(f.binary_op(&TokenType::And, "P", "Q"), "(P ∧ Q)");
        assert_eq!(f.binary_op(&TokenType::Or, "P", "Q"), "(P ∨ Q)");
        assert_eq!(f.binary_op(&TokenType::If, "P", "Q"), "(P → Q)");
        assert_eq!(f.binary_op(&TokenType::Iff, "P", "Q"), "(P ↔ Q)");
    }

    #[test]
    fn latex_binary_operators() {
        let f = LatexFormatter;
        assert_eq!(f.binary_op(&TokenType::And, "P", "Q"), r"(P \cdot Q)");
        assert_eq!(f.binary_op(&TokenType::Or, "P", "Q"), r"(P \vee Q)");
        assert_eq!(f.binary_op(&TokenType::If, "P", "Q"), r"(P \supset Q)");
        assert_eq!(f.binary_op(&TokenType::Iff, "P", "Q"), r"(P \equiv Q)");
    }

    #[test]
    fn unicode_quantifiers() {
        let f = UnicodeFormatter;
        assert_eq!(f.quantifier(&QuantifierKind::Universal, "x", "P(x)"), "∀x(P(x))");
        assert_eq!(f.quantifier(&QuantifierKind::Existential, "x", "P(x)"), "∃x(P(x))");
        assert_eq!(f.quantifier(&QuantifierKind::Cardinal(3), "x", "P(x)"), "∃=3.x(P(x))");
    }

    #[test]
    fn latex_quantifiers() {
        let f = LatexFormatter;
        assert_eq!(f.quantifier(&QuantifierKind::Universal, "x", "P(x)"), "\\forall x(P(x))");
        assert_eq!(f.quantifier(&QuantifierKind::Existential, "x", "P(x)"), "\\exists x(P(x))");
    }

    #[test]
    fn latex_sanitization() {
        let f = LatexFormatter;
        assert_eq!(f.sanitize("foo_bar"), r"foo\_bar");
        assert_eq!(f.sanitize("x^2"), r"x\^{}2");
        assert_eq!(f.sanitize("a&b"), r"a\&b");
    }

    #[test]
    fn unicode_no_sanitization() {
        let f = UnicodeFormatter;
        assert_eq!(f.sanitize("foo_bar"), "foo_bar");
    }

    #[test]
    fn unicode_lambda() {
        let f = UnicodeFormatter;
        assert_eq!(f.lambda("x", "P(x)"), "λx.P(x)");
    }

    #[test]
    fn latex_lambda() {
        let f = LatexFormatter;
        assert_eq!(f.lambda("x", "P(x)"), "\\lambda x.P(x)");
    }

    #[test]
    fn unicode_counterfactual() {
        let f = UnicodeFormatter;
        assert_eq!(f.counterfactual("P", "Q"), "(P □→ Q)");
    }

    #[test]
    fn latex_counterfactual() {
        let f = LatexFormatter;
        assert_eq!(f.counterfactual("P", "Q"), r"(P \boxright Q)");
    }

    // RustFormatter tests
    #[test]
    fn rust_binary_operators() {
        let f = RustFormatter;
        assert_eq!(f.binary_op(&TokenType::And, "P", "Q"), "(P && Q)");
        assert_eq!(f.binary_op(&TokenType::Or, "P", "Q"), "(P || Q)");
        assert_eq!(f.binary_op(&TokenType::Iff, "P", "Q"), "(P == Q)");
    }

    #[test]
    fn rust_implication_desugaring() {
        let f = RustFormatter;
        // A → B desugars to !A || B
        assert_eq!(f.binary_op(&TokenType::If, "P", "Q"), "(!(P) || (Q))");
    }

    #[test]
    fn rust_lambda() {
        let f = RustFormatter;
        assert_eq!(f.lambda("x", "x > 0"), "|x| { x > 0 }");
    }

    #[test]
    fn rust_quantifiers_as_comments() {
        let f = RustFormatter;
        assert_eq!(f.universal(), "/* ∀ */");
        assert_eq!(f.existential(), "/* ∃ */");
    }
}

```

---

### Symbol Registry

**File:** `src/registry.rs`

Maps interned symbols to readable output strings. Manages predicate and constant naming conventions.

```rust
use std::collections::HashMap;
use crate::intern::{Interner, Symbol};

pub struct SymbolRegistry {
    mapping: HashMap<String, String>,
    counters: HashMap<char, usize>,
}

impl SymbolRegistry {
    pub fn new() -> Self {
        SymbolRegistry {
            mapping: HashMap::new(),
            counters: HashMap::new(),
        }
    }

    pub fn get_symbol_full(&self, sym: Symbol, interner: &Interner) -> String {
        let word = interner.resolve(sym);
        let mut chars = word.chars();
        match chars.next() {
            Some(c) => c.to_uppercase().collect::<String>() + chars.as_str(),
            None => String::new(),
        }
    }

    pub fn get_symbol(&mut self, sym: Symbol, interner: &Interner) -> String {
        let word = interner.resolve(sym);
        let normalized = word.to_lowercase();

        if let Some(sym) = self.mapping.get(&normalized) {
            return sym.clone();
        }

        // For hyphenated compounds (non-intersective adjectives), return full form
        // "fake-gun" → "Fake-Gun" (not "F")
        if word.contains('-') {
            let compound: String = word
                .split('-')
                .map(|part| {
                    let mut chars = part.chars();
                    match chars.next() {
                        Some(c) => c.to_uppercase().collect::<String>() + chars.as_str(),
                        None => String::new(),
                    }
                })
                .collect::<Vec<_>>()
                .join("-");
            self.mapping.insert(normalized, compound.clone());
            return compound;
        }

        // Preserve specific relational terms (bridging markers)
        const PRESERVED_TERMS: &[&str] = &["PartOf"];
        if PRESERVED_TERMS.iter().any(|t| t.eq_ignore_ascii_case(word)) {
            self.mapping.insert(normalized, word.to_string());
            return word.to_string();
        }

        let first = normalized
            .chars()
            .next()
            .unwrap()
            .to_uppercase()
            .next()
            .unwrap();

        let counter = self.counters.entry(first).or_insert(0);
        *counter += 1;

        let symbol = if *counter == 1 {
            first.to_string()
        } else {
            format!("{}{}", first, counter)
        };

        self.mapping.insert(normalized, symbol.clone());
        symbol
    }
}

impl Default for SymbolRegistry {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn first_word_gets_single_letter() {
        let mut interner = Interner::new();
        let mut reg = SymbolRegistry::new();
        let dog = interner.intern("dog");
        assert_eq!(reg.get_symbol(dog, &interner), "D");
    }

    #[test]
    fn second_word_same_letter_gets_numbered() {
        let mut interner = Interner::new();
        let mut reg = SymbolRegistry::new();
        let dog = interner.intern("dog");
        let dangerous = interner.intern("dangerous");
        reg.get_symbol(dog, &interner);
        assert_eq!(reg.get_symbol(dangerous, &interner), "D2");
    }

    #[test]
    fn same_word_returns_same_symbol() {
        let mut interner = Interner::new();
        let mut reg = SymbolRegistry::new();
        let cat = interner.intern("cat");
        let first = reg.get_symbol(cat, &interner);
        let second = reg.get_symbol(cat, &interner);
        assert_eq!(first, second);
    }

    #[test]
    fn case_insensitive() {
        let mut interner = Interner::new();
        let mut reg = SymbolRegistry::new();
        let dog = interner.intern("dog");
        let dog_upper = interner.intern("DOG");
        let lower = reg.get_symbol(dog, &interner);
        let upper = reg.get_symbol(dog_upper, &interner);
        assert_eq!(lower, upper);
    }
}

```

---

## Semantic Analysis

Advanced semantic computation using lambda calculus for compositional meaning construction.

**Location:** `src/lambda.rs`, `src/context.rs`, `src/view.rs`

### Lambda Calculus

**File:** `src/lambda.rs`

Lambda calculus core with Montague-style compositional semantics. Features: Lambda abstraction, application, and beta reduction. **Quantifier Scope Enumeration** via enumerate_scopings() returning lazy ScopeIterator. **Complexity:** Factorial O(n!) worst-case, optimized by Island constraints to Π(k_i!). **Island Constraints:** Scope boundaries (if/and/or) prevent cross-island quantifier movement. **Intensionality (De Re/De Dicto):** enumerate_intensional_readings() for opaque verbs (seek, want, believe, need, fear). **Opacity-Respecting Substitution:** substitute_respecting_opacity() blocks substitution inside intensional contexts. **Montague Up-Arrow:** Term::Intension(^P) for de dicto readings.

```rust
use crate::arena::Arena;
use crate::ast::{LogicExpr, QuantifierKind, Term};
use crate::intern::{Interner, Symbol};
use crate::lexicon;
use crate::token::TokenType;

fn clone_term<'a>(term: &Term<'a>, arena: &'a Arena<Term<'a>>) -> Term<'a> {
    match term {
        Term::Constant(s) => Term::Constant(*s),
        Term::Variable(s) => Term::Variable(*s),
        Term::Function(name, args) => {
            let cloned_args: Vec<Term<'a>> = args.iter().map(|t| clone_term(t, arena)).collect();
            Term::Function(*name, arena.alloc_slice(cloned_args))
        }
        Term::Group(members) => {
            let cloned: Vec<Term<'a>> = members.iter().map(|t| clone_term(t, arena)).collect();
            Term::Group(arena.alloc_slice(cloned))
        }
        Term::Possessed { possessor, possessed } => Term::Possessed {
            possessor: arena.alloc(clone_term(possessor, arena)),
            possessed: *possessed,
        },
        Term::Sigma(predicate) => Term::Sigma(*predicate),
        Term::Intension(predicate) => Term::Intension(*predicate),
        Term::Proposition(expr) => Term::Proposition(*expr),
        Term::Value { kind, unit, dimension } => Term::Value {
            kind: *kind,
            unit: *unit,
            dimension: *dimension,
        },
    }
}

pub fn is_opaque_verb(verb: Symbol, interner: &Interner) -> bool {
    let verb_str = interner.resolve(verb);
    let lower = verb_str.to_lowercase();
    lexicon::is_opaque_verb(&lower)
}

pub fn make_intensional<'a>(
    operator: Symbol,
    content: &'a LogicExpr<'a>,
    arena: &'a Arena<LogicExpr<'a>>,
) -> &'a LogicExpr<'a> {
    arena.alloc(LogicExpr::Intensional { operator, content })
}

pub fn substitute_respecting_opacity<'a>(
    expr: &'a LogicExpr<'a>,
    var: Symbol,
    replacement: &'a LogicExpr<'a>,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
) -> &'a LogicExpr<'a> {
    match expr {
        LogicExpr::Intensional { operator, content } => {
            expr_arena.alloc(LogicExpr::Intensional {
                operator: *operator,
                content: *content,
            })
        }

        LogicExpr::Predicate { name, args } => {
            let new_args: Vec<Term<'a>> = args
                .iter()
                .map(|arg| substitute_term_for_opacity(arg, var, replacement, term_arena))
                .collect();
            expr_arena.alloc(LogicExpr::Predicate {
                name: *name,
                args: term_arena.alloc_slice(new_args),
            })
        }

        LogicExpr::BinaryOp { left, op, right } => expr_arena.alloc(LogicExpr::BinaryOp {
            left: substitute_respecting_opacity(left, var, replacement, expr_arena, term_arena),
            op: op.clone(),
            right: substitute_respecting_opacity(right, var, replacement, expr_arena, term_arena),
        }),

        LogicExpr::UnaryOp { op, operand } => expr_arena.alloc(LogicExpr::UnaryOp {
            op: op.clone(),
            operand: substitute_respecting_opacity(operand, var, replacement, expr_arena, term_arena),
        }),

        LogicExpr::Quantifier { kind, variable, body, island_id } => {
            if *variable == var {
                expr
            } else {
                expr_arena.alloc(LogicExpr::Quantifier {
                    kind: *kind,
                    variable: *variable,
                    body: substitute_respecting_opacity(body, var, replacement, expr_arena, term_arena),
                    island_id: *island_id,
                })
            }
        }

        LogicExpr::Lambda { variable, body } => {
            if *variable == var {
                expr
            } else {
                expr_arena.alloc(LogicExpr::Lambda {
                    variable: *variable,
                    body: substitute_respecting_opacity(body, var, replacement, expr_arena, term_arena),
                })
            }
        }

        LogicExpr::App { function, argument } => expr_arena.alloc(LogicExpr::App {
            function: substitute_respecting_opacity(function, var, replacement, expr_arena, term_arena),
            argument: substitute_respecting_opacity(argument, var, replacement, expr_arena, term_arena),
        }),

        LogicExpr::Atom(s) => {
            if *s == var {
                replacement
            } else {
                expr
            }
        }

        _ => expr,
    }
}

fn substitute_term_for_opacity<'a>(
    term: &Term<'a>,
    var: Symbol,
    replacement: &LogicExpr<'a>,
    arena: &'a Arena<Term<'a>>,
) -> Term<'a> {
    match term {
        Term::Constant(c) if *c == var => {
            match replacement {
                LogicExpr::Atom(s) => Term::Constant(*s),
                _ => clone_term(term, arena),
            }
        }
        Term::Variable(v) if *v == var => {
            match replacement {
                LogicExpr::Atom(s) => Term::Constant(*s),
                _ => clone_term(term, arena),
            }
        }
        _ => clone_term(term, arena),
    }
}

pub fn to_event_semantics<'a>(
    expr: &'a LogicExpr<'a>,
    interner: &mut Interner,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
) -> &'a LogicExpr<'a> {
    match expr {
        LogicExpr::Predicate { name, args } => {
            let e_sym = interner.intern("e");
            let _event_var = term_arena.alloc(Term::Variable(e_sym));

            let event_pred = expr_arena.alloc(LogicExpr::Predicate {
                name: *name,
                args: term_arena.alloc_slice([Term::Variable(e_sym)]),
            });

            let mut body = event_pred;

            if !args.is_empty() {
                let agent_args = term_arena.alloc_slice([Term::Variable(e_sym), clone_term(&args[0], term_arena)]);
                let agent_pred = expr_arena.alloc(LogicExpr::Predicate {
                    name: interner.intern("Agent"),
                    args: agent_args,
                });
                body = expr_arena.alloc(LogicExpr::BinaryOp {
                    left: body,
                    op: TokenType::And,
                    right: agent_pred,
                });
            }

            if args.len() > 1 {
                let theme_args = term_arena.alloc_slice([Term::Variable(e_sym), clone_term(&args[1], term_arena)]);
                let theme_pred = expr_arena.alloc(LogicExpr::Predicate {
                    name: interner.intern("Theme"),
                    args: theme_args,
                });
                body = expr_arena.alloc(LogicExpr::BinaryOp {
                    left: body,
                    op: TokenType::And,
                    right: theme_pred,
                });
            }

            if args.len() > 2 {
                let goal_args = term_arena.alloc_slice([Term::Variable(e_sym), clone_term(&args[2], term_arena)]);
                let goal_pred = expr_arena.alloc(LogicExpr::Predicate {
                    name: interner.intern("Goal"),
                    args: goal_args,
                });
                body = expr_arena.alloc(LogicExpr::BinaryOp {
                    left: body,
                    op: TokenType::And,
                    right: goal_pred,
                });
            }

            expr_arena.alloc(LogicExpr::Quantifier {
                kind: QuantifierKind::Existential,
                variable: e_sym,
                body,
                island_id: 0,
            })
        }
        _ => expr,
    }
}

pub fn apply_adverb<'a>(
    expr: &'a LogicExpr<'a>,
    adverb: Symbol,
    interner: &mut Interner,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
) -> &'a LogicExpr<'a> {
    let e_sym = interner.intern("e");
    match expr {
        LogicExpr::Quantifier { kind, variable, body, island_id } if *variable == e_sym => {
            let adverb_str = interner.resolve(adverb);
            let capitalized = capitalize(adverb_str);
            let adverb_pred = expr_arena.alloc(LogicExpr::Predicate {
                name: interner.intern(&capitalized),
                args: term_arena.alloc_slice([Term::Variable(*variable)]),
            });

            let new_body = expr_arena.alloc(LogicExpr::BinaryOp {
                left: *body,
                op: TokenType::And,
                right: adverb_pred,
            });

            expr_arena.alloc(LogicExpr::Quantifier {
                kind: *kind,
                variable: *variable,
                body: new_body,
                island_id: *island_id,
            })
        }
        _ => expr,
    }
}

fn capitalize(s: &str) -> String {
    let mut chars = s.chars();
    match chars.next() {
        None => String::new(),
        Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
    }
}

fn factorial(n: usize) -> u64 {
    (1..=n as u64).product()
}

pub struct ScopeIterator<'a> {
    expr_arena: &'a Arena<LogicExpr<'a>>,
    islands: Vec<Vec<ScopalElement<'a>>>,
    core: &'a LogicExpr<'a>,
    current_index: u64,
    total: u64,
    single_result: Option<&'a LogicExpr<'a>>,
    returned_single: bool,
}

impl<'a> ScopeIterator<'a> {
    fn nth_island_aware_permutation(&self, n: u64) -> Vec<ScopalElement<'a>> {
        let mut result = Vec::new();
        let mut remainder = n;

        for island in &self.islands {
            let island_perms = factorial(island.len());
            let island_index = remainder % island_perms;
            remainder /= island_perms;

            let perm = nth_permutation_of_slice(island, island_index);
            result.extend(perm);
        }

        result
    }
}

fn nth_permutation_of_slice<T: Clone>(items: &[T], n: u64) -> Vec<T> {
    let len = items.len();
    let mut available: Vec<usize> = (0..len).collect();
    let mut result = Vec::with_capacity(len);
    let mut remainder = n;

    for i in 0..len {
        let divisor = factorial(len - i - 1);
        let index = (remainder / divisor) as usize;
        remainder %= divisor;
        result.push(items[available.remove(index)].clone());
    }
    result
}

impl<'a> Iterator for ScopeIterator<'a> {
    type Item = &'a LogicExpr<'a>;

    fn next(&mut self) -> Option<Self::Item> {
        if let Some(single) = self.single_result {
            if self.returned_single {
                return None;
            }
            self.returned_single = true;
            return Some(single);
        }

        if self.current_index >= self.total {
            return None;
        }
        let ordered = self.nth_island_aware_permutation(self.current_index);
        self.current_index += 1;
        Some(rebuild_with_scopal_elements(&ordered, self.core, self.expr_arena))
    }

    fn size_hint(&self) -> (usize, Option<usize>) {
        if self.single_result.is_some() {
            let remaining = if self.returned_single { 0 } else { 1 };
            return (remaining, Some(remaining));
        }
        let remaining = (self.total - self.current_index) as usize;
        (remaining, Some(remaining))
    }
}

impl<'a> ExactSizeIterator for ScopeIterator<'a> {}

#[derive(Clone, Debug)]
struct QuantifierInfo<'a> {
    kind: QuantifierKind,
    variable: Symbol,
    restrictor: &'a LogicExpr<'a>,
    island_id: u32,
}

#[derive(Clone, Debug)]
enum ScopalElement<'a> {
    Quantifier(QuantifierInfo<'a>),
    Negation { island_id: u32 },
}

impl<'a> ScopalElement<'a> {
    fn island_id(&self) -> u32 {
        match self {
            ScopalElement::Quantifier(q) => q.island_id,
            ScopalElement::Negation { island_id } => *island_id,
        }
    }
}

pub fn enumerate_scopings<'a>(
    expr: &'a LogicExpr<'a>,
    interner: &mut Interner,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    _term_arena: &'a Arena<Term<'a>>,
) -> ScopeIterator<'a> {
    let mut elements = Vec::new();
    let core = extract_scopal_elements(expr, &mut elements, interner, expr_arena);

    if elements.is_empty() || elements.len() == 1 {
        return ScopeIterator {
            expr_arena,
            islands: Vec::new(),
            core,
            current_index: 0,
            total: 0,
            single_result: Some(expr),
            returned_single: false,
        };
    }

    let islands = group_scopal_by_island(elements);
    let total: u64 = islands.iter().map(|island| factorial(island.len())).product();

    ScopeIterator {
        expr_arena,
        islands,
        core,
        current_index: 0,
        total,
        single_result: None,
        returned_single: false,
    }
}

fn group_by_island<'a>(quantifiers: Vec<QuantifierInfo<'a>>) -> Vec<Vec<QuantifierInfo<'a>>> {
    use std::collections::BTreeMap;

    let mut by_island: BTreeMap<u32, Vec<QuantifierInfo<'a>>> = BTreeMap::new();
    for q in quantifiers {
        by_island.entry(q.island_id).or_default().push(q);
    }

    by_island.into_values().collect()
}

fn group_scopal_by_island<'a>(elements: Vec<ScopalElement<'a>>) -> Vec<Vec<ScopalElement<'a>>> {
    use std::collections::BTreeMap;

    let mut by_island: BTreeMap<u32, Vec<ScopalElement<'a>>> = BTreeMap::new();
    for elem in elements {
        by_island.entry(elem.island_id()).or_default().push(elem);
    }

    by_island.into_values().collect()
}

fn extract_scopal_elements<'a>(
    expr: &'a LogicExpr<'a>,
    elements: &mut Vec<ScopalElement<'a>>,
    interner: &mut Interner,
    expr_arena: &'a Arena<LogicExpr<'a>>,
) -> &'a LogicExpr<'a> {
    match expr {
        LogicExpr::Quantifier { kind, variable, body, island_id } => {
            if let LogicExpr::BinaryOp { left, op, right } = body {
                if matches!(op, TokenType::If | TokenType::And) {
                    // Check if right side has a negation at the top level
                    if let LogicExpr::UnaryOp { op: TokenType::Not, operand } = right {
                        // Pattern: ∀x(R(x) → ¬P(x)) or ∃x(R(x) ∧ ¬P(x))
                        // Extract both quantifier and negation
                        elements.push(ScopalElement::Quantifier(QuantifierInfo {
                            kind: *kind,
                            variable: *variable,
                            restrictor: *left,
                            island_id: *island_id,
                        }));
                        elements.push(ScopalElement::Negation { island_id: *island_id });
                        return extract_scopal_elements(operand, elements, interner, expr_arena);
                    }
                    // No negation in right side, just extract quantifier
                    elements.push(ScopalElement::Quantifier(QuantifierInfo {
                        kind: *kind,
                        variable: *variable,
                        restrictor: *left,
                        island_id: *island_id,
                    }));
                    return extract_scopal_elements(right, elements, interner, expr_arena);
                }
            }
            // No binary op body, use a true restrictor
            elements.push(ScopalElement::Quantifier(QuantifierInfo {
                kind: *kind,
                variable: *variable,
                restrictor: expr_arena.alloc(LogicExpr::Atom(interner.intern("T"))),
                island_id: *island_id,
            }));
            extract_scopal_elements(body, elements, interner, expr_arena)
        }
        LogicExpr::UnaryOp { op: TokenType::Not, operand } => {
            // Standalone negation (not inside a quantifier body)
            elements.push(ScopalElement::Negation { island_id: 0 });
            extract_scopal_elements(operand, elements, interner, expr_arena)
        }
        _ => expr,
    }
}

fn rebuild_with_scopal_elements<'a>(
    elements: &[ScopalElement<'a>],
    core: &'a LogicExpr<'a>,
    arena: &'a Arena<LogicExpr<'a>>,
) -> &'a LogicExpr<'a> {
    let mut result = core;

    for elem in elements.iter().rev() {
        match elem {
            ScopalElement::Quantifier(q) => {
                let connective = match q.kind {
                    QuantifierKind::Universal => TokenType::If,
                    _ => TokenType::And,
                };

                let body = arena.alloc(LogicExpr::BinaryOp {
                    left: q.restrictor,
                    op: connective,
                    right: result,
                });

                result = arena.alloc(LogicExpr::Quantifier {
                    kind: q.kind,
                    variable: q.variable,
                    body,
                    island_id: q.island_id,
                });
            }
            ScopalElement::Negation { .. } => {
                result = arena.alloc(LogicExpr::UnaryOp {
                    op: TokenType::Not,
                    operand: result,
                });
            }
        }
    }

    result
}

fn extract_quantifiers<'a>(
    expr: &'a LogicExpr<'a>,
    quantifiers: &mut Vec<QuantifierInfo<'a>>,
    interner: &mut Interner,
    expr_arena: &'a Arena<LogicExpr<'a>>,
) -> &'a LogicExpr<'a> {
    match expr {
        LogicExpr::Quantifier { kind, variable, body, island_id } => {
            if let LogicExpr::BinaryOp { left, op, right } = body {
                if matches!(op, TokenType::If | TokenType::And) {
                    quantifiers.push(QuantifierInfo {
                        kind: *kind,
                        variable: *variable,
                        restrictor: *left,
                        island_id: *island_id,
                    });
                    return extract_quantifiers(right, quantifiers, interner, expr_arena);
                }
            }
            quantifiers.push(QuantifierInfo {
                kind: *kind,
                variable: *variable,
                restrictor: expr_arena.alloc(LogicExpr::Atom(interner.intern("T"))),
                island_id: *island_id,
            });
            extract_quantifiers(body, quantifiers, interner, expr_arena)
        }
        _ => expr,
    }
}

fn rebuild_with_scope_order<'a>(
    quantifiers: &[QuantifierInfo<'a>],
    core: &'a LogicExpr<'a>,
    arena: &'a Arena<LogicExpr<'a>>,
) -> &'a LogicExpr<'a> {
    let mut result = core;

    for q in quantifiers.iter().rev() {
        let connective = match q.kind {
            QuantifierKind::Universal => TokenType::If,
            _ => TokenType::And,
        };

        let body = arena.alloc(LogicExpr::BinaryOp {
            left: q.restrictor,
            op: connective,
            right: result,
        });

        result = arena.alloc(LogicExpr::Quantifier {
            kind: q.kind,
            variable: q.variable,
            body,
            island_id: q.island_id,
        });
    }

    result
}

pub fn lift_proper_name<'a>(
    name: Symbol,
    interner: &mut Interner,
    arena: &'a Arena<LogicExpr<'a>>,
) -> &'a LogicExpr<'a> {
    let p_sym = interner.intern("P");
    let inner_app = arena.alloc(LogicExpr::App {
        function: arena.alloc(LogicExpr::Atom(p_sym)),
        argument: arena.alloc(LogicExpr::Atom(name)),
    });
    arena.alloc(LogicExpr::Lambda {
        variable: p_sym,
        body: inner_app,
    })
}

pub fn lift_quantifier<'a>(
    kind: QuantifierKind,
    restrictor: Symbol,
    interner: &mut Interner,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
) -> &'a LogicExpr<'a> {
    let x_sym = interner.intern("x");
    let q_sym = interner.intern("Q");

    let restrictor_pred = expr_arena.alloc(LogicExpr::Predicate {
        name: restrictor,
        args: term_arena.alloc_slice([Term::Variable(x_sym)]),
    });

    let q_of_x = expr_arena.alloc(LogicExpr::App {
        function: expr_arena.alloc(LogicExpr::Atom(q_sym)),
        argument: expr_arena.alloc(LogicExpr::Atom(x_sym)),
    });

    let connective = match kind {
        QuantifierKind::Universal => TokenType::If,
        _ => TokenType::And,
    };

    let body = expr_arena.alloc(LogicExpr::BinaryOp {
        left: restrictor_pred,
        op: connective,
        right: q_of_x,
    });

    let quantifier = expr_arena.alloc(LogicExpr::Quantifier {
        kind,
        variable: x_sym,
        body,
        island_id: 0,
    });

    expr_arena.alloc(LogicExpr::Lambda {
        variable: q_sym,
        body: quantifier,
    })
}

pub fn beta_reduce<'a>(
    expr: &'a LogicExpr<'a>,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
) -> &'a LogicExpr<'a> {
    match expr {
        LogicExpr::App { function, argument } => {
            if let LogicExpr::Lambda { variable, body } = function {
                substitute(body, *variable, argument, expr_arena, term_arena)
            } else {
                expr_arena.alloc(LogicExpr::App {
                    function: beta_reduce(function, expr_arena, term_arena),
                    argument: beta_reduce(argument, expr_arena, term_arena),
                })
            }
        }
        LogicExpr::Lambda { variable, body } => expr_arena.alloc(LogicExpr::Lambda {
            variable: *variable,
            body: beta_reduce(body, expr_arena, term_arena),
        }),
        _ => expr,
    }
}

fn substitute<'a>(
    expr: &'a LogicExpr<'a>,
    var: Symbol,
    replacement: &'a LogicExpr<'a>,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
) -> &'a LogicExpr<'a> {
    match expr {
        LogicExpr::Predicate { name, args } => {
            let new_args: Vec<Term<'a>> = args
                .iter()
                .map(|arg| substitute_term(arg, var, replacement, term_arena))
                .collect();
            expr_arena.alloc(LogicExpr::Predicate {
                name: *name,
                args: term_arena.alloc_slice(new_args),
            })
        }

        LogicExpr::Lambda { variable, body } => {
            if *variable == var {
                expr
            } else {
                expr_arena.alloc(LogicExpr::Lambda {
                    variable: *variable,
                    body: substitute(body, var, replacement, expr_arena, term_arena),
                })
            }
        }

        LogicExpr::App { function, argument } => expr_arena.alloc(LogicExpr::App {
            function: substitute(function, var, replacement, expr_arena, term_arena),
            argument: substitute(argument, var, replacement, expr_arena, term_arena),
        }),

        LogicExpr::BinaryOp { left, op, right } => expr_arena.alloc(LogicExpr::BinaryOp {
            left: substitute(left, var, replacement, expr_arena, term_arena),
            op: op.clone(),
            right: substitute(right, var, replacement, expr_arena, term_arena),
        }),

        LogicExpr::UnaryOp { op, operand } => expr_arena.alloc(LogicExpr::UnaryOp {
            op: op.clone(),
            operand: substitute(operand, var, replacement, expr_arena, term_arena),
        }),

        LogicExpr::Quantifier { kind, variable, body, island_id } => {
            if *variable == var {
                expr
            } else {
                expr_arena.alloc(LogicExpr::Quantifier {
                    kind: *kind,
                    variable: *variable,
                    body: substitute(body, var, replacement, expr_arena, term_arena),
                    island_id: *island_id,
                })
            }
        }

        LogicExpr::Atom(s) => {
            if *s == var {
                replacement
            } else {
                expr
            }
        }

        _ => expr,
    }
}

fn substitute_term<'a>(
    term: &Term<'a>,
    var: Symbol,
    replacement: &LogicExpr<'a>,
    term_arena: &'a Arena<Term<'a>>,
) -> Term<'a> {
    match term {
        Term::Variable(v) if *v == var => {
            match replacement {
                LogicExpr::Atom(s) => Term::Constant(*s),
                LogicExpr::Predicate { name, .. } => Term::Constant(*name),
                _ => clone_term(term, term_arena),
            }
        }
        _ => clone_term(term, term_arena),
    }
}

// ═══════════════════════════════════════════════════════════════════
// Intensional Reading Generation (De Re / De Dicto)
// ═══════════════════════════════════════════════════════════════════

#[derive(Debug)]
struct IntensionalContext {
    verb: Symbol,
    quantifier_var: Symbol,
    restrictor: Symbol,
}

fn find_opaque_verb_context<'a>(
    expr: &'a LogicExpr<'a>,
    interner: &Interner,
) -> Option<IntensionalContext> {
    match expr {
        LogicExpr::Quantifier { kind: QuantifierKind::Existential, variable, body, .. } => {
            if let LogicExpr::BinaryOp { left, op: TokenType::And, right } = body {
                if let LogicExpr::Predicate { name: restrictor, args } = left {
                    if args.len() == 1 {
                        if let Term::Variable(v) = &args[0] {
                            if *v == *variable {
                                if let Some(verb) = find_opaque_verb_in_scope(right, *variable, interner) {
                                    return Some(IntensionalContext {
                                        verb,
                                        quantifier_var: *variable,
                                        restrictor: *restrictor,
                                    });
                                }
                            }
                        }
                    }
                }
            }
            None
        }
        _ => None,
    }
}

fn find_opaque_verb_in_scope<'a>(
    expr: &'a LogicExpr<'a>,
    theme_var: Symbol,
    interner: &Interner,
) -> Option<Symbol> {
    match expr {
        LogicExpr::Quantifier { body, .. } => find_opaque_verb_in_scope(body, theme_var, interner),
        LogicExpr::BinaryOp { left, right, .. } => {
            find_opaque_verb_in_scope(left, theme_var, interner)
                .or_else(|| find_opaque_verb_in_scope(right, theme_var, interner))
        }
        LogicExpr::NeoEvent(data) => {
            if is_opaque_verb(data.verb, interner) {
                for (role, term) in data.roles.iter() {
                    if matches!(role, crate::ast::ThematicRole::Theme) {
                        if let Term::Variable(v) = term {
                            if *v == theme_var {
                                return Some(data.verb);
                            }
                        }
                    }
                }
            }
            None
        }
        LogicExpr::Predicate { name, args } => {
            if is_opaque_verb(*name, interner) && args.len() >= 2 {
                if let Term::Variable(v) = &args[1] {
                    if *v == theme_var {
                        return Some(*name);
                    }
                }
            }
            None
        }
        _ => None,
    }
}

fn build_de_dicto_reading<'a>(
    expr: &'a LogicExpr<'a>,
    ctx: &IntensionalContext,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
    role_arena: &'a Arena<(crate::ast::ThematicRole, Term<'a>)>,
) -> &'a LogicExpr<'a> {
    match expr {
        LogicExpr::Quantifier { kind: QuantifierKind::Existential, variable, body, .. }
            if *variable == ctx.quantifier_var =>
        {
            if let LogicExpr::BinaryOp { right, .. } = body {
                replace_theme_with_intension(right, ctx, expr_arena, term_arena, role_arena)
            } else {
                expr
            }
        }
        _ => expr,
    }
}

fn replace_theme_with_intension<'a>(
    expr: &'a LogicExpr<'a>,
    ctx: &IntensionalContext,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
    role_arena: &'a Arena<(crate::ast::ThematicRole, Term<'a>)>,
) -> &'a LogicExpr<'a> {
    match expr {
        LogicExpr::Quantifier { kind, variable, body, island_id } => {
            let new_body = replace_theme_with_intension(body, ctx, expr_arena, term_arena, role_arena);
            expr_arena.alloc(LogicExpr::Quantifier {
                kind: *kind,
                variable: *variable,
                body: new_body,
                island_id: *island_id,
            })
        }
        LogicExpr::BinaryOp { left, op, right } => {
            let new_left = replace_theme_with_intension(left, ctx, expr_arena, term_arena, role_arena);
            let new_right = replace_theme_with_intension(right, ctx, expr_arena, term_arena, role_arena);
            expr_arena.alloc(LogicExpr::BinaryOp {
                left: new_left,
                op: op.clone(),
                right: new_right,
            })
        }
        LogicExpr::NeoEvent(data) => {
            let new_roles: Vec<_> = data.roles.iter().map(|(role, term)| {
                if matches!(role, crate::ast::ThematicRole::Theme) {
                    if let Term::Variable(v) = term {
                        if *v == ctx.quantifier_var {
                            return (*role, Term::Intension(ctx.restrictor));
                        }
                    }
                }
                (*role, clone_term(term, term_arena))
            }).collect();

            expr_arena.alloc(LogicExpr::NeoEvent(Box::new(crate::ast::NeoEventData {
                event_var: data.event_var,
                verb: data.verb,
                roles: role_arena.alloc_slice(new_roles),
                modifiers: data.modifiers,
                suppress_existential: false,
            })))
        }
        LogicExpr::Predicate { name, args } => {
            let new_args: Vec<_> = args.iter().map(|arg| {
                if let Term::Variable(v) = arg {
                    if *v == ctx.quantifier_var {
                        return Term::Intension(ctx.restrictor);
                    }
                }
                clone_term(arg, term_arena)
            }).collect();

            expr_arena.alloc(LogicExpr::Predicate {
                name: *name,
                args: term_arena.alloc_slice(new_args),
            })
        }
        _ => expr,
    }
}

pub fn enumerate_intensional_readings<'a>(
    expr: &'a LogicExpr<'a>,
    interner: &mut Interner,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
    role_arena: &'a Arena<(crate::ast::ThematicRole, Term<'a>)>,
) -> Vec<&'a LogicExpr<'a>> {
    // Check if expression already has intensional terms (de dicto from parser)
    if let Some(de_re) = build_de_re_from_de_dicto(expr, interner, expr_arena, term_arena, role_arena) {
        // Return both: de re first (existential), de dicto second (intension)
        return vec![de_re, expr];
    }

    // Original logic: check for de re that can be converted to de dicto
    if let Some(ctx) = find_opaque_verb_context(expr, interner) {
        let de_dicto = build_de_dicto_reading(expr, &ctx, expr_arena, term_arena, role_arena);
        vec![expr, de_dicto]
    } else {
        vec![expr]
    }
}

fn build_de_re_from_de_dicto<'a>(
    expr: &'a LogicExpr<'a>,
    interner: &mut Interner,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
    role_arena: &'a Arena<(crate::ast::ThematicRole, Term<'a>)>,
) -> Option<&'a LogicExpr<'a>> {
    // Find Term::Intension in NeoEvent themes and expand to existential
    match expr {
        LogicExpr::NeoEvent(data) => {
            // Check if any role has an Intension term
            for (role, term) in data.roles.iter() {
                if matches!(role, crate::ast::ThematicRole::Theme) {
                    if let Term::Intension(noun) = term {
                        // Build de re: ∃x(Noun(x) ∧ Event[Theme=x])
                        let var = interner.intern("x");

                        // Build noun predicate: Noun(x)
                        let noun_pred = expr_arena.alloc(LogicExpr::Predicate {
                            name: *noun,
                            args: term_arena.alloc_slice([Term::Variable(var)]),
                        });

                        // Build new roles with variable instead of intension
                        let new_roles: Vec<_> = data.roles.iter().map(|(r, t)| {
                            if matches!(r, crate::ast::ThematicRole::Theme) {
                                (*r, Term::Variable(var))
                            } else {
                                (*r, t.clone())
                            }
                        }).collect();

                        let new_event = expr_arena.alloc(LogicExpr::NeoEvent(Box::new(crate::ast::NeoEventData {
                            event_var: data.event_var,
                            verb: data.verb,
                            roles: role_arena.alloc_slice(new_roles),
                            modifiers: data.modifiers,
                            suppress_existential: false,
                        })));

                        // Build: ∃x(Noun(x) ∧ Event)
                        let body = expr_arena.alloc(LogicExpr::BinaryOp {
                            left: noun_pred,
                            op: crate::token::TokenType::And,
                            right: new_event,
                        });

                        return Some(expr_arena.alloc(LogicExpr::Quantifier {
                            kind: crate::ast::QuantifierKind::Existential,
                            variable: var,
                            body,
                            island_id: 0,
                        }));
                    }
                }
            }
            None
        }
        _ => None,
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::ast::{LogicExpr, Term};
    use crate::intern::Interner;
    use crate::registry::SymbolRegistry;
    use crate::OutputFormat;

    #[test]
    fn test_lambda_formatting_unicode() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let sleep = interner.intern("Sleep");

        let body = expr_arena.alloc(LogicExpr::Predicate {
            name: sleep,
            args: term_arena.alloc_slice([Term::Variable(x)]),
        });
        let lambda = expr_arena.alloc(LogicExpr::Lambda { variable: x, body });

        let mut registry = SymbolRegistry::new();
        let output = lambda.transpile(&mut registry, &interner, OutputFormat::Unicode);
        assert!(output.contains("λx"), "Unicode should use λ: {}", output);
    }

    #[test]
    fn test_lambda_formatting_latex() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let sleep = interner.intern("Sleep");

        let body = expr_arena.alloc(LogicExpr::Predicate {
            name: sleep,
            args: term_arena.alloc_slice([Term::Variable(x)]),
        });
        let lambda = expr_arena.alloc(LogicExpr::Lambda { variable: x, body });

        let mut registry = SymbolRegistry::new();
        let output = lambda.transpile(&mut registry, &interner, OutputFormat::LaTeX);
        assert!(output.contains("\\lambda"), "LaTeX should use \\lambda: {}", output);
    }

    #[test]
    fn test_application_formatting() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();

        let p = interner.intern("P");
        let j = interner.intern("j");

        let func = expr_arena.alloc(LogicExpr::Atom(p));
        let arg = expr_arena.alloc(LogicExpr::Atom(j));
        let app = expr_arena.alloc(LogicExpr::App { function: func, argument: arg });

        let mut registry = SymbolRegistry::new();
        let output = app.transpile(&mut registry, &interner, OutputFormat::Unicode);
        assert!(output.contains("(") && output.contains(")"), "App should have parens: {}", output);
    }

    #[test]
    fn test_nested_lambda() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();

        let x = interner.intern("x");
        let y = interner.intern("y");

        let inner_body = expr_arena.alloc(LogicExpr::Atom(x));
        let inner_lambda = expr_arena.alloc(LogicExpr::Lambda { variable: y, body: inner_body });
        let outer_lambda = expr_arena.alloc(LogicExpr::Lambda { variable: x, body: inner_lambda });

        let mut registry = SymbolRegistry::new();
        let output = outer_lambda.transpile(&mut registry, &interner, OutputFormat::Unicode);
        assert!(output.contains("λx") && output.contains("λy"), "Nested lambdas: {}", output);
    }

    #[test]
    fn test_lambda_app_helper_functions() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let _term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let p = interner.intern("P");

        let body = expr_arena.alloc(LogicExpr::Atom(x));
        let lambda = LogicExpr::lambda(x, body, &expr_arena);

        let arg = expr_arena.alloc(LogicExpr::Atom(p));
        let app = LogicExpr::app(lambda, arg, &expr_arena);

        assert!(matches!(app, LogicExpr::App { .. }));
    }

    #[test]
    fn lift_proper_name_returns_lambda() {
        let mut interner = Interner::new();
        let arena: Arena<LogicExpr> = Arena::new();

        let john = interner.intern("John");
        let lifted = lift_proper_name(john, &mut interner, &arena);

        assert!(matches!(lifted, LogicExpr::Lambda { .. }), "Should return Lambda");
    }

    #[test]
    fn lift_proper_name_applies_predicate() {
        let mut interner = Interner::new();
        let arena: Arena<LogicExpr> = Arena::new();

        let john = interner.intern("John");
        let lifted = lift_proper_name(john, &mut interner, &arena);

        if let LogicExpr::Lambda { body, .. } = lifted {
            assert!(matches!(body, LogicExpr::App { .. }), "Body should be App");
        } else {
            panic!("Expected Lambda");
        }
    }

    #[test]
    fn lift_quantifier_universal_returns_lambda() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let woman = interner.intern("woman");
        let lifted = lift_quantifier(QuantifierKind::Universal, woman, &mut interner, &expr_arena, &term_arena);

        assert!(matches!(lifted, LogicExpr::Lambda { .. }), "Should return Lambda");
    }

    #[test]
    fn lift_quantifier_universal_structure() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let woman = interner.intern("woman");
        let lifted = lift_quantifier(QuantifierKind::Universal, woman, &mut interner, &expr_arena, &term_arena);

        if let LogicExpr::Lambda { body, .. } = lifted {
            assert!(
                matches!(body, LogicExpr::Quantifier { kind: QuantifierKind::Universal, .. }),
                "Body should contain ∀, got {:?}",
                body
            );
        } else {
            panic!("Expected Lambda, got {:?}", lifted);
        }
    }

    #[test]
    fn lift_quantifier_existential_returns_lambda() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let man = interner.intern("man");
        let lifted = lift_quantifier(QuantifierKind::Existential, man, &mut interner, &expr_arena, &term_arena);

        assert!(matches!(lifted, LogicExpr::Lambda { .. }), "Should return Lambda");
    }

    #[test]
    fn lift_quantifier_existential_structure() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let man = interner.intern("man");
        let lifted = lift_quantifier(QuantifierKind::Existential, man, &mut interner, &expr_arena, &term_arena);

        if let LogicExpr::Lambda { body, .. } = lifted {
            assert!(
                matches!(body, LogicExpr::Quantifier { kind: QuantifierKind::Existential, .. }),
                "Body should contain ∃, got {:?}",
                body
            );
        } else {
            panic!("Expected Lambda, got {:?}", lifted);
        }
    }

    #[test]
    fn beta_reduce_simple_predicate() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let john = interner.intern("John");
        let run = interner.intern("Run");

        let body = expr_arena.alloc(LogicExpr::Predicate {
            name: run,
            args: term_arena.alloc_slice([Term::Variable(x)]),
        });
        let lambda = expr_arena.alloc(LogicExpr::Lambda { variable: x, body });
        let arg = expr_arena.alloc(LogicExpr::Atom(john));
        let app = expr_arena.alloc(LogicExpr::App { function: lambda, argument: arg });

        let reduced = beta_reduce(app, &expr_arena, &term_arena);

        let mut registry = SymbolRegistry::new();
        let output = reduced.transpile(&mut registry, &interner, OutputFormat::Unicode);
        assert!(output.contains("R(J)") || output.contains("Run(John)"), "Should substitute: {}", output);
    }

    #[test]
    fn beta_reduce_with_constant() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let c = interner.intern("c");

        let body = expr_arena.alloc(LogicExpr::Atom(c));
        let lambda = expr_arena.alloc(LogicExpr::Lambda { variable: x, body });
        let arg = expr_arena.alloc(LogicExpr::Atom(interner.intern("anything")));
        let app = expr_arena.alloc(LogicExpr::App { function: lambda, argument: arg });

        let reduced = beta_reduce(app, &expr_arena, &term_arena);
        assert!(matches!(reduced, LogicExpr::Atom(s) if *s == c), "Constant should remain");
    }

    #[test]
    fn beta_reduce_nested_lambda() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let y = interner.intern("y");

        let inner_body = expr_arena.alloc(LogicExpr::Atom(x));
        let inner_lambda = expr_arena.alloc(LogicExpr::Lambda { variable: y, body: inner_body });
        let outer_lambda = expr_arena.alloc(LogicExpr::Lambda { variable: x, body: inner_lambda });

        let reduced = beta_reduce(outer_lambda, &expr_arena, &term_arena);
        assert!(matches!(reduced, LogicExpr::Lambda { .. }), "Should still be lambda");
    }

    #[test]
    fn beta_reduce_non_application_unchanged() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let p = interner.intern("P");
        let atom = expr_arena.alloc(LogicExpr::Atom(p));

        let reduced = beta_reduce(atom, &expr_arena, &term_arena);
        assert!(matches!(reduced, LogicExpr::Atom(s) if *s == p), "Atom unchanged");
    }

    #[test]
    fn beta_reduce_preserves_unbound_variables() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let y = interner.intern("y");
        let john = interner.intern("John");
        let loves = interner.intern("Loves");

        let body = expr_arena.alloc(LogicExpr::Predicate {
            name: loves,
            args: term_arena.alloc_slice([Term::Variable(x), Term::Variable(y)]),
        });
        let lambda = expr_arena.alloc(LogicExpr::Lambda { variable: x, body });
        let arg = expr_arena.alloc(LogicExpr::Atom(john));
        let app = expr_arena.alloc(LogicExpr::App { function: lambda, argument: arg });

        let reduced = beta_reduce(app, &expr_arena, &term_arena);

        let mut registry = SymbolRegistry::new();
        let output = reduced.transpile(&mut registry, &interner, OutputFormat::Unicode);
        assert!(output.contains("y"), "y should remain unbound: {}", output);
    }

    #[test]
    fn enumerate_scopings_single_quantifier() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let dog = interner.intern("Dog");
        let bark = interner.intern("Bark");

        let left = expr_arena.alloc(LogicExpr::Predicate {
            name: dog,
            args: term_arena.alloc_slice([Term::Variable(x)]),
        });
        let right = expr_arena.alloc(LogicExpr::Predicate {
            name: bark,
            args: term_arena.alloc_slice([Term::Variable(x)]),
        });
        let body = expr_arena.alloc(LogicExpr::BinaryOp {
            left,
            op: TokenType::If,
            right,
        });
        let expr = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Universal,
            variable: x,
            body,
            island_id: 0,
        });

        let scopings = enumerate_scopings(expr, &mut interner, &expr_arena, &term_arena);
        assert_eq!(scopings.len(), 1, "Single quantifier should have 1 reading");
    }

    #[test]
    fn enumerate_scopings_no_quantifier() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let run = interner.intern("Run");
        let john = interner.intern("John");

        let expr = expr_arena.alloc(LogicExpr::Predicate {
            name: run,
            args: term_arena.alloc_slice([Term::Constant(john)]),
        });

        let scopings = enumerate_scopings(expr, &mut interner, &expr_arena, &term_arena);
        assert_eq!(scopings.len(), 1, "No quantifiers should have 1 reading");
    }

    #[test]
    fn is_opaque_verb_believes() {
        let mut interner = Interner::new();
        let believes = interner.intern("believes");
        let believes_cap = interner.intern("Believes");
        assert!(is_opaque_verb(believes, &interner), "believes should be opaque");
        assert!(is_opaque_verb(believes_cap, &interner), "Believes should be opaque");
    }

    #[test]
    fn is_opaque_verb_seeks() {
        let mut interner = Interner::new();
        let seeks = interner.intern("seeks");
        let wants = interner.intern("wants");
        assert!(is_opaque_verb(seeks, &interner), "seeks should be opaque");
        assert!(is_opaque_verb(wants, &interner), "wants should be opaque");
    }

    #[test]
    fn is_opaque_verb_normal_verbs() {
        let mut interner = Interner::new();
        let runs = interner.intern("runs");
        let loves = interner.intern("loves");
        assert!(!is_opaque_verb(runs, &interner), "runs should NOT be opaque");
        assert!(!is_opaque_verb(loves, &interner), "loves should NOT be opaque");
    }

    #[test]
    fn make_intensional_creates_wrapper() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let weak = interner.intern("Weak");
        let clark = interner.intern("Clark");
        let believes = interner.intern("believes");

        let content = expr_arena.alloc(LogicExpr::Predicate {
            name: weak,
            args: term_arena.alloc_slice([Term::Constant(clark)]),
        });

        let intensional = make_intensional(believes, content, &expr_arena);

        assert!(
            matches!(intensional, LogicExpr::Intensional { operator, .. } if *operator == believes),
            "Should create Intensional wrapper, got {:?}",
            intensional
        );
    }

    #[test]
    fn intensional_transpiles_with_brackets() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let weak = interner.intern("Weak");
        let clark = interner.intern("Clark");
        let believes = interner.intern("Believes");

        let content = expr_arena.alloc(LogicExpr::Predicate {
            name: weak,
            args: term_arena.alloc_slice([Term::Constant(clark)]),
        });

        let intensional = expr_arena.alloc(LogicExpr::Intensional {
            operator: believes,
            content,
        });

        let mut registry = SymbolRegistry::new();
        let output = intensional.transpile(&mut registry, &interner, OutputFormat::Unicode);

        assert!(
            output.contains("[") && output.contains("]"),
            "Intensional should use brackets: got {}",
            output
        );
    }

    #[test]
    fn substitute_respecting_opacity_blocks_inside_intensional() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let weak = interner.intern("Weak");
        let clark = interner.intern("Clark");
        let believes = interner.intern("Believes");
        let superman = interner.intern("Superman");

        let inner = expr_arena.alloc(LogicExpr::Predicate {
            name: weak,
            args: term_arena.alloc_slice([Term::Constant(clark)]),
        });
        let expr = expr_arena.alloc(LogicExpr::Intensional {
            operator: believes,
            content: inner,
        });

        let replacement = expr_arena.alloc(LogicExpr::Atom(superman));
        let result = substitute_respecting_opacity(expr, clark, replacement, &expr_arena, &term_arena);

        let mut registry = SymbolRegistry::new();
        let output = result.transpile(&mut registry, &interner, OutputFormat::Unicode);

        assert!(
            output.contains("C") && !output.contains("S"),
            "Should NOT substitute inside intensional context: got {}",
            output
        );
    }

    #[test]
    fn substitute_respecting_opacity_allows_outside() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let weak = interner.intern("Weak");
        let clark = interner.intern("Clark");
        let superman = interner.intern("Superman");

        let expr = expr_arena.alloc(LogicExpr::Predicate {
            name: weak,
            args: term_arena.alloc_slice([Term::Constant(clark)]),
        });

        let replacement = expr_arena.alloc(LogicExpr::Atom(superman));
        let result = substitute_respecting_opacity(expr, clark, replacement, &expr_arena, &term_arena);

        let mut registry = SymbolRegistry::new();
        let output = result.transpile(&mut registry, &interner, OutputFormat::Unicode);

        assert!(
            output.contains("S"),
            "Should substitute outside intensional context: got {}",
            output
        );
    }

    #[test]
    fn factorial_basic() {
        assert_eq!(factorial(0), 1);
        assert_eq!(factorial(1), 1);
        assert_eq!(factorial(2), 2);
        assert_eq!(factorial(3), 6);
        assert_eq!(factorial(4), 24);
        assert_eq!(factorial(5), 120);
    }

    #[test]
    fn scope_iterator_two_quantifiers_yields_two() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let y = interner.intern("y");
        let man = interner.intern("Man");
        let woman = interner.intern("Woman");
        let loves = interner.intern("Loves");

        let man_x = expr_arena.alloc(LogicExpr::Predicate {
            name: man,
            args: term_arena.alloc_slice([Term::Variable(x)]),
        });
        let woman_y = expr_arena.alloc(LogicExpr::Predicate {
            name: woman,
            args: term_arena.alloc_slice([Term::Variable(y)]),
        });
        let loves_xy = expr_arena.alloc(LogicExpr::Predicate {
            name: loves,
            args: term_arena.alloc_slice([Term::Variable(x), Term::Variable(y)]),
        });

        let inner = expr_arena.alloc(LogicExpr::BinaryOp {
            left: woman_y,
            op: TokenType::And,
            right: loves_xy,
        });
        let inner_q = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Existential,
            variable: y,
            body: inner,
            island_id: 0,
        });

        let outer = expr_arena.alloc(LogicExpr::BinaryOp {
            left: man_x,
            op: TokenType::If,
            right: inner_q,
        });
        let expr = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Universal,
            variable: x,
            body: outer,
            island_id: 0,
        });

        let scopings: Vec<_> = enumerate_scopings(expr, &mut interner, &expr_arena, &term_arena).collect();
        assert_eq!(scopings.len(), 2, "Two quantifiers should have 2! = 2 readings");
    }

    #[test]
    fn scope_iterator_three_quantifiers_yields_six() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let y = interner.intern("y");
        let z = interner.intern("z");
        let man = interner.intern("Man");
        let woman = interner.intern("Woman");
        let book = interner.intern("Book");
        let gives = interner.intern("Gives");

        let man_x = expr_arena.alloc(LogicExpr::Predicate {
            name: man,
            args: term_arena.alloc_slice([Term::Variable(x)]),
        });
        let woman_y = expr_arena.alloc(LogicExpr::Predicate {
            name: woman,
            args: term_arena.alloc_slice([Term::Variable(y)]),
        });
        let book_z = expr_arena.alloc(LogicExpr::Predicate {
            name: book,
            args: term_arena.alloc_slice([Term::Variable(z)]),
        });
        let gives_xyz = expr_arena.alloc(LogicExpr::Predicate {
            name: gives,
            args: term_arena.alloc_slice([Term::Variable(x), Term::Variable(y), Term::Variable(z)]),
        });

        let inner_z = expr_arena.alloc(LogicExpr::BinaryOp {
            left: book_z,
            op: TokenType::And,
            right: gives_xyz,
        });
        let q_z = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Existential,
            variable: z,
            body: inner_z,
            island_id: 0,
        });

        let inner_y = expr_arena.alloc(LogicExpr::BinaryOp {
            left: woman_y,
            op: TokenType::And,
            right: q_z,
        });
        let q_y = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Existential,
            variable: y,
            body: inner_y,
            island_id: 0,
        });

        let outer = expr_arena.alloc(LogicExpr::BinaryOp {
            left: man_x,
            op: TokenType::If,
            right: q_y,
        });
        let expr = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Universal,
            variable: x,
            body: outer,
            island_id: 0,
        });

        let scopings: Vec<_> = enumerate_scopings(expr, &mut interner, &expr_arena, &term_arena).collect();
        assert_eq!(scopings.len(), 6, "Three quantifiers should have 3! = 6 readings");
    }

    #[test]
    fn scope_iterator_no_duplicates() {
        use std::collections::HashSet;

        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let y = interner.intern("y");
        let man = interner.intern("Man");
        let woman = interner.intern("Woman");
        let loves = interner.intern("Loves");

        let man_x = expr_arena.alloc(LogicExpr::Predicate {
            name: man,
            args: term_arena.alloc_slice([Term::Variable(x)]),
        });
        let woman_y = expr_arena.alloc(LogicExpr::Predicate {
            name: woman,
            args: term_arena.alloc_slice([Term::Variable(y)]),
        });
        let loves_xy = expr_arena.alloc(LogicExpr::Predicate {
            name: loves,
            args: term_arena.alloc_slice([Term::Variable(x), Term::Variable(y)]),
        });

        let inner = expr_arena.alloc(LogicExpr::BinaryOp {
            left: woman_y,
            op: TokenType::And,
            right: loves_xy,
        });
        let inner_q = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Existential,
            variable: y,
            body: inner,
            island_id: 0,
        });

        let outer = expr_arena.alloc(LogicExpr::BinaryOp {
            left: man_x,
            op: TokenType::If,
            right: inner_q,
        });
        let expr = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Universal,
            variable: x,
            body: outer,
            island_id: 0,
        });

        let mut registry = SymbolRegistry::new();
        let outputs: HashSet<String> = enumerate_scopings(expr, &mut interner, &expr_arena, &term_arena)
            .map(|e| e.transpile(&mut registry, &interner, OutputFormat::Unicode))
            .collect();

        assert_eq!(outputs.len(), 2, "All scopings should be unique");
    }

    #[test]
    fn scope_iterator_exact_size() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let y = interner.intern("y");
        let man = interner.intern("Man");
        let woman = interner.intern("Woman");
        let loves = interner.intern("Loves");

        let man_x = expr_arena.alloc(LogicExpr::Predicate {
            name: man,
            args: term_arena.alloc_slice([Term::Variable(x)]),
        });
        let woman_y = expr_arena.alloc(LogicExpr::Predicate {
            name: woman,
            args: term_arena.alloc_slice([Term::Variable(y)]),
        });
        let loves_xy = expr_arena.alloc(LogicExpr::Predicate {
            name: loves,
            args: term_arena.alloc_slice([Term::Variable(x), Term::Variable(y)]),
        });

        let inner = expr_arena.alloc(LogicExpr::BinaryOp {
            left: woman_y,
            op: TokenType::And,
            right: loves_xy,
        });
        let inner_q = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Existential,
            variable: y,
            body: inner,
            island_id: 0,
        });

        let outer = expr_arena.alloc(LogicExpr::BinaryOp {
            left: man_x,
            op: TokenType::If,
            right: inner_q,
        });
        let expr = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Universal,
            variable: x,
            body: outer,
            island_id: 0,
        });

        let mut iter = enumerate_scopings(expr, &mut interner, &expr_arena, &term_arena);
        assert_eq!(iter.len(), 2);
        iter.next();
        assert_eq!(iter.len(), 1);
        iter.next();
        assert_eq!(iter.len(), 0);
    }

    #[test]
    fn island_constraints_reduce_permutations() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let y = interner.intern("y");
        let man = interner.intern("Man");
        let woman = interner.intern("Woman");
        let loves = interner.intern("Loves");

        let man_x = expr_arena.alloc(LogicExpr::Predicate {
            name: man,
            args: term_arena.alloc_slice([Term::Variable(x)]),
        });
        let woman_y = expr_arena.alloc(LogicExpr::Predicate {
            name: woman,
            args: term_arena.alloc_slice([Term::Variable(y)]),
        });
        let loves_xy = expr_arena.alloc(LogicExpr::Predicate {
            name: loves,
            args: term_arena.alloc_slice([Term::Variable(x), Term::Variable(y)]),
        });

        let inner = expr_arena.alloc(LogicExpr::BinaryOp {
            left: woman_y,
            op: TokenType::And,
            right: loves_xy,
        });
        let inner_q = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Existential,
            variable: y,
            body: inner,
            island_id: 1,
        });

        let outer = expr_arena.alloc(LogicExpr::BinaryOp {
            left: man_x,
            op: TokenType::If,
            right: inner_q,
        });
        let expr = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Universal,
            variable: x,
            body: outer,
            island_id: 0,
        });

        let scopings = enumerate_scopings(expr, &mut interner, &expr_arena, &term_arena);
        assert_eq!(
            scopings.len(),
            1,
            "Two quantifiers in different islands: 1! × 1! = 1 reading (no cross-island scoping)"
        );
    }

    #[test]
    fn multiple_quantifiers_per_island() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();

        let x = interner.intern("x");
        let y = interner.intern("y");
        let z = interner.intern("z");
        let w = interner.intern("w");
        let pred = interner.intern("P");

        let core = expr_arena.alloc(LogicExpr::Predicate {
            name: pred,
            args: term_arena.alloc_slice([
                Term::Variable(x),
                Term::Variable(y),
                Term::Variable(z),
                Term::Variable(w),
            ]),
        });

        let true_sym = interner.intern("T");
        let t = expr_arena.alloc(LogicExpr::Atom(true_sym));

        let q_w = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Existential,
            variable: w,
            body: expr_arena.alloc(LogicExpr::BinaryOp { left: t, op: TokenType::And, right: core }),
            island_id: 1,
        });
        let q_z = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Existential,
            variable: z,
            body: expr_arena.alloc(LogicExpr::BinaryOp { left: t, op: TokenType::And, right: q_w }),
            island_id: 1,
        });
        let q_y = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Existential,
            variable: y,
            body: expr_arena.alloc(LogicExpr::BinaryOp { left: t, op: TokenType::And, right: q_z }),
            island_id: 0,
        });
        let expr = expr_arena.alloc(LogicExpr::Quantifier {
            kind: QuantifierKind::Universal,
            variable: x,
            body: expr_arena.alloc(LogicExpr::BinaryOp { left: t, op: TokenType::If, right: q_y }),
            island_id: 0,
        });

        let scopings = enumerate_scopings(expr, &mut interner, &expr_arena, &term_arena);
        assert_eq!(
            scopings.len(),
            4,
            "4 quantifiers split 2+2 across islands: 2! × 2! = 4 (not 4! = 24)"
        );
    }
}

```

---

### Discourse Context

**File:** `src/context.rs`

Entity registration and resolution for anaphora. Tracks gender, number, and case attributes for pronoun binding.

```rust
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum TimeRelation {
    Precedes,
    Equals,
}

#[derive(Debug, Clone)]
pub struct TimeConstraint {
    pub left: String,
    pub relation: TimeRelation,
    pub right: String,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum Gender {
    Male,
    Female,
    Neuter,
    Unknown,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum Number {
    Singular,
    Plural,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum Case {
    Subject,
    Object,
    Possessive,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
pub enum OwnershipState {
    #[default]
    Owned,
    Moved,
    Borrowed,
}

#[derive(Debug, Clone)]
pub struct Entity {
    pub symbol: String,
    pub gender: Gender,
    pub number: Number,
    pub noun_class: String,
    pub ownership: OwnershipState,
}

#[derive(Debug, Clone, Default)]
pub struct DiscourseContext {
    history: Vec<Entity>,
    event_counter: usize,
    event_history: Vec<String>,
    reference_time_counter: usize,
    current_reference_time: Option<String>,
    time_constraints: Vec<TimeConstraint>,
}

impl DiscourseContext {
    pub fn new() -> Self {
        Self {
            history: Vec::new(),
            event_counter: 0,
            event_history: Vec::new(),
            reference_time_counter: 0,
            current_reference_time: None,
            time_constraints: Vec::new(),
        }
    }

    pub fn next_reference_time(&mut self) -> String {
        self.reference_time_counter += 1;
        let var = format!("r{}", self.reference_time_counter);
        self.current_reference_time = Some(var.clone());
        var
    }

    pub fn current_reference_time(&self) -> String {
        self.current_reference_time.clone().unwrap_or_else(|| "S".to_string())
    }

    pub fn add_time_constraint(&mut self, left: String, relation: TimeRelation, right: String) {
        self.time_constraints.push(TimeConstraint { left, relation, right });
    }

    pub fn time_constraints(&self) -> &[TimeConstraint] {
        &self.time_constraints
    }

    pub fn clear_time_constraints(&mut self) {
        self.time_constraints.clear();
        self.reference_time_counter = 0;
        self.current_reference_time = None;
    }

    pub fn next_event_var(&mut self) -> String {
        self.event_counter += 1;
        let var = format!("e{}", self.event_counter);
        self.event_history.push(var.clone());
        var
    }

    pub fn event_history(&self) -> &[String] {
        &self.event_history
    }

    pub fn register(&mut self, entity: Entity) {
        self.history.push(entity);
    }

    pub fn resolve_pronoun(&self, gender: Gender, number: Number) -> Option<&Entity> {
        self.history
            .iter()
            .rev()
            .find(|e| {
                let gender_match = gender == Gender::Unknown
                    || e.gender == Gender::Unknown
                    || e.gender == gender;
                let number_match = e.number == number;
                gender_match && number_match
            })
    }

    pub fn resolve_definite(&self, noun_class: &str) -> Option<&Entity> {
        self.history
            .iter()
            .rev()
            .find(|e| e.noun_class.to_lowercase() == noun_class.to_lowercase())
    }

    pub fn has_entity_by_noun_class(&self, noun_class: &str) -> bool {
        self.history
            .iter()
            .any(|e| e.noun_class.to_lowercase() == noun_class.to_lowercase())
    }

    /// Resolve bridging anaphora by finding entities whose type contains the noun as a part.
    /// Returns all matching entities for ambiguity handling (parse forest).
    pub fn resolve_bridging(&self, noun_class: &str) -> Vec<(&Entity, &'static str)> {
        use crate::ontology::find_bridging_wholes;

        let Some(wholes) = find_bridging_wholes(noun_class) else {
            return Vec::new();
        };

        let mut matches = Vec::new();
        for whole in wholes {
            for entity in self.history.iter().rev() {
                if entity.noun_class.to_lowercase() == whole.to_lowercase() {
                    matches.push((entity, *whole));
                }
            }
        }
        matches
    }

    pub fn set_ownership(&mut self, noun_class: &str, state: OwnershipState) {
        for entity in self.history.iter_mut() {
            if entity.noun_class.to_lowercase() == noun_class.to_lowercase() {
                entity.ownership = state;
                return;
            }
        }
    }

    pub fn get_ownership(&self, noun_class: &str) -> Option<OwnershipState> {
        self.history
            .iter()
            .find(|e| e.noun_class.to_lowercase() == noun_class.to_lowercase())
            .map(|e| e.ownership)
    }

    pub fn clear(&mut self) {
        self.history.clear();
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn register_and_resolve_male() {
        let mut ctx = DiscourseContext::new();
        ctx.register(Entity {
            symbol: "John".into(),
            gender: Gender::Male,
            number: Number::Singular,
            noun_class: "John".into(),
            ownership: OwnershipState::Owned,
        });
        let resolved = ctx.resolve_pronoun(Gender::Male, Number::Singular);
        assert!(resolved.is_some());
        assert_eq!(resolved.unwrap().symbol, "John");
    }

    #[test]
    fn resolve_female_pronoun() {
        let mut ctx = DiscourseContext::new();
        ctx.register(Entity {
            symbol: "Mary".into(),
            gender: Gender::Female,
            number: Number::Singular,
            noun_class: "Mary".into(),
            ownership: OwnershipState::Owned,
        });
        let resolved = ctx.resolve_pronoun(Gender::Female, Number::Singular);
        assert!(resolved.is_some());
        assert_eq!(resolved.unwrap().symbol, "Mary");
    }

    #[test]
    fn resolve_most_recent() {
        let mut ctx = DiscourseContext::new();
        ctx.register(Entity {
            symbol: "John".into(),
            gender: Gender::Male,
            number: Number::Singular,
            noun_class: "John".into(),
            ownership: OwnershipState::Owned,
        });
        ctx.register(Entity {
            symbol: "Bob".into(),
            gender: Gender::Male,
            number: Number::Singular,
            noun_class: "Bob".into(),
            ownership: OwnershipState::Owned,
        });
        let resolved = ctx.resolve_pronoun(Gender::Male, Number::Singular);
        assert_eq!(resolved.unwrap().symbol, "Bob");
    }

    #[test]
    fn resolve_definite_by_class() {
        let mut ctx = DiscourseContext::new();
        ctx.register(Entity {
            symbol: "Dog".into(),
            gender: Gender::Neuter,
            number: Number::Singular,
            noun_class: "Dog".into(),
            ownership: OwnershipState::Owned,
        });
        let resolved = ctx.resolve_definite("dog");
        assert!(resolved.is_some());
        assert_eq!(resolved.unwrap().symbol, "Dog");
    }

    #[test]
    fn gender_filtering() {
        let mut ctx = DiscourseContext::new();
        ctx.register(Entity {
            symbol: "John".into(),
            gender: Gender::Male,
            number: Number::Singular,
            noun_class: "John".into(),
            ownership: OwnershipState::Owned,
        });
        ctx.register(Entity {
            symbol: "Mary".into(),
            gender: Gender::Female,
            number: Number::Singular,
            noun_class: "Mary".into(),
            ownership: OwnershipState::Owned,
        });
        let he = ctx.resolve_pronoun(Gender::Male, Number::Singular);
        let she = ctx.resolve_pronoun(Gender::Female, Number::Singular);
        assert_eq!(he.unwrap().symbol, "John");
        assert_eq!(she.unwrap().symbol, "Mary");
    }
}

```

---

### Discourse Representation Structures

**File:** `src/drs.rs`

Kamp's DRT implementation for donkey anaphora and accessibility. **ReferentSource** tracks where variables are introduced (MainClause, ConditionalAntecedent, UniversalRestrictor, NegationScope). **BoxType** represents DRS boxes (Main, ConditionalAntecedent/Consequent, NegationScope, UniversalRestrictor/Scope, Disjunct). **Referent** stores variable info with noun_class, gender, source, and used_by_pronoun flag. **DrsBox** contains universe of referents with parent pointer. **Drs** manages box stack and provides introduce_referent(), resolve_pronoun(), find_accessible_referent() methods.

```rust
use crate::context::Gender;
use crate::intern::Symbol;

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum ReferentSource {
    /// Indefinite in main clause - gets existential force
    MainClause,
    /// Proper name - no quantifier (constant)
    ProperName,
    /// Indefinite in conditional antecedent - gets universal force (DRS signature)
    ConditionalAntecedent,
    /// Indefinite in universal restrictor (relative clause) - gets universal force
    UniversalRestrictor,
    /// Inside negation scope - inaccessible outward
    NegationScope,
    /// Inside disjunction - inaccessible outward
    Disjunct,
}

impl ReferentSource {
    pub fn gets_universal_force(&self) -> bool {
        matches!(
            self,
            ReferentSource::ConditionalAntecedent | ReferentSource::UniversalRestrictor
        )
    }
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum BoxType {
    /// Top-level discourse box
    Main,
    /// Antecedent of conditional ("if" clause)
    ConditionalAntecedent,
    /// Consequent of conditional ("then" clause)
    ConditionalConsequent,
    /// Scope of negation
    NegationScope,
    /// Restrictor of universal quantifier (relative clause in "every X who...")
    UniversalRestrictor,
    /// Nuclear scope of universal quantifier
    UniversalScope,
    /// Branch of disjunction
    Disjunct,
}

impl BoxType {
    pub fn to_referent_source(&self) -> ReferentSource {
        match self {
            BoxType::Main => ReferentSource::MainClause,
            BoxType::ConditionalAntecedent => ReferentSource::ConditionalAntecedent,
            BoxType::ConditionalConsequent => ReferentSource::MainClause,
            BoxType::NegationScope => ReferentSource::NegationScope,
            BoxType::UniversalRestrictor => ReferentSource::UniversalRestrictor,
            BoxType::UniversalScope => ReferentSource::MainClause,
            BoxType::Disjunct => ReferentSource::Disjunct,
        }
    }
}

#[derive(Debug, Clone)]
pub struct Referent {
    pub variable: Symbol,
    pub noun_class: Symbol,
    pub gender: Gender,
    pub source: ReferentSource,
    pub used_by_pronoun: bool,
}

impl Referent {
    pub fn new(variable: Symbol, noun_class: Symbol, gender: Gender, source: ReferentSource) -> Self {
        Self {
            variable,
            noun_class,
            gender,
            source,
            used_by_pronoun: false,
        }
    }

    pub fn should_be_universal(&self) -> bool {
        self.source.gets_universal_force() || self.used_by_pronoun
    }
}

#[derive(Debug, Clone, Default)]
pub struct DrsBox {
    pub universe: Vec<Referent>,
    pub box_type: Option<BoxType>,
    pub parent: Option<usize>,
}

impl DrsBox {
    pub fn new(box_type: BoxType, parent: Option<usize>) -> Self {
        Self {
            universe: Vec::new(),
            box_type: Some(box_type),
            parent,
        }
    }
}

#[derive(Debug, Clone)]
pub struct Drs {
    boxes: Vec<DrsBox>,
    main_box: usize,
    current_box: usize,
}

impl Drs {
    pub fn new() -> Self {
        let main = DrsBox::new(BoxType::Main, None);
        Self {
            boxes: vec![main],
            main_box: 0,
            current_box: 0,
        }
    }

    pub fn enter_box(&mut self, box_type: BoxType) -> usize {
        let parent = self.current_box;
        let new_box = DrsBox::new(box_type, Some(parent));
        let idx = self.boxes.len();
        self.boxes.push(new_box);
        self.current_box = idx;
        idx
    }

    pub fn exit_box(&mut self) {
        if let Some(parent) = self.boxes[self.current_box].parent {
            self.current_box = parent;
        }
    }

    pub fn current_box_index(&self) -> usize {
        self.current_box
    }

    pub fn current_box_type(&self) -> Option<BoxType> {
        self.boxes.get(self.current_box).and_then(|b| b.box_type)
    }

    pub fn introduce_referent(&mut self, variable: Symbol, noun_class: Symbol, gender: Gender) {
        let source = self.boxes[self.current_box]
            .box_type
            .map(|bt| bt.to_referent_source())
            .unwrap_or(ReferentSource::MainClause);

        let referent = Referent::new(variable, noun_class, gender, source);
        self.boxes[self.current_box].universe.push(referent);
    }

    pub fn introduce_proper_name(&mut self, variable: Symbol, name: Symbol, gender: Gender) {
        let referent = Referent::new(variable, name, gender, ReferentSource::ProperName);
        self.boxes[self.current_box].universe.push(referent);
    }

    /// Check if a referent in box `from_box` can access referents in box `target_box`
    pub fn is_accessible(&self, target_box: usize, from_box: usize) -> bool {
        if target_box == from_box {
            return true;
        }

        let target = &self.boxes[target_box];
        let from = &self.boxes[from_box];

        // Check target box type - some boxes block outward access
        if let Some(bt) = target.box_type {
            match bt {
                BoxType::NegationScope | BoxType::Disjunct => {
                    // These boxes are NOT accessible from outside
                    return false;
                }
                _ => {}
            }
        }

        // Check if from_box can see target_box
        // Consequent can see antecedent
        if let (Some(BoxType::ConditionalConsequent), Some(BoxType::ConditionalAntecedent)) =
            (from.box_type, target.box_type)
        {
            // Check if they share the same parent (same conditional)
            if from.parent == target.parent {
                return true;
            }
        }

        // Universal scope can see universal restrictor
        if let (Some(BoxType::UniversalScope), Some(BoxType::UniversalRestrictor)) =
            (from.box_type, target.box_type)
        {
            if from.parent == target.parent {
                return true;
            }
        }

        // Can always access ancestors (parent chain)
        let mut current = from_box;
        while let Some(parent) = self.boxes[current].parent {
            if parent == target_box {
                return true;
            }
            current = parent;
        }

        false
    }

    /// Resolve a pronoun by finding accessible referents matching gender
    pub fn resolve_pronoun(&mut self, from_box: usize, gender: Gender) -> Option<Symbol> {
        // Search current box and accessible ancestors/siblings
        let mut candidates = Vec::new();

        // Check all boxes for accessibility
        for (box_idx, drs_box) in self.boxes.iter().enumerate() {
            if self.is_accessible(box_idx, from_box) {
                for referent in &drs_box.universe {
                    let gender_match = gender == Gender::Unknown
                        || referent.gender == Gender::Unknown
                        || referent.gender == gender
                        || gender == Gender::Neuter; // "it" can refer to things

                    if gender_match {
                        candidates.push((box_idx, referent.variable));
                    }
                }
            }
        }

        // Return most recent (last) candidate
        if let Some((box_idx, var)) = candidates.last() {
            // Mark as used by pronoun
            let box_idx = *box_idx;
            let var = *var;
            for referent in &mut self.boxes[box_idx].universe {
                if referent.variable == var {
                    referent.used_by_pronoun = true;
                    return Some(var);
                }
            }
        }

        None
    }

    /// Resolve a definite description by finding accessible referent matching noun class
    pub fn resolve_definite(&self, from_box: usize, noun_class: Symbol) -> Option<Symbol> {
        for (box_idx, drs_box) in self.boxes.iter().enumerate() {
            if self.is_accessible(box_idx, from_box) {
                for referent in drs_box.universe.iter().rev() {
                    if referent.noun_class == noun_class {
                        return Some(referent.variable);
                    }
                }
            }
        }
        None
    }

    /// Get all referents that should receive universal quantification
    pub fn get_universal_referents(&self) -> Vec<Symbol> {
        let mut result = Vec::new();
        for drs_box in &self.boxes {
            for referent in &drs_box.universe {
                if referent.should_be_universal() {
                    result.push(referent.variable);
                }
            }
        }
        result
    }

    /// Get all referents that should receive existential quantification
    pub fn get_existential_referents(&self) -> Vec<Symbol> {
        let mut result = Vec::new();
        for drs_box in &self.boxes {
            for referent in &drs_box.universe {
                if !referent.should_be_universal()
                    && !matches!(referent.source, ReferentSource::ProperName)
                {
                    result.push(referent.variable);
                }
            }
        }
        result
    }

    /// Get the most recent event referent (for binding weather adjectives to events)
    pub fn get_last_event_referent(&self, interner: &crate::intern::Interner) -> Option<Symbol> {
        // Search all boxes in reverse order for event referents
        for drs_box in self.boxes.iter().rev() {
            for referent in drs_box.universe.iter().rev() {
                let class_str = interner.resolve(referent.noun_class);
                if class_str == "Event" {
                    return Some(referent.variable);
                }
            }
        }
        None
    }

    /// Check if we're currently in a conditional antecedent
    pub fn in_conditional_antecedent(&self) -> bool {
        matches!(
            self.boxes.get(self.current_box).and_then(|b| b.box_type),
            Some(BoxType::ConditionalAntecedent)
        )
    }

    /// Check if we're currently in a universal restrictor
    pub fn in_universal_restrictor(&self) -> bool {
        matches!(
            self.boxes.get(self.current_box).and_then(|b| b.box_type),
            Some(BoxType::UniversalRestrictor)
        )
    }

    pub fn clear(&mut self) {
        self.boxes.clear();
        let main = DrsBox::new(BoxType::Main, None);
        self.boxes.push(main);
        self.main_box = 0;
        self.current_box = 0;
    }
}

impl Default for Drs {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::intern::Interner;

    #[test]
    fn referent_source_universal_force() {
        assert!(ReferentSource::ConditionalAntecedent.gets_universal_force());
        assert!(ReferentSource::UniversalRestrictor.gets_universal_force());
        assert!(!ReferentSource::MainClause.gets_universal_force());
        assert!(!ReferentSource::ProperName.gets_universal_force());
    }

    #[test]
    fn drs_new_has_main_box() {
        let drs = Drs::new();
        assert_eq!(drs.boxes.len(), 1);
        assert_eq!(drs.current_box, 0);
        assert_eq!(drs.boxes[0].box_type, Some(BoxType::Main));
    }

    #[test]
    fn drs_enter_exit_box() {
        let mut drs = Drs::new();
        assert_eq!(drs.current_box, 0);

        let ant_idx = drs.enter_box(BoxType::ConditionalAntecedent);
        assert_eq!(ant_idx, 1);
        assert_eq!(drs.current_box, 1);
        assert_eq!(drs.boxes[1].parent, Some(0));

        drs.exit_box();
        assert_eq!(drs.current_box, 0);
    }

    #[test]
    fn drs_introduce_referent_tracks_source() {
        let mut interner = Interner::new();
        let mut drs = Drs::new();

        let x = interner.intern("x");
        let farmer = interner.intern("Farmer");

        // In main box - should be MainClause
        drs.introduce_referent(x, farmer, Gender::Male);
        assert_eq!(drs.boxes[0].universe[0].source, ReferentSource::MainClause);

        // Enter conditional antecedent
        drs.enter_box(BoxType::ConditionalAntecedent);
        let y = interner.intern("y");
        let donkey = interner.intern("Donkey");
        drs.introduce_referent(y, donkey, Gender::Neuter);
        assert_eq!(
            drs.boxes[1].universe[0].source,
            ReferentSource::ConditionalAntecedent
        );
    }

    #[test]
    fn drs_conditional_antecedent_accessible_from_consequent() {
        let mut interner = Interner::new();
        let mut drs = Drs::new();

        // Enter conditional antecedent
        let ant_idx = drs.enter_box(BoxType::ConditionalAntecedent);
        let y = interner.intern("y");
        let donkey = interner.intern("Donkey");
        drs.introduce_referent(y, donkey, Gender::Neuter);
        drs.exit_box();

        // Enter conditional consequent
        let cons_idx = drs.enter_box(BoxType::ConditionalConsequent);

        // Consequent should be able to access antecedent
        assert!(drs.is_accessible(ant_idx, cons_idx));
    }

    #[test]
    fn drs_negation_blocks_accessibility() {
        let mut drs = Drs::new();

        // Enter negation scope
        let neg_idx = drs.enter_box(BoxType::NegationScope);
        drs.exit_box();

        // Main box should NOT be able to access negation scope
        assert!(!drs.is_accessible(neg_idx, 0));
    }

    #[test]
    fn drs_get_universal_referents() {
        let mut interner = Interner::new();
        let mut drs = Drs::new();

        let x = interner.intern("x");
        let farmer = interner.intern("Farmer");
        drs.introduce_referent(x, farmer, Gender::Male);

        drs.enter_box(BoxType::ConditionalAntecedent);
        let y = interner.intern("y");
        let donkey = interner.intern("Donkey");
        drs.introduce_referent(y, donkey, Gender::Neuter);

        let universals = drs.get_universal_referents();
        assert_eq!(universals.len(), 1);
        assert_eq!(universals[0], y);
    }

    #[test]
    fn drs_pronoun_resolution_marks_used() {
        let mut interner = Interner::new();
        let mut drs = Drs::new();

        drs.enter_box(BoxType::UniversalRestrictor);
        let y = interner.intern("y");
        let donkey = interner.intern("Donkey");
        drs.introduce_referent(y, donkey, Gender::Neuter);

        // Resolve "it" - should find donkey
        let resolved = drs.resolve_pronoun(drs.current_box, Gender::Neuter);
        assert_eq!(resolved, Some(y));

        // Should be marked as used
        assert!(drs.boxes[1].universe[0].used_by_pronoun);
    }
}

```

---

### AST Views & Resolution

**File:** `src/view.rs`

ExprView (including Causal variant), TermView, NounPhraseView types for AST traversal. Symbol resolution and display utilities.

```rust
use crate::ast::{
    AspectOperator, LogicExpr, ModalVector, NounPhrase, QuantifierKind, TemporalOperator, VoiceOperator, Term,
    ThematicRole,
};
use crate::intern::Interner;
use crate::lexicon::Definiteness;
use crate::token::{FocusKind, TokenType};

#[derive(Debug, Clone, PartialEq)]
pub enum TermView<'a> {
    Constant(&'a str),
    Variable(&'a str),
    Function(&'a str, Vec<TermView<'a>>),
    Group(Vec<TermView<'a>>),
    Possessed {
        possessor: Box<TermView<'a>>,
        possessed: &'a str,
    },
    Sigma(&'a str),
    Intension(&'a str),
    Proposition(Box<ExprView<'a>>),
    Value {
        kind: NumberKindView<'a>,
        unit: Option<&'a str>,
        dimension: Option<crate::ast::Dimension>,
    },
}

#[derive(Debug, Clone, PartialEq)]
pub enum NumberKindView<'a> {
    Real(f64),
    Integer(i64),
    Symbolic(&'a str),
}

#[derive(Debug, Clone, PartialEq)]
pub struct NounPhraseView<'a> {
    pub definiteness: Option<Definiteness>,
    pub adjectives: Vec<&'a str>,
    pub noun: &'a str,
    pub possessor: Option<Box<NounPhraseView<'a>>>,
    pub pps: Vec<Box<ExprView<'a>>>,
    pub superlative: Option<&'a str>,
}

#[derive(Debug, Clone, PartialEq)]
pub enum ExprView<'a> {
    Predicate {
        name: &'a str,
        args: Vec<TermView<'a>>,
    },
    Identity {
        left: TermView<'a>,
        right: TermView<'a>,
    },
    Metaphor {
        tenor: TermView<'a>,
        vehicle: TermView<'a>,
    },
    Quantifier {
        kind: QuantifierKind,
        variable: &'a str,
        body: Box<ExprView<'a>>,
    },
    Categorical {
        quantifier: TokenType,
        subject: NounPhraseView<'a>,
        copula_negative: bool,
        predicate: NounPhraseView<'a>,
    },
    Relation {
        subject: NounPhraseView<'a>,
        verb: &'a str,
        object: NounPhraseView<'a>,
    },
    Modal {
        vector: ModalVector,
        operand: Box<ExprView<'a>>,
    },
    Temporal {
        operator: TemporalOperator,
        body: Box<ExprView<'a>>,
    },
    Aspectual {
        operator: AspectOperator,
        body: Box<ExprView<'a>>,
    },
    Voice {
        operator: VoiceOperator,
        body: Box<ExprView<'a>>,
    },
    BinaryOp {
        left: Box<ExprView<'a>>,
        op: TokenType,
        right: Box<ExprView<'a>>,
    },
    UnaryOp {
        op: TokenType,
        operand: Box<ExprView<'a>>,
    },
    Question {
        wh_variable: &'a str,
        body: Box<ExprView<'a>>,
    },
    YesNoQuestion {
        body: Box<ExprView<'a>>,
    },
    Atom(&'a str),
    Lambda {
        variable: &'a str,
        body: Box<ExprView<'a>>,
    },
    App {
        function: Box<ExprView<'a>>,
        argument: Box<ExprView<'a>>,
    },
    Intensional {
        operator: &'a str,
        content: Box<ExprView<'a>>,
    },
    Event {
        predicate: Box<ExprView<'a>>,
        adverbs: Vec<&'a str>,
    },
    NeoEvent {
        event_var: &'a str,
        verb: &'a str,
        roles: Vec<(ThematicRole, TermView<'a>)>,
        modifiers: Vec<&'a str>,
    },
    Imperative {
        action: Box<ExprView<'a>>,
    },
    SpeechAct {
        performer: &'a str,
        act_type: &'a str,
        content: Box<ExprView<'a>>,
    },
    Counterfactual {
        antecedent: Box<ExprView<'a>>,
        consequent: Box<ExprView<'a>>,
    },
    Causal {
        effect: Box<ExprView<'a>>,
        cause: Box<ExprView<'a>>,
    },
    Comparative {
        adjective: &'a str,
        subject: TermView<'a>,
        object: TermView<'a>,
        difference: Option<Box<TermView<'a>>>,
    },
    Superlative {
        adjective: &'a str,
        subject: TermView<'a>,
        domain: &'a str,
    },
    Scopal {
        operator: &'a str,
        body: Box<ExprView<'a>>,
    },
    Control {
        verb: &'a str,
        subject: TermView<'a>,
        object: Option<TermView<'a>>,
        infinitive: Box<ExprView<'a>>,
    },
    Presupposition {
        assertion: Box<ExprView<'a>>,
        presupposition: Box<ExprView<'a>>,
    },
    Focus {
        kind: FocusKind,
        focused: TermView<'a>,
        scope: Box<ExprView<'a>>,
    },
    TemporalAnchor {
        anchor: &'a str,
        body: Box<ExprView<'a>>,
    },
    Distributive {
        predicate: Box<ExprView<'a>>,
    },
    GroupQuantifier {
        group_var: &'a str,
        count: u32,
        member_var: &'a str,
        restriction: Box<ExprView<'a>>,
        body: Box<ExprView<'a>>,
    },
}

pub trait Resolve<'a> {
    type Output;
    fn resolve(&self, interner: &'a Interner) -> Self::Output;
}

impl<'a, 'b> Resolve<'a> for Term<'b> {
    type Output = TermView<'a>;

    fn resolve(&self, interner: &'a Interner) -> TermView<'a> {
        match self {
            Term::Constant(s) => TermView::Constant(interner.resolve(*s)),
            Term::Variable(s) => TermView::Variable(interner.resolve(*s)),
            Term::Function(name, args) => TermView::Function(
                interner.resolve(*name),
                args.iter().map(|a| a.resolve(interner)).collect(),
            ),
            Term::Group(members) => {
                TermView::Group(members.iter().map(|m| m.resolve(interner)).collect())
            }
            Term::Possessed {
                possessor,
                possessed,
            } => TermView::Possessed {
                possessor: Box::new(possessor.resolve(interner)),
                possessed: interner.resolve(*possessed),
            },
            Term::Sigma(predicate) => TermView::Sigma(interner.resolve(*predicate)),
            Term::Intension(predicate) => TermView::Intension(interner.resolve(*predicate)),
            Term::Proposition(expr) => {
                TermView::Proposition(Box::new(expr.resolve(interner)))
            }
            Term::Value { kind, unit, dimension } => {
                use crate::ast::NumberKind;
                let kind_view = match kind {
                    NumberKind::Real(r) => NumberKindView::Real(*r),
                    NumberKind::Integer(i) => NumberKindView::Integer(*i),
                    NumberKind::Symbolic(s) => NumberKindView::Symbolic(interner.resolve(*s)),
                };
                TermView::Value {
                    kind: kind_view,
                    unit: unit.map(|u| interner.resolve(u)),
                    dimension: *dimension,
                }
            }
        }
    }
}

impl<'a, 'b> Resolve<'a> for NounPhrase<'b> {
    type Output = NounPhraseView<'a>;

    fn resolve(&self, interner: &'a Interner) -> NounPhraseView<'a> {
        NounPhraseView {
            definiteness: self.definiteness,
            adjectives: self.adjectives.iter().map(|s| interner.resolve(*s)).collect(),
            noun: interner.resolve(self.noun),
            possessor: self.possessor.map(|p| Box::new(p.resolve(interner))),
            pps: self.pps.iter().map(|pp| Box::new(pp.resolve(interner))).collect(),
            superlative: self.superlative.map(|s| interner.resolve(s)),
        }
    }
}

impl<'a, 'b> Resolve<'a> for LogicExpr<'b> {
    type Output = ExprView<'a>;

    fn resolve(&self, interner: &'a Interner) -> ExprView<'a> {
        match self {
            LogicExpr::Predicate { name, args } => ExprView::Predicate {
                name: interner.resolve(*name),
                args: args.iter().map(|a| a.resolve(interner)).collect(),
            },
            LogicExpr::Identity { left, right } => ExprView::Identity {
                left: left.resolve(interner),
                right: right.resolve(interner),
            },
            LogicExpr::Metaphor { tenor, vehicle } => ExprView::Metaphor {
                tenor: tenor.resolve(interner),
                vehicle: vehicle.resolve(interner),
            },
            LogicExpr::Quantifier { kind, variable, body, .. } => ExprView::Quantifier {
                kind: *kind,
                variable: interner.resolve(*variable),
                body: Box::new(body.resolve(interner)),
            },
            LogicExpr::Categorical(data) => ExprView::Categorical {
                quantifier: data.quantifier.clone(),
                subject: data.subject.resolve(interner),
                copula_negative: data.copula_negative,
                predicate: data.predicate.resolve(interner),
            },
            LogicExpr::Relation(data) => ExprView::Relation {
                subject: data.subject.resolve(interner),
                verb: interner.resolve(data.verb),
                object: data.object.resolve(interner),
            },
            LogicExpr::Modal { vector, operand } => ExprView::Modal {
                vector: *vector,
                operand: Box::new(operand.resolve(interner)),
            },
            LogicExpr::Temporal { operator, body } => ExprView::Temporal {
                operator: *operator,
                body: Box::new(body.resolve(interner)),
            },
            LogicExpr::Aspectual { operator, body } => ExprView::Aspectual {
                operator: *operator,
                body: Box::new(body.resolve(interner)),
            },
            LogicExpr::Voice { operator, body } => ExprView::Voice {
                operator: *operator,
                body: Box::new(body.resolve(interner)),
            },
            LogicExpr::BinaryOp { left, op, right } => ExprView::BinaryOp {
                left: Box::new(left.resolve(interner)),
                op: op.clone(),
                right: Box::new(right.resolve(interner)),
            },
            LogicExpr::UnaryOp { op, operand } => ExprView::UnaryOp {
                op: op.clone(),
                operand: Box::new(operand.resolve(interner)),
            },
            LogicExpr::Question { wh_variable, body } => ExprView::Question {
                wh_variable: interner.resolve(*wh_variable),
                body: Box::new(body.resolve(interner)),
            },
            LogicExpr::YesNoQuestion { body } => ExprView::YesNoQuestion {
                body: Box::new(body.resolve(interner)),
            },
            LogicExpr::Atom(s) => ExprView::Atom(interner.resolve(*s)),
            LogicExpr::Lambda { variable, body } => ExprView::Lambda {
                variable: interner.resolve(*variable),
                body: Box::new(body.resolve(interner)),
            },
            LogicExpr::App { function, argument } => ExprView::App {
                function: Box::new(function.resolve(interner)),
                argument: Box::new(argument.resolve(interner)),
            },
            LogicExpr::Intensional { operator, content } => ExprView::Intensional {
                operator: interner.resolve(*operator),
                content: Box::new(content.resolve(interner)),
            },
            LogicExpr::Event { predicate, adverbs } => ExprView::Event {
                predicate: Box::new(predicate.resolve(interner)),
                adverbs: adverbs.iter().map(|s| interner.resolve(*s)).collect(),
            },
            LogicExpr::NeoEvent(data) => ExprView::NeoEvent {
                event_var: interner.resolve(data.event_var),
                verb: interner.resolve(data.verb),
                roles: data.roles.iter().map(|(role, term)| (*role, term.resolve(interner))).collect(),
                modifiers: data.modifiers.iter().map(|s| interner.resolve(*s)).collect(),
            },
            LogicExpr::Imperative { action } => ExprView::Imperative {
                action: Box::new(action.resolve(interner)),
            },
            LogicExpr::SpeechAct {
                performer,
                act_type,
                content,
            } => ExprView::SpeechAct {
                performer: interner.resolve(*performer),
                act_type: interner.resolve(*act_type),
                content: Box::new(content.resolve(interner)),
            },
            LogicExpr::Counterfactual { antecedent, consequent } => ExprView::Counterfactual {
                antecedent: Box::new(antecedent.resolve(interner)),
                consequent: Box::new(consequent.resolve(interner)),
            },
            LogicExpr::Causal { effect, cause } => ExprView::Causal {
                effect: Box::new(effect.resolve(interner)),
                cause: Box::new(cause.resolve(interner)),
            },
            LogicExpr::Comparative { adjective, subject, object, difference } => ExprView::Comparative {
                adjective: interner.resolve(*adjective),
                subject: subject.resolve(interner),
                object: object.resolve(interner),
                difference: difference.map(|d| Box::new(d.resolve(interner))),
            },
            LogicExpr::Superlative { adjective, subject, domain } => ExprView::Superlative {
                adjective: interner.resolve(*adjective),
                subject: subject.resolve(interner),
                domain: interner.resolve(*domain),
            },
            LogicExpr::Scopal { operator, body } => ExprView::Scopal {
                operator: interner.resolve(*operator),
                body: Box::new(body.resolve(interner)),
            },
            LogicExpr::Control {
                verb,
                subject,
                object,
                infinitive,
            } => ExprView::Control {
                verb: interner.resolve(*verb),
                subject: subject.resolve(interner),
                object: object.map(|o| o.resolve(interner)),
                infinitive: Box::new(infinitive.resolve(interner)),
            },
            LogicExpr::Presupposition { assertion, presupposition } => ExprView::Presupposition {
                assertion: Box::new(assertion.resolve(interner)),
                presupposition: Box::new(presupposition.resolve(interner)),
            },
            LogicExpr::Focus { kind, focused, scope } => ExprView::Focus {
                kind: *kind,
                focused: focused.resolve(interner),
                scope: Box::new(scope.resolve(interner)),
            },
            LogicExpr::TemporalAnchor { anchor, body } => ExprView::TemporalAnchor {
                anchor: interner.resolve(*anchor),
                body: Box::new(body.resolve(interner)),
            },
            LogicExpr::Distributive { predicate } => ExprView::Distributive {
                predicate: Box::new(predicate.resolve(interner)),
            },
            LogicExpr::GroupQuantifier { group_var, count, member_var, restriction, body } => ExprView::GroupQuantifier {
                group_var: interner.resolve(*group_var),
                count: *count,
                member_var: interner.resolve(*member_var),
                restriction: Box::new(restriction.resolve(interner)),
                body: Box::new(body.resolve(interner)),
            },
        }
    }
}

#[cfg(test)]
mod term_view_tests {
    use super::*;
    use crate::arena::Arena;

    #[test]
    fn resolve_term_constant() {
        let mut interner = Interner::new();
        let sym = interner.intern("Socrates");
        let term = Term::Constant(sym);
        assert_eq!(term.resolve(&interner), TermView::Constant("Socrates"));
    }

    #[test]
    fn resolve_term_variable() {
        let mut interner = Interner::new();
        let x = interner.intern("x");
        let term = Term::Variable(x);
        assert_eq!(term.resolve(&interner), TermView::Variable("x"));
    }

    #[test]
    fn resolve_term_function() {
        let mut interner = Interner::new();
        let term_arena: Arena<Term> = Arena::new();
        let father = interner.intern("father");
        let john = interner.intern("John");
        let term = Term::Function(father, term_arena.alloc_slice([Term::Constant(john)]));

        assert_eq!(
            term.resolve(&interner),
            TermView::Function("father", vec![TermView::Constant("John")])
        );
    }

    #[test]
    fn resolve_term_group() {
        let mut interner = Interner::new();
        let term_arena: Arena<Term> = Arena::new();
        let j = interner.intern("John");
        let m = interner.intern("Mary");
        let term = Term::Group(term_arena.alloc_slice([Term::Constant(j), Term::Constant(m)]));

        assert_eq!(
            term.resolve(&interner),
            TermView::Group(vec![
                TermView::Constant("John"),
                TermView::Constant("Mary")
            ])
        );
    }

    #[test]
    fn resolve_term_possessed() {
        let mut interner = Interner::new();
        let term_arena: Arena<Term> = Arena::new();
        let john = interner.intern("John");
        let dog = interner.intern("dog");
        let term = Term::Possessed {
            possessor: term_arena.alloc(Term::Constant(john)),
            possessed: dog,
        };

        assert_eq!(
            term.resolve(&interner),
            TermView::Possessed {
                possessor: Box::new(TermView::Constant("John")),
                possessed: "dog",
            }
        );
    }

    #[test]
    fn term_view_equality_is_bit_exact() {
        let a = TermView::Constant("test");
        let b = TermView::Constant("test");
        let c = TermView::Constant("Test");
        assert_eq!(a, b);
        assert_ne!(a, c);
    }

    #[test]
    fn nested_function_resolve() {
        let mut interner = Interner::new();
        let term_arena: Arena<Term> = Arena::new();
        let f = interner.intern("f");
        let g = interner.intern("g");
        let x = interner.intern("x");

        let inner = Term::Function(g, term_arena.alloc_slice([Term::Variable(x)]));
        let outer = Term::Function(f, term_arena.alloc_slice([inner]));

        assert_eq!(
            outer.resolve(&interner),
            TermView::Function(
                "f",
                vec![TermView::Function("g", vec![TermView::Variable("x")])]
            )
        );
    }
}

#[cfg(test)]
mod expr_view_tests {
    use super::*;
    use crate::arena::Arena;
    use crate::ast::ModalDomain;

    #[test]
    fn resolve_expr_predicate() {
        let mut interner = Interner::new();
        let term_arena: Arena<Term> = Arena::new();
        let mortal = interner.intern("Mortal");
        let x = interner.intern("x");
        let expr = LogicExpr::Predicate {
            name: mortal,
            args: term_arena.alloc_slice([Term::Variable(x)]),
        };

        assert_eq!(
            expr.resolve(&interner),
            ExprView::Predicate {
                name: "Mortal",
                args: vec![TermView::Variable("x")],
            }
        );
    }

    #[test]
    fn resolve_expr_identity() {
        let mut interner = Interner::new();
        let term_arena: Arena<Term> = Arena::new();
        let clark = interner.intern("Clark");
        let superman = interner.intern("Superman");
        let expr = LogicExpr::Identity {
            left: term_arena.alloc(Term::Constant(clark)),
            right: term_arena.alloc(Term::Constant(superman)),
        };

        assert_eq!(
            expr.resolve(&interner),
            ExprView::Identity {
                left: TermView::Constant("Clark"),
                right: TermView::Constant("Superman"),
            }
        );
    }

    #[test]
    fn resolve_expr_quantifier() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();
        let x = interner.intern("x");
        let mortal = interner.intern("Mortal");

        let body = expr_arena.alloc(LogicExpr::Predicate {
            name: mortal,
            args: term_arena.alloc_slice([Term::Variable(x)]),
        });
        let expr = LogicExpr::Quantifier {
            kind: QuantifierKind::Universal,
            variable: x,
            body,
            island_id: 0,
        };

        assert_eq!(
            expr.resolve(&interner),
            ExprView::Quantifier {
                kind: QuantifierKind::Universal,
                variable: "x",
                body: Box::new(ExprView::Predicate {
                    name: "Mortal",
                    args: vec![TermView::Variable("x")],
                }),
            }
        );
    }

    #[test]
    fn resolve_expr_atom() {
        let mut interner = Interner::new();
        let p = interner.intern("P");
        let expr = LogicExpr::Atom(p);

        assert_eq!(expr.resolve(&interner), ExprView::Atom("P"));
    }

    #[test]
    fn resolve_expr_binary_op() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let p = interner.intern("P");
        let q = interner.intern("Q");
        let expr = LogicExpr::BinaryOp {
            left: expr_arena.alloc(LogicExpr::Atom(p)),
            op: TokenType::And,
            right: expr_arena.alloc(LogicExpr::Atom(q)),
        };

        assert_eq!(
            expr.resolve(&interner),
            ExprView::BinaryOp {
                left: Box::new(ExprView::Atom("P")),
                op: TokenType::And,
                right: Box::new(ExprView::Atom("Q")),
            }
        );
    }

    #[test]
    fn resolve_expr_lambda() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let x = interner.intern("x");
        let p = interner.intern("P");
        let expr = LogicExpr::Lambda {
            variable: x,
            body: expr_arena.alloc(LogicExpr::Atom(p)),
        };

        assert_eq!(
            expr.resolve(&interner),
            ExprView::Lambda {
                variable: "x",
                body: Box::new(ExprView::Atom("P")),
            }
        );
    }

    #[test]
    fn resolve_expr_temporal() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let run = interner.intern("Run");
        let expr = LogicExpr::Temporal {
            operator: TemporalOperator::Past,
            body: expr_arena.alloc(LogicExpr::Atom(run)),
        };

        assert_eq!(
            expr.resolve(&interner),
            ExprView::Temporal {
                operator: TemporalOperator::Past,
                body: Box::new(ExprView::Atom("Run")),
            }
        );
    }

    #[test]
    fn resolve_expr_modal() {
        use crate::ast::ModalFlavor;
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let rain = interner.intern("Rain");
        let expr = LogicExpr::Modal {
            vector: ModalVector {
                domain: ModalDomain::Alethic,
                force: 1.0,
                flavor: ModalFlavor::Root,
            },
            operand: expr_arena.alloc(LogicExpr::Atom(rain)),
        };

        assert_eq!(
            expr.resolve(&interner),
            ExprView::Modal {
                vector: ModalVector {
                    domain: ModalDomain::Alethic,
                    force: 1.0,
                    flavor: ModalFlavor::Root,
                },
                operand: Box::new(ExprView::Atom("Rain")),
            }
        );
    }

    #[test]
    fn modal_vector_equality_is_bit_exact() {
        use crate::ast::ModalFlavor;
        let v1 = ModalVector {
            domain: ModalDomain::Alethic,
            force: 0.5,
            flavor: ModalFlavor::Root,
        };
        let v2 = ModalVector {
            domain: ModalDomain::Alethic,
            force: 0.5,
            flavor: ModalFlavor::Root,
        };
        let v3 = ModalVector {
            domain: ModalDomain::Alethic,
            force: 0.51,
            flavor: ModalFlavor::Root,
        };

        assert_eq!(v1, v2);
        assert_ne!(v1, v3);
    }

    #[test]
    fn resolve_expr_unary_op() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let p = interner.intern("P");
        let expr = LogicExpr::UnaryOp {
            op: TokenType::Not,
            operand: expr_arena.alloc(LogicExpr::Atom(p)),
        };

        assert_eq!(
            expr.resolve(&interner),
            ExprView::UnaryOp {
                op: TokenType::Not,
                operand: Box::new(ExprView::Atom("P")),
            }
        );
    }

    #[test]
    fn resolve_expr_app() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let f = interner.intern("f");
        let x = interner.intern("x");
        let expr = LogicExpr::App {
            function: expr_arena.alloc(LogicExpr::Atom(f)),
            argument: expr_arena.alloc(LogicExpr::Atom(x)),
        };

        assert_eq!(
            expr.resolve(&interner),
            ExprView::App {
                function: Box::new(ExprView::Atom("f")),
                argument: Box::new(ExprView::Atom("x")),
            }
        );
    }

    #[test]
    fn expr_view_equality_complex() {
        let a = ExprView::Quantifier {
            kind: QuantifierKind::Universal,
            variable: "x",
            body: Box::new(ExprView::Predicate {
                name: "P",
                args: vec![TermView::Variable("x")],
            }),
        };
        let b = ExprView::Quantifier {
            kind: QuantifierKind::Universal,
            variable: "x",
            body: Box::new(ExprView::Predicate {
                name: "P",
                args: vec![TermView::Variable("x")],
            }),
        };
        assert_eq!(a, b);
    }
}

```

---

### Semantics Module

**File:** `src/semantics/mod.rs`

Entry point for semantic axiom layer. Includes generated axiom_data and exports apply_axioms().

```rust
mod axioms;

pub use axioms::apply_axioms;

include!(concat!(env!("OUT_DIR"), "/axiom_data.rs"));

```

---

### Axiom Expansion

**File:** `src/semantics/axioms.rs`

AST transformation for meaning postulates. Handles noun entailments (bachelor→unmarried), hypernyms (dog→animal), privative adjectives (fake→¬N∧Resembles), and verb entailments (murder→kill).

```rust
use crate::arena::Arena;
use crate::ast::{LogicExpr, NeoEventData, Term, ThematicRole};
use crate::intern::{Interner, Symbol};
use crate::lexicon::{lookup_canonical, Polarity};
use crate::token::TokenType;

use super::{is_privative_adjective, lookup_noun_entailments, lookup_noun_hypernyms, lookup_verb_entailment};

pub fn apply_axioms<'a>(
    expr: &'a LogicExpr<'a>,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
    interner: &mut Interner,
) -> &'a LogicExpr<'a> {
    transform_expr(expr, expr_arena, term_arena, interner)
}

fn transform_expr<'a>(
    expr: &'a LogicExpr<'a>,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
    interner: &mut Interner,
) -> &'a LogicExpr<'a> {
    match expr {
        LogicExpr::Predicate { name, args } => {
            expand_predicate(*name, args, expr_arena, term_arena, interner)
        }

        LogicExpr::Quantifier { kind, variable, body, island_id } => {
            let new_body = transform_expr(body, expr_arena, term_arena, interner);
            expr_arena.alloc(LogicExpr::Quantifier {
                kind: *kind,
                variable: *variable,
                body: new_body,
                island_id: *island_id,
            })
        }

        LogicExpr::BinaryOp { left, op, right } => {
            let new_left = transform_expr(left, expr_arena, term_arena, interner);
            let new_right = transform_expr(right, expr_arena, term_arena, interner);
            expr_arena.alloc(LogicExpr::BinaryOp {
                left: new_left,
                op: op.clone(),
                right: new_right,
            })
        }

        LogicExpr::UnaryOp { op, operand } => {
            let new_operand = transform_expr(operand, expr_arena, term_arena, interner);
            expr_arena.alloc(LogicExpr::UnaryOp {
                op: op.clone(),
                operand: new_operand,
            })
        }

        LogicExpr::NeoEvent(data) => {
            expand_neo_event(data, expr_arena, term_arena, interner)
        }

        LogicExpr::Modal { vector, operand } => {
            let new_operand = transform_expr(operand, expr_arena, term_arena, interner);
            expr_arena.alloc(LogicExpr::Modal {
                vector: *vector,
                operand: new_operand,
            })
        }

        LogicExpr::Temporal { operator, body } => {
            let new_body = transform_expr(body, expr_arena, term_arena, interner);
            expr_arena.alloc(LogicExpr::Temporal {
                operator: *operator,
                body: new_body,
            })
        }

        LogicExpr::Lambda { variable, body } => {
            let new_body = transform_expr(body, expr_arena, term_arena, interner);
            expr_arena.alloc(LogicExpr::Lambda {
                variable: *variable,
                body: new_body,
            })
        }

        LogicExpr::Question { wh_variable, body } => {
            let new_body = transform_expr(body, expr_arena, term_arena, interner);
            expr_arena.alloc(LogicExpr::Question {
                wh_variable: *wh_variable,
                body: new_body,
            })
        }

        LogicExpr::YesNoQuestion { body } => {
            let new_body = transform_expr(body, expr_arena, term_arena, interner);
            expr_arena.alloc(LogicExpr::YesNoQuestion { body: new_body })
        }

        _ => expr,
    }
}

fn expand_predicate<'a>(
    name: Symbol,
    args: &'a [Term<'a>],
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
    interner: &mut Interner,
) -> &'a LogicExpr<'a> {
    let name_str = interner.resolve(name).to_string();
    let lower_name = name_str.to_lowercase();

    // Check for canonical mapping (synonyms/antonyms)
    // E.g., Lack(x,y) -> ¬Have(x,y), Possess(x,y) -> Have(x,y)
    if let Some(mapping) = lookup_canonical(&lower_name) {
        let canonical_sym = interner.intern(mapping.lemma);
        let canonical_pred = expr_arena.alloc(LogicExpr::Predicate {
            name: canonical_sym,
            args,
        });

        // Wrap antonyms in negation
        return match mapping.polarity {
            Polarity::Positive => canonical_pred,
            Polarity::Negative => expr_arena.alloc(LogicExpr::UnaryOp {
                op: TokenType::Not,
                operand: canonical_pred,
            }),
        };
    }

    // Check for compound predicates (e.g., Fake-Gun from non-intersective adjectives)
    if let Some(hyphen_pos) = name_str.find('-') {
        let adj_part = name_str[..hyphen_pos].to_string();
        let noun_part = name_str[hyphen_pos + 1..].to_string();

        if is_privative_adjective(&adj_part) {
            return expand_privative(&noun_part, args, expr_arena, term_arena, interner);
        }
    }

    // Check for noun entailments (Bachelor -> Unmarried + Male)
    let entailments = lookup_noun_entailments(&lower_name);
    if !entailments.is_empty() {
        return expand_noun_entailments(name, args, entailments, expr_arena, term_arena, interner);
    }

    // Check for hypernyms (Dog -> Animal)
    let hypernyms = lookup_noun_hypernyms(&lower_name);
    if !hypernyms.is_empty() {
        return expand_hypernyms(name, args, hypernyms, expr_arena, term_arena, interner);
    }

    // No expansion needed - return original
    expr_arena.alloc(LogicExpr::Predicate { name, args })
}

fn expand_privative<'a>(
    noun: &str,
    args: &'a [Term<'a>],
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
    interner: &mut Interner,
) -> &'a LogicExpr<'a> {
    // Fake-Gun(x) => ¬Gun(x) ∧ Resembles(x, ^Gun)
    let noun_sym = interner.intern(noun);
    let resembles_sym = interner.intern("Resembles");

    // Gun(x)
    let noun_pred = expr_arena.alloc(LogicExpr::Predicate {
        name: noun_sym,
        args,
    });

    // ¬Gun(x)
    let negated_noun = expr_arena.alloc(LogicExpr::UnaryOp {
        op: TokenType::Not,
        operand: noun_pred,
    });

    // Resembles(x, ^Gun)
    let intension_term = Term::Intension(noun_sym);
    let mut resembles_args_vec = Vec::with_capacity(args.len() + 1);
    if !args.is_empty() {
        resembles_args_vec.push(clone_term(&args[0], term_arena));
    }
    resembles_args_vec.push(intension_term);
    let resembles_args = term_arena.alloc_slice(resembles_args_vec);

    let resembles_pred = expr_arena.alloc(LogicExpr::Predicate {
        name: resembles_sym,
        args: resembles_args,
    });

    // ¬Gun(x) ∧ Resembles(x, ^Gun)
    expr_arena.alloc(LogicExpr::BinaryOp {
        left: negated_noun,
        op: TokenType::And,
        right: resembles_pred,
    })
}

fn expand_noun_entailments<'a>(
    base: Symbol,
    args: &'a [Term<'a>],
    entailments: &[&str],
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
    interner: &mut Interner,
) -> &'a LogicExpr<'a> {
    // Bachelor(x) => Bachelor(x) ∧ Unmarried(x) ∧ Male(x)
    let base_pred = expr_arena.alloc(LogicExpr::Predicate { name: base, args });

    let mut result: &LogicExpr = base_pred;
    for entailment in entailments {
        let ent_sym = interner.intern(entailment);
        let ent_pred = expr_arena.alloc(LogicExpr::Predicate {
            name: ent_sym,
            args,
        });
        result = expr_arena.alloc(LogicExpr::BinaryOp {
            left: result,
            op: TokenType::And,
            right: ent_pred,
        });
    }

    result
}

fn expand_hypernyms<'a>(
    base: Symbol,
    args: &'a [Term<'a>],
    hypernyms: &[&str],
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
    interner: &mut Interner,
) -> &'a LogicExpr<'a> {
    // Dog(x) => Dog(x) ∧ Animal(x)
    let base_pred = expr_arena.alloc(LogicExpr::Predicate { name: base, args });

    let mut result: &LogicExpr = base_pred;
    for hypernym in hypernyms {
        let hyp_sym = interner.intern(hypernym);
        let hyp_pred = expr_arena.alloc(LogicExpr::Predicate {
            name: hyp_sym,
            args,
        });
        result = expr_arena.alloc(LogicExpr::BinaryOp {
            left: result,
            op: TokenType::And,
            right: hyp_pred,
        });
    }

    result
}

fn expand_neo_event<'a>(
    data: &NeoEventData<'a>,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    term_arena: &'a Arena<Term<'a>>,
    interner: &mut Interner,
) -> &'a LogicExpr<'a> {
    let verb_str = interner.resolve(data.verb);
    let lower_verb = verb_str.to_lowercase();

    // Check for canonical mapping (synonyms/antonyms)
    // E.g., Lack(x,y) -> ¬Have(x,y)
    if let Some(mapping) = lookup_canonical(&lower_verb) {
        let canonical_sym = interner.intern(mapping.lemma);

        // Create NeoEvent with canonical verb
        let canonical_event = expr_arena.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
            event_var: data.event_var,
            verb: canonical_sym,
            roles: data.roles,
            modifiers: data.modifiers,
            suppress_existential: data.suppress_existential,
        })));

        // Wrap antonyms in negation
        return match mapping.polarity {
            Polarity::Positive => canonical_event,
            Polarity::Negative => expr_arena.alloc(LogicExpr::UnaryOp {
                op: TokenType::Not,
                operand: canonical_event,
            }),
        };
    }

    if let Some((base_verb, manner_preds)) = lookup_verb_entailment(&lower_verb) {
        // Murder(e) => Murder(e) ∧ Kill(e) ∧ Intentional(Agent)
        let base_verb_sym = interner.intern(base_verb);

        // Keep original NeoEvent
        let original = expr_arena.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
            event_var: data.event_var,
            verb: data.verb,
            roles: data.roles,
            modifiers: data.modifiers,
            suppress_existential: data.suppress_existential,
        })));

        // Create entailed verb NeoEvent (e.g., Kill)
        let entailed_event = expr_arena.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
            event_var: data.event_var,
            verb: base_verb_sym,
            roles: data.roles,
            modifiers: data.modifiers,
            suppress_existential: data.suppress_existential,
        })));

        // Conjoin original with entailed
        let mut result = expr_arena.alloc(LogicExpr::BinaryOp {
            left: original,
            op: TokenType::And,
            right: entailed_event,
        });

        // Add manner predicates (e.g., Intentional(Agent))
        for manner in manner_preds {
            let manner_sym = interner.intern(manner);

            // Find the agent in roles
            let agent_term = data.roles.iter()
                .find(|(role, _)| *role == ThematicRole::Agent)
                .map(|(_, term)| term);

            if let Some(agent) = agent_term {
                let manner_args = term_arena.alloc_slice([clone_term(agent, term_arena)]);
                let manner_pred = expr_arena.alloc(LogicExpr::Predicate {
                    name: manner_sym,
                    args: manner_args,
                });
                result = expr_arena.alloc(LogicExpr::BinaryOp {
                    left: result,
                    op: TokenType::And,
                    right: manner_pred,
                });
            }
        }

        result
    } else {
        // No entailment - return original unchanged
        expr_arena.alloc(LogicExpr::NeoEvent(Box::new(NeoEventData {
            event_var: data.event_var,
            verb: data.verb,
            roles: data.roles,
            modifiers: data.modifiers,
            suppress_existential: data.suppress_existential,
        })))
    }
}

fn clone_term<'a>(term: &Term<'a>, arena: &'a Arena<Term<'a>>) -> Term<'a> {
    match term {
        Term::Constant(s) => Term::Constant(*s),
        Term::Variable(s) => Term::Variable(*s),
        Term::Function(s, args) => {
            let cloned_args: Vec<Term<'a>> = args.iter().map(|t| clone_term(t, arena)).collect();
            Term::Function(*s, arena.alloc_slice(cloned_args))
        }
        Term::Group(terms) => {
            let cloned: Vec<Term<'a>> = terms.iter().map(|t| clone_term(t, arena)).collect();
            Term::Group(arena.alloc_slice(cloned))
        }
        Term::Possessed { possessor, possessed } => {
            let cloned_possessor = arena.alloc(clone_term(possessor, arena));
            Term::Possessed { possessor: cloned_possessor, possessed: *possessed }
        }
        Term::Sigma(s) => Term::Sigma(*s),
        Term::Intension(s) => Term::Intension(*s),
        Term::Proposition(e) => Term::Proposition(*e),
        Term::Value { kind, unit, dimension } => Term::Value {
            kind: *kind,
            unit: *unit,
            dimension: *dimension,
        },
    }
}

```

---

## Type Analysis

Two-pass compilation infrastructure for type discovery and resolution.

**Location:** `src/analysis/`

### Analysis Module

**File:** `src/analysis/mod.rs`

Entry point for type analysis. Re-exports TypeRegistry and DiscoveryPass for two-pass compilation.

```rust
pub mod registry;
pub mod discovery;
pub mod dependencies;
pub mod escape;
pub mod ownership;
pub mod policy;

pub use registry::{TypeRegistry, TypeDef};
pub use discovery::{DiscoveryPass, DiscoveryResult};
pub use dependencies::{scan_dependencies, Dependency};
pub use escape::{EscapeChecker, EscapeError, EscapeErrorKind};
pub use ownership::{OwnershipChecker, OwnershipError, OwnershipErrorKind, VarState};
pub use policy::{PolicyRegistry, PredicateDef, CapabilityDef, PolicyCondition};

#[cfg(not(target_arch = "wasm32"))]
pub use discovery::discover_with_imports;

```

---

### Type Registry

**File:** `src/analysis/registry.rs`

TypeRegistry struct for tracking type definitions. TypeDef enum with variants: Generic (type parameters), Struct (record types), Enum (sum types). register_type() adds definitions; resolve_type() looks up by name. Supports the Adjective System where adjectives become type parameters.

```rust
use std::collections::HashMap;
use crate::intern::{Interner, Symbol};

/// Type reference for struct fields (avoids circular deps with ast::TypeExpr)
#[derive(Debug, Clone, PartialEq, Eq)]
pub enum FieldType {
    /// Primitive type name (Int, Nat, Text, Bool, etc.)
    Primitive(Symbol),
    /// User-defined type name
    Named(Symbol),
    /// Generic type with parameters (List of Int, Seq of Text)
    Generic { base: Symbol, params: Vec<FieldType> },
    /// Phase 34: Type parameter reference (T, U, etc.)
    TypeParam(Symbol),
}

/// Field definition within a struct
#[derive(Debug, Clone, PartialEq, Eq)]
pub struct FieldDef {
    pub name: Symbol,
    pub ty: FieldType,
    pub is_public: bool,
}

/// Phase 33: Variant definition for sum types
#[derive(Debug, Clone, PartialEq, Eq)]
pub struct VariantDef {
    pub name: Symbol,
    pub fields: Vec<FieldDef>,  // Empty for unit variants
}

#[derive(Debug, Clone, PartialEq, Eq)]
pub enum TypeDef {
    /// Primitive type (Nat, Int, Text, Bool)
    Primitive,
    /// Struct with named fields and visibility
    /// Phase 34: Now includes optional type parameters
    /// Phase 47: Added is_portable for serde derives
    /// Phase 49: Added is_shared for CRDT Merge impl
    Struct {
        fields: Vec<FieldDef>,
        generics: Vec<Symbol>,  // [T, U] for "A Pair of [T] and [U] has:"
        is_portable: bool,       // Phase 47: Derives Serialize/Deserialize
        is_shared: bool,         // Phase 49: Generates impl Merge
    },
    /// Phase 33: Enum with variants (unit or with payload)
    /// Phase 34: Now includes optional type parameters
    /// Phase 47: Added is_portable for serde derives
    /// Phase 49: Added is_shared for CRDT Merge impl
    Enum {
        variants: Vec<VariantDef>,
        generics: Vec<Symbol>,  // [T] for "A Maybe of [T] is either:"
        is_portable: bool,       // Phase 47: Derives Serialize/Deserialize
        is_shared: bool,         // Phase 49: Generates impl Merge
    },
    /// Built-in generic type (List, Option, Result)
    Generic { param_count: usize },
    /// Type alias
    Alias { target: Symbol },
}

#[derive(Debug, Default, Clone)]
pub struct TypeRegistry {
    types: HashMap<Symbol, TypeDef>,
}

impl TypeRegistry {
    pub fn new() -> Self {
        Self::default()
    }

    /// Register a type definition
    pub fn register(&mut self, name: Symbol, def: TypeDef) {
        self.types.insert(name, def);
    }

    /// Check if a symbol is a known type
    pub fn is_type(&self, name: Symbol) -> bool {
        self.types.contains_key(&name)
    }

    /// Check if a symbol is a generic type (takes parameters)
    pub fn is_generic(&self, name: Symbol) -> bool {
        match self.types.get(&name) {
            Some(TypeDef::Generic { .. }) => true,
            Some(TypeDef::Struct { generics, .. }) => !generics.is_empty(),
            Some(TypeDef::Enum { generics, .. }) => !generics.is_empty(),
            _ => false,
        }
    }

    /// Phase 34: Get type parameters for a user-defined generic type
    pub fn get_generics(&self, name: Symbol) -> Option<&[Symbol]> {
        match self.types.get(&name)? {
            TypeDef::Struct { generics, .. } => Some(generics),
            TypeDef::Enum { generics, .. } => Some(generics),
            _ => None,
        }
    }

    /// Get type definition
    pub fn get(&self, name: Symbol) -> Option<&TypeDef> {
        self.types.get(&name)
    }

    /// Iterate over all registered types (for codegen)
    pub fn iter_types(&self) -> impl Iterator<Item = (&Symbol, &TypeDef)> {
        self.types.iter()
    }

    /// Phase 33: Check if a symbol is a known enum variant
    /// Returns Some((enum_name, variant_def)) if found
    pub fn find_variant(&self, variant_name: Symbol) -> Option<(Symbol, &VariantDef)> {
        for (enum_name, type_def) in &self.types {
            if let TypeDef::Enum { variants, .. } = type_def {
                for variant in variants {
                    if variant.name == variant_name {
                        return Some((*enum_name, variant));
                    }
                }
            }
        }
        None
    }

    /// Phase 33: Check if a symbol is an enum variant
    pub fn is_variant(&self, name: Symbol) -> bool {
        self.find_variant(name).is_some()
    }

    /// Pre-register primitives and intrinsic generics
    pub fn with_primitives(interner: &mut Interner) -> Self {
        let mut reg = Self::new();

        // LOGOS Core Primitives
        reg.register(interner.intern("Nat"), TypeDef::Primitive);
        reg.register(interner.intern("Int"), TypeDef::Primitive);
        reg.register(interner.intern("Text"), TypeDef::Primitive);
        reg.register(interner.intern("Bool"), TypeDef::Primitive);
        reg.register(interner.intern("Boolean"), TypeDef::Primitive);
        reg.register(interner.intern("Unit"), TypeDef::Primitive);
        reg.register(interner.intern("Real"), TypeDef::Primitive);  // Floating point
        reg.register(interner.intern("Char"), TypeDef::Primitive);  // Character
        reg.register(interner.intern("Byte"), TypeDef::Primitive);  // 8-bit unsigned (0-255)

        // Intrinsic Generics
        reg.register(interner.intern("List"), TypeDef::Generic { param_count: 1 });
        reg.register(interner.intern("Seq"), TypeDef::Generic { param_count: 1 });  // Phase 30: Sequences
        reg.register(interner.intern("Map"), TypeDef::Generic { param_count: 2 });  // Phase 43D: Key-value maps
        reg.register(interner.intern("Set"), TypeDef::Generic { param_count: 1 });  // Set collection (HashSet)
        reg.register(interner.intern("Option"), TypeDef::Generic { param_count: 1 });
        reg.register(interner.intern("Result"), TypeDef::Generic { param_count: 2 });

        reg
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn registry_stores_and_retrieves() {
        let mut interner = Interner::new();
        let mut registry = TypeRegistry::new();
        let foo = interner.intern("Foo");
        registry.register(foo, TypeDef::Primitive);
        assert!(registry.is_type(foo));
        assert!(!registry.is_generic(foo));
    }
}

```

---

### Discovery Pass

**File:** `src/analysis/discovery.rs`

First pass of two-pass compilation. DiscoveryPass scans source for ## Definition blocks to populate TypeRegistry before full parsing. Enables forward references and mutual recursion in type definitions. Extracts type names, parameters, and kind (struct/enum) from definition headers.

```rust
use crate::token::{Token, TokenType, BlockType};
use crate::intern::{Interner, Symbol};
use super::registry::{TypeRegistry, TypeDef, FieldDef, FieldType, VariantDef};
use super::policy::{PolicyRegistry, PredicateDef, CapabilityDef, PolicyCondition};
use super::dependencies::scan_dependencies;

#[cfg(not(target_arch = "wasm32"))]
use std::path::Path;
#[cfg(not(target_arch = "wasm32"))]
use crate::project::Loader;

/// Result of running the discovery pass
pub struct DiscoveryResult {
    pub types: TypeRegistry,
    pub policies: PolicyRegistry,
}

/// Discovery pass that scans tokens before main parsing to build a TypeRegistry.
///
/// This pass looks for type definitions in `## Definition` blocks:
/// - "A Stack is a generic collection." → Generic type
/// - "A User is a structure." → Struct type
/// - "A Shape is an enum." → Enum type
///
/// Phase 50: Also scans `## Policy` blocks for security predicates and capabilities.
pub struct DiscoveryPass<'a> {
    tokens: &'a [Token],
    pos: usize,
    interner: &'a mut Interner,
}

impl<'a> DiscoveryPass<'a> {
    pub fn new(tokens: &'a [Token], interner: &'a mut Interner) -> Self {
        Self { tokens, pos: 0, interner }
    }

    /// Run discovery pass, returning populated TypeRegistry
    /// (Backward compatible - returns only TypeRegistry)
    pub fn run(&mut self) -> TypeRegistry {
        self.run_full().types
    }

    /// Phase 50: Run discovery pass, returning both TypeRegistry and PolicyRegistry
    pub fn run_full(&mut self) -> DiscoveryResult {
        let mut type_registry = TypeRegistry::with_primitives(self.interner);
        let mut policy_registry = PolicyRegistry::new();

        while self.pos < self.tokens.len() {
            // Look for Definition blocks
            if self.check_block_header(BlockType::Definition) {
                self.advance(); // consume ## Definition
                self.scan_definition_block(&mut type_registry);
            } else if self.check_block_header(BlockType::TypeDef) {
                // Inline type definition: ## A Point has: or ## A Color is one of:
                // The article is part of the block header, so don't skip it
                self.advance(); // consume ## A/An
                self.parse_type_definition_inline(&mut type_registry);
            } else if self.check_block_header(BlockType::Policy) {
                // Phase 50: Security policy definitions
                self.advance(); // consume ## Policy
                self.scan_policy_block(&mut policy_registry);
            } else {
                self.advance();
            }
        }

        DiscoveryResult {
            types: type_registry,
            policies: policy_registry,
        }
    }

    fn check_block_header(&self, expected: BlockType) -> bool {
        matches!(
            self.tokens.get(self.pos),
            Some(Token { kind: TokenType::BlockHeader { block_type }, .. })
            if *block_type == expected
        )
    }

    fn scan_definition_block(&mut self, registry: &mut TypeRegistry) {
        // Scan until next block header or EOF
        while self.pos < self.tokens.len() {
            if matches!(self.peek(), Some(Token { kind: TokenType::BlockHeader { .. }, .. })) {
                break;
            }

            // Look for "A [Name] is a..." pattern
            if self.check_article() {
                self.try_parse_type_definition(registry);
            } else {
                self.advance();
            }
        }
    }

    /// Phase 50: Scan policy block for predicate and capability definitions
    /// Patterns:
    /// - "A User is admin if the user's role equals \"admin\"."
    /// - "A User can publish the Document if the user is admin OR the user equals the document's owner."
    fn scan_policy_block(&mut self, registry: &mut PolicyRegistry) {
        while self.pos < self.tokens.len() {
            if matches!(self.peek(), Some(Token { kind: TokenType::BlockHeader { .. }, .. })) {
                break;
            }

            // Skip newlines and indentation
            if self.check_newline() || self.check_indent() || self.check_dedent() {
                self.advance();
                continue;
            }

            // Look for "A [Type] is [predicate] if..." or "A [Type] can [action] ..."
            if self.check_article() {
                self.try_parse_policy_definition(registry);
            } else {
                self.advance();
            }
        }
    }

    /// Phase 50: Parse a policy definition
    fn try_parse_policy_definition(&mut self, registry: &mut PolicyRegistry) {
        self.advance(); // consume article

        // Get subject type name (e.g., "User")
        let subject_type = match self.consume_noun_or_proper() {
            Some(sym) => sym,
            None => return,
        };

        // Determine if predicate ("is admin") or capability ("can publish")
        if self.check_copula() {
            // "A User is admin if..."
            self.advance(); // consume "is"

            // Get predicate name (e.g., "admin")
            let predicate_name = match self.consume_noun_or_proper() {
                Some(sym) => sym,
                None => return,
            };

            // Expect "if"
            if !self.check_word("if") {
                self.skip_to_period();
                return;
            }
            self.advance(); // consume "if"

            // Handle multi-line condition (colon followed by indented lines)
            if self.check_colon() {
                self.advance();
            }
            if self.check_newline() {
                self.advance();
            }
            if self.check_indent() {
                self.advance();
            }

            // Parse condition
            let condition = self.parse_policy_condition(subject_type, None);

            registry.register_predicate(PredicateDef {
                subject_type,
                predicate_name,
                condition,
            });

            self.skip_to_period();
        } else if self.check_word("can") {
            // "A User can publish the Document if..."
            self.advance(); // consume "can"

            // Get action name (e.g., "publish")
            let action = match self.consume_noun_or_proper() {
                Some(sym) => sym,
                None => {
                    // Try verb token
                    if let Some(Token { kind: TokenType::Verb { lemma, .. }, .. }) = self.peek() {
                        let sym = *lemma;
                        self.advance();
                        sym
                    } else {
                        return;
                    }
                }
            };

            // Skip "the" article if present
            if self.check_article() {
                self.advance();
            }

            // Get object type (e.g., "Document")
            let object_type = match self.consume_noun_or_proper() {
                Some(sym) => sym,
                None => return,
            };

            // Expect "if"
            if !self.check_word("if") {
                self.skip_to_period();
                return;
            }
            self.advance(); // consume "if"

            // Parse condition (may include colon for multi-line)
            if self.check_colon() {
                self.advance();
            }
            if self.check_newline() {
                self.advance();
            }
            if self.check_indent() {
                self.advance();
            }

            let condition = self.parse_policy_condition(subject_type, Some(object_type));

            registry.register_capability(CapabilityDef {
                subject_type,
                action,
                object_type,
                condition,
            });

            // Skip to end of definition (may span multiple lines)
            self.skip_policy_definition();
        } else {
            self.skip_to_period();
        }
    }

    /// Phase 50: Parse a policy condition
    /// Handles: field comparisons, predicate references, and OR/AND combinators
    fn parse_policy_condition(&mut self, subject_type: Symbol, object_type: Option<Symbol>) -> PolicyCondition {
        let first = self.parse_atomic_condition(subject_type, object_type);

        // Check for OR/AND combinators
        loop {
            // Skip newlines between conditions
            while self.check_newline() {
                self.advance();
            }

            // Handle ", AND" or ", OR" patterns
            if self.check_comma() {
                self.advance(); // consume comma
                // Skip whitespace after comma
                while self.check_newline() {
                    self.advance();
                }
            }

            if self.check_word("AND") {
                self.advance();
                // Skip newlines after AND
                while self.check_newline() {
                    self.advance();
                }
                let right = self.parse_atomic_condition(subject_type, object_type);
                return PolicyCondition::And(Box::new(first), Box::new(right));
            } else if self.check_word("OR") {
                self.advance();
                // Skip newlines after OR
                while self.check_newline() {
                    self.advance();
                }
                let right = self.parse_atomic_condition(subject_type, object_type);
                return PolicyCondition::Or(Box::new(first), Box::new(right));
            } else {
                break;
            }
        }

        first
    }

    /// Phase 50: Parse an atomic condition
    fn parse_atomic_condition(&mut self, subject_type: Symbol, object_type: Option<Symbol>) -> PolicyCondition {
        // Skip "The" article if present
        if self.check_article() {
            self.advance();
        }

        // Get the subject reference (e.g., "user" or "user's role")
        let subject_ref = match self.consume_noun_or_proper() {
            Some(sym) => sym,
            None => return PolicyCondition::FieldEquals {
                field: self.interner.intern("unknown"),
                value: self.interner.intern("unknown"),
                is_string_literal: false,
            },
        };

        // Check if it's a field access ("'s role") or a predicate ("is admin")
        if self.check_possessive() {
            self.advance(); // consume "'s"

            // Get field name
            let field = match self.consume_noun_or_proper() {
                Some(sym) => sym,
                None => return PolicyCondition::FieldEquals {
                    field: self.interner.intern("unknown"),
                    value: self.interner.intern("unknown"),
                    is_string_literal: false,
                },
            };

            // Expect "equals"
            if self.check_word("equals") {
                self.advance();

                // Get value (string literal or identifier)
                let (value, is_string_literal) = self.consume_value();

                return PolicyCondition::FieldEquals { field, value, is_string_literal };
            }
        } else if self.check_copula() {
            // "user is admin"
            self.advance(); // consume "is"

            // Get predicate name
            let predicate = match self.consume_noun_or_proper() {
                Some(sym) => sym,
                None => return PolicyCondition::FieldEquals {
                    field: self.interner.intern("unknown"),
                    value: self.interner.intern("unknown"),
                    is_string_literal: false,
                },
            };

            return PolicyCondition::Predicate {
                subject: subject_ref,
                predicate,
            };
        } else if self.check_word("equals") {
            // "user equals the document's owner"
            self.advance(); // consume "equals"

            // Skip "the" if present
            if self.check_article() {
                self.advance();
            }

            // Check for object field reference: "document's owner"
            if let Some(obj_ref) = self.consume_noun_or_proper() {
                if self.check_possessive() {
                    self.advance(); // consume "'s"
                    if let Some(field) = self.consume_noun_or_proper() {
                        return PolicyCondition::ObjectFieldEquals {
                            subject: subject_ref,
                            object: obj_ref,
                            field,
                        };
                    }
                }
            }
        }

        // Fallback: unknown condition
        PolicyCondition::FieldEquals {
            field: self.interner.intern("unknown"),
            value: self.interner.intern("unknown"),
            is_string_literal: false,
        }
    }

    /// Consume a value (string literal or identifier), returning the symbol and whether it was a string literal
    fn consume_value(&mut self) -> (Symbol, bool) {
        if let Some(Token { kind: TokenType::StringLiteral(sym), .. }) = self.peek() {
            let s = *sym;
            self.advance();
            (s, true)
        } else if let Some(sym) = self.consume_noun_or_proper() {
            (sym, false)
        } else {
            (self.interner.intern("unknown"), false)
        }
    }

    /// Check for possessive marker ('s)
    fn check_possessive(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::Possessive, .. }))
    }

    /// Skip to end of a multi-line policy definition
    fn skip_policy_definition(&mut self) {
        let mut depth = 0;
        while self.pos < self.tokens.len() {
            if self.check_indent() {
                depth += 1;
            } else if self.check_dedent() {
                if depth == 0 {
                    break;
                }
                depth -= 1;
            }
            if self.check_period() && depth == 0 {
                self.advance();
                break;
            }
            if matches!(self.peek(), Some(Token { kind: TokenType::BlockHeader { .. }, .. })) {
                break;
            }
            self.advance();
        }
    }

    /// Parse inline type definition where article was part of block header (## A Point has:)
    fn parse_type_definition_inline(&mut self, registry: &mut TypeRegistry) {
        // Don't skip article - it was part of the block header
        self.parse_type_definition_body(registry);
    }

    fn try_parse_type_definition(&mut self, registry: &mut TypeRegistry) {
        self.advance(); // skip article
        self.parse_type_definition_body(registry);
    }

    fn parse_type_definition_body(&mut self, registry: &mut TypeRegistry) {
        if let Some(name_sym) = self.consume_noun_or_proper() {
            // Phase 34: Check for "of [T]" which indicates user-defined generic
            let type_params = if self.check_preposition("of") {
                self.advance(); // consume "of"
                self.parse_type_params()
            } else {
                vec![]
            };

            // Phase 47/49: Check for "is Portable/Shared and" pattern before "has:"
            let mut is_portable = false;
            let mut is_shared = false;
            if self.check_copula() {
                let copula_pos = self.pos;
                self.advance(); // consume is/are

                // Check for modifiers in any order (e.g., "is Shared and Portable and")
                loop {
                    if self.check_portable() {
                        self.advance(); // consume "Portable"
                        is_portable = true;
                        if self.check_word("and") {
                            self.advance(); // consume "and"
                        }
                    } else if self.check_shared() {
                        self.advance(); // consume "Shared"
                        is_shared = true;
                        if self.check_word("and") {
                            self.advance(); // consume "and"
                        }
                    } else {
                        break;
                    }
                }

                // If no modifiers were found, restore position
                if !is_portable && !is_shared {
                    self.pos = copula_pos;
                }
            }

            // Phase 31/34: Check for "has:" which indicates struct with fields
            // Pattern: "A Point has:" or "A Box of [T] has:" or "A Message is Portable and has:"
            if self.check_word("has") {
                self.advance(); // consume "has"
                if self.check_colon() {
                    self.advance(); // consume ":"
                    // Skip newline if present
                    if self.check_newline() {
                        self.advance();
                    }
                    if self.check_indent() {
                        self.advance(); // consume INDENT
                        let fields = self.parse_struct_fields_with_params(&type_params);
                        registry.register(name_sym, TypeDef::Struct { fields, generics: type_params, is_portable, is_shared });
                        return;
                    }
                }
            }

            // Check for "is either:" or "is one of:" pattern (Phase 33/34: Sum types with variants)
            if self.check_copula() {
                self.advance(); // consume is/are

                // Phase 33: Check for "either:" or "one of:" pattern
                let is_enum_pattern = if self.check_either() {
                    self.advance(); // consume "either"
                    true
                } else if self.check_word("one") {
                    self.advance(); // consume "one"
                    if self.check_word("of") {
                        self.advance(); // consume "of"
                        true
                    } else {
                        false
                    }
                } else {
                    false
                };

                if is_enum_pattern {
                    if self.check_colon() {
                        self.advance(); // consume ":"
                        // Skip newline if present
                        if self.check_newline() {
                            self.advance();
                        }
                        if self.check_indent() {
                            self.advance(); // consume INDENT
                            let variants = self.parse_enum_variants_with_params(&type_params);
                            registry.register(name_sym, TypeDef::Enum { variants, generics: type_params, is_portable, is_shared });
                            return;
                        }
                    }
                }

                if self.check_article() {
                    self.advance(); // consume a/an

                    // Look for type indicators
                    if self.check_word("generic") {
                        registry.register(name_sym, TypeDef::Generic { param_count: 1 });
                        self.skip_to_period();
                    } else if self.check_word("record") || self.check_word("struct") || self.check_word("structure") {
                        registry.register(name_sym, TypeDef::Struct { fields: vec![], generics: vec![], is_portable: false, is_shared: false });
                        self.skip_to_period();
                    } else if self.check_word("sum") || self.check_word("enum") || self.check_word("choice") {
                        registry.register(name_sym, TypeDef::Enum { variants: vec![], generics: vec![], is_portable: false, is_shared: false });
                        self.skip_to_period();
                    }
                }
            } else if !type_params.is_empty() {
                // "A Stack of [Things] is..." - old generic syntax, still supported
                registry.register(name_sym, TypeDef::Generic { param_count: type_params.len() });
                self.skip_to_period();
            }
        }
    }

    /// Phase 33/34: Parse enum variants in "is either:" block
    /// Each variant: "A VariantName." or "A VariantName with a field, which is Type."
    /// or concise: "A VariantName (field: Type)."
    fn parse_enum_variants_with_params(&mut self, type_params: &[Symbol]) -> Vec<VariantDef> {
        let mut variants = Vec::new();

        while self.pos < self.tokens.len() {
            // Exit on dedent or next block
            if self.check_dedent() {
                self.advance();
                break;
            }
            if matches!(self.peek(), Some(Token { kind: TokenType::BlockHeader { .. }, .. })) {
                break;
            }

            // Skip newlines between variants
            if self.check_newline() {
                self.advance();
                continue;
            }

            // Parse variant: "A VariantName [with fields | (field: Type)]." or bare "VariantName."
            // Optionally consume article (a/an) if present
            if self.check_article() {
                self.advance(); // consume "A"/"An"
            }

            // Try to parse variant name (noun or proper name)
            if let Some(variant_name) = self.consume_noun_or_proper() {
                // Check for payload fields
                let fields = if self.check_word("with") {
                    // Natural syntax: "A Circle with a radius, which is Int."
                    self.parse_variant_fields_natural_with_params(type_params)
                } else if self.check_lparen() {
                    // Concise syntax: "A Circle (radius: Int)."
                    self.parse_variant_fields_concise_with_params(type_params)
                } else {
                    // Unit variant: "A Point." or "Point."
                    vec![]
                };

                variants.push(VariantDef {
                    name: variant_name,
                    fields,
                });

                // Consume period
                if self.check_period() {
                    self.advance();
                }
            } else {
                self.advance(); // skip malformed token
            }
        }

        variants
    }

    /// Phase 33: Parse enum variants (backward compat wrapper)
    fn parse_enum_variants(&mut self) -> Vec<VariantDef> {
        self.parse_enum_variants_with_params(&[])
    }

    /// Parse variant fields in natural syntax.
    /// Supports multiple syntaxes:
    /// - "with a radius, which is Int." (verbose natural)
    /// - "with radius Int" (concise natural - no article/comma)
    fn parse_variant_fields_natural_with_params(&mut self, type_params: &[Symbol]) -> Vec<FieldDef> {
        let mut fields = Vec::new();

        // "with" has already been detected, consume it
        self.advance();

        loop {
            // Skip article (optional)
            if self.check_article() {
                self.advance();
            }

            // Get field name
            if let Some(field_name) = self.consume_noun_or_proper() {
                // Support multiple type annotation patterns:
                // 1. ", which is Type" (verbose)
                // 2. " Type" (concise - just a type name after field name)
                let ty = if self.check_comma() {
                    self.advance(); // consume ","
                    // Consume "which"
                    if self.check_word("which") {
                        self.advance();
                    }
                    // Consume "is"
                    if self.check_copula() {
                        self.advance();
                    }
                    self.consume_field_type_with_params(type_params)
                } else {
                    // Concise syntax: "radius Int" - type immediately follows field name
                    self.consume_field_type_with_params(type_params)
                };

                fields.push(FieldDef {
                    name: field_name,
                    ty,
                    is_public: true, // Variant fields are always public
                });

                // Check for "and" to continue: "and height Int"
                // May have comma before "and"
                if self.check_comma() {
                    self.advance(); // consume comma before "and"
                }
                if self.check_word("and") {
                    self.advance();
                    continue;
                }
            }
            break;
        }

        fields
    }

    /// Backward compat wrapper
    fn parse_variant_fields_natural(&mut self) -> Vec<FieldDef> {
        self.parse_variant_fields_natural_with_params(&[])
    }

    /// Parse variant fields in concise syntax: "(radius: Int)" or "(width: Int, height: Int)"
    fn parse_variant_fields_concise_with_params(&mut self, type_params: &[Symbol]) -> Vec<FieldDef> {
        let mut fields = Vec::new();

        // Consume "("
        self.advance();

        loop {
            // Get field name
            if let Some(field_name) = self.consume_noun_or_proper() {
                // Expect ": Type" pattern
                let ty = if self.check_colon() {
                    self.advance(); // consume ":"
                    self.consume_field_type_with_params(type_params)
                } else {
                    FieldType::Primitive(self.interner.intern("Unknown"))
                };

                fields.push(FieldDef {
                    name: field_name,
                    ty,
                    is_public: true, // Variant fields are always public
                });

                // Check for "," to continue
                if self.check_comma() {
                    self.advance();
                    continue;
                }
            }
            break;
        }

        // Consume ")"
        if self.check_rparen() {
            self.advance();
        }

        fields
    }

    /// Backward compat wrapper
    fn parse_variant_fields_concise(&mut self) -> Vec<FieldDef> {
        self.parse_variant_fields_concise_with_params(&[])
    }

    /// Parse struct fields in "has:" block
    /// Each field: "a [public] name, which is Type."
    fn parse_struct_fields_with_params(&mut self, type_params: &[Symbol]) -> Vec<FieldDef> {
        let mut fields = Vec::new();

        while self.pos < self.tokens.len() {
            // Exit on dedent or next block
            if self.check_dedent() {
                self.advance();
                break;
            }
            if matches!(self.peek(), Some(Token { kind: TokenType::BlockHeader { .. }, .. })) {
                break;
            }

            // Skip newlines between fields
            if self.check_newline() {
                self.advance();
                continue;
            }

            // Parse field: "a [public] name, which is Type." or "name: Type." (no article)
            // Check for article (optional for concise syntax)
            let has_article = self.check_article();
            if has_article {
                self.advance(); // consume "a"/"an"
            }

            // Check for "public" modifier
            let has_public_keyword = if self.check_word("public") {
                self.advance();
                true
            } else {
                false
            };
            // Visibility determined later based on syntax used
            let mut is_public = has_public_keyword;

            // Get field name - try to parse if we had article OR if next token looks like identifier
            if let Some(field_name) = self.consume_noun_or_proper() {
                // Support both syntaxes:
                // 1. "name: Type." (concise) - public by default
                // 2. "name, which is Type." (natural) - public by default
                let ty = if self.check_colon() {
                    // Concise syntax: "x: Int" - public by default
                    is_public = true;
                    self.advance(); // consume ":"
                    self.consume_field_type_with_params(type_params)
                } else if self.check_comma() {
                    // Natural syntax: "name, which is Type" - also public by default
                    is_public = true;
                    self.advance(); // consume ","
                    // Consume "which"
                    if self.check_word("which") {
                        self.advance();
                    }
                    // Consume "is"
                    if self.check_copula() {
                        self.advance();
                    }
                    self.consume_field_type_with_params(type_params)
                } else if !has_article {
                    // No colon and no article - this wasn't a field, skip
                    continue;
                } else {
                    // Fallback: unknown type
                    FieldType::Primitive(self.interner.intern("Unknown"))
                };

                fields.push(FieldDef {
                    name: field_name,
                    ty,
                    is_public,
                });

                // Consume period
                if self.check_period() {
                    self.advance();
                }
            } else if !has_article {
                // Didn't have article and couldn't get field name - skip this token
                self.advance();
            }
        }

        fields
    }

    /// Backward compat wrapper
    fn parse_struct_fields(&mut self) -> Vec<FieldDef> {
        self.parse_struct_fields_with_params(&[])
    }

    /// Parse a field type reference
    fn consume_field_type(&mut self) -> FieldType {
        // Skip article if present (e.g., "a Tally" -> "Tally")
        if self.check_article() {
            self.advance();
        }

        if let Some(name) = self.consume_noun_or_proper() {
            let name_str = self.interner.resolve(name);

            // Phase 49c: Check for bias/algorithm modifier on SharedSet: "SharedSet (AddWins) of T"
            let modified_name = if name_str == "SharedSet" || name_str == "ORSet" {
                if self.check_lparen() {
                    self.advance(); // consume "("
                    let modifier = if self.check_removewins() {
                        self.advance(); // consume "RemoveWins"
                        Some("SharedSet_RemoveWins")
                    } else if self.check_addwins() {
                        self.advance(); // consume "AddWins"
                        Some("SharedSet_AddWins")
                    } else {
                        None
                    };
                    if self.check_rparen() {
                        self.advance(); // consume ")"
                    }
                    modifier.map(|m| self.interner.intern(m))
                } else {
                    None
                }
            } else if name_str == "SharedSequence" {
                // Phase 49c: Check for algorithm modifier on SharedSequence: "SharedSequence (YATA) of T"
                if self.check_lparen() {
                    self.advance(); // consume "("
                    let modifier = if self.check_yata() {
                        self.advance(); // consume "YATA"
                        Some("SharedSequence_YATA")
                    } else {
                        None
                    };
                    if self.check_rparen() {
                        self.advance(); // consume ")"
                    }
                    modifier.map(|m| self.interner.intern(m))
                } else {
                    None
                }
            } else {
                None
            };

            // Use modified name if we found a modifier, otherwise use original
            let final_name = modified_name.unwrap_or(name);
            let final_name_str = self.interner.resolve(final_name);

            // Phase 49c: Handle "SharedMap from K to V" / "ORMap from K to V" syntax
            if (final_name_str == "SharedMap" || final_name_str == "ORMap") && self.check_from() {
                self.advance(); // consume "from"
                let key_type = self.consume_field_type();
                // Expect "to" (can be TokenType::To or preposition)
                if self.check_to() {
                    self.advance(); // consume "to"
                }
                let value_type = self.consume_field_type();
                return FieldType::Generic { base: final_name, params: vec![key_type, value_type] };
            }

            // Check for generic: "List of Int", "Seq of Text"
            if self.check_preposition("of") {
                self.advance();
                let param = self.consume_field_type();
                return FieldType::Generic { base: final_name, params: vec![param] };
            }

            // Phase 49b: "Divergent T" syntax (no "of" required)
            if final_name_str == "Divergent" {
                // Next token should be the inner type
                let param = self.consume_field_type();
                return FieldType::Generic { base: final_name, params: vec![param] };
            }

            // Check if primitive
            match final_name_str {
                "Int" | "Nat" | "Text" | "Bool" | "Real" | "Unit" => FieldType::Primitive(final_name),
                _ => FieldType::Named(final_name),
            }
        } else {
            FieldType::Primitive(self.interner.intern("Unknown"))
        }
    }

    // Helper methods
    fn peek(&self) -> Option<&Token> {
        self.tokens.get(self.pos)
    }

    fn advance(&mut self) {
        if self.pos < self.tokens.len() {
            self.pos += 1;
        }
    }

    fn check_article(&self) -> bool {
        match self.peek() {
            Some(Token { kind: TokenType::Article(_), .. }) => true,
            // Also accept ProperName("A") / ProperName("An") which can occur at line starts
            Some(Token { kind: TokenType::ProperName(sym), .. }) => {
                let text = self.interner.resolve(*sym);
                text.eq_ignore_ascii_case("a") || text.eq_ignore_ascii_case("an")
            }
            _ => false,
        }
    }

    fn check_copula(&self) -> bool {
        match self.peek() {
            Some(Token { kind: TokenType::Is | TokenType::Are, .. }) => true,
            // Also match "is" when tokenized as a verb (common in declarative mode)
            Some(Token { kind: TokenType::Verb { lemma, .. }, .. }) => {
                let word = self.interner.resolve(*lemma).to_lowercase();
                word == "is" || word == "are"
            }
            _ => false,
        }
    }

    fn check_preposition(&self, word: &str) -> bool {
        if let Some(Token { kind: TokenType::Preposition(sym), .. }) = self.peek() {
            self.interner.resolve(*sym) == word
        } else {
            false
        }
    }

    fn consume_noun_or_proper(&mut self) -> Option<Symbol> {
        let t = self.peek()?;
        match &t.kind {
            TokenType::Noun(s) | TokenType::ProperName(s) => {
                let sym = *s;
                self.advance();
                Some(sym)
            }
            // Phase 31: Also accept Adjective as identifier (for field names like "x")
            TokenType::Adjective(s) => {
                let sym = *s;
                self.advance();
                Some(sym)
            }
            // Phase 47: Accept Performative as type name (for agent messages like "Command")
            TokenType::Performative(s) => {
                let sym = *s;
                self.advance();
                Some(sym)
            }
            // Phase 34: Accept special tokens as identifiers using their lexeme
            TokenType::Items | TokenType::Some => {
                let sym = t.lexeme;
                self.advance();
                Some(sym)
            }
            // Phase 49/50: Accept Verb tokens as identifiers
            // - Uppercase verbs like "Setting" are type names
            // - Lowercase verbs like "trusted", "privileged" are predicate names
            // Use lexeme to preserve the original word (not lemma which strips suffixes)
            TokenType::Verb { .. } => {
                let sym = t.lexeme;
                self.advance();
                Some(sym)
            }
            // Phase 49b: Accept CRDT type tokens as type names
            TokenType::Tally => {
                self.advance();
                Some(self.interner.intern("Tally"))
            }
            TokenType::SharedSet => {
                self.advance();
                Some(self.interner.intern("SharedSet"))
            }
            TokenType::SharedSequence => {
                self.advance();
                Some(self.interner.intern("SharedSequence"))
            }
            TokenType::CollaborativeSequence => {
                self.advance();
                Some(self.interner.intern("CollaborativeSequence"))
            }
            TokenType::SharedMap => {
                self.advance();
                Some(self.interner.intern("SharedMap"))
            }
            TokenType::Divergent => {
                self.advance();
                Some(self.interner.intern("Divergent"))
            }
            _ => None
        }
    }

    fn check_word(&self, word: &str) -> bool {
        if let Some(token) = self.peek() {
            // Check against the lexeme of the token
            self.interner.resolve(token.lexeme).eq_ignore_ascii_case(word)
        } else {
            false
        }
    }

    fn skip_to_period(&mut self) {
        while self.pos < self.tokens.len() {
            if matches!(self.peek(), Some(Token { kind: TokenType::Period, .. })) {
                self.advance();
                break;
            }
            self.advance();
        }
    }

    fn check_colon(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::Colon, .. }))
    }

    fn check_newline(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::Newline, .. }))
    }

    fn check_indent(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::Indent, .. }))
    }

    fn check_dedent(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::Dedent, .. }))
    }

    fn check_comma(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::Comma, .. }))
    }

    fn check_period(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::Period, .. }))
    }

    fn check_either(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::Either, .. }))
    }

    fn check_lparen(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::LParen, .. }))
    }

    fn check_rparen(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::RParen, .. }))
    }

    /// Phase 49c: Check for AddWins token
    fn check_addwins(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::AddWins, .. }))
    }

    /// Phase 49c: Check for RemoveWins token
    fn check_removewins(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::RemoveWins, .. }))
    }

    /// Phase 49c: Check for YATA token
    fn check_yata(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::YATA, .. }))
    }

    /// Phase 49c: Check for "to" (either TokenType::To or preposition "to")
    fn check_to(&self) -> bool {
        match self.peek() {
            Some(Token { kind: TokenType::To, .. }) => true,
            Some(Token { kind: TokenType::Preposition(sym), .. }) => {
                self.interner.resolve(*sym) == "to"
            }
            _ => false,
        }
    }

    /// Phase 49c: Check for "from" (either TokenType::From or preposition "from")
    fn check_from(&self) -> bool {
        match self.peek() {
            Some(Token { kind: TokenType::From, .. }) => true,
            Some(Token { kind: TokenType::Preposition(sym), .. }) => {
                self.interner.resolve(*sym) == "from"
            }
            _ => false,
        }
    }

    /// Phase 47: Check for Portable token
    fn check_portable(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::Portable, .. }))
    }

    /// Phase 49: Check for Shared token
    fn check_shared(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::Shared, .. }))
    }

    // Phase 34: Bracket checks for type parameters
    fn check_lbracket(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::LBracket, .. }))
    }

    fn check_rbracket(&self) -> bool {
        matches!(self.peek(), Some(Token { kind: TokenType::RBracket, .. }))
    }

    /// Phase 34: Parse type parameters in brackets: "[T]" or "[A] and [B]"
    fn parse_type_params(&mut self) -> Vec<Symbol> {
        let mut params = Vec::new();

        loop {
            if self.check_lbracket() {
                self.advance(); // consume [
                if let Some(param) = self.consume_noun_or_proper() {
                    params.push(param);
                }
                if self.check_rbracket() {
                    self.advance(); // consume ]
                }
            }

            // Check for "and" separator for multi-param generics
            if self.check_word("and") {
                self.advance();
                continue;
            }
            break;
        }
        params
    }

    /// Phase 34: Parse a field type reference, recognizing type parameters
    fn consume_field_type_with_params(&mut self, type_params: &[Symbol]) -> FieldType {
        // Phase 34: Single-letter type params like "A" may be tokenized as Article
        // Check for Article that matches a type param first
        if let Some(Token { kind: TokenType::Article(_), lexeme, .. }) = self.peek() {
            let text = self.interner.resolve(*lexeme);
            // Find matching type param by name (case-insensitive for single letters)
            for &param_sym in type_params {
                let param_name = self.interner.resolve(param_sym);
                if text.eq_ignore_ascii_case(param_name) {
                    self.advance(); // consume the article token
                    return FieldType::TypeParam(param_sym);
                }
            }
            // Article didn't match a type param, skip it (e.g., "a Tally" -> "Tally")
            self.advance();
        }

        if let Some(name) = self.consume_noun_or_proper() {
            // Check if this is a type parameter reference
            if type_params.contains(&name) {
                return FieldType::TypeParam(name);
            }

            let name_str = self.interner.resolve(name);

            // Phase 49c: Check for bias/algorithm modifier on SharedSet: "SharedSet (AddWins) of T"
            let modified_name = if name_str == "SharedSet" || name_str == "ORSet" {
                if self.check_lparen() {
                    self.advance(); // consume "("
                    let modifier = if self.check_removewins() {
                        self.advance(); // consume "RemoveWins"
                        Some("SharedSet_RemoveWins")
                    } else if self.check_addwins() {
                        self.advance(); // consume "AddWins"
                        Some("SharedSet_AddWins")
                    } else {
                        None
                    };
                    if self.check_rparen() {
                        self.advance(); // consume ")"
                    }
                    modifier.map(|m| self.interner.intern(m))
                } else {
                    None
                }
            } else if name_str == "SharedSequence" {
                // Phase 49c: Check for algorithm modifier on SharedSequence: "SharedSequence (YATA) of T"
                if self.check_lparen() {
                    self.advance(); // consume "("
                    let modifier = if self.check_yata() {
                        self.advance(); // consume "YATA"
                        Some("SharedSequence_YATA")
                    } else {
                        None
                    };
                    if self.check_rparen() {
                        self.advance(); // consume ")"
                    }
                    modifier.map(|m| self.interner.intern(m))
                } else {
                    None
                }
            } else {
                None
            };

            // Use modified name if we found a modifier, otherwise use original
            let final_name = modified_name.unwrap_or(name);
            let final_name_str = self.interner.resolve(final_name);

            // Phase 49c: Handle "SharedMap from K to V" / "ORMap from K to V" syntax
            if (final_name_str == "SharedMap" || final_name_str == "ORMap") && self.check_from() {
                self.advance(); // consume "from"
                let key_type = self.consume_field_type_with_params(type_params);
                // Expect "to" (can be TokenType::To or preposition)
                if self.check_to() {
                    self.advance(); // consume "to"
                }
                let value_type = self.consume_field_type_with_params(type_params);
                return FieldType::Generic { base: final_name, params: vec![key_type, value_type] };
            }

            // Check for generic: "List of Int", "Seq of Text", "List of T"
            if self.check_preposition("of") {
                self.advance();
                let param = self.consume_field_type_with_params(type_params);
                return FieldType::Generic { base: final_name, params: vec![param] };
            }

            // Phase 49b: "Divergent T" syntax (no "of" required)
            if final_name_str == "Divergent" {
                // Next token should be the inner type
                let param = self.consume_field_type_with_params(type_params);
                return FieldType::Generic { base: final_name, params: vec![param] };
            }

            // Check if primitive
            match final_name_str {
                "Int" | "Nat" | "Text" | "Bool" | "Real" | "Unit" => FieldType::Primitive(final_name),
                _ => FieldType::Named(final_name),
            }
        } else {
            FieldType::Primitive(self.interner.intern("Unknown"))
        }
    }
}

/// Phase 36: Recursive discovery with module imports.
///
/// This function scans a LOGOS source file for:
/// 1. Dependencies declared in the Abstract (Markdown links)
/// 2. Type definitions in ## Definition blocks
///
/// Dependencies are loaded recursively, and their types are merged into
/// the registry with namespace prefixes (e.g., "Geometry::Point").
#[cfg(not(target_arch = "wasm32"))]
pub fn discover_with_imports(
    file_path: &Path,
    source: &str,
    loader: &mut Loader,
    interner: &mut Interner,
) -> Result<TypeRegistry, String> {
    use crate::Lexer;
    use crate::mwe;

    let mut registry = TypeRegistry::with_primitives(interner);

    // 1. Scan for dependencies in the abstract
    let deps = scan_dependencies(source);

    // 2. For each dependency, recursively discover types
    for dep in deps {
        let module_source = loader.resolve(file_path, &dep.uri)?;
        let dep_content = module_source.content.clone();
        let dep_path = module_source.path.clone();

        // Recursively discover types in the dependency
        let dep_registry = discover_with_imports(
            &dep_path,
            &dep_content,
            loader,
            interner
        )?;

        // Merge with namespace prefix
        merge_registry(&mut registry, &dep.alias, dep_registry, interner);
    }

    // 3. Scan local definitions using existing DiscoveryPass
    let mut lexer = Lexer::new(source, interner);
    let tokens = lexer.tokenize();
    let mwe_trie = mwe::build_mwe_trie();
    let tokens = mwe::apply_mwe_pipeline(tokens, &mwe_trie, interner);

    let mut discovery = DiscoveryPass::new(&tokens, interner);
    let local_registry = discovery.run();

    // Merge local types (without namespace prefix)
    for (sym, def) in local_registry.iter_types() {
        // Skip primitives (already in registry)
        let name = interner.resolve(*sym);
        if !["Int", "Nat", "Text", "Bool", "Real", "Unit"].contains(&name) {
            registry.register(*sym, def.clone());
        }
    }

    Ok(registry)
}

/// Merges types from a dependency registry into the main registry with namespace prefix.
#[cfg(not(target_arch = "wasm32"))]
fn merge_registry(
    main: &mut TypeRegistry,
    namespace: &str,
    dep: TypeRegistry,
    interner: &mut Interner,
) {
    for (sym, def) in dep.iter_types() {
        let name = interner.resolve(*sym);
        // Skip primitives
        if ["Int", "Nat", "Text", "Bool", "Real", "Unit"].contains(&name) {
            continue;
        }
        // Create namespaced symbol: "Geometry::Point"
        let qualified = format!("{}::{}", namespace, name);
        let new_sym = interner.intern(&qualified);
        main.register(new_sym, def.clone());
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::Lexer;
    use crate::mwe;

    fn make_tokens(source: &str, interner: &mut Interner) -> Vec<Token> {
        let mut lexer = Lexer::new(source, interner);
        let tokens = lexer.tokenize();
        let mwe_trie = mwe::build_mwe_trie();
        mwe::apply_mwe_pipeline(tokens, &mwe_trie, interner)
    }

    #[test]
    fn discovery_finds_generic_in_definition_block() {
        let source = "## Definition\nA Stack is a generic collection.";
        let mut interner = Interner::new();
        let tokens = make_tokens(source, &mut interner);

        let mut discovery = DiscoveryPass::new(&tokens, &mut interner);
        let registry = discovery.run();

        let stack = interner.intern("Stack");
        assert!(registry.is_generic(stack), "Stack should be discovered as generic");
    }

    #[test]
    fn discovery_parses_struct_with_fields() {
        let source = r#"## Definition
A Point has:
    an x, which is Int.
    a y, which is Int.
"#;
        let mut interner = Interner::new();
        let tokens = make_tokens(source, &mut interner);

        let mut discovery = DiscoveryPass::new(&tokens, &mut interner);
        let registry = discovery.run();

        let point = interner.intern("Point");
        assert!(registry.is_type(point), "Point should be registered");

        if let Some(TypeDef::Struct { fields, generics, .. }) = registry.get(point) {
            assert_eq!(fields.len(), 2, "Point should have 2 fields, got {:?}", fields);
            assert_eq!(interner.resolve(fields[0].name), "x");
            assert_eq!(interner.resolve(fields[1].name), "y");
            assert!(generics.is_empty(), "Point should have no generics");
        } else {
            panic!("Point should be a struct with fields");
        }
    }

    #[test]
    fn discovery_works_with_markdown_header() {
        // Phase 36: LOGOS files have `# Header` before `## Definition`
        let source = r#"# Geometry

## Definition
A Point has:
    an x, which is Int.
"#;
        let mut interner = Interner::new();
        let tokens = make_tokens(source, &mut interner);

        // Debug: print tokens to see what we're getting
        for (i, tok) in tokens.iter().enumerate() {
            eprintln!("Token {}: {:?}", i, tok.kind);
        }

        let mut discovery = DiscoveryPass::new(&tokens, &mut interner);
        let registry = discovery.run();
        let point = interner.intern("Point");
        assert!(registry.is_type(point), "Point should be discovered even with # header");
    }

    #[test]
    fn discovery_parses_portable_enum() {
        let source = r#"## Definition
A Command is Portable and is either:
    a Start.
    a Stop.
    a Pause.
"#;
        let mut interner = Interner::new();
        let tokens = make_tokens(source, &mut interner);

        // Debug: print tokens to see what we're getting
        eprintln!("Tokens for portable enum:");
        for (i, tok) in tokens.iter().enumerate() {
            eprintln!("Token {}: {:?} ({})", i, tok.kind, interner.resolve(tok.lexeme));
        }

        let mut discovery = DiscoveryPass::new(&tokens, &mut interner);
        let registry = discovery.run();

        let command = interner.intern("Command");
        assert!(registry.is_type(command), "Command should be registered as type");

        if let Some(TypeDef::Enum { variants, is_portable, .. }) = registry.get(command) {
            eprintln!("Command is_portable: {}", is_portable);
            eprintln!("Variants: {:?}", variants.iter().map(|v| interner.resolve(v.name)).collect::<Vec<_>>());
            assert!(*is_portable, "Command should be portable");
            assert_eq!(variants.len(), 3, "Command should have 3 variants");
        } else {
            panic!("Command should be an enum, got: {:?}", registry.get(command));
        }
    }

    #[test]
    fn discovery_parses_lww_int_field() {
        let source = r#"## Definition
A Setting is Shared and has:
    a volume, which is LastWriteWins of Int.
"#;
        let mut interner = Interner::new();
        let tokens = make_tokens(source, &mut interner);

        // Debug: print tokens
        eprintln!("Tokens for LWW of Int:");
        for (i, tok) in tokens.iter().enumerate() {
            eprintln!("{:3}: {:?} ({})", i, tok.kind, interner.resolve(tok.lexeme));
        }

        let mut discovery = DiscoveryPass::new(&tokens, &mut interner);
        let registry = discovery.run();

        let setting = interner.intern("Setting");
        assert!(registry.is_type(setting), "Setting should be registered");

        if let Some(TypeDef::Struct { fields, is_shared, .. }) = registry.get(setting) {
            eprintln!("is_shared: {}", is_shared);
            eprintln!("Fields: {:?}", fields.len());
            for f in fields {
                eprintln!("  field: {} = {:?}", interner.resolve(f.name), f.ty);
            }
            assert!(*is_shared, "Setting should be shared");
            assert_eq!(fields.len(), 1, "Setting should have 1 field");
        } else {
            panic!("Setting should be a struct, got: {:?}", registry.get(setting));
        }
    }
}

```

---

### Module Dependency Scanner

**File:** `src/analysis/dependencies.rs`

Phase 36 hyperlink-based module system. **Dependency** struct stores alias, uri, and source positions. **scan_dependencies()** parses the Abstract (first paragraph after module header) for Markdown links [Alias](URI). Supports file: scheme for local paths and logos: scheme for standard library. Scanning stops at first empty line or code block header (##).

```rust
//! Phase 36: Dependency Scanner for the Hyperlink Module System
//!
//! Scans the "Abstract" (first paragraph) of a LOGOS document for Markdown links,
//! which are interpreted as module dependencies.
//!
//! Syntax: `[Alias](URI)` where:
//! - Alias: The name to reference the module by (e.g., "Geometry")
//! - URI: The location of the module source (e.g., "file:./geo.md", "logos:std")

/// A dependency declaration found in the document's abstract.
#[derive(Debug, Clone, PartialEq, Eq)]
pub struct Dependency {
    /// The alias to use when referencing this module (e.g., "Geometry")
    pub alias: String,
    /// The URI pointing to the module source (e.g., "file:./geo.md")
    pub uri: String,
    /// Start position in the source for error reporting
    pub start: usize,
    /// End position in the source for error reporting
    pub end: usize,
}

/// Scans the first paragraph (Abstract) of a LOGOS file for `[Alias](URI)` links.
///
/// The Abstract is defined as the first non-empty block of text following the
/// module header (# Name). Links inside this paragraph are treated as imports.
/// Scanning stops at the first empty line after the abstract or when a code
/// block header (`##`) is encountered.
///
/// # Example
///
/// ```text
/// # My Game
///
/// This module uses [Geometry](file:./geo.md) for math.
///
/// ## Main
/// Let x be 1.
/// ```
///
/// Returns: `[Dependency { alias: "Geometry", uri: "file:./geo.md", ... }]`
pub fn scan_dependencies(source: &str) -> Vec<Dependency> {
    let mut dependencies = Vec::new();
    let mut in_abstract = false;
    let mut abstract_started = false;
    let mut current_pos = 0;

    for line in source.lines() {
        let line_start = current_pos;
        let trimmed = line.trim();

        // Track position for the next line
        current_pos += line.len() + 1; // +1 for newline

        // Skip completely empty lines before the abstract starts
        if trimmed.is_empty() {
            if abstract_started && in_abstract {
                // Empty line after abstract content - we're done
                break;
            }
            continue;
        }

        // Skip the header line (# Title)
        if trimmed.starts_with("# ") && !trimmed.starts_with("## ") {
            continue;
        }

        // Stop at code block headers (## Main, ## Definition, etc.)
        if trimmed.starts_with("## ") {
            break;
        }

        // We found non-empty, non-header content - this is the abstract
        in_abstract = true;
        abstract_started = true;

        // Scan this line for Markdown links [Alias](URI)
        scan_line_for_links(line, line_start, &mut dependencies);
    }

    dependencies
}

/// Scans a single line for Markdown link patterns `[Alias](URI)`.
fn scan_line_for_links(line: &str, line_start: usize, deps: &mut Vec<Dependency>) {
    let bytes = line.as_bytes();
    let mut i = 0;

    while i < bytes.len() {
        // Look for opening bracket
        if bytes[i] == b'[' {
            let link_start = line_start + i;
            i += 1;

            // Read the alias (text between [ and ])
            let alias_start = i;
            while i < bytes.len() && bytes[i] != b']' {
                i += 1;
            }

            if i >= bytes.len() {
                // No closing bracket found
                break;
            }

            let alias = &line[alias_start..i];
            i += 1; // Skip ]

            // Expect immediate opening parenthesis
            if i >= bytes.len() || bytes[i] != b'(' {
                continue;
            }
            i += 1; // Skip (

            // Read the URI (text between ( and ))
            let uri_start = i;
            let mut paren_depth = 1;
            while i < bytes.len() && paren_depth > 0 {
                if bytes[i] == b'(' {
                    paren_depth += 1;
                } else if bytes[i] == b')' {
                    paren_depth -= 1;
                }
                if paren_depth > 0 {
                    i += 1;
                }
            }

            if paren_depth != 0 {
                // No closing parenthesis found
                break;
            }

            let uri = &line[uri_start..i];
            let link_end = line_start + i + 1;
            i += 1; // Skip )

            // Skip empty aliases or URIs
            if alias.is_empty() || uri.is_empty() {
                continue;
            }

            deps.push(Dependency {
                alias: alias.trim().to_string(),
                uri: uri.trim().to_string(),
                start: link_start,
                end: link_end,
            });
        } else {
            i += 1;
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn basic_dependency_scanning() {
        let source = r#"
# My Game

This uses [Geometry](file:./geo.md) and [Physics](logos:std).

## Main
Let x be 1.
"#;
        let deps = scan_dependencies(source);
        assert_eq!(deps.len(), 2);
        assert_eq!(deps[0].alias, "Geometry");
        assert_eq!(deps[0].uri, "file:./geo.md");
        assert_eq!(deps[1].alias, "Physics");
        assert_eq!(deps[1].uri, "logos:std");
    }

    #[test]
    fn ignores_links_after_abstract() {
        let source = r#"
# Header

This is the abstract with [Dep1](file:a.md).

This second paragraph has [Dep2](file:b.md).

## Main
Let x be 1.
"#;
        let deps = scan_dependencies(source);
        assert_eq!(deps.len(), 1);
        assert_eq!(deps[0].alias, "Dep1");
    }

    #[test]
    fn no_dependencies_without_abstract() {
        let source = r#"
# Module

## Main
Let x be 1.
"#;
        let deps = scan_dependencies(source);
        assert_eq!(deps.len(), 0);
    }

    #[test]
    fn multiline_abstract() {
        let source = r#"
# My Project

This project uses [Math](file:./math.md) for calculations
and [IO](file:./io.md) for input/output operations.

## Main
Let x be 1.
"#;
        let deps = scan_dependencies(source);
        assert_eq!(deps.len(), 2);
        assert_eq!(deps[0].alias, "Math");
        assert_eq!(deps[1].alias, "IO");
    }

    #[test]
    fn handles_spaces_in_alias() {
        let source = r#"
# App

Uses the [Standard Library](logos:std).

## Main
"#;
        let deps = scan_dependencies(source);
        assert_eq!(deps.len(), 1);
        assert_eq!(deps[0].alias, "Standard Library");
        assert_eq!(deps[0].uri, "logos:std");
    }

    #[test]
    fn handles_https_urls() {
        let source = r#"
# App

Uses [Physics](https://logicaffeine.dev/pkg/physics).

## Main
"#;
        let deps = scan_dependencies(source);
        assert_eq!(deps.len(), 1);
        assert_eq!(deps[0].alias, "Physics");
        assert_eq!(deps[0].uri, "https://logicaffeine.dev/pkg/physics");
    }

    #[test]
    fn handles_multiple_links_on_one_line() {
        let source = r#"
# App

Uses [A](file:a.md), [B](file:b.md), and [C](file:c.md).

## Main
"#;
        let deps = scan_dependencies(source);
        assert_eq!(deps.len(), 3);
        assert_eq!(deps[0].alias, "A");
        assert_eq!(deps[1].alias, "B");
        assert_eq!(deps[2].alias, "C");
    }
}

```

---

### Escape Analysis

**File:** `src/analysis/escape.rs`

Phase 8.5: Zone safety enforcement. EscapeChecker tracks variable zone depths and detects escape violations (return from zone, assignment to outer variable). Socratic error messages explain Hotel California rule. Falls back to Rust's borrow checker for complex patterns.

```rust
//! Phase 8.5: Escape Analysis for Zone Safety
//!
//! Implements the "Hotel California" containment rule: values can enter
//! zones but cannot escape. This pass checks for obvious violations before
//! codegen, providing Socratic error messages.
//!
//! More complex escape patterns are caught by Rust's borrow checker at
//! compile time, but this pass catches the common cases with better errors.

use std::collections::HashMap;
use crate::ast::stmt::{Stmt, Expr, Block};
use crate::intern::{Interner, Symbol};
use crate::token::Span;

/// Error type for escape violations
#[derive(Debug, Clone)]
pub struct EscapeError {
    pub kind: EscapeErrorKind,
    pub span: Span,
}

#[derive(Debug, Clone)]
pub enum EscapeErrorKind {
    /// Variable cannot escape zone via return
    ReturnEscape {
        variable: String,
        zone_name: String,
    },
    /// Variable cannot escape zone via assignment to outer variable
    AssignmentEscape {
        variable: String,
        target: String,
        zone_name: String,
    },
}

impl std::fmt::Display for EscapeError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match &self.kind {
            EscapeErrorKind::ReturnEscape { variable, zone_name } => {
                write!(
                    f,
                    "Reference '{}' cannot escape zone '{}'.\n\n\
                    Variables allocated inside a zone are deallocated when the zone ends.\n\
                    Returning them would create a dangling reference.\n\n\
                    Tip: Copy the data if you need it outside the zone.",
                    variable, zone_name
                )
            }
            EscapeErrorKind::AssignmentEscape { variable, target, zone_name } => {
                write!(
                    f,
                    "Reference '{}' cannot escape zone '{}' via assignment to '{}'.\n\n\
                    Variables allocated inside a zone are deallocated when the zone ends.\n\
                    Assigning them to outer scope variables would create a dangling reference.\n\n\
                    Tip: Copy the data if you need it outside the zone.",
                    variable, zone_name, target
                )
            }
        }
    }
}

impl std::error::Error for EscapeError {}

/// Tracks the "zone depth" of variables for escape analysis
pub struct EscapeChecker<'a> {
    /// Maps variable symbols to their zone depth (0 = global/outside all zones)
    zone_depth: HashMap<Symbol, usize>,
    /// Current zone depth (increases when entering zones)
    current_depth: usize,
    /// Stack of zone names for error messages
    zone_stack: Vec<Symbol>,
    /// String interner for resolving symbols
    interner: &'a Interner,
}

impl<'a> EscapeChecker<'a> {
    /// Create a new escape checker
    pub fn new(interner: &'a Interner) -> Self {
        Self {
            zone_depth: HashMap::new(),
            current_depth: 0,
            zone_stack: Vec::new(),
            interner,
        }
    }

    /// Check a program (list of statements) for escape violations
    pub fn check_program(&mut self, stmts: &[Stmt<'_>]) -> Result<(), EscapeError> {
        self.check_block(stmts)
    }

    /// Check a block of statements
    fn check_block(&mut self, stmts: &[Stmt<'_>]) -> Result<(), EscapeError> {
        for stmt in stmts {
            self.check_stmt(stmt)?;
        }
        Ok(())
    }

    /// Check a single statement for escape violations
    fn check_stmt(&mut self, stmt: &Stmt<'_>) -> Result<(), EscapeError> {
        match stmt {
            Stmt::Zone { name, body, .. } => {
                // Enter zone: increase depth
                self.current_depth += 1;
                self.zone_stack.push(*name);

                // Check body statements
                self.check_block(body)?;

                // Exit zone: decrease depth
                self.zone_stack.pop();
                self.current_depth -= 1;
            }

            Stmt::Let { var, .. } => {
                // Register variable at current depth
                self.zone_depth.insert(*var, self.current_depth);
            }

            Stmt::Return { value: Some(expr) } => {
                // Return escapes all zones (target depth = 0)
                self.check_no_escape(expr, 0)?;
            }

            Stmt::Set { target, value } => {
                // Assignment: check if value escapes to target's depth
                let target_depth = self.zone_depth.get(target).copied().unwrap_or(0);
                self.check_no_escape_with_target(value, target_depth, *target)?;
            }

            // Recurse into nested blocks
            Stmt::If { then_block, else_block, .. } => {
                self.check_block(then_block)?;
                if let Some(else_b) = else_block {
                    self.check_block(else_b)?;
                }
            }

            Stmt::While { body, .. } => {
                self.check_block(body)?;
            }

            Stmt::Repeat { body, .. } => {
                self.check_block(body)?;
            }

            Stmt::Inspect { arms, .. } => {
                for arm in arms {
                    self.check_block(arm.body)?;
                }
            }

            // Other statements don't introduce escape risks
            _ => {}
        }
        Ok(())
    }

    /// Check that an expression doesn't escape to a shallower depth
    fn check_no_escape(&self, expr: &Expr<'_>, max_depth: usize) -> Result<(), EscapeError> {
        match expr {
            Expr::Identifier(sym) => {
                if let Some(&depth) = self.zone_depth.get(sym) {
                    if depth > max_depth && depth > 0 {
                        // This variable was defined in a deeper zone
                        let zone_name = self.zone_stack.get(depth - 1)
                            .map(|s| self.interner.resolve(*s).to_string())
                            .unwrap_or_else(|| "unknown".to_string());
                        let var_name = self.interner.resolve(*sym).to_string();
                        return Err(EscapeError {
                            kind: EscapeErrorKind::ReturnEscape {
                                variable: var_name,
                                zone_name,
                            },
                            span: Span::default(),
                        });
                    }
                }
            }

            // Recurse into compound expressions
            Expr::BinaryOp { left, right, .. } => {
                self.check_no_escape(left, max_depth)?;
                self.check_no_escape(right, max_depth)?;
            }

            Expr::Call { args, .. } => {
                for arg in args {
                    self.check_no_escape(arg, max_depth)?;
                }
            }

            Expr::FieldAccess { object, .. } => {
                self.check_no_escape(object, max_depth)?;
            }

            Expr::Index { collection, index } => {
                self.check_no_escape(collection, max_depth)?;
                self.check_no_escape(index, max_depth)?;
            }

            Expr::Slice { collection, start, end } => {
                self.check_no_escape(collection, max_depth)?;
                self.check_no_escape(start, max_depth)?;
                self.check_no_escape(end, max_depth)?;
            }

            Expr::Copy { expr } | Expr::Length { collection: expr } => {
                self.check_no_escape(expr, max_depth)?;
            }

            Expr::List(items) | Expr::Tuple(items) => {
                for item in items {
                    self.check_no_escape(item, max_depth)?;
                }
            }

            Expr::Range { start, end } => {
                self.check_no_escape(start, max_depth)?;
                self.check_no_escape(end, max_depth)?;
            }

            Expr::New { init_fields, .. } => {
                for (_, expr) in init_fields {
                    self.check_no_escape(expr, max_depth)?;
                }
            }

            Expr::NewVariant { fields, .. } => {
                for (_, expr) in fields {
                    self.check_no_escape(expr, max_depth)?;
                }
            }

            Expr::ManifestOf { zone } => {
                self.check_no_escape(zone, max_depth)?;
            }

            Expr::ChunkAt { index, zone } => {
                self.check_no_escape(index, max_depth)?;
                self.check_no_escape(zone, max_depth)?;
            }

            Expr::Contains { collection, value } => {
                self.check_no_escape(collection, max_depth)?;
                self.check_no_escape(value, max_depth)?;
            }

            Expr::Union { left, right } | Expr::Intersection { left, right } => {
                self.check_no_escape(left, max_depth)?;
                self.check_no_escape(right, max_depth)?;
            }

            // Literals are always safe
            Expr::Literal(_) => {}
        }
        Ok(())
    }

    /// Check that an expression doesn't escape via assignment
    fn check_no_escape_with_target(
        &self,
        expr: &Expr<'_>,
        max_depth: usize,
        target: Symbol,
    ) -> Result<(), EscapeError> {
        match expr {
            Expr::Identifier(sym) => {
                if let Some(&depth) = self.zone_depth.get(sym) {
                    if depth > max_depth && depth > 0 {
                        let zone_name = self.zone_stack.get(depth - 1)
                            .map(|s| self.interner.resolve(*s).to_string())
                            .unwrap_or_else(|| "unknown".to_string());
                        let var_name = self.interner.resolve(*sym).to_string();
                        let target_name = self.interner.resolve(target).to_string();
                        return Err(EscapeError {
                            kind: EscapeErrorKind::AssignmentEscape {
                                variable: var_name,
                                target: target_name,
                                zone_name,
                            },
                            span: Span::default(),
                        });
                    }
                }
            }
            // For compound expressions, use the simpler check (return style error)
            _ => self.check_no_escape(expr, max_depth)?,
        }
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    // Note: Full integration tests are in tests/phase85_zones.rs
    // These unit tests verify the basic mechanics of the escape checker

    #[test]
    fn test_escape_checker_basic() {
        use crate::intern::Interner;

        let mut interner = Interner::new();
        let checker = EscapeChecker::new(&interner);

        // Just verify creation works
        assert_eq!(checker.current_depth, 0);
        assert!(checker.zone_depth.is_empty());
    }
}

```

---

### Policy Analysis

**File:** `src/analysis/policy.rs`

PolicyRegistry for storing predicate and capability definitions. PolicyCondition enum for rule composition: FieldEquals, FieldBool, Predicate, ObjectFieldEquals, Or, And. PredicateDef and CapabilityDef structs. Integrated with DiscoveryPass for ## Policy block scanning.

```rust
//! Phase 50: Security Policy Registry
//!
//! Stores predicate and capability definitions parsed from `## Policy` blocks.
//! These are used to generate security methods on structs and enforce them
//! with the `Check` statement.

use std::collections::HashMap;
use crate::intern::Symbol;

/// Condition in a policy definition.
/// Represents the predicate logic for security rules.
#[derive(Debug, Clone)]
pub enum PolicyCondition {
    /// Field comparison: `the user's role equals "admin"`
    FieldEquals {
        field: Symbol,
        value: Symbol,
        /// Whether the value came from a string literal (needs quotes in codegen)
        is_string_literal: bool,
    },
    /// Boolean field: `the user's verified equals true`
    FieldBool {
        field: Symbol,
        value: bool,
    },
    /// Predicate call: `the user is admin`
    Predicate {
        subject: Symbol,
        predicate: Symbol,
    },
    /// Object field comparison: `the user equals the document's owner`
    ObjectFieldEquals {
        subject: Symbol,
        object: Symbol,
        field: Symbol,
    },
    /// Logical OR: `A OR B`
    Or(Box<PolicyCondition>, Box<PolicyCondition>),
    /// Logical AND: `A AND B`
    And(Box<PolicyCondition>, Box<PolicyCondition>),
}

/// A predicate definition: `A User is admin if the user's role equals "admin".`
#[derive(Debug, Clone)]
pub struct PredicateDef {
    /// The type this predicate applies to (e.g., "User")
    pub subject_type: Symbol,
    /// The predicate name (e.g., "admin")
    pub predicate_name: Symbol,
    /// The condition that must be true
    pub condition: PolicyCondition,
}

/// A capability definition: `A User can publish the Document if...`
#[derive(Debug, Clone)]
pub struct CapabilityDef {
    /// The type that has this capability (e.g., "User")
    pub subject_type: Symbol,
    /// The action name (e.g., "publish")
    pub action: Symbol,
    /// The object type the action applies to (e.g., "Document")
    pub object_type: Symbol,
    /// The condition that must be true
    pub condition: PolicyCondition,
}

/// Registry for security policies defined in `## Policy` blocks.
#[derive(Debug, Default, Clone)]
pub struct PolicyRegistry {
    /// Predicates indexed by subject type
    predicates: HashMap<Symbol, Vec<PredicateDef>>,
    /// Capabilities indexed by subject type
    capabilities: HashMap<Symbol, Vec<CapabilityDef>>,
}

impl PolicyRegistry {
    pub fn new() -> Self {
        Self::default()
    }

    /// Register a predicate definition
    pub fn register_predicate(&mut self, def: PredicateDef) {
        self.predicates
            .entry(def.subject_type)
            .or_insert_with(Vec::new)
            .push(def);
    }

    /// Register a capability definition
    pub fn register_capability(&mut self, def: CapabilityDef) {
        self.capabilities
            .entry(def.subject_type)
            .or_insert_with(Vec::new)
            .push(def);
    }

    /// Get predicates for a type
    pub fn get_predicates(&self, subject_type: Symbol) -> Option<&[PredicateDef]> {
        self.predicates.get(&subject_type).map(|v| v.as_slice())
    }

    /// Get capabilities for a type
    pub fn get_capabilities(&self, subject_type: Symbol) -> Option<&[CapabilityDef]> {
        self.capabilities.get(&subject_type).map(|v| v.as_slice())
    }

    /// Check if a type has any predicates
    pub fn has_predicates(&self, subject_type: Symbol) -> bool {
        self.predicates.contains_key(&subject_type)
    }

    /// Check if a type has any capabilities
    pub fn has_capabilities(&self, subject_type: Symbol) -> bool {
        self.capabilities.contains_key(&subject_type)
    }

    /// Iterate over all types with predicates (for codegen)
    pub fn iter_predicates(&self) -> impl Iterator<Item = (&Symbol, &Vec<PredicateDef>)> {
        self.predicates.iter()
    }

    /// Iterate over all types with capabilities (for codegen)
    pub fn iter_capabilities(&self) -> impl Iterator<Item = (&Symbol, &Vec<CapabilityDef>)> {
        self.capabilities.iter()
    }

    /// Check if registry has any policies
    pub fn is_empty(&self) -> bool {
        self.predicates.is_empty() && self.capabilities.is_empty()
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::intern::Interner;

    #[test]
    fn registry_stores_predicates() {
        let mut interner = Interner::new();
        let mut registry = PolicyRegistry::new();

        let user = interner.intern("User");
        let admin = interner.intern("admin");
        let role = interner.intern("role");
        let admin_val = interner.intern("admin");

        let def = PredicateDef {
            subject_type: user,
            predicate_name: admin,
            condition: PolicyCondition::FieldEquals {
                field: role,
                value: admin_val,
                is_string_literal: true,
            },
        };

        registry.register_predicate(def);

        assert!(registry.has_predicates(user));
        let preds = registry.get_predicates(user).unwrap();
        assert_eq!(preds.len(), 1);
        assert_eq!(preds[0].predicate_name, admin);
    }

    #[test]
    fn registry_stores_capabilities() {
        let mut interner = Interner::new();
        let mut registry = PolicyRegistry::new();

        let user = interner.intern("User");
        let doc = interner.intern("Document");
        let publish = interner.intern("publish");
        let admin = interner.intern("admin");
        let user_var = interner.intern("user");

        let def = CapabilityDef {
            subject_type: user,
            action: publish,
            object_type: doc,
            condition: PolicyCondition::Predicate {
                subject: user_var,
                predicate: admin,
            },
        };

        registry.register_capability(def);

        assert!(registry.has_capabilities(user));
        let caps = registry.get_capabilities(user).unwrap();
        assert_eq!(caps.len(), 1);
        assert_eq!(caps[0].action, publish);
        assert_eq!(caps[0].object_type, doc);
    }
}

```

---

### Ownership Analysis (Phase 45)

**File:** `src/analysis/ownership.rs`

Control-flow-aware ownership tracking. Move detection in branches, use-after-move errors, Give/Show semantics. OwnershipState tracks Live/Moved/MaybeValid states per variable. Merges states at control flow joins.

```rust
//! Phase 45: Native Ownership Analysis
//!
//! Lightweight data-flow analysis for use-after-move detection.
//! Catches the 90% common cases at check-time (milliseconds), before Rust compilation.
//!
//! This pass tracks `Owned`, `Moved`, and `Borrowed` states through control flow
//! to catch use-after-move errors instantly.

use std::collections::HashMap;
use crate::ast::stmt::{Stmt, Expr};
use crate::intern::{Interner, Symbol};
use crate::token::Span;

/// Ownership state for a variable
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum VarState {
    /// Variable is owned and can be used
    Owned,
    /// Variable has been moved (Give)
    Moved,
    /// Variable might be moved (conditional branch)
    MaybeMoved,
    /// Variable is borrowed (Show) - still usable
    Borrowed,
}

/// Error type for ownership violations
#[derive(Debug, Clone)]
pub struct OwnershipError {
    pub kind: OwnershipErrorKind,
    pub span: Span,
}

#[derive(Debug, Clone)]
pub enum OwnershipErrorKind {
    /// Use after move
    UseAfterMove { variable: String },
    /// Use after potential move (in conditional)
    UseAfterMaybeMove { variable: String, branch: String },
    /// Double move
    DoubleMoved { variable: String },
}

impl std::fmt::Display for OwnershipError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match &self.kind {
            OwnershipErrorKind::UseAfterMove { variable } => {
                write!(f, "Cannot use '{}' after giving it away.\n\n\
                    You transferred ownership of '{}' with Give.\n\
                    Once given, you cannot use it anymore.\n\n\
                    Tip: Use Show instead to lend without giving up ownership.",
                    variable, variable)
            }
            OwnershipErrorKind::UseAfterMaybeMove { variable, branch } => {
                write!(f, "Cannot use '{}' - it might have been given away in {}.\n\n\
                    If the {} branch executes, '{}' will be moved.\n\
                    Using it afterward is not safe.\n\n\
                    Tip: Move the usage inside the branch, or restructure to ensure ownership.",
                    variable, branch, branch, variable)
            }
            OwnershipErrorKind::DoubleMoved { variable } => {
                write!(f, "Cannot give '{}' twice.\n\n\
                    You already transferred ownership of '{}' with Give.\n\
                    You cannot give it again.\n\n\
                    Tip: Consider using Copy to duplicate the value.",
                    variable, variable)
            }
        }
    }
}

impl std::error::Error for OwnershipError {}

/// Ownership checker - tracks variable states through control flow
pub struct OwnershipChecker<'a> {
    /// Maps variable symbols to their current ownership state
    state: HashMap<Symbol, VarState>,
    /// String interner for resolving symbols
    interner: &'a Interner,
}

impl<'a> OwnershipChecker<'a> {
    pub fn new(interner: &'a Interner) -> Self {
        Self {
            state: HashMap::new(),
            interner,
        }
    }

    /// Check a program for ownership violations
    pub fn check_program(&mut self, stmts: &[Stmt<'_>]) -> Result<(), OwnershipError> {
        self.check_block(stmts)
    }

    fn check_block(&mut self, stmts: &[Stmt<'_>]) -> Result<(), OwnershipError> {
        for stmt in stmts {
            self.check_stmt(stmt)?;
        }
        Ok(())
    }

    fn check_stmt(&mut self, stmt: &Stmt<'_>) -> Result<(), OwnershipError> {
        match stmt {
            Stmt::Let { var, value, .. } => {
                // Check the value expression first
                self.check_not_moved(value)?;
                // Register variable as Owned
                self.state.insert(*var, VarState::Owned);
            }

            Stmt::Give { object, .. } => {
                // Check if object is already moved
                if let Expr::Identifier(sym) = object {
                    let current = self.state.get(sym).copied().unwrap_or(VarState::Owned);
                    match current {
                        VarState::Moved => {
                            return Err(OwnershipError {
                                kind: OwnershipErrorKind::DoubleMoved {
                                    variable: self.interner.resolve(*sym).to_string(),
                                },
                                span: Span::default(),
                            });
                        }
                        VarState::MaybeMoved => {
                            return Err(OwnershipError {
                                kind: OwnershipErrorKind::UseAfterMaybeMove {
                                    variable: self.interner.resolve(*sym).to_string(),
                                    branch: "a previous branch".to_string(),
                                },
                                span: Span::default(),
                            });
                        }
                        _ => {
                            self.state.insert(*sym, VarState::Moved);
                        }
                    }
                } else {
                    // For complex expressions, just check they're not moved
                    self.check_not_moved(object)?;
                }
            }

            Stmt::Show { object, .. } => {
                // Check if object is moved before borrowing
                self.check_not_moved(object)?;
                // Mark as borrowed (still usable)
                if let Expr::Identifier(sym) = object {
                    let current = self.state.get(sym).copied();
                    if current == Some(VarState::Owned) || current.is_none() {
                        self.state.insert(*sym, VarState::Borrowed);
                    }
                }
            }

            Stmt::If { then_block, else_block, .. } => {
                // Clone state before branching
                let state_before = self.state.clone();

                // Check then branch
                self.check_block(then_block)?;
                let state_after_then = self.state.clone();

                // Check else branch (if exists)
                let state_after_else = if let Some(else_b) = else_block {
                    self.state = state_before.clone();
                    self.check_block(else_b)?;
                    self.state.clone()
                } else {
                    state_before.clone()
                };

                // Merge states: MaybeMoved if moved in any branch
                self.state = self.merge_states(&state_after_then, &state_after_else);
            }

            Stmt::While { body, .. } => {
                // Clone state before loop
                let state_before = self.state.clone();

                // Check body once
                self.check_block(body)?;
                let state_after_body = self.state.clone();

                // Merge: if moved in body, mark as MaybeMoved
                // (loop might not execute, or might execute multiple times)
                self.state = self.merge_states(&state_before, &state_after_body);
            }

            Stmt::Repeat { body, .. } => {
                // Check body once
                self.check_block(body)?;
            }

            Stmt::Zone { body, .. } => {
                self.check_block(body)?;
            }

            Stmt::Inspect { arms, .. } => {
                if arms.is_empty() {
                    return Ok(());
                }

                // Clone state before branches
                let state_before = self.state.clone();
                let mut branch_states = Vec::new();

                for arm in arms {
                    self.state = state_before.clone();
                    self.check_block(arm.body)?;
                    branch_states.push(self.state.clone());
                }

                // Merge all branch states
                if let Some(first) = branch_states.first() {
                    let mut merged = first.clone();
                    for state in branch_states.iter().skip(1) {
                        merged = self.merge_states(&merged, state);
                    }
                    self.state = merged;
                }
            }

            Stmt::Return { value: Some(expr) } => {
                self.check_not_moved(expr)?;
            }

            Stmt::Return { value: None } => {}

            Stmt::Set { value, .. } => {
                self.check_not_moved(value)?;
            }

            Stmt::Call { args, .. } => {
                for arg in args {
                    self.check_not_moved(arg)?;
                }
            }

            // Other statements don't affect ownership
            _ => {}
        }
        Ok(())
    }

    /// Check that an expression doesn't reference a moved variable
    fn check_not_moved(&self, expr: &Expr<'_>) -> Result<(), OwnershipError> {
        match expr {
            Expr::Identifier(sym) => {
                match self.state.get(sym).copied() {
                    Some(VarState::Moved) => {
                        Err(OwnershipError {
                            kind: OwnershipErrorKind::UseAfterMove {
                                variable: self.interner.resolve(*sym).to_string(),
                            },
                            span: Span::default(),
                        })
                    }
                    Some(VarState::MaybeMoved) => {
                        Err(OwnershipError {
                            kind: OwnershipErrorKind::UseAfterMaybeMove {
                                variable: self.interner.resolve(*sym).to_string(),
                                branch: "a conditional branch".to_string(),
                            },
                            span: Span::default(),
                        })
                    }
                    _ => Ok(())
                }
            }
            Expr::BinaryOp { left, right, .. } => {
                self.check_not_moved(left)?;
                self.check_not_moved(right)?;
                Ok(())
            }
            Expr::FieldAccess { object, .. } => {
                self.check_not_moved(object)
            }
            Expr::Index { collection, index } => {
                self.check_not_moved(collection)?;
                self.check_not_moved(index)?;
                Ok(())
            }
            Expr::Slice { collection, start, end } => {
                self.check_not_moved(collection)?;
                self.check_not_moved(start)?;
                self.check_not_moved(end)?;
                Ok(())
            }
            Expr::Call { args, .. } => {
                for arg in args {
                    self.check_not_moved(arg)?;
                }
                Ok(())
            }
            Expr::List(items) | Expr::Tuple(items) => {
                for item in items {
                    self.check_not_moved(item)?;
                }
                Ok(())
            }
            Expr::Range { start, end } => {
                self.check_not_moved(start)?;
                self.check_not_moved(end)?;
                Ok(())
            }
            Expr::New { init_fields, .. } => {
                for (_, field_expr) in init_fields {
                    self.check_not_moved(field_expr)?;
                }
                Ok(())
            }
            Expr::NewVariant { fields, .. } => {
                for (_, field_expr) in fields {
                    self.check_not_moved(field_expr)?;
                }
                Ok(())
            }
            Expr::Copy { expr } | Expr::Length { collection: expr } => {
                self.check_not_moved(expr)
            }
            Expr::ManifestOf { zone } => {
                self.check_not_moved(zone)
            }
            Expr::ChunkAt { index, zone } => {
                self.check_not_moved(index)?;
                self.check_not_moved(zone)
            }
            Expr::Contains { collection, value } => {
                self.check_not_moved(collection)?;
                self.check_not_moved(value)
            }
            Expr::Union { left, right } | Expr::Intersection { left, right } => {
                self.check_not_moved(left)?;
                self.check_not_moved(right)
            }
            // Literals are always safe
            Expr::Literal(_) => Ok(()),
        }
    }

    /// Merge two branch states - if moved in either, mark as MaybeMoved
    fn merge_states(
        &self,
        state_a: &HashMap<Symbol, VarState>,
        state_b: &HashMap<Symbol, VarState>,
    ) -> HashMap<Symbol, VarState> {
        let mut merged = state_a.clone();

        // Merge keys from state_b
        for (sym, state_b_val) in state_b {
            let state_a_val = state_a.get(sym).copied().unwrap_or(VarState::Owned);

            let merged_val = match (state_a_val, *state_b_val) {
                // Both moved = definitely moved
                (VarState::Moved, VarState::Moved) => VarState::Moved,
                // One moved, one not = maybe moved
                (VarState::Moved, _) | (_, VarState::Moved) => VarState::MaybeMoved,
                // Any maybe moved = maybe moved
                (VarState::MaybeMoved, _) | (_, VarState::MaybeMoved) => VarState::MaybeMoved,
                // Both borrowed = borrowed
                (VarState::Borrowed, VarState::Borrowed) => VarState::Borrowed,
                // Borrowed + Owned = Borrowed (conservative)
                (VarState::Borrowed, _) | (_, VarState::Borrowed) => VarState::Borrowed,
                // Both owned = owned
                (VarState::Owned, VarState::Owned) => VarState::Owned,
            };

            merged.insert(*sym, merged_val);
        }

        // Also check keys only in state_a
        for sym in state_a.keys() {
            if !state_b.contains_key(sym) {
                // Variable exists in one branch but not other - keep state_a value
                // (already in merged)
            }
        }

        merged
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_ownership_checker_basic() {
        let interner = Interner::new();
        let checker = OwnershipChecker::new(&interner);
        assert!(checker.state.is_empty());
    }
}

```

---

## Code Generation

Rust code emission from imperative AST.

**Location:** `src/codegen.rs`, `src/compile.rs`, `src/scope.rs`

### Rust Code Generation

**File:** `src/codegen.rs`

Converts imperative Stmt AST to valid Rust source code. codegen_program() emits complete program with main(). codegen_stmt() handles each Stmt variant: Let→let binding, Set→assignment, Call→function call, If→if/else, While→while loop, Return→return, Assert→debug_assert!, Give→move semantics, Show→borrow. RefinementContext tracks 'Type where predicate' constraints; emit_refinement_check() generates debug_assert!() at Let and on Set mutations. Uses String buffer for zero-dependency output.

```rust
use std::collections::{HashMap, HashSet};
use std::fmt::Write;

use crate::analysis::registry::{FieldDef, FieldType, TypeDef, TypeRegistry, VariantDef};
use crate::analysis::policy::{PolicyRegistry, PredicateDef, CapabilityDef, PolicyCondition};
use crate::ast::logic::{LogicExpr, NumberKind, Term};
use crate::ast::stmt::{BinaryOpKind, Expr, Literal, ReadSource, Stmt, TypeExpr};
use crate::formatter::RustFormatter;
use crate::intern::{Interner, Symbol};
use crate::registry::SymbolRegistry;

// =============================================================================
// Phase 43C: Refinement Type Enforcement
// =============================================================================

/// Tracks refinement type constraints across scopes for mutation enforcement.
/// When a variable with a refinement type is defined, we register its constraint.
/// When that variable is mutated via `Set`, we re-emit the assertion.
/// Phase 50: Also tracks variable types for capability Check resolution.
pub struct RefinementContext<'a> {
    /// Stack of scopes. Each scope maps variable Symbol to (bound_var, predicate).
    scopes: Vec<HashMap<Symbol, (Symbol, &'a LogicExpr<'a>)>>,
    /// Phase 50: Maps variable name Symbol to type name (for capability resolution)
    /// e.g., "doc" -> "Document" allows "Check that user can publish the document" to resolve to &doc
    variable_types: HashMap<Symbol, String>,
}

impl<'a> RefinementContext<'a> {
    pub fn new() -> Self {
        Self {
            scopes: vec![HashMap::new()],
            variable_types: HashMap::new(),
        }
    }

    fn push_scope(&mut self) {
        self.scopes.push(HashMap::new());
    }

    fn pop_scope(&mut self) {
        self.scopes.pop();
    }

    fn register(&mut self, var: Symbol, bound_var: Symbol, predicate: &'a LogicExpr<'a>) {
        if let Some(scope) = self.scopes.last_mut() {
            scope.insert(var, (bound_var, predicate));
        }
    }

    fn get_constraint(&self, var: Symbol) -> Option<(Symbol, &'a LogicExpr<'a>)> {
        for scope in self.scopes.iter().rev() {
            if let Some(entry) = scope.get(&var) {
                return Some(*entry);
            }
        }
        None
    }

    /// Phase 50: Register a variable with its type for capability resolution
    fn register_variable_type(&mut self, var: Symbol, type_name: String) {
        self.variable_types.insert(var, type_name);
    }

    /// Phase 50: Find a variable name by its type (for resolving "the document" to "doc")
    fn find_variable_by_type(&self, type_name: &str, interner: &Interner) -> Option<String> {
        let type_lower = type_name.to_lowercase();
        for (var_sym, var_type) in &self.variable_types {
            if var_type.to_lowercase() == type_lower {
                return Some(interner.resolve(*var_sym).to_string());
            }
        }
        None
    }
}

/// Emits a debug_assert for a refinement predicate, substituting the bound variable.
fn emit_refinement_check(
    var_name: &str,
    bound_var: Symbol,
    predicate: &LogicExpr,
    interner: &Interner,
    indent_str: &str,
    output: &mut String,
) {
    let assertion = codegen_assertion(predicate, interner);
    let bound = interner.resolve(bound_var);
    let check = if bound == var_name {
        assertion
    } else {
        replace_word(&assertion, bound, var_name)
    };
    writeln!(output, "{}debug_assert!({});", indent_str, check).unwrap();
}

/// Word-boundary replacement to substitute bound variable with actual variable.
fn replace_word(text: &str, from: &str, to: &str) -> String {
    let mut result = String::with_capacity(text.len());
    let mut word = String::new();
    for c in text.chars() {
        if c.is_alphanumeric() || c == '_' {
            word.push(c);
        } else {
            if !word.is_empty() {
                result.push_str(if word == from { to } else { &word });
                word.clear();
            }
            result.push(c);
        }
    }
    if !word.is_empty() {
        result.push_str(if word == from { to } else { &word });
    }
    result
}

// =============================================================================
// Phase 56: Mount+Sync Detection for Distributed<T>
// =============================================================================

/// Tracks which variables have Mount and/or Sync statements.
/// Used to detect when a variable needs Distributed<T> instead of separate wrappers.
#[derive(Debug, Default)]
pub struct VariableCapabilities {
    /// Variable has a Mount statement
    mounted: bool,
    /// Variable has a Sync statement
    synced: bool,
    /// Path expression for Mount (as generated code string)
    mount_path: Option<String>,
    /// Topic expression for Sync (as generated code string)
    sync_topic: Option<String>,
}

/// Helper to create an empty VariableCapabilities map (for tests).
pub fn empty_var_caps() -> HashMap<Symbol, VariableCapabilities> {
    HashMap::new()
}

/// Pre-scan statements to detect variables that have both Mount and Sync.
/// Returns a map from variable Symbol to its capabilities.
fn analyze_variable_capabilities<'a>(
    stmts: &[Stmt<'a>],
    interner: &Interner,
) -> HashMap<Symbol, VariableCapabilities> {
    let mut caps: HashMap<Symbol, VariableCapabilities> = HashMap::new();
    let empty_synced = HashSet::new();

    for stmt in stmts {
        match stmt {
            Stmt::Mount { var, path } => {
                let entry = caps.entry(*var).or_default();
                entry.mounted = true;
                entry.mount_path = Some(codegen_expr(path, interner, &empty_synced));
            }
            Stmt::Sync { var, topic } => {
                let entry = caps.entry(*var).or_default();
                entry.synced = true;
                entry.sync_topic = Some(codegen_expr(topic, interner, &empty_synced));
            }
            // Recursively check nested blocks (Block<'a> is &[Stmt<'a>])
            Stmt::If { then_block, else_block, .. } => {
                let nested = analyze_variable_capabilities(then_block, interner);
                for (var, cap) in nested {
                    let entry = caps.entry(var).or_default();
                    if cap.mounted { entry.mounted = true; entry.mount_path = cap.mount_path; }
                    if cap.synced { entry.synced = true; entry.sync_topic = cap.sync_topic; }
                }
                if let Some(else_b) = else_block {
                    let nested = analyze_variable_capabilities(else_b, interner);
                    for (var, cap) in nested {
                        let entry = caps.entry(var).or_default();
                        if cap.mounted { entry.mounted = true; entry.mount_path = cap.mount_path; }
                        if cap.synced { entry.synced = true; entry.sync_topic = cap.sync_topic; }
                    }
                }
            }
            Stmt::While { body, .. } | Stmt::Repeat { body, .. } => {
                let nested = analyze_variable_capabilities(body, interner);
                for (var, cap) in nested {
                    let entry = caps.entry(var).or_default();
                    if cap.mounted { entry.mounted = true; entry.mount_path = cap.mount_path; }
                    if cap.synced { entry.synced = true; entry.sync_topic = cap.sync_topic; }
                }
            }
            _ => {}
        }
    }

    caps
}

/// Phase 51: Detect if any statements require async execution.
/// Returns true if the program needs #[tokio::main] async fn main().
fn requires_async(stmts: &[Stmt]) -> bool {
    stmts.iter().any(|s| requires_async_stmt(s))
}

fn requires_async_stmt(stmt: &Stmt) -> bool {
    match stmt {
        // Phase 9: Concurrent blocks use tokio::join!
        Stmt::Concurrent { tasks } => true,
        // Phase 51: Network operations and Sleep are async
        Stmt::Listen { .. } => true,
        Stmt::ConnectTo { .. } => true,
        Stmt::Sleep { .. } => true,
        // Phase 52: Sync is async (GossipSub subscription)
        Stmt::Sync { .. } => true,
        // Phase 53: Mount is async (VFS file operations)
        Stmt::Mount { .. } => true,
        // Phase 53: File I/O is async (VFS operations)
        Stmt::ReadFrom { source: ReadSource::File(_), .. } => true,
        Stmt::WriteFile { .. } => true,
        // Phase 54: Go-like concurrency is async
        Stmt::LaunchTask { .. } => true,
        Stmt::LaunchTaskWithHandle { .. } => true,
        Stmt::SendPipe { .. } => true,
        Stmt::ReceivePipe { .. } => true,
        Stmt::Select { .. } => true,
        // While and Repeat are now always async due to check_preemption()
        // (handled below in recursive check)
        // Recursively check nested blocks
        Stmt::If { then_block, else_block, .. } => {
            then_block.iter().any(|s| requires_async_stmt(s))
                || else_block.map_or(false, |b| b.iter().any(|s| requires_async_stmt(s)))
        }
        Stmt::While { body, .. } => body.iter().any(|s| requires_async_stmt(s)),
        Stmt::Repeat { body, .. } => body.iter().any(|s| requires_async_stmt(s)),
        Stmt::Zone { body, .. } => body.iter().any(|s| requires_async_stmt(s)),
        Stmt::Parallel { tasks } => tasks.iter().any(|s| requires_async_stmt(s)),
        Stmt::FunctionDef { body, .. } => body.iter().any(|s| requires_async_stmt(s)),
        _ => false,
    }
}

/// Phase 53: Detect if any statements require VFS (Virtual File System).
/// Returns true if the program uses file operations or persistent storage.
fn requires_vfs(stmts: &[Stmt]) -> bool {
    stmts.iter().any(|s| requires_vfs_stmt(s))
}

fn requires_vfs_stmt(stmt: &Stmt) -> bool {
    match stmt {
        // Phase 53: Mount uses VFS for persistent storage
        Stmt::Mount { .. } => true,
        // Phase 53: File I/O uses VFS
        Stmt::ReadFrom { source: ReadSource::File(_), .. } => true,
        Stmt::WriteFile { .. } => true,
        // Recursively check nested blocks
        Stmt::If { then_block, else_block, .. } => {
            then_block.iter().any(|s| requires_vfs_stmt(s))
                || else_block.map_or(false, |b| b.iter().any(|s| requires_vfs_stmt(s)))
        }
        Stmt::While { body, .. } => body.iter().any(|s| requires_vfs_stmt(s)),
        Stmt::Repeat { body, .. } => body.iter().any(|s| requires_vfs_stmt(s)),
        Stmt::Zone { body, .. } => body.iter().any(|s| requires_vfs_stmt(s)),
        Stmt::Concurrent { tasks } => tasks.iter().any(|s| requires_vfs_stmt(s)),
        Stmt::Parallel { tasks } => tasks.iter().any(|s| requires_vfs_stmt(s)),
        Stmt::FunctionDef { body, .. } => body.iter().any(|s| requires_vfs_stmt(s)),
        _ => false,
    }
}

/// Phase 49b: Extract root identifier from expression for mutability analysis.
/// Works with both simple identifiers and field accesses.
fn get_root_identifier_for_mutability(expr: &Expr) -> Option<Symbol> {
    match expr {
        Expr::Identifier(sym) => Some(*sym),
        Expr::FieldAccess { object, .. } => get_root_identifier_for_mutability(object),
        _ => None,
    }
}

/// Grand Challenge: Collect all variables that need `let mut` in Rust.
/// This includes:
/// - Variables that are targets of `Set` statements (reassignment)
/// - Variables that are targets of `Push` statements (mutation via push)
/// - Variables that are targets of `Pop` statements (mutation via pop)
fn collect_mutable_vars(stmts: &[Stmt]) -> HashSet<Symbol> {
    let mut targets = HashSet::new();
    for stmt in stmts {
        collect_mutable_vars_stmt(stmt, &mut targets);
    }
    targets
}

fn collect_mutable_vars_stmt(stmt: &Stmt, targets: &mut HashSet<Symbol>) {
    match stmt {
        Stmt::Set { target, .. } => {
            targets.insert(*target);
        }
        Stmt::Push { collection, .. } => {
            // If collection is an identifier, it needs to be mutable
            if let Expr::Identifier(sym) = collection {
                targets.insert(*sym);
            }
        }
        Stmt::Pop { collection, .. } => {
            // If collection is an identifier, it needs to be mutable
            if let Expr::Identifier(sym) = collection {
                targets.insert(*sym);
            }
        }
        Stmt::Add { collection, .. } => {
            // If collection is an identifier (Set) or field access, root needs to be mutable
            if let Some(sym) = get_root_identifier_for_mutability(collection) {
                targets.insert(sym);
            }
        }
        Stmt::Remove { collection, .. } => {
            // If collection is an identifier (Set) or field access, root needs to be mutable
            if let Some(sym) = get_root_identifier_for_mutability(collection) {
                targets.insert(sym);
            }
        }
        Stmt::SetIndex { collection, .. } => {
            // If collection is an identifier, it needs to be mutable
            if let Expr::Identifier(sym) = collection {
                targets.insert(*sym);
            }
        }
        Stmt::If { then_block, else_block, .. } => {
            for s in *then_block {
                collect_mutable_vars_stmt(s, targets);
            }
            if let Some(else_stmts) = else_block {
                for s in *else_stmts {
                    collect_mutable_vars_stmt(s, targets);
                }
            }
        }
        Stmt::While { body, .. } => {
            for s in *body {
                collect_mutable_vars_stmt(s, targets);
            }
        }
        Stmt::Repeat { body, .. } => {
            for s in *body {
                collect_mutable_vars_stmt(s, targets);
            }
        }
        Stmt::Zone { body, .. } => {
            for s in *body {
                collect_mutable_vars_stmt(s, targets);
            }
        }
        // Phase 9: Structured Concurrency blocks
        Stmt::Concurrent { tasks } | Stmt::Parallel { tasks } => {
            for s in *tasks {
                collect_mutable_vars_stmt(s, targets);
            }
        }
        // Phase 49b: CRDT operations require mutable access
        Stmt::IncreaseCrdt { object, .. } | Stmt::DecreaseCrdt { object, .. } => {
            // Extract root variable from field access (e.g., g.score -> g)
            if let Some(sym) = get_root_identifier_for_mutability(object) {
                targets.insert(sym);
            }
        }
        Stmt::AppendToSequence { sequence, .. } => {
            if let Some(sym) = get_root_identifier_for_mutability(sequence) {
                targets.insert(sym);
            }
        }
        Stmt::ResolveConflict { object, .. } => {
            if let Some(sym) = get_root_identifier_for_mutability(object) {
                targets.insert(sym);
            }
        }
        // Phase 49b: SetField on MVRegister/LWWRegister uses .set() which requires &mut self
        Stmt::SetField { object, .. } => {
            if let Some(sym) = get_root_identifier_for_mutability(object) {
                targets.insert(sym);
            }
        }
        _ => {}
    }
}

// =============================================================================
// Phase 50: Policy Method Generation
// =============================================================================

/// Generate impl blocks with predicate and capability methods for security policies.
fn codegen_policy_impls(policies: &PolicyRegistry, interner: &Interner) -> String {
    let mut output = String::new();

    // Collect all types that have policies
    let mut type_predicates: HashMap<Symbol, Vec<&PredicateDef>> = HashMap::new();
    let mut type_capabilities: HashMap<Symbol, Vec<&CapabilityDef>> = HashMap::new();

    for (type_sym, predicates) in policies.iter_predicates() {
        type_predicates.entry(*type_sym).or_insert_with(Vec::new).extend(predicates.iter());
    }

    for (type_sym, capabilities) in policies.iter_capabilities() {
        type_capabilities.entry(*type_sym).or_insert_with(Vec::new).extend(capabilities.iter());
    }

    // Get all types that have any policies
    let mut all_types: HashSet<Symbol> = HashSet::new();
    all_types.extend(type_predicates.keys().copied());
    all_types.extend(type_capabilities.keys().copied());

    // Generate impl block for each type
    for type_sym in all_types {
        let type_name = interner.resolve(type_sym);

        writeln!(output, "impl {} {{", type_name).unwrap();

        // Generate predicate methods
        if let Some(predicates) = type_predicates.get(&type_sym) {
            for pred in predicates {
                let pred_name = interner.resolve(pred.predicate_name).to_lowercase();
                writeln!(output, "    pub fn is_{}(&self) -> bool {{", pred_name).unwrap();
                let condition_code = codegen_policy_condition(&pred.condition, interner);
                writeln!(output, "        {}", condition_code).unwrap();
                writeln!(output, "    }}\n").unwrap();
            }
        }

        // Generate capability methods
        if let Some(capabilities) = type_capabilities.get(&type_sym) {
            for cap in capabilities {
                let action_name = interner.resolve(cap.action).to_lowercase();
                let object_type = interner.resolve(cap.object_type);
                let object_param = object_type.to_lowercase();

                writeln!(output, "    pub fn can_{}(&self, {}: &{}) -> bool {{",
                         action_name, object_param, object_type).unwrap();
                let condition_code = codegen_policy_condition(&cap.condition, interner);
                writeln!(output, "        {}", condition_code).unwrap();
                writeln!(output, "    }}\n").unwrap();
            }
        }

        writeln!(output, "}}\n").unwrap();
    }

    output
}

/// Generate Rust code for a policy condition.
fn codegen_policy_condition(condition: &PolicyCondition, interner: &Interner) -> String {
    match condition {
        PolicyCondition::FieldEquals { field, value, is_string_literal } => {
            let field_name = interner.resolve(*field);
            let value_str = interner.resolve(*value);
            if *is_string_literal {
                format!("self.{} == \"{}\"", field_name, value_str)
            } else {
                format!("self.{} == {}", field_name, value_str)
            }
        }
        PolicyCondition::FieldBool { field, value } => {
            let field_name = interner.resolve(*field);
            format!("self.{} == {}", field_name, value)
        }
        PolicyCondition::Predicate { subject: _, predicate } => {
            let pred_name = interner.resolve(*predicate).to_lowercase();
            format!("self.is_{}()", pred_name)
        }
        PolicyCondition::ObjectFieldEquals { subject: _, object, field } => {
            let object_name = interner.resolve(*object).to_lowercase();
            let field_name = interner.resolve(*field);
            format!("self == &{}.{}", object_name, field_name)
        }
        PolicyCondition::Or(left, right) => {
            let left_code = codegen_policy_condition(left, interner);
            let right_code = codegen_policy_condition(right, interner);
            format!("{} || {}", left_code, right_code)
        }
        PolicyCondition::And(left, right) => {
            let left_code = codegen_policy_condition(left, interner);
            let right_code = codegen_policy_condition(right, interner);
            format!("{} && {}", left_code, right_code)
        }
    }
}

/// Collect LWWRegister and MVRegister field paths for special handling in SetField codegen.
/// Returns a set of (type_name, field_name) pairs where the field uses .set() method.
fn collect_lww_fields(registry: &TypeRegistry, interner: &Interner) -> HashSet<(String, String)> {
    let mut lww_fields = HashSet::new();
    for (type_sym, def) in registry.iter_types() {
        if let TypeDef::Struct { fields, .. } = def {
            let type_name = interner.resolve(*type_sym).to_string();
            for field in fields {
                if let FieldType::Generic { base, .. } = &field.ty {
                    let base_name = interner.resolve(*base);
                    // Phase 49b: Both LWWRegister and MVRegister (Divergent) use .set()
                    if base_name == "LastWriteWins" || base_name == "Divergent" || base_name == "MVRegister" {
                        let field_name = interner.resolve(field.name).to_string();
                        lww_fields.insert((type_name.clone(), field_name));
                    }
                }
            }
        }
    }
    lww_fields
}

/// Phase 54: Collect function names that are async.
/// Used by LaunchTask codegen to determine if .await is needed.
fn collect_async_functions(stmts: &[Stmt]) -> HashSet<Symbol> {
    let mut async_fns = HashSet::new();
    for stmt in stmts {
        if let Stmt::FunctionDef { name, body, .. } = stmt {
            if body.iter().any(|s| requires_async_stmt(s)) {
                async_fns.insert(*name);
            }
        }
    }
    async_fns
}

/// Phase 54: Collect parameters that are used as pipe senders in function body.
/// If a param appears in `SendPipe { pipe: Expr::Identifier(param) }`, it's a sender.
fn collect_pipe_sender_params(body: &[Stmt]) -> HashSet<Symbol> {
    let mut senders = HashSet::new();
    for stmt in body {
        collect_pipe_sender_params_stmt(stmt, &mut senders);
    }
    senders
}

fn collect_pipe_sender_params_stmt(stmt: &Stmt, senders: &mut HashSet<Symbol>) {
    match stmt {
        Stmt::SendPipe { pipe, .. } | Stmt::TrySendPipe { pipe, .. } => {
            if let Expr::Identifier(sym) = pipe {
                senders.insert(*sym);
            }
        }
        Stmt::If { then_block, else_block, .. } => {
            for s in *then_block {
                collect_pipe_sender_params_stmt(s, senders);
            }
            if let Some(else_stmts) = else_block {
                for s in *else_stmts {
                    collect_pipe_sender_params_stmt(s, senders);
                }
            }
        }
        Stmt::While { body, .. } | Stmt::Repeat { body, .. } | Stmt::Zone { body, .. } => {
            for s in *body {
                collect_pipe_sender_params_stmt(s, senders);
            }
        }
        _ => {}
    }
}

/// Phase 54: Collect variables that are pipe declarations (created with CreatePipe).
/// These have _tx/_rx suffixes, while pipe parameters don't.
fn collect_pipe_vars(stmts: &[Stmt]) -> HashSet<Symbol> {
    let mut pipe_vars = HashSet::new();
    for stmt in stmts {
        collect_pipe_vars_stmt(stmt, &mut pipe_vars);
    }
    pipe_vars
}

fn collect_pipe_vars_stmt(stmt: &Stmt, pipe_vars: &mut HashSet<Symbol>) {
    match stmt {
        Stmt::CreatePipe { var, .. } => {
            pipe_vars.insert(*var);
        }
        Stmt::If { then_block, else_block, .. } => {
            for s in *then_block {
                collect_pipe_vars_stmt(s, pipe_vars);
            }
            if let Some(else_stmts) = else_block {
                for s in *else_stmts {
                    collect_pipe_vars_stmt(s, pipe_vars);
                }
            }
        }
        Stmt::While { body, .. } | Stmt::Repeat { body, .. } | Stmt::Zone { body, .. } => {
            for s in *body {
                collect_pipe_vars_stmt(s, pipe_vars);
            }
        }
        Stmt::Concurrent { tasks } | Stmt::Parallel { tasks } => {
            for s in *tasks {
                collect_pipe_vars_stmt(s, pipe_vars);
            }
        }
        _ => {}
    }
}

/// Generate complete Rust program with struct definitions and main function.
///
/// Phase 31: Structs are wrapped in `mod user_types` to enforce visibility.
/// Phase 32: Function definitions are emitted before main.
/// Phase 50: Accepts PolicyRegistry to generate security predicate methods.
pub fn codegen_program(stmts: &[Stmt], registry: &TypeRegistry, policies: &PolicyRegistry, interner: &Interner) -> String {
    let mut output = String::new();

    // Prelude
    writeln!(output, "use logos_core::prelude::*;\n").unwrap();

    // Phase 49: Collect LWWRegister fields for special SetField handling
    let lww_fields = collect_lww_fields(registry, interner);

    // Phase 54: Collect async functions for Launch codegen
    let async_functions = collect_async_functions(stmts);

    // Phase 54: Collect pipe declarations (variables with _tx/_rx suffixes)
    let main_pipe_vars = collect_pipe_vars(stmts);

    // Collect user-defined structs from registry (Phase 34: generics, Phase 47: is_portable, Phase 49: is_shared)
    let structs: Vec<_> = registry.iter_types()
        .filter_map(|(name, def)| {
            if let TypeDef::Struct { fields, generics, is_portable, is_shared } = def {
                if !fields.is_empty() || !generics.is_empty() {
                    Some((*name, fields.clone(), generics.clone(), *is_portable, *is_shared))
                } else {
                    None
                }
            } else {
                None
            }
        })
        .collect();

    // Phase 33/34: Collect user-defined enums from registry (generics, Phase 47: is_portable, Phase 49: is_shared)
    let enums: Vec<_> = registry.iter_types()
        .filter_map(|(name, def)| {
            if let TypeDef::Enum { variants, generics, is_portable, is_shared } = def {
                if !variants.is_empty() || !generics.is_empty() {
                    Some((*name, variants.clone(), generics.clone(), *is_portable, *is_shared))
                } else {
                    None
                }
            } else {
                None
            }
        })
        .collect();

    // Emit struct and enum definitions in user_types module if any exist
    if !structs.is_empty() || !enums.is_empty() {
        writeln!(output, "pub mod user_types {{").unwrap();
        writeln!(output, "    use super::*;\n").unwrap();

        for (name, fields, generics, is_portable, is_shared) in &structs {
            output.push_str(&codegen_struct_def(*name, fields, generics, *is_portable, *is_shared, interner, 4));
        }

        for (name, variants, generics, is_portable, is_shared) in &enums {
            output.push_str(&codegen_enum_def(*name, variants, generics, *is_portable, *is_shared, interner, 4));
        }

        writeln!(output, "}}\n").unwrap();
        writeln!(output, "use user_types::*;\n").unwrap();
    }

    // Phase 50: Generate policy impl blocks with predicate and capability methods
    output.push_str(&codegen_policy_impls(policies, interner));

    // Phase 32/38: Emit function definitions before main
    for stmt in stmts {
        if let Stmt::FunctionDef { name, params, body, return_type, is_native } = stmt {
            output.push_str(&codegen_function_def(*name, params, body, return_type.as_ref().copied(), *is_native, interner, &lww_fields, &async_functions));
        }
    }

    // Grand Challenge: Collect variables that need to be mutable
    let main_stmts: Vec<&Stmt> = stmts.iter()
        .filter(|s| !matches!(s, Stmt::FunctionDef { .. }))
        .collect();
    let mut main_mutable_vars = HashSet::new();
    for stmt in &main_stmts {
        collect_mutable_vars_stmt(stmt, &mut main_mutable_vars);
    }

    // Main function
    // Phase 51: Use async main when async operations are present
    if requires_async(stmts) {
        writeln!(output, "#[tokio::main]").unwrap();
        writeln!(output, "async fn main() {{").unwrap();
    } else {
        writeln!(output, "fn main() {{").unwrap();
    }
    // Phase 53: Inject VFS when file operations or persistence is used
    if requires_vfs(stmts) {
        writeln!(output, "    let vfs = logos_core::fs::NativeVfs::new(\".\");").unwrap();
    }
    let mut main_ctx = RefinementContext::new();
    let mut main_synced_vars = HashSet::new();  // Phase 52: Track synced variables in main
    // Phase 56: Pre-scan for Mount+Sync combinations
    let main_var_caps = analyze_variable_capabilities(stmts, interner);
    for stmt in stmts {
        // Skip function definitions - they're already emitted above
        if matches!(stmt, Stmt::FunctionDef { .. }) {
            continue;
        }
        output.push_str(&codegen_stmt(stmt, interner, 1, &main_mutable_vars, &mut main_ctx, &lww_fields, &mut main_synced_vars, &main_var_caps, &async_functions, &main_pipe_vars));
    }
    writeln!(output, "}}").unwrap();
    output
}

/// Phase 32/38: Generate a function definition.
/// Phase 38: Updated for native functions and TypeExpr types.
/// Phase 49: Accepts lww_fields for LWWRegister SetField handling.
fn codegen_function_def(
    name: Symbol,
    params: &[(Symbol, &TypeExpr)],
    body: &[Stmt],
    return_type: Option<&TypeExpr>,
    is_native: bool,
    interner: &Interner,
    lww_fields: &HashSet<(String, String)>,
    async_functions: &HashSet<Symbol>,  // Phase 54
) -> String {
    let mut output = String::new();
    let func_name = interner.resolve(name);

    // Phase 54: Detect which parameters are used as pipe senders
    let pipe_sender_params = collect_pipe_sender_params(body);

    // Build parameter list using TypeExpr
    let params_str: Vec<String> = params.iter()
        .map(|(param_name, param_type)| {
            let name = interner.resolve(*param_name);
            let ty = codegen_type_expr(param_type, interner);
            // Phase 54: If param is used as a pipe sender, wrap type in Sender<T>
            if pipe_sender_params.contains(param_name) {
                format!("{}: tokio::sync::mpsc::Sender<{}>", name, ty)
            } else {
                format!("{}: {}", name, ty)
            }
        })
        .collect();

    // Get return type string from TypeExpr or infer from body
    let return_type_str = return_type
        .map(|t| codegen_type_expr(t, interner))
        .or_else(|| infer_return_type_from_body(body, interner));

    // Phase 51: Check if function body requires async
    let is_async = body.iter().any(|s| requires_async_stmt(s));
    let fn_keyword = if is_async { "async fn" } else { "fn" };

    // Build function signature
    let signature = if let Some(ref ret_ty) = return_type_str {
        if ret_ty != "()" {
            format!("{} {}({}) -> {}", fn_keyword, func_name, params_str.join(", "), ret_ty)
        } else {
            format!("{} {}({})", fn_keyword, func_name, params_str.join(", "))
        }
    } else {
        format!("{} {}({})", fn_keyword, func_name, params_str.join(", "))
    };

    // Phase 38: Handle native functions
    if is_native {
        let (module, core_fn) = map_native_function(func_name);
        writeln!(output, "{} {{", signature).unwrap();

        // Generate call to logos_core
        let arg_names: Vec<&str> = params.iter()
            .map(|(n, _)| interner.resolve(*n))
            .collect();

        writeln!(output, "    logos_core::{}::{}({})", module, core_fn, arg_names.join(", ")).unwrap();
        writeln!(output, "}}\n").unwrap();
    } else {
        // Non-native: emit body
        // Grand Challenge: Collect mutable vars for this function
        let func_mutable_vars = collect_mutable_vars(body);
        writeln!(output, "{} {{", signature).unwrap();
        let mut func_ctx = RefinementContext::new();
        let mut func_synced_vars = HashSet::new();  // Phase 52: Track synced variables in function
        // Phase 56: Pre-scan for Mount+Sync combinations in function body
        let func_var_caps = analyze_variable_capabilities(body, interner);

        // Phase 50: Register parameter types for capability Check resolution
        for (param_name, param_type) in params {
            let type_name = codegen_type_expr(param_type, interner);
            func_ctx.register_variable_type(*param_name, type_name);
        }

        // Phase 54: Functions receive pipe senders as parameters, no local pipe declarations
        let func_pipe_vars = HashSet::new();

        for stmt in body {
            output.push_str(&codegen_stmt(stmt, interner, 1, &func_mutable_vars, &mut func_ctx, lww_fields, &mut func_synced_vars, &func_var_caps, async_functions, &func_pipe_vars));
        }
        writeln!(output, "}}\n").unwrap();
    }

    output
}

/// Phase 38: Map native function names to logos_core module paths.
fn map_native_function(name: &str) -> (&'static str, &'static str) {
    match name {
        "read" => ("file", "read"),
        "write" => ("file", "write"),
        "now" => ("time", "now"),
        "sleep" => ("time", "sleep"),
        "randomInt" => ("random", "randomInt"),
        "randomFloat" => ("random", "randomFloat"),
        "get" => ("env", "get"),
        "args" => ("env", "args"),
        _ => panic!("Unknown native function: {}. Add mapping to map_native_function().", name),
    }
}

/// Phase 38: Convert TypeExpr to Rust type string.
fn codegen_type_expr(ty: &TypeExpr, interner: &Interner) -> String {
    match ty {
        TypeExpr::Primitive(sym) => {
            map_type_to_rust(interner.resolve(*sym))
        }
        TypeExpr::Named(sym) => {
            let name = interner.resolve(*sym);
            // Check for common mappings
            map_type_to_rust(name)
        }
        TypeExpr::Generic { base, params } => {
            let base_name = interner.resolve(*base);
            let params_str: Vec<String> = params.iter()
                .map(|p| codegen_type_expr(p, interner))
                .collect();

            match base_name {
                "Result" => {
                    if params_str.len() == 2 {
                        format!("Result<{}, {}>", params_str[0], params_str[1])
                    } else if params_str.len() == 1 {
                        format!("Result<{}, String>", params_str[0])
                    } else {
                        "Result<(), String>".to_string()
                    }
                }
                "Option" => {
                    if !params_str.is_empty() {
                        format!("Option<{}>", params_str[0])
                    } else {
                        "Option<()>".to_string()
                    }
                }
                "Seq" | "List" | "Vec" => {
                    if !params_str.is_empty() {
                        format!("Vec<{}>", params_str[0])
                    } else {
                        "Vec<()>".to_string()
                    }
                }
                "Map" | "HashMap" => {
                    if params_str.len() >= 2 {
                        format!("std::collections::HashMap<{}, {}>", params_str[0], params_str[1])
                    } else {
                        "std::collections::HashMap<String, String>".to_string()
                    }
                }
                "Set" | "HashSet" => {
                    if !params_str.is_empty() {
                        format!("std::collections::HashSet<{}>", params_str[0])
                    } else {
                        "std::collections::HashSet<()>".to_string()
                    }
                }
                other => {
                    if params_str.is_empty() {
                        other.to_string()
                    } else {
                        format!("{}<{}>", other, params_str.join(", "))
                    }
                }
            }
        }
        TypeExpr::Function { inputs, output } => {
            let inputs_str: Vec<String> = inputs.iter()
                .map(|i| codegen_type_expr(i, interner))
                .collect();
            let output_str = codegen_type_expr(output, interner);
            format!("fn({}) -> {}", inputs_str.join(", "), output_str)
        }
        // Phase 43C: Refinement types use the base type for Rust type annotation
        // The constraint predicate is handled separately via debug_assert!
        TypeExpr::Refinement { base, .. } => {
            codegen_type_expr(base, interner)
        }
        // Phase 53: Persistent storage wrapper
        TypeExpr::Persistent { inner } => {
            let inner_type = codegen_type_expr(inner, interner);
            format!("logos_core::storage::Persistent<{}>", inner_type)
        }
    }
}

/// Infer return type from function body by looking at Return statements.
fn infer_return_type_from_body(body: &[Stmt], _interner: &Interner) -> Option<String> {
    for stmt in body {
        if let Stmt::Return { value: Some(_) } = stmt {
            // For now, assume i64 for any expression return
            // TODO: Implement proper type inference
            return Some("i64".to_string());
        }
    }
    None
}

/// Map LOGOS type names to Rust types.
fn map_type_to_rust(ty: &str) -> String {
    match ty {
        "Int" => "i64".to_string(),
        "Nat" => "u64".to_string(),
        "Text" => "String".to_string(),
        "Bool" | "Boolean" => "bool".to_string(),
        "Real" => "f64".to_string(),
        "Char" => "char".to_string(),
        "Byte" => "u8".to_string(),
        "Unit" | "()" => "()".to_string(),
        other => other.to_string(),
    }
}

/// Generate a single struct definition with derives and visibility.
/// Phase 34: Now supports generic type parameters.
/// Phase 47: Now supports is_portable for Serialize/Deserialize derives.
/// Phase 49: Now supports is_shared for CRDT Merge impl.
fn codegen_struct_def(name: Symbol, fields: &[FieldDef], generics: &[Symbol], is_portable: bool, is_shared: bool, interner: &Interner, indent: usize) -> String {
    let ind = " ".repeat(indent);
    let mut output = String::new();

    // Build generic parameter string: <T, U> or empty
    let generic_str = if generics.is_empty() {
        String::new()
    } else {
        let params: Vec<&str> = generics.iter()
            .map(|g| interner.resolve(*g))
            .collect();
        format!("<{}>", params.join(", "))
    };

    // Phase 47: Add Serialize, Deserialize derives if portable
    // Phase 50: Add PartialEq for policy equality comparisons
    // Phase 52: Shared types also need Serialize/Deserialize for Synced<T>
    if is_portable || is_shared {
        writeln!(output, "{}#[derive(Default, Debug, Clone, PartialEq, serde::Serialize, serde::Deserialize)]", ind).unwrap();
    } else {
        writeln!(output, "{}#[derive(Default, Debug, Clone, PartialEq)]", ind).unwrap();
    }
    writeln!(output, "{}pub struct {}{} {{", ind, interner.resolve(name), generic_str).unwrap();

    for field in fields {
        let vis = if field.is_public { "pub " } else { "" };
        let rust_type = codegen_field_type(&field.ty, interner);
        writeln!(output, "{}    {}{}: {},", ind, vis, interner.resolve(field.name), rust_type).unwrap();
    }

    writeln!(output, "{}}}\n", ind).unwrap();

    // Phase 49: Generate Merge impl for Shared structs
    if is_shared {
        output.push_str(&codegen_merge_impl(name, fields, generics, interner, indent));
    }

    output
}

/// Phase 49: Generate impl Merge for a Shared struct.
fn codegen_merge_impl(name: Symbol, fields: &[FieldDef], generics: &[Symbol], interner: &Interner, indent: usize) -> String {
    let ind = " ".repeat(indent);
    let name_str = interner.resolve(name);
    let mut output = String::new();

    // Build generic parameter string: <T, U> or empty
    let generic_str = if generics.is_empty() {
        String::new()
    } else {
        let params: Vec<&str> = generics.iter()
            .map(|g| interner.resolve(*g))
            .collect();
        format!("<{}>", params.join(", "))
    };

    writeln!(output, "{}impl{} logos_core::crdt::Merge for {}{} {{", ind, generic_str, name_str, generic_str).unwrap();
    writeln!(output, "{}    fn merge(&mut self, other: &Self) {{", ind).unwrap();

    for field in fields {
        let field_name = interner.resolve(field.name);
        // Only merge fields that implement Merge (CRDT types)
        if is_crdt_field_type(&field.ty, interner) {
            writeln!(output, "{}        self.{}.merge(&other.{});", ind, field_name, field_name).unwrap();
        }
    }

    writeln!(output, "{}    }}", ind).unwrap();
    writeln!(output, "{}}}\n", ind).unwrap();

    output
}

/// Phase 49: Check if a field type is a CRDT type that implements Merge.
fn is_crdt_field_type(ty: &FieldType, interner: &Interner) -> bool {
    match ty {
        FieldType::Named(sym) => {
            let name = interner.resolve(*sym);
            matches!(name,
                "ConvergentCount" | "GCounter" |
                "Tally" | "PNCounter"
            )
        }
        FieldType::Generic { base, .. } => {
            let name = interner.resolve(*base);
            matches!(name,
                "LastWriteWins" | "LWWRegister" |
                "SharedSet" | "ORSet" | "SharedSet_AddWins" | "SharedSet_RemoveWins" |
                "SharedSequence" | "RGA" | "SharedSequence_YATA" | "CollaborativeSequence" |
                "SharedMap" | "ORMap" |
                "Divergent" | "MVRegister"
            )
        }
        _ => false,
    }
}

/// Phase 33/34: Generate enum definition with optional generic parameters.
/// Phase 47: Now supports is_portable for Serialize/Deserialize derives.
/// Phase 49: Now accepts is_shared parameter (enums don't generate Merge impl yet).
fn codegen_enum_def(name: Symbol, variants: &[VariantDef], generics: &[Symbol], is_portable: bool, _is_shared: bool, interner: &Interner, indent: usize) -> String {
    let ind = " ".repeat(indent);
    let mut output = String::new();

    // Build generic parameter string: <T, U> or empty
    let generic_str = if generics.is_empty() {
        String::new()
    } else {
        let params: Vec<&str> = generics.iter()
            .map(|g| interner.resolve(*g))
            .collect();
        format!("<{}>", params.join(", "))
    };

    // Phase 47: Add Serialize, Deserialize derives if portable
    if is_portable {
        writeln!(output, "{}#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]", ind).unwrap();
    } else {
        writeln!(output, "{}#[derive(Debug, Clone)]", ind).unwrap();
    }
    writeln!(output, "{}pub enum {}{} {{", ind, interner.resolve(name), generic_str).unwrap();

    for variant in variants {
        let variant_name = interner.resolve(variant.name);
        if variant.fields.is_empty() {
            // Unit variant
            writeln!(output, "{}    {},", ind, variant_name).unwrap();
        } else {
            // Struct variant with named fields
            let fields_str: Vec<String> = variant.fields.iter()
                .map(|f| {
                    let rust_type = codegen_field_type(&f.ty, interner);
                    format!("{}: {}", interner.resolve(f.name), rust_type)
                })
                .collect();
            writeln!(output, "{}    {} {{ {} }},", ind, variant_name, fields_str.join(", ")).unwrap();
        }
    }

    writeln!(output, "{}}}\n", ind).unwrap();
    output
}

/// Convert FieldType to Rust type string.
fn codegen_field_type(ty: &FieldType, interner: &Interner) -> String {
    match ty {
        FieldType::Primitive(sym) => {
            match interner.resolve(*sym) {
                "Int" => "i64".to_string(),
                "Nat" => "u64".to_string(),
                "Text" => "String".to_string(),
                "Bool" | "Boolean" => "bool".to_string(),
                "Real" => "f64".to_string(),
                "Char" => "char".to_string(),
                "Byte" => "u8".to_string(),
                "Unit" => "()".to_string(),
                other => other.to_string(),
            }
        }
        FieldType::Named(sym) => {
            let name = interner.resolve(*sym);
            match name {
                // Phase 49: CRDT type mapping
                "ConvergentCount" => "logos_core::crdt::GCounter".to_string(),
                // Phase 49b: New CRDT types (Wave 5)
                "Tally" => "logos_core::crdt::PNCounter".to_string(),
                _ => name.to_string(),
            }
        }
        FieldType::Generic { base, params } => {
            let base_name = interner.resolve(*base);
            let param_strs: Vec<String> = params.iter()
                .map(|p| codegen_field_type(p, interner))
                .collect();

            // Phase 49c: Handle CRDT types with bias/algorithm modifiers
            match base_name {
                // SharedSet with explicit bias
                "SharedSet_RemoveWins" => {
                    return format!("logos_core::crdt::ORSet<{}, logos_core::crdt::RemoveWins>", param_strs.join(", "));
                }
                "SharedSet_AddWins" => {
                    return format!("logos_core::crdt::ORSet<{}, logos_core::crdt::AddWins>", param_strs.join(", "));
                }
                // SharedSequence with YATA algorithm
                "SharedSequence_YATA" | "CollaborativeSequence" => {
                    return format!("logos_core::crdt::YATA<{}>", param_strs.join(", "));
                }
                _ => {}
            }

            let base_str = match base_name {
                "List" | "Seq" => "Vec",
                "Set" => "std::collections::HashSet",
                "Map" => "std::collections::HashMap",
                "Option" => "Option",
                "Result" => "Result",
                // Phase 49: CRDT generic type
                "LastWriteWins" => "logos_core::crdt::LWWRegister",
                // Phase 49b: New CRDT generic types (Wave 5) - default to AddWins for ORSet
                "SharedSet" | "ORSet" => "logos_core::crdt::ORSet",
                "SharedSequence" | "RGA" => "logos_core::crdt::RGA",
                "SharedMap" | "ORMap" => "logos_core::crdt::ORMap",
                "Divergent" | "MVRegister" => "logos_core::crdt::MVRegister",
                other => other,
            };
            format!("{}<{}>", base_str, param_strs.join(", "))
        }
        // Phase 34: Type parameter reference (T, U, etc.)
        FieldType::TypeParam(sym) => interner.resolve(*sym).to_string(),
    }
}

pub fn codegen_stmt<'a>(
    stmt: &Stmt<'a>,
    interner: &Interner,
    indent: usize,
    mutable_vars: &HashSet<Symbol>,
    ctx: &mut RefinementContext<'a>,
    lww_fields: &HashSet<(String, String)>,
    synced_vars: &mut HashSet<Symbol>,  // Phase 52: Track synced variables
    var_caps: &HashMap<Symbol, VariableCapabilities>,  // Phase 56: Mount+Sync detection
    async_functions: &HashSet<Symbol>,  // Phase 54: Functions that are async
    pipe_vars: &HashSet<Symbol>,  // Phase 54: Pipe declarations (have _tx/_rx suffixes)
) -> String {
    let indent_str = "    ".repeat(indent);
    let mut output = String::new();

    match stmt {
        Stmt::Let { var, ty, value, mutable } => {
            let var_name = interner.resolve(*var);
            let value_str = codegen_expr(value, interner, synced_vars);
            let type_annotation = ty.map(|t| codegen_type_expr(t, interner));

            // Grand Challenge: Variable is mutable if explicitly marked OR if it's a Set target
            let is_mutable = *mutable || mutable_vars.contains(var);

            match (is_mutable, type_annotation) {
                (true, Some(t)) => writeln!(output, "{}let mut {}: {} = {};", indent_str, var_name, t, value_str).unwrap(),
                (true, None) => writeln!(output, "{}let mut {} = {};", indent_str, var_name, value_str).unwrap(),
                (false, Some(t)) => writeln!(output, "{}let {}: {} = {};", indent_str, var_name, t, value_str).unwrap(),
                (false, None) => writeln!(output, "{}let {} = {};", indent_str, var_name, value_str).unwrap(),
            }

            // Phase 43C: Handle refinement type
            if let Some(TypeExpr::Refinement { base: _, var: bound_var, predicate }) = ty {
                emit_refinement_check(var_name, *bound_var, predicate, interner, &indent_str, &mut output);
                ctx.register(*var, *bound_var, predicate);
            }
        }

        Stmt::Set { target, value } => {
            let target_name = interner.resolve(*target);
            let value_str = codegen_expr(value, interner, synced_vars);
            writeln!(output, "{}{} = {};", indent_str, target_name, value_str).unwrap();

            // Phase 43C: Check if this variable has a refinement constraint
            if let Some((bound_var, predicate)) = ctx.get_constraint(*target) {
                emit_refinement_check(target_name, bound_var, predicate, interner, &indent_str, &mut output);
            }
        }

        Stmt::Call { function, args } => {
            let func_name = interner.resolve(*function);
            let args_str: Vec<String> = args.iter().map(|a| codegen_expr(a, interner, synced_vars)).collect();
            writeln!(output, "{}{}({});", indent_str, func_name, args_str.join(", ")).unwrap();
        }

        Stmt::If { cond, then_block, else_block } => {
            let cond_str = codegen_expr(cond, interner, synced_vars);
            writeln!(output, "{}if {} {{", indent_str, cond_str).unwrap();
            ctx.push_scope();
            for stmt in *then_block {
                output.push_str(&codegen_stmt(stmt, interner, indent + 1, mutable_vars, ctx, lww_fields, synced_vars, var_caps, async_functions, pipe_vars));
            }
            ctx.pop_scope();
            if let Some(else_stmts) = else_block {
                writeln!(output, "{}}} else {{", indent_str).unwrap();
                ctx.push_scope();
                for stmt in *else_stmts {
                    output.push_str(&codegen_stmt(stmt, interner, indent + 1, mutable_vars, ctx, lww_fields, synced_vars, var_caps, async_functions, pipe_vars));
                }
                ctx.pop_scope();
            }
            writeln!(output, "{}}}", indent_str).unwrap();
        }

        Stmt::While { cond, body, decreasing: _ } => {
            // decreasing is compile-time only, ignored at runtime
            let cond_str = codegen_expr(cond, interner, synced_vars);
            writeln!(output, "{}while {} {{", indent_str, cond_str).unwrap();
            ctx.push_scope();
            for stmt in *body {
                output.push_str(&codegen_stmt(stmt, interner, indent + 1, mutable_vars, ctx, lww_fields, synced_vars, var_caps, async_functions, pipe_vars));
            }
            ctx.pop_scope();
            writeln!(output, "{}}}", indent_str).unwrap();
        }

        Stmt::Repeat { var, iterable, body } => {
            let var_name = interner.resolve(*var);
            let iter_str = codegen_expr(iterable, interner, synced_vars);
            writeln!(output, "{}for {} in {} {{", indent_str, var_name, iter_str).unwrap();
            ctx.push_scope();
            for stmt in *body {
                output.push_str(&codegen_stmt(stmt, interner, indent + 1, mutable_vars, ctx, lww_fields, synced_vars, var_caps, async_functions, pipe_vars));
            }
            ctx.pop_scope();
            writeln!(output, "{}}}", indent_str).unwrap();
        }

        Stmt::Return { value } => {
            if let Some(v) = value {
                let value_str = codegen_expr(v, interner, synced_vars);
                writeln!(output, "{}return {};", indent_str, value_str).unwrap();
            } else {
                writeln!(output, "{}return;", indent_str).unwrap();
            }
        }

        Stmt::Assert { proposition } => {
            let condition = codegen_assertion(proposition, interner);
            writeln!(output, "{}debug_assert!({});", indent_str, condition).unwrap();
        }

        // Phase 35: Trust with documented justification
        Stmt::Trust { proposition, justification } => {
            let reason = interner.resolve(*justification);
            // Strip quotes if present (string literals include their quotes)
            let reason_clean = reason.trim_matches('"');
            writeln!(output, "{}// TRUST: {}", indent_str, reason_clean).unwrap();
            let condition = codegen_assertion(proposition, interner);
            writeln!(output, "{}debug_assert!({});", indent_str, condition).unwrap();
        }

        Stmt::RuntimeAssert { condition } => {
            let cond_str = codegen_expr(condition, interner, synced_vars);
            writeln!(output, "{}debug_assert!({});", indent_str, cond_str).unwrap();
        }

        // Phase 50: Security Check - mandatory runtime guard (NEVER optimized out)
        Stmt::Check { subject, predicate, is_capability, object, source_text, span } => {
            let subj_name = interner.resolve(*subject);
            let pred_name = interner.resolve(*predicate).to_lowercase();

            let call = if *is_capability {
                let obj_sym = object.expect("capability must have object");
                let obj_word = interner.resolve(obj_sym);

                // Phase 50: Type-based resolution
                // "Check that user can publish the document" -> find variable of type Document
                // First try to find a variable whose type matches the object word
                let obj_name = ctx.find_variable_by_type(obj_word, interner)
                    .unwrap_or_else(|| obj_word.to_string());

                format!("{}.can_{}(&{})", subj_name, pred_name, obj_name)
            } else {
                format!("{}.is_{}()", subj_name, pred_name)
            };

            writeln!(output, "{}if !({}) {{", indent_str, call).unwrap();
            writeln!(output, "{}    logos_core::panic_with(\"Security Check Failed at line {}: {}\");",
                     indent_str, span.start, source_text).unwrap();
            writeln!(output, "{}}}", indent_str).unwrap();
        }

        // Phase 51: P2P Networking - Listen on network address
        Stmt::Listen { address } => {
            let addr_str = codegen_expr(address, interner, synced_vars);
            // Pass &str instead of String
            writeln!(output, "{}logos_core::network::listen(&{}).await.expect(\"Failed to listen\");",
                     indent_str, addr_str).unwrap();
        }

        // Phase 51: P2P Networking - Connect to remote peer
        Stmt::ConnectTo { address } => {
            let addr_str = codegen_expr(address, interner, synced_vars);
            // Pass &str instead of String
            writeln!(output, "{}logos_core::network::connect(&{}).await.expect(\"Failed to connect\");",
                     indent_str, addr_str).unwrap();
        }

        // Phase 51: P2P Networking - Create PeerAgent remote handle
        Stmt::LetPeerAgent { var, address } => {
            let var_name = interner.resolve(*var);
            let addr_str = codegen_expr(address, interner, synced_vars);
            // Pass &str instead of String
            writeln!(output, "{}let {} = logos_core::network::PeerAgent::new(&{}).expect(\"Invalid address\");",
                     indent_str, var_name, addr_str).unwrap();
        }

        // Phase 51: Sleep for milliseconds
        Stmt::Sleep { milliseconds } => {
            let ms_str = codegen_expr(milliseconds, interner, synced_vars);
            // Use tokio async sleep
            writeln!(output, "{}tokio::time::sleep(std::time::Duration::from_millis({} as u64)).await;",
                     indent_str, ms_str).unwrap();
        }

        // Phase 52/56: Sync CRDT variable on topic
        Stmt::Sync { var, topic } => {
            let var_name = interner.resolve(*var);
            let topic_str = codegen_expr(topic, interner, synced_vars);

            // Phase 56: Check if this variable is also mounted
            if let Some(caps) = var_caps.get(var) {
                if caps.mounted {
                    // Both Mount and Sync: use Distributed<T>
                    // Mount statement will handle the Distributed::mount call
                    // Here we just track it as synced
                    synced_vars.insert(*var);
                    return output;  // Skip - Mount will emit Distributed<T>
                }
            }

            // Sync-only: use Synced<T>
            writeln!(
                output,
                "{}let {} = logos_core::crdt::Synced::new({}, &{}).await;",
                indent_str, var_name, var_name, topic_str
            ).unwrap();
            synced_vars.insert(*var);
        }

        // Phase 53/56: Mount persistent CRDT from journal
        Stmt::Mount { var, path } => {
            let var_name = interner.resolve(*var);
            let path_str = codegen_expr(path, interner, synced_vars);

            // Phase 56: Check if this variable is also synced
            if let Some(caps) = var_caps.get(var) {
                if caps.synced {
                    // Both Mount and Sync: use Distributed<T>
                    let topic_str = caps.sync_topic.as_ref()
                        .map(|s| s.as_str())
                        .unwrap_or("\"default\"");
                    writeln!(
                        output,
                        "{}let {} = logos_core::distributed::Distributed::mount(std::sync::Arc::new(vfs.clone()), &{}, Some({}.to_string())).await.expect(\"Failed to mount\");",
                        indent_str, var_name, path_str, topic_str
                    ).unwrap();
                    synced_vars.insert(*var);
                    return output;
                }
            }

            // Mount-only: use Persistent<T>
            writeln!(
                output,
                "{}let {} = logos_core::storage::Persistent::mount(&vfs, &{}).await.expect(\"Failed to mount\");",
                indent_str, var_name, path_str
            ).unwrap();
            synced_vars.insert(*var);
        }

        // =====================================================================
        // Phase 54: Go-like Concurrency Codegen
        // =====================================================================

        Stmt::LaunchTask { function, args } => {
            let fn_name = interner.resolve(*function);
            // Phase 54: When passing a pipe variable, pass the sender (_tx)
            let args_str: Vec<String> = args.iter()
                .map(|a| {
                    if let Expr::Identifier(sym) = a {
                        if pipe_vars.contains(sym) {
                            return format!("{}_tx.clone()", interner.resolve(*sym));
                        }
                    }
                    codegen_expr(a, interner, synced_vars)
                })
                .collect();
            // Phase 54: Add .await only if the function is async
            let await_suffix = if async_functions.contains(function) { ".await" } else { "" };
            writeln!(
                output,
                "{}tokio::spawn(async move {{ {}({}){await_suffix}; }});",
                indent_str, fn_name, args_str.join(", ")
            ).unwrap();
        }

        Stmt::LaunchTaskWithHandle { handle, function, args } => {
            let handle_name = interner.resolve(*handle);
            let fn_name = interner.resolve(*function);
            // Phase 54: When passing a pipe variable, pass the sender (_tx)
            let args_str: Vec<String> = args.iter()
                .map(|a| {
                    if let Expr::Identifier(sym) = a {
                        if pipe_vars.contains(sym) {
                            return format!("{}_tx.clone()", interner.resolve(*sym));
                        }
                    }
                    codegen_expr(a, interner, synced_vars)
                })
                .collect();
            // Phase 54: Add .await only if the function is async
            let await_suffix = if async_functions.contains(function) { ".await" } else { "" };
            writeln!(
                output,
                "{}let {} = tokio::spawn(async move {{ {}({}){await_suffix} }});",
                indent_str, handle_name, fn_name, args_str.join(", ")
            ).unwrap();
        }

        Stmt::CreatePipe { var, element_type, capacity } => {
            let var_name = interner.resolve(*var);
            let type_name = interner.resolve(*element_type);
            let cap = capacity.unwrap_or(32);
            // Map LOGOS types to Rust types
            let rust_type = match type_name {
                "Int" => "i64",
                "Nat" => "u64",
                "Text" => "String",
                "Bool" => "bool",
                _ => type_name,
            };
            writeln!(
                output,
                "{}let ({}_tx, mut {}_rx) = tokio::sync::mpsc::channel::<{}>({});",
                indent_str, var_name, var_name, rust_type, cap
            ).unwrap();
        }

        Stmt::SendPipe { value, pipe } => {
            let val_str = codegen_expr(value, interner, synced_vars);
            let pipe_str = codegen_expr(pipe, interner, synced_vars);
            // Phase 54: Check if pipe is a local declaration (has _tx suffix) or parameter (no suffix)
            let is_local_pipe = if let Expr::Identifier(sym) = pipe {
                pipe_vars.contains(sym)
            } else {
                false
            };
            if is_local_pipe {
                writeln!(
                    output,
                    "{}{}_tx.send({}).await.expect(\"pipe send failed\");",
                    indent_str, pipe_str, val_str
                ).unwrap();
            } else {
                writeln!(
                    output,
                    "{}{}.send({}).await.expect(\"pipe send failed\");",
                    indent_str, pipe_str, val_str
                ).unwrap();
            }
        }

        Stmt::ReceivePipe { var, pipe } => {
            let var_name = interner.resolve(*var);
            let pipe_str = codegen_expr(pipe, interner, synced_vars);
            // Phase 54: Check if pipe is a local declaration (has _rx suffix) or parameter (no suffix)
            let is_local_pipe = if let Expr::Identifier(sym) = pipe {
                pipe_vars.contains(sym)
            } else {
                false
            };
            if is_local_pipe {
                writeln!(
                    output,
                    "{}let {} = {}_rx.recv().await.expect(\"pipe closed\");",
                    indent_str, var_name, pipe_str
                ).unwrap();
            } else {
                writeln!(
                    output,
                    "{}let {} = {}.recv().await.expect(\"pipe closed\");",
                    indent_str, var_name, pipe_str
                ).unwrap();
            }
        }

        Stmt::TrySendPipe { value, pipe, result } => {
            let val_str = codegen_expr(value, interner, synced_vars);
            let pipe_str = codegen_expr(pipe, interner, synced_vars);
            // Phase 54: Check if pipe is a local declaration
            let is_local_pipe = if let Expr::Identifier(sym) = pipe {
                pipe_vars.contains(sym)
            } else {
                false
            };
            let suffix = if is_local_pipe { "_tx" } else { "" };
            if let Some(res) = result {
                let res_name = interner.resolve(*res);
                writeln!(
                    output,
                    "{}let {} = {}{}.try_send({}).is_ok();",
                    indent_str, res_name, pipe_str, suffix, val_str
                ).unwrap();
            } else {
                writeln!(
                    output,
                    "{}let _ = {}{}.try_send({});",
                    indent_str, pipe_str, suffix, val_str
                ).unwrap();
            }
        }

        Stmt::TryReceivePipe { var, pipe } => {
            let var_name = interner.resolve(*var);
            let pipe_str = codegen_expr(pipe, interner, synced_vars);
            // Phase 54: Check if pipe is a local declaration
            let is_local_pipe = if let Expr::Identifier(sym) = pipe {
                pipe_vars.contains(sym)
            } else {
                false
            };
            let suffix = if is_local_pipe { "_rx" } else { "" };
            writeln!(
                output,
                "{}let {} = {}{}.try_recv().ok();",
                indent_str, var_name, pipe_str, suffix
            ).unwrap();
        }

        Stmt::StopTask { handle } => {
            let handle_str = codegen_expr(handle, interner, synced_vars);
            writeln!(output, "{}{}.abort();", indent_str, handle_str).unwrap();
        }

        Stmt::Select { branches } => {
            use crate::ast::stmt::SelectBranch;

            writeln!(output, "{}tokio::select! {{", indent_str).unwrap();
            for branch in branches {
                match branch {
                    SelectBranch::Receive { var, pipe, body } => {
                        let var_name = interner.resolve(*var);
                        let pipe_str = codegen_expr(pipe, interner, synced_vars);
                        writeln!(
                            output,
                            "{}    {} = {}_rx.recv() => {{",
                            indent_str, var_name, pipe_str
                        ).unwrap();
                        writeln!(
                            output,
                            "{}        if let Some({}) = {} {{",
                            indent_str, var_name, var_name
                        ).unwrap();
                        for stmt in *body {
                            let stmt_code = codegen_stmt(stmt, interner, indent + 3, mutable_vars, ctx, lww_fields, synced_vars, var_caps, async_functions, pipe_vars);
                            write!(output, "{}", stmt_code).unwrap();
                        }
                        writeln!(output, "{}        }}", indent_str).unwrap();
                        writeln!(output, "{}    }}", indent_str).unwrap();
                    }
                    SelectBranch::Timeout { milliseconds, body } => {
                        let ms_str = codegen_expr(milliseconds, interner, synced_vars);
                        // Convert seconds to milliseconds if the value looks like seconds
                        writeln!(
                            output,
                            "{}    _ = tokio::time::sleep(std::time::Duration::from_secs({} as u64)) => {{",
                            indent_str, ms_str
                        ).unwrap();
                        for stmt in *body {
                            let stmt_code = codegen_stmt(stmt, interner, indent + 2, mutable_vars, ctx, lww_fields, synced_vars, var_caps, async_functions, pipe_vars);
                            write!(output, "{}", stmt_code).unwrap();
                        }
                        writeln!(output, "{}    }}", indent_str).unwrap();
                    }
                }
            }
            writeln!(output, "{}}}", indent_str).unwrap();
        }

        Stmt::Give { object, recipient } => {
            // Move semantics: pass ownership without borrowing
            let obj_str = codegen_expr(object, interner, synced_vars);
            let recv_str = codegen_expr(recipient, interner, synced_vars);
            writeln!(output, "{}{}({});", indent_str, recv_str, obj_str).unwrap();
        }

        Stmt::Show { object, recipient } => {
            // Borrow semantics: pass immutable reference
            let obj_str = codegen_expr(object, interner, synced_vars);
            let recv_str = codegen_expr(recipient, interner, synced_vars);
            writeln!(output, "{}{}(&{});", indent_str, recv_str, obj_str).unwrap();
        }

        Stmt::SetField { object, field, value } => {
            let obj_str = codegen_expr(object, interner, synced_vars);
            let field_name = interner.resolve(*field);
            let value_str = codegen_expr(value, interner, synced_vars);

            // Phase 49: Check if this field is an LWWRegister - use .set() instead of =
            // We check if ANY type has this field as LWW (heuristic - works for most cases)
            let is_lww = lww_fields.iter().any(|(_, f)| f == field_name);
            if is_lww {
                writeln!(output, "{}{}.{}.set({});", indent_str, obj_str, field_name, value_str).unwrap();
            } else {
                writeln!(output, "{}{}.{} = {};", indent_str, obj_str, field_name, value_str).unwrap();
            }
        }

        Stmt::StructDef { .. } => {
            // Struct definitions are handled in codegen_program, not here
        }

        Stmt::FunctionDef { .. } => {
            // Function definitions are handled in codegen_program, not here
        }

        Stmt::Inspect { target, arms, .. } => {
            let target_str = codegen_expr(target, interner, synced_vars);
            writeln!(output, "{}match {} {{", indent_str, target_str).unwrap();

            for arm in arms {
                if let Some(variant) = arm.variant {
                    let variant_name = interner.resolve(variant);
                    // Get the enum name from the arm, or fallback to just variant name
                    let enum_prefix = arm.enum_name
                        .map(|e| format!("{}::", interner.resolve(e)))
                        .unwrap_or_default();

                    if arm.bindings.is_empty() {
                        // Unit variant pattern
                        writeln!(output, "{}    {}{} => {{", indent_str, enum_prefix, variant_name).unwrap();
                    } else {
                        // Pattern with bindings
                        let bindings_str: Vec<String> = arm.bindings.iter()
                            .map(|(field, binding)| {
                                let field_name = interner.resolve(*field);
                                let binding_name = interner.resolve(*binding);
                                if field_name == binding_name {
                                    field_name.to_string()
                                } else {
                                    format!("{}: {}", field_name, binding_name)
                                }
                            })
                            .collect();
                        writeln!(output, "{}    {}{} {{ {} }} => {{", indent_str, enum_prefix, variant_name, bindings_str.join(", ")).unwrap();
                    }
                } else {
                    // Otherwise (wildcard) pattern
                    writeln!(output, "{}    _ => {{", indent_str).unwrap();
                }

                ctx.push_scope();
                for stmt in arm.body {
                    output.push_str(&codegen_stmt(stmt, interner, indent + 2, mutable_vars, ctx, lww_fields, synced_vars, var_caps, async_functions, pipe_vars));
                }
                ctx.pop_scope();
                writeln!(output, "{}    }}", indent_str).unwrap();
            }

            writeln!(output, "{}}}", indent_str).unwrap();
        }

        Stmt::Push { value, collection } => {
            let val_str = codegen_expr(value, interner, synced_vars);
            let coll_str = codegen_expr(collection, interner, synced_vars);
            writeln!(output, "{}{}.push({});", indent_str, coll_str, val_str).unwrap();
        }

        Stmt::Pop { collection, into } => {
            let coll_str = codegen_expr(collection, interner, synced_vars);
            match into {
                Some(var) => {
                    let var_name = interner.resolve(*var);
                    // Unwrap the Option returned by pop() - panics if empty
                    writeln!(output, "{}let {} = {}.pop().expect(\"Pop from empty collection\");", indent_str, var_name, coll_str).unwrap();
                }
                None => {
                    writeln!(output, "{}{}.pop();", indent_str, coll_str).unwrap();
                }
            }
        }

        Stmt::Add { value, collection } => {
            let val_str = codegen_expr(value, interner, synced_vars);
            let coll_str = codegen_expr(collection, interner, synced_vars);
            writeln!(output, "{}{}.insert({});", indent_str, coll_str, val_str).unwrap();
        }

        Stmt::Remove { value, collection } => {
            let val_str = codegen_expr(value, interner, synced_vars);
            let coll_str = codegen_expr(collection, interner, synced_vars);
            writeln!(output, "{}{}.remove(&{});", indent_str, coll_str, val_str).unwrap();
        }

        Stmt::SetIndex { collection, index, value } => {
            let coll_str = codegen_expr(collection, interner, synced_vars);
            let index_str = codegen_expr(index, interner, synced_vars);
            let value_str = codegen_expr(value, interner, synced_vars);
            // Phase 57: Polymorphic indexing via trait
            writeln!(output, "{}LogosIndexMut::logos_set(&mut {}, {}, {});", indent_str, coll_str, index_str, value_str).unwrap();
        }

        // Phase 8.5: Zone (memory arena) block
        Stmt::Zone { name, capacity, source_file, body } => {
            let zone_name = interner.resolve(*name);

            // Generate zone creation based on type
            if let Some(path_sym) = source_file {
                // Memory-mapped file zone
                let path = interner.resolve(*path_sym);
                writeln!(
                    output,
                    "{}let {} = logos_core::memory::Zone::new_mapped(\"{}\").expect(\"Failed to map file\");",
                    indent_str, zone_name, path
                ).unwrap();
            } else {
                // Heap arena zone
                let cap = capacity.unwrap_or(4096); // Default 4KB
                writeln!(
                    output,
                    "{}let {} = logos_core::memory::Zone::new_heap({});",
                    indent_str, zone_name, cap
                ).unwrap();
            }

            // Open block scope
            writeln!(output, "{}{{", indent_str).unwrap();
            ctx.push_scope();

            // Generate body statements
            for stmt in *body {
                output.push_str(&codegen_stmt(stmt, interner, indent + 1, mutable_vars, ctx, lww_fields, synced_vars, var_caps, async_functions, pipe_vars));
            }

            ctx.pop_scope();
            writeln!(output, "{}}}", indent_str).unwrap();
        }

        // Phase 9: Concurrent execution block (async, I/O-bound)
        // Generates tokio::join! for concurrent task execution
        // Phase 51: Variables used across multiple tasks are cloned to avoid move issues
        Stmt::Concurrent { tasks } => {
            // Collect Let statements to generate tuple destructuring
            let let_bindings: Vec<_> = tasks.iter().filter_map(|s| {
                if let Stmt::Let { var, .. } = s {
                    Some(interner.resolve(*var).to_string())
                } else {
                    None
                }
            }).collect();

            // Collect variables used in Call statements across all tasks
            let used_vars: HashSet<String> = tasks.iter().flat_map(|s| {
                if let Stmt::Call { args, .. } = s {
                    args.iter().filter_map(|arg| {
                        if let Expr::Identifier(sym) = arg {
                            Some(interner.resolve(*sym).to_string())
                        } else {
                            None
                        }
                    }).collect::<Vec<_>>()
                } else {
                    vec![]
                }
            }).collect();

            if !let_bindings.is_empty() {
                // Generate tuple destructuring for concurrent Let bindings
                writeln!(output, "{}let ({}) = tokio::join!(", indent_str, let_bindings.join(", ")).unwrap();
            } else {
                writeln!(output, "{}tokio::join!(", indent_str).unwrap();
            }

            for (i, stmt) in tasks.iter().enumerate() {
                let inner = codegen_stmt(stmt, interner, indent + 1, mutable_vars, ctx, lww_fields, synced_vars, var_caps, async_functions, pipe_vars);

                // Convert call statements to awaited calls for async context
                let inner_awaited = if let Stmt::Call { .. } = stmt {
                    // Add .await before the semicolon for function calls
                    inner.trim().trim_end_matches(';').to_string() + ".await;"
                } else {
                    inner.trim().to_string()
                };

                // For tasks that use shared variables, wrap in a block that clones them
                if !used_vars.is_empty() && i < tasks.len() - 1 {
                    // Clone variables for all tasks except the last one
                    let clones: Vec<String> = used_vars.iter()
                        .map(|v| format!("let {} = {}.clone();", v, v))
                        .collect();
                    write!(output, "{}    {{ {} async move {{ {} }} }}",
                           indent_str, clones.join(" "), inner_awaited).unwrap();
                } else {
                    // Last task can use original variables
                    write!(output, "{}    async {{ {} }}", indent_str, inner_awaited).unwrap();
                }

                if i < tasks.len() - 1 {
                    writeln!(output, ",").unwrap();
                } else {
                    writeln!(output).unwrap();
                }
            }

            writeln!(output, "{});", indent_str).unwrap();
        }

        // Phase 9: Parallel execution block (CPU-bound)
        // Generates rayon::join for two tasks, or thread::spawn for 3+ tasks
        Stmt::Parallel { tasks } => {
            // Collect Let statements to generate tuple destructuring
            let let_bindings: Vec<_> = tasks.iter().filter_map(|s| {
                if let Stmt::Let { var, .. } = s {
                    Some(interner.resolve(*var).to_string())
                } else {
                    None
                }
            }).collect();

            if tasks.len() == 2 {
                // Use rayon::join for exactly 2 tasks
                if !let_bindings.is_empty() {
                    writeln!(output, "{}let ({}) = rayon::join(", indent_str, let_bindings.join(", ")).unwrap();
                } else {
                    writeln!(output, "{}rayon::join(", indent_str).unwrap();
                }

                for (i, stmt) in tasks.iter().enumerate() {
                    let inner = codegen_stmt(stmt, interner, indent + 1, mutable_vars, ctx, lww_fields, synced_vars, var_caps, async_functions, pipe_vars);
                    write!(output, "{}    || {{ {} }}", indent_str, inner.trim()).unwrap();
                    if i == 0 {
                        writeln!(output, ",").unwrap();
                    } else {
                        writeln!(output).unwrap();
                    }
                }
                writeln!(output, "{});", indent_str).unwrap();
            } else {
                // For 3+ tasks, use thread::spawn pattern
                writeln!(output, "{}{{", indent_str).unwrap();
                writeln!(output, "{}    let handles: Vec<_> = vec![", indent_str).unwrap();
                for stmt in *tasks {
                    let inner = codegen_stmt(stmt, interner, indent + 2, mutable_vars, ctx, lww_fields, synced_vars, var_caps, async_functions, pipe_vars);
                    writeln!(output, "{}        std::thread::spawn(move || {{ {} }}),",
                             indent_str, inner.trim()).unwrap();
                }
                writeln!(output, "{}    ];", indent_str).unwrap();
                writeln!(output, "{}    for h in handles {{ h.join().unwrap(); }}", indent_str).unwrap();
                writeln!(output, "{}}}", indent_str).unwrap();
            }
        }

        // Phase 10: Read from console or file
        // Phase 53: File reads now use async VFS
        Stmt::ReadFrom { var, source } => {
            let var_name = interner.resolve(*var);
            match source {
                ReadSource::Console => {
                    writeln!(output, "{}let {} = logos_core::io::read_line();", indent_str, var_name).unwrap();
                }
                ReadSource::File(path_expr) => {
                    let path_str = codegen_expr(path_expr, interner, synced_vars);
                    // Phase 53: Use VFS with async
                    writeln!(
                        output,
                        "{}let {} = vfs.read_to_string(&{}).await.expect(\"Failed to read file\");",
                        indent_str, var_name, path_str
                    ).unwrap();
                }
            }
        }

        // Phase 10: Write to file
        // Phase 53: File writes now use async VFS
        Stmt::WriteFile { content, path } => {
            let content_str = codegen_expr(content, interner, synced_vars);
            let path_str = codegen_expr(path, interner, synced_vars);
            // Phase 53: Use VFS with async
            writeln!(
                output,
                "{}vfs.write(&{}, {}.as_bytes()).await.expect(\"Failed to write file\");",
                indent_str, path_str, content_str
            ).unwrap();
        }

        // Phase 46: Spawn an agent
        Stmt::Spawn { agent_type, name } => {
            let type_name = interner.resolve(*agent_type);
            let agent_name = interner.resolve(*name);
            // Generate agent spawn with tokio channel
            writeln!(
                output,
                "{}let {} = tokio::spawn(async move {{ /* {} agent loop */ }});",
                indent_str, agent_name, type_name
            ).unwrap();
        }

        // Phase 46: Send message to agent
        Stmt::SendMessage { message, destination } => {
            let msg_str = codegen_expr(message, interner, synced_vars);
            let dest_str = codegen_expr(destination, interner, synced_vars);
            writeln!(
                output,
                "{}{}.send({}).await.expect(\"Failed to send message\");",
                indent_str, dest_str, msg_str
            ).unwrap();
        }

        // Phase 46: Await response from agent
        Stmt::AwaitMessage { source, into } => {
            let src_str = codegen_expr(source, interner, synced_vars);
            let var_name = interner.resolve(*into);
            writeln!(
                output,
                "{}let {} = {}.recv().await.expect(\"Failed to receive message\");",
                indent_str, var_name, src_str
            ).unwrap();
        }

        // Phase 49: Merge CRDT state
        Stmt::MergeCrdt { source, target } => {
            let src_str = codegen_expr(source, interner, synced_vars);
            let tgt_str = codegen_expr(target, interner, synced_vars);
            writeln!(
                output,
                "{}{}.merge(&{});",
                indent_str, tgt_str, src_str
            ).unwrap();
        }

        // Phase 49: Increment GCounter
        // Phase 52: If object is synced, wrap in .mutate() for auto-publish
        Stmt::IncreaseCrdt { object, field, amount } => {
            let field_name = interner.resolve(*field);
            let amount_str = codegen_expr(amount, interner, synced_vars);

            // Check if the root object is synced
            let root_sym = get_root_identifier(object);
            if let Some(sym) = root_sym {
                if synced_vars.contains(&sym) {
                    // Synced: use .mutate() for auto-publish
                    let obj_name = interner.resolve(sym);
                    writeln!(
                        output,
                        "{}{}.mutate(|inner| inner.{}.increment({} as u64)).await;",
                        indent_str, obj_name, field_name, amount_str
                    ).unwrap();
                    return output;
                }
            }

            // Not synced: direct access
            let obj_str = codegen_expr(object, interner, synced_vars);
            writeln!(
                output,
                "{}{}.{}.increment({} as u64);",
                indent_str, obj_str, field_name, amount_str
            ).unwrap();
        }

        // Phase 49b: Decrement PNCounter
        Stmt::DecreaseCrdt { object, field, amount } => {
            let field_name = interner.resolve(*field);
            let amount_str = codegen_expr(amount, interner, synced_vars);

            // Check if the root object is synced
            let root_sym = get_root_identifier(object);
            if let Some(sym) = root_sym {
                if synced_vars.contains(&sym) {
                    // Synced: use .mutate() for auto-publish
                    let obj_name = interner.resolve(sym);
                    writeln!(
                        output,
                        "{}{}.mutate(|inner| inner.{}.decrement({} as u64)).await;",
                        indent_str, obj_name, field_name, amount_str
                    ).unwrap();
                    return output;
                }
            }

            // Not synced: direct access
            let obj_str = codegen_expr(object, interner, synced_vars);
            writeln!(
                output,
                "{}{}.{}.decrement({} as u64);",
                indent_str, obj_str, field_name, amount_str
            ).unwrap();
        }

        // Phase 49b: Append to SharedSequence (RGA)
        Stmt::AppendToSequence { sequence, value } => {
            let seq_str = codegen_expr(sequence, interner, synced_vars);
            let val_str = codegen_expr(value, interner, synced_vars);
            writeln!(
                output,
                "{}{}.append({});",
                indent_str, seq_str, val_str
            ).unwrap();
        }

        // Phase 49b: Resolve MVRegister conflicts
        Stmt::ResolveConflict { object, field, value } => {
            let field_name = interner.resolve(*field);
            let val_str = codegen_expr(value, interner, synced_vars);
            let obj_str = codegen_expr(object, interner, synced_vars);
            writeln!(
                output,
                "{}{}.{}.resolve({});",
                indent_str, obj_str, field_name, val_str
            ).unwrap();
        }
    }

    output
}

/// Phase 52: Extract the root identifier from an expression.
/// For `x.field.subfield`, returns `x`.
fn get_root_identifier(expr: &Expr) -> Option<Symbol> {
    match expr {
        Expr::Identifier(sym) => Some(*sym),
        Expr::FieldAccess { object, .. } => get_root_identifier(object),
        _ => None,
    }
}

pub fn codegen_expr(expr: &Expr, interner: &Interner, synced_vars: &HashSet<Symbol>) -> String {
    match expr {
        Expr::Literal(lit) => codegen_literal(lit, interner),

        Expr::Identifier(sym) => interner.resolve(*sym).to_string(),

        Expr::BinaryOp { op, left, right } => {
            let left_str = codegen_expr(left, interner, synced_vars);
            let right_str = codegen_expr(right, interner, synced_vars);
            // Phase 53: String concatenation requires special handling
            if matches!(op, BinaryOpKind::Concat) {
                return format!("format!(\"{{}}{{}}\", {}, {})", left_str, right_str);
            }
            let op_str = match op {
                BinaryOpKind::Add => "+",
                BinaryOpKind::Subtract => "-",
                BinaryOpKind::Multiply => "*",
                BinaryOpKind::Divide => "/",
                BinaryOpKind::Modulo => "%",
                BinaryOpKind::Eq => "==",
                BinaryOpKind::NotEq => "!=",
                BinaryOpKind::Lt => "<",
                BinaryOpKind::Gt => ">",
                BinaryOpKind::LtEq => "<=",
                BinaryOpKind::GtEq => ">=",
                BinaryOpKind::And => "&&",
                BinaryOpKind::Or => "||",
                BinaryOpKind::Concat => unreachable!(), // Handled above
            };
            format!("({} {} {})", left_str, op_str, right_str)
        }

        Expr::Call { function, args } => {
            let func_name = interner.resolve(*function);
            let args_str: Vec<String> = args.iter().map(|a| codegen_expr(a, interner, synced_vars)).collect();
            format!("{}({})", func_name, args_str.join(", "))
        }

        Expr::Index { collection, index } => {
            let coll_str = codegen_expr(collection, interner, synced_vars);
            let index_str = codegen_expr(index, interner, synced_vars);
            // Phase 57: Polymorphic indexing via trait
            format!("LogosIndex::logos_get(&{}, {})", coll_str, index_str)
        }

        Expr::Slice { collection, start, end } => {
            let coll_str = codegen_expr(collection, interner, synced_vars);
            let start_str = codegen_expr(start, interner, synced_vars);
            let end_str = codegen_expr(end, interner, synced_vars);
            // Phase 43D: 1-indexed inclusive to 0-indexed exclusive
            // "items 1 through 3" → &items[0..3] (elements at indices 0, 1, 2)
            format!("&{}[({} - 1) as usize..{} as usize]", coll_str, start_str, end_str)
        }

        Expr::Copy { expr } => {
            let expr_str = codegen_expr(expr, interner, synced_vars);
            // Phase 43D: Explicit clone to owned Vec
            format!("{}.to_vec()", expr_str)
        }

        Expr::Length { collection } => {
            let coll_str = codegen_expr(collection, interner, synced_vars);
            // Phase 43D: Collection length - cast to i64 for LOGOS integer semantics
            format!("({}.len() as i64)", coll_str)
        }

        Expr::Contains { collection, value } => {
            let coll_str = codegen_expr(collection, interner, synced_vars);
            let val_str = codegen_expr(value, interner, synced_vars);
            // Use LogosContains trait for unified contains across List, Set, Map, Text
            format!("{}.logos_contains(&{})", coll_str, val_str)
        }

        Expr::Union { left, right } => {
            let left_str = codegen_expr(left, interner, synced_vars);
            let right_str = codegen_expr(right, interner, synced_vars);
            format!("{}.union(&{}).cloned().collect::<std::collections::HashSet<_>>()", left_str, right_str)
        }

        Expr::Intersection { left, right } => {
            let left_str = codegen_expr(left, interner, synced_vars);
            let right_str = codegen_expr(right, interner, synced_vars);
            format!("{}.intersection(&{}).cloned().collect::<std::collections::HashSet<_>>()", left_str, right_str)
        }

        // Phase 48: Sipping Protocol expressions
        Expr::ManifestOf { zone } => {
            let zone_str = codegen_expr(zone, interner, synced_vars);
            format!("logos_core::network::FileSipper::from_zone(&{}).manifest()", zone_str)
        }

        Expr::ChunkAt { index, zone } => {
            let zone_str = codegen_expr(zone, interner, synced_vars);
            let index_str = codegen_expr(index, interner, synced_vars);
            // LOGOS uses 1-indexed, Rust uses 0-indexed
            format!("logos_core::network::FileSipper::from_zone(&{}).get_chunk(({} - 1) as usize)", zone_str, index_str)
        }

        Expr::List(ref items) => {
            let item_strs: Vec<String> = items.iter()
                .map(|i| codegen_expr(i, interner, synced_vars))
                .collect();
            format!("vec![{}]", item_strs.join(", "))
        }

        Expr::Tuple(ref items) => {
            let item_strs: Vec<String> = items.iter()
                .map(|i| format!("Value::from({})", codegen_expr(i, interner, synced_vars)))
                .collect();
            // Tuples as Vec<Value> for heterogeneous support
            format!("vec![{}]", item_strs.join(", "))
        }

        Expr::Range { start, end } => {
            let start_str = codegen_expr(start, interner, synced_vars);
            let end_str = codegen_expr(end, interner, synced_vars);
            format!("({}..={})", start_str, end_str)
        }

        Expr::FieldAccess { object, field } => {
            let field_name = interner.resolve(*field);

            // Phase 52: Check if root object is synced - use .get().await
            let root_sym = get_root_identifier(object);
            if let Some(sym) = root_sym {
                if synced_vars.contains(&sym) {
                    let obj_name = interner.resolve(sym);
                    return format!("{}.get().await.{}", obj_name, field_name);
                }
            }

            let obj_str = codegen_expr(object, interner, synced_vars);
            format!("{}.{}", obj_str, field_name)
        }

        Expr::New { type_name, type_args, init_fields } => {
            let type_str = interner.resolve(*type_name);
            if !init_fields.is_empty() {
                // Struct initialization with fields: Point { x: 10, y: 20, ..Default::default() }
                // Always add ..Default::default() to handle partial initialization (e.g., CRDT fields)
                let fields_str = init_fields.iter()
                    .map(|(name, value)| {
                        let field_name = interner.resolve(*name);
                        let value_str = codegen_expr(value, interner, synced_vars);
                        format!("{}: {}", field_name, value_str)
                    })
                    .collect::<Vec<_>>()
                    .join(", ");
                format!("{} {{ {}, ..Default::default() }}", type_str, fields_str)
            } else if type_args.is_empty() {
                format!("{}::default()", type_str)
            } else {
                // Phase 34: Turbofish syntax for generic instantiation
                let args_str = type_args.iter()
                    .map(|s| map_type_to_rust(interner.resolve(*s)))
                    .collect::<Vec<_>>()
                    .join(", ");
                format!("{}::<{}>::default()", type_str, args_str)
            }
        }

        Expr::NewVariant { enum_name, variant, fields } => {
            let enum_str = interner.resolve(*enum_name);
            let variant_str = interner.resolve(*variant);
            if fields.is_empty() {
                // Unit variant: Shape::Point
                format!("{}::{}", enum_str, variant_str)
            } else {
                // Struct variant: Shape::Circle { radius: 10 }
                let fields_str: Vec<String> = fields.iter()
                    .map(|(field_name, value)| {
                        let name = interner.resolve(*field_name);
                        let val = codegen_expr(value, interner, synced_vars);
                        format!("{}: {}", name, val)
                    })
                    .collect();
                format!("{}::{} {{ {} }}", enum_str, variant_str, fields_str.join(", "))
            }
        }
    }
}

fn codegen_literal(lit: &Literal, interner: &Interner) -> String {
    match lit {
        Literal::Number(n) => n.to_string(),
        Literal::Float(f) => format!("{}f64", f),
        // String literals are converted to String for consistent Text type handling
        Literal::Text(sym) => format!("String::from(\"{}\")", interner.resolve(*sym)),
        Literal::Boolean(b) => b.to_string(),
        Literal::Nothing => "()".to_string(),
        // Character literals
        Literal::Char(c) => {
            // Handle escape sequences for special characters
            match c {
                '\n' => "'\\n'".to_string(),
                '\t' => "'\\t'".to_string(),
                '\r' => "'\\r'".to_string(),
                '\\' => "'\\\\'".to_string(),
                '\'' => "'\\''".to_string(),
                '\0' => "'\\0'".to_string(),
                c => format!("'{}'", c),
            }
        }
    }
}

/// Converts a LogicExpr to a Rust boolean expression for debug_assert!().
/// Uses RustFormatter to unify all logic-to-Rust translation.
pub fn codegen_assertion(expr: &LogicExpr, interner: &Interner) -> String {
    let mut registry = SymbolRegistry::new();
    let formatter = RustFormatter;
    let mut buf = String::new();

    match expr.write_logic(&mut buf, &mut registry, interner, &formatter) {
        Ok(_) => buf,
        Err(_) => "/* error generating assertion */ false".to_string(),
    }
}

pub fn codegen_term(term: &Term, interner: &Interner) -> String {
    match term {
        Term::Constant(sym) => interner.resolve(*sym).to_string(),
        Term::Variable(sym) => interner.resolve(*sym).to_string(),
        Term::Value { kind, .. } => match kind {
            NumberKind::Integer(n) => n.to_string(),
            NumberKind::Real(f) => f.to_string(),
            NumberKind::Symbolic(sym) => interner.resolve(*sym).to_string(),
        },
        Term::Function(name, args) => {
            let args_str: Vec<String> = args.iter()
                .map(|a| codegen_term(a, interner))
                .collect();
            format!("{}({})", interner.resolve(*name), args_str.join(", "))
        }
        Term::Possessed { possessor, possessed } => {
            let poss_str = codegen_term(possessor, interner);
            format!("{}.{}", poss_str, interner.resolve(*possessed))
        }
        Term::Group(members) => {
            let members_str: Vec<String> = members.iter()
                .map(|m| codegen_term(m, interner))
                .collect();
            format!("({})", members_str.join(", "))
        }
        _ => "/* unsupported Term */".to_string(),
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_literal_number() {
        let interner = Interner::new();
        let synced_vars = HashSet::new();
        let expr = Expr::Literal(Literal::Number(42));
        assert_eq!(codegen_expr(&expr, &interner, &synced_vars), "42");
    }

    #[test]
    fn test_literal_boolean() {
        let interner = Interner::new();
        let synced_vars = HashSet::new();
        assert_eq!(codegen_expr(&Expr::Literal(Literal::Boolean(true)), &interner, &synced_vars), "true");
        assert_eq!(codegen_expr(&Expr::Literal(Literal::Boolean(false)), &interner, &synced_vars), "false");
    }

    #[test]
    fn test_literal_nothing() {
        let interner = Interner::new();
        let synced_vars = HashSet::new();
        assert_eq!(codegen_expr(&Expr::Literal(Literal::Nothing), &interner, &synced_vars), "()");
    }
}

```

---

### Compilation Orchestration

**File:** `src/compile.rs`

High-level compilation pipeline. compile_to_rust() coordinates lexer→parser→codegen for imperative programs. compile_to_rust_verified() adds Z3 verification pass for Assert statements (requires verification feature). Manages parser mode switching between declarative and imperative contexts. Handles ## Main and ## Definition block routing.

```rust
//! LOGOS Compilation Pipeline
//!
//! This module provides the end-to-end compilation pipeline:
//! LOGOS source → Rust source → executable

use std::fs;
use std::io::Write;
use std::path::Path;
use std::process::Command;

// Embed runtime at compile time
const LOGOS_CORE_TOML: &str = include_str!("../logos_core/Cargo.toml");
const LOGOS_CORE_LIB: &str = include_str!("../logos_core/src/lib.rs");
const LOGOS_CORE_TYPES: &str = include_str!("../logos_core/src/types.rs");
const LOGOS_CORE_IO: &str = include_str!("../logos_core/src/io.rs");
// Phase 38: Standard library modules
const LOGOS_CORE_FILE: &str = include_str!("../logos_core/src/file.rs");
const LOGOS_CORE_TIME: &str = include_str!("../logos_core/src/time.rs");
const LOGOS_CORE_RANDOM: &str = include_str!("../logos_core/src/random.rs");
const LOGOS_CORE_ENV: &str = include_str!("../logos_core/src/env.rs");
// Phase 8.5: Zone-based memory management
const LOGOS_CORE_MEMORY: &str = include_str!("../logos_core/src/memory.rs");

use crate::analysis::{DiscoveryPass, EscapeChecker, OwnershipChecker, PolicyRegistry};
use crate::arena::Arena;
use crate::arena_ctx::AstContext;
use crate::ast::{Expr, Stmt, TypeExpr};
use crate::codegen::codegen_program;
use crate::context::DiscourseContext;
use crate::diagnostic::{parse_rustc_json, translate_diagnostics, LogosError};
use crate::error::ParseError;
use crate::intern::Interner;
use crate::lexer::Lexer;
use crate::parser::Parser;
use crate::sourcemap::SourceMap;

/// Compile LOGOS source to Rust source code.
pub fn compile_to_rust(source: &str) -> Result<String, ParseError> {
    let mut interner = Interner::new();
    let mut lexer = Lexer::new(source, &mut interner);
    let tokens = lexer.tokenize();

    // Pass 1: Discovery - scan for type definitions and policies
    let (type_registry, policy_registry) = {
        let mut discovery = DiscoveryPass::new(&tokens, &mut interner);
        let result = discovery.run_full();
        (result.types, result.policies)
    };
    // Clone for codegen (parser takes ownership)
    let codegen_registry = type_registry.clone();
    let codegen_policies = policy_registry.clone();

    let mut ctx = DiscourseContext::new();
    let expr_arena = Arena::new();
    let term_arena = Arena::new();
    let np_arena = Arena::new();
    let sym_arena = Arena::new();
    let role_arena = Arena::new();
    let pp_arena = Arena::new();
    let stmt_arena: Arena<Stmt> = Arena::new();
    let imperative_expr_arena: Arena<Expr> = Arena::new();
    let type_expr_arena: Arena<TypeExpr> = Arena::new();

    let ast_ctx = AstContext::with_types(
        &expr_arena,
        &term_arena,
        &np_arena,
        &sym_arena,
        &role_arena,
        &pp_arena,
        &stmt_arena,
        &imperative_expr_arena,
        &type_expr_arena,
    );

    // Pass 2: Parse with type context
    let mut parser = Parser::with_types(tokens, &mut ctx, &mut interner, ast_ctx, type_registry);
    // Note: Don't call process_block_headers() - parse_program handles blocks itself

    let stmts = parser.parse_program()?;

    // Pass 3: Escape analysis - check for zone escape violations
    // This catches obvious cases like returning zone-local variables
    let mut escape_checker = EscapeChecker::new(&interner);
    escape_checker.check_program(&stmts).map_err(|e| {
        // Convert EscapeError to ParseError for now
        // The error message is already Socratic from EscapeChecker
        ParseError {
            kind: crate::error::ParseErrorKind::Custom(e.to_string()),
            span: e.span,
        }
    })?;

    // Note: Static verification (Phase 42) is available when the `verification`
    // feature is enabled, but must be explicitly invoked via compile_to_rust_verified().

    let rust_code = codegen_program(&stmts, &codegen_registry, &codegen_policies, &interner);

    Ok(rust_code)
}

/// Compile LOGOS source to Rust with ownership checking enabled.
///
/// This runs the lightweight ownership analysis pass (Phase 45) that catches
/// use-after-move errors with control flow awareness in milliseconds.
/// Use this with `--check` flag for instant feedback on ownership errors.
pub fn compile_to_rust_checked(source: &str) -> Result<String, ParseError> {
    let mut interner = Interner::new();
    let mut lexer = Lexer::new(source, &mut interner);
    let tokens = lexer.tokenize();

    // Pass 1: Discovery - scan for type definitions and policies
    let (type_registry, policy_registry) = {
        let mut discovery = DiscoveryPass::new(&tokens, &mut interner);
        let result = discovery.run_full();
        (result.types, result.policies)
    };
    // Clone for codegen (parser takes ownership)
    let codegen_registry = type_registry.clone();
    let codegen_policies = policy_registry.clone();

    let mut ctx = DiscourseContext::new();
    let expr_arena = Arena::new();
    let term_arena = Arena::new();
    let np_arena = Arena::new();
    let sym_arena = Arena::new();
    let role_arena = Arena::new();
    let pp_arena = Arena::new();
    let stmt_arena: Arena<Stmt> = Arena::new();
    let imperative_expr_arena: Arena<Expr> = Arena::new();
    let type_expr_arena: Arena<TypeExpr> = Arena::new();

    let ast_ctx = AstContext::with_types(
        &expr_arena,
        &term_arena,
        &np_arena,
        &sym_arena,
        &role_arena,
        &pp_arena,
        &stmt_arena,
        &imperative_expr_arena,
        &type_expr_arena,
    );

    // Pass 2: Parse with type context
    let mut parser = Parser::with_types(tokens, &mut ctx, &mut interner, ast_ctx, type_registry);
    let stmts = parser.parse_program()?;

    // Pass 3: Escape analysis
    let mut escape_checker = EscapeChecker::new(&interner);
    escape_checker.check_program(&stmts).map_err(|e| {
        ParseError {
            kind: crate::error::ParseErrorKind::Custom(e.to_string()),
            span: e.span,
        }
    })?;

    // Pass 4: Ownership analysis (Phase 45)
    // Catches use-after-move errors with control flow awareness
    let mut ownership_checker = OwnershipChecker::new(&interner);
    ownership_checker.check_program(&stmts).map_err(|e| {
        ParseError {
            kind: crate::error::ParseErrorKind::Custom(e.to_string()),
            span: e.span,
        }
    })?;

    let rust_code = codegen_program(&stmts, &codegen_registry, &codegen_policies, &interner);

    Ok(rust_code)
}

/// Compile LOGOS source to Rust source code with static verification.
///
/// This runs the Z3-based verifier on Assert statements before codegen.
/// Requires the `verification` feature to be enabled.
#[cfg(feature = "verification")]
pub fn compile_to_rust_verified(source: &str) -> Result<String, ParseError> {
    use crate::verification::VerificationPass;

    let mut interner = Interner::new();
    let mut lexer = Lexer::new(source, &mut interner);
    let tokens = lexer.tokenize();

    // Pass 1: Discovery - scan for type definitions and policies
    let (type_registry, policy_registry) = {
        let mut discovery = DiscoveryPass::new(&tokens, &mut interner);
        let result = discovery.run_full();
        (result.types, result.policies)
    };
    // Clone for codegen (parser takes ownership)
    let codegen_registry = type_registry.clone();
    let codegen_policies = policy_registry.clone();

    let mut ctx = DiscourseContext::new();
    let expr_arena = Arena::new();
    let term_arena = Arena::new();
    let np_arena = Arena::new();
    let sym_arena = Arena::new();
    let role_arena = Arena::new();
    let pp_arena = Arena::new();
    let stmt_arena: Arena<Stmt> = Arena::new();
    let imperative_expr_arena: Arena<Expr> = Arena::new();
    let type_expr_arena: Arena<TypeExpr> = Arena::new();

    let ast_ctx = AstContext::with_types(
        &expr_arena,
        &term_arena,
        &np_arena,
        &sym_arena,
        &role_arena,
        &pp_arena,
        &stmt_arena,
        &imperative_expr_arena,
        &type_expr_arena,
    );

    // Pass 2: Parse with type context
    let mut parser = Parser::with_types(tokens, &mut ctx, &mut interner, ast_ctx, type_registry);
    let stmts = parser.parse_program()?;

    // Pass 3: Escape analysis
    let mut escape_checker = EscapeChecker::new(&interner);
    escape_checker.check_program(&stmts).map_err(|e| {
        ParseError {
            kind: crate::error::ParseErrorKind::Custom(e.to_string()),
            span: e.span,
        }
    })?;

    // Pass 4: Static verification
    let mut verifier = VerificationPass::new(&interner);
    verifier.verify_program(&stmts).map_err(|e| {
        ParseError {
            kind: crate::error::ParseErrorKind::Custom(format!(
                "Verification Failed:\n\n{}",
                e
            )),
            span: crate::token::Span::default(),
        }
    })?;

    let rust_code = codegen_program(&stmts, &codegen_registry, &codegen_policies, &interner);

    Ok(rust_code)
}

/// Compile LOGOS source and write output to a directory.
/// Creates a Cargo project with logos_core dependency.
pub fn compile_to_dir(source: &str, output_dir: &Path) -> Result<(), CompileError> {
    let rust_code = compile_to_rust(source).map_err(CompileError::Parse)?;

    // Create output directory structure
    let src_dir = output_dir.join("src");
    fs::create_dir_all(&src_dir).map_err(|e| CompileError::Io(e.to_string()))?;

    // Write main.rs with logos_core import
    let main_rs = format!(
        "use logos_core::prelude::*;\n\n{}",
        rust_code
    );
    let main_path = src_dir.join("main.rs");
    let mut file = fs::File::create(&main_path).map_err(|e| CompileError::Io(e.to_string()))?;
    file.write_all(main_rs.as_bytes()).map_err(|e| CompileError::Io(e.to_string()))?;

    // Write Cargo.toml
    let cargo_toml = format!(
        r#"[package]
name = "logos_output"
version = "0.1.0"
edition = "2021"

[dependencies]
logos_core = {{ path = "./logos_core" }}
"#
    );
    let cargo_path = output_dir.join("Cargo.toml");
    let mut file = fs::File::create(&cargo_path).map_err(|e| CompileError::Io(e.to_string()))?;
    file.write_all(cargo_toml.as_bytes()).map_err(|e| CompileError::Io(e.to_string()))?;

    // Copy logos_core to output directory
    copy_logos_core(output_dir)?;

    Ok(())
}

/// Copy the logos_core crate to the output directory.
/// This recursively copies the entire crate including all modules.
pub fn copy_logos_core(output_dir: &Path) -> Result<(), CompileError> {
    let dest_dir = output_dir.join("logos_core");

    // Find the logos_core source directory relative to the CARGO_MANIFEST_DIR
    // or use the embedded constants as fallback
    let source_dir = std::env::var("CARGO_MANIFEST_DIR")
        .map(|d| Path::new(&d).join("logos_core"))
        .ok()
        .filter(|p| p.exists());

    if let Some(src) = source_dir {
        // Recursively copy the actual logos_core directory
        copy_dir_recursive(&src, &dest_dir)?;
    } else {
        // Fallback to embedded files for distribution builds
        let src_dir = dest_dir.join("src");
        fs::create_dir_all(&src_dir).map_err(|e| CompileError::Io(e.to_string()))?;

        fs::write(dest_dir.join("Cargo.toml"), LOGOS_CORE_TOML)
            .map_err(|e| CompileError::Io(e.to_string()))?;
        fs::write(src_dir.join("lib.rs"), LOGOS_CORE_LIB)
            .map_err(|e| CompileError::Io(e.to_string()))?;
        fs::write(src_dir.join("types.rs"), LOGOS_CORE_TYPES)
            .map_err(|e| CompileError::Io(e.to_string()))?;
        fs::write(src_dir.join("io.rs"), LOGOS_CORE_IO)
            .map_err(|e| CompileError::Io(e.to_string()))?;
        fs::write(src_dir.join("file.rs"), LOGOS_CORE_FILE)
            .map_err(|e| CompileError::Io(e.to_string()))?;
        fs::write(src_dir.join("time.rs"), LOGOS_CORE_TIME)
            .map_err(|e| CompileError::Io(e.to_string()))?;
        fs::write(src_dir.join("random.rs"), LOGOS_CORE_RANDOM)
            .map_err(|e| CompileError::Io(e.to_string()))?;
        fs::write(src_dir.join("env.rs"), LOGOS_CORE_ENV)
            .map_err(|e| CompileError::Io(e.to_string()))?;
        fs::write(src_dir.join("memory.rs"), LOGOS_CORE_MEMORY)
            .map_err(|e| CompileError::Io(e.to_string()))?;
    }

    Ok(())
}

/// Recursively copy a directory.
fn copy_dir_recursive(src: &Path, dst: &Path) -> Result<(), CompileError> {
    fs::create_dir_all(dst).map_err(|e| CompileError::Io(e.to_string()))?;

    for entry in fs::read_dir(src).map_err(|e| CompileError::Io(e.to_string()))? {
        let entry = entry.map_err(|e| CompileError::Io(e.to_string()))?;
        let src_path = entry.path();
        let file_name = entry.file_name();
        let dst_path = dst.join(&file_name);

        // Skip target directory and other build artifacts
        if file_name == "target" || file_name == ".git" {
            continue;
        }

        if src_path.is_dir() {
            copy_dir_recursive(&src_path, &dst_path)?;
        } else if file_name == "Cargo.toml" {
            // Special handling for Cargo.toml: remove [workspace] line
            // which can interfere with nested crate dependencies
            let content = fs::read_to_string(&src_path)
                .map_err(|e| CompileError::Io(e.to_string()))?;
            let filtered: String = content
                .lines()
                .filter(|line| !line.trim().starts_with("[workspace]"))
                .collect::<Vec<_>>()
                .join("\n");
            fs::write(&dst_path, filtered).map_err(|e| CompileError::Io(e.to_string()))?;
        } else {
            fs::copy(&src_path, &dst_path).map_err(|e| CompileError::Io(e.to_string()))?;
        }
    }

    Ok(())
}

/// Compile and run a LOGOS program.
pub fn compile_and_run(source: &str, output_dir: &Path) -> Result<String, CompileError> {
    compile_to_dir(source, output_dir)?;

    // Run cargo build with JSON message format for structured error parsing
    let build_output = Command::new("cargo")
        .arg("build")
        .arg("--message-format=json")
        .current_dir(output_dir)
        .output()
        .map_err(|e| CompileError::Io(e.to_string()))?;

    if !build_output.status.success() {
        let stderr = String::from_utf8_lossy(&build_output.stderr);
        let stdout = String::from_utf8_lossy(&build_output.stdout);

        // Try to parse JSON diagnostics and translate them
        let diagnostics = parse_rustc_json(&stdout);

        if !diagnostics.is_empty() {
            // Create a basic source map with the LOGOS source
            let source_map = SourceMap::new(source.to_string());
            let interner = Interner::new();

            if let Some(logos_error) = translate_diagnostics(&diagnostics, &source_map, &interner) {
                return Err(CompileError::Ownership(logos_error));
            }
        }

        // Fallback to raw error if translation fails
        return Err(CompileError::Build(stderr.to_string()));
    }

    // Run the compiled program
    let run_output = Command::new("cargo")
        .arg("run")
        .arg("--quiet")
        .current_dir(output_dir)
        .output()
        .map_err(|e| CompileError::Io(e.to_string()))?;

    if !run_output.status.success() {
        let stderr = String::from_utf8_lossy(&run_output.stderr);
        return Err(CompileError::Runtime(stderr.to_string()));
    }

    let stdout = String::from_utf8_lossy(&run_output.stdout);
    Ok(stdout.to_string())
}

/// Compile a LOGOS source file.
/// For single-file compilation without dependencies.
pub fn compile_file(path: &Path) -> Result<String, CompileError> {
    let source = fs::read_to_string(path).map_err(|e| CompileError::Io(e.to_string()))?;
    compile_to_rust(&source).map_err(CompileError::Parse)
}

/// Phase 36: Compile a LOGOS project with dependencies.
/// Scans the Abstract for [Alias](URI) links and loads dependencies recursively.
pub fn compile_project(path: &Path) -> Result<String, CompileError> {
    use crate::analysis::discover_with_imports;
    use crate::project::Loader;

    let source = fs::read_to_string(path).map_err(|e| CompileError::Io(e.to_string()))?;
    let root_dir = path.parent().unwrap_or(Path::new(".")).to_path_buf();

    let mut interner = Interner::new();
    let mut loader = Loader::new(root_dir);

    // Pass 1: Recursive discovery with imports
    let type_registry = discover_with_imports(path, &source, &mut loader, &mut interner)
        .map_err(|e| CompileError::Io(e))?;
    let codegen_registry = type_registry.clone();

    // Phase 50: Also discover policies from the main file
    // (discover_with_imports doesn't handle policies yet, so we do a separate pass)
    let mut lexer = Lexer::new(&source, &mut interner);
    let tokens = lexer.tokenize();
    let policy_registry = {
        let mut discovery = DiscoveryPass::new(&tokens, &mut interner);
        discovery.run_full().policies
    };
    let codegen_policies = policy_registry.clone();

    // Re-tokenize for parsing (interner may have been modified)
    let mut lexer = Lexer::new(&source, &mut interner);
    let tokens = lexer.tokenize();

    let mut ctx = DiscourseContext::new();
    let expr_arena = Arena::new();
    let term_arena = Arena::new();
    let np_arena = Arena::new();
    let sym_arena = Arena::new();
    let role_arena = Arena::new();
    let pp_arena = Arena::new();
    let stmt_arena: Arena<Stmt> = Arena::new();
    let imperative_expr_arena: Arena<Expr> = Arena::new();
    let type_expr_arena: Arena<TypeExpr> = Arena::new();

    let ast_ctx = AstContext::with_types(
        &expr_arena,
        &term_arena,
        &np_arena,
        &sym_arena,
        &role_arena,
        &pp_arena,
        &stmt_arena,
        &imperative_expr_arena,
        &type_expr_arena,
    );

    // Pass 2: Parse with type context (includes imported types)
    let mut parser = Parser::with_types(tokens, &mut ctx, &mut interner, ast_ctx, type_registry);
    let stmts = parser.parse_program().map_err(CompileError::Parse)?;
    let rust_code = codegen_program(&stmts, &codegen_registry, &codegen_policies, &interner);

    Ok(rust_code)
}

/// Errors that can occur during compilation.
#[derive(Debug)]
pub enum CompileError {
    Parse(ParseError),
    Io(String),
    Build(String),
    Runtime(String),
    /// Translated ownership/borrow checker error with friendly LOGOS message
    Ownership(LogosError),
}

impl std::fmt::Display for CompileError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            CompileError::Parse(e) => write!(f, "Parse error: {:?}", e),
            CompileError::Io(e) => write!(f, "IO error: {}", e),
            CompileError::Build(e) => write!(f, "Build error: {}", e),
            CompileError::Runtime(e) => write!(f, "Runtime error: {}", e),
            CompileError::Ownership(e) => write!(f, "{}", e),
        }
    }
}

impl std::error::Error for CompileError {}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_compile_let_statement() {
        let source = "## Main\nLet x be 5.";
        let result = compile_to_rust(source);
        assert!(result.is_ok(), "Should compile: {:?}", result);
        let rust = result.unwrap();
        assert!(rust.contains("fn main()"));
        assert!(rust.contains("let x = 5;"));
    }

    #[test]
    fn test_compile_return_statement() {
        let source = "## Main\nReturn 42.";
        let result = compile_to_rust(source);
        assert!(result.is_ok(), "Should compile: {:?}", result);
        let rust = result.unwrap();
        assert!(rust.contains("return 42;"));
    }
}

```

---

### Scope Management

**File:** `src/scope.rs`

Variable scope tracking for imperative blocks. ScopeStack manages nested lexical scopes with push/pop. resolve_identifier() finds variable bindings respecting shadowing. Tracks ownership state (owned/moved/borrowed) for each binding.

```rust
use std::collections::HashMap;
use crate::context::OwnershipState;

#[derive(Debug, Clone)]
pub struct ScopeEntry {
    pub symbol: String,
    pub ownership: OwnershipState,
}

impl ScopeEntry {
    pub fn variable(name: &str) -> Self {
        Self {
            symbol: name.to_string(),
            ownership: OwnershipState::Owned,
        }
    }
}

#[derive(Debug, Default)]
pub struct ScopeStack {
    scopes: Vec<HashMap<String, ScopeEntry>>,
}

impl ScopeStack {
    pub fn new() -> Self {
        Self::default()
    }

    pub fn push_scope(&mut self) {
        self.scopes.push(HashMap::new());
    }

    pub fn pop_scope(&mut self) {
        self.scopes.pop();
    }

    pub fn bind(&mut self, name: &str, entry: ScopeEntry) {
        if let Some(scope) = self.scopes.last_mut() {
            scope.insert(name.to_string(), entry);
        }
    }

    pub fn lookup(&self, name: &str) -> Option<&ScopeEntry> {
        for scope in self.scopes.iter().rev() {
            if let Some(entry) = scope.get(name) {
                return Some(entry);
            }
        }
        None
    }

    pub fn lookup_mut(&mut self, name: &str) -> Option<&mut ScopeEntry> {
        for scope in self.scopes.iter_mut().rev() {
            if let Some(entry) = scope.get_mut(name) {
                return Some(entry);
            }
        }
        None
    }
}

```

---

### CLI Interface

**File:** `src/cli.rs`

Command-line interface for LOGOS build tool. Implements largo new/init/build/run/check commands via clap. Feature-gated behind 'cli' feature flag.

```rust
//! Phase 37/39: LOGOS CLI (largo)
//!
//! Command-line interface for the LOGOS build system and package registry.

use clap::{Parser, Subcommand};
use std::env;
use std::fs;
use std::io::{self, Write};
use std::path::PathBuf;

use crate::compile::compile_project;
use crate::project::build::{self, find_project_root, BuildConfig};
use crate::project::manifest::Manifest;
use crate::project::credentials::{Credentials, get_token};
use crate::project::registry::{
    RegistryClient, PublishMetadata, create_tarball, is_git_dirty,
};

#[derive(Parser)]
#[command(name = "largo")]
#[command(about = "The LOGOS build tool", long_about = None)]
#[command(version)]
pub struct Cli {
    #[command(subcommand)]
    pub command: Commands,
}

#[derive(Subcommand)]
pub enum Commands {
    /// Create a new LOGOS project
    New {
        /// Project name
        name: String,
    },
    /// Initialize a LOGOS project in the current directory
    Init {
        /// Project name (defaults to directory name)
        #[arg(long)]
        name: Option<String>,
    },
    /// Build the current project
    Build {
        /// Build in release mode
        #[arg(long, short)]
        release: bool,

        /// Run Z3 static verification (requires Pro+ license)
        #[arg(long)]
        verify: bool,

        /// License key for verification (or set LOGOS_LICENSE env var)
        #[arg(long)]
        license: Option<String>,
    },
    /// Verify the project without building (requires Pro+ license)
    Verify {
        /// License key (or set LOGOS_LICENSE env var)
        #[arg(long)]
        license: Option<String>,
    },
    /// Build and run the current project
    Run {
        /// Build in release mode
        #[arg(long, short)]
        release: bool,
    },
    /// Check the project for errors without building
    Check,

    // Phase 39: Package Registry Commands
    /// Publish the package to the registry
    Publish {
        /// Registry URL (defaults to registry.logicaffeine.com)
        #[arg(long)]
        registry: Option<String>,

        /// Perform all checks without actually publishing
        #[arg(long)]
        dry_run: bool,

        /// Allow publishing with uncommitted changes
        #[arg(long)]
        allow_dirty: bool,
    },
    /// Log in to the package registry
    Login {
        /// Registry URL
        #[arg(long)]
        registry: Option<String>,

        /// Token to store (reads from stdin if not provided)
        #[arg(long)]
        token: Option<String>,
    },
    /// Log out from the package registry
    Logout {
        /// Registry URL
        #[arg(long)]
        registry: Option<String>,
    },
}

/// Entry point for the CLI
pub fn run_cli() -> Result<(), Box<dyn std::error::Error>> {
    let cli = Cli::parse();

    match cli.command {
        Commands::New { name } => cmd_new(&name),
        Commands::Init { name } => cmd_init(name.as_deref()),
        Commands::Build { release, verify, license } => cmd_build(release, verify, license),
        Commands::Run { release } => cmd_run(release),
        Commands::Check => cmd_check(),
        Commands::Verify { license } => cmd_verify(license),
        Commands::Publish { registry, dry_run, allow_dirty } => {
            cmd_publish(registry.as_deref(), dry_run, allow_dirty)
        }
        Commands::Login { registry, token } => cmd_login(registry.as_deref(), token),
        Commands::Logout { registry } => cmd_logout(registry.as_deref()),
    }
}

fn cmd_new(name: &str) -> Result<(), Box<dyn std::error::Error>> {
    let project_dir = PathBuf::from(name);

    if project_dir.exists() {
        return Err(format!("Directory '{}' already exists", project_dir.display()).into());
    }

    // Create project structure
    fs::create_dir_all(&project_dir)?;
    fs::create_dir_all(project_dir.join("src"))?;

    // Write Largo.toml
    let manifest = Manifest::new(name);
    fs::write(project_dir.join("Largo.toml"), manifest.to_toml()?)?;

    // Write src/main.lg
    let main_lg = r#"# Main

A simple LOGOS program.

## Main

Show "Hello, world!".
"#;
    fs::write(project_dir.join("src/main.lg"), main_lg)?;

    // Write .gitignore
    fs::write(project_dir.join(".gitignore"), "/target\n")?;

    println!("Created LOGOS project '{}'", name);
    println!("  cd {}", project_dir.display());
    println!("  largo run");

    Ok(())
}

fn cmd_init(name: Option<&str>) -> Result<(), Box<dyn std::error::Error>> {
    let current_dir = env::current_dir()?;
    let project_name = name
        .map(String::from)
        .or_else(|| {
            current_dir
                .file_name()
                .and_then(|n| n.to_str())
                .map(String::from)
        })
        .unwrap_or_else(|| "project".to_string());

    if current_dir.join("Largo.toml").exists() {
        return Err("Largo.toml already exists".into());
    }

    // Create src directory if needed
    fs::create_dir_all(current_dir.join("src"))?;

    // Write Largo.toml
    let manifest = Manifest::new(&project_name);
    fs::write(current_dir.join("Largo.toml"), manifest.to_toml()?)?;

    // Write src/main.lg if it doesn't exist
    let main_path = current_dir.join("src/main.lg");
    if !main_path.exists() {
        let main_lg = r#"# Main

A simple LOGOS program.

## Main

Show "Hello, world!".
"#;
        fs::write(main_path, main_lg)?;
    }

    println!("Initialized LOGOS project '{}'", project_name);

    Ok(())
}

fn cmd_build(
    release: bool,
    verify: bool,
    license: Option<String>,
) -> Result<(), Box<dyn std::error::Error>> {
    let current_dir = env::current_dir()?;
    let project_root =
        find_project_root(&current_dir).ok_or("Not in a LOGOS project (Largo.toml not found)")?;

    // Run verification if requested
    if verify {
        run_verification(&project_root, license.as_deref())?;
    }

    let config = BuildConfig {
        project_dir: project_root,
        release,
    };

    let result = build::build(config)?;

    let mode = if release { "release" } else { "debug" };
    println!("Built {} [{}]", result.binary_path.display(), mode);

    Ok(())
}

fn cmd_verify(license: Option<String>) -> Result<(), Box<dyn std::error::Error>> {
    let current_dir = env::current_dir()?;
    let project_root =
        find_project_root(&current_dir).ok_or("Not in a LOGOS project (Largo.toml not found)")?;

    run_verification(&project_root, license.as_deref())?;
    println!("Verification passed");
    Ok(())
}

#[cfg(feature = "verification")]
fn run_verification(
    project_root: &std::path::Path,
    license: Option<&str>,
) -> Result<(), Box<dyn std::error::Error>> {
    use logos_verification::{LicenseValidator, Verifier};

    // Get license key from argument or environment
    let license_key = license
        .map(String::from)
        .or_else(|| env::var("LOGOS_LICENSE").ok());

    let license_key = license_key.ok_or(
        "Verification requires a license key.\n\
         Use --license <key> or set LOGOS_LICENSE environment variable.\n\
         Get a license at https://logicaffeine.com/pricing",
    )?;

    // Validate license
    println!("Validating license...");
    let validator = LicenseValidator::new();
    let plan = validator.validate(&license_key)?;
    println!("License valid ({})", plan);

    // Load and parse the project
    let manifest = Manifest::load(project_root)?;
    let entry_path = project_root.join(&manifest.package.entry);
    let source = fs::read_to_string(&entry_path)?;

    // For now, just verify that Z3 works
    // TODO: Implement full AST encoding in Phase 2
    println!("Running Z3 verification...");
    let verifier = Verifier::new();

    // Basic smoke test - verify that true is valid
    verifier.check_bool(true)?;

    Ok(())
}

#[cfg(not(feature = "verification"))]
fn run_verification(
    _project_root: &std::path::Path,
    _license: Option<&str>,
) -> Result<(), Box<dyn std::error::Error>> {
    Err("Verification requires the 'verification' feature.\n\
         Rebuild with: cargo build --features verification"
        .into())
}

fn cmd_run(release: bool) -> Result<(), Box<dyn std::error::Error>> {
    let current_dir = env::current_dir()?;
    let project_root =
        find_project_root(&current_dir).ok_or("Not in a LOGOS project (Largo.toml not found)")?;

    let config = BuildConfig {
        project_dir: project_root,
        release,
    };

    let result = build::build(config)?;
    let exit_code = build::run(&result)?;

    if exit_code != 0 {
        std::process::exit(exit_code);
    }

    Ok(())
}

fn cmd_check() -> Result<(), Box<dyn std::error::Error>> {
    let current_dir = env::current_dir()?;
    let project_root =
        find_project_root(&current_dir).ok_or("Not in a LOGOS project (Largo.toml not found)")?;

    let manifest = Manifest::load(&project_root)?;
    let entry_path = project_root.join(&manifest.package.entry);

    // Just compile to Rust without building
    compile_project(&entry_path)?;

    println!("Check passed");
    Ok(())
}

// ============================================================
// Phase 39: Registry Commands
// ============================================================

fn cmd_publish(
    registry: Option<&str>,
    dry_run: bool,
    allow_dirty: bool,
) -> Result<(), Box<dyn std::error::Error>> {
    let current_dir = env::current_dir()?;
    let project_root =
        find_project_root(&current_dir).ok_or("Not in a LOGOS project (Largo.toml not found)")?;

    // Load manifest
    let manifest = Manifest::load(&project_root)?;
    let name = &manifest.package.name;
    let version = &manifest.package.version;

    println!("Packaging {} v{}", name, version);

    // Determine registry URL
    let registry_url = registry.unwrap_or(RegistryClient::default_url());

    // Get authentication token
    let token = get_token(registry_url).ok_or_else(|| {
        format!(
            "No authentication token found for {}.\n\
             Run 'largo login' or set LOGOS_TOKEN environment variable.",
            registry_url
        )
    })?;

    // Verify the package
    let entry_path = project_root.join(&manifest.package.entry);
    if !entry_path.exists() {
        return Err(format!(
            "Entry point '{}' not found",
            manifest.package.entry
        ).into());
    }

    // Check for uncommitted changes
    if !allow_dirty && is_git_dirty(&project_root) {
        return Err(
            "Working directory has uncommitted changes.\n\
             Use --allow-dirty to publish anyway.".into()
        );
    }

    // Create tarball
    println!("Creating package tarball...");
    let tarball = create_tarball(&project_root)?;
    println!("  Package size: {} bytes", tarball.len());

    // Read README if present
    let readme = project_root.join("README.md");
    let readme_content = if readme.exists() {
        fs::read_to_string(&readme).ok()
    } else {
        None
    };

    // Build metadata
    let metadata = PublishMetadata {
        name: name.clone(),
        version: version.clone(),
        description: manifest.package.description.clone(),
        repository: None, // Could add to manifest later
        homepage: None,
        license: None,
        keywords: vec![],
        entry_point: manifest.package.entry.clone(),
        dependencies: manifest
            .dependencies
            .iter()
            .map(|(k, v)| (k.clone(), v.to_string()))
            .collect(),
        readme: readme_content,
    };

    if dry_run {
        println!("\n[dry-run] Would publish to {}", registry_url);
        println!("[dry-run] Package validated successfully");
        return Ok(());
    }

    // Upload to registry
    println!("Uploading to {}...", registry_url);
    let client = RegistryClient::new(registry_url, &token);
    let result = client.publish(name, version, &tarball, &metadata)?;

    println!(
        "\nPublished {} v{} to {}",
        result.package, result.version, registry_url
    );
    println!("  SHA256: {}", result.sha256);

    Ok(())
}

fn cmd_login(
    registry: Option<&str>,
    token: Option<String>,
) -> Result<(), Box<dyn std::error::Error>> {
    let registry_url = registry.unwrap_or(RegistryClient::default_url());

    // Get token from argument or stdin
    let token = match token {
        Some(t) => t,
        None => {
            println!("To get a token, visit: {}/auth/github", registry_url);
            println!("Then generate an API token from your profile.");
            println!();
            print!("Enter token for {}: ", registry_url);
            io::stdout().flush()?;

            let mut line = String::new();
            io::stdin().read_line(&mut line)?;
            line.trim().to_string()
        }
    };

    if token.is_empty() {
        return Err("Token cannot be empty".into());
    }

    // Validate token with registry
    println!("Validating token...");
    let client = RegistryClient::new(registry_url, &token);
    let user_info = client.validate_token()?;

    // Save to credentials file
    let mut creds = Credentials::load().unwrap_or_default();
    creds.set_token(registry_url, &token);
    creds.save()?;

    println!("Logged in as {} to {}", user_info.login, registry_url);

    Ok(())
}

fn cmd_logout(registry: Option<&str>) -> Result<(), Box<dyn std::error::Error>> {
    let registry_url = registry.unwrap_or(RegistryClient::default_url());

    let mut creds = Credentials::load().unwrap_or_default();

    if creds.get_token(registry_url).is_none() {
        println!("Not logged in to {}", registry_url);
        return Ok(());
    }

    creds.remove_token(registry_url);
    creds.save()?;

    println!("Logged out from {}", registry_url);

    Ok(())
}

```

---

### Project Module

**File:** `src/project/mod.rs`

Infrastructure for multi-file LOGOS projects (Phase 36/37/39). Provides module loading from URI schemes (file:, logos:, https:), caching, standard library embedding, manifests, build orchestration, and package registry client.

```rust
//! Phase 36/37/39: Project Module System
//!
//! Provides infrastructure for multi-file LOGOS projects, including:
//! - Module loading from various URI schemes (file:, logos:, https:)
//! - Caching of loaded modules
//! - Standard library embedding
//! - Project manifests and build orchestration (Phase 37)
//! - Package registry client and credentials (Phase 39)

pub mod loader;
#[cfg(feature = "cli")]
pub mod manifest;
#[cfg(feature = "cli")]
pub mod build;
#[cfg(feature = "cli")]
pub mod credentials;
#[cfg(feature = "cli")]
pub mod registry;

pub use loader::{Loader, ModuleSource};
#[cfg(feature = "cli")]
pub use manifest::{Manifest, ManifestError};
#[cfg(feature = "cli")]
pub use build::{build, find_project_root, run, BuildConfig, BuildError, BuildResult};
#[cfg(feature = "cli")]
pub use credentials::{Credentials, get_token as get_registry_token};
#[cfg(feature = "cli")]
pub use registry::{RegistryClient, create_tarball, is_git_dirty};

```

---

### Module Loader

**File:** `src/project/loader.rs`

Phase 36 module loader. Handles resolution from URI schemes: file: (local filesystem), logos: (built-in stdlib), https: (remote registry). Caches loaded modules with cycle detection. ModuleSource stores content and resolved path.

```rust
//! Phase 36: Module Loader
//!
//! Handles resolution and loading of module sources from various URI schemes:
//! - `file:./path.md` - Local filesystem relative to current file
//! - `logos:std` - Built-in standard library (embedded at compile time)
//! - `https://logicaffeine.dev/...` - Remote registry (Phase 37)

use std::collections::HashMap;
use std::fs;
use std::path::{Path, PathBuf};

/// A loaded module's source content and metadata.
#[derive(Debug, Clone)]
pub struct ModuleSource {
    /// The source content of the module
    pub content: String,
    /// The resolved path (for error reporting and relative resolution)
    pub path: PathBuf,
}

/// Module loader that handles multiple URI schemes.
///
/// Caches loaded modules to prevent duplicate loading and supports
/// cycle detection through the cache.
pub struct Loader {
    /// Cache of loaded modules (URI -> ModuleSource)
    cache: HashMap<String, ModuleSource>,
    /// Root directory of the project (for relative path resolution)
    root_path: PathBuf,
}

impl Loader {
    /// Creates a new Loader with the given root path.
    pub fn new(root_path: PathBuf) -> Self {
        Loader {
            cache: HashMap::new(),
            root_path,
        }
    }

    /// Resolves a URI to a module source.
    ///
    /// Supports:
    /// - `file:./path.md` - Local filesystem (relative to base_path)
    /// - `logos:std` - Built-in standard library
    /// - `logos:core` - Built-in core types
    /// - `https://logicaffeine.dev/...` - Remote registry (returns error for now)
    pub fn resolve(&mut self, base_path: &Path, uri: &str) -> Result<&ModuleSource, String> {
        // Normalize the URI for caching
        let cache_key = self.normalize_uri(base_path, uri)?;

        // Check cache first
        if self.cache.contains_key(&cache_key) {
            return Ok(&self.cache[&cache_key]);
        }

        // Load based on scheme
        let source = if uri.starts_with("file:") {
            self.load_file(base_path, uri)?
        } else if uri.starts_with("logos:") {
            self.load_intrinsic(uri)?
        } else if uri.starts_with("https://") || uri.starts_with("http://") {
            self.load_remote(uri)?
        } else {
            // Default to file: scheme if no scheme provided
            self.load_file(base_path, &format!("file:{}", uri))?
        };

        // Cache and return
        self.cache.insert(cache_key.clone(), source);
        Ok(&self.cache[&cache_key])
    }

    /// Normalizes a URI for consistent caching.
    fn normalize_uri(&self, base_path: &Path, uri: &str) -> Result<String, String> {
        if uri.starts_with("file:") {
            let path_str = uri.trim_start_matches("file:");
            let base_dir = base_path.parent().unwrap_or(&self.root_path);
            let resolved = base_dir.join(path_str);
            Ok(format!("file:{}", resolved.display()))
        } else {
            Ok(uri.to_string())
        }
    }

    /// Loads a module from the local filesystem.
    fn load_file(&self, base_path: &Path, uri: &str) -> Result<ModuleSource, String> {
        let path_str = uri.trim_start_matches("file:");

        // Resolve relative to the base file's directory
        let base_dir = base_path.parent().unwrap_or(&self.root_path);
        let resolved_path = base_dir.join(path_str);

        // Security: Check that we're not escaping the root path
        // (Basic check - a real implementation would canonicalize paths)
        let canonical_root = self.root_path.canonicalize()
            .unwrap_or_else(|_| self.root_path.clone());

        // Read the file
        let content = fs::read_to_string(&resolved_path)
            .map_err(|e| format!("Failed to read '{}': {}", resolved_path.display(), e))?;

        // Check if escaping root (after we know the file exists)
        if let Ok(canonical_path) = resolved_path.canonicalize() {
            if !canonical_path.starts_with(&canonical_root) {
                return Err(format!(
                    "Security: Cannot load '{}' - path escapes project root",
                    uri
                ));
            }
        }

        Ok(ModuleSource {
            content,
            path: resolved_path,
        })
    }

    /// Loads a built-in module (embedded at compile time).
    fn load_intrinsic(&self, uri: &str) -> Result<ModuleSource, String> {
        let name = uri.trim_start_matches("logos:");

        match name {
            "std" => Ok(ModuleSource {
                content: include_str!("../../assets/std/std.md").to_string(),
                path: PathBuf::from("logos:std"),
            }),
            "core" => Ok(ModuleSource {
                content: include_str!("../../assets/std/core.md").to_string(),
                path: PathBuf::from("logos:core"),
            }),
            _ => Err(format!("Unknown intrinsic module: '{}'", uri)),
        }
    }

    /// Loads a module from a remote URL (Phase 37).
    fn load_remote(&self, uri: &str) -> Result<ModuleSource, String> {
        // Phase 37: Implement actual HTTP fetching with caching and lockfile
        // For now, return an error directing users to use local imports
        Err(format!(
            "Remote module loading not yet implemented for '{}'. \
             Use 'logos fetch' to download dependencies locally first. \
             (Full remote support coming in Phase 37)",
            uri
        ))
    }

    /// Checks if a module has already been loaded (for cycle detection).
    pub fn is_loaded(&self, uri: &str) -> bool {
        self.cache.contains_key(uri)
    }

    /// Returns all loaded module URIs (for debugging).
    pub fn loaded_modules(&self) -> Vec<&str> {
        self.cache.keys().map(|s| s.as_str()).collect()
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::tempdir;

    #[test]
    fn test_file_scheme_resolution() {
        let temp_dir = tempdir().unwrap();
        let geo_path = temp_dir.path().join("geo.md");
        fs::write(&geo_path, "## Definition\nA Point has:\n    an x, which is Int.\n").unwrap();

        let mut loader = Loader::new(temp_dir.path().to_path_buf());
        let result = loader.resolve(&temp_dir.path().join("main.md"), "file:./geo.md");

        assert!(result.is_ok(), "Should resolve file: scheme: {:?}", result);
        assert!(result.unwrap().content.contains("Point"));
    }

    #[test]
    fn test_logos_std_scheme() {
        let mut loader = Loader::new(PathBuf::from("."));
        let result = loader.resolve(&PathBuf::from("main.md"), "logos:std");

        assert!(result.is_ok(), "Should resolve logos:std: {:?}", result);
    }

    #[test]
    fn test_logos_core_scheme() {
        let mut loader = Loader::new(PathBuf::from("."));
        let result = loader.resolve(&PathBuf::from("main.md"), "logos:core");

        assert!(result.is_ok(), "Should resolve logos:core: {:?}", result);
    }

    #[test]
    fn test_unknown_intrinsic() {
        let mut loader = Loader::new(PathBuf::from("."));
        let result = loader.resolve(&PathBuf::from("main.md"), "logos:unknown");

        assert!(result.is_err());
        assert!(result.unwrap_err().contains("Unknown intrinsic"));
    }

    #[test]
    fn test_caching() {
        let temp_dir = tempdir().unwrap();
        let geo_path = temp_dir.path().join("geo.md");
        fs::write(&geo_path, "content").unwrap();

        let mut loader = Loader::new(temp_dir.path().to_path_buf());

        // First load
        let _ = loader.resolve(&temp_dir.path().join("main.md"), "file:./geo.md");

        // Should be cached now
        assert!(loader.loaded_modules().len() == 1);
    }

    #[test]
    fn test_missing_file() {
        let temp_dir = tempdir().unwrap();
        let mut loader = Loader::new(temp_dir.path().to_path_buf());

        let result = loader.resolve(&temp_dir.path().join("main.md"), "file:./nonexistent.md");

        assert!(result.is_err());
        assert!(result.unwrap_err().contains("Failed to read"));
    }
}

```

---

### Project Manifest

**File:** `src/project/manifest.rs`

Largo.toml parser. Defines Manifest struct with package metadata (name, version, edition) and dependencies (path/git/version variants).

```rust
//! Phase 37: Largo.toml Manifest Parser
//!
//! Parses project manifests for LOGOS build configuration.

use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::fs;
use std::path::Path;

/// Project manifest (Largo.toml)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Manifest {
    pub package: Package,
    #[serde(default)]
    pub dependencies: HashMap<String, DependencySpec>,
}

/// Package metadata
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Package {
    pub name: String,
    #[serde(default = "default_version")]
    pub version: String,
    #[serde(default)]
    pub description: Option<String>,
    #[serde(default)]
    pub authors: Vec<String>,
    #[serde(default = "default_entry")]
    pub entry: String,
}

/// Dependency specification
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(untagged)]
pub enum DependencySpec {
    /// Simple version string: "1.0.0" or URI: "logos:std"
    Simple(String),
    /// Detailed dependency: { version = "1.0", path = "../foo" }
    Detailed(DependencyDetail),
}

impl std::fmt::Display for DependencySpec {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            DependencySpec::Simple(s) => write!(f, "{}", s),
            DependencySpec::Detailed(d) => {
                if let Some(v) = &d.version {
                    write!(f, "{}", v)
                } else if let Some(p) = &d.path {
                    write!(f, "path:{}", p)
                } else if let Some(g) = &d.git {
                    write!(f, "git:{}", g)
                } else {
                    write!(f, "*")
                }
            }
        }
    }
}

/// Detailed dependency specification
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DependencyDetail {
    #[serde(default)]
    pub version: Option<String>,
    #[serde(default)]
    pub path: Option<String>,
    #[serde(default)]
    pub git: Option<String>,
}

fn default_version() -> String {
    "0.1.0".to_string()
}

fn default_entry() -> String {
    "src/main.lg".to_string()
}

/// Errors that can occur when loading a manifest
#[derive(Debug)]
pub enum ManifestError {
    Io(std::path::PathBuf, String),
    Parse(std::path::PathBuf, String),
    Serialize(String),
}

impl std::fmt::Display for ManifestError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            ManifestError::Io(path, e) => write!(f, "Failed to read {}: {}", path.display(), e),
            ManifestError::Parse(path, e) => write!(f, "Failed to parse {}: {}", path.display(), e),
            ManifestError::Serialize(e) => write!(f, "Failed to serialize manifest: {}", e),
        }
    }
}

impl std::error::Error for ManifestError {}

impl Manifest {
    /// Load manifest from a directory (looks for Largo.toml)
    pub fn load(dir: &Path) -> Result<Self, ManifestError> {
        let path = dir.join("Largo.toml");
        let content = fs::read_to_string(&path)
            .map_err(|e| ManifestError::Io(path.clone(), e.to_string()))?;
        toml::from_str(&content).map_err(|e| ManifestError::Parse(path, e.to_string()))
    }

    /// Create a new manifest with default values
    pub fn new(name: &str) -> Self {
        Manifest {
            package: Package {
                name: name.to_string(),
                version: default_version(),
                description: None,
                authors: Vec::new(),
                entry: default_entry(),
            },
            dependencies: HashMap::new(),
        }
    }

    /// Serialize to TOML string
    pub fn to_toml(&self) -> Result<String, ManifestError> {
        toml::to_string_pretty(self).map_err(|e| ManifestError::Serialize(e.to_string()))
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn parse_minimal_manifest() {
        let toml = r#"
[package]
name = "myproject"
"#;
        let manifest: Manifest = toml::from_str(toml).expect("Should parse minimal manifest");
        assert_eq!(manifest.package.name, "myproject");
        assert_eq!(manifest.package.version, "0.1.0"); // default
        assert_eq!(manifest.package.entry, "src/main.lg"); // default
    }

    #[test]
    fn parse_full_manifest() {
        let toml = r#"
[package]
name = "myproject"
version = "1.0.0"
description = "A test project"
entry = "src/app.lg"
authors = ["Test Author"]

[dependencies]
std = "logos:std"
"#;
        let manifest: Manifest = toml::from_str(toml).expect("Should parse full manifest");
        assert_eq!(manifest.package.name, "myproject");
        assert_eq!(manifest.package.version, "1.0.0");
        assert_eq!(manifest.package.entry, "src/app.lg");
        assert!(manifest.package.description.is_some());
        assert_eq!(manifest.package.authors.len(), 1);
    }

    #[test]
    fn create_new_manifest() {
        let manifest = Manifest::new("testproject");
        assert_eq!(manifest.package.name, "testproject");
        let toml = manifest.to_toml().expect("Should serialize");
        assert!(toml.contains("name = \"testproject\""));
    }

    #[test]
    fn parse_path_dependency() {
        let toml = r#"
[package]
name = "with_deps"

[dependencies]
math = { path = "./math" }
"#;
        let manifest: Manifest = toml::from_str(toml).expect("Should parse path deps");
        assert!(!manifest.dependencies.is_empty());
        match &manifest.dependencies["math"] {
            DependencySpec::Detailed(d) => {
                assert_eq!(d.path.as_deref(), Some("./math"));
            }
            _ => panic!("Expected detailed dependency"),
        }
    }
}

```

---

### Build Orchestration

**File:** `src/project/build.rs`

Project build pipeline. find_project_root() walks up to find Largo.toml, build() coordinates parse→compile→cargo build, run() executes the built binary.

```rust
//! Phase 37: Build Orchestration
//!
//! Coordinates the build process for LOGOS projects.

use std::fs;
use std::path::{Path, PathBuf};
use std::process::Command;

use crate::compile::{compile_project, copy_logos_core, CompileError};

use super::manifest::{Manifest, ManifestError};

/// Build configuration
pub struct BuildConfig {
    pub project_dir: PathBuf,
    pub release: bool,
}

/// Result of a build operation
#[derive(Debug)]
pub struct BuildResult {
    pub target_dir: PathBuf,
    pub binary_path: PathBuf,
}

/// Errors that can occur during the build process
#[derive(Debug)]
pub enum BuildError {
    Manifest(ManifestError),
    Compile(CompileError),
    Io(String),
    Cargo(String),
    NotFound(String),
}

impl std::fmt::Display for BuildError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            BuildError::Manifest(e) => write!(f, "{}", e),
            BuildError::Compile(e) => write!(f, "{}", e),
            BuildError::Io(e) => write!(f, "IO error: {}", e),
            BuildError::Cargo(e) => write!(f, "Cargo error: {}", e),
            BuildError::NotFound(e) => write!(f, "Not found: {}", e),
        }
    }
}

impl std::error::Error for BuildError {}

impl From<ManifestError> for BuildError {
    fn from(e: ManifestError) -> Self {
        BuildError::Manifest(e)
    }
}

impl From<CompileError> for BuildError {
    fn from(e: CompileError) -> Self {
        BuildError::Compile(e)
    }
}

/// Find project root by walking up directory tree looking for Largo.toml
pub fn find_project_root(start: &Path) -> Option<PathBuf> {
    let mut current = if start.is_file() {
        start.parent()?.to_path_buf()
    } else {
        start.to_path_buf()
    };

    loop {
        if current.join("Largo.toml").exists() {
            return Some(current);
        }
        if !current.pop() {
            return None;
        }
    }
}

/// Build a LOGOS project
pub fn build(config: BuildConfig) -> Result<BuildResult, BuildError> {
    // Load manifest
    let manifest = Manifest::load(&config.project_dir)?;

    // Resolve entry point (supports .lg and .md)
    let entry_path = config.project_dir.join(&manifest.package.entry);
    if entry_path.exists() {
        return build_with_entry(&config, &manifest, &entry_path);
    }

    // Try .md fallback if .lg not found
    let md_path = entry_path.with_extension("md");
    if md_path.exists() {
        return build_with_entry(&config, &manifest, &md_path);
    }

    Err(BuildError::NotFound(format!(
        "Entry point not found: {} (also tried .md)",
        entry_path.display()
    )))
}

fn build_with_entry(
    config: &BuildConfig,
    manifest: &Manifest,
    entry_path: &Path,
) -> Result<BuildResult, BuildError> {
    // Create target directory structure
    let target_dir = config.project_dir.join("target");
    let build_dir = if config.release {
        target_dir.join("release")
    } else {
        target_dir.join("debug")
    };
    let rust_project_dir = build_dir.join("build");

    // Clean and recreate build directory
    if rust_project_dir.exists() {
        fs::remove_dir_all(&rust_project_dir).map_err(|e| BuildError::Io(e.to_string()))?;
    }
    fs::create_dir_all(&rust_project_dir).map_err(|e| BuildError::Io(e.to_string()))?;

    // Compile LOGOS to Rust using Phase 36 compile_project
    let rust_code = compile_project(entry_path)?;

    // Write generated Rust code
    let src_dir = rust_project_dir.join("src");
    fs::create_dir_all(&src_dir).map_err(|e| BuildError::Io(e.to_string()))?;

    let main_rs = format!("use logos_core::prelude::*;\n\n{}", rust_code);
    fs::write(src_dir.join("main.rs"), main_rs).map_err(|e| BuildError::Io(e.to_string()))?;

    // Write Cargo.toml for the generated project
    let cargo_toml = format!(
        r#"[package]
name = "{}"
version = "{}"
edition = "2021"

[dependencies]
logos_core = {{ path = "./logos_core" }}
"#,
        manifest.package.name, manifest.package.version
    );
    fs::write(rust_project_dir.join("Cargo.toml"), cargo_toml)
        .map_err(|e| BuildError::Io(e.to_string()))?;

    // Copy logos_core runtime
    copy_logos_core(&rust_project_dir)?;

    // Run cargo build
    let mut cmd = Command::new("cargo");
    cmd.arg("build").current_dir(&rust_project_dir);
    if config.release {
        cmd.arg("--release");
    }

    let output = cmd.output().map_err(|e| BuildError::Io(e.to_string()))?;

    if !output.status.success() {
        let stderr = String::from_utf8_lossy(&output.stderr);
        return Err(BuildError::Cargo(stderr.to_string()));
    }

    // Determine binary path
    let binary_name = if cfg!(windows) {
        format!("{}.exe", manifest.package.name)
    } else {
        manifest.package.name.clone()
    };
    let cargo_target = if config.release { "release" } else { "debug" };
    let binary_path = rust_project_dir
        .join("target")
        .join(cargo_target)
        .join(&binary_name);

    Ok(BuildResult {
        target_dir: build_dir,
        binary_path,
    })
}

/// Run a built project
pub fn run(build_result: &BuildResult) -> Result<i32, BuildError> {
    let mut child = Command::new(&build_result.binary_path)
        .spawn()
        .map_err(|e| BuildError::Io(e.to_string()))?;

    let status = child.wait().map_err(|e| BuildError::Io(e.to_string()))?;

    Ok(status.code().unwrap_or(1))
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::tempdir;

    #[test]
    fn find_project_root_finds_largo_toml() {
        let temp = tempdir().unwrap();
        let sub = temp.path().join("a/b/c");
        fs::create_dir_all(&sub).unwrap();
        fs::write(temp.path().join("Largo.toml"), "[package]\nname=\"test\"\n").unwrap();

        let found = find_project_root(&sub);
        assert!(found.is_some());
        assert_eq!(found.unwrap(), temp.path());
    }

    #[test]
    fn find_project_root_returns_none_if_not_found() {
        let temp = tempdir().unwrap();
        let found = find_project_root(temp.path());
        assert!(found.is_none());
    }
}

```

---

### Credential Management

**File:** `src/project/credentials.rs`

Phase 39 API token storage. Credentials struct persists to ~/.config/logos/credentials.toml with 0600 permissions. Supports LOGOS_TOKEN env var override. TOML format with registry→token map.

```rust
//! Phase 39: Credential Management
//!
//! Stores and retrieves API tokens for the package registry.

use std::collections::HashMap;
use std::fs;
use std::path::PathBuf;

/// Credentials storage format
#[derive(Debug, Default, serde::Serialize, serde::Deserialize)]
pub struct Credentials {
    /// Map of registry URL -> token
    #[serde(default)]
    pub registries: HashMap<String, String>,
}

impl Credentials {
    /// Load credentials from the default location
    pub fn load() -> Result<Self, CredentialsError> {
        let path = credentials_path().ok_or(CredentialsError::NoConfigDir)?;

        if !path.exists() {
            return Ok(Self::default());
        }

        let content = fs::read_to_string(&path)
            .map_err(|e| CredentialsError::Io(e.to_string()))?;

        toml::from_str(&content)
            .map_err(|e| CredentialsError::Parse(e.to_string()))
    }

    /// Save credentials to the default location
    pub fn save(&self) -> Result<(), CredentialsError> {
        let path = credentials_path().ok_or(CredentialsError::NoConfigDir)?;

        // Create parent directory if needed
        if let Some(parent) = path.parent() {
            fs::create_dir_all(parent)
                .map_err(|e| CredentialsError::Io(e.to_string()))?;
        }

        let content = toml::to_string_pretty(self)
            .map_err(|e| CredentialsError::Serialize(e.to_string()))?;

        fs::write(&path, content)
            .map_err(|e| CredentialsError::Io(e.to_string()))?;

        // Set restrictive permissions on Unix
        #[cfg(unix)]
        {
            use std::os::unix::fs::PermissionsExt;
            let perms = std::fs::Permissions::from_mode(0o600);
            fs::set_permissions(&path, perms)
                .map_err(|e| CredentialsError::Io(e.to_string()))?;
        }

        Ok(())
    }

    /// Get token for a registry
    pub fn get_token(&self, registry_url: &str) -> Option<&str> {
        self.registries.get(registry_url).map(|s| s.as_str())
    }

    /// Set token for a registry
    pub fn set_token(&mut self, registry_url: &str, token: &str) {
        self.registries.insert(registry_url.to_string(), token.to_string());
    }

    /// Remove token for a registry
    pub fn remove_token(&mut self, registry_url: &str) {
        self.registries.remove(registry_url);
    }
}

/// Get the token for a registry, checking env var first then credentials file
pub fn get_token(registry_url: &str) -> Option<String> {
    // Check LOGOS_TOKEN env var first
    if let Ok(token) = std::env::var("LOGOS_TOKEN") {
        if !token.is_empty() {
            return Some(token);
        }
    }

    // Fall back to credentials file
    Credentials::load()
        .ok()
        .and_then(|c| c.get_token(registry_url).map(String::from))
}

/// Get the path to the credentials file
pub fn credentials_path() -> Option<PathBuf> {
    // Check LOGOS_CREDENTIALS_PATH env var first
    if let Ok(path) = std::env::var("LOGOS_CREDENTIALS_PATH") {
        return Some(PathBuf::from(path));
    }

    // Use standard config directory
    dirs::config_dir().map(|p| p.join("logos").join("credentials.toml"))
}

#[derive(Debug)]
pub enum CredentialsError {
    NoConfigDir,
    Io(String),
    Parse(String),
    Serialize(String),
}

impl std::fmt::Display for CredentialsError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            Self::NoConfigDir => write!(f, "Could not determine config directory"),
            Self::Io(e) => write!(f, "I/O error: {}", e),
            Self::Parse(e) => write!(f, "Failed to parse credentials: {}", e),
            Self::Serialize(e) => write!(f, "Failed to serialize credentials: {}", e),
        }
    }
}

impl std::error::Error for CredentialsError {}

```

---

### Registry Client

**File:** `src/project/registry.rs`

Phase 39 package registry HTTP client. RegistryClient handles auth, publish (multipart tarball upload), token validation. create_tarball() packages src/, Largo.toml, README.md, LICENSE. is_git_dirty() for safety checks.

```rust
//! Phase 39: Registry Client
//!
//! HTTP client for communicating with the LOGOS package registry.

use std::path::Path;

const DEFAULT_REGISTRY_URL: &str = "https://registry.logicaffeine.com";

/// Registry client for API communication
pub struct RegistryClient {
    base_url: String,
    token: String,
}

impl RegistryClient {
    pub fn new(base_url: &str, token: &str) -> Self {
        Self {
            base_url: base_url.trim_end_matches('/').to_string(),
            token: token.to_string(),
        }
    }

    pub fn default_url() -> &'static str {
        DEFAULT_REGISTRY_URL
    }

    /// Validate the authentication token
    pub fn validate_token(&self) -> Result<UserInfo, RegistryError> {
        let url = format!("{}/auth/me", self.base_url);

        let response = ureq::get(&url)
            .set("Authorization", &format!("Bearer {}", self.token))
            .call()
            .map_err(|e| match e {
                ureq::Error::Status(401, _) => RegistryError::Unauthorized,
                ureq::Error::Status(403, r) => {
                    let msg = r.into_string().unwrap_or_default();
                    RegistryError::Forbidden(msg)
                }
                ureq::Error::Status(code, r) => RegistryError::Server {
                    status: code,
                    message: r.into_string().unwrap_or_default(),
                },
                e => RegistryError::Network(e.to_string()),
            })?;

        let user: UserInfo = response.into_json()
            .map_err(|e| RegistryError::Network(e.to_string()))?;

        Ok(user)
    }

    /// Publish a package to the registry
    pub fn publish(
        &self,
        name: &str,
        version: &str,
        tarball: &[u8],
        metadata: &PublishMetadata,
    ) -> Result<PublishResult, RegistryError> {
        use std::io::Read;

        let url = format!("{}/packages/publish", self.base_url);

        // Create multipart form data
        let boundary = format!("----LargoBoundary{}", rand::random::<u64>());

        let metadata_json = serde_json::to_string(metadata)
            .map_err(|e| RegistryError::InvalidPackage(e.to_string()))?;

        let mut body = Vec::new();

        // Add metadata field
        body.extend_from_slice(format!(
            "--{}\r\nContent-Disposition: form-data; name=\"metadata\"\r\n\r\n{}\r\n",
            boundary, metadata_json
        ).as_bytes());

        // Add tarball field
        body.extend_from_slice(format!(
            "--{}\r\nContent-Disposition: form-data; name=\"tarball\"; filename=\"{}-{}.tar.gz\"\r\nContent-Type: application/gzip\r\n\r\n",
            boundary, name, version
        ).as_bytes());
        body.extend_from_slice(tarball);
        body.extend_from_slice(format!("\r\n--{}--\r\n", boundary).as_bytes());

        let response = ureq::post(&url)
            .set("Authorization", &format!("Bearer {}", self.token))
            .set("Content-Type", &format!("multipart/form-data; boundary={}", boundary))
            .send_bytes(&body)
            .map_err(|e| match e {
                ureq::Error::Status(401, _) => RegistryError::Unauthorized,
                ureq::Error::Status(403, r) => {
                    let msg = r.into_string().unwrap_or_else(|_| "Forbidden".to_string());
                    RegistryError::Forbidden(msg)
                }
                ureq::Error::Status(409, _) => RegistryError::VersionExists {
                    name: name.to_string(),
                    version: version.to_string(),
                },
                ureq::Error::Status(413, _) => RegistryError::TooLarge,
                ureq::Error::Status(code, r) => RegistryError::Server {
                    status: code,
                    message: r.into_string().unwrap_or_default(),
                },
                e => RegistryError::Network(e.to_string()),
            })?;

        let result: PublishResult = response.into_json()
            .map_err(|e| RegistryError::Network(e.to_string()))?;

        Ok(result)
    }
}

/// Create a tarball from a LOGOS project
pub fn create_tarball(project_dir: &Path) -> Result<Vec<u8>, PackageError> {
    use flate2::write::GzEncoder;
    use flate2::Compression;
    use tar::Builder;
    use std::fs::File;
    use std::io::Write;

    let mut tarball = Vec::new();

    {
        let encoder = GzEncoder::new(&mut tarball, Compression::default());
        let mut builder = Builder::new(encoder);

        // Add Largo.toml
        let manifest_path = project_dir.join("Largo.toml");
        if !manifest_path.exists() {
            return Err(PackageError::MissingFile("Largo.toml".to_string()));
        }
        add_file_to_tar(&mut builder, project_dir, "Largo.toml")?;

        // Add src/ directory recursively
        let src_dir = project_dir.join("src");
        if !src_dir.exists() {
            return Err(PackageError::MissingFile("src/".to_string()));
        }
        add_dir_recursive(&mut builder, project_dir, "src")?;

        // Add README.md if it exists
        if project_dir.join("README.md").exists() {
            add_file_to_tar(&mut builder, project_dir, "README.md")?;
        }

        // Add LICENSE if it exists
        if project_dir.join("LICENSE").exists() {
            add_file_to_tar(&mut builder, project_dir, "LICENSE")?;
        }

        builder.finish()
            .map_err(|e| PackageError::TarError(e.to_string()))?;
    }

    Ok(tarball)
}

fn add_file_to_tar<W: std::io::Write>(
    builder: &mut tar::Builder<W>,
    base_dir: &Path,
    rel_path: &str,
) -> Result<(), PackageError> {
    let full_path = base_dir.join(rel_path);
    let content = std::fs::read(&full_path)
        .map_err(|e| PackageError::Io(format!("{}: {}", rel_path, e)))?;

    let mut header = tar::Header::new_gnu();
    header.set_path(rel_path)
        .map_err(|e| PackageError::TarError(e.to_string()))?;
    header.set_size(content.len() as u64);
    header.set_mode(0o644);
    header.set_mtime(0); // Reproducible builds
    header.set_cksum();

    builder.append(&header, content.as_slice())
        .map_err(|e| PackageError::TarError(e.to_string()))?;

    Ok(())
}

fn add_dir_recursive<W: std::io::Write>(
    builder: &mut tar::Builder<W>,
    base_dir: &Path,
    rel_dir: &str,
) -> Result<(), PackageError> {
    let full_dir = base_dir.join(rel_dir);

    for entry in std::fs::read_dir(&full_dir)
        .map_err(|e| PackageError::Io(format!("{}: {}", rel_dir, e)))?
    {
        let entry = entry.map_err(|e| PackageError::Io(e.to_string()))?;
        let path = entry.path();
        let name = entry.file_name();
        let rel_path = format!("{}/{}", rel_dir, name.to_string_lossy());

        // Skip hidden files and target directory
        let name_str = name.to_string_lossy();
        if name_str.starts_with('.') || name_str == "target" {
            continue;
        }

        if path.is_dir() {
            add_dir_recursive(builder, base_dir, &rel_path)?;
        } else if path.is_file() {
            // Only include .lg, .md, and common config files
            let ext = path.extension().and_then(|e| e.to_str()).unwrap_or("");
            if matches!(ext, "lg" | "md" | "toml" | "json") || name_str == "LICENSE" {
                add_file_to_tar(builder, base_dir, &rel_path)?;
            }
        }
    }

    Ok(())
}

/// Check if git working directory is dirty
pub fn is_git_dirty(project_dir: &Path) -> bool {
    use std::process::Command;

    let output = Command::new("git")
        .args(["status", "--porcelain"])
        .current_dir(project_dir)
        .output();

    match output {
        Ok(out) if out.status.success() => !out.stdout.is_empty(),
        _ => false, // Not a git repo or git not available
    }
}

// ============== Types ==============

#[derive(Debug, serde::Deserialize)]
pub struct UserInfo {
    pub id: String,
    pub login: String,
    pub name: Option<String>,
    pub is_admin: bool,
}

#[derive(Debug, serde::Serialize)]
pub struct PublishMetadata {
    pub name: String,
    pub version: String,
    pub description: Option<String>,
    pub repository: Option<String>,
    pub homepage: Option<String>,
    pub license: Option<String>,
    pub keywords: Vec<String>,
    pub entry_point: String,
    pub dependencies: std::collections::HashMap<String, String>,
    pub readme: Option<String>,
}

#[derive(Debug, serde::Deserialize)]
pub struct PublishResult {
    pub success: bool,
    pub package: String,
    pub version: String,
    pub sha256: String,
    pub size: u64,
}

// ============== Errors ==============

#[derive(Debug)]
pub enum RegistryError {
    NoToken,
    Unauthorized,
    Forbidden(String),
    VersionExists { name: String, version: String },
    TooLarge,
    Network(String),
    Server { status: u16, message: String },
    InvalidPackage(String),
}

impl std::fmt::Display for RegistryError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            Self::NoToken => write!(
                f,
                "No authentication token found.\n\
                 Run 'largo login' or set LOGOS_TOKEN environment variable."
            ),
            Self::Unauthorized => write!(
                f,
                "Authentication failed. Your token may be invalid or expired.\n\
                 Run 'largo login' to get a new token."
            ),
            Self::Forbidden(msg) => write!(f, "Access denied: {}", msg),
            Self::VersionExists { name, version } => write!(
                f,
                "Version {} of package '{}' already exists.\n\
                 Update the version in Largo.toml and try again.",
                version, name
            ),
            Self::TooLarge => write!(f, "Package too large. Maximum size is 10MB."),
            Self::Network(e) => write!(f, "Network error: {}", e),
            Self::Server { status, message } => {
                write!(f, "Registry returned error {}: {}", status, message)
            }
            Self::InvalidPackage(e) => write!(f, "Invalid package: {}", e),
        }
    }
}

impl std::error::Error for RegistryError {}

#[derive(Debug)]
pub enum PackageError {
    MissingFile(String),
    Io(String),
    TarError(String),
}

impl std::fmt::Display for PackageError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            Self::MissingFile(name) => write!(f, "Missing required file: {}", name),
            Self::Io(e) => write!(f, "I/O error: {}", e),
            Self::TarError(e) => write!(f, "Failed to create tarball: {}", e),
        }
    }
}

impl std::error::Error for PackageError {}

```

---

## Public API

The public interface for embedding LOGICAFFEINE in other applications.

**Location:** `src/lib.rs`

### Library Entry Point

**File:** `src/lib.rs`

Exports compile(), compile_with_options(), compile_ambiguous(), compile_all_scopes(), compile_all_scopes_with_options(), compile_discourse(), compile_discourse_with_options(), and compile_with_context(). **Phase 12 Parse Forest:** compile_forest() and compile_forest_with_options() return Vec<String> of all valid readings for ambiguous sentences. MAX_FOREST_READINGS (12) limits output size. Handles lexical ambiguity (Noun/Verb tokens) via noun_priority_mode forking and structural ambiguity (PP attachment) via pp_attachment_mode. **Ambiguity APIs:** compile_ambiguous() returns Vec<String> for PP-attachment ambiguity; compile_all_scopes() returns all quantifier scope readings PLUS intensional readings (de re/de dicto) by calling enumerate_scopings() for scope permutations then enumerate_intensional_readings() for opaque verb ambiguity. **Discourse API:** compile_discourse() handles multi-sentence input with persistent DiscourseContext. Defines TranspileContext, CompileOptions, and OutputFormat (Unicode/LaTeX).

```rust
/// Maximum number of readings in a parse forest.
/// Prevents exponential blowup from ambiguous sentences.
pub const MAX_FOREST_READINGS: usize = 12;

pub mod arena;
pub mod arena_ctx;
pub mod ast;
pub mod audio;
pub mod codegen;
#[cfg(not(target_arch = "wasm32"))]
pub mod compile;
// Diagnostic Bridge for ownership error translation
#[cfg(not(target_arch = "wasm32"))]
pub mod diagnostic;
#[cfg(not(target_arch = "wasm32"))]
pub mod sourcemap;
pub mod content;
pub mod context;
pub mod debug;
pub mod drs;
pub mod error;
pub mod formatter;
pub mod game;
pub mod generator;
pub mod grader;
pub mod achievements;
pub mod analysis;
pub mod intern;
pub mod lambda;
pub mod lexer;
pub mod lexicon;
pub mod mwe;
pub mod ontology;
pub mod parser;
pub mod pragmatics;
pub mod progress;
#[cfg(not(target_arch = "wasm32"))]
pub mod project;
#[cfg(all(not(target_arch = "wasm32"), feature = "cli"))]
pub mod cli;
#[cfg(all(not(target_arch = "wasm32"), feature = "verification"))]
pub mod verification;
pub mod runtime_lexicon;
pub mod semantics;
pub mod registry;
pub mod scope;
#[cfg(target_arch = "wasm32")]
pub mod storage;
pub mod srs;
pub mod style;
pub mod unlock;
pub mod learn_state;
pub mod symbol_dict;
pub mod struggle;
pub mod suggest;
pub mod token;
pub mod transpile;
pub mod ui;
pub mod view;
pub mod visitor;
pub mod interpreter;

pub mod test_utils;

pub use analysis::{TypeRegistry, TypeDef, DiscoveryPass, scan_dependencies, Dependency};
#[cfg(not(target_arch = "wasm32"))]
pub use analysis::discover_with_imports;
#[cfg(not(target_arch = "wasm32"))]
pub use project::{Loader, ModuleSource};
#[cfg(not(target_arch = "wasm32"))]
pub use compile::copy_logos_core;
pub use arena::Arena;
pub use arena_ctx::AstContext;
pub use ast::{LogicExpr, NounPhrase, Term, ThematicRole};
pub use context::{DiscourseContext, OwnershipState, TimeConstraint, TimeRelation};
pub use error::{ParseError, ParseErrorKind, socratic_explanation};
pub use debug::{DebugWorld, DisplayWith, WithInterner};
pub use formatter::{LatexFormatter, LogicFormatter, UnicodeFormatter};
pub use intern::{Interner, Symbol, SymbolEq};
pub use lexer::Lexer;
pub use parser::{Parser, ParserMode, NegativeScopeMode};
pub use parser::QuantifierParsing;
pub use registry::SymbolRegistry;
pub use scope::{ScopeStack, ScopeEntry};
pub use token::{BlockType, Token, TokenType};
pub use view::{ExprView, NounPhraseView, Resolve, TermView};
pub use visitor::{Visitor, walk_expr, walk_term, walk_np};
pub use interpreter::{Interpreter, InterpreterResult, RuntimeValue};

// ═══════════════════════════════════════════════════════════════════
// Output Format Configuration
// ═══════════════════════════════════════════════════════════════════

#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
pub enum OutputFormat {
    #[default]
    Unicode,
    LaTeX,
    SimpleFOL,
}

// ═══════════════════════════════════════════════════════════════════
// Transpile Context
// ═══════════════════════════════════════════════════════════════════

pub struct TranspileContext<'a> {
    pub registry: &'a mut SymbolRegistry,
    pub interner: &'a Interner,
}

impl<'a> TranspileContext<'a> {
    pub fn new(registry: &'a mut SymbolRegistry, interner: &'a Interner) -> Self {
        TranspileContext { registry, interner }
    }
}

#[derive(Debug, Clone, Copy)]
pub struct CompileOptions {
    pub format: OutputFormat,
}

impl Default for CompileOptions {
    fn default() -> Self {
        CompileOptions {
            format: OutputFormat::Unicode,
        }
    }
}

// ═══════════════════════════════════════════════════════════════════
// Public API
// ═══════════════════════════════════════════════════════════════════

pub fn compile(input: &str) -> Result<String, ParseError> {
    compile_with_options(input, CompileOptions::default())
}

pub fn compile_simple(input: &str) -> Result<String, ParseError> {
    compile_with_options(input, CompileOptions {
        format: OutputFormat::SimpleFOL,
    })
}

pub fn compile_with_options(input: &str, options: CompileOptions) -> Result<String, ParseError> {
    let mut interner = Interner::new();
    let mut lexer = Lexer::new(input, &mut interner);
    let tokens = lexer.tokenize();

    // Apply MWE collapsing
    let mwe_trie = mwe::build_mwe_trie();
    let tokens = mwe::apply_mwe_pipeline(tokens, &mwe_trie, &mut interner);

    // Pass 1: Discovery - scan for type definitions
    let type_registry = {
        let mut discovery = analysis::DiscoveryPass::new(&tokens, &mut interner);
        discovery.run()
    };

    let expr_arena = Arena::new();
    let term_arena = Arena::new();
    let np_arena = Arena::new();
    let sym_arena = Arena::new();
    let role_arena = Arena::new();
    let pp_arena = Arena::new();

    let ctx = AstContext::new(
        &expr_arena,
        &term_arena,
        &np_arena,
        &sym_arena,
        &role_arena,
        &pp_arena,
    );

    // Pass 2: Parse with type context
    let mut discourse = DiscourseContext::new();
    let mut parser = Parser::with_types(tokens, &mut discourse, &mut interner, ctx, type_registry);
    let ast = parser.parse()?;
    let ast = semantics::apply_axioms(ast, ctx.exprs, ctx.terms, &mut interner);
    let ast = pragmatics::apply_pragmatics(ast, ctx.exprs, &interner);
    let mut registry = SymbolRegistry::new();
    let main_output = ast.transpile(&mut registry, &interner, options.format);

    let constraints = discourse.time_constraints();
    if constraints.is_empty() {
        Ok(main_output)
    } else {
        let constraint_strs: Vec<String> = constraints.iter().map(|c| {
            match c.relation {
                TimeRelation::Precedes => format!("Precedes({}, {})", c.left, c.right),
                TimeRelation::Equals => format!("{}={}", c.left, c.right),
            }
        }).collect();
        Ok(format!("{} ∧ {}", main_output, constraint_strs.join(" ∧ ")))
    }
}

pub fn compile_with_context(input: &str, ctx: &mut DiscourseContext) -> Result<String, ParseError> {
    compile_with_context_options(input, ctx, CompileOptions::default())
}

pub fn compile_with_context_options(
    input: &str,
    ctx: &mut DiscourseContext,
    options: CompileOptions,
) -> Result<String, ParseError> {
    let mut interner = Interner::new();
    let mut lexer = Lexer::new(input, &mut interner);
    let tokens = lexer.tokenize();

    // Apply MWE collapsing
    let mwe_trie = mwe::build_mwe_trie();
    let tokens = mwe::apply_mwe_pipeline(tokens, &mwe_trie, &mut interner);

    // Pass 1: Discovery - scan for type definitions
    let type_registry = {
        let mut discovery = analysis::DiscoveryPass::new(&tokens, &mut interner);
        discovery.run()
    };

    let expr_arena = Arena::new();
    let term_arena = Arena::new();
    let np_arena = Arena::new();
    let sym_arena = Arena::new();
    let role_arena = Arena::new();
    let pp_arena = Arena::new();

    let ast_ctx = AstContext::new(
        &expr_arena,
        &term_arena,
        &np_arena,
        &sym_arena,
        &role_arena,
        &pp_arena,
    );

    // Pass 2: Parse with type context
    let mut parser = Parser::with_types(tokens, ctx, &mut interner, ast_ctx, type_registry);
    let ast = parser.parse()?;
    let ast = semantics::apply_axioms(ast, ast_ctx.exprs, ast_ctx.terms, &mut interner);
    let mut registry = SymbolRegistry::new();
    Ok(ast.transpile(&mut registry, &interner, options.format))
}

pub fn compile_discourse(sentences: &[&str]) -> Result<String, ParseError> {
    compile_discourse_with_options(sentences, CompileOptions::default())
}

pub fn compile_discourse_with_options(sentences: &[&str], options: CompileOptions) -> Result<String, ParseError> {
    let mut interner = Interner::new();
    let mut ctx = DiscourseContext::new();
    let mut results = Vec::new();
    let mut registry = SymbolRegistry::new();
    let mwe_trie = mwe::build_mwe_trie();

    for sentence in sentences {
        let event_var_name = ctx.next_event_var();
        let event_var_symbol = interner.intern(&event_var_name);

        let mut lexer = Lexer::new(sentence, &mut interner);
        let tokens = lexer.tokenize();

        // Apply MWE collapsing
        let tokens = mwe::apply_mwe_pipeline(tokens, &mwe_trie, &mut interner);

        // Pass 1: Discovery - scan for type definitions
        let type_registry = {
            let mut discovery = analysis::DiscoveryPass::new(&tokens, &mut interner);
            discovery.run()
        };

        let expr_arena = Arena::new();
        let term_arena = Arena::new();
        let np_arena = Arena::new();
        let sym_arena = Arena::new();
        let role_arena = Arena::new();
        let pp_arena = Arena::new();

        let ast_ctx = AstContext::new(
            &expr_arena,
            &term_arena,
            &np_arena,
            &sym_arena,
            &role_arena,
            &pp_arena,
        );

        // Pass 2: Parse with type context
        let mut parser = Parser::with_types(tokens, &mut ctx, &mut interner, ast_ctx, type_registry);
        parser.set_discourse_event_var(event_var_symbol);
        let ast = parser.parse()?;
        let ast = semantics::apply_axioms(ast, ast_ctx.exprs, ast_ctx.terms, &mut interner);
        results.push(ast.transpile(&mut registry, &interner, options.format));
    }

    let event_history = ctx.event_history();
    let mut precedes = Vec::new();
    for i in 0..event_history.len().saturating_sub(1) {
        precedes.push(format!("Precedes({}, {})", event_history[i], event_history[i + 1]));
    }

    if precedes.is_empty() {
        Ok(results.join(" ∧ "))
    } else {
        Ok(format!("{} ∧ {}", results.join(" ∧ "), precedes.join(" ∧ ")))
    }
}

/// Returns all possible scope readings for a sentence.
/// For sentences with multiple quantifiers, this returns all permutations.
/// Example: "Every woman loves a man" returns both:
///   - Surface: ∀x(Woman(x) → ∃y(Man(y) ∧ Loves(x, y)))
///   - Inverse: ∃y(Man(y) ∧ ∀x(Woman(x) → Loves(x, y)))
pub fn compile_all_scopes(input: &str) -> Result<Vec<String>, ParseError> {
    compile_all_scopes_with_options(input, CompileOptions::default())
}

pub fn compile_all_scopes_with_options(input: &str, options: CompileOptions) -> Result<Vec<String>, ParseError> {
    let mut interner = Interner::new();
    let mut lexer = Lexer::new(input, &mut interner);
    let tokens = lexer.tokenize();

    // Apply MWE collapsing
    let mwe_trie = mwe::build_mwe_trie();
    let tokens = mwe::apply_mwe_pipeline(tokens, &mwe_trie, &mut interner);

    // Pass 1: Discovery - scan for type definitions
    let type_registry = {
        let mut discovery = analysis::DiscoveryPass::new(&tokens, &mut interner);
        discovery.run()
    };

    let expr_arena = Arena::new();
    let term_arena = Arena::new();
    let np_arena = Arena::new();
    let sym_arena = Arena::new();
    let role_arena = Arena::new();
    let pp_arena = Arena::new();

    let ctx = AstContext::new(
        &expr_arena,
        &term_arena,
        &np_arena,
        &sym_arena,
        &role_arena,
        &pp_arena,
    );

    // Pass 2: Parse with type context
    let mut discourse = DiscourseContext::new();
    let mut parser = Parser::with_types(tokens, &mut discourse, &mut interner, ctx, type_registry);
    let ast = parser.parse()?;

    let scope_arena = Arena::new();
    let scope_term_arena = Arena::new();
    let scopings = lambda::enumerate_scopings(ast, &mut interner, &scope_arena, &scope_term_arena);

    let intensional_arena = Arena::new();
    let intensional_term_arena = Arena::new();
    let intensional_role_arena: Arena<(ast::ThematicRole, ast::Term)> = Arena::new();

    let mut results = Vec::new();
    for scoped_expr in scopings {
        let intensional_readings = lambda::enumerate_intensional_readings(
            scoped_expr,
            &mut interner,
            &intensional_arena,
            &intensional_term_arena,
            &intensional_role_arena,
        );
        for reading in intensional_readings {
            let reading = semantics::apply_axioms(reading, &intensional_arena, &intensional_term_arena, &mut interner);
            let mut registry = SymbolRegistry::new();
            results.push(reading.transpile(&mut registry, &interner, options.format));
        }
    }

    Ok(results)
}

pub fn compile_ambiguous(input: &str) -> Result<Vec<String>, ParseError> {
    compile_ambiguous_with_options(input, CompileOptions::default())
}

pub fn compile_ambiguous_with_options(input: &str, options: CompileOptions) -> Result<Vec<String>, ParseError> {
    let mut interner = Interner::new();
    let mut lexer = Lexer::new(input, &mut interner);
    let tokens = lexer.tokenize();

    // Apply MWE collapsing
    let mwe_trie = mwe::build_mwe_trie();
    let tokens = mwe::apply_mwe_pipeline(tokens, &mwe_trie, &mut interner);

    // Pass 1: Discovery - scan for type definitions
    let type_registry = {
        let mut discovery = analysis::DiscoveryPass::new(&tokens, &mut interner);
        discovery.run()
    };

    let expr_arena = Arena::new();
    let term_arena = Arena::new();
    let np_arena = Arena::new();
    let sym_arena = Arena::new();
    let role_arena = Arena::new();
    let pp_arena = Arena::new();

    let ctx = AstContext::new(
        &expr_arena,
        &term_arena,
        &np_arena,
        &sym_arena,
        &role_arena,
        &pp_arena,
    );

    // Pass 2: Parse with type context
    let mut discourse = DiscourseContext::new();
    let mut parser = Parser::with_types(tokens.clone(), &mut discourse, &mut interner, ctx, type_registry.clone());
    let ast = parser.parse()?;
    let ast = semantics::apply_axioms(ast, ctx.exprs, ctx.terms, &mut interner);
    let mut registry = SymbolRegistry::new();
    let reading1 = ast.transpile(&mut registry, &interner, options.format);

    let has_pp_ambiguity = tokens.iter().any(|t| {
        if let token::TokenType::Preposition(sym) = &t.kind {
            let prep = interner.resolve(*sym);
            prep == "with" || prep == "by" || prep == "for"
        } else {
            false
        }
    });

    if has_pp_ambiguity {
        let expr_arena2 = Arena::new();
        let term_arena2 = Arena::new();
        let np_arena2 = Arena::new();
        let sym_arena2 = Arena::new();
        let role_arena2 = Arena::new();
        let pp_arena2 = Arena::new();

        let ctx2 = AstContext::new(
            &expr_arena2,
            &term_arena2,
            &np_arena2,
            &sym_arena2,
            &role_arena2,
            &pp_arena2,
        );

        let mut discourse2 = DiscourseContext::new();
        let mut parser2 = Parser::with_types(tokens, &mut discourse2, &mut interner, ctx2, type_registry);
        parser2.set_pp_attachment_mode(true);
        let ast2 = parser2.parse()?;
        let ast2 = semantics::apply_axioms(ast2, ctx2.exprs, ctx2.terms, &mut interner);
        let mut registry2 = SymbolRegistry::new();
        let reading2 = ast2.transpile(&mut registry2, &interner, options.format);

        if reading1 != reading2 {
            return Ok(vec![reading1, reading2]);
        }
    }

    Ok(vec![reading1])
}

/// Phase 12: Parse Forest - Returns all valid readings for ambiguous sentences.
/// Handles lexical ambiguity (Noun/Verb) and structural ambiguity (PP attachment).
pub fn compile_forest(input: &str) -> Vec<String> {
    compile_forest_with_options(input, CompileOptions::default())
}

pub fn compile_forest_with_options(input: &str, options: CompileOptions) -> Vec<String> {
    let mut interner = Interner::new();
    let mut lexer = Lexer::new(input, &mut interner);
    let tokens = lexer.tokenize();

    // Apply MWE collapsing
    let mwe_trie = mwe::build_mwe_trie();
    let tokens = mwe::apply_mwe_pipeline(tokens, &mwe_trie, &mut interner);

    // Pass 1: Discovery - scan for type definitions
    let type_registry = {
        let mut discovery = analysis::DiscoveryPass::new(&tokens, &mut interner);
        discovery.run()
    };

    let has_lexical_ambiguity = tokens.iter().any(|t| {
        matches!(t.kind, token::TokenType::Ambiguous { .. })
    });

    let has_pp_ambiguity = tokens.iter().any(|t| {
        if let token::TokenType::Preposition(sym) = &t.kind {
            let prep = interner.resolve(*sym);
            prep == "with" || prep == "by" || prep == "for"
        } else {
            false
        }
    });

    // Phase 18: Detect plurality ambiguity (mixed verb + plural subject)
    let has_mixed_verb = tokens.iter().any(|t| {
        if let token::TokenType::Verb { lemma, .. } = &t.kind {
            Lexer::is_mixed_verb(interner.resolve(*lemma))
        } else {
            false
        }
    });

    // Phase 19: Detect collective verbs (always require group reading with cardinals)
    let has_collective_verb = tokens.iter().any(|t| {
        if let token::TokenType::Verb { lemma, .. } = &t.kind {
            Lexer::is_collective_verb(interner.resolve(*lemma))
        } else {
            false
        }
    });

    let has_plural_subject = tokens.iter().any(|t| {
        matches!(t.kind, token::TokenType::Cardinal(_))
            || matches!(&t.kind, token::TokenType::Article(def) if matches!(def, lexicon::Definiteness::Definite))
    });

    let has_plurality_ambiguity = (has_mixed_verb || has_collective_verb) && has_plural_subject;

    // Phase 41: Detect event adjective + agentive noun ambiguity
    // "beautiful dancer" can mean: Beautiful(x) ∧ Dancer(x) OR ∃e(Dance(e) ∧ Agent(e,x) ∧ Beautiful(e))
    let has_event_adjective_ambiguity = {
        let mut has_event_adj = false;
        let mut has_agentive_noun = false;
        for token in &tokens {
            if let token::TokenType::Adjective(sym) = &token.kind {
                if lexicon::is_event_modifier_adjective(interner.resolve(*sym)) {
                    has_event_adj = true;
                }
            }
            if let token::TokenType::Noun(sym) = &token.kind {
                if lexicon::lookup_agentive_noun(interner.resolve(*sym)).is_some() {
                    has_agentive_noun = true;
                }
            }
        }
        has_event_adj && has_agentive_noun
    };

    // Detect lexically negative verbs (e.g., "lacks", "miss") for scope ambiguity
    // These verbs transform to canonical form + negation, which can take wide or narrow scope
    let has_negative_verb = tokens.iter().any(|t| {
        if let token::TokenType::Verb { lemma, .. } = &t.kind {
            lexicon::get_canonical_verb(&interner.resolve(*lemma).to_lowercase())
                .map(|(_, is_neg)| is_neg)
                .unwrap_or(false)
        } else {
            false
        }
    });

    let mut results: Vec<String> = Vec::new();

    // Reading 1: Default mode (verb priority for Ambiguous tokens)
    {
        let expr_arena = Arena::new();
        let term_arena = Arena::new();
        let np_arena = Arena::new();
        let sym_arena = Arena::new();
        let role_arena = Arena::new();
        let pp_arena = Arena::new();

        let ast_ctx = AstContext::new(
            &expr_arena,
            &term_arena,
            &np_arena,
            &sym_arena,
            &role_arena,
            &pp_arena,
        );

        // Pass 2: Parse with type context
        let mut discourse_ctx = context::DiscourseContext::new();
        let mut parser = Parser::with_types(tokens.clone(), &mut discourse_ctx, &mut interner, ast_ctx, type_registry.clone());
        parser.set_noun_priority_mode(false);

        if let Ok(ast) = parser.parse() {
            let ast = semantics::apply_axioms(ast, ast_ctx.exprs, ast_ctx.terms, &mut interner);
            let mut registry = SymbolRegistry::new();
            results.push(ast.transpile(&mut registry, &interner, options.format));
        }
    }

    // Reading 2: Noun priority mode (for lexical ambiguity)
    if has_lexical_ambiguity {
        let expr_arena = Arena::new();
        let term_arena = Arena::new();
        let np_arena = Arena::new();
        let sym_arena = Arena::new();
        let role_arena = Arena::new();
        let pp_arena = Arena::new();

        let ast_ctx = AstContext::new(
            &expr_arena,
            &term_arena,
            &np_arena,
            &sym_arena,
            &role_arena,
            &pp_arena,
        );

        let mut discourse_ctx = context::DiscourseContext::new();
        let mut parser = Parser::with_types(tokens.clone(), &mut discourse_ctx, &mut interner, ast_ctx, type_registry.clone());
        parser.set_noun_priority_mode(true);

        if let Ok(ast) = parser.parse() {
            let ast = semantics::apply_axioms(ast, ast_ctx.exprs, ast_ctx.terms, &mut interner);
            let mut registry = SymbolRegistry::new();
            let reading = ast.transpile(&mut registry, &interner, options.format);
            if !results.contains(&reading) {
                results.push(reading);
            }
        }
    }

    // Reading 3: PP attachment mode (for structural ambiguity)
    if has_pp_ambiguity {
        let expr_arena = Arena::new();
        let term_arena = Arena::new();
        let np_arena = Arena::new();
        let sym_arena = Arena::new();
        let role_arena = Arena::new();
        let pp_arena = Arena::new();

        let ast_ctx = AstContext::new(
            &expr_arena,
            &term_arena,
            &np_arena,
            &sym_arena,
            &role_arena,
            &pp_arena,
        );

        let mut discourse_ctx = context::DiscourseContext::new();
        let mut parser = Parser::with_types(tokens.clone(), &mut discourse_ctx, &mut interner, ast_ctx, type_registry.clone());
        parser.set_pp_attachment_mode(true);

        if let Ok(ast) = parser.parse() {
            let ast = semantics::apply_axioms(ast, ast_ctx.exprs, ast_ctx.terms, &mut interner);
            let mut registry = SymbolRegistry::new();
            let reading = ast.transpile(&mut registry, &interner, options.format);
            if !results.contains(&reading) {
                results.push(reading);
            }
        }
    }

    // Reading 4: Collective mode (for plurality ambiguity with mixed verbs)
    if has_plurality_ambiguity {
        let expr_arena = Arena::new();
        let term_arena = Arena::new();
        let np_arena = Arena::new();
        let sym_arena = Arena::new();
        let role_arena = Arena::new();
        let pp_arena = Arena::new();

        let ast_ctx = AstContext::new(
            &expr_arena,
            &term_arena,
            &np_arena,
            &sym_arena,
            &role_arena,
            &pp_arena,
        );

        let mut discourse_ctx = context::DiscourseContext::new();
        let mut parser = Parser::with_types(tokens.clone(), &mut discourse_ctx, &mut interner, ast_ctx, type_registry.clone());
        parser.set_collective_mode(true);

        if let Ok(ast) = parser.parse() {
            // Transform cardinal quantifiers to group quantifiers for collective reading
            if let Ok(transformed) = parser.transform_cardinal_to_group(ast) {
                let transformed = semantics::apply_axioms(transformed, ast_ctx.exprs, ast_ctx.terms, &mut interner);
                let mut registry = SymbolRegistry::new();
                let reading = transformed.transpile(&mut registry, &interner, options.format);
                if !results.contains(&reading) {
                    results.push(reading);
                }
            }
        }
    }

    // Reading 5: Event adjective mode (for event-modifying adjectives with agentive nouns)
    if has_event_adjective_ambiguity {
        let expr_arena = Arena::new();
        let term_arena = Arena::new();
        let np_arena = Arena::new();
        let sym_arena = Arena::new();
        let role_arena = Arena::new();
        let pp_arena = Arena::new();

        let ast_ctx = AstContext::new(
            &expr_arena,
            &term_arena,
            &np_arena,
            &sym_arena,
            &role_arena,
            &pp_arena,
        );

        let mut discourse_ctx = context::DiscourseContext::new();
        let mut parser = Parser::with_types(tokens.clone(), &mut discourse_ctx, &mut interner, ast_ctx, type_registry.clone());
        parser.set_event_reading_mode(true);

        if let Ok(ast) = parser.parse() {
            let ast = semantics::apply_axioms(ast, ast_ctx.exprs, ast_ctx.terms, &mut interner);
            let mut registry = SymbolRegistry::new();
            let reading = ast.transpile(&mut registry, &interner, options.format);
            if !results.contains(&reading) {
                results.push(reading);
            }
        }
    }

    // Reading 6: Wide scope negation mode (for lexically negative verbs like "lacks")
    // Produces: ¬∃y(Key(y) ∧ Have(x,y)) - "has NO keys" (de dicto reading)
    // vs default: ∃y(Key(y) ∧ ¬Have(x,y)) - "missing SOME key" (de re reading)
    if has_negative_verb {
        let expr_arena = Arena::new();
        let term_arena = Arena::new();
        let np_arena = Arena::new();
        let sym_arena = Arena::new();
        let role_arena = Arena::new();
        let pp_arena = Arena::new();

        let ast_ctx = AstContext::new(
            &expr_arena,
            &term_arena,
            &np_arena,
            &sym_arena,
            &role_arena,
            &pp_arena,
        );

        let mut discourse_ctx = context::DiscourseContext::new();
        let mut parser = Parser::with_types(tokens.clone(), &mut discourse_ctx, &mut interner, ast_ctx, type_registry);
        parser.set_negative_scope_mode(parser::NegativeScopeMode::Wide);

        if let Ok(ast) = parser.parse() {
            let ast = semantics::apply_axioms(ast, ast_ctx.exprs, ast_ctx.terms, &mut interner);
            let mut registry = SymbolRegistry::new();
            let reading = ast.transpile(&mut registry, &interner, options.format);
            if !results.contains(&reading) {
                results.push(reading);
            }
        }
    }

    // Enforce MAX_FOREST_READINGS limit
    results.truncate(MAX_FOREST_READINGS);

    results
}

// ═══════════════════════════════════════════════════════════════════
// UI API - For Live Transpilation & Visualization
// ═══════════════════════════════════════════════════════════════════

use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub enum TokenCategory {
    Quantifier,
    Noun,
    Verb,
    Adjective,
    Connective,
    Determiner,
    Preposition,
    Pronoun,
    Modal,
    Punctuation,
    Proper,
    Other,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TokenInfo {
    pub start: usize,
    pub end: usize,
    pub text: String,
    pub category: TokenCategory,
}

fn categorize_token(kind: &TokenType, _interner: &Interner) -> TokenCategory {
    match kind {
        TokenType::All | TokenType::Some | TokenType::No | TokenType::Any
        | TokenType::Most | TokenType::Few | TokenType::Many
        | TokenType::Cardinal(_) | TokenType::AtLeast(_) | TokenType::AtMost(_) => TokenCategory::Quantifier,
        TokenType::Noun(_) => TokenCategory::Noun,
        TokenType::Verb { .. } => TokenCategory::Verb,
        TokenType::Adjective(_) | TokenType::NonIntersectiveAdjective(_) => TokenCategory::Adjective,
        TokenType::And | TokenType::Or | TokenType::Not | TokenType::If | TokenType::Then
        | TokenType::Iff | TokenType::Because => TokenCategory::Connective,
        TokenType::Article(_) => TokenCategory::Determiner,
        TokenType::Preposition(_) => TokenCategory::Preposition,
        TokenType::Pronoun { .. } => TokenCategory::Pronoun,
        TokenType::Must | TokenType::Can | TokenType::Should | TokenType::Shall
        | TokenType::Would | TokenType::Could | TokenType::May | TokenType::Cannot => TokenCategory::Modal,
        TokenType::Period | TokenType::Comma => TokenCategory::Punctuation,
        TokenType::ProperName(_) => TokenCategory::Proper,
        _ => TokenCategory::Other,
    }
}

pub fn tokenize_for_ui(input: &str) -> Vec<TokenInfo> {
    let mut interner = Interner::new();
    let mut lexer = Lexer::new(input, &mut interner);
    let tokens = lexer.tokenize();

    tokens.iter().map(|t| TokenInfo {
        start: t.span.start,
        end: t.span.end,
        text: input[t.span.start..t.span.end].to_string(),
        category: categorize_token(&t.kind, &interner),
    }).collect()
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct AstNode {
    pub label: String,
    pub node_type: String,
    pub children: Vec<AstNode>,
}

impl AstNode {
    pub fn leaf(label: &str, node_type: &str) -> Self {
        AstNode {
            label: label.to_string(),
            node_type: node_type.to_string(),
            children: Vec::new(),
        }
    }

    pub fn with_children(label: &str, node_type: &str, children: Vec<AstNode>) -> Self {
        AstNode {
            label: label.to_string(),
            node_type: node_type.to_string(),
            children,
        }
    }
}

pub fn expr_to_ast_node(expr: &LogicExpr, interner: &Interner) -> AstNode {
    match expr {
        LogicExpr::Predicate { name, args } => {
            let name_str = interner.resolve(*name);
            let arg_nodes: Vec<AstNode> = args.iter()
                .map(|t| term_to_ast_node(t, interner))
                .collect();
            AstNode::with_children(
                &format!("{}({})", name_str, args.len()),
                "predicate",
                arg_nodes,
            )
        }
        LogicExpr::Quantifier { kind, variable, body, .. } => {
            let var_str = interner.resolve(*variable);
            let symbol = match kind {
                ast::QuantifierKind::Universal => "∀",
                ast::QuantifierKind::Existential => "∃",
                ast::QuantifierKind::Most => "MOST",
                ast::QuantifierKind::Few => "FEW",
                ast::QuantifierKind::Many => "MANY",
                ast::QuantifierKind::Cardinal(n) => return AstNode::with_children(
                    &format!("∃={}{}", n, var_str),
                    "quantifier",
                    vec![expr_to_ast_node(body, interner)],
                ),
                ast::QuantifierKind::AtLeast(n) => return AstNode::with_children(
                    &format!("∃≥{}{}", n, var_str),
                    "quantifier",
                    vec![expr_to_ast_node(body, interner)],
                ),
                ast::QuantifierKind::AtMost(n) => return AstNode::with_children(
                    &format!("∃≤{}{}", n, var_str),
                    "quantifier",
                    vec![expr_to_ast_node(body, interner)],
                ),
                ast::QuantifierKind::Generic => "GEN",
            };
            AstNode::with_children(
                &format!("{}{}", symbol, var_str),
                "quantifier",
                vec![expr_to_ast_node(body, interner)],
            )
        }
        LogicExpr::BinaryOp { left, op, right } => {
            let op_str = match op {
                TokenType::And => "∧",
                TokenType::Or => "∨",
                TokenType::If | TokenType::Then => "→",
                TokenType::Iff => "↔",
                _ => "?",
            };
            AstNode::with_children(
                op_str,
                "binary_op",
                vec![
                    expr_to_ast_node(left, interner),
                    expr_to_ast_node(right, interner),
                ],
            )
        }
        LogicExpr::UnaryOp { op, operand } => {
            let op_str = match op {
                TokenType::Not => "¬",
                _ => "?",
            };
            AstNode::with_children(
                op_str,
                "unary_op",
                vec![expr_to_ast_node(operand, interner)],
            )
        }
        LogicExpr::Identity { left, right } => {
            AstNode::with_children(
                "=",
                "identity",
                vec![
                    term_to_ast_node(left, interner),
                    term_to_ast_node(right, interner),
                ],
            )
        }
        LogicExpr::Modal { vector, operand } => {
            AstNode::with_children(
                &format!("□{:?}", vector.domain),
                "modal",
                vec![expr_to_ast_node(operand, interner)],
            )
        }
        LogicExpr::Lambda { variable, body } => {
            let var_str = interner.resolve(*variable);
            AstNode::with_children(
                &format!("λ{}", var_str),
                "lambda",
                vec![expr_to_ast_node(body, interner)],
            )
        }
        _ => AstNode::leaf(&format!("{:?}", expr), "other"),
    }
}

fn term_to_ast_node(term: &Term, interner: &Interner) -> AstNode {
    match term {
        Term::Constant(sym) => AstNode::leaf(interner.resolve(*sym), "constant"),
        Term::Variable(sym) => AstNode::leaf(interner.resolve(*sym), "variable"),
        Term::Function(name, args) => {
            let name_str = interner.resolve(*name);
            let arg_nodes: Vec<AstNode> = args.iter()
                .map(|t| term_to_ast_node(t, interner))
                .collect();
            AstNode::with_children(&format!("{}()", name_str), "function", arg_nodes)
        }
        Term::Group(terms) => {
            let term_nodes: Vec<AstNode> = terms.iter()
                .map(|t| term_to_ast_node(t, interner))
                .collect();
            AstNode::with_children("⊕", "group", term_nodes)
        }
        _ => AstNode::leaf(&format!("{:?}", term), "term"),
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CompileResult {
    pub logic: Option<String>,
    pub simple_logic: Option<String>,
    pub ast: Option<AstNode>,
    pub readings: Vec<String>,
    pub tokens: Vec<TokenInfo>,
    pub error: Option<String>,
}

pub fn compile_for_ui(input: &str) -> CompileResult {
    let tokens = tokenize_for_ui(input);
    let readings = compile_forest(input);

    let mut interner = Interner::new();
    let mut lexer = Lexer::new(input, &mut interner);
    let lex_tokens = lexer.tokenize();

    let mwe_trie = mwe::build_mwe_trie();
    let lex_tokens = mwe::apply_mwe_pipeline(lex_tokens, &mwe_trie, &mut interner);

    // Pass 1: Discovery - scan for type definitions
    let type_registry = {
        let mut discovery = analysis::DiscoveryPass::new(&lex_tokens, &mut interner);
        discovery.run()
    };

    let expr_arena = Arena::new();
    let term_arena = Arena::new();
    let np_arena = Arena::new();
    let sym_arena = Arena::new();
    let role_arena = Arena::new();
    let pp_arena = Arena::new();

    let ctx = AstContext::new(
        &expr_arena,
        &term_arena,
        &np_arena,
        &sym_arena,
        &role_arena,
        &pp_arena,
    );

    // Pass 2: Parse with type context
    let mut discourse = DiscourseContext::new();
    let mut parser = Parser::with_types(lex_tokens, &mut discourse, &mut interner, ctx, type_registry);

    match parser.parse() {
        Ok(ast) => {
            // Apply semantic normalization (canonical forms: lack -> ¬Have, etc.)
            let ast = semantics::apply_axioms(ast, ctx.exprs, ctx.terms, &mut interner);
            let ast = pragmatics::apply_pragmatics(ast, ctx.exprs, &interner);
            let ast_node = expr_to_ast_node(ast, &interner);
            let mut registry = SymbolRegistry::new();
            let logic = ast.transpile(&mut registry, &interner, OutputFormat::Unicode);
            let simple_logic = ast.transpile(&mut registry, &interner, OutputFormat::SimpleFOL);

            CompileResult {
                logic: Some(logic),
                simple_logic: Some(simple_logic),
                ast: Some(ast_node),
                readings,
                tokens,
                error: None,
            }
        }
        Err(e) => {
            let advice = socratic_explanation(&e, &interner);
            CompileResult {
                logic: None,
                simple_logic: None,
                ast: None,
                readings: Vec::new(),
                tokens,
                error: Some(advice),
            }
        }
    }
}

// ═══════════════════════════════════════════════════════════════════
// Imperative Interpreter API - For Guide Page Interactive Examples
// ═══════════════════════════════════════════════════════════════════

use crate::ast::stmt::{Stmt, Expr, TypeExpr};

/// Interpret LOGOS imperative code and return output lines.
/// This is used by the Guide page for interactive code examples.
/// Phase 55: Now async to support VFS operations.
pub async fn interpret_for_ui(input: &str) -> InterpreterResult {
    let mut interner = Interner::new();
    let mut lexer = Lexer::new(input, &mut interner);
    let tokens = lexer.tokenize();

    // Apply MWE collapsing (for consistency with compile pipeline)
    let mwe_trie = mwe::build_mwe_trie();
    let tokens = mwe::apply_mwe_pipeline(tokens, &mwe_trie, &mut interner);

    // Pass 1: Discovery - scan for type definitions
    let type_registry = {
        let mut discovery = analysis::DiscoveryPass::new(&tokens, &mut interner);
        discovery.run()
    };

    // Create arenas for AST allocation
    let expr_arena = Arena::new();
    let term_arena = Arena::new();
    let np_arena = Arena::new();
    let sym_arena = Arena::new();
    let role_arena = Arena::new();
    let pp_arena = Arena::new();
    let stmt_arena: Arena<Stmt> = Arena::new();
    let imperative_expr_arena: Arena<Expr> = Arena::new();
    let type_expr_arena: Arena<TypeExpr> = Arena::new();

    let ctx = AstContext::with_types(
        &expr_arena,
        &term_arena,
        &np_arena,
        &sym_arena,
        &role_arena,
        &pp_arena,
        &stmt_arena,
        &imperative_expr_arena,
        &type_expr_arena,
    );

    // Pass 2: Parse with type context (imperative mode)
    let mut discourse = DiscourseContext::new();
    let mut parser = Parser::with_types(tokens, &mut discourse, &mut interner, ctx, type_registry);

    match parser.parse_program() {
        Ok(stmts) => {
            let mut interp = interpreter::Interpreter::new(&interner);
            match interp.run(&stmts).await {
                Ok(()) => InterpreterResult {
                    lines: interp.output,
                    error: None,
                },
                Err(e) => InterpreterResult {
                    lines: interp.output,
                    error: Some(e),
                },
            }
        }
        Err(e) => {
            let advice = socratic_explanation(&e, &interner);
            InterpreterResult {
                lines: vec![],
                error: Some(advice),
            }
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    // ═══════════════════════════════════════════════════════════════════
    // Phase 0: Output Format Configuration (FOL Upgrade)
    // ═══════════════════════════════════════════════════════════════════

    #[test]
    fn compile_with_unicode_default() {
        let result = compile("All men are mortal.").unwrap();
        assert!(
            result.contains("∀") || result.contains("→"),
            "Unicode format should use ∀ or →: got '{}'",
            result
        );
    }

    #[test]
    fn compile_with_latex_option() {
        let options = CompileOptions {
            format: OutputFormat::LaTeX,
        };
        let result = compile_with_options("All men are mortal.", options).unwrap();
        assert!(
            result.contains("\\forall") && result.contains("\\supset"),
            "LaTeX format should use \\forall and \\supset: got '{}'",
            result
        );
    }

    #[test]
    fn latex_uses_latex_operators() {
        let options = CompileOptions {
            format: OutputFormat::LaTeX,
        };
        let result = compile_with_options("If it is raining, then it is pouring.", options).unwrap();
        assert!(
            result.contains("\\supset"),
            "LaTeX format should use \\supset: got '{}'",
            result
        );
    }

    // ═══════════════════════════════════════════════════════════════════
    // Phase 2: AST Structure Tests (FOL Upgrade)
    // ═══════════════════════════════════════════════════════════════════

    #[test]
    fn term_constant_creation() {
        use crate::ast::Term;
        let mut interner = Interner::new();
        let sym = interner.intern("Socrates");
        let term = Term::Constant(sym);
        assert!(matches!(term, Term::Constant(_)));
    }

    #[test]
    fn term_variable_creation() {
        use crate::ast::Term;
        let mut interner = Interner::new();
        let x = interner.intern("x");
        let term = Term::Variable(x);
        assert!(matches!(term, Term::Variable(_)));
    }

    #[test]
    fn predicate_unary() {
        use crate::ast::{LogicExpr, Term};
        let mut interner = Interner::new();
        let term_arena: Arena<Term> = Arena::new();
        let mortal = interner.intern("Mortal");
        let x = interner.intern("x");
        let expr = LogicExpr::Predicate {
            name: mortal,
            args: term_arena.alloc_slice([Term::Variable(x)]),
        };
        assert!(matches!(expr, LogicExpr::Predicate { .. }));
    }

    #[test]
    fn predicate_binary() {
        use crate::ast::{LogicExpr, Term};
        let mut interner = Interner::new();
        let term_arena: Arena<Term> = Arena::new();
        let loves = interner.intern("Loves");
        let john = interner.intern("John");
        let mary = interner.intern("Mary");
        let expr = LogicExpr::Predicate {
            name: loves,
            args: term_arena.alloc_slice([
                Term::Constant(john),
                Term::Constant(mary),
            ]),
        };
        if let LogicExpr::Predicate { args, .. } = expr {
            assert_eq!(args.len(), 2);
        }
    }

    #[test]
    fn identity_expression() {
        use crate::ast::{LogicExpr, Term};
        let mut interner = Interner::new();
        let term_arena: Arena<Term> = Arena::new();
        let clark = interner.intern("Clark");
        let superman = interner.intern("Superman");
        let expr = LogicExpr::Identity {
            left: term_arena.alloc(Term::Constant(clark)),
            right: term_arena.alloc(Term::Constant(superman)),
        };
        assert!(matches!(expr, LogicExpr::Identity { .. }));
    }

    #[test]
    fn quantifier_universal() {
        use crate::ast::{LogicExpr, QuantifierKind, Term};
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();
        let x = interner.intern("x");
        let mortal = interner.intern("Mortal");
        let body = expr_arena.alloc(LogicExpr::Predicate {
            name: mortal,
            args: term_arena.alloc_slice([Term::Variable(x)]),
        });
        let expr = LogicExpr::Quantifier {
            kind: QuantifierKind::Universal,
            variable: x,
            body,
            island_id: 0,
        };
        assert!(matches!(
            expr,
            LogicExpr::Quantifier {
                kind: QuantifierKind::Universal,
                ..
            }
        ));
    }

    // ═══════════════════════════════════════════════════════════════════
    // Phase 3: Parser Desugaring Tests (FOL Upgrade)
    // ═══════════════════════════════════════════════════════════════════

    #[test]
    fn all_produces_universal_quantifier() {
        let result = compile("All men are mortal.").unwrap();
        assert!(
            result.contains("∀") && result.contains("→"),
            "All should produce ∀x(S(x) → P(x)): got '{}'",
            result
        );
    }

    #[test]
    fn some_produces_existential_quantifier() {
        let result = compile("Some cats are black.").unwrap();
        assert!(
            result.contains("∃") && result.contains("∧"),
            "Some should produce ∃x(S(x) ∧ P(x)): got '{}'",
            result
        );
    }

    #[test]
    fn no_produces_universal_negation() {
        let result = compile("No dogs are cats.").unwrap();
        assert!(
            result.contains("∀") && result.contains("¬"),
            "No should produce ∀x(S(x) → ¬P(x)): got '{}'",
            result
        );
    }

    #[test]
    fn multiple_quantifiers_have_unique_variables() {
        // Compound sentence with two quantified clauses
        let result = compile("All men are mortal and some cats are black.").unwrap();
        assert!(
            result.contains("x") && result.contains("y"),
            "Multiple quantifiers should have unique variables: got '{}'",
            result
        );
    }

    // ═══════════════════════════════════════════════════════════════════
    // Phase 4: N-Ary Relations & Prepositions (FOL Upgrade)
    // ═══════════════════════════════════════════════════════════════════

    #[test]
    fn ternary_relation_with_to() {
        // Debug: check tokens
        let mut interner = Interner::new();
        let mut lexer = Lexer::new("John gave the book to Mary.", &mut interner);
        let tokens = lexer.tokenize();
        eprintln!("Tokens: {:?}", tokens);

        let result = compile("John gave the book to Mary.").unwrap();
        eprintln!("Result: {}", result);

        // Should have 3 arguments (2 commas)
        let comma_count = result.matches(',').count();
        assert!(
            comma_count >= 2,
            "Ternary relation should have 3 args (2+ commas): got '{}'",
            result
        );
    }

    #[test]
    fn binary_relation_basic() {
        let result = compile("John loves Mary.").unwrap();
        assert!(
            (result.contains("Agent(e, John)") && result.contains("Theme(e, Mary)"))
                || result.contains("(John, Mary)"),
            "Binary relation should have Agent and Theme roles: got '{}'",
            result
        );
    }

    // ═══════════════════════════════════════════════════════════════════
    // Legacy Tests (will be updated as we progress)
    // ═══════════════════════════════════════════════════════════════════

    #[test]
    fn dogs_and_dangerous_get_different_symbols() {
        let output = compile("All dogs are dangerous.").unwrap();
        assert_ne!(output, "All D is D", "dogs and dangerous should have different symbols");
    }

    #[test]
    fn men_and_mortal_get_different_symbols() {
        let output = compile("All men are mortal.").unwrap();
        assert_ne!(output, "All M is M", "men and mortal should have different symbols");
    }

    #[test]
    fn same_word_gets_same_symbol() {
        let output = compile("All cats are cats.").unwrap();
        // FOL output: ∀x((Cats(x) → Cats(x))) - same word appears twice
        let cats_count = output.matches("Cats(").count();
        assert!(
            cats_count >= 2,
            "same word should get same symbol (Cats appears twice): got '{}'",
            output
        );
    }

    #[test]
    fn compile_conditional() {
        let output = compile("If it is raining, then it is pouring.").unwrap();
        assert!(
            output.contains("→") || output.contains("\\supset"),
            "conditional should produce implication: got '{}'",
            output
        );
    }

    #[test]
    fn parse_adjective_noun_subject() {
        let output = compile("All old men are mortal.").unwrap();
        assert!(
            !output.contains("All O is"),
            "should not treat 'old' as the subject"
        );
    }

    #[test]
    fn parse_multiple_adjectives() {
        let output = compile("All old tired men are happy.").unwrap();
        assert!(
            !output.contains("All O is"),
            "should not treat first adjective as subject"
        );
    }

    // ═══════════════════════════════════════════════════════════════════
    // Phase 4: Transitive Verbs (Relations)
    // ═══════════════════════════════════════════════════════════════════

    #[test]
    fn parse_transitive_verb() {
        let output = compile("John loves Mary.").unwrap();
        assert!(
            (output.contains("Agent(e, John)") && output.contains("Theme(e, Mary)"))
                || output.contains("(John, Mary)"),
            "transitive verb should produce Agent/Theme roles or binary predicate: got '{}'",
            output
        );
    }

    #[test]
    fn parse_transitive_verb_symbols_unique() {
        let output = compile("John sees Jane.").unwrap();
        assert!(
            output.contains("Agent(e, John)") && output.contains("Theme(e, Jane)"),
            "John and Jane should get unique full names: got '{}'",
            output
        );
    }

    // ═══════════════════════════════════════════════════════════════════
    // Phase 5: Modal Vector Theory
    // ═══════════════════════════════════════════════════════════════════

    #[test]
    fn parse_modal_must_alethic() {
        let output = compile("All cats must sleep.").unwrap();
        assert!(
            output.contains("□_{1.0}") || output.contains("\\Box_{1.0}"),
            "must should produce alethic necessity: got '{}'",
            output
        );
    }

    #[test]
    fn parse_modal_should_deontic() {
        let output = compile("All students should study.").unwrap();
        assert!(
            output.contains("O_{0.6}"),
            "should produces deontic obligation: got '{}'",
            output
        );
    }

    #[test]
    fn parse_modal_can_possibility() {
        let output = compile("Some birds can fly.").unwrap();
        assert!(
            output.contains("◇") || output.contains("\\Diamond"),
            "can should produce possibility: got '{}'",
            output
        );
    }

    #[test]
    fn parse_modal_cannot_impossibility() {
        let output = compile("All code cannot run.").unwrap();
        assert!(
            output.contains("□_{0.0}") || output.contains("\\Box_{0.0}"),
            "cannot should produce impossibility: got '{}'",
            output
        );
    }

    #[test]
    fn parse_compound_modal_sentence() {
        let output = compile("The user should compile and the code cannot run.").unwrap();
        assert!(
            output.contains("O_{0.6}") && (output.contains("□_{0.0}") || output.contains("\\Box_{0.0}")),
            "compound modal should have both operators: got '{}'",
            output
        );
    }

    // ═══════════════════════════════════════════════════════════════════
    // Phase 1: Identity & Biconditional (TDD RED)
    // ═══════════════════════════════════════════════════════════════════

    #[test]
    fn identity_clark_is_superman() {
        let result = compile("Clark is equal to Superman.").unwrap();
        assert!(
            result.contains("="),
            "Identity should produce =: got '{}'",
            result
        );
    }

    #[test]
    fn identity_same_constant() {
        let result = compile("Socrates is identical to Socrates.").unwrap();
        assert!(
            result.contains("Socrates = Socrates"),
            "Same constant should appear twice: got '{}'",
            result
        );
    }

    #[test]
    fn iff_produces_biconditional() {
        let result = compile("A if and only if B.").unwrap();
        assert!(
            result.contains("↔"),
            "Iff should produce ↔: got '{}'",
            result
        );
    }

    #[test]
    fn iff_latex_uses_equiv() {
        let options = CompileOptions {
            format: OutputFormat::LaTeX,
        };
        let result = compile_with_options("A if and only if B.", options).unwrap();
        assert!(
            result.contains("\\equiv"),
            "LaTeX Iff should use \\equiv: got '{}'",
            result
        );
    }

    // ═══════════════════════════════════════════════════════════════════
    // Phase 2: Reflexive Binding (TDD RED)
    // ═══════════════════════════════════════════════════════════════════

    #[test]
    fn reflexive_binds_to_subject() {
        let result = compile("John loves himself.").unwrap();
        assert!(
            (result.contains("Agent(e, John)") && result.contains("Theme(e, John)"))
                || result.contains("(John, John)"),
            "Reflexive should bind Agent and Theme to same entity: got '{}'",
            result
        );
    }

    #[test]
    fn reflexive_with_herself() {
        let result = compile("Mary sees herself.").unwrap();
        assert!(
            (result.contains("Agent(e, Mary)") && result.contains("Theme(e, Mary)"))
                || result.contains("(Mary, Mary)"),
            "Reflexive herself should bind: got '{}'",
            result
        );
    }

    #[test]
    fn reflexive_in_prepositional_phrase() {
        let result = compile("John gave the book to himself.").unwrap();
        assert!(
            result.contains("Agent(e, John)") && result.contains("Theme(e, Book)")
                || result.contains("(John, Book, John)"),
            "Reflexive in preposition should bind to subject: got '{}'",
            result
        );
    }

    #[test]
    fn relative_clause_with_preposition() {
        let result = compile("All dogs that ran to the house are tired.").unwrap();
        assert!(
            result.contains("Run(x, House)"),
            "Relative clause should support prepositions: got '{}'",
            result
        );
    }

    #[test]
    fn relative_clause_with_reflexive_preposition() {
        let result = compile("All men that speak to themselves are wise.").unwrap();
        assert!(
            result.contains("Speak(x, x)"),
            "Relative clause reflexive should bind to variable: got '{}'",
            result
        );
    }

    // ═══════════════════════════════════════════════════════════════════
    // Phase 3: Relative Clauses & Adjective Predicates (TDD RED)
    // ═══════════════════════════════════════════════════════════════════

    #[test]
    fn adjectives_as_separate_predicates() {
        let result = compile("All happy dogs are friendly.").unwrap();
        // Subject should be: Happy(x) ∧ Dogs(x) → Friendly(x)
        // Check that adjective creates separate predicate in conjunction
        assert!(
            result.contains("Happy(x)") && result.contains("∧") && result.contains("Dogs(x)"),
            "Adjectives should create separate predicates: got '{}'",
            result
        );
    }

    #[test]
    fn relative_clause_basic() {
        let result = compile("All dogs that bark are loud.").unwrap();
        // Subject should be: Dogs(x) ∧ Bark(x) → Loud(x)
        assert!(
            result.contains("Dogs(x)") && result.contains("∧") && result.contains("Bark(x)"),
            "Relative clause should create conjunction: got '{}'",
            result
        );
    }

    #[test]
    fn relative_clause_with_object() {
        let result = compile("All cats that chase mice are hunters.").unwrap();
        // Subject should be: Cats(x) ∧ Chase(x, Mice) → Hunters(x)
        assert!(
            result.contains("∧") && (result.contains("(x, Mice)") || result.contains("(x,Mice)")),
            "Relative clause should include predicate with object: got '{}'",
            result
        );
    }

    // ═══════════════════════════════════════════════════════════════════
    // Phase 1: Discourse Context & Pronoun Resolution (TDD RED)
    // ═══════════════════════════════════════════════════════════════════

    #[test]
    fn discourse_basic_pronoun_he() {
        use crate::context::DiscourseContext;
        let mut ctx = DiscourseContext::new();
        let _r1 = compile_with_context("John ran.", &mut ctx).unwrap();
        let r2 = compile_with_context("He stopped.", &mut ctx).unwrap();
        assert!(
            r2.contains("J"),
            "He should resolve to John (J): got '{}'",
            r2
        );
    }

    #[test]
    fn discourse_basic_pronoun_she() {
        use crate::context::DiscourseContext;
        let mut ctx = DiscourseContext::new();
        let _r1 = compile_with_context("Mary ran.", &mut ctx).unwrap();
        let r2 = compile_with_context("She stopped.", &mut ctx).unwrap();
        assert!(
            r2.contains("M"),
            "She should resolve to Mary (M): got '{}'",
            r2
        );
    }

    #[test]
    fn discourse_multiple_entities() {
        use crate::context::DiscourseContext;
        let mut ctx = DiscourseContext::new();
        compile_with_context("John saw Mary.", &mut ctx).unwrap();
        let result = compile_with_context("He loves her.", &mut ctx).unwrap();
        assert!(
            (result.contains("Agent(e, John)") && result.contains("Theme(e, Mary)"))
                || result.contains("(John, Mary)")
                || result.contains("(John,Mary)"),
            "He->John, her->Mary: got '{}'",
            result
        );
    }

    #[test]
    fn discourse_definite_reference() {
        use crate::context::DiscourseContext;
        let mut ctx = DiscourseContext::new();
        compile_with_context("A dog barked.", &mut ctx).unwrap();
        let result = compile_with_context("The dog ran.", &mut ctx).unwrap();
        assert!(
            !result.contains("D2"),
            "The dog should refer to same entity, not D2: got '{}'",
            result
        );
    }

    #[test]
    fn discourse_plural_pronoun_they() {
        use crate::context::DiscourseContext;
        let mut ctx = DiscourseContext::new();
        compile_with_context("The dogs ran.", &mut ctx).unwrap();
        let result = compile_with_context("They barked.", &mut ctx).unwrap();
        assert!(
            result.contains("D"),
            "They should resolve to dogs: got '{}'",
            result
        );
    }

    #[test]
    fn discourse_object_pronoun_him() {
        use crate::context::DiscourseContext;
        let mut ctx = DiscourseContext::new();
        compile_with_context("John entered.", &mut ctx).unwrap();
        let result = compile_with_context("Mary saw him.", &mut ctx).unwrap();
        assert!(
            (result.contains("Agent(e, Mary)") && result.contains("Theme(e, John)"))
                || result.contains("(Mary, John)"),
            "him should resolve to John: got '{}'",
            result
        );
    }

    #[test]
    fn compile_discourse_batch() {
        let result = compile_discourse(&["John ran.", "He stopped."]).unwrap();
        assert!(
            result.contains("J") && result.contains("∧"),
            "Batch compile should conjoin and resolve: got '{}'",
            result
        );
    }

    // ═══════════════════════════════════════════════════════════════════
    // Phase 2: Recursive Relative Clauses (TDD RED)
    // ═══════════════════════════════════════════════════════════════════

    #[test]
    fn relative_clause_object_gap() {
        // "The cat that the dog chased ran."
        // The cat is the OBJECT of "chased" (gap), not the subject
        let result = compile("The cat that the dog chased ran.").unwrap();
        // Structure: ∃x(Cat(x) ∧ Chase(Dog, x) ∧ Ran(x))
        assert!(
            result.contains("Theme(e, x)") && result.contains("Cat(x)"),
            "Object-gap relative: dog chases cat, cat ran: got '{}'",
            result
        );
    }

    #[test]
    fn relative_clause_who_subject() {
        // "The man who loves Mary left."
        // "who" = subject of "loves"
        let result = compile("The man who loves Mary left.").unwrap();
        // Structure: ∃x(Man(x) ∧ Love(x, Mary) ∧ Left(x))
        assert!(
            result.contains("(x, Mary)") && result.contains("Man(x)"),
            "Who-clause should bind subject: got '{}'",
            result
        );
    }

    #[test]
    fn relative_clause_who_object() {
        // "The man who Mary loves left."
        // "who" = object of "loves"
        let result = compile("The man who Mary loves left.").unwrap();
        // Structure: ∃x(Man(x) ∧ Love(e) ∧ Agent(e, M) ∧ Theme(e, x) ∧ Left(x))
        // Uses neo-event semantics with Agent/Theme roles
        assert!(
            (result.contains("Agent(e, M") || result.contains("(Mary"))
                && result.contains("Theme(e, x)")
                && result.contains("Man(x)"),
            "Who as object: Mary loves the man: got '{}'",
            result
        );
    }

    #[test]
    fn nested_relative_clause() {
        // "The rat that the cat that the dog chased ate died."
        // dog chased cat, cat ate rat, rat died
        let result = compile("The rat that the cat that the dog chased ate died.").unwrap();
        assert!(
            result.contains("D(") || result.contains("Die(") || result.contains("Died("),
            "Nested relatives should parse: got '{}'",
            result
        );
    }

    #[test]
    fn relative_clause_with_transitive() {
        // "The book that John read is good."
        let result = compile("The book that John read is good.").unwrap();
        assert!(
            result.contains("Agent(e, John)") && result.contains("Theme(e, x)"),
            "Book is object of read: got '{}'",
            result
        );
    }

    // ═══════════════════════════════════════════════════════════════════
    // Phase 3: Generalized Quantifiers (TDD RED)
    // ═══════════════════════════════════════════════════════════════════

    #[test]
    fn quantifier_most() {
        let result = compile("Most dogs bark.").unwrap();
        assert!(
            result.contains("MOST") && result.contains("Dogs(x)") && result.contains("Bark(x)"),
            "Most should produce MOST x(Dogs(x), Bark(x)): got '{}'",
            result
        );
    }

    #[test]
    fn quantifier_few() {
        let result = compile("Few cats swim.").unwrap();
        assert!(
            result.contains("FEW") && result.contains("Cats(x)") && result.contains("Swim(x)"),
            "Few should produce FEW x(Cats(x), Swim(x)): got '{}'",
            result
        );
    }

    #[test]
    fn quantifier_cardinal_three() {
        let result = compile("Three dogs bark.").unwrap();
        assert!(
            result.contains("∃≥3") || result.contains("∃=3"),
            "Three should produce cardinal quantifier: got '{}'",
            result
        );
    }

    #[test]
    fn quantifier_at_least_two() {
        let result = compile("At least two birds fly.").unwrap();
        assert!(
            result.contains("∃≥2"),
            "At least two should produce ∃≥2: got '{}'",
            result
        );
    }

    #[test]
    fn quantifier_at_most_five() {
        let result = compile("At most five cats sleep.").unwrap();
        assert!(
            result.contains("∃≤5"),
            "At most five should produce ∃≤5: got '{}'",
            result
        );
    }

    // ═══════════════════════════════════════════════════════════════════
    // Phase 4: Wh-Questions (TDD RED)
    // ═══════════════════════════════════════════════════════════════════

    #[test]
    fn wh_question_who_subject() {
        let result = compile("Who loves Mary?").unwrap();
        assert!(
            result.contains("λx") && result.contains("Love(x, Mary)"),
            "Who-subject should produce λx.Love(x, Mary): got '{}'",
            result
        );
    }

    #[test]
    fn wh_question_what_object() {
        let result = compile("What does John love?").unwrap();
        assert!(
            result.contains("λx") && result.contains("Love(John, x)"),
            "What-object should produce λx.Love(John, x): got '{}'",
            result
        );
    }

    #[test]
    fn yes_no_question() {
        let result = compile("Does John love Mary?").unwrap();
        assert!(
            result.contains("?") || result.contains("L(J, M)"),
            "Yes/no question should produce query: got '{}'",
            result
        );
    }

    // ═══════════════════════════════════════════════════════════════════
    // Phase 5: Passive Voice (TDD RED)
    // ═══════════════════════════════════════════════════════════════════

    #[test]
    fn passive_with_agent() {
        let result = compile("Mary was loved by John.").unwrap();
        assert!(
            result.contains("Love(John, Mary)"),
            "Passive 'Mary was loved by John' should produce Love(John, Mary): got '{}'",
            result
        );
    }

    #[test]
    fn passive_without_agent() {
        let result = compile("The book was read.").unwrap();
        assert!(
            result.contains("∃") && result.contains("Read("),
            "Agentless passive should produce ∃x.Read(x, Book): got '{}'",
            result
        );
    }
}

```

---

## Linguistic Data

Dictionary and semantic information for word classification.

**Location:** `src/lexicon.rs`

### Lexicon

**File:** `src/lexicon.rs`

Feature-based lexical database. Feature enum (22 variants) classifies words by transitivity (Transitive, Intransitive, Ditransitive), control theory (SubjectControl, ObjectControl, Raising), semantics (Opaque, Factive, Performative, Collective), noun properties (Count, Mass, Proper, Masculine, Feminine, Neuter, Animate, Inanimate), and adjective types (Intersective, Subsective, NonIntersective, Gradable). Subsective adjectives use intension (^Noun) for class-relative predicates like 'small elephant' → S(x, ^E). VerbClass enum implements Vendler's Aktionsart with is_stative()/is_durative()/is_telic(). Metadata structs (VerbMetadata, NounMetadata, AdjectiveMetadata) provide lemma plus feature arrays. Generated lookup functions (lookup_verb_db, lookup_noun_db, lookup_adjective_db) return full metadata at runtime. is_subsective() generated check for adjective type. **Zero-Derivation Morphology:** Consonant cluster heuristic (vowel + consonant + l/r) recovers silent-e lemmas: 'tabled' → 'table', 'googled' → 'google'. **Phase 11 Sort System:** Sort enum (Human, Animate, Celestial, Abstract, Physical, Value) for ontological type hierarchy. lookup_sort() returns Sort for proper names. is_compatible_with() checks sort subsumption (Human⊂Animate⊂Physical). Used for metaphor detection via sort violations ('Juliet is the sun' violates Human/Celestial compatibility).

```rust
include!(concat!(env!("OUT_DIR"), "/lexicon_data.rs"));

/// Get canonical verb form and whether it's lexically negative.
/// Used at parse time to transform "lacks" → ("Have", true).
/// Returns (canonical_lemma, is_negative).
pub fn get_canonical_verb(lemma: &str) -> Option<(&'static str, bool)> {
    lookup_canonical(lemma).map(|m| (m.lemma, m.polarity == Polarity::Negative))
}

/// Feature-based lexical properties
/// Words can have multiple overlapping features
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum Feature {
    // Verb Transitivity
    Transitive,
    Intransitive,
    Ditransitive,

    // Control Theory
    SubjectControl, // "I want to run"
    ObjectControl,  // "I persuaded him to run"
    Raising,        // "He seems to run"

    // Semantics
    Opaque,      // "I seek a unicorn" (De Dicto/De Re ambiguity)
    Factive,     // "I know that..." (Presupposes truth)
    Performative, // "I promise"
    Collective,  // "The group gathered"
    Mixed,       // "Lift" - can be collective or distributive
    Weather,     // "Rain", "Snow" - weather verbs with expletive "it"
    Unaccusative, // "The door opens" - intransitive subject is Theme, not Agent

    // Noun Features
    Count,
    Mass,
    Proper, // Proper Name

    // Gender
    Masculine,
    Feminine,
    Neuter,

    // Animacy
    Animate,
    Inanimate,

    // Adjective Features
    Intersective,    // "Red ball" -> Red(x) AND Ball(x)
    NonIntersective, // "Fake gun" -> Fake(Gun)
    Subsective,      // "Small elephant" -> Small(x, ^Elephant)
    Gradable,        // "Tall", "Taller"
    EventModifier,   // "Beautiful dancer" -> can modify dancing event
}

impl Feature {
    pub fn from_str(s: &str) -> Option<Feature> {
        match s {
            "Transitive" => Some(Feature::Transitive),
            "Intransitive" => Some(Feature::Intransitive),
            "Ditransitive" => Some(Feature::Ditransitive),
            "SubjectControl" => Some(Feature::SubjectControl),
            "ObjectControl" => Some(Feature::ObjectControl),
            "Raising" => Some(Feature::Raising),
            "Opaque" => Some(Feature::Opaque),
            "Factive" => Some(Feature::Factive),
            "Performative" => Some(Feature::Performative),
            "Collective" => Some(Feature::Collective),
            "Weather" => Some(Feature::Weather),
            "Unaccusative" => Some(Feature::Unaccusative),
            "Count" => Some(Feature::Count),
            "Mass" => Some(Feature::Mass),
            "Proper" => Some(Feature::Proper),
            "Masculine" => Some(Feature::Masculine),
            "Feminine" => Some(Feature::Feminine),
            "Neuter" => Some(Feature::Neuter),
            "Animate" => Some(Feature::Animate),
            "Inanimate" => Some(Feature::Inanimate),
            "Intersective" => Some(Feature::Intersective),
            "NonIntersective" => Some(Feature::NonIntersective),
            "Subsective" => Some(Feature::Subsective),
            "Gradable" => Some(Feature::Gradable),
            "EventModifier" => Some(Feature::EventModifier),
            _ => None,
        }
    }
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum Sort {
    Entity,
    Physical,
    Animate,
    Human,
    Plant,
    Place,
    Time,
    Abstract,
    Information,
    Event,
    Celestial,
    Value,
    Group,
}

impl Sort {
    pub fn is_compatible_with(self, other: Sort) -> bool {
        if self == other {
            return true;
        }
        match (self, other) {
            (Sort::Human, Sort::Animate) => true,
            (Sort::Plant, Sort::Animate) => true,
            (Sort::Animate, Sort::Physical) => true,
            (Sort::Human, Sort::Physical) => true,
            (Sort::Plant, Sort::Physical) => true,
            (_, Sort::Entity) => true,
            _ => false,
        }
    }
}

/// Vendler's Lexical Aspect Classes (Aktionsart)
///
/// Classification based on three binary features:
/// - Static: Does the predicate involve change?
/// - Durative: Does the predicate extend over time?
/// - Telic: Does the predicate have a natural endpoint?
#[derive(Debug, Clone, Copy, PartialEq, Eq, Default, Hash)]
pub enum VerbClass {
    /// +static, +durative, -telic: know, love, exist
    State,
    /// -static, +durative, -telic: run, swim, drive
    #[default]
    Activity,
    /// -static, +durative, +telic: build, draw, write
    Accomplishment,
    /// -static, -durative, +telic: win, find, die
    Achievement,
    /// -static, -durative, -telic: knock, cough, blink
    Semelfactive,
}

impl VerbClass {
    /// Returns true if this verb class is stative (+static)
    pub fn is_stative(&self) -> bool {
        matches!(self, VerbClass::State)
    }

    /// Returns true if this verb class is durative (+durative)
    pub fn is_durative(&self) -> bool {
        matches!(
            self,
            VerbClass::State | VerbClass::Activity | VerbClass::Accomplishment
        )
    }

    /// Returns true if this verb class is telic (+telic)
    pub fn is_telic(&self) -> bool {
        matches!(self, VerbClass::Accomplishment | VerbClass::Achievement)
    }
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum Time {
    Past,
    Present,
    Future,
    None,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum Aspect {
    Simple,
    Progressive,
    Perfect,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum Definiteness {
    Definite,
    Indefinite,
    Proximal,
    Distal,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum Number {
    Singular,
    Plural,
}

#[derive(Debug, Clone, PartialEq, Eq)]
pub struct VerbEntry {
    pub lemma: String,
    pub time: Time,
    pub aspect: Aspect,
    pub class: VerbClass,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub struct VerbMetadata {
    pub lemma: &'static str,
    pub class: VerbClass,
    pub time: Time,
    pub aspect: Aspect,
    pub features: &'static [Feature],
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub struct NounMetadata {
    pub lemma: &'static str,
    pub number: Number,
    pub features: &'static [Feature],
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub struct AdjectiveMetadata {
    pub lemma: &'static str,
    pub features: &'static [Feature],
}

pub struct Lexicon {}

impl Lexicon {
    pub fn new() -> Self {
        Lexicon {}
    }

    pub fn lookup_verb(&self, word: &str) -> Option<VerbEntry> {
        let lower = word.to_lowercase();

        if let Some(entry) = lookup_irregular_verb(&lower) {
            return Some(entry);
        }

        if lower.ends_with("ing") {
            let stem = self.strip_ing(&lower);
            let lemma = Self::capitalize(&stem);
            let class = self.lookup_verb_class(&lemma.to_lowercase());
            return Some(VerbEntry {
                lemma,
                time: Time::None,
                aspect: Aspect::Progressive,
                class,
            });
        }

        if lower.ends_with("ed") {
            let stem = self.strip_ed(&lower);
            let lemma = Self::capitalize(&stem);
            let class = self.lookup_verb_class(&lemma.to_lowercase());
            return Some(VerbEntry {
                lemma,
                time: Time::Past,
                aspect: Aspect::Simple,
                class,
            });
        }

        let is_third_person = if lower.ends_with("es") && lower.len() > 2 {
            true
        } else if lower.ends_with("s") && !lower.ends_with("ss") && lower.len() > 2 {
            true
        } else {
            false
        };

        if is_third_person {
            if is_stemming_exception(&lower) {
                return None;
            }

            let stem = self.strip_s(&lower);
            if !is_base_verb(&stem) {
                return None;
            }
            let lemma = Self::capitalize(&stem);
            let class = self.lookup_verb_class(&lemma.to_lowercase());
            return Some(VerbEntry {
                lemma,
                time: Time::Present,
                aspect: Aspect::Simple,
                class,
            });
        }

        // Check if this is a base verb form
        if is_base_verb(&lower) {
            let lemma = Self::capitalize(&lower);
            let class = self.lookup_verb_class(&lower);
            return Some(VerbEntry {
                lemma,
                time: Time::Present,
                aspect: Aspect::Simple,
                class,
            });
        }

        None
    }

    fn lookup_verb_class(&self, lemma: &str) -> VerbClass {
        lookup_verb_class(lemma)
    }

    fn strip_ing(&self, word: &str) -> String {
        let base = &word[..word.len() - 3];

        if base.len() >= 2 {
            let chars: Vec<char> = base.chars().collect();
            let last = chars[chars.len() - 1];
            let second_last = chars[chars.len() - 2];

            if last == second_last && !"aeiou".contains(last) {
                return base[..base.len() - 1].to_string();
            }
        }

        if needs_e_ing(base) {
            return format!("{}e", base);
        }

        base.to_string()
    }

    fn strip_ed(&self, word: &str) -> String {
        let base = &word[..word.len() - 2];

        if base.ends_with("i") {
            return format!("{}y", &base[..base.len() - 1]);
        }

        if base.len() >= 2 {
            let chars: Vec<char> = base.chars().collect();
            let last = chars[chars.len() - 1];
            let second_last = chars[chars.len() - 2];

            if last == second_last && !"aeiou".contains(last) {
                return base[..base.len() - 1].to_string();
            }

            // Consonant clusters that typically come from silent-e verbs:
            // "tabled" → "tabl" needs "e", "googled" → "googl" needs "e"
            // Pattern: consonant + l/r at end, with vowel before the consonant
            if (last == 'l' || last == 'r') && !"aeiou".contains(second_last) {
                if chars.len() >= 3 && "aeiou".contains(chars[chars.len() - 3]) {
                    return format!("{}e", base);
                }
            }
        }

        if needs_e_ed(base) {
            return format!("{}e", base);
        }

        base.to_string()
    }

    fn strip_s(&self, word: &str) -> String {
        if word.ends_with("ies") {
            return format!("{}y", &word[..word.len() - 3]);
        }
        // For verbs ending in silent 'e': hopes → hope, decides → decide
        // These add "s" not "es", so stripping just "s" gives correct lemma
        if word.ends_with("es") {
            let base_minus_es = &word[..word.len() - 2];
            let base_minus_s = &word[..word.len() - 1];
            // If base-1 ends in 'e', probably a silent-e verb: hopes → hope
            if base_minus_s.ends_with('e') {
                return base_minus_s.to_string();
            }
            // Otherwise it's a sibilant ending: watches → watch, fixes → fix
            return base_minus_es.to_string();
        }
        word[..word.len() - 1].to_string()
    }

    fn capitalize(s: &str) -> String {
        let mut chars = s.chars();
        match chars.next() {
            None => String::new(),
            Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
        }
    }
}

impl Default for Lexicon {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn feature_from_str_ditransitive() {
        assert_eq!(
            Feature::from_str("Ditransitive"),
            Some(Feature::Ditransitive)
        );
    }

    #[test]
    fn feature_from_str_subject_control() {
        assert_eq!(
            Feature::from_str("SubjectControl"),
            Some(Feature::SubjectControl)
        );
    }

    #[test]
    fn feature_from_str_opaque() {
        assert_eq!(Feature::from_str("Opaque"), Some(Feature::Opaque));
    }

    #[test]
    fn feature_from_str_unknown() {
        assert_eq!(Feature::from_str("Unknown"), None);
    }

    #[test]
    fn irregular_past_ran() {
        let lex = Lexicon::new();
        let entry = lex.lookup_verb("ran").unwrap();
        assert_eq!(entry.lemma, "Run");
        assert_eq!(entry.time, Time::Past);
        assert_eq!(entry.aspect, Aspect::Simple);
    }

    #[test]
    fn irregular_progressive_running() {
        let lex = Lexicon::new();
        let entry = lex.lookup_verb("running").unwrap();
        assert_eq!(entry.lemma, "Run");
        assert_eq!(entry.time, Time::None);
        assert_eq!(entry.aspect, Aspect::Progressive);
    }

    #[test]
    fn regular_past_jumped() {
        let lex = Lexicon::new();
        let entry = lex.lookup_verb("jumped").unwrap();
        assert_eq!(entry.lemma, "Jump");
        assert_eq!(entry.time, Time::Past);
    }

    #[test]
    fn regular_present_runs() {
        let lex = Lexicon::new();
        let entry = lex.lookup_verb("runs").unwrap();
        assert_eq!(entry.lemma, "Run");
        assert_eq!(entry.time, Time::Present);
    }

    #[test]
    fn present_silent_e_hopes() {
        let lex = Lexicon::new();
        let entry = lex.lookup_verb("hopes").unwrap();
        assert_eq!(entry.lemma, "Hope");
        assert_eq!(entry.time, Time::Present);
    }

    #[test]
    fn present_silent_e_decides() {
        let lex = Lexicon::new();
        let entry = lex.lookup_verb("decides").unwrap();
        assert_eq!(entry.lemma, "Decide");
        assert_eq!(entry.time, Time::Present);
    }

    #[test]
    fn present_silent_e_convinces() {
        let lex = Lexicon::new();
        let entry = lex.lookup_verb("convinces").unwrap();
        assert_eq!(entry.lemma, "Convince");
        assert_eq!(entry.time, Time::Present);
    }

    #[test]
    fn past_silent_e_decided() {
        let lex = Lexicon::new();
        let entry = lex.lookup_verb("decided").unwrap();
        assert_eq!(entry.lemma, "Decide");
        assert_eq!(entry.time, Time::Past);
    }

    #[test]
    fn regular_progressive_jumping() {
        let lex = Lexicon::new();
        let entry = lex.lookup_verb("jumping").unwrap();
        assert_eq!(entry.lemma, "Jump");
        assert_eq!(entry.aspect, Aspect::Progressive);
    }

    #[test]
    fn regular_present_barks() {
        let lex = Lexicon::new();
        let entry = lex.lookup_verb("barks").unwrap();
        assert_eq!(entry.lemma, "Bark");
        assert_eq!(entry.time, Time::Present);
    }

    #[test]
    fn verb_db_returns_metadata_with_features() {
        let meta = lookup_verb_db("give").unwrap();
        assert_eq!(meta.lemma, "Give");
        assert_eq!(meta.class, VerbClass::Achievement);
        assert!(meta.features.contains(&Feature::Ditransitive));
    }

    #[test]
    fn verb_db_irregular_past() {
        let meta = lookup_verb_db("ran").unwrap();
        assert_eq!(meta.lemma, "Run");
        assert_eq!(meta.time, Time::Past);
    }

    #[test]
    fn verb_db_opaque_verb_has_feature() {
        let meta = lookup_verb_db("seek").unwrap();
        assert_eq!(meta.lemma, "Seek");
        assert!(meta.features.contains(&Feature::Opaque));
    }

    #[test]
    fn noun_db_returns_metadata() {
        let meta = lookup_noun_db("dog").unwrap();
        assert_eq!(meta.lemma, "Dog");
        assert_eq!(meta.number, Number::Singular);
    }

    #[test]
    fn noun_db_plural_form() {
        let meta = lookup_noun_db("men").unwrap();
        assert_eq!(meta.lemma, "Man");
        assert_eq!(meta.number, Number::Plural);
    }

    #[test]
    fn noun_db_proper_name_has_features() {
        let meta = lookup_noun_db("john").unwrap();
        assert_eq!(meta.lemma, "John");
        assert!(meta.features.contains(&Feature::Proper));
        assert!(meta.features.contains(&Feature::Masculine));
    }

    #[test]
    fn adjective_db_returns_metadata() {
        let meta = lookup_adjective_db("fake").unwrap();
        assert_eq!(meta.lemma, "Fake");
        assert!(meta.features.contains(&Feature::NonIntersective));
    }

    #[test]
    fn adjective_db_gradable() {
        let meta = lookup_adjective_db("tall").unwrap();
        assert_eq!(meta.lemma, "Tall");
        assert!(meta.features.contains(&Feature::Gradable));
    }
}

```

---

### Multi-Word Expressions

**File:** `src/mwe.rs`

Post-tokenization MWE pipeline (Phase 13). MweTrie for pattern storage with longest-match lookup. apply_mwe_pipeline() collapses multi-token sequences into single semantic units. Handles compound nouns (fire engine → FireEngine), idioms (kicked the bucket → Die), and phrasal verbs (gave up → Surrender). Inherits tense from head token for morphological variants. build_mwe_trie() creates default vocabulary with common MWEs.

```rust
//! Multi-Word Expression (MWE) processing
//!
//! Post-tokenization pipeline that collapses multi-token sequences
//! into single semantic units (e.g., "fire engine" -> FireEngine).

use std::collections::HashMap;
use crate::token::{Token, TokenType};
use crate::lexicon::{VerbClass, Time, Aspect};
use crate::intern::Interner;

#[derive(Debug, Clone)]
pub struct MweTarget {
    pub lemma: &'static str,
    pub pos: &'static str,
    pub class: Option<VerbClass>,
}

#[derive(Default, Debug)]
pub struct MweTrie {
    pub children: HashMap<String, MweTrie>,
    pub target: Option<MweTarget>,
}

impl MweTrie {
    pub fn insert(&mut self, pattern: &[&str], target: MweTarget) {
        if pattern.is_empty() {
            self.target = Some(target);
            return;
        }
        self.children
            .entry(pattern[0].to_lowercase())
            .or_default()
            .insert(&pattern[1..], target);
    }
}

/// Apply MWE collapsing to a token stream.
/// Matches on lemmas (not raw strings) to handle morphological variants.
pub fn apply_mwe_pipeline(
    tokens: Vec<Token>,
    trie: &MweTrie,
    interner: &mut Interner,
) -> Vec<Token> {
    let mut result = Vec::new();
    let mut i = 0;

    while i < tokens.len() {
        if let Some((match_len, target)) = find_longest_match(&tokens[i..], trie, interner) {
            let merged = create_merged_token(&tokens[i], target, interner);
            result.push(merged);
            i += match_len;
        } else {
            result.push(tokens[i].clone());
            i += 1;
        }
    }
    result
}

/// Extract lemma from a token for MWE matching.
/// Uses lowercase for case-insensitive matching.
fn get_lemma(token: &Token, interner: &Interner) -> String {
    match &token.kind {
        TokenType::Verb { lemma, .. } => interner.resolve(*lemma).to_lowercase(),
        TokenType::Noun(sym) => interner.resolve(*sym).to_lowercase(),
        TokenType::Adjective(sym) => interner.resolve(*sym).to_lowercase(),
        TokenType::NonIntersectiveAdjective(sym) => interner.resolve(*sym).to_lowercase(),
        TokenType::Preposition(sym) => interner.resolve(*sym).to_lowercase(),
        TokenType::Particle(sym) => interner.resolve(*sym).to_lowercase(),
        TokenType::Article(_) => interner.resolve(token.lexeme).to_lowercase(),
        _ => interner.resolve(token.lexeme).to_lowercase(),
    }
}

/// Find the longest MWE match starting at the beginning of the token slice.
fn find_longest_match<'a>(
    tokens: &[Token],
    trie: &'a MweTrie,
    interner: &Interner,
) -> Option<(usize, &'a MweTarget)> {
    let mut node = trie;
    let mut best: Option<(usize, &MweTarget)> = None;

    for (i, token) in tokens.iter().enumerate() {
        let lemma = get_lemma(token, interner);
        if let Some(child) = node.children.get(&lemma) {
            node = child;
            if let Some(target) = &node.target {
                best = Some((i + 1, target));
            }
        } else {
            break;
        }
    }
    best
}

/// Create a merged token from the MWE target, inheriting tense from the head token.
fn create_merged_token(head: &Token, target: &MweTarget, interner: &mut Interner) -> Token {
    let lemma_sym = interner.intern(target.lemma);

    let kind = match target.pos {
        "Noun" => TokenType::Noun(lemma_sym),
        "Verb" => {
            let (time, aspect) = match &head.kind {
                TokenType::Verb { time, aspect, .. } => (*time, *aspect),
                _ => (Time::Present, Aspect::Simple),
            };
            TokenType::Verb {
                lemma: lemma_sym,
                time,
                aspect,
                class: target.class.unwrap_or(VerbClass::Activity),
            }
        }
        "Preposition" => TokenType::Preposition(lemma_sym),
        "Conjunction" => TokenType::And,
        "Quantifier" => TokenType::NoOne,
        _ => TokenType::Noun(lemma_sym),
    };

    Token {
        kind,
        lexeme: lemma_sym,
        span: head.span,
    }
}

include!(concat!(env!("OUT_DIR"), "/mwe_data.rs"));

```

---

### Ontology Module

**File:** `src/ontology.rs`

Bridging anaphora and sort checking (Phase 14). find_bridging_wholes() returns possible whole objects for parts (e.g., 'engine' → ['car', 'plane']). check_sort_compatibility() validates predicate-subject sort match for metaphor detection. required_sort() gets predicate's required sort. Uses generated ontology_data.rs from build.rs with part-whole mappings and predicate sort requirements.

```rust
//! Ontology module for bridging anaphora and sort compatibility checking.
//!
//! This module provides:
//! - Part-whole relationship lookup for bridging anaphora resolution
//! - Predicate sort requirements for metaphor detection

use crate::lexicon::Sort;

include!(concat!(env!("OUT_DIR"), "/ontology_data.rs"));

/// Find possible whole objects for a given part noun.
/// Returns None if the noun is not a known part of any whole.
pub fn find_bridging_wholes(part_noun: &str) -> Option<&'static [&'static str]> {
    let wholes = get_possible_wholes(&part_noun.to_lowercase());
    if wholes.is_empty() {
        None
    } else {
        Some(wholes)
    }
}

/// Check if a predicate is compatible with a subject's sort.
/// Returns true if compatible or no sort requirement exists.
pub fn check_sort_compatibility(predicate: &str, subject_sort: Sort) -> bool {
    match get_predicate_sort(&predicate.to_lowercase()) {
        Some(required) => subject_sort.is_compatible_with(required),
        None => true,
    }
}

/// Get the required sort for a predicate, if any.
pub fn required_sort(predicate: &str) -> Option<Sort> {
    get_predicate_sort(&predicate.to_lowercase())
}

```

---

## Memory Management

Efficient memory allocation strategies for AST construction.

**Location:** `src/intern.rs`, `src/arena.rs`

### Symbol Interning

**File:** `src/intern.rs`

Interner and Symbol types for efficient string storage. Enables O(1) symbol comparisons and reduced memory footprint.

```rust
use std::collections::HashMap;

#[derive(Clone, Copy, PartialEq, Eq, Hash, Debug)]
pub struct Symbol(u32);

impl Symbol {
    pub const EMPTY: Symbol = Symbol(0);

    pub fn index(self) -> usize {
        self.0 as usize
    }
}

impl Default for Symbol {
    fn default() -> Self {
        Self::EMPTY
    }
}

pub struct Interner {
    map: HashMap<String, Symbol>,
    vec: Vec<String>,
}

impl Interner {
    pub fn new() -> Self {
        let mut interner = Interner {
            map: HashMap::new(),
            vec: Vec::new(),
        };
        interner.vec.push(String::new());
        interner
    }

    pub fn intern(&mut self, s: &str) -> Symbol {
        if let Some(&sym) = self.map.get(s) {
            return sym;
        }
        let sym = Symbol(self.vec.len() as u32);
        self.vec.push(s.to_string());
        self.map.insert(s.to_string(), sym);
        sym
    }

    pub fn resolve(&self, sym: Symbol) -> &str {
        &self.vec[sym.0 as usize]
    }

    pub fn len(&self) -> usize {
        self.vec.len()
    }

    pub fn is_empty(&self) -> bool {
        self.vec.len() <= 1
    }
}

impl Default for Interner {
    fn default() -> Self {
        Self::new()
    }
}

pub trait SymbolEq {
    fn is(&self, interner: &Interner, s: &str) -> bool;
}

impl SymbolEq for Symbol {
    #[inline]
    fn is(&self, interner: &Interner, s: &str) -> bool {
        interner.resolve(*self) == s
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn intern_returns_same_symbol_for_same_string() {
        let mut interner = Interner::new();
        let s1 = interner.intern("hello");
        let s2 = interner.intern("hello");
        assert_eq!(s1, s2);
    }

    #[test]
    fn intern_returns_different_symbols_for_different_strings() {
        let mut interner = Interner::new();
        let s1 = interner.intern("hello");
        let s2 = interner.intern("world");
        assert_ne!(s1, s2);
    }

    #[test]
    fn resolve_returns_original_string() {
        let mut interner = Interner::new();
        let sym = interner.intern("test");
        assert_eq!(interner.resolve(sym), "test");
    }

    #[test]
    fn empty_symbol_resolves_to_empty_string() {
        let interner = Interner::new();
        assert_eq!(interner.resolve(Symbol::EMPTY), "");
    }

    #[test]
    fn symbols_are_copy() {
        let mut interner = Interner::new();
        let s1 = interner.intern("copy_test");
        let s2 = s1;
        assert_eq!(s1, s2);
        assert_eq!(interner.resolve(s1), interner.resolve(s2));
    }

    #[test]
    fn symbol_equality_is_fast() {
        let mut interner = Interner::new();
        let s1 = interner.intern("a_very_long_string_that_would_be_slow_to_compare");
        let s2 = interner.intern("a_very_long_string_that_would_be_slow_to_compare");
        assert_eq!(s1, s2);
    }

    #[test]
    fn len_tracks_interned_count() {
        let mut interner = Interner::new();
        assert_eq!(interner.len(), 1);
        interner.intern("first");
        assert_eq!(interner.len(), 2);
        interner.intern("second");
        assert_eq!(interner.len(), 3);
        interner.intern("first");
        assert_eq!(interner.len(), 3);
    }

    #[test]
    fn is_empty_after_new() {
        let interner = Interner::new();
        assert!(interner.is_empty());
    }

    #[test]
    fn not_empty_after_intern() {
        let mut interner = Interner::new();
        interner.intern("something");
        assert!(!interner.is_empty());
    }

    #[test]
    fn symbol_index_matches_position() {
        let mut interner = Interner::new();
        let s1 = interner.intern("first");
        let s2 = interner.intern("second");
        assert_eq!(s1.index(), 1);
        assert_eq!(s2.index(), 2);
    }

    #[test]
    fn symbol_is_matches_interned_string() {
        let mut interner = Interner::new();
        let sym = interner.intern("test");
        assert!(sym.is(&interner, "test"));
    }

    #[test]
    fn symbol_is_rejects_different_string() {
        let mut interner = Interner::new();
        let sym = interner.intern("hello");
        assert!(!sym.is(&interner, "world"));
    }

    #[test]
    fn symbol_is_case_sensitive() {
        let mut interner = Interner::new();
        let sym = interner.intern("Test");
        assert!(!sym.is(&interner, "test"));
        assert!(sym.is(&interner, "Test"));
    }

    #[test]
    fn symbol_empty_is_empty_string() {
        let interner = Interner::new();
        assert!(Symbol::EMPTY.is(&interner, ""));
    }
}

```

---

### Arena Allocation

**File:** `src/arena.rs`

Bumpalo-based arena allocator for AST nodes. Provides fast allocation with batch deallocation.

```rust
use bumpalo::Bump;

pub struct Arena<T> {
    bump: Bump,
    _marker: std::marker::PhantomData<T>,
}

impl<T> Arena<T> {
    pub fn new() -> Self {
        Arena {
            bump: Bump::new(),
            _marker: std::marker::PhantomData,
        }
    }

    pub fn alloc(&self, value: T) -> &T {
        self.bump.alloc(value)
    }

    pub fn alloc_slice<I>(&self, items: I) -> &[T]
    where
        I: IntoIterator<Item = T>,
        I::IntoIter: ExactSizeIterator,
    {
        self.bump.alloc_slice_fill_iter(items)
    }

    /// Resets the arena, invalidating all references but keeping allocated capacity.
    /// This enables zero-allocation REPL loops by reusing memory.
    pub fn reset(&mut self) {
        self.bump.reset();
    }
}

impl<T> Default for Arena<T> {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn alloc_returns_stable_reference() {
        let arena: Arena<i32> = Arena::new();
        let r1 = arena.alloc(42);
        let r2 = arena.alloc(100);
        assert_eq!(*r1, 42);
        assert_eq!(*r2, 100);
    }

    #[test]
    fn references_remain_valid_after_many_allocations() {
        let arena: Arena<i32> = Arena::new();
        let refs: Vec<&i32> = (0..10000).map(|i| arena.alloc(i)).collect();
        for (i, r) in refs.iter().enumerate() {
            assert_eq!(**r, i as i32);
        }
    }

    #[test]
    fn works_with_structs() {
        #[derive(Debug, PartialEq)]
        struct Point {
            x: i32,
            y: i32,
        }

        let arena: Arena<Point> = Arena::new();
        let p1 = arena.alloc(Point { x: 1, y: 2 });
        let p2 = arena.alloc(Point { x: 3, y: 4 });
        assert_eq!(p1, &Point { x: 1, y: 2 });
        assert_eq!(p2, &Point { x: 3, y: 4 });
    }

    #[test]
    fn alloc_slice_works() {
        let arena: Arena<i32> = Arena::new();
        let slice = arena.alloc_slice([1, 2, 3]);
        assert_eq!(slice, &[1, 2, 3]);
    }

    #[test]
    fn alloc_slice_from_vec() {
        let arena: Arena<i32> = Arena::new();
        let vec = vec![10, 20, 30];
        let slice = arena.alloc_slice(vec);
        assert_eq!(slice, &[10, 20, 30]);
    }

    #[test]
    fn alloc_empty_slice() {
        let arena: Arena<i32> = Arena::new();
        let empty: Vec<i32> = vec![];
        let slice = arena.alloc_slice(empty);
        assert!(slice.is_empty());
    }
}

```

---

### AST Context

**File:** `src/arena_ctx.rs`

AstContext struct unifying 6 separate arenas into one Copy struct. Provides alloc_expr(), alloc_term(), alloc_slice() helpers for ergonomic AST construction. Fluent expression builders: binary(), unary(), quantifier(), temporal(), aspectual(), modal() with #[inline(always)].

```rust
use crate::arena::Arena;
use crate::ast::{AspectOperator, LogicExpr, ModalVector, NounPhrase, QuantifierKind, TemporalOperator, VoiceOperator, Term, ThematicRole, Stmt, Expr, TypeExpr};
use crate::intern::Symbol;
use crate::token::TokenType;

#[derive(Clone, Copy)]
pub struct AstContext<'a> {
    pub exprs: &'a Arena<LogicExpr<'a>>,
    pub terms: &'a Arena<Term<'a>>,
    pub nps: &'a Arena<NounPhrase<'a>>,
    pub syms: &'a Arena<Symbol>,
    pub roles: &'a Arena<(ThematicRole, Term<'a>)>,
    pub pps: &'a Arena<&'a LogicExpr<'a>>,
    pub stmts: Option<&'a Arena<Stmt<'a>>>,
    pub imperative_exprs: Option<&'a Arena<Expr<'a>>>,
    pub type_exprs: Option<&'a Arena<TypeExpr<'a>>>,
}

impl<'a> AstContext<'a> {
    pub fn new(
        exprs: &'a Arena<LogicExpr<'a>>,
        terms: &'a Arena<Term<'a>>,
        nps: &'a Arena<NounPhrase<'a>>,
        syms: &'a Arena<Symbol>,
        roles: &'a Arena<(ThematicRole, Term<'a>)>,
        pps: &'a Arena<&'a LogicExpr<'a>>,
    ) -> Self {
        AstContext { exprs, terms, nps, syms, roles, pps, stmts: None, imperative_exprs: None, type_exprs: None }
    }

    pub fn with_imperative(
        exprs: &'a Arena<LogicExpr<'a>>,
        terms: &'a Arena<Term<'a>>,
        nps: &'a Arena<NounPhrase<'a>>,
        syms: &'a Arena<Symbol>,
        roles: &'a Arena<(ThematicRole, Term<'a>)>,
        pps: &'a Arena<&'a LogicExpr<'a>>,
        stmts: &'a Arena<Stmt<'a>>,
        imperative_exprs: &'a Arena<Expr<'a>>,
    ) -> Self {
        AstContext { exprs, terms, nps, syms, roles, pps, stmts: Some(stmts), imperative_exprs: Some(imperative_exprs), type_exprs: None }
    }

    pub fn with_types(
        exprs: &'a Arena<LogicExpr<'a>>,
        terms: &'a Arena<Term<'a>>,
        nps: &'a Arena<NounPhrase<'a>>,
        syms: &'a Arena<Symbol>,
        roles: &'a Arena<(ThematicRole, Term<'a>)>,
        pps: &'a Arena<&'a LogicExpr<'a>>,
        stmts: &'a Arena<Stmt<'a>>,
        imperative_exprs: &'a Arena<Expr<'a>>,
        type_exprs: &'a Arena<TypeExpr<'a>>,
    ) -> Self {
        AstContext {
            exprs, terms, nps, syms, roles, pps,
            stmts: Some(stmts),
            imperative_exprs: Some(imperative_exprs),
            type_exprs: Some(type_exprs),
        }
    }

    pub fn alloc_stmt(&self, stmt: Stmt<'a>) -> &'a Stmt<'a> {
        self.stmts.expect("imperative arenas not initialized").alloc(stmt)
    }

    pub fn alloc_imperative_expr(&self, expr: Expr<'a>) -> &'a Expr<'a> {
        self.imperative_exprs.expect("imperative arenas not initialized").alloc(expr)
    }

    pub fn alloc_type_expr(&self, ty: TypeExpr<'a>) -> &'a TypeExpr<'a> {
        self.type_exprs.expect("type_exprs arena not initialized").alloc(ty)
    }

    pub fn alloc_type_exprs<I>(&self, types: I) -> &'a [TypeExpr<'a>]
    where
        I: IntoIterator<Item = TypeExpr<'a>>,
        I::IntoIter: ExactSizeIterator,
    {
        self.type_exprs.expect("type_exprs arena not initialized").alloc_slice(types)
    }

    pub fn alloc_expr(&self, expr: LogicExpr<'a>) -> &'a LogicExpr<'a> {
        self.exprs.alloc(expr)
    }

    pub fn alloc_term(&self, term: Term<'a>) -> &'a Term<'a> {
        self.terms.alloc(term)
    }

    pub fn alloc_terms<I>(&self, terms: I) -> &'a [Term<'a>]
    where
        I: IntoIterator<Item = Term<'a>>,
        I::IntoIter: ExactSizeIterator,
    {
        self.terms.alloc_slice(terms)
    }

    pub fn alloc_np(&self, np: NounPhrase<'a>) -> &'a NounPhrase<'a> {
        self.nps.alloc(np)
    }

    pub fn alloc_syms<I>(&self, syms: I) -> &'a [Symbol]
    where
        I: IntoIterator<Item = Symbol>,
        I::IntoIter: ExactSizeIterator,
    {
        self.syms.alloc_slice(syms)
    }

    pub fn alloc_roles<I>(&self, roles: I) -> &'a [(ThematicRole, Term<'a>)]
    where
        I: IntoIterator<Item = (ThematicRole, Term<'a>)>,
        I::IntoIter: ExactSizeIterator,
    {
        self.roles.alloc_slice(roles)
    }

    pub fn alloc_pps<I>(&self, pps: I) -> &'a [&'a LogicExpr<'a>]
    where
        I: IntoIterator<Item = &'a LogicExpr<'a>>,
        I::IntoIter: ExactSizeIterator,
    {
        self.pps.alloc_slice(pps)
    }

    pub fn predicate(&self, name: Symbol, args: &'a [Term<'a>]) -> &'a LogicExpr<'a> {
        self.exprs.alloc(LogicExpr::Predicate { name, args })
    }

    #[inline(always)]
    pub fn binary(&self, left: &'a LogicExpr<'a>, op: TokenType, right: &'a LogicExpr<'a>) -> &'a LogicExpr<'a> {
        self.exprs.alloc(LogicExpr::BinaryOp { left, op, right })
    }

    #[inline(always)]
    pub fn unary(&self, op: TokenType, operand: &'a LogicExpr<'a>) -> &'a LogicExpr<'a> {
        self.exprs.alloc(LogicExpr::UnaryOp { op, operand })
    }

    #[inline(always)]
    pub fn quantifier(&self, kind: QuantifierKind, variable: Symbol, body: &'a LogicExpr<'a>, island_id: u32) -> &'a LogicExpr<'a> {
        self.exprs.alloc(LogicExpr::Quantifier { kind, variable, body, island_id })
    }

    #[inline(always)]
    pub fn temporal(&self, operator: TemporalOperator, body: &'a LogicExpr<'a>) -> &'a LogicExpr<'a> {
        self.exprs.alloc(LogicExpr::Temporal { operator, body })
    }

    #[inline(always)]
    pub fn aspectual(&self, operator: AspectOperator, body: &'a LogicExpr<'a>) -> &'a LogicExpr<'a> {
        self.exprs.alloc(LogicExpr::Aspectual { operator, body })
    }

    #[inline(always)]
    pub fn voice(&self, operator: VoiceOperator, body: &'a LogicExpr<'a>) -> &'a LogicExpr<'a> {
        self.exprs.alloc(LogicExpr::Voice { operator, body })
    }

    #[inline(always)]
    pub fn modal(&self, vector: ModalVector, operand: &'a LogicExpr<'a>) -> &'a LogicExpr<'a> {
        self.exprs.alloc(LogicExpr::Modal { vector, operand })
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::ast::{QuantifierKind, TemporalOperator, AspectOperator, ModalVector, ModalDomain};
    use crate::intern::Interner;
    use crate::token::TokenType;

    fn setup<'a>(
        expr_arena: &'a Arena<LogicExpr<'a>>,
        term_arena: &'a Arena<Term<'a>>,
        np_arena: &'a Arena<NounPhrase<'a>>,
        sym_arena: &'a Arena<Symbol>,
        role_arena: &'a Arena<(ThematicRole, Term<'a>)>,
        pp_arena: &'a Arena<&'a LogicExpr<'a>>,
    ) -> AstContext<'a> {
        AstContext::new(expr_arena, term_arena, np_arena, sym_arena, role_arena, pp_arena)
    }

    #[test]
    fn binary_builder_creates_binary_op() {
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();
        let np_arena: Arena<NounPhrase> = Arena::new();
        let sym_arena: Arena<Symbol> = Arena::new();
        let role_arena: Arena<(ThematicRole, Term)> = Arena::new();
        let pp_arena: Arena<&LogicExpr> = Arena::new();
        let ctx = setup(&expr_arena, &term_arena, &np_arena, &sym_arena, &role_arena, &pp_arena);

        let mut interner = Interner::new();
        let p = interner.intern("P");
        let q = interner.intern("Q");

        let left = ctx.alloc_expr(LogicExpr::Atom(p));
        let right = ctx.alloc_expr(LogicExpr::Atom(q));
        let result = ctx.binary(left, TokenType::And, right);

        assert!(matches!(result, LogicExpr::BinaryOp { op: TokenType::And, .. }));
    }

    #[test]
    fn unary_builder_creates_unary_op() {
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();
        let np_arena: Arena<NounPhrase> = Arena::new();
        let sym_arena: Arena<Symbol> = Arena::new();
        let role_arena: Arena<(ThematicRole, Term)> = Arena::new();
        let pp_arena: Arena<&LogicExpr> = Arena::new();
        let ctx = setup(&expr_arena, &term_arena, &np_arena, &sym_arena, &role_arena, &pp_arena);

        let mut interner = Interner::new();
        let p = interner.intern("P");
        let operand = ctx.alloc_expr(LogicExpr::Atom(p));
        let result = ctx.unary(TokenType::Not, operand);

        assert!(matches!(result, LogicExpr::UnaryOp { op: TokenType::Not, .. }));
    }

    #[test]
    fn quantifier_builder_creates_quantifier() {
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();
        let np_arena: Arena<NounPhrase> = Arena::new();
        let sym_arena: Arena<Symbol> = Arena::new();
        let role_arena: Arena<(ThematicRole, Term)> = Arena::new();
        let pp_arena: Arena<&LogicExpr> = Arena::new();
        let ctx = setup(&expr_arena, &term_arena, &np_arena, &sym_arena, &role_arena, &pp_arena);

        let mut interner = Interner::new();
        let x = interner.intern("x");
        let p = interner.intern("P");
        let body = ctx.alloc_expr(LogicExpr::Atom(p));
        let result = ctx.quantifier(QuantifierKind::Universal, x, body, 0);

        assert!(matches!(result, LogicExpr::Quantifier { kind: QuantifierKind::Universal, .. }));
    }

    #[test]
    fn temporal_builder_creates_temporal() {
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();
        let np_arena: Arena<NounPhrase> = Arena::new();
        let sym_arena: Arena<Symbol> = Arena::new();
        let role_arena: Arena<(ThematicRole, Term)> = Arena::new();
        let pp_arena: Arena<&LogicExpr> = Arena::new();
        let ctx = setup(&expr_arena, &term_arena, &np_arena, &sym_arena, &role_arena, &pp_arena);

        let mut interner = Interner::new();
        let p = interner.intern("P");
        let body = ctx.alloc_expr(LogicExpr::Atom(p));
        let result = ctx.temporal(TemporalOperator::Past, body);

        assert!(matches!(result, LogicExpr::Temporal { operator: TemporalOperator::Past, .. }));
    }

    #[test]
    fn aspectual_builder_creates_aspectual() {
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();
        let np_arena: Arena<NounPhrase> = Arena::new();
        let sym_arena: Arena<Symbol> = Arena::new();
        let role_arena: Arena<(ThematicRole, Term)> = Arena::new();
        let pp_arena: Arena<&LogicExpr> = Arena::new();
        let ctx = setup(&expr_arena, &term_arena, &np_arena, &sym_arena, &role_arena, &pp_arena);

        let mut interner = Interner::new();
        let p = interner.intern("P");
        let body = ctx.alloc_expr(LogicExpr::Atom(p));
        let result = ctx.aspectual(AspectOperator::Progressive, body);

        assert!(matches!(result, LogicExpr::Aspectual { operator: AspectOperator::Progressive, .. }));
    }

    #[test]
    fn modal_builder_creates_modal() {
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();
        let np_arena: Arena<NounPhrase> = Arena::new();
        let sym_arena: Arena<Symbol> = Arena::new();
        let role_arena: Arena<(ThematicRole, Term)> = Arena::new();
        let pp_arena: Arena<&LogicExpr> = Arena::new();
        let ctx = setup(&expr_arena, &term_arena, &np_arena, &sym_arena, &role_arena, &pp_arena);

        let mut interner = Interner::new();
        let p = interner.intern("P");
        let operand = ctx.alloc_expr(LogicExpr::Atom(p));
        let vector = ModalVector { domain: ModalDomain::Alethic, force: 1.0, flavor: crate::ast::ModalFlavor::Root };
        let result = ctx.modal(vector, operand);

        assert!(matches!(result, LogicExpr::Modal { .. }));
    }
}

```

---

## Error Handling

User-friendly error reporting with educational feedback.

**Location:** `src/error.rs`

### Error Types

**File:** `src/error.rs`

ParseError and ParseErrorKind types. ParseError includes Span for source location. display_with_source() renders errors with ANSI colors, line numbers, underline markers, and 'did you mean?' suggestions. Implements socratic_explanation() for Socratic-style error guidance.

```rust
use crate::intern::Interner;
use crate::style::Style;
use crate::suggest::{find_similar, KNOWN_WORDS};
use crate::token::{Span, TokenType};

#[derive(Debug, Clone)]
pub struct ParseError {
    pub kind: ParseErrorKind,
    pub span: Span,
}

impl ParseError {
    pub fn display_with_source(&self, source: &str) -> String {
        let (line_num, line_start, line_content) = self.find_context(source);
        let col = self.span.start.saturating_sub(line_start);
        let len = (self.span.end - self.span.start).max(1);
        let underline = format!("{}{}", " ".repeat(col), "^".repeat(len));

        let error_label = Style::bold_red("error");
        let kind_str = format!("{:?}", self.kind);
        let line_num_str = Style::blue(&format!("{:4}", line_num));
        let pipe = Style::blue("|");
        let underline_colored = Style::red(&underline);

        let mut result = format!(
            "{}: {}\n\n{} {} {}\n     {} {}",
            error_label, kind_str, line_num_str, pipe, line_content, pipe, underline_colored
        );

        if let Some(word) = self.extract_word(source) {
            if let Some(suggestion) = find_similar(&word, KNOWN_WORDS, 2) {
                let hint = Style::cyan("help");
                result.push_str(&format!("\n     {} {}: did you mean '{}'?", pipe, hint, Style::green(suggestion)));
            }
        }

        result
    }

    fn extract_word<'a>(&self, source: &'a str) -> Option<&'a str> {
        if self.span.start < source.len() && self.span.end <= source.len() {
            let word = &source[self.span.start..self.span.end];
            if !word.is_empty() && word.chars().all(|c| c.is_alphabetic()) {
                return Some(word);
            }
        }
        None
    }

    fn find_context<'a>(&self, source: &'a str) -> (usize, usize, &'a str) {
        let mut line_num = 1;
        let mut line_start = 0;

        for (i, c) in source.char_indices() {
            if i >= self.span.start {
                break;
            }
            if c == '\n' {
                line_num += 1;
                line_start = i + 1;
            }
        }

        let line_end = source[line_start..]
            .find('\n')
            .map(|off| line_start + off)
            .unwrap_or(source.len());

        (line_num, line_start, &source[line_start..line_end])
    }
}

#[derive(Debug, Clone)]
pub enum ParseErrorKind {
    UnexpectedToken {
        expected: TokenType,
        found: TokenType,
    },
    ExpectedContentWord {
        found: TokenType,
    },
    ExpectedCopula,
    UnknownQuantifier {
        found: TokenType,
    },
    UnknownModal {
        found: TokenType,
    },
    ExpectedVerb {
        found: TokenType,
    },
    ExpectedTemporalAdverb,
    ExpectedPresuppositionTrigger,
    ExpectedFocusParticle,
    ExpectedScopalAdverb,
    ExpectedSuperlativeAdjective,
    ExpectedComparativeAdjective,
    ExpectedThan,
    ExpectedNumber,
    EmptyRestriction,
    GappingResolutionFailed,
    StativeProgressiveConflict,
    UndefinedVariable {
        name: String,
    },
    UseAfterMove {
        name: String,
    },
    IsValueEquality {
        variable: String,
        value: String,
    },
    ZeroIndex,
    ExpectedStatement,
    ExpectedKeyword { keyword: String },
    ExpectedExpression,
    ExpectedIdentifier,
    // Phase 35: Respectively operator
    RespectivelyLengthMismatch {
        subject_count: usize,
        object_count: usize,
    },
    // Phase 43: Type checking
    TypeMismatch {
        expected: String,
        found: String,
    },
    // Phase 43C: Refinement types
    InvalidRefinementPredicate,
    // Phase 42: Grammar errors (e.g., "its" vs "it's")
    GrammarError(String),
    // Phase 8.5: Escape analysis errors
    Custom(String),
}

#[cold]
pub fn socratic_explanation(error: &ParseError, _interner: &Interner) -> String {
    let pos = error.span.start;
    match &error.kind {
        ParseErrorKind::UnexpectedToken { expected, found } => {
            format!(
                "I was following your logic, but I stumbled at position {}. \
                I expected {:?}, but found {:?}. Perhaps you meant to use a different word here?",
                pos, expected, found
            )
        }
        ParseErrorKind::ExpectedContentWord { found } => {
            format!(
                "I was looking for a noun, verb, or adjective at position {}, \
                but found {:?} instead. The logic needs a content word to ground it.",
                pos, found
            )
        }
        ParseErrorKind::ExpectedCopula => {
            format!(
                "At position {}, I expected 'is' or 'are' to link the subject and predicate. \
                Without it, the sentence structure is incomplete.",
                pos
            )
        }
        ParseErrorKind::UnknownQuantifier { found } => {
            format!(
                "At position {}, I found {:?} where I expected a quantifier like 'all', 'some', or 'no'. \
                These words tell me how many things we're talking about.",
                pos, found
            )
        }
        ParseErrorKind::UnknownModal { found } => {
            format!(
                "At position {}, I found {:?} where I expected a modal like 'must', 'can', or 'should'. \
                Modals express possibility, necessity, or obligation.",
                pos, found
            )
        }
        ParseErrorKind::ExpectedVerb { found } => {
            format!(
                "At position {}, I expected a verb to describe an action or state, \
                but found {:?}. Every sentence needs a verb.",
                pos, found
            )
        }
        ParseErrorKind::ExpectedTemporalAdverb => {
            format!(
                "At position {}, I expected a temporal adverb like 'yesterday' or 'tomorrow' \
                to anchor the sentence in time.",
                pos
            )
        }
        ParseErrorKind::ExpectedPresuppositionTrigger => {
            format!(
                "At position {}, I expected a presupposition trigger like 'stopped', 'realized', or 'regrets'. \
                These words carry hidden assumptions.",
                pos
            )
        }
        ParseErrorKind::ExpectedFocusParticle => {
            format!(
                "At position {}, I expected a focus particle like 'only', 'even', or 'just'. \
                These words highlight what's important in the sentence.",
                pos
            )
        }
        ParseErrorKind::ExpectedScopalAdverb => {
            format!(
                "At position {}, I expected a scopal adverb that modifies the entire proposition.",
                pos
            )
        }
        ParseErrorKind::ExpectedSuperlativeAdjective => {
            format!(
                "At position {}, I expected a superlative adjective like 'tallest' or 'fastest'. \
                These words compare one thing to all others.",
                pos
            )
        }
        ParseErrorKind::ExpectedComparativeAdjective => {
            format!(
                "At position {}, I expected a comparative adjective like 'taller' or 'faster'. \
                These words compare two things.",
                pos
            )
        }
        ParseErrorKind::ExpectedThan => {
            format!(
                "At position {}, I expected 'than' after the comparative. \
                Comparisons need 'than' to introduce the thing being compared to.",
                pos
            )
        }
        ParseErrorKind::ExpectedNumber => {
            format!(
                "At position {}, I expected a numeric value like '2', '3.14', or 'aleph_0'. \
                Measure phrases require a number.",
                pos
            )
        }
        ParseErrorKind::EmptyRestriction => {
            format!(
                "At position {}, the restriction clause is empty. \
                A relative clause needs content to restrict the noun phrase.",
                pos
            )
        }
        ParseErrorKind::GappingResolutionFailed => {
            format!(
                "At position {}, I see a gapped construction (like '...and Mary, a pear'), \
                but I couldn't find a verb in the previous clause to borrow. \
                Gapping requires a clear action to repeat.",
                pos
            )
        }
        ParseErrorKind::StativeProgressiveConflict => {
            format!(
                "At position {}, a stative verb like 'know' or 'love' cannot be used with progressive aspect. \
                Stative verbs describe states, not activities in progress.",
                pos
            )
        }
        ParseErrorKind::UndefinedVariable { name } => {
            format!(
                "At position {}, I found '{}' but this variable has not been defined. \
                In imperative mode, all variables must be declared before use.",
                pos, name
            )
        }
        ParseErrorKind::UseAfterMove { name } => {
            format!(
                "At position {}, I found '{}' but this value has been moved. \
                Once a value is moved, it cannot be used again.",
                pos, name
            )
        }
        ParseErrorKind::IsValueEquality { variable, value } => {
            format!(
                "At position {}, I found '{} is {}' but 'is' is for type/predicate checks. \
                For value equality, use '{} equals {}'.",
                pos, variable, value, variable, value
            )
        }
        ParseErrorKind::ZeroIndex => {
            format!(
                "At position {}, I found 'item 0' but indices in LOGOS start at 1. \
                In English, 'the 1st item' is the first item, not the zeroth. \
                Try 'item 1 of list' to get the first element.",
                pos
            )
        }
        ParseErrorKind::ExpectedStatement => {
            format!(
                "At position {}, I expected a statement like 'Let', 'Set', or 'Return'.",
                pos
            )
        }
        ParseErrorKind::ExpectedKeyword { keyword } => {
            format!(
                "At position {}, I expected the keyword '{}'.",
                pos, keyword
            )
        }
        ParseErrorKind::ExpectedExpression => {
            format!(
                "At position {}, I expected an expression (number, variable, or computation).",
                pos
            )
        }
        ParseErrorKind::ExpectedIdentifier => {
            format!(
                "At position {}, I expected an identifier (variable name).",
                pos
            )
        }
        ParseErrorKind::RespectivelyLengthMismatch { subject_count, object_count } => {
            format!(
                "At position {}, 'respectively' requires equal-length lists. \
                The subject has {} element(s) and the object has {} element(s). \
                Each subject must pair with exactly one object.",
                pos, subject_count, object_count
            )
        }
        ParseErrorKind::TypeMismatch { expected, found } => {
            format!(
                "At position {}, I expected a value of type '{}' but found '{}'. \
                Types must match in LOGOS. Check that your value matches the declared type.",
                pos, expected, found
            )
        }
        ParseErrorKind::InvalidRefinementPredicate => {
            format!(
                "At position {}, the refinement predicate is not valid. \
                A refinement predicate must be a comparison like 'x > 0' or 'n < 100'.",
                pos
            )
        }
        // Phase 42: Grammar errors
        ParseErrorKind::GrammarError(msg) => {
            format!(
                "At position {}, grammar issue: {}",
                pos, msg
            )
        }
        // Phase 8.5: Escape analysis - the message is already Socratic
        ParseErrorKind::Custom(msg) => msg.clone(),
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::token::Span;

    #[test]
    fn parse_error_has_span() {
        let error = ParseError {
            kind: ParseErrorKind::ExpectedCopula,
            span: Span::new(5, 10),
        };
        assert_eq!(error.span.start, 5);
        assert_eq!(error.span.end, 10);
    }

    #[test]
    fn display_with_source_shows_line_and_underline() {
        let error = ParseError {
            kind: ParseErrorKind::ExpectedCopula,
            span: Span::new(8, 14),
        };
        let source = "All men mortal are.";
        let display = error.display_with_source(source);
        assert!(display.contains("mortal"), "Should contain source word: {}", display);
        assert!(display.contains("^^^^^^"), "Should contain underline: {}", display);
    }

    #[test]
    fn display_with_source_suggests_typo_fix() {
        let error = ParseError {
            kind: ParseErrorKind::ExpectedCopula,
            span: Span::new(0, 5),
        };
        let source = "logoc is the study of reason.";
        let display = error.display_with_source(source);
        assert!(display.contains("did you mean"), "Should suggest fix: {}", display);
        assert!(display.contains("logic"), "Should suggest 'logic': {}", display);
    }

    #[test]
    fn display_with_source_has_color_codes() {
        let error = ParseError {
            kind: ParseErrorKind::ExpectedCopula,
            span: Span::new(0, 3),
        };
        let source = "Alll men are mortal.";
        let display = error.display_with_source(source);
        assert!(display.contains("\x1b["), "Should contain ANSI escape codes: {}", display);
    }
}

```

---

### Diagnostic Bridge

**File:** `src/diagnostic.rs`

Translates Rust borrow checker errors into friendly LOGOS messages. Parses rustc JSON output (E0382, E0597, E0505) and maps errors back to LOGOS source via SourceMap. LogosError struct with title, explanation, suggestion fields. Socratic messages explain ownership semantics.

```rust
//! Diagnostic Bridge for LOGOS
//!
//! Translates Rust borrow checker errors into friendly LOGOS error messages.
//! Parses rustc JSON output and maps errors back to LOGOS source.

use crate::intern::Interner;
use crate::sourcemap::{OwnershipRole, SourceMap};
use crate::style::Style;
use crate::token::Span;
use serde::Deserialize;

/// A translated error message for LOGOS users.
#[derive(Debug, Clone)]
pub struct LogosError {
    pub title: String,
    pub explanation: String,
    pub logos_span: Option<Span>,
    pub suggestion: Option<String>,
}

impl std::fmt::Display for LogosError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        writeln!(f, "{}: {}", Style::bold_red("ownership error"), self.title)?;
        writeln!(f)?;
        writeln!(f, "{}", self.explanation)?;
        if let Some(suggestion) = &self.suggestion {
            writeln!(f)?;
            writeln!(f, "{}: {}", Style::cyan("suggestion"), suggestion)?;
        }
        Ok(())
    }
}

// =============================================================================
// Rustc JSON Diagnostic Types
// =============================================================================

/// Rustc JSON diagnostic message (subset of fields we need).
#[derive(Debug, Deserialize)]
pub struct RustcDiagnostic {
    pub message: String,
    pub code: Option<RustcCode>,
    pub level: String,
    pub spans: Vec<RustcSpan>,
    #[serde(default)]
    pub children: Vec<RustcDiagnostic>,
}

#[derive(Debug, Deserialize)]
pub struct RustcCode {
    pub code: String,
}

#[derive(Debug, Deserialize)]
pub struct RustcSpan {
    pub file_name: String,
    pub line_start: u32,
    pub line_end: u32,
    pub column_start: u32,
    pub column_end: u32,
    pub is_primary: bool,
    pub label: Option<String>,
    #[serde(default)]
    pub text: Vec<RustcSpanText>,
}

#[derive(Debug, Deserialize)]
pub struct RustcSpanText {
    pub text: String,
    pub highlight_start: u32,
    pub highlight_end: u32,
}

/// Parsed rustc output: either a diagnostic or artifact info.
#[derive(Debug, Deserialize)]
#[serde(tag = "reason")]
#[serde(rename_all = "kebab-case")]
pub enum RustcMessage {
    CompilerMessage { message: RustcDiagnostic },
    #[serde(other)]
    Other,
}

// =============================================================================
// JSON Parsing
// =============================================================================

/// Parse rustc stderr output from `cargo build --message-format=json`.
pub fn parse_rustc_json(stderr: &str) -> Vec<RustcDiagnostic> {
    let mut diagnostics = Vec::new();

    for line in stderr.lines() {
        // Skip empty lines and non-JSON output
        if !line.starts_with('{') {
            continue;
        }

        match serde_json::from_str::<RustcMessage>(line) {
            Ok(RustcMessage::CompilerMessage { message }) => {
                if message.level == "error" {
                    diagnostics.push(message);
                }
            }
            Ok(RustcMessage::Other) => {} // Ignore artifacts, build-finished, etc.
            Err(_) => {} // Ignore malformed lines
        }
    }

    diagnostics
}

/// Extract error code from a diagnostic.
pub fn get_error_code(diag: &RustcDiagnostic) -> Option<&str> {
    diag.code.as_ref().map(|c| c.code.as_str())
}

/// Extract the primary span from a diagnostic.
pub fn get_primary_span(diag: &RustcDiagnostic) -> Option<&RustcSpan> {
    diag.spans.iter().find(|s| s.is_primary)
}

/// Extract variable name from rustc error message.
/// Example: "use of moved value: `data`" -> "data"
fn extract_var_from_message(message: &str, prefix: &str, suffix: &str) -> Option<String> {
    let start = message.find(prefix)?;
    let after_prefix = &message[start + prefix.len()..];
    let end = after_prefix.find(suffix)?;
    Some(after_prefix[..end].to_string())
}

// =============================================================================
// Diagnostic Bridge
// =============================================================================

/// Translates rustc diagnostics into LOGOS error messages.
pub struct DiagnosticBridge<'a> {
    source_map: &'a SourceMap,
    interner: &'a Interner,
}

impl<'a> DiagnosticBridge<'a> {
    pub fn new(source_map: &'a SourceMap, interner: &'a Interner) -> Self {
        Self { source_map, interner }
    }

    /// Translate a rustc diagnostic into a LOGOS error.
    pub fn translate(&self, diag: &RustcDiagnostic) -> Option<LogosError> {
        let code = get_error_code(diag)?;
        let span = get_primary_span(diag);

        match code {
            "E0382" => self.translate_use_after_move(diag, span),
            "E0505" => self.translate_move_while_borrowed(diag, span),
            "E0597" => self.translate_lifetime_error(diag, span),
            _ => self.translate_generic(diag, span),
        }
    }

    /// E0382: "use of moved value: `x`"
    /// LOGOS: "You already gave X away - you can't use it anymore"
    fn translate_use_after_move(&self, diag: &RustcDiagnostic, span: Option<&RustcSpan>) -> Option<LogosError> {
        let var_name = extract_var_from_message(&diag.message, "value: `", "`")
            .or_else(|| extract_var_from_message(&diag.message, "value `", "`"))?;

        let logos_span = span.and_then(|s| self.source_map.find_nearest_span(s.line_start));

        // Look up variable origin if available
        let (logos_name, role) = if let Some(origin) = self.source_map.get_var_origin(&var_name) {
            (self.interner.resolve(origin.logos_name).to_string(), Some(origin.role))
        } else {
            (var_name.clone(), None)
        };

        let explanation = match role {
            Some(OwnershipRole::GiveObject) => format!(
                "You gave '{}' away with a Give statement, so you can't use it anymore.\n\
                In LOGOS, 'Give X to Y' transfers ownership - X moves to Y and leaves your hands.\n\
                This is like handing someone a physical object: once given, you no longer have it.",
                logos_name
            ),
            Some(OwnershipRole::LetBinding) | None => format!(
                "The value '{}' was moved somewhere else and can't be used again.\n\
                Check if you used 'Give' or passed it to a function that took ownership.",
                logos_name
            ),
            _ => format!(
                "The value '{}' has been moved and is no longer available.",
                logos_name
            ),
        };

        let suggestion = Some(format!(
            "If you need to use '{}' after giving it away, either:\n\
             1. Use 'Show {} to Y' instead (this borrows, keeping ownership)\n\
             2. Use 'a copy of {}' before the Give",
            logos_name, logos_name, logos_name
        ));

        Some(LogosError {
            title: format!("Cannot use '{}' after giving it away", logos_name),
            explanation,
            logos_span,
            suggestion,
        })
    }

    /// E0505: "cannot move out of `x` because it is borrowed"
    /// LOGOS: "You're trying to give X away while someone is still looking at it"
    fn translate_move_while_borrowed(&self, diag: &RustcDiagnostic, span: Option<&RustcSpan>) -> Option<LogosError> {
        let var_name = extract_var_from_message(&diag.message, "out of `", "`")
            .or_else(|| extract_var_from_message(&diag.message, "move out of `", "`"))?;

        let logos_span = span.and_then(|s| self.source_map.find_nearest_span(s.line_start));

        let logos_name = if let Some(origin) = self.source_map.get_var_origin(&var_name) {
            self.interner.resolve(origin.logos_name).to_string()
        } else {
            var_name.clone()
        };

        let explanation = format!(
            "You showed '{}' to someone (creating a temporary view),\n\
            but then tried to give it away before they finished looking.\n\
            In LOGOS, 'Show' creates a promise that the data won't change or disappear\n\
            while being viewed. You can't break that promise by giving it away.",
            logos_name
        );

        let suggestion = Some(format!(
            "Make sure all 'Show' usages of '{}' complete before any 'Give'.\n\
            Alternatively, give away a copy: 'Give a copy of {} to Y'",
            logos_name, logos_name
        ));

        Some(LogosError {
            title: format!("Cannot give '{}' while it's being shown", logos_name),
            explanation,
            logos_span,
            suggestion,
        })
    }

    /// E0597: "borrowed value does not live long enough"
    /// LOGOS: "You can't take a reference outside its zone" (Hotel California)
    fn translate_lifetime_error(&self, diag: &RustcDiagnostic, span: Option<&RustcSpan>) -> Option<LogosError> {
        let logos_span = span.and_then(|s| self.source_map.find_nearest_span(s.line_start));

        // Check if this is zone-related by looking at the message and children
        let is_zone_related = diag.message.contains("borrowed")
            || diag.children.iter().any(|c| c.message.contains("dropped"));

        let explanation = if is_zone_related {
            "A value created inside a Zone cannot be referenced from outside.\n\
            Zones are memory arenas - when the Zone ends, everything inside it is released.\n\
            This is the 'Hotel California' rule: data can check in (be created),\n\
            but references can't check out (escape the Zone).".to_string()
        } else {
            "A borrowed reference is being used after the original value has gone away.\n\
            References are temporary views - they can't outlive what they're viewing.".to_string()
        };

        let suggestion = Some(
            "If you need the data after the Zone ends, either:\n\
             1. Move the data out with 'Give' before the Zone closes\n\
             2. Copy the data: 'Let result be a copy of zone_data'\n\
             3. Restructure so the computation completes inside the Zone".to_string()
        );

        Some(LogosError {
            title: "Reference cannot outlive its data".to_string(),
            explanation,
            logos_span,
            suggestion,
        })
    }

    /// Fallback for other errors - provide the raw message with context.
    fn translate_generic(&self, diag: &RustcDiagnostic, span: Option<&RustcSpan>) -> Option<LogosError> {
        let logos_span = span.and_then(|s| self.source_map.find_nearest_span(s.line_start));

        // Try to extract any variable name
        let var_hint = if let Some(start) = diag.message.find('`') {
            if let Some(end) = diag.message[start + 1..].find('`') {
                Some(&diag.message[start + 1..start + 1 + end])
            } else {
                None
            }
        } else {
            None
        };

        let explanation = if let Some(var) = var_hint {
            format!(
                "The Rust compiler reported an error involving '{}':\n{}",
                var, diag.message
            )
        } else {
            format!("The Rust compiler reported an error:\n{}", diag.message)
        };

        Some(LogosError {
            title: "Compilation error".to_string(),
            explanation,
            logos_span,
            suggestion: None,
        })
    }
}

/// Attempt to translate all diagnostics and return the first translated error.
pub fn translate_diagnostics(
    diagnostics: &[RustcDiagnostic],
    source_map: &SourceMap,
    interner: &Interner,
) -> Option<LogosError> {
    let bridge = DiagnosticBridge::new(source_map, interner);

    for diag in diagnostics {
        if let Some(error) = bridge.translate(diag) {
            return Some(error);
        }
    }

    None
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn parse_rustc_json_extracts_errors() {
        let json_output = r#"{"reason":"compiler-message","message":{"message":"use of moved value: `x`","code":{"code":"E0382"},"level":"error","spans":[{"file_name":"src/main.rs","line_start":5,"line_end":5,"column_start":10,"column_end":11,"is_primary":true,"label":null,"text":[]}],"children":[]}}
{"reason":"build-finished","success":false}"#;

        let diagnostics = parse_rustc_json(json_output);
        assert_eq!(diagnostics.len(), 1);
        assert_eq!(diagnostics[0].message, "use of moved value: `x`");
        assert_eq!(get_error_code(&diagnostics[0]), Some("E0382"));
    }

    #[test]
    fn extract_var_from_message_works() {
        assert_eq!(
            extract_var_from_message("use of moved value: `data`", "value: `", "`"),
            Some("data".to_string())
        );
        assert_eq!(
            extract_var_from_message("cannot move out of `x` because", "out of `", "`"),
            Some("x".to_string())
        );
    }

    #[test]
    fn translate_e0382_creates_friendly_error() {
        let interner = Interner::new();
        let source_map = SourceMap::new("Let data be 5.\nGive data to processor.".to_string());

        let diag = RustcDiagnostic {
            message: "use of moved value: `data`".to_string(),
            code: Some(RustcCode { code: "E0382".to_string() }),
            level: "error".to_string(),
            spans: vec![RustcSpan {
                file_name: "src/main.rs".to_string(),
                line_start: 3,
                line_end: 3,
                column_start: 10,
                column_end: 14,
                is_primary: true,
                label: None,
                text: vec![],
            }],
            children: vec![],
        };

        let bridge = DiagnosticBridge::new(&source_map, &interner);
        let error = bridge.translate(&diag).expect("Should translate");

        assert!(error.title.contains("data"));
        assert!(error.title.contains("giving it away"));
        assert!(error.explanation.contains("moved"));
        assert!(error.suggestion.is_some());
    }

    #[test]
    fn translate_e0597_creates_hotel_california_error() {
        let interner = Interner::new();
        let source_map = SourceMap::new("Inside a zone:\n    Let x be 5.".to_string());

        let diag = RustcDiagnostic {
            message: "borrowed value does not live long enough".to_string(),
            code: Some(RustcCode { code: "E0597".to_string() }),
            level: "error".to_string(),
            spans: vec![RustcSpan {
                file_name: "src/main.rs".to_string(),
                line_start: 5,
                line_end: 5,
                column_start: 1,
                column_end: 10,
                is_primary: true,
                label: None,
                text: vec![],
            }],
            children: vec![],
        };

        let bridge = DiagnosticBridge::new(&source_map, &interner);
        let error = bridge.translate(&diag).expect("Should translate");

        assert!(error.title.contains("outlive"));
        assert!(error.explanation.contains("Zone") || error.explanation.contains("borrowed"));
    }
}

```

---

### Source Map

**File:** `src/sourcemap.rs`

Maps generated Rust code back to LOGOS source positions. OwnershipRole enum (GiveObject, GiveRecipient, ShowObject, ShowRecipient, LetBinding, SetTarget, ZoneLocal) tracks semantic context. VarOrigin stores logos_name, span, and role. Enables friendly error messages for ownership/lifetime violations.

```rust
//! Source Map for Diagnostic Bridge
//!
//! Maps generated Rust code back to LOGOS source positions,
//! enabling friendly error messages for ownership/lifetime errors.

use crate::intern::Symbol;
use crate::token::Span;
use std::collections::HashMap;

/// Semantic role of a variable in LOGOS ownership semantics.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum OwnershipRole {
    /// The object being moved in "Give X to Y"
    GiveObject,
    /// The recipient in "Give X to Y"
    GiveRecipient,
    /// The object being borrowed in "Show X to Y"
    ShowObject,
    /// The recipient in "Show X to Y"
    ShowRecipient,
    /// A Let-bound variable
    LetBinding,
    /// Target of a Set statement
    SetTarget,
    /// Variable allocated inside a Zone
    ZoneLocal,
}

/// Variable origin tracking for error translation.
#[derive(Debug, Clone)]
pub struct VarOrigin {
    pub logos_name: Symbol,
    pub span: Span,
    pub role: OwnershipRole,
}

/// Maps generated Rust code back to LOGOS source.
#[derive(Debug, Clone, Default)]
pub struct SourceMap {
    /// Maps line in generated Rust -> Span in LOGOS source
    line_to_span: HashMap<u32, Span>,

    /// Maps generated Rust variable names -> LOGOS origin info
    var_origins: HashMap<String, VarOrigin>,

    /// The original LOGOS source code (for error display)
    logos_source: String,
}

impl SourceMap {
    /// Create a new empty source map.
    pub fn new(logos_source: String) -> Self {
        Self {
            line_to_span: HashMap::new(),
            var_origins: HashMap::new(),
            logos_source,
        }
    }

    /// Get the LOGOS span for a given Rust line number.
    pub fn get_span_for_line(&self, line: u32) -> Option<Span> {
        self.line_to_span.get(&line).copied()
    }

    /// Get the origin info for a Rust variable name.
    pub fn get_var_origin(&self, rust_var: &str) -> Option<&VarOrigin> {
        self.var_origins.get(rust_var)
    }

    /// Get the original LOGOS source.
    pub fn logos_source(&self) -> &str {
        &self.logos_source
    }

    /// Find the closest LOGOS span by searching nearby lines.
    pub fn find_nearest_span(&self, rust_line: u32) -> Option<Span> {
        // Try exact match first
        if let Some(span) = self.line_to_span.get(&rust_line) {
            return Some(*span);
        }

        // Search nearby lines (within 5 lines)
        for offset in 1..=5 {
            if rust_line > offset {
                if let Some(span) = self.line_to_span.get(&(rust_line - offset)) {
                    return Some(*span);
                }
            }
            if let Some(span) = self.line_to_span.get(&(rust_line + offset)) {
                return Some(*span);
            }
        }

        None
    }
}

/// Builder for constructing a SourceMap during code generation.
#[derive(Debug)]
pub struct SourceMapBuilder {
    current_line: u32,
    map: SourceMap,
}

impl SourceMapBuilder {
    /// Create a new builder with the LOGOS source.
    pub fn new(logos_source: &str) -> Self {
        Self {
            current_line: 1,
            map: SourceMap::new(logos_source.to_string()),
        }
    }

    /// Record a mapping from current Rust line to LOGOS span.
    pub fn record_line(&mut self, logos_span: Span) {
        self.map.line_to_span.insert(self.current_line, logos_span);
    }

    /// Record a variable origin.
    pub fn record_var(&mut self, rust_name: &str, logos_name: Symbol, span: Span, role: OwnershipRole) {
        self.map.var_origins.insert(
            rust_name.to_string(),
            VarOrigin {
                logos_name,
                span,
                role,
            },
        );
    }

    /// Advance to the next line.
    pub fn newline(&mut self) {
        self.current_line += 1;
    }

    /// Add multiple newlines.
    pub fn add_lines(&mut self, count: u32) {
        self.current_line += count;
    }

    /// Get current line number.
    pub fn current_line(&self) -> u32 {
        self.current_line
    }

    /// Build the final source map.
    pub fn build(self) -> SourceMap {
        self.map
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn source_map_stores_line_mappings() {
        let mut map = SourceMap::new("Let x be 5.".to_string());
        map.line_to_span.insert(1, Span::new(0, 11));

        assert_eq!(map.get_span_for_line(1), Some(Span::new(0, 11)));
        assert_eq!(map.get_span_for_line(2), None);
    }

    #[test]
    fn source_map_builder_tracks_lines() {
        let mut builder = SourceMapBuilder::new("test source");
        assert_eq!(builder.current_line(), 1);

        builder.newline();
        assert_eq!(builder.current_line(), 2);

        builder.add_lines(3);
        assert_eq!(builder.current_line(), 5);
    }

    #[test]
    fn source_map_builder_records_spans() {
        let mut builder = SourceMapBuilder::new("Let x be 5.\nLet y be 10.");
        builder.record_line(Span::new(0, 11));
        builder.newline();
        builder.record_line(Span::new(12, 24));

        let map = builder.build();
        assert_eq!(map.get_span_for_line(1), Some(Span::new(0, 11)));
        assert_eq!(map.get_span_for_line(2), Some(Span::new(12, 24)));
    }

    #[test]
    fn find_nearest_span_searches_nearby() {
        let mut builder = SourceMapBuilder::new("source");
        builder.record_line(Span::new(0, 10));
        builder.add_lines(5);
        // Line 1 has span, lines 2-6 don't

        let map = builder.build();
        // Line 3 should find line 1's span
        assert_eq!(map.find_nearest_span(3), Some(Span::new(0, 10)));
    }
}

```

---

### Verification Pass (AST Mapper)

**File:** `src/verification.rs`

Bridges LOGOS AST to logos_verification IR. VerificationPass maps Stmt::Let → declare+assume, Stmt::Set → assume (simplified SSA), Stmt::Assert/Trust → verify. check_refinement() verifies refinement type constraints at Let bindings. Maps LogicExpr to VerifyExpr with special handling for comparison predicates (Greater, Less, GreaterEqual, LessEqual, Equal, NotEqual). Complex linguistic constructs gracefully degrade to Bool(true).

```rust
//! Verification Pass: AST to Verification IR Mapper
//!
//! This module bridges the LOGOS AST to the Z3-based verification system.
//! It maps LogicExpr, Stmt, and Term types to the lightweight Verification IR,
//! which is then encoded into Z3 constraints.
//!
//! Strategy: Smart Full Mapping with Uninterpreted Functions
//! - Int, Bool → direct Z3 sorts
//! - Object → uninterpreted sort for entities
//! - Predicates, Modals, Temporals → Apply (uninterpreted functions)
//! - Z3 reasons structurally without semantic knowledge

use crate::ast::{LogicExpr, ModalDomain, NumberKind, QuantifierKind, Term};
use crate::ast::stmt::{BinaryOpKind, Expr, Literal, Stmt, TypeExpr};
use crate::intern::{Interner, Symbol};
use crate::token::TokenType;

use logos_verification::{VerificationSession, VerifyExpr, VerifyOp, VerifyType};

/// The verification pass that maps LOGOS AST to Z3 constraints.
pub struct VerificationPass<'a> {
    session: VerificationSession,
    interner: &'a Interner,
}

impl<'a> VerificationPass<'a> {
    /// Create a new verification pass.
    pub fn new(interner: &'a Interner) -> Self {
        Self {
            session: VerificationSession::new(),
            interner,
        }
    }

    /// Run verification on a list of statements.
    ///
    /// This processes Let statements to build up assumptions,
    /// then verifies Assert statements against those assumptions.
    pub fn verify_program(&mut self, stmts: &[Stmt]) -> Result<(), String> {
        for stmt in stmts {
            self.visit_stmt(stmt)?;
        }
        Ok(())
    }

    fn visit_stmt(&mut self, stmt: &Stmt) -> Result<(), String> {
        match stmt {
            Stmt::Let { var, ty, value, .. } => {
                let name = self.interner.resolve(*var);

                // Phase 43D: Check refinement constraints BEFORE declaring variable
                if let Some(TypeExpr::Refinement { var: bound_var, predicate, .. }) = ty {
                    self.check_refinement(name, *bound_var, predicate, value)?;
                }

                // Infer type from the value
                let inferred_ty = self.infer_type(value);
                self.session.declare(name, inferred_ty);

                // Map the value to IR and assume var = value
                if let Some(val_ir) = self.map_imperative_expr(value) {
                    let constraint = VerifyExpr::eq(
                        VerifyExpr::var(name),
                        val_ir,
                    );
                    self.session.assume(&constraint);
                }
                Ok(())
            }

            Stmt::Set { target, value } => {
                // Mutation: add new constraint (simplified SSA)
                // In full verification, this would use SSA renaming
                let name = self.interner.resolve(*target);
                if let Some(val_ir) = self.map_imperative_expr(value) {
                    let constraint = VerifyExpr::eq(
                        VerifyExpr::var(name),
                        val_ir,
                    );
                    self.session.assume(&constraint);
                }
                Ok(())
            }

            Stmt::Assert { proposition } => {
                let ir = self.map_logic_expr(proposition);
                // Skip verification if the assertion maps to a trivial True
                // This handles complex linguistic constructs we can't verify yet
                if matches!(&ir, VerifyExpr::Bool(true)) {
                    return Ok(());
                }
                self.session.verify(&ir).map_err(|e| format!("{}", e))
            }

            Stmt::Trust { proposition, justification } => {
                // Trust is like Assert but with documented justification
                // For static verification, we verify it like an assertion
                let ir = self.map_logic_expr(proposition);
                // Skip verification if the assertion maps to a trivial True
                if matches!(&ir, VerifyExpr::Bool(true)) {
                    return Ok(());
                }
                let reason = self.interner.resolve(*justification);
                self.session.verify(&ir).map_err(|e| {
                    format!("Trust verification failed (justification: {}): {}", reason, e)
                })
            }

            // Recurse into blocks (simplified - no path-sensitive analysis yet)
            Stmt::If { then_block, else_block, .. } => {
                // Verify both branches independently
                for stmt in *then_block {
                    self.visit_stmt(stmt)?;
                }
                if let Some(else_stmts) = else_block {
                    for stmt in *else_stmts {
                        self.visit_stmt(stmt)?;
                    }
                }
                Ok(())
            }

            Stmt::While { body, decreasing, .. } => {
                // Phase 44: Termination checking
                if let Some(variant_expr) = decreasing {
                    self.check_termination(variant_expr, body)?;
                }

                // Visit body statements
                for stmt in *body {
                    self.visit_stmt(stmt)?;
                }
                Ok(())
            }

            Stmt::Repeat { body, .. } => {
                for stmt in *body {
                    self.visit_stmt(stmt)?;
                }
                Ok(())
            }

            Stmt::Zone { body, .. } => {
                for stmt in *body {
                    self.visit_stmt(stmt)?;
                }
                Ok(())
            }

            Stmt::FunctionDef { body, .. } => {
                for stmt in *body {
                    self.visit_stmt(stmt)?;
                }
                Ok(())
            }

            // Skip statements that don't affect verification
            Stmt::Return { .. }
            | Stmt::Call { .. }
            | Stmt::Give { .. }
            | Stmt::Show { .. }
            | Stmt::SetField { .. }
            | Stmt::StructDef { .. }
            | Stmt::Inspect { .. }
            | Stmt::Push { .. }
            | Stmt::Pop { .. }
            | Stmt::SetIndex { .. }
            | Stmt::Concurrent { .. }
            | Stmt::Parallel { .. }
            | Stmt::ReadFrom { .. }
            | Stmt::WriteFile { .. }
            // Phase 51: P2P Networking
            | Stmt::Listen { .. }
            | Stmt::ConnectTo { .. }
            | Stmt::LetPeerAgent { .. } => Ok(()),
        }
    }

    /// Infer the verification type from an imperative expression.
    fn infer_type(&self, expr: &Expr) -> VerifyType {
        match expr {
            Expr::Literal(Literal::Number(_)) => VerifyType::Int,
            Expr::Literal(Literal::Boolean(_)) => VerifyType::Bool,
            Expr::Literal(Literal::Text(_)) => VerifyType::Object,
            Expr::Literal(Literal::Nothing) => VerifyType::Object,
            Expr::BinaryOp { op, .. } => {
                match op {
                    // Comparison operators produce Bool
                    BinaryOpKind::Eq
                    | BinaryOpKind::NotEq
                    | BinaryOpKind::Lt
                    | BinaryOpKind::Gt
                    | BinaryOpKind::LtEq
                    | BinaryOpKind::GtEq
                    | BinaryOpKind::And
                    | BinaryOpKind::Or => VerifyType::Bool,
                    // Arithmetic operators produce Int
                    BinaryOpKind::Add
                    | BinaryOpKind::Subtract
                    | BinaryOpKind::Multiply
                    | BinaryOpKind::Divide => VerifyType::Int,
                }
            }
            // Default to Int for other expressions
            _ => VerifyType::Int,
        }
    }

    /// Phase 43D: Check that a value satisfies a refinement type constraint.
    fn check_refinement(
        &self,
        var_name: &str,
        bound_var: Symbol,
        predicate: &LogicExpr,
        value: &Expr,
    ) -> Result<(), String> {
        // 1. Map the value to IR
        let val_ir = self.map_imperative_expr(value)
            .ok_or_else(|| format!(
                "Cannot verify refinement for '{}': value expression not supported for verification",
                var_name
            ))?;

        // 2. Map the predicate to IR
        let pred_ir = self.map_logic_expr(predicate);

        // Skip if predicate maps to trivial True (complex linguistic constructs)
        if matches!(&pred_ir, VerifyExpr::Bool(true)) {
            return Ok(());
        }

        // 3. Get the bound variable name (e.g., "it" or "x")
        let bound_name = self.interner.resolve(bound_var);

        // 4. Verify with the binding
        self.session.verify_with_binding(
            bound_name,
            VerifyType::Int, // Refinements are typically on Int
            &val_ir,
            &pred_ir,
        ).map_err(|e| format!(
            "Refinement type verification failed for '{}': {}",
            var_name, e
        ))
    }

    /// Phase 44: Verify that a loop terminates by checking its decreasing variant.
    fn check_termination(
        &self,
        variant_expr: &Expr,
        body: &[Stmt],
    ) -> Result<(), String> {
        // 1. Map the variant to IR (this is V₀ - value before loop body)
        let v0 = self.map_imperative_expr(variant_expr)
            .ok_or_else(|| "Cannot verify termination: variant expression not supported".to_string())?;

        // 2. Get the variant variable name (must be a simple identifier for now)
        let variant_name = match variant_expr {
            Expr::Identifier(sym) => self.interner.resolve(*sym),
            _ => return Err("Decreasing clause must be a simple variable".to_string()),
        };

        // 3. Simulate the loop body to find V₁ (value after one iteration)
        let v1 = self.simulate_body_for_variant(variant_name, body)?;

        // 4. Verify: V₁ < V₀ (strictly decreasing)
        let decreasing_constraint = VerifyExpr::lt(v1.clone(), v0.clone());

        // 5. Verify: V₀ >= 0 (bounded below)
        let bounded_constraint = VerifyExpr::gte(v0.clone(), VerifyExpr::int(0));

        // 6. Combined: decreasing AND bounded
        let termination_proof = VerifyExpr::and(decreasing_constraint, bounded_constraint);

        self.session.verify(&termination_proof).map_err(|e| {
            format!("Termination verification failed for '{}': {}", variant_name, e)
        })
    }

    /// Simulate the loop body to determine the final value of the variant.
    fn simulate_body_for_variant(
        &self,
        variant_name: &str,
        body: &[Stmt],
    ) -> Result<VerifyExpr, String> {
        use std::collections::HashMap;

        // Track all bindings in the loop body
        let mut bindings: HashMap<String, VerifyExpr> = HashMap::new();
        let mut latest_value: Option<VerifyExpr> = None;

        for stmt in body {
            match stmt {
                Stmt::Let { var, value, .. } => {
                    let var_name = self.interner.resolve(*var);
                    if let Some(val_ir) = self.map_imperative_expr_with_bindings(value, &bindings) {
                        bindings.insert(var_name.to_string(), val_ir);
                    }
                }
                Stmt::Set { target, value } => {
                    let target_name = self.interner.resolve(*target);
                    if target_name == variant_name {
                        latest_value = self.map_imperative_expr_with_bindings(value, &bindings);
                    } else {
                        // Track other Set statements that might affect bindings
                        if let Some(val_ir) = self.map_imperative_expr_with_bindings(value, &bindings) {
                            bindings.insert(target_name.to_string(), val_ir);
                        }
                    }
                }
                _ => {
                    // TODO: Handle nested If/While for more complex cases
                }
            }
        }

        latest_value.ok_or_else(|| {
            format!("Variant '{}' is not modified in loop body", variant_name)
        })
    }

    /// Map an imperative expression to Verification IR, substituting known bindings.
    fn map_imperative_expr_with_bindings(
        &self,
        expr: &Expr,
        bindings: &std::collections::HashMap<String, VerifyExpr>,
    ) -> Option<VerifyExpr> {
        match expr {
            Expr::Literal(Literal::Number(n)) => Some(VerifyExpr::int(*n)),
            Expr::Literal(Literal::Boolean(b)) => Some(VerifyExpr::bool(*b)),
            Expr::Literal(Literal::Text(_)) => None,
            Expr::Literal(Literal::Nothing) => None,

            Expr::Identifier(sym) => {
                let name = self.interner.resolve(*sym);
                // Check if we have a known binding for this variable
                if let Some(bound_val) = bindings.get(name) {
                    Some(bound_val.clone())
                } else {
                    Some(VerifyExpr::var(name))
                }
            }

            Expr::BinaryOp { op, left, right } => {
                let l = self.map_imperative_expr_with_bindings(left, bindings)?;
                let r = self.map_imperative_expr_with_bindings(right, bindings)?;
                let verify_op = match op {
                    BinaryOpKind::Add => VerifyOp::Add,
                    BinaryOpKind::Subtract => VerifyOp::Sub,
                    BinaryOpKind::Multiply => VerifyOp::Mul,
                    BinaryOpKind::Divide => VerifyOp::Div,
                    BinaryOpKind::Eq => VerifyOp::Eq,
                    BinaryOpKind::NotEq => VerifyOp::Neq,
                    BinaryOpKind::Gt => VerifyOp::Gt,
                    BinaryOpKind::Lt => VerifyOp::Lt,
                    BinaryOpKind::GtEq => VerifyOp::Gte,
                    BinaryOpKind::LtEq => VerifyOp::Lte,
                    BinaryOpKind::And => VerifyOp::And,
                    BinaryOpKind::Or => VerifyOp::Or,
                };
                Some(VerifyExpr::binary(verify_op, l, r))
            }

            Expr::Call { function, args } => {
                let func_name = self.interner.resolve(*function);
                let verify_args: Vec<VerifyExpr> = args
                    .iter()
                    .filter_map(|a| self.map_imperative_expr_with_bindings(a, bindings))
                    .collect();
                Some(VerifyExpr::apply(func_name, verify_args))
            }

            // Unsupported expressions
            _ => None,
        }
    }

    /// Map an imperative expression to Verification IR.
    fn map_imperative_expr(&self, expr: &Expr) -> Option<VerifyExpr> {
        match expr {
            Expr::Literal(Literal::Number(n)) => Some(VerifyExpr::int(*n)),
            Expr::Literal(Literal::Boolean(b)) => Some(VerifyExpr::bool(*b)),
            Expr::Literal(Literal::Text(_)) => None, // Text not supported in Z3
            Expr::Literal(Literal::Nothing) => None,

            Expr::Identifier(sym) => {
                let name = self.interner.resolve(*sym);
                Some(VerifyExpr::var(name))
            }

            Expr::BinaryOp { op, left, right } => {
                let l = self.map_imperative_expr(left)?;
                let r = self.map_imperative_expr(right)?;
                let verify_op = match op {
                    BinaryOpKind::Add => VerifyOp::Add,
                    BinaryOpKind::Subtract => VerifyOp::Sub,
                    BinaryOpKind::Multiply => VerifyOp::Mul,
                    BinaryOpKind::Divide => VerifyOp::Div,
                    BinaryOpKind::Eq => VerifyOp::Eq,
                    BinaryOpKind::NotEq => VerifyOp::Neq,
                    BinaryOpKind::Gt => VerifyOp::Gt,
                    BinaryOpKind::Lt => VerifyOp::Lt,
                    BinaryOpKind::GtEq => VerifyOp::Gte,
                    BinaryOpKind::LtEq => VerifyOp::Lte,
                    BinaryOpKind::And => VerifyOp::And,
                    BinaryOpKind::Or => VerifyOp::Or,
                };
                Some(VerifyExpr::binary(verify_op, l, r))
            }

            Expr::Call { function, args } => {
                let func_name = self.interner.resolve(*function);
                let verify_args: Vec<VerifyExpr> = args
                    .iter()
                    .filter_map(|a| self.map_imperative_expr(a))
                    .collect();
                Some(VerifyExpr::apply(func_name, verify_args))
            }

            // Unsupported expressions
            Expr::Index { .. }
            | Expr::Slice { .. }
            | Expr::Copy { .. }
            | Expr::Length { .. }
            | Expr::List(_)
            | Expr::Range { .. }
            | Expr::FieldAccess { .. }
            | Expr::New { .. }
            | Expr::NewVariant { .. } => None,
        }
    }

    /// Map a logic expression to Verification IR.
    ///
    /// This is the core of the "Smart Full Mapping" strategy:
    /// - Simple types (Int, Bool) map directly
    /// - Complex types (Predicates, Modals) become uninterpreted functions
    fn map_logic_expr(&self, expr: &LogicExpr) -> VerifyExpr {
        match expr {
            LogicExpr::Atom(sym) => {
                // Atoms are boolean variables or 0-arity predicates
                let name = self.interner.resolve(*sym);
                VerifyExpr::var(name)
            }

            LogicExpr::Predicate { name, args } => {
                let pred_name = self.interner.resolve(*name);
                let verify_args: Vec<VerifyExpr> = args
                    .iter()
                    .map(|t| self.map_term(t))
                    .collect();

                // Phase 43D: Handle comparison predicates from refinement types
                // The parser creates predicates like "Greater(it, 0)" for "it > 0"
                if verify_args.len() == 2 {
                    let left = verify_args[0].clone();
                    let right = verify_args[1].clone();
                    match pred_name {
                        "Greater" => return VerifyExpr::gt(left, right),
                        "Less" => return VerifyExpr::lt(left, right),
                        "GreaterEqual" => return VerifyExpr::gte(left, right),
                        "LessEqual" => return VerifyExpr::lte(left, right),
                        "Equal" => return VerifyExpr::eq(left, right),
                        "NotEqual" => return VerifyExpr::neq(left, right),
                        _ => {}
                    }
                }

                // Default: treat as uninterpreted function
                VerifyExpr::apply(pred_name, verify_args)
            }

            LogicExpr::Identity { left, right } => {
                let l = self.map_term(left);
                let r = self.map_term(right);
                VerifyExpr::eq(l, r)
            }

            LogicExpr::BinaryOp { left, op, right } => {
                let l = self.map_logic_expr(left);
                let r = self.map_logic_expr(right);
                let verify_op = match op {
                    TokenType::And => VerifyOp::And,
                    TokenType::Or => VerifyOp::Or,
                    TokenType::If | TokenType::Then => VerifyOp::Implies,
                    TokenType::Iff => VerifyOp::Eq, // Biconditional is boolean equality
                    _ => VerifyOp::And, // Fallback
                };
                VerifyExpr::binary(verify_op, l, r)
            }

            LogicExpr::UnaryOp { op, operand } => {
                match op {
                    TokenType::Not => VerifyExpr::not(self.map_logic_expr(operand)),
                    _ => self.map_logic_expr(operand),
                }
            }

            // Smart Mapping: Modal operators become uninterpreted functions
            LogicExpr::Modal { vector, operand } => {
                let op_name = match vector.domain {
                    ModalDomain::Alethic => {
                        if vector.force > 0.5 { "Necessarily" } else { "Possibly" }
                    }
                    ModalDomain::Deontic => {
                        if vector.force > 0.5 { "Obligatory" } else { "Permissible" }
                    }
                };
                VerifyExpr::apply(op_name, vec![self.map_logic_expr(operand)])
            }

            // Smart Mapping: Temporal operators become uninterpreted functions
            LogicExpr::Temporal { operator, body } => {
                let op_name = match operator {
                    crate::ast::TemporalOperator::Past => "Past",
                    crate::ast::TemporalOperator::Future => "Future",
                };
                VerifyExpr::apply(op_name, vec![self.map_logic_expr(body)])
            }

            // Smart Mapping: Aspectual operators become uninterpreted functions
            LogicExpr::Aspectual { operator, body } => {
                let op_name = match operator {
                    crate::ast::AspectOperator::Progressive => "Progressive",
                    crate::ast::AspectOperator::Perfect => "Perfect",
                    crate::ast::AspectOperator::Habitual => "Habitual",
                    crate::ast::AspectOperator::Iterative => "Iterative",
                };
                VerifyExpr::apply(op_name, vec![self.map_logic_expr(body)])
            }

            // Quantifiers map to IR quantifiers
            LogicExpr::Quantifier { kind, variable, body, .. } => {
                let var_name = self.interner.resolve(*variable);
                let body_ir = self.map_logic_expr(body);
                match kind {
                    QuantifierKind::Universal => {
                        VerifyExpr::forall(
                            vec![(var_name.to_string(), VerifyType::Object)],
                            body_ir,
                        )
                    }
                    QuantifierKind::Existential => {
                        VerifyExpr::exists(
                            vec![(var_name.to_string(), VerifyType::Object)],
                            body_ir,
                        )
                    }
                    // Generalized quantifiers become uninterpreted
                    QuantifierKind::Most => {
                        VerifyExpr::apply("Most", vec![VerifyExpr::var(var_name), body_ir])
                    }
                    QuantifierKind::Few => {
                        VerifyExpr::apply("Few", vec![VerifyExpr::var(var_name), body_ir])
                    }
                    QuantifierKind::Many => {
                        VerifyExpr::apply("Many", vec![VerifyExpr::var(var_name), body_ir])
                    }
                    QuantifierKind::Cardinal(n) => {
                        VerifyExpr::apply(
                            &format!("Exactly{}", n),
                            vec![VerifyExpr::var(var_name), body_ir],
                        )
                    }
                    QuantifierKind::AtLeast(n) => {
                        VerifyExpr::apply(
                            &format!("AtLeast{}", n),
                            vec![VerifyExpr::var(var_name), body_ir],
                        )
                    }
                    QuantifierKind::AtMost(n) => {
                        VerifyExpr::apply(
                            &format!("AtMost{}", n),
                            vec![VerifyExpr::var(var_name), body_ir],
                        )
                    }
                    QuantifierKind::Generic => {
                        VerifyExpr::apply("Generic", vec![VerifyExpr::var(var_name), body_ir])
                    }
                }
            }

            // Lambda abstractions become uninterpreted
            LogicExpr::Lambda { variable, body } => {
                let var_name = self.interner.resolve(*variable);
                VerifyExpr::apply(
                    "Lambda",
                    vec![VerifyExpr::var(var_name), self.map_logic_expr(body)],
                )
            }

            // Function application
            LogicExpr::App { function, argument } => {
                VerifyExpr::apply(
                    "App",
                    vec![self.map_logic_expr(function), self.map_logic_expr(argument)],
                )
            }

            // Counterfactuals: if-then with special modal semantics
            LogicExpr::Counterfactual { antecedent, consequent } => {
                VerifyExpr::apply(
                    "Counterfactual",
                    vec![self.map_logic_expr(antecedent), self.map_logic_expr(consequent)],
                )
            }

            // Causation
            LogicExpr::Causal { cause, effect } => {
                VerifyExpr::apply(
                    "Causes",
                    vec![self.map_logic_expr(cause), self.map_logic_expr(effect)],
                )
            }

            // Questions become uninterpreted (for query semantics)
            LogicExpr::Question { wh_variable, body } => {
                let var_name = self.interner.resolve(*wh_variable);
                VerifyExpr::apply(
                    "Question",
                    vec![VerifyExpr::var(var_name), self.map_logic_expr(body)],
                )
            }

            LogicExpr::YesNoQuestion { body } => {
                VerifyExpr::apply("YesNo", vec![self.map_logic_expr(body)])
            }

            // Intensional contexts
            LogicExpr::Intensional { operator, content } => {
                let op_name = self.interner.resolve(*operator);
                VerifyExpr::apply(op_name, vec![self.map_logic_expr(content)])
            }

            // Speech acts
            LogicExpr::SpeechAct { performer, act_type, content } => {
                let performer_name = self.interner.resolve(*performer);
                let act_name = self.interner.resolve(*act_type);
                VerifyExpr::apply(
                    act_name,
                    vec![VerifyExpr::var(performer_name), self.map_logic_expr(content)],
                )
            }

            // Comparatives
            LogicExpr::Comparative { adjective, subject, object, difference } => {
                let adj_name = self.interner.resolve(*adjective);
                let mut args = vec![
                    self.map_term(subject),
                    self.map_term(object),
                ];
                if let Some(diff) = difference {
                    args.push(self.map_term(diff));
                }
                VerifyExpr::apply(&format!("More{}", adj_name), args)
            }

            // Superlatives
            LogicExpr::Superlative { adjective, subject, domain } => {
                let adj_name = self.interner.resolve(*adjective);
                let domain_name = self.interner.resolve(*domain);
                VerifyExpr::apply(
                    &format!("Most{}", adj_name),
                    vec![self.map_term(subject), VerifyExpr::var(domain_name)],
                )
            }

            // Focus
            LogicExpr::Focus { focused, scope, .. } => {
                VerifyExpr::apply(
                    "Focus",
                    vec![self.map_term(focused), self.map_logic_expr(scope)],
                )
            }

            // Presupposition
            LogicExpr::Presupposition { assertion, presupposition } => {
                // Verify both assertion and presupposition
                VerifyExpr::and(
                    self.map_logic_expr(presupposition),
                    self.map_logic_expr(assertion),
                )
            }

            // Fallback for complex types: map to True to avoid false positives
            LogicExpr::Metaphor { .. }
            | LogicExpr::Categorical(_)
            | LogicExpr::Relation(_)
            | LogicExpr::Voice { .. }
            | LogicExpr::Event { .. }
            | LogicExpr::NeoEvent(_)
            | LogicExpr::Imperative { .. }
            | LogicExpr::TemporalAnchor { .. }
            | LogicExpr::Distributive { .. }
            | LogicExpr::GroupQuantifier { .. }
            | LogicExpr::Scopal { .. }
            | LogicExpr::Control { .. } => {
                // These complex linguistic constructs are assumed valid
                VerifyExpr::bool(true)
            }
        }
    }

    /// Map a term to Verification IR.
    fn map_term(&self, term: &Term) -> VerifyExpr {
        match term {
            Term::Constant(sym) | Term::Variable(sym) => {
                let name = self.interner.resolve(*sym);
                VerifyExpr::var(name)
            }

            Term::Value { kind, .. } => {
                match kind {
                    NumberKind::Integer(n) => VerifyExpr::int(*n),
                    NumberKind::Real(r) => VerifyExpr::int(*r as i64), // Truncate for now
                    NumberKind::Symbolic(s) => {
                        let name = self.interner.resolve(*s);
                        VerifyExpr::var(name)
                    }
                }
            }

            Term::Function(name, args) => {
                let func_name = self.interner.resolve(*name);
                let verify_args: Vec<VerifyExpr> = args
                    .iter()
                    .map(|t| self.map_term(t))
                    .collect();
                VerifyExpr::apply(func_name, verify_args)
            }

            Term::Group(terms) => {
                // Group terms become a special "Group" function
                let verify_args: Vec<VerifyExpr> = terms
                    .iter()
                    .map(|t| self.map_term(t))
                    .collect();
                VerifyExpr::apply("Group", verify_args)
            }

            Term::Possessed { possessor, possessed } => {
                let poss_name = self.interner.resolve(*possessed);
                VerifyExpr::apply(
                    &format!("{}Of", poss_name),
                    vec![self.map_term(possessor)],
                )
            }

            Term::Sigma(sym) => {
                let name = self.interner.resolve(*sym);
                VerifyExpr::apply("Sigma", vec![VerifyExpr::var(name)])
            }

            Term::Intension(sym) => {
                let name = self.interner.resolve(*sym);
                VerifyExpr::apply("Intension", vec![VerifyExpr::var(name)])
            }

            Term::Proposition(expr) => {
                self.map_logic_expr(expr)
            }
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    fn make_interner() -> Interner {
        Interner::new()
    }

    #[test]
    fn test_verification_pass_creation() {
        let interner = make_interner();
        let pass = VerificationPass::new(&interner);
        // Just verify it constructs without panic
        drop(pass);
    }
}

```

---

## Suggestions & Styling

Compiler-style error presentation with typo correction and ANSI colors.

**Location:** `src/suggest.rs`, `src/style.rs`

### Typo Suggestions

**File:** `src/suggest.rs`

Zero-dependency Levenshtein distance algorithm. find_similar() finds closest vocabulary match for 'did you mean?' suggestions in error messages.

```rust
pub fn levenshtein(a: &str, b: &str) -> usize {
    let a_chars: Vec<char> = a.chars().collect();
    let b_chars: Vec<char> = b.chars().collect();
    let m = a_chars.len();
    let n = b_chars.len();

    if m == 0 {
        return n;
    }
    if n == 0 {
        return m;
    }

    let mut prev: Vec<usize> = (0..=n).collect();
    let mut curr = vec![0; n + 1];

    for i in 1..=m {
        curr[0] = i;
        for j in 1..=n {
            let cost = if a_chars[i - 1] == b_chars[j - 1] { 0 } else { 1 };
            curr[j] = (prev[j] + 1)
                .min(curr[j - 1] + 1)
                .min(prev[j - 1] + cost);
        }
        std::mem::swap(&mut prev, &mut curr);
    }

    prev[n]
}

pub fn find_similar<'a>(word: &str, candidates: &[&'a str], max_distance: usize) -> Option<&'a str> {
    let word_lower = word.to_lowercase();
    let mut best: Option<(&str, usize)> = None;

    for &candidate in candidates {
        let dist = levenshtein(&word_lower, &candidate.to_lowercase());
        if dist <= max_distance {
            match best {
                None => best = Some((candidate, dist)),
                Some((_, d)) if dist < d => best = Some((candidate, dist)),
                _ => {}
            }
        }
    }

    best.map(|(s, _)| s)
}

pub const KNOWN_WORDS: &[&str] = &[
    "all", "some", "no", "most", "few", "every",
    "the", "a", "an", "this", "that",
    "is", "are", "was", "were", "be",
    "and", "or", "if", "then", "not",
    "must", "can", "may", "should", "would", "could",
    "who", "what", "where", "when", "why", "how",
    "man", "men", "woman", "women", "dog", "cat", "bird",
    "mortal", "happy", "sad", "tall", "fast", "slow",
    "loves", "runs", "sees", "knows", "thinks",
    "logic", "reason", "truth", "false",
    "John", "Mary", "Socrates", "Aristotle",
    "to", "by", "with", "from", "for", "in", "on", "at",
    "himself", "herself", "itself", "themselves",
    "he", "she", "it", "they", "him", "her", "them",
];

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn levenshtein_identical() {
        assert_eq!(levenshtein("hello", "hello"), 0);
    }

    #[test]
    fn levenshtein_one_char_diff() {
        assert_eq!(levenshtein("hello", "hallo"), 1);
    }

    #[test]
    fn levenshtein_insertion() {
        assert_eq!(levenshtein("hello", "helllo"), 1);
    }

    #[test]
    fn levenshtein_deletion() {
        assert_eq!(levenshtein("hello", "helo"), 1);
    }

    #[test]
    fn levenshtein_empty() {
        assert_eq!(levenshtein("", "abc"), 3);
        assert_eq!(levenshtein("abc", ""), 3);
    }

    #[test]
    fn levenshtein_transposition() {
        assert_eq!(levenshtein("ab", "ba"), 2);
    }

    #[test]
    fn find_similar_typo() {
        let result = find_similar("logoc", KNOWN_WORDS, 2);
        assert_eq!(result, Some("logic"));
    }

    #[test]
    fn find_similar_no_match() {
        let result = find_similar("xyzzy", KNOWN_WORDS, 2);
        assert_eq!(result, None);
    }

    #[test]
    fn find_similar_case_insensitive() {
        let result = find_similar("LOGIC", KNOWN_WORDS, 2);
        assert_eq!(result, Some("logic"));
    }
}

```

---

### ANSI Styling

**File:** `src/style.rs`

Style struct with red(), blue(), cyan(), green(), bold_red() methods for terminal color output. Integrated into display_with_source() for compiler-style error presentation.

```rust
pub struct Style;

impl Style {
    pub const RESET: &'static str = "\x1b[0m";
    pub const BOLD: &'static str = "\x1b[1m";
    pub const RED: &'static str = "\x1b[31m";
    pub const GREEN: &'static str = "\x1b[32m";
    pub const YELLOW: &'static str = "\x1b[33m";
    pub const BLUE: &'static str = "\x1b[34m";
    pub const CYAN: &'static str = "\x1b[36m";

    pub fn red(s: &str) -> String {
        format!("{}{}{}", Self::RED, s, Self::RESET)
    }

    pub fn blue(s: &str) -> String {
        format!("{}{}{}", Self::BLUE, s, Self::RESET)
    }

    pub fn cyan(s: &str) -> String {
        format!("{}{}{}", Self::CYAN, s, Self::RESET)
    }

    pub fn yellow(s: &str) -> String {
        format!("{}{}{}", Self::YELLOW, s, Self::RESET)
    }

    pub fn green(s: &str) -> String {
        format!("{}{}{}", Self::GREEN, s, Self::RESET)
    }

    pub fn bold(s: &str) -> String {
        format!("{}{}{}", Self::BOLD, s, Self::RESET)
    }

    pub fn bold_red(s: &str) -> String {
        format!("{}{}{}{}", Self::BOLD, Self::RED, s, Self::RESET)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn red_wraps_string() {
        let result = Style::red("error");
        assert!(result.contains("\x1b[31m"));
        assert!(result.contains("error"));
        assert!(result.contains("\x1b[0m"));
    }

    #[test]
    fn bold_red_combines_codes() {
        let result = Style::bold_red("Error");
        assert!(result.contains("\x1b[1m"));
        assert!(result.contains("\x1b[31m"));
    }
}

```

---

## Debug Utilities

Development and introspection tools.

**Location:** `src/debug.rs`

### Debug Tools

**File:** `src/debug.rs`

DebugWorld for AST introspection. DisplayWith trait for custom formatting during development. Includes Causal expression display support.

```rust
use std::fmt;

use crate::ast::{
    AspectOperator, LogicExpr, NounPhrase, QuantifierKind, TemporalOperator, VoiceOperator, Term,
};
use crate::intern::{Interner, Symbol};
use crate::token::TokenType;

pub trait DisplayWith {
    fn fmt_with(&self, interner: &Interner, f: &mut fmt::Formatter<'_>) -> fmt::Result;

    fn with<'a>(&'a self, interner: &'a Interner) -> WithInterner<'a, Self> {
        WithInterner {
            target: self,
            interner,
        }
    }
}

pub struct WithInterner<'a, T: ?Sized> {
    pub target: &'a T,
    pub interner: &'a Interner,
}

impl<'a, T: DisplayWith> fmt::Display for WithInterner<'a, T> {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        self.target.fmt_with(self.interner, f)
    }
}

pub struct DebugWorld<'a, T: ?Sized> {
    pub target: &'a T,
    pub interner: &'a Interner,
}

impl<'a, T: DisplayWith> fmt::Debug for DebugWorld<'a, T> {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        self.target.fmt_with(self.interner, f)
    }
}

impl DisplayWith for Symbol {
    fn fmt_with(&self, interner: &Interner, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(f, "{}", interner.resolve(*self))
    }
}

impl<'a> DisplayWith for Term<'a> {
    fn fmt_with(&self, interner: &Interner, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            Term::Constant(s) => write!(f, "{}", interner.resolve(*s)),
            Term::Variable(s) => write!(f, "{}", interner.resolve(*s)),
            Term::Function(name, args) => {
                write!(f, "{}(", interner.resolve(*name))?;
                for (i, arg) in args.iter().enumerate() {
                    if i > 0 {
                        write!(f, ", ")?;
                    }
                    arg.fmt_with(interner, f)?;
                }
                write!(f, ")")
            }
            Term::Group(members) => {
                write!(f, "[")?;
                for (i, m) in members.iter().enumerate() {
                    if i > 0 {
                        write!(f, " ⊕ ")?;
                    }
                    m.fmt_with(interner, f)?;
                }
                write!(f, "]")
            }
            Term::Possessed { possessor, possessed } => {
                possessor.fmt_with(interner, f)?;
                write!(f, ".{}", interner.resolve(*possessed))
            }
            Term::Sigma(predicate) => {
                write!(f, "σx.{}(x)", interner.resolve(*predicate))
            }
            Term::Intension(predicate) => {
                write!(f, "^{}", interner.resolve(*predicate))
            }
            Term::Proposition(expr) => {
                write!(f, "[{:?}]", expr)
            }
            Term::Value { kind, unit, dimension } => {
                use crate::ast::NumberKind;
                match kind {
                    NumberKind::Real(r) => write!(f, "{}", r)?,
                    NumberKind::Integer(i) => write!(f, "{}", i)?,
                    NumberKind::Symbolic(s) => write!(f, "{}", interner.resolve(*s))?,
                }
                if let Some(u) = unit {
                    write!(f, " {}", interner.resolve(*u))?;
                }
                if let Some(d) = dimension {
                    write!(f, " [{:?}]", d)?;
                }
                Ok(())
            }
        }
    }
}

impl<'a> DisplayWith for NounPhrase<'a> {
    fn fmt_with(&self, interner: &Interner, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        if let Some(def) = &self.definiteness {
            write!(f, "{:?} ", def)?;
        }
        for adj in self.adjectives {
            write!(f, "{} ", interner.resolve(*adj))?;
        }
        write!(f, "{}", interner.resolve(self.noun))
    }
}

impl<'a> DisplayWith for LogicExpr<'a> {
    fn fmt_with(&self, interner: &Interner, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            LogicExpr::Predicate { name, args } => {
                write!(f, "{}(", interner.resolve(*name))?;
                for (i, arg) in args.iter().enumerate() {
                    if i > 0 {
                        write!(f, ", ")?;
                    }
                    arg.fmt_with(interner, f)?;
                }
                write!(f, ")")
            }
            LogicExpr::Identity { left, right } => {
                left.fmt_with(interner, f)?;
                write!(f, " = ")?;
                right.fmt_with(interner, f)
            }
            LogicExpr::Metaphor { tenor, vehicle } => {
                write!(f, "Metaphor(")?;
                tenor.fmt_with(interner, f)?;
                write!(f, ", ")?;
                vehicle.fmt_with(interner, f)?;
                write!(f, ")")
            }
            LogicExpr::Quantifier { kind, variable, body, .. } => {
                let q = match kind {
                    QuantifierKind::Universal => "∀",
                    QuantifierKind::Existential => "∃",
                    QuantifierKind::Most => "MOST",
                    QuantifierKind::Few => "FEW",
                    QuantifierKind::Many => "MANY",
                    QuantifierKind::Generic => "Gen",
                    QuantifierKind::Cardinal(n) => return write!(f, "∃={}{}.{}", n, interner.resolve(*variable), body.with(interner)),
                    QuantifierKind::AtLeast(n) => return write!(f, "∃≥{}{}.{}", n, interner.resolve(*variable), body.with(interner)),
                    QuantifierKind::AtMost(n) => return write!(f, "∃≤{}{}.{}", n, interner.resolve(*variable), body.with(interner)),
                };
                write!(f, "{}{}.{}", q, interner.resolve(*variable), body.with(interner))
            }
            LogicExpr::Categorical(data) => {
                let q = match &data.quantifier {
                    TokenType::All => "All",
                    TokenType::Some => "Some",
                    TokenType::No => "No",
                    _ => "?",
                };
                let cop = if data.copula_negative { "are not" } else { "are" };
                write!(f, "{} {} {} {}", q, data.subject.with(interner), cop, data.predicate.with(interner))
            }
            LogicExpr::Relation(data) => {
                write!(f, "{}({}, {})", interner.resolve(data.verb), data.subject.with(interner), data.object.with(interner))
            }
            LogicExpr::Modal { vector, operand } => {
                let op = match (vector.domain, vector.force >= 0.5) {
                    (crate::ast::ModalDomain::Alethic, true) => "□",
                    (crate::ast::ModalDomain::Alethic, false) => "◇",
                    (crate::ast::ModalDomain::Deontic, true) => "O",
                    (crate::ast::ModalDomain::Deontic, false) => "P",
                };
                write!(f, "{}({})", op, operand.with(interner))
            }
            LogicExpr::Temporal { operator, body } => {
                let op = match operator {
                    TemporalOperator::Past => "P",
                    TemporalOperator::Future => "F",
                };
                write!(f, "{}({})", op, body.with(interner))
            }
            LogicExpr::Aspectual { operator, body } => {
                let op = match operator {
                    AspectOperator::Progressive => "PROG",
                    AspectOperator::Perfect => "PERF",
                    AspectOperator::Habitual => "HAB",
                    AspectOperator::Iterative => "ITER",
                };
                write!(f, "{}({})", op, body.with(interner))
            }
            LogicExpr::Voice { operator, body } => {
                let op = match operator {
                    VoiceOperator::Passive => "PASS",
                };
                write!(f, "{}({})", op, body.with(interner))
            }
            LogicExpr::BinaryOp { left, op, right } => {
                let sym = match op {
                    TokenType::And => "∧",
                    TokenType::Or => "∨",
                    TokenType::If => "→",
                    TokenType::Iff => "↔",
                    _ => "?",
                };
                write!(f, "({} {} {})", left.with(interner), sym, right.with(interner))
            }
            LogicExpr::UnaryOp { op, operand } => {
                let sym = match op {
                    TokenType::Not => "¬",
                    _ => "?",
                };
                write!(f, "{}({})", sym, operand.with(interner))
            }
            LogicExpr::Question { wh_variable, body } => {
                write!(f, "?{}.{}", interner.resolve(*wh_variable), body.with(interner))
            }
            LogicExpr::YesNoQuestion { body } => {
                write!(f, "?{}", body.with(interner))
            }
            LogicExpr::Atom(s) => write!(f, "{}", interner.resolve(*s)),
            LogicExpr::Lambda { variable, body } => {
                write!(f, "λ{}.{}", interner.resolve(*variable), body.with(interner))
            }
            LogicExpr::App { function, argument } => {
                write!(f, "({})({})", function.with(interner), argument.with(interner))
            }
            LogicExpr::Intensional { operator, content } => {
                write!(f, "{}({})", interner.resolve(*operator), content.with(interner))
            }
            LogicExpr::Event { predicate, adverbs } => {
                predicate.fmt_with(interner, f)?;
                for adv in *adverbs {
                    write!(f, "[{}]", interner.resolve(*adv))?;
                }
                Ok(())
            }
            LogicExpr::NeoEvent(data) => {
                write!(f, "∃{}({}({})", interner.resolve(data.event_var), interner.resolve(data.verb), interner.resolve(data.event_var))?;
                for (role, term) in data.roles.iter() {
                    write!(f, " ∧ {:?}({}, {})", role, interner.resolve(data.event_var), term.with(interner))?;
                }
                for mod_sym in data.modifiers.iter() {
                    write!(f, " ∧ {}({})", interner.resolve(*mod_sym), interner.resolve(data.event_var))?;
                }
                write!(f, ")")
            }
            LogicExpr::Imperative { action } => {
                write!(f, "!({})", action.with(interner))
            }
            LogicExpr::SpeechAct { performer, act_type, content } => {
                write!(f, "{}:{}({})", interner.resolve(*performer), interner.resolve(*act_type), content.with(interner))
            }
            LogicExpr::Counterfactual { antecedent, consequent } => {
                write!(f, "({} □→ {})", antecedent.with(interner), consequent.with(interner))
            }
            LogicExpr::Causal { effect, cause } => {
                write!(f, "Cause({}, {})", cause.with(interner), effect.with(interner))
            }
            LogicExpr::Comparative { adjective, subject, object, difference } => {
                if let Some(diff) = difference {
                    write!(f, "{}({}, {}, by: {})", interner.resolve(*adjective), subject.with(interner), object.with(interner), diff.with(interner))
                } else {
                    write!(f, "{}({}, {})", interner.resolve(*adjective), subject.with(interner), object.with(interner))
                }
            }
            LogicExpr::Superlative { adjective, subject, domain } => {
                write!(f, "MOST-{}({}, {})", interner.resolve(*adjective), subject.with(interner), interner.resolve(*domain))
            }
            LogicExpr::Scopal { operator, body } => {
                write!(f, "{}({})", interner.resolve(*operator), body.with(interner))
            }
            LogicExpr::Control { verb, subject, object, infinitive } => {
                write!(f, "{}(", interner.resolve(*verb))?;
                subject.fmt_with(interner, f)?;
                if let Some(obj) = object {
                    write!(f, ", ")?;
                    obj.fmt_with(interner, f)?;
                }
                write!(f, ", {})", infinitive.with(interner))
            }
            LogicExpr::Presupposition { assertion, presupposition } => {
                write!(f, "[{} | {}]", assertion.with(interner), presupposition.with(interner))
            }
            LogicExpr::Focus { kind, focused, scope } => {
                let k = match kind {
                    crate::token::FocusKind::Only => "ONLY",
                    crate::token::FocusKind::Even => "EVEN",
                    crate::token::FocusKind::Just => "JUST",
                };
                write!(f, "{}[", k)?;
                focused.fmt_with(interner, f)?;
                write!(f, "]({})", scope.with(interner))
            }
            LogicExpr::TemporalAnchor { anchor, body } => {
                write!(f, "@{}({})", interner.resolve(*anchor), body.with(interner))
            }
            LogicExpr::Distributive { predicate } => {
                write!(f, "*")?;
                predicate.fmt_with(interner, f)
            }
            LogicExpr::GroupQuantifier { group_var, count, member_var, restriction, body } => {
                write!(
                    f,
                    "∃{}(Group({}) ∧ Count({}, {}) ∧ ∀{}(Member({}, {}) → ",
                    interner.resolve(*group_var),
                    interner.resolve(*group_var),
                    interner.resolve(*group_var),
                    count,
                    interner.resolve(*member_var),
                    interner.resolve(*member_var),
                    interner.resolve(*group_var)
                )?;
                restriction.fmt_with(interner, f)?;
                write!(f, ") ∧ ")?;
                body.fmt_with(interner, f)?;
                write!(f, ")")
            }
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::arena::Arena;

    #[test]
    fn symbol_display_with_interner() {
        let mut interner = Interner::new();
        let sym = interner.intern("Socrates");
        assert_eq!(sym.with(&interner).to_string(), "Socrates");
    }

    #[test]
    fn symbol_empty_displays_empty() {
        let interner = Interner::new();
        assert_eq!(Symbol::EMPTY.with(&interner).to_string(), "");
    }

    #[test]
    fn term_constant_display() {
        let mut interner = Interner::new();
        let sym = interner.intern("John");
        let term = Term::Constant(sym);
        assert_eq!(term.with(&interner).to_string(), "John");
    }

    #[test]
    fn term_variable_display() {
        let mut interner = Interner::new();
        let x = interner.intern("x");
        let term = Term::Variable(x);
        assert_eq!(term.with(&interner).to_string(), "x");
    }

    #[test]
    fn term_function_display() {
        let mut interner = Interner::new();
        let term_arena: Arena<Term> = Arena::new();
        let f = interner.intern("father");
        let j = interner.intern("John");
        let term = Term::Function(f, term_arena.alloc_slice([Term::Constant(j)]));
        assert_eq!(term.with(&interner).to_string(), "father(John)");
    }

    #[test]
    fn term_group_display() {
        let mut interner = Interner::new();
        let term_arena: Arena<Term> = Arena::new();
        let j = interner.intern("John");
        let m = interner.intern("Mary");
        let term = Term::Group(term_arena.alloc_slice([Term::Constant(j), Term::Constant(m)]));
        assert_eq!(term.with(&interner).to_string(), "[John ⊕ Mary]");
    }

    #[test]
    fn term_possessed_display() {
        let mut interner = Interner::new();
        let term_arena: Arena<Term> = Arena::new();
        let j = interner.intern("John");
        let dog = interner.intern("dog");
        let term = Term::Possessed {
            possessor: term_arena.alloc(Term::Constant(j)),
            possessed: dog,
        };
        assert_eq!(term.with(&interner).to_string(), "John.dog");
    }

    #[test]
    fn expr_predicate_display() {
        let mut interner = Interner::new();
        let term_arena: Arena<Term> = Arena::new();
        let mortal = interner.intern("Mortal");
        let x = interner.intern("x");
        let expr = LogicExpr::Predicate {
            name: mortal,
            args: term_arena.alloc_slice([Term::Variable(x)]),
        };
        assert_eq!(expr.with(&interner).to_string(), "Mortal(x)");
    }

    #[test]
    fn expr_quantifier_display() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let term_arena: Arena<Term> = Arena::new();
        let x = interner.intern("x");
        let mortal = interner.intern("Mortal");
        let body = expr_arena.alloc(LogicExpr::Predicate {
            name: mortal,
            args: term_arena.alloc_slice([Term::Variable(x)]),
        });
        let expr = LogicExpr::Quantifier {
            kind: QuantifierKind::Universal,
            variable: x,
            body,
            island_id: 0,
        };
        assert_eq!(expr.with(&interner).to_string(), "∀x.Mortal(x)");
    }

    #[test]
    fn expr_atom_display() {
        let mut interner = Interner::new();
        let p = interner.intern("P");
        let expr = LogicExpr::Atom(p);
        assert_eq!(expr.with(&interner).to_string(), "P");
    }

    #[test]
    fn expr_binary_op_display() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let p = interner.intern("P");
        let q = interner.intern("Q");
        let expr = LogicExpr::BinaryOp {
            left: expr_arena.alloc(LogicExpr::Atom(p)),
            op: TokenType::And,
            right: expr_arena.alloc(LogicExpr::Atom(q)),
        };
        assert_eq!(expr.with(&interner).to_string(), "(P ∧ Q)");
    }

    #[test]
    fn expr_lambda_display() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let x = interner.intern("x");
        let p = interner.intern("P");
        let expr = LogicExpr::Lambda {
            variable: x,
            body: expr_arena.alloc(LogicExpr::Atom(p)),
        };
        assert_eq!(expr.with(&interner).to_string(), "λx.P");
    }

    #[test]
    fn debug_world_works_with_dbg_pattern() {
        let mut interner = Interner::new();
        let sym = interner.intern("test");
        let term = Term::Constant(sym);
        let debug_str = format!("{:?}", DebugWorld { target: &term, interner: &interner });
        assert!(debug_str.contains("test"));
    }

    #[test]
    fn expr_temporal_display() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let p = interner.intern("Run");
        let expr = LogicExpr::Temporal {
            operator: TemporalOperator::Past,
            body: expr_arena.alloc(LogicExpr::Atom(p)),
        };
        assert_eq!(expr.with(&interner).to_string(), "P(Run)");
    }

    #[test]
    fn expr_modal_display() {
        let mut interner = Interner::new();
        let expr_arena: Arena<LogicExpr> = Arena::new();
        let p = interner.intern("Rain");
        let expr = LogicExpr::Modal {
            vector: crate::ast::ModalVector {
                domain: crate::ast::ModalDomain::Alethic,
                force: 1.0,
                flavor: crate::ast::ModalFlavor::Root,
            },
            operand: expr_arena.alloc(LogicExpr::Atom(p)),
        };
        assert_eq!(expr.with(&interner).to_string(), "□(Rain)");
    }
}

```

---

## Visitor Pattern

Tree traversal infrastructure for AST analysis.

**Location:** `src/visitor.rs`

### Visitor Trait

**File:** `src/visitor.rs`

Visitor trait with walk_expr() and walk_term() functions for AST traversal. Enables analysis passes without manual recursion.

```rust
use crate::ast::{LogicExpr, NounPhrase, Term};

pub trait Visitor<'a>: Sized {
    fn visit_expr(&mut self, expr: &'a LogicExpr<'a>) {
        walk_expr(self, expr);
    }

    fn visit_term(&mut self, term: &'a Term<'a>) {
        walk_term(self, term);
    }

    fn visit_np(&mut self, np: &'a NounPhrase<'a>) {
        walk_np(self, np);
    }
}

pub fn walk_expr<'a, V: Visitor<'a>>(v: &mut V, expr: &'a LogicExpr<'a>) {
    match expr {
        LogicExpr::Predicate { args, .. } => {
            for arg in *args {
                v.visit_term(arg);
            }
        }

        LogicExpr::Identity { left, right } => {
            v.visit_term(left);
            v.visit_term(right);
        }

        LogicExpr::Metaphor { tenor, vehicle } => {
            v.visit_term(tenor);
            v.visit_term(vehicle);
        }

        LogicExpr::Quantifier { body, .. } => {
            v.visit_expr(body);
        }

        LogicExpr::Categorical(data) => {
            v.visit_np(&data.subject);
            v.visit_np(&data.predicate);
        }

        LogicExpr::Relation(data) => {
            v.visit_np(&data.subject);
            v.visit_np(&data.object);
        }

        LogicExpr::Modal { operand, .. } => {
            v.visit_expr(operand);
        }

        LogicExpr::Temporal { body, .. } => {
            v.visit_expr(body);
        }

        LogicExpr::Aspectual { body, .. } => {
            v.visit_expr(body);
        }

        LogicExpr::Voice { body, .. } => {
            v.visit_expr(body);
        }

        LogicExpr::BinaryOp { left, right, .. } => {
            v.visit_expr(left);
            v.visit_expr(right);
        }

        LogicExpr::UnaryOp { operand, .. } => {
            v.visit_expr(operand);
        }

        LogicExpr::Question { body, .. } => {
            v.visit_expr(body);
        }

        LogicExpr::YesNoQuestion { body } => {
            v.visit_expr(body);
        }

        LogicExpr::Atom(_) => {}

        LogicExpr::Lambda { body, .. } => {
            v.visit_expr(body);
        }

        LogicExpr::App { function, argument } => {
            v.visit_expr(function);
            v.visit_expr(argument);
        }

        LogicExpr::Intensional { content, .. } => {
            v.visit_expr(content);
        }

        LogicExpr::Event { predicate, .. } => {
            v.visit_expr(predicate);
        }

        LogicExpr::NeoEvent(data) => {
            for (_, term) in data.roles.iter() {
                v.visit_term(term);
            }
        }

        LogicExpr::Imperative { action } => {
            v.visit_expr(action);
        }

        LogicExpr::SpeechAct { content, .. } => {
            v.visit_expr(content);
        }

        LogicExpr::Counterfactual { antecedent, consequent } => {
            v.visit_expr(antecedent);
            v.visit_expr(consequent);
        }

        LogicExpr::Causal { effect, cause } => {
            v.visit_expr(cause);
            v.visit_expr(effect);
        }

        LogicExpr::Comparative { subject, object, .. } => {
            v.visit_term(subject);
            v.visit_term(object);
        }

        LogicExpr::Superlative { subject, .. } => {
            v.visit_term(subject);
        }

        LogicExpr::Scopal { body, .. } => {
            v.visit_expr(body);
        }

        LogicExpr::Control { subject, object, infinitive, .. } => {
            v.visit_term(subject);
            if let Some(obj) = object {
                v.visit_term(obj);
            }
            v.visit_expr(infinitive);
        }

        LogicExpr::Presupposition { assertion, presupposition } => {
            v.visit_expr(assertion);
            v.visit_expr(presupposition);
        }

        LogicExpr::Focus { focused, scope, .. } => {
            v.visit_term(focused);
            v.visit_expr(scope);
        }

        LogicExpr::TemporalAnchor { body, .. } => {
            v.visit_expr(body);
        }

        LogicExpr::Distributive { predicate } => {
            v.visit_expr(predicate);
        }

        LogicExpr::GroupQuantifier { restriction, body, .. } => {
            v.visit_expr(restriction);
            v.visit_expr(body);
        }
    }
}

pub fn walk_term<'a, V: Visitor<'a>>(v: &mut V, term: &'a Term<'a>) {
    match term {
        Term::Constant(_) | Term::Variable(_) | Term::Sigma(_) | Term::Intension(_) | Term::Value { .. } => {}

        Term::Function(_, args) => {
            for arg in *args {
                v.visit_term(arg);
            }
        }

        Term::Group(members) => {
            for m in *members {
                v.visit_term(m);
            }
        }

        Term::Possessed { possessor, .. } => {
            v.visit_term(possessor);
        }

        Term::Proposition(expr) => {
            v.visit_expr(expr);
        }
    }
}

pub fn walk_np<'a, V: Visitor<'a>>(v: &mut V, np: &'a NounPhrase<'a>) {
    if let Some(poss) = np.possessor {
        v.visit_np(poss);
    }
    for pp in np.pps.iter() {
        v.visit_expr(pp);
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::intern::Symbol;

    struct VariableCollector {
        variables: Vec<Symbol>,
    }

    impl<'a> Visitor<'a> for VariableCollector {
        fn visit_term(&mut self, term: &'a Term<'a>) {
            if let Term::Variable(sym) = term {
                self.variables.push(*sym);
            }
            walk_term(self, term);
        }
    }

    struct ExprCounter {
        count: usize,
    }

    impl<'a> Visitor<'a> for ExprCounter {
        fn visit_expr(&mut self, expr: &'a LogicExpr<'a>) {
            self.count += 1;
            walk_expr(self, expr);
        }
    }

    #[test]
    fn variable_collector_finds_variables() {
        use crate::arena::Arena;
        use crate::intern::Interner;

        let mut interner = Interner::new();
        let x = interner.intern("x");
        let y = interner.intern("y");

        let term_arena: Arena<Term> = Arena::new();
        let terms = term_arena.alloc_slice([Term::Variable(x), Term::Variable(y)]);

        let expr_arena: Arena<LogicExpr> = Arena::new();
        let pred = interner.intern("P");
        let expr = expr_arena.alloc(LogicExpr::Predicate { name: pred, args: terms });

        let mut collector = VariableCollector { variables: vec![] };
        collector.visit_expr(expr);

        assert_eq!(collector.variables.len(), 2);
        assert!(collector.variables.contains(&x));
        assert!(collector.variables.contains(&y));
    }

    #[test]
    fn expr_counter_counts_nested() {
        use crate::arena::Arena;
        use crate::intern::Interner;
        use crate::token::TokenType;

        let mut interner = Interner::new();
        let p = interner.intern("P");
        let q = interner.intern("Q");

        let expr_arena: Arena<LogicExpr> = Arena::new();

        let left = expr_arena.alloc(LogicExpr::Atom(p));
        let right = expr_arena.alloc(LogicExpr::Atom(q));
        let binary = expr_arena.alloc(LogicExpr::BinaryOp {
            left,
            op: TokenType::And,
            right,
        });

        let mut counter = ExprCounter { count: 0 };
        counter.visit_expr(binary);

        assert_eq!(counter.count, 3);
    }
}

```

---

## Test Utilities

Helper functions for unit and integration testing.

**Location:** `src/test_utils.rs`

### Test Helpers

**File:** `src/test_utils.rs`

Utility functions for constructing test cases and validating transpilation output. assert_snapshot! macro for golden master testing. Snapshots stored in tests/snapshots/. Set UPDATE_SNAPSHOTS=1 to regenerate.

```rust
use crate::ast::{AspectOperator, ModalDomain, ModalVector, QuantifierKind, TemporalOperator};
use crate::token::{FocusKind, TokenType};
use crate::view::{ExprView, NounPhraseView, TermView};
use crate::lexicon::Definiteness;

#[macro_export]
macro_rules! assert_snapshot {
    ($name:expr, $actual:expr) => {{
        let manifest_dir = std::env::var("CARGO_MANIFEST_DIR")
            .expect("CARGO_MANIFEST_DIR not set");
        let snapshot_dir = std::path::Path::new(&manifest_dir)
            .join("tests")
            .join("snapshots");
        let snapshot_path = snapshot_dir.join(format!("{}.txt", $name));

        if !snapshot_dir.exists() {
            std::fs::create_dir_all(&snapshot_dir).expect("Failed to create snapshot dir");
        }

        let actual_str = $actual.trim();
        let force_update = std::env::var("UPDATE_SNAPSHOTS").is_ok();

        if force_update || !snapshot_path.exists() {
            std::fs::write(&snapshot_path, actual_str).expect("Failed to write snapshot");
            println!("Snapshot created/updated: {:?}", snapshot_path);
        } else {
            let expected = std::fs::read_to_string(&snapshot_path)
                .expect("Failed to read snapshot");
            let expected_str = expected.trim();

            if actual_str != expected_str {
                panic!(
                    "\nSnapshot Mismatch: {}\n\nExpected:\n{}\n\nActual:\n{}\n\n\
                    Run `UPDATE_SNAPSHOTS=1 cargo test` to update.\n",
                    $name, expected_str, actual_str
                );
            }
        }
    }};
}

#[macro_export]
macro_rules! parse {
    ($input:expr) => {{
        use $crate::{Arena, AstContext, LogicExpr, Interner, Lexer, NounPhrase, Parser, Resolve, Symbol, Term, ThematicRole};

        let interner: &'static mut Interner = Box::leak(Box::new(Interner::new()));
        let expr_arena: &'static Arena<LogicExpr> = Box::leak(Box::new(Arena::new()));
        let term_arena: &'static Arena<Term> = Box::leak(Box::new(Arena::new()));
        let np_arena: &'static Arena<NounPhrase> = Box::leak(Box::new(Arena::new()));
        let sym_arena: &'static Arena<Symbol> = Box::leak(Box::new(Arena::new()));
        let role_arena: &'static Arena<(ThematicRole, Term)> = Box::leak(Box::new(Arena::new()));
        let pp_arena: &'static Arena<&'static LogicExpr> = Box::leak(Box::new(Arena::new()));

        let ctx = AstContext::new(
            expr_arena,
            term_arena,
            np_arena,
            sym_arena,
            role_arena,
            pp_arena,
        );

        let mut lexer = Lexer::new($input, interner);
        let tokens = lexer.tokenize();

        let mut parser = Parser::new(tokens, interner, ctx);

        let ast = parser.parse().unwrap();
        ast.resolve(interner)
    }};
}

pub mod dsl {
    use super::*;

    fn b<T>(t: T) -> Box<T> {
        Box::new(t)
    }

    // === Terms ===
    pub fn c(name: &'static str) -> TermView<'static> {
        TermView::Constant(name)
    }

    pub fn v(name: &'static str) -> TermView<'static> {
        TermView::Variable(name)
    }

    pub fn func(name: &'static str, args: Vec<TermView<'static>>) -> TermView<'static> {
        TermView::Function(name, args)
    }

    pub fn group(members: Vec<TermView<'static>>) -> TermView<'static> {
        TermView::Group(members)
    }

    pub fn possessed(possessor: TermView<'static>, possessed: &'static str) -> TermView<'static> {
        TermView::Possessed {
            possessor: b(possessor),
            possessed,
        }
    }

    // === Atoms & Predicates ===
    pub fn atom(s: &'static str) -> ExprView<'static> {
        ExprView::Atom(s)
    }

    pub fn pred(name: &'static str, args: Vec<TermView<'static>>) -> ExprView<'static> {
        ExprView::Predicate { name, args }
    }

    pub fn pred1(name: &'static str, arg: &'static str) -> ExprView<'static> {
        pred(name, vec![c(arg)])
    }

    pub fn pred1v(name: &'static str, var: &'static str) -> ExprView<'static> {
        pred(name, vec![v(var)])
    }

    pub fn pred2(name: &'static str, a1: &'static str, a2: &'static str) -> ExprView<'static> {
        pred(name, vec![c(a1), c(a2)])
    }

    pub fn pred2v(name: &'static str, v1: &'static str, v2: &'static str) -> ExprView<'static> {
        pred(name, vec![v(v1), v(v2)])
    }

    // === Identity ===
    pub fn identity(left: TermView<'static>, right: TermView<'static>) -> ExprView<'static> {
        ExprView::Identity { left, right }
    }

    // === Quantifiers ===
    pub fn forall(var: &'static str, body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Quantifier {
            kind: QuantifierKind::Universal,
            variable: var,
            body: b(body),
        }
    }

    pub fn exists(var: &'static str, body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Quantifier {
            kind: QuantifierKind::Existential,
            variable: var,
            body: b(body),
        }
    }

    pub fn most(var: &'static str, body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Quantifier {
            kind: QuantifierKind::Most,
            variable: var,
            body: b(body),
        }
    }

    pub fn few(var: &'static str, body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Quantifier {
            kind: QuantifierKind::Few,
            variable: var,
            body: b(body),
        }
    }

    pub fn cardinal(n: u32, var: &'static str, body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Quantifier {
            kind: QuantifierKind::Cardinal(n),
            variable: var,
            body: b(body),
        }
    }

    pub fn at_least(n: u32, var: &'static str, body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Quantifier {
            kind: QuantifierKind::AtLeast(n),
            variable: var,
            body: b(body),
        }
    }

    pub fn at_most(n: u32, var: &'static str, body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Quantifier {
            kind: QuantifierKind::AtMost(n),
            variable: var,
            body: b(body),
        }
    }

    // === Temporal ===
    pub fn past(body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Temporal {
            operator: TemporalOperator::Past,
            body: b(body),
        }
    }

    pub fn future(body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Temporal {
            operator: TemporalOperator::Future,
            body: b(body),
        }
    }

    // === Aspect ===
    pub fn prog(body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Aspectual {
            operator: AspectOperator::Progressive,
            body: b(body),
        }
    }

    pub fn perf(body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Aspectual {
            operator: AspectOperator::Perfect,
            body: b(body),
        }
    }

    // === Modal ===
    pub fn necessity(body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Modal {
            vector: ModalVector {
                domain: ModalDomain::Alethic,
                force: 1.0,
                flavor: crate::ast::ModalFlavor::Root,
            },
            operand: b(body),
        }
    }

    pub fn possibility(body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Modal {
            vector: ModalVector {
                domain: ModalDomain::Alethic,
                force: 0.0,
                flavor: crate::ast::ModalFlavor::Root,
            },
            operand: b(body),
        }
    }

    pub fn obligation(force: f32, body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Modal {
            vector: ModalVector {
                domain: ModalDomain::Deontic,
                force,
                flavor: crate::ast::ModalFlavor::Root,
            },
            operand: b(body),
        }
    }

    pub fn modal(domain: ModalDomain, force: f32, body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Modal {
            vector: ModalVector { domain, force, flavor: crate::ast::ModalFlavor::Root },
            operand: b(body),
        }
    }

    // === Binary Ops ===
    pub fn and(left: ExprView<'static>, right: ExprView<'static>) -> ExprView<'static> {
        ExprView::BinaryOp {
            left: b(left),
            op: TokenType::And,
            right: b(right),
        }
    }

    pub fn or(left: ExprView<'static>, right: ExprView<'static>) -> ExprView<'static> {
        ExprView::BinaryOp {
            left: b(left),
            op: TokenType::Or,
            right: b(right),
        }
    }

    pub fn implies(left: ExprView<'static>, right: ExprView<'static>) -> ExprView<'static> {
        ExprView::BinaryOp {
            left: b(left),
            op: TokenType::If,
            right: b(right),
        }
    }

    pub fn iff(left: ExprView<'static>, right: ExprView<'static>) -> ExprView<'static> {
        ExprView::BinaryOp {
            left: b(left),
            op: TokenType::Iff,
            right: b(right),
        }
    }

    // === Unary Ops ===
    pub fn not(body: ExprView<'static>) -> ExprView<'static> {
        ExprView::UnaryOp {
            op: TokenType::Not,
            operand: b(body),
        }
    }

    // === Lambda & Application ===
    pub fn lambda(var: &'static str, body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Lambda {
            variable: var,
            body: b(body),
        }
    }

    pub fn app(func: ExprView<'static>, arg: ExprView<'static>) -> ExprView<'static> {
        ExprView::App {
            function: b(func),
            argument: b(arg),
        }
    }

    // === Questions ===
    pub fn wh_question(var: &'static str, body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Question {
            wh_variable: var,
            body: b(body),
        }
    }

    pub fn yes_no_question(body: ExprView<'static>) -> ExprView<'static> {
        ExprView::YesNoQuestion { body: b(body) }
    }

    // === Intensional ===
    pub fn intensional(op: &'static str, content: ExprView<'static>) -> ExprView<'static> {
        ExprView::Intensional {
            operator: op,
            content: b(content),
        }
    }

    // === Event ===
    pub fn event(pred: ExprView<'static>, adverbs: Vec<&'static str>) -> ExprView<'static> {
        ExprView::Event {
            predicate: b(pred),
            adverbs,
        }
    }

    // === Imperative ===
    pub fn imperative(action: ExprView<'static>) -> ExprView<'static> {
        ExprView::Imperative { action: b(action) }
    }

    // === Speech Act ===
    pub fn speech_act(
        performer: &'static str,
        act_type: &'static str,
        content: ExprView<'static>,
    ) -> ExprView<'static> {
        ExprView::SpeechAct {
            performer,
            act_type,
            content: b(content),
        }
    }

    // === Counterfactual ===
    pub fn counterfactual(
        antecedent: ExprView<'static>,
        consequent: ExprView<'static>,
    ) -> ExprView<'static> {
        ExprView::Counterfactual {
            antecedent: b(antecedent),
            consequent: b(consequent),
        }
    }

    // === Comparative & Superlative ===
    pub fn comparative(
        adj: &'static str,
        subject: TermView<'static>,
        object: TermView<'static>,
    ) -> ExprView<'static> {
        ExprView::Comparative {
            adjective: adj,
            subject,
            object,
            difference: None,
        }
    }

    pub fn superlative(
        adj: &'static str,
        subject: TermView<'static>,
        domain: &'static str,
    ) -> ExprView<'static> {
        ExprView::Superlative {
            adjective: adj,
            subject,
            domain,
        }
    }

    // === Scopal ===
    pub fn scopal(op: &'static str, body: ExprView<'static>) -> ExprView<'static> {
        ExprView::Scopal {
            operator: op,
            body: b(body),
        }
    }

    // === Control ===
    pub fn control(
        verb: &'static str,
        subject: TermView<'static>,
        object: Option<TermView<'static>>,
        infinitive: ExprView<'static>,
    ) -> ExprView<'static> {
        ExprView::Control {
            verb,
            subject,
            object,
            infinitive: b(infinitive),
        }
    }

    // === Presupposition ===
    pub fn presupposition(
        assertion: ExprView<'static>,
        presup: ExprView<'static>,
    ) -> ExprView<'static> {
        ExprView::Presupposition {
            assertion: b(assertion),
            presupposition: b(presup),
        }
    }

    // === Focus ===
    pub fn focus_only(
        focused: TermView<'static>,
        scope: ExprView<'static>,
    ) -> ExprView<'static> {
        ExprView::Focus {
            kind: FocusKind::Only,
            focused,
            scope: b(scope),
        }
    }

    pub fn focus_even(
        focused: TermView<'static>,
        scope: ExprView<'static>,
    ) -> ExprView<'static> {
        ExprView::Focus {
            kind: FocusKind::Even,
            focused,
            scope: b(scope),
        }
    }

    pub fn focus_just(
        focused: TermView<'static>,
        scope: ExprView<'static>,
    ) -> ExprView<'static> {
        ExprView::Focus {
            kind: FocusKind::Just,
            focused,
            scope: b(scope),
        }
    }

    // === Temporal Anchor ===
    pub fn temporal_anchor(anchor: &'static str, body: ExprView<'static>) -> ExprView<'static> {
        ExprView::TemporalAnchor {
            anchor,
            body: b(body),
        }
    }

    // === Categorical (legacy support) ===
    pub fn categorical(
        quantifier: TokenType,
        subject: NounPhraseView<'static>,
        copula_negative: bool,
        predicate: NounPhraseView<'static>,
    ) -> ExprView<'static> {
        ExprView::Categorical {
            quantifier,
            subject,
            copula_negative,
            predicate,
        }
    }

    // === Relation (legacy support) ===
    pub fn relation(
        subject: NounPhraseView<'static>,
        verb: &'static str,
        object: NounPhraseView<'static>,
    ) -> ExprView<'static> {
        ExprView::Relation {
            subject,
            verb,
            object,
        }
    }

    // === NounPhrase builders ===
    pub fn np(noun: &'static str) -> NounPhraseView<'static> {
        NounPhraseView {
            definiteness: None,
            adjectives: vec![],
            noun,
            possessor: None,
            pps: vec![],
            superlative: None,
        }
    }

    pub fn np_def(definiteness: Definiteness, noun: &'static str) -> NounPhraseView<'static> {
        NounPhraseView {
            definiteness: Some(definiteness),
            adjectives: vec![],
            noun,
            possessor: None,
            pps: vec![],
            superlative: None,
        }
    }

    pub fn np_adj(
        adjectives: Vec<&'static str>,
        noun: &'static str,
    ) -> NounPhraseView<'static> {
        NounPhraseView {
            definiteness: None,
            adjectives,
            noun,
            possessor: None,
            pps: vec![],
            superlative: None,
        }
    }

    pub fn np_full(
        definiteness: Option<Definiteness>,
        adjectives: Vec<&'static str>,
        noun: &'static str,
        possessor: Option<NounPhraseView<'static>>,
    ) -> NounPhraseView<'static> {
        NounPhraseView {
            definiteness,
            adjectives,
            noun,
            possessor: possessor.map(Box::new),
            pps: vec![],
            superlative: None,
        }
    }
}

#[cfg(test)]
mod tests {
    use super::dsl::*;
    use crate::ast::{ModalDomain, QuantifierKind, TemporalOperator};
    use crate::token::TokenType;
    use crate::view::{ExprView, TermView};

    #[test]
    fn dsl_constant_term() {
        let term = c("John");
        assert_eq!(term, TermView::Constant("John"));
    }

    #[test]
    fn dsl_variable_term() {
        let term = v("x");
        assert_eq!(term, TermView::Variable("x"));
    }

    #[test]
    fn dsl_atom() {
        let expr = atom("P");
        assert_eq!(expr, ExprView::Atom("P"));
    }

    #[test]
    fn dsl_pred1() {
        let expr = pred1("Run", "John");
        assert_eq!(
            expr,
            ExprView::Predicate {
                name: "Run",
                args: vec![TermView::Constant("John")],
            }
        );
    }

    #[test]
    fn dsl_pred2() {
        let expr = pred2("Love", "John", "Mary");
        assert_eq!(
            expr,
            ExprView::Predicate {
                name: "Love",
                args: vec![
                    TermView::Constant("John"),
                    TermView::Constant("Mary")
                ],
            }
        );
    }

    #[test]
    fn dsl_forall() {
        let expr = forall("x", pred1v("P", "x"));
        assert_eq!(
            expr,
            ExprView::Quantifier {
                kind: QuantifierKind::Universal,
                variable: "x",
                body: Box::new(ExprView::Predicate {
                    name: "P",
                    args: vec![TermView::Variable("x")],
                }),
            }
        );
    }

    #[test]
    fn dsl_exists() {
        let expr = exists("x", pred1v("P", "x"));
        assert_eq!(
            expr,
            ExprView::Quantifier {
                kind: QuantifierKind::Existential,
                variable: "x",
                body: Box::new(ExprView::Predicate {
                    name: "P",
                    args: vec![TermView::Variable("x")],
                }),
            }
        );
    }

    #[test]
    fn dsl_past() {
        let expr = past(pred1("Run", "John"));
        assert_eq!(
            expr,
            ExprView::Temporal {
                operator: TemporalOperator::Past,
                body: Box::new(ExprView::Predicate {
                    name: "Run",
                    args: vec![TermView::Constant("John")],
                }),
            }
        );
    }

    #[test]
    fn dsl_and() {
        let expr = and(atom("P"), atom("Q"));
        assert_eq!(
            expr,
            ExprView::BinaryOp {
                left: Box::new(ExprView::Atom("P")),
                op: TokenType::And,
                right: Box::new(ExprView::Atom("Q")),
            }
        );
    }

    #[test]
    fn dsl_implies() {
        let expr = implies(atom("P"), atom("Q"));
        assert_eq!(
            expr,
            ExprView::BinaryOp {
                left: Box::new(ExprView::Atom("P")),
                op: TokenType::If,
                right: Box::new(ExprView::Atom("Q")),
            }
        );
    }

    #[test]
    fn dsl_not() {
        let expr = not(atom("P"));
        assert_eq!(
            expr,
            ExprView::UnaryOp {
                op: TokenType::Not,
                operand: Box::new(ExprView::Atom("P")),
            }
        );
    }

    #[test]
    fn dsl_lambda() {
        let expr = lambda("x", pred1v("P", "x"));
        assert_eq!(
            expr,
            ExprView::Lambda {
                variable: "x",
                body: Box::new(ExprView::Predicate {
                    name: "P",
                    args: vec![TermView::Variable("x")],
                }),
            }
        );
    }

    #[test]
    fn dsl_modal_necessity() {
        let expr = necessity(atom("Rain"));
        if let ExprView::Modal { vector, operand } = expr {
            assert_eq!(vector.domain, ModalDomain::Alethic);
            assert_eq!(vector.force, 1.0);
            assert_eq!(*operand, ExprView::Atom("Rain"));
        } else {
            panic!("Expected Modal");
        }
    }

    #[test]
    fn dsl_complex_nested() {
        let expr = forall(
            "x",
            implies(pred1v("Human", "x"), pred1v("Mortal", "x")),
        );

        assert_eq!(
            expr,
            ExprView::Quantifier {
                kind: QuantifierKind::Universal,
                variable: "x",
                body: Box::new(ExprView::BinaryOp {
                    left: Box::new(ExprView::Predicate {
                        name: "Human",
                        args: vec![TermView::Variable("x")],
                    }),
                    op: TokenType::If,
                    right: Box::new(ExprView::Predicate {
                        name: "Mortal",
                        args: vec![TermView::Variable("x")],
                    }),
                }),
            }
        );
    }

    #[test]
    fn dsl_box_is_hidden() {
        let expr = past(pred1("Run", "John"));
        if let ExprView::Temporal { body, .. } = expr {
            assert!(matches!(*body, ExprView::Predicate { .. }));
        }
    }

    #[test]
    fn parse_macro_returns_static_view() {
        let view = crate::parse!("John ran.");
        assert!(
            matches!(view, ExprView::NeoEvent { .. }) || matches!(view, ExprView::Temporal { .. }),
            "Expected NeoEvent or Temporal, got {:?}", view
        );
    }

    #[test]
    fn snapshot_macro_creates_file() {
        let output = "test output";
        crate::assert_snapshot!("test_snapshot_macro", output);
    }
}

```

---

## Pragmatics

Speech act theory and modal-to-imperative conversion.

**Location:** `src/pragmatics.rs`

### Pragmatics Module

**File:** `src/pragmatics.rs`

Modal-to-imperative conversion for indirect speech acts. Detects when modal questions should be interpreted as imperatives (e.g., 'Can you pass the salt?' → Pass(you, salt), 'Could you please open the door?' → Open(you, door)). Handles both Expr::NeoEvent and Expr::Predicate forms for addressee detection.

```rust
use crate::ast::{LogicExpr, ModalDomain, ThematicRole, Term};
use crate::arena::Arena;
use crate::intern::Interner;

pub fn apply_pragmatics<'a>(
    expr: &'a LogicExpr<'a>,
    expr_arena: &'a Arena<LogicExpr<'a>>,
    interner: &Interner,
) -> &'a LogicExpr<'a> {
    match expr {
        LogicExpr::Modal { vector, operand } => {
            if vector.domain == ModalDomain::Alethic && vector.force > 0.0 && vector.force < 1.0 {
                if is_addressee_agent(operand, interner) {
                    return expr_arena.alloc(LogicExpr::Imperative { action: *operand });
                }
            }
            expr
        }
        LogicExpr::Question { body, .. } => {
            if let LogicExpr::Modal { vector, operand } = body {
                if vector.domain == ModalDomain::Alethic && vector.force > 0.0 && vector.force < 1.0 {
                    if is_addressee_agent(operand, interner) {
                        return expr_arena.alloc(LogicExpr::Imperative { action: *operand });
                    }
                }
            }
            expr
        }
        LogicExpr::YesNoQuestion { body } => {
            if let LogicExpr::Modal { vector, operand } = body {
                if vector.domain == ModalDomain::Alethic && vector.force > 0.0 && vector.force < 1.0 {
                    if is_addressee_agent(operand, interner) {
                        return expr_arena.alloc(LogicExpr::Imperative { action: *operand });
                    }
                }
            }
            expr
        }
        _ => expr,
    }
}

fn is_addressee_agent(expr: &LogicExpr, interner: &Interner) -> bool {
    match expr {
        LogicExpr::NeoEvent(data) => {
            for (role, term) in data.roles.iter() {
                if *role == ThematicRole::Agent {
                    if let Term::Constant(sym) = term {
                        let name = interner.resolve(*sym);
                        if name == "Addressee" {
                            return true;
                        }
                    }
                }
            }
            false
        }
        LogicExpr::Predicate { args, .. } => {
            if let Some(Term::Constant(sym)) = args.first() {
                let name = interner.resolve(*sym);
                return name == "Addressee";
            }
            false
        }
        _ => false,
    }
}

```

---

## Gamification

Achievement system, progress tracking, and spaced repetition for learning engagement.

**Location:** `src/achievements.rs`, `src/progress.rs`, `src/game.rs`, `src/srs.rs`

### Achievements

**File:** `src/achievements.rs`

Achievement system with unlock conditions and tracking. Defines achievements for milestones (first problem, streak, mastery). Checks unlock conditions and emits events for UI notifications.

```rust
use crate::progress::UserProgress;

#[derive(Debug, Clone, PartialEq, Eq)]
pub struct Achievement {
    pub id: &'static str,
    pub title: &'static str,
    pub description: &'static str,
    pub xp_reward: u64,
    pub unlocks_title: Option<&'static str>,
    pub grants_freeze: bool,
}

pub const ACHIEVEMENTS: &[Achievement] = &[
    Achievement {
        id: "first_blood",
        title: "First Blood",
        description: "Answer your first question correctly",
        xp_reward: 50,
        unlocks_title: None,
        grants_freeze: false,
    },
    Achievement {
        id: "combo_5",
        title: "On Fire",
        description: "Get a 5-answer combo",
        xp_reward: 100,
        unlocks_title: None,
        grants_freeze: false,
    },
    Achievement {
        id: "combo_10",
        title: "Unstoppable",
        description: "Get a 10-answer combo",
        xp_reward: 250,
        unlocks_title: Some("Logic Machine"),
        grants_freeze: false,
    },
    Achievement {
        id: "combo_25",
        title: "Terminator",
        description: "Get a 25-answer combo",
        xp_reward: 500,
        unlocks_title: Some("Automaton"),
        grants_freeze: false,
    },
    Achievement {
        id: "streak_3",
        title: "Getting Started",
        description: "Maintain a 3-day streak",
        xp_reward: 75,
        unlocks_title: None,
        grants_freeze: false,
    },
    Achievement {
        id: "streak_7",
        title: "Week Warrior",
        description: "Maintain a 7-day streak",
        xp_reward: 200,
        unlocks_title: Some("Dedicated"),
        grants_freeze: true,
    },
    Achievement {
        id: "streak_14",
        title: "Fortnight Fighter",
        description: "Maintain a 14-day streak",
        xp_reward: 400,
        unlocks_title: None,
        grants_freeze: true,
    },
    Achievement {
        id: "streak_30",
        title: "Monthly Master",
        description: "Maintain a 30-day streak",
        xp_reward: 1000,
        unlocks_title: Some("Logician"),
        grants_freeze: true,
    },
    Achievement {
        id: "perfect_module",
        title: "Flawless",
        description: "Complete a module with no mistakes",
        xp_reward: 300,
        unlocks_title: None,
        grants_freeze: false,
    },
    Achievement {
        id: "century",
        title: "Century",
        description: "Answer 100 questions correctly",
        xp_reward: 500,
        unlocks_title: Some("Scholar"),
        grants_freeze: false,
    },
    Achievement {
        id: "millennium",
        title: "Millennium",
        description: "Answer 1000 questions correctly",
        xp_reward: 2000,
        unlocks_title: Some("Sage"),
        grants_freeze: false,
    },
    Achievement {
        id: "level_10",
        title: "Double Digits",
        description: "Reach level 10",
        xp_reward: 300,
        unlocks_title: None,
        grants_freeze: false,
    },
    Achievement {
        id: "level_25",
        title: "Quarter Century",
        description: "Reach level 25",
        xp_reward: 750,
        unlocks_title: Some("Adept"),
        grants_freeze: false,
    },
    Achievement {
        id: "level_50",
        title: "Half Century",
        description: "Reach level 50",
        xp_reward: 1500,
        unlocks_title: Some("Grandmaster"),
        grants_freeze: false,
    },
];

pub fn get_achievement(id: &str) -> Option<&'static Achievement> {
    ACHIEVEMENTS.iter().find(|a| a.id == id)
}

pub fn check_achievements(progress: &UserProgress) -> Vec<&'static Achievement> {
    let mut newly_unlocked = Vec::new();

    for achievement in ACHIEVEMENTS {
        if progress.achievements.contains(achievement.id) {
            continue;
        }

        let earned = match achievement.id {
            "first_blood" => total_correct(progress) >= 1,
            "combo_5" => progress.best_combo >= 5,
            "combo_10" => progress.best_combo >= 10,
            "combo_25" => progress.best_combo >= 25,
            "streak_3" => progress.streak_days >= 3,
            "streak_7" => progress.streak_days >= 7,
            "streak_14" => progress.streak_days >= 14,
            "streak_30" => progress.streak_days >= 30,
            "century" => total_correct(progress) >= 100,
            "millennium" => total_correct(progress) >= 1000,
            "level_10" => progress.level >= 10,
            "level_25" => progress.level >= 25,
            "level_50" => progress.level >= 50,
            "perfect_module" => false, // Checked separately in lesson completion
            _ => false,
        };

        if earned {
            newly_unlocked.push(achievement);
        }
    }

    newly_unlocked
}

fn total_correct(progress: &UserProgress) -> u32 {
    progress.exercises.values().map(|e| e.correct_count).sum()
}

pub fn unlock_achievement(progress: &mut UserProgress, achievement: &Achievement) {
    progress.achievements.insert(achievement.id.to_string());
    progress.xp += achievement.xp_reward;
    progress.level = crate::progress::calculate_level(progress.xp);

    if let Some(title) = achievement.unlocks_title {
        if progress.title.is_none() {
            progress.title = Some(title.to_string());
        }
    }

    if achievement.grants_freeze && progress.streak_freezes < 3 {
        progress.streak_freezes += 1;
    }

    progress.save();
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_get_achievement() {
        let achievement = get_achievement("first_blood");
        assert!(achievement.is_some());
        assert_eq!(achievement.unwrap().title, "First Blood");
    }

    #[test]
    fn test_achievement_not_found() {
        let achievement = get_achievement("nonexistent");
        assert!(achievement.is_none());
    }

    #[test]
    fn test_check_achievements_first_blood() {
        let mut progress = UserProgress::new();
        progress.record_attempt("test", true);

        let newly_unlocked = check_achievements(&progress);
        assert!(newly_unlocked.iter().any(|a| a.id == "first_blood"));
    }

    #[test]
    fn test_check_achievements_combo() {
        let mut progress = UserProgress::new();
        progress.best_combo = 5;

        let newly_unlocked = check_achievements(&progress);
        assert!(newly_unlocked.iter().any(|a| a.id == "combo_5"));
        assert!(!newly_unlocked.iter().any(|a| a.id == "combo_10"));
    }

    #[test]
    fn test_streak_achievements_grant_freeze() {
        let streak_7 = get_achievement("streak_7").unwrap();
        assert!(streak_7.grants_freeze);

        let first_blood = get_achievement("first_blood").unwrap();
        assert!(!first_blood.grants_freeze);
    }
}

```

---

### Progress Tracking

**File:** `src/progress.rs`

Lesson and module progress tracking. Tracks completion status, scores, and time spent. Persists progress to storage for cross-session continuity.

```rust
use serde::{Deserialize, Serialize};
use std::collections::{HashMap, HashSet};

#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct UserProgress {
    pub xp: u64,
    pub level: u32,
    pub streak_days: u32,
    pub last_session: Option<String>,
    pub exercises: HashMap<String, ExerciseProgress>,
    pub modules: HashMap<String, ModuleProgress>,
    #[serde(default)]
    pub combo: u32,
    #[serde(default)]
    pub best_combo: u32,
    #[serde(default)]
    pub streak_freezes: u8,
    #[serde(default)]
    pub last_streak_date: Option<String>,
    #[serde(default)]
    pub achievements: HashSet<String>,
    #[serde(default)]
    pub title: Option<String>,
    #[serde(default)]
    pub last_weekly_freeze_date: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExerciseProgress {
    pub exercise_id: String,
    pub attempts: u32,
    pub correct_count: u32,
    pub last_attempt: Option<String>,
    pub srs: SrsData,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SrsData {
    pub ease_factor: f64,
    pub interval: u32,
    pub repetitions: u32,
    pub next_review: Option<String>,
}

impl Default for SrsData {
    fn default() -> Self {
        Self {
            ease_factor: 2.5,
            interval: 1,
            repetitions: 0,
            next_review: None,
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModuleProgress {
    pub module_id: String,
    pub unlocked: bool,
    pub completed: bool,
    pub stars: u8,
    pub best_score: u32,
    pub attempts: u32,
}

impl Default for ModuleProgress {
    fn default() -> Self {
        Self {
            module_id: String::new(),
            unlocked: false,
            completed: false,
            stars: 0,
            best_score: 0,
            attempts: 0,
        }
    }
}

impl UserProgress {
    pub fn new() -> Self {
        Self {
            level: 1,
            ..Default::default()
        }
    }

    pub fn load() -> Self {
        #[cfg(target_arch = "wasm32")]
        {
            crate::storage::load_raw()
                .and_then(|json| serde_json::from_str(&json).ok())
                .unwrap_or_else(Self::new)
        }
        #[cfg(not(target_arch = "wasm32"))]
        {
            Self::new()
        }
    }

    pub fn save(&self) {
        #[cfg(target_arch = "wasm32")]
        {
            if let Ok(json) = serde_json::to_string(self) {
                crate::storage::save_raw(&json);
            }
        }
    }

    pub fn add_xp(&mut self, amount: u64) {
        self.xp += amount;
        self.level = calculate_level(self.xp);
        self.save();
    }

    pub fn record_attempt(&mut self, exercise_id: &str, correct: bool) {
        let entry = self.exercises.entry(exercise_id.to_string()).or_insert_with(|| {
            ExerciseProgress {
                exercise_id: exercise_id.to_string(),
                attempts: 0,
                correct_count: 0,
                last_attempt: None,
                srs: SrsData::default(),
            }
        });

        entry.attempts += 1;
        if correct {
            entry.correct_count += 1;
        }

        self.save();
    }

    pub fn get_exercise_progress(&self, exercise_id: &str) -> Option<&ExerciseProgress> {
        self.exercises.get(exercise_id)
    }

    pub fn get_module_progress(&self, module_id: &str) -> Option<&ModuleProgress> {
        self.modules.get(module_id)
    }

    pub fn update_module_score(&mut self, module_id: &str, score: u32) {
        let entry = self.modules.entry(module_id.to_string()).or_insert_with(|| {
            ModuleProgress {
                module_id: module_id.to_string(),
                ..Default::default()
            }
        });

        entry.attempts += 1;
        if score > entry.best_score {
            entry.best_score = score;
        }

        self.save();
    }
}

pub fn calculate_level(xp: u64) -> u32 {
    ((xp as f64).sqrt() / 10.0).floor() as u32 + 1
}

pub fn xp_for_level(level: u32) -> u64 {
    let l = level as u64;
    l * l * 100
}

pub fn calculate_xp_reward(difficulty: u32, first_try: bool, streak_days: u32) -> u64 {
    let base: u64 = 10;
    let difficulty_bonus = (difficulty.saturating_sub(1) as u64) * 5;
    let first_try_bonus = if first_try { 5 } else { 0 };
    let streak_bonus = (streak_days.min(7) as u64) * 2;

    base + difficulty_bonus + first_try_bonus + streak_bonus
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_level_calculation() {
        assert_eq!(calculate_level(0), 1);
        assert_eq!(calculate_level(100), 2);
        assert_eq!(calculate_level(400), 3);
        assert_eq!(calculate_level(900), 4);
    }

    #[test]
    fn test_xp_reward() {
        assert_eq!(calculate_xp_reward(1, false, 0), 10);
        assert_eq!(calculate_xp_reward(1, true, 0), 15);
        assert_eq!(calculate_xp_reward(2, false, 0), 15);
        assert_eq!(calculate_xp_reward(1, false, 3), 16);
        assert_eq!(calculate_xp_reward(3, true, 5), 10 + 10 + 5 + 10);
    }

    #[test]
    fn test_user_progress_record() {
        let mut progress = UserProgress::new();
        progress.record_attempt("test_q1", true);
        progress.record_attempt("test_q1", false);

        let ex = progress.get_exercise_progress("test_q1").unwrap();
        assert_eq!(ex.attempts, 2);
        assert_eq!(ex.correct_count, 1);
    }
}

```

---

### Game State

**File:** `src/game.rs`

Central game state management. Tracks XP, level, combo/streak counters, and current lesson. Coordinates between achievements, progress, and SRS systems.

```rust
use crate::progress::UserProgress;
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub struct XpReward {
    pub base: u64,
    pub combo_bonus: u64,
    pub streak_bonus: u64,
    pub critical_bonus: u64,
    pub first_try_bonus: u64,
    pub total: u64,
    pub is_critical: bool,
}

pub fn calculate_xp_reward(
    difficulty: u32,
    combo: u32,
    streak_days: u32,
    first_try: bool,
    rng_seed: u64,
) -> XpReward {
    let base = 10 + (difficulty.saturating_sub(1) * 5) as u64;

    let combo_mult = 1.0 + (combo.min(10) as f64 * 0.1);
    let combo_bonus = ((base as f64) * (combo_mult - 1.0)) as u64;

    let streak_bonus = (streak_days.min(7) * 2) as u64;

    let first_try_bonus = if first_try { 5 } else { 0 };

    let is_critical = (rng_seed % 10) == 0;
    let critical_bonus = if is_critical { base } else { 0 };

    let total = base + combo_bonus + streak_bonus + first_try_bonus + critical_bonus;

    XpReward {
        base,
        combo_bonus,
        streak_bonus,
        critical_bonus,
        first_try_bonus,
        total,
        is_critical,
    }
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum StreakStatus {
    Active { days: u32 },
    AtRisk,
    Frozen,
    Lost { was: u32 },
}

pub fn update_streak(progress: &mut UserProgress, today: &str) -> StreakStatus {
    match &progress.last_streak_date {
        None => {
            progress.streak_days = 1;
            progress.last_streak_date = Some(today.to_string());
            StreakStatus::Active { days: 1 }
        }
        Some(last) if last == today => {
            StreakStatus::Active { days: progress.streak_days }
        }
        Some(last) if is_yesterday(last, today) => {
            progress.streak_days += 1;
            progress.last_streak_date = Some(today.to_string());
            StreakStatus::Active { days: progress.streak_days }
        }
        Some(last) if is_two_days_ago(last, today) && progress.streak_freezes > 0 => {
            progress.streak_freezes -= 1;
            progress.last_streak_date = Some(today.to_string());
            StreakStatus::Frozen
        }
        Some(_) => {
            let was = progress.streak_days;
            progress.streak_days = 1;
            progress.last_streak_date = Some(today.to_string());
            StreakStatus::Lost { was }
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ComboResult {
    pub new_combo: u32,
    pub is_new_record: bool,
    pub multiplier: f64,
}

pub fn update_combo(progress: &mut UserProgress, correct: bool) -> ComboResult {
    if correct {
        progress.combo += 1;
        let is_new_record = progress.combo > progress.best_combo;
        if is_new_record {
            progress.best_combo = progress.combo;
        }
        let multiplier = 1.0 + (progress.combo.min(10) as f64 * 0.1);
        ComboResult { new_combo: progress.combo, is_new_record, multiplier }
    } else {
        progress.combo = 0;
        ComboResult { new_combo: 0, is_new_record: false, multiplier: 1.0 }
    }
}

pub fn level_title(level: u32) -> &'static str {
    match level {
        1 => "Novice",
        2..=4 => "Apprentice",
        5..=9 => "Student",
        10..=14 => "Scholar",
        15..=19 => "Adept",
        20..=29 => "Expert",
        30..=39 => "Master",
        40..=49 => "Sage",
        _ => "Grandmaster",
    }
}

pub fn xp_progress_to_next_level(xp: u64, level: u32) -> (u64, u64, f64) {
    let current_threshold = crate::progress::xp_for_level(level);
    let next_threshold = crate::progress::xp_for_level(level + 1);
    let progress = xp.saturating_sub(current_threshold);
    let needed = next_threshold - current_threshold;
    let percentage = if needed > 0 {
        (progress as f64) / (needed as f64)
    } else {
        0.0
    };
    (progress, needed, percentage)
}

pub struct FreezeGrant {
    pub freezes: u8,
    pub reason: &'static str,
}

pub fn check_level_up_freeze_grants(old_level: u32, new_level: u32) -> Option<FreezeGrant> {
    let freeze_count = (old_level + 1..=new_level)
        .filter(|l| l % 5 == 0)
        .count() as u8;

    if freeze_count > 0 {
        Some(FreezeGrant {
            freezes: freeze_count,
            reason: "Level milestone reward",
        })
    } else {
        None
    }
}

pub fn is_sunday(date: &str) -> bool {
    if let Ok(num) = parse_date_to_days(date) {
        (num + 4) % 7 == 0
    } else {
        false
    }
}

fn is_yesterday(last: &str, today: &str) -> bool {
    if let (Ok(l), Ok(t)) = (parse_date_to_days(last), parse_date_to_days(today)) {
        t - l == 1
    } else {
        false
    }
}

fn is_two_days_ago(last: &str, today: &str) -> bool {
    if let (Ok(l), Ok(t)) = (parse_date_to_days(last), parse_date_to_days(today)) {
        t - l == 2
    } else {
        false
    }
}

fn parse_date_to_days(date: &str) -> Result<i64, ()> {
    let parts: Vec<&str> = date.split('-').collect();
    if parts.len() != 3 {
        return Err(());
    }

    let year: i64 = parts[0].parse().map_err(|_| ())?;
    let month: i64 = parts[1].parse().map_err(|_| ())?;
    let day: i64 = parts[2].parse().map_err(|_| ())?;

    let days = year * 365 + (year / 4) - (year / 100) + (year / 400)
        + (month * 30) + day;
    Ok(days)
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_xp_reward_base() {
        let reward = calculate_xp_reward(1, 0, 0, false, 1);
        assert_eq!(reward.base, 10);
        assert_eq!(reward.combo_bonus, 0);
        assert_eq!(reward.total, 10);
        assert!(!reward.is_critical);
    }

    #[test]
    fn test_xp_reward_with_combo() {
        let reward = calculate_xp_reward(1, 5, 0, false, 1);
        assert_eq!(reward.base, 10);
        assert_eq!(reward.combo_bonus, 5); // 10 * 0.5 = 5
        assert_eq!(reward.total, 15);
    }

    #[test]
    fn test_xp_reward_critical() {
        let reward = calculate_xp_reward(1, 0, 0, false, 10); // seed % 10 == 0
        assert!(reward.is_critical);
        assert_eq!(reward.critical_bonus, 10);
        assert_eq!(reward.total, 20);
    }

    #[test]
    fn test_xp_reward_full() {
        // difficulty 3, combo 10, streak 7, first try, non-crit
        let reward = calculate_xp_reward(3, 10, 7, true, 1);
        // base = 10 + (2 * 5) = 20
        // combo = 20 * 1.0 = 20
        // streak = 14
        // first_try = 5
        // total = 20 + 20 + 14 + 5 = 59
        assert_eq!(reward.base, 20);
        assert_eq!(reward.combo_bonus, 20);
        assert_eq!(reward.streak_bonus, 14);
        assert_eq!(reward.first_try_bonus, 5);
        assert_eq!(reward.total, 59);
    }

    #[test]
    fn test_combo_increment() {
        let mut progress = UserProgress::new();

        let result = update_combo(&mut progress, true);
        assert_eq!(result.new_combo, 1);
        assert!(result.is_new_record);

        let result = update_combo(&mut progress, true);
        assert_eq!(result.new_combo, 2);
        assert!(result.is_new_record);

        let result = update_combo(&mut progress, false);
        assert_eq!(result.new_combo, 0);
        assert!(!result.is_new_record);
    }

    #[test]
    fn test_combo_multiplier() {
        let mut progress = UserProgress::new();

        for _ in 0..10 {
            update_combo(&mut progress, true);
        }

        let result = update_combo(&mut progress, true);
        assert!((result.multiplier - 2.0).abs() < 0.01);
    }

    #[test]
    fn test_level_titles() {
        assert_eq!(level_title(1), "Novice");
        assert_eq!(level_title(5), "Student");
        assert_eq!(level_title(10), "Scholar");
        assert_eq!(level_title(50), "Grandmaster");
    }

    #[test]
    fn test_level_up_freeze_grants() {
        assert!(check_level_up_freeze_grants(1, 4).is_none());

        let grant = check_level_up_freeze_grants(4, 5).unwrap();
        assert_eq!(grant.freezes, 1);

        let grant = check_level_up_freeze_grants(1, 10).unwrap();
        assert_eq!(grant.freezes, 2); // levels 5 and 10
    }

    #[test]
    fn test_is_yesterday() {
        assert!(is_yesterday("2025-01-01", "2025-01-02"));
        assert!(!is_yesterday("2025-01-01", "2025-01-03"));
    }
}

```

---

### Spaced Repetition

**File:** `src/srs.rs`

SM-2 style spaced repetition algorithm for review scheduling. Calculates next review date based on performance. Prioritizes due items in review queue.

```rust
use crate::progress::SrsData;

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum ResponseQuality {
    Blackout = 0,
    Incorrect = 1,
    IncorrectEasy = 2,
    CorrectDifficult = 3,
    CorrectHesitation = 4,
    Perfect = 5,
}

impl ResponseQuality {
    pub fn from_score(score: u8) -> Self {
        match score {
            0 => Self::Blackout,
            1 => Self::Incorrect,
            2 => Self::IncorrectEasy,
            3 => Self::CorrectDifficult,
            4 => Self::CorrectHesitation,
            _ => Self::Perfect,
        }
    }

    pub fn is_correct(self) -> bool {
        (self as u8) >= 3
    }
}

pub fn sm2_update(srs: &mut SrsData, quality: ResponseQuality) {
    let q = quality as u8 as f64;

    if quality.is_correct() {
        srs.repetitions += 1;
        srs.interval = match srs.repetitions {
            1 => 1,
            2 => 6,
            _ => (srs.interval as f64 * srs.ease_factor).round() as u32,
        };

        srs.ease_factor += 0.1 - (5.0 - q) * (0.08 + (5.0 - q) * 0.02);
        if srs.ease_factor < 1.3 {
            srs.ease_factor = 1.3;
        }
    } else {
        srs.repetitions = 0;
        srs.interval = 1;
    }
}

pub fn calculate_next_review(current_date: &str, interval_days: u32) -> String {
    if let Ok(date) = parse_date(current_date) {
        let next = date + interval_days as i64;
        format_date(next)
    } else {
        current_date.to_string()
    }
}

pub fn is_due(next_review: Option<&str>, today: &str) -> bool {
    match next_review {
        None => true,
        Some(review_date) => {
            if let (Ok(review), Ok(now)) = (parse_date(review_date), parse_date(today)) {
                review <= now
            } else {
                true
            }
        }
    }
}

fn parse_date(date_str: &str) -> Result<i64, ()> {
    let parts: Vec<&str> = date_str.split('-').collect();
    if parts.len() != 3 {
        return Err(());
    }

    let year: i64 = parts[0].parse().map_err(|_| ())?;
    let month: i64 = parts[1].parse().map_err(|_| ())?;
    let day: i64 = parts[2].parse().map_err(|_| ())?;

    Ok(year * 10000 + month * 100 + day)
}

fn format_date(date_num: i64) -> String {
    let year = date_num / 10000;
    let month = (date_num % 10000) / 100;
    let day = date_num % 100;

    let (year, month, day) = normalize_date(year as i32, month as i32, day as i32);
    format!("{:04}-{:02}-{:02}", year, month, day)
}

fn normalize_date(year: i32, month: i32, day: i32) -> (i32, i32, i32) {
    let days_in_month = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31];

    let mut y = year;
    let mut m = month;
    let mut d = day;

    while d > days_in_month[(m - 1) as usize] {
        d -= days_in_month[(m - 1) as usize];
        m += 1;
        if m > 12 {
            m = 1;
            y += 1;
        }
    }

    (y, m, d)
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_sm2_first_correct() {
        let mut srs = SrsData::default();
        sm2_update(&mut srs, ResponseQuality::Perfect);

        assert_eq!(srs.repetitions, 1);
        assert_eq!(srs.interval, 1);
        assert!(srs.ease_factor > 2.5);
    }

    #[test]
    fn test_sm2_second_correct() {
        let mut srs = SrsData::default();
        sm2_update(&mut srs, ResponseQuality::Perfect);
        sm2_update(&mut srs, ResponseQuality::Perfect);

        assert_eq!(srs.repetitions, 2);
        assert_eq!(srs.interval, 6);
    }

    #[test]
    fn test_sm2_incorrect_resets() {
        let mut srs = SrsData::default();
        sm2_update(&mut srs, ResponseQuality::Perfect);
        sm2_update(&mut srs, ResponseQuality::Perfect);
        sm2_update(&mut srs, ResponseQuality::Incorrect);

        assert_eq!(srs.repetitions, 0);
        assert_eq!(srs.interval, 1);
    }

    #[test]
    fn test_sm2_ease_factor_minimum() {
        let mut srs = SrsData::default();
        srs.ease_factor = 1.3;
        sm2_update(&mut srs, ResponseQuality::CorrectDifficult);

        assert!(srs.ease_factor >= 1.3);
    }

    #[test]
    fn test_is_due_none() {
        assert!(is_due(None, "2025-01-01"));
    }

    #[test]
    fn test_is_due_past() {
        assert!(is_due(Some("2025-01-01"), "2025-01-02"));
    }

    #[test]
    fn test_is_due_future() {
        assert!(!is_due(Some("2025-01-05"), "2025-01-02"));
    }

    #[test]
    fn test_is_due_today() {
        assert!(is_due(Some("2025-01-01"), "2025-01-01"));
    }

    #[test]
    fn test_calculate_next_review() {
        let next = calculate_next_review("2025-01-15", 6);
        assert_eq!(next, "2025-01-21");
    }

    #[test]
    fn test_calculate_next_review_month_overflow() {
        let next = calculate_next_review("2025-01-28", 6);
        assert_eq!(next, "2025-02-03");
    }

    #[test]
    fn test_response_quality_is_correct() {
        assert!(!ResponseQuality::Blackout.is_correct());
        assert!(!ResponseQuality::Incorrect.is_correct());
        assert!(!ResponseQuality::IncorrectEasy.is_correct());
        assert!(ResponseQuality::CorrectDifficult.is_correct());
        assert!(ResponseQuality::CorrectHesitation.is_correct());
        assert!(ResponseQuality::Perfect.is_correct());
    }
}

```

---

### Audio Feedback

**File:** `src/audio.rs`

Sound effect management for feedback. Plays success/failure/achievement sounds. Uses web audio API in WASM context.

```rust
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum SoundEffect {
    XpGain,
    CriticalHit,
    ComboUp,
    ComboBreak,
    Achievement,
    LevelUp,
    StreakSaved,
    StreakLost,
    Correct,
    Incorrect,
}

impl SoundEffect {
    pub fn as_str(&self) -> &'static str {
        match self {
            Self::XpGain => "xp_gain",
            Self::CriticalHit => "critical",
            Self::ComboUp => "combo_up",
            Self::ComboBreak => "combo_break",
            Self::Achievement => "achievement",
            Self::LevelUp => "level_up",
            Self::StreakSaved => "streak_saved",
            Self::StreakLost => "streak_lost",
            Self::Correct => "correct",
            Self::Incorrect => "incorrect",
        }
    }
}

#[cfg(target_arch = "wasm32")]
mod wasm {
    use super::SoundEffect;
    use wasm_bindgen::prelude::*;

    #[wasm_bindgen]
    extern "C" {
        #[wasm_bindgen(js_namespace = window, js_name = playSound)]
        fn play_sound_js(effect: &str);
    }

    pub fn play_sound(effect: SoundEffect) {
        play_sound_js(effect.as_str());
    }
}

#[cfg(target_arch = "wasm32")]
pub use wasm::play_sound;

#[cfg(not(target_arch = "wasm32"))]
pub fn play_sound(_effect: SoundEffect) {
    // No-op on non-wasm targets
}

```

---

### Persistent Storage

**File:** `src/storage.rs`

LocalStorage interface for saving game state. Handles serialization/deserialization of progress, settings, and achievements. Provides fallback for browsers without storage access.

```rust
use wasm_bindgen::prelude::*;

const PROGRESS_KEY: &str = "logos_user_progress";

#[wasm_bindgen]
extern "C" {
    #[wasm_bindgen(js_namespace = localStorage, js_name = getItem)]
    fn local_storage_get(key: &str) -> Option<String>;

    #[wasm_bindgen(js_namespace = localStorage, js_name = setItem)]
    fn local_storage_set(key: &str, value: &str);

    #[wasm_bindgen(js_namespace = localStorage, js_name = removeItem)]
    fn local_storage_remove(key: &str);
}

pub fn load_raw() -> Option<String> {
    local_storage_get(PROGRESS_KEY)
}

pub fn save_raw(json: &str) {
    local_storage_set(PROGRESS_KEY, json);
}

pub fn clear() {
    local_storage_remove(PROGRESS_KEY);
}

```

---

### LOGOS Interpreter

**File:** `src/interpreter.rs`

Direct AST interpretation without compilation. Used for REPL, debugging, and rapid prototyping. Evaluates expressions and statements in a runtime environment.

```rust
//! Tree-walking interpreter for LOGOS imperative code.
//!
//! This module provides runtime execution of parsed LOGOS programs,
//! walking the AST and executing statements/expressions directly.
//!
//! Phase 55: Made async for VFS operations (OPFS on WASM, tokio::fs on native).

use std::collections::HashMap;
use std::sync::Arc;

use async_recursion::async_recursion;

use crate::ast::stmt::{BinaryOpKind, Block, Expr, Literal, MatchArm, ReadSource, Stmt, TypeExpr};
use crate::intern::{Interner, Symbol};

// Phase 55: VFS imports
use logos_core::fs::Vfs;

/// Runtime values during interpretation.
#[derive(Debug, Clone)]
pub enum RuntimeValue {
    Int(i64),
    Float(f64),
    Bool(bool),
    Text(String),
    Char(char),
    List(Vec<RuntimeValue>),
    Tuple(Vec<RuntimeValue>),  // Heterogeneous tuple
    Set(Vec<RuntimeValue>),  // HashSet equivalent - Vec for simplicity in interpreter
    Map(HashMap<String, RuntimeValue>),
    Struct {
        type_name: String,
        fields: HashMap<String, RuntimeValue>,
    },
    Nothing,
}

impl RuntimeValue {
    pub fn type_name(&self) -> &'static str {
        match self {
            RuntimeValue::Int(_) => "Int",
            RuntimeValue::Float(_) => "Float",
            RuntimeValue::Bool(_) => "Bool",
            RuntimeValue::Text(_) => "Text",
            RuntimeValue::Char(_) => "Char",
            RuntimeValue::List(_) => "List",
            RuntimeValue::Tuple(_) => "Tuple",
            RuntimeValue::Set(_) => "Set",
            RuntimeValue::Map(_) => "Map",
            RuntimeValue::Struct { .. } => "Struct",
            RuntimeValue::Nothing => "Nothing",
        }
    }

    pub fn is_truthy(&self) -> bool {
        match self {
            RuntimeValue::Bool(b) => *b,
            RuntimeValue::Int(n) => *n != 0,
            RuntimeValue::Nothing => false,
            _ => true,
        }
    }

    pub fn to_display_string(&self) -> String {
        match self {
            RuntimeValue::Int(n) => n.to_string(),
            RuntimeValue::Float(f) => format!("{:.6}", f).trim_end_matches('0').trim_end_matches('.').to_string(),
            RuntimeValue::Bool(b) => if *b { "true" } else { "false" }.to_string(),
            RuntimeValue::Text(s) => s.clone(),
            RuntimeValue::Char(c) => c.to_string(),
            RuntimeValue::List(items) => {
                let parts: Vec<String> = items.iter().map(|v| v.to_display_string()).collect();
                format!("[{}]", parts.join(", "))
            }
            RuntimeValue::Tuple(items) => {
                let parts: Vec<String> = items.iter().map(|v| v.to_display_string()).collect();
                format!("({})", parts.join(", "))
            }
            RuntimeValue::Set(items) => {
                let parts: Vec<String> = items.iter().map(|v| v.to_display_string()).collect();
                format!("{{{}}}", parts.join(", "))
            }
            RuntimeValue::Map(m) => {
                let pairs: Vec<String> = m.iter()
                    .map(|(k, v)| format!("{}: {}", k, v.to_display_string()))
                    .collect();
                format!("{{{}}}", pairs.join(", "))
            }
            RuntimeValue::Struct { type_name, fields } => {
                if fields.is_empty() {
                    // Unit variant - just show the name
                    type_name.clone()
                } else {
                    let field_strs: Vec<String> = fields
                        .iter()
                        .map(|(k, v)| format!("{}: {}", k, v.to_display_string()))
                        .collect();
                    format!("{} {{ {} }}", type_name, field_strs.join(", "))
                }
            }
            RuntimeValue::Nothing => "nothing".to_string(),
        }
    }
}

/// Control flow signals for statement execution.
pub enum ControlFlow {
    Continue,
    Return(RuntimeValue),
    Break,
}

/// Stored function definition for user-defined functions.
pub struct FunctionDef<'a> {
    pub params: Vec<(Symbol, &'a TypeExpr<'a>)>,
    pub body: Block<'a>,
    pub return_type: Option<&'a TypeExpr<'a>>,
}

/// Tree-walking interpreter for LOGOS programs.
///
/// Phase 55: Now async with optional VFS for file operations.
pub struct Interpreter<'a> {
    interner: &'a Interner,
    /// Scope stack - each HashMap is a scope level
    env: Vec<HashMap<Symbol, RuntimeValue>>,
    /// User-defined functions
    functions: HashMap<Symbol, FunctionDef<'a>>,
    /// Struct type definitions (for constructor validation)
    struct_defs: HashMap<Symbol, Vec<(Symbol, Symbol, bool)>>,
    /// Output lines from show() calls
    pub output: Vec<String>,
    /// Phase 55: VFS for file operations (OPFS on WASM, NativeVfs on native)
    vfs: Option<Arc<dyn Vfs>>,
}

impl<'a> Interpreter<'a> {
    pub fn new(interner: &'a Interner) -> Self {
        Interpreter {
            interner,
            env: vec![HashMap::new()], // Global scope
            functions: HashMap::new(),
            struct_defs: HashMap::new(),
            output: Vec::new(),
            vfs: None,
        }
    }

    /// Phase 55: Set the VFS for file operations.
    pub fn with_vfs(mut self, vfs: Arc<dyn Vfs>) -> Self {
        self.vfs = Some(vfs);
        self
    }

    /// Execute a program (list of statements).
    /// Phase 55: Now async for VFS operations.
    pub async fn run(&mut self, stmts: &[Stmt<'a>]) -> Result<(), String> {
        for stmt in stmts {
            match self.execute_stmt(stmt).await? {
                ControlFlow::Return(_) => break,
                ControlFlow::Break => break,
                ControlFlow::Continue => {}
            }
        }
        Ok(())
    }

    /// Execute a single statement.
    /// Phase 55: Now async for VFS operations.
    #[async_recursion(?Send)]
    async fn execute_stmt(&mut self, stmt: &Stmt<'a>) -> Result<ControlFlow, String> {
        match stmt {
            Stmt::Let { var, value, .. } => {
                let val = self.evaluate_expr(value).await?;
                self.define(*var, val);
                Ok(ControlFlow::Continue)
            }

            Stmt::Set { target, value } => {
                let val = self.evaluate_expr(value).await?;
                self.assign(*target, val)?;
                Ok(ControlFlow::Continue)
            }

            Stmt::Call { function, args } => {
                self.call_function(*function, args).await?;
                Ok(ControlFlow::Continue)
            }

            Stmt::If { cond, then_block, else_block } => {
                let condition = self.evaluate_expr(cond).await?;
                if condition.is_truthy() {
                    let flow = self.execute_block(then_block).await?;
                    if !matches!(flow, ControlFlow::Continue) {
                        return Ok(flow);
                    }
                } else if let Some(else_stmts) = else_block {
                    let flow = self.execute_block(else_stmts).await?;
                    if !matches!(flow, ControlFlow::Continue) {
                        return Ok(flow);
                    }
                }
                Ok(ControlFlow::Continue)
            }

            Stmt::While { cond, body, .. } => {
                loop {
                    let condition = self.evaluate_expr(cond).await?;
                    if !condition.is_truthy() {
                        break;
                    }
                    match self.execute_block(body).await? {
                        ControlFlow::Break => break,
                        ControlFlow::Return(v) => return Ok(ControlFlow::Return(v)),
                        ControlFlow::Continue => {}
                    }
                }
                Ok(ControlFlow::Continue)
            }

            Stmt::Repeat { var, iterable, body } => {
                let iter_val = self.evaluate_expr(iterable).await?;
                let items = match iter_val {
                    RuntimeValue::List(list) => list,
                    RuntimeValue::Text(s) => {
                        s.chars().map(|c| RuntimeValue::Text(c.to_string())).collect()
                    }
                    _ => return Err(format!("Cannot iterate over {}", iter_val.type_name())),
                };

                self.push_scope();
                for item in items {
                    self.define(*var, item);
                    match self.execute_block(body).await? {
                        ControlFlow::Break => break,
                        ControlFlow::Return(v) => {
                            self.pop_scope();
                            return Ok(ControlFlow::Return(v));
                        }
                        ControlFlow::Continue => {}
                    }
                }
                self.pop_scope();
                Ok(ControlFlow::Continue)
            }

            Stmt::Return { value } => {
                let ret_val = match value {
                    Some(expr) => self.evaluate_expr(expr).await?,
                    None => RuntimeValue::Nothing,
                };
                Ok(ControlFlow::Return(ret_val))
            }

            Stmt::FunctionDef { name, params, body, return_type, .. } => {
                let func = FunctionDef {
                    params: params.clone(),
                    body: *body,
                    return_type: *return_type,
                };
                self.functions.insert(*name, func);
                Ok(ControlFlow::Continue)
            }

            Stmt::StructDef { name, fields, .. } => {
                self.struct_defs.insert(*name, fields.clone());
                Ok(ControlFlow::Continue)
            }

            Stmt::SetField { object, field, value } => {
                let new_val = self.evaluate_expr(value).await?;
                if let Expr::Identifier(obj_sym) = object {
                    let mut obj_val = self.lookup(*obj_sym)?.clone();
                    if let RuntimeValue::Struct { fields, .. } = &mut obj_val {
                        let field_name = self.interner.resolve(*field).to_string();
                        fields.insert(field_name, new_val);
                        self.assign(*obj_sym, obj_val)?;
                    } else {
                        return Err(format!("Cannot set field on non-struct value"));
                    }
                } else {
                    return Err("SetField target must be an identifier".to_string());
                }
                Ok(ControlFlow::Continue)
            }

            Stmt::Push { value, collection } => {
                let val = self.evaluate_expr(value).await?;
                if let Expr::Identifier(coll_sym) = collection {
                    let mut coll_val = self.lookup(*coll_sym)?.clone();
                    if let RuntimeValue::List(ref mut items) = coll_val {
                        items.push(val);
                        self.assign(*coll_sym, coll_val)?;
                    } else {
                        return Err("Can only push to a List".to_string());
                    }
                } else {
                    return Err("Push collection must be an identifier".to_string());
                }
                Ok(ControlFlow::Continue)
            }

            Stmt::Pop { collection, into } => {
                if let Expr::Identifier(coll_sym) = collection {
                    let mut coll_val = self.lookup(*coll_sym)?.clone();
                    if let RuntimeValue::List(ref mut items) = coll_val {
                        let popped = items.pop().unwrap_or(RuntimeValue::Nothing);
                        self.assign(*coll_sym, coll_val)?;
                        if let Some(into_var) = into {
                            self.define(*into_var, popped);
                        }
                    } else {
                        return Err("Can only pop from a List".to_string());
                    }
                } else {
                    return Err("Pop collection must be an identifier".to_string());
                }
                Ok(ControlFlow::Continue)
            }

            Stmt::Add { value, collection } => {
                let val = self.evaluate_expr(value).await?;
                if let Expr::Identifier(coll_sym) = collection {
                    let mut coll_val = self.lookup(*coll_sym)?.clone();
                    if let RuntimeValue::Set(ref mut items) = coll_val {
                        // Only add if not already present
                        if !items.iter().any(|x| self.values_equal(x, &val)) {
                            items.push(val);
                        }
                        self.assign(*coll_sym, coll_val)?;
                    } else {
                        return Err("Can only add to a Set".to_string());
                    }
                } else {
                    return Err("Add collection must be an identifier".to_string());
                }
                Ok(ControlFlow::Continue)
            }

            Stmt::Remove { value, collection } => {
                let val = self.evaluate_expr(value).await?;
                if let Expr::Identifier(coll_sym) = collection {
                    let mut coll_val = self.lookup(*coll_sym)?.clone();
                    if let RuntimeValue::Set(ref mut items) = coll_val {
                        items.retain(|x| !self.values_equal(x, &val));
                        self.assign(*coll_sym, coll_val)?;
                    } else {
                        return Err("Can only remove from a Set".to_string());
                    }
                } else {
                    return Err("Remove collection must be an identifier".to_string());
                }
                Ok(ControlFlow::Continue)
            }

            Stmt::SetIndex { collection, index, value } => {
                let idx_val = self.evaluate_expr(index).await?;
                let new_val = self.evaluate_expr(value).await?;
                if let Expr::Identifier(coll_sym) = collection {
                    let mut coll_val = self.lookup(*coll_sym)?.clone();
                    match (&mut coll_val, &idx_val) {
                        (RuntimeValue::List(ref mut items), RuntimeValue::Int(n)) => {
                            let idx = *n as usize;
                            if idx == 0 || idx > items.len() {
                                return Err(format!("Index {} out of bounds for list of length {}", idx, items.len()));
                            }
                            items[idx - 1] = new_val;
                        }
                        (RuntimeValue::Map(ref mut map), RuntimeValue::Text(key)) => {
                            map.insert(key.clone(), new_val);
                        }
                        (RuntimeValue::List(_), _) => {
                            return Err("List index must be an integer".to_string());
                        }
                        (RuntimeValue::Map(_), _) => {
                            return Err("Map key must be a string".to_string());
                        }
                        _ => {
                            return Err(format!("Cannot index into {}", coll_val.type_name()));
                        }
                    }
                    self.assign(*coll_sym, coll_val)?;
                } else {
                    return Err("SetIndex collection must be an identifier".to_string());
                }
                Ok(ControlFlow::Continue)
            }

            Stmt::Inspect { target, arms, .. } => {
                let target_val = self.evaluate_expr(target).await?;
                self.execute_inspect(&target_val, arms).await?;
                Ok(ControlFlow::Continue)
            }

            Stmt::Zone { name, body, .. } => {
                self.push_scope();
                self.define(*name, RuntimeValue::Nothing);
                let result = self.execute_block(body).await;
                self.pop_scope();
                result?;
                Ok(ControlFlow::Continue)
            }

            Stmt::Concurrent { tasks } | Stmt::Parallel { tasks } => {
                // In WASM, execute sequentially (no threads)
                for task in tasks.iter() {
                    self.execute_stmt(task).await?;
                }
                Ok(ControlFlow::Continue)
            }

            Stmt::Assert { .. } | Stmt::Trust { .. } => {
                Ok(ControlFlow::Continue)
            }

            Stmt::RuntimeAssert { condition } => {
                let val = self.evaluate_expr(condition).await?;
                if !val.is_truthy() {
                    return Err("Assertion failed".to_string());
                }
                Ok(ControlFlow::Continue)
            }

            Stmt::Give { .. } => {
                Ok(ControlFlow::Continue)
            }

            Stmt::Show { object, recipient } => {
                let obj_val = self.evaluate_expr(object).await?;
                if let Expr::Identifier(sym) = recipient {
                    let name = self.interner.resolve(*sym);
                    if name == "show" {
                        self.output.push(obj_val.to_display_string());
                    }
                }
                Ok(ControlFlow::Continue)
            }

            // Phase 55: VFS operations now supported
            Stmt::ReadFrom { var, source } => {
                let content = match source {
                    ReadSource::Console => {
                        // Console read not available in WASM interpreter
                        String::new()
                    }
                    ReadSource::File(path_expr) => {
                        let path = self.evaluate_expr(path_expr).await?.to_display_string();
                        match &self.vfs {
                            Some(vfs) => {
                                vfs.read_to_string(&path).await
                                    .map_err(|e| format!("Read error: {}", e))?
                            }
                            None => return Err("VFS not initialized. Use Interpreter::with_vfs()".to_string()),
                        }
                    }
                };
                self.define(*var, RuntimeValue::Text(content));
                Ok(ControlFlow::Continue)
            }

            Stmt::WriteFile { content, path } => {
                let content_val = self.evaluate_expr(content).await?.to_display_string();
                let path_val = self.evaluate_expr(path).await?.to_display_string();
                match &self.vfs {
                    Some(vfs) => {
                        vfs.write(&path_val, content_val.as_bytes()).await
                            .map_err(|e| format!("Write error: {}", e))?;
                    }
                    None => return Err("VFS not initialized. Use Interpreter::with_vfs()".to_string()),
                }
                Ok(ControlFlow::Continue)
            }

            Stmt::Spawn { name, .. } => {
                self.define(*name, RuntimeValue::Nothing);
                Ok(ControlFlow::Continue)
            }

            Stmt::SendMessage { .. } => {
                Ok(ControlFlow::Continue)
            }

            Stmt::AwaitMessage { into, .. } => {
                self.define(*into, RuntimeValue::Nothing);
                Ok(ControlFlow::Continue)
            }

            Stmt::MergeCrdt { .. } => {
                Err("CRDT Merge is not supported in the interpreter. Use compiled Rust.".to_string())
            }

            Stmt::IncreaseCrdt { .. } => {
                Err("CRDT Increase is not supported in the interpreter. Use compiled Rust.".to_string())
            }

            Stmt::DecreaseCrdt { .. } => {
                Err("CRDT Decrease is not supported in the interpreter. Use compiled Rust.".to_string())
            }

            Stmt::AppendToSequence { .. } => {
                Err("Append to sequence is not supported in the interpreter. Use compiled Rust.".to_string())
            }

            Stmt::ResolveConflict { .. } => {
                Err("Resolve conflict is not supported in the interpreter. Use compiled Rust.".to_string())
            }

            Stmt::Check { .. } => {
                Err("Security Check is not supported in the interpreter. Use compiled Rust.".to_string())
            }

            Stmt::Listen { .. } => {
                Err("Listen is not supported in the interpreter. Use compiled Rust.".to_string())
            }
            Stmt::ConnectTo { .. } => {
                Err("Connect is not supported in the interpreter. Use compiled Rust.".to_string())
            }
            Stmt::LetPeerAgent { .. } => {
                Err("PeerAgent is not supported in the interpreter. Use compiled Rust.".to_string())
            }
            Stmt::Sleep { .. } => {
                // Phase 55: Sleep could be implemented with gloo-timers on WASM
                Err("Sleep is not yet supported in the interpreter.".to_string())
            }
            Stmt::Sync { .. } => {
                Err("Sync is not supported in the interpreter. Use compiled Rust.".to_string())
            }
            // Phase 55: Mount now supported via VFS
            Stmt::Mount { var, path } => {
                let path_val = self.evaluate_expr(path).await?.to_display_string();
                match &self.vfs {
                    Some(vfs) => {
                        // Read existing content or create empty
                        let content = match vfs.read_to_string(&path_val).await {
                            Ok(s) => s,
                            Err(_) => String::new(),
                        };
                        // Store as a simple value for now (full Persistent<T> requires more work)
                        self.define(*var, RuntimeValue::Text(content));
                    }
                    None => return Err("VFS not initialized. Use Interpreter::with_vfs()".to_string()),
                }
                Ok(ControlFlow::Continue)
            }

            // Phase 54: Go-like concurrency - not supported in interpreter
            // These are compile-to-Rust only features
            Stmt::LaunchTask { .. } |
            Stmt::LaunchTaskWithHandle { .. } |
            Stmt::CreatePipe { .. } |
            Stmt::SendPipe { .. } |
            Stmt::ReceivePipe { .. } |
            Stmt::TrySendPipe { .. } |
            Stmt::TryReceivePipe { .. } |
            Stmt::StopTask { .. } |
            Stmt::Select { .. } => {
                Err("Go-like concurrency (Launch, Pipe, Select) is only supported in compiled mode".to_string())
            }
        }
    }

    /// Execute a block of statements, returning control flow.
    /// Phase 55: Now async.
    #[async_recursion(?Send)]
    async fn execute_block(&mut self, block: Block<'a>) -> Result<ControlFlow, String> {
        self.push_scope();
        for stmt in block.iter() {
            match self.execute_stmt(stmt).await? {
                ControlFlow::Continue => {}
                flow => {
                    self.pop_scope();
                    return Ok(flow);
                }
            }
        }
        self.pop_scope();
        Ok(ControlFlow::Continue)
    }

    /// Execute Inspect (pattern matching).
    /// Phase 55: Now async.
    #[async_recursion(?Send)]
    async fn execute_inspect(&mut self, target: &RuntimeValue, arms: &[MatchArm<'a>]) -> Result<(), String> {
        for arm in arms {
            if arm.variant.is_none() {
                self.execute_block(arm.body).await?;
                return Ok(());
            }
            if let RuntimeValue::Struct { type_name, fields } = target {
                if let Some(variant) = arm.variant {
                    let variant_name = self.interner.resolve(variant);
                    if type_name == variant_name {
                        self.push_scope();
                        for (field_name, binding_name) in &arm.bindings {
                            let field_str = self.interner.resolve(*field_name);
                            if let Some(val) = fields.get(field_str) {
                                self.define(*binding_name, val.clone());
                            }
                        }
                        let result = self.execute_block(arm.body).await;
                        self.pop_scope();
                        result?;
                        return Ok(());
                    }
                }
            }
        }
        Ok(())
    }

    /// Evaluate an expression to a runtime value.
    /// Phase 55: Now async.
    #[async_recursion(?Send)]
    async fn evaluate_expr(&mut self, expr: &Expr<'a>) -> Result<RuntimeValue, String> {
        match expr {
            Expr::Literal(lit) => self.evaluate_literal(lit),

            Expr::Identifier(sym) => {
                self.lookup(*sym).cloned()
            }

            Expr::BinaryOp { op, left, right } => {
                let left_val = self.evaluate_expr(left).await?;
                let right_val = self.evaluate_expr(right).await?;
                self.apply_binary_op(*op, left_val, right_val)
            }

            Expr::Call { function, args } => {
                self.call_function(*function, args).await
            }

            Expr::Index { collection, index } => {
                let coll_val = self.evaluate_expr(collection).await?;
                let idx_val = self.evaluate_expr(index).await?;
                match (&coll_val, &idx_val) {
                    (RuntimeValue::List(items), RuntimeValue::Int(idx)) => {
                        let idx = *idx as usize;
                        if idx == 0 || idx > items.len() {
                            return Err(format!("Index {} out of bounds", idx));
                        }
                        Ok(items[idx - 1].clone())
                    }
                    (RuntimeValue::Tuple(items), RuntimeValue::Int(idx)) => {
                        let idx = *idx as usize;
                        if idx == 0 || idx > items.len() {
                            return Err(format!("Index {} out of bounds", idx));
                        }
                        Ok(items[idx - 1].clone())
                    }
                    (RuntimeValue::Text(s), RuntimeValue::Int(idx)) => {
                        let idx = *idx as usize;
                        if idx == 0 || idx > s.len() {
                            return Err(format!("Index {} out of bounds", idx));
                        }
                        Ok(RuntimeValue::Text(s.chars().nth(idx - 1).unwrap().to_string()))
                    }
                    (RuntimeValue::Map(map), RuntimeValue::Text(key)) => {
                        match map.get(key) {
                            Some(val) => Ok(val.clone()),
                            None => Err(format!("Key '{}' not found in map", key)),
                        }
                    }
                    _ => Err(format!("Cannot index {} with {}", coll_val.type_name(), idx_val.type_name())),
                }
            }

            Expr::Slice { collection, start, end } => {
                let coll_val = self.evaluate_expr(collection).await?;
                let start_val = self.evaluate_expr(start).await?;
                let end_val = self.evaluate_expr(end).await?;
                match (&coll_val, &start_val, &end_val) {
                    (RuntimeValue::List(items), RuntimeValue::Int(s), RuntimeValue::Int(e)) => {
                        let start = (*s as usize).saturating_sub(1);
                        let end = *e as usize;
                        let slice: Vec<RuntimeValue> = items.get(start..end).unwrap_or(&[]).to_vec();
                        Ok(RuntimeValue::List(slice))
                    }
                    _ => Err("Slice requires List and Int indices".to_string()),
                }
            }

            Expr::Copy { expr: inner } => {
                self.evaluate_expr(inner).await
            }

            Expr::Length { collection } => {
                let coll_val = self.evaluate_expr(collection).await?;
                match &coll_val {
                    RuntimeValue::List(items) => Ok(RuntimeValue::Int(items.len() as i64)),
                    RuntimeValue::Tuple(items) => Ok(RuntimeValue::Int(items.len() as i64)),
                    RuntimeValue::Set(items) => Ok(RuntimeValue::Int(items.len() as i64)),
                    RuntimeValue::Text(s) => Ok(RuntimeValue::Int(s.len() as i64)),
                    _ => Err(format!("Cannot get length of {}", coll_val.type_name())),
                }
            }

            Expr::Contains { collection, value } => {
                let coll_val = self.evaluate_expr(collection).await?;
                let val = self.evaluate_expr(value).await?;
                match &coll_val {
                    RuntimeValue::Set(items) => {
                        let found = items.iter().any(|item| self.values_equal(item, &val));
                        Ok(RuntimeValue::Bool(found))
                    }
                    RuntimeValue::List(items) => {
                        let found = items.iter().any(|item| self.values_equal(item, &val));
                        Ok(RuntimeValue::Bool(found))
                    }
                    RuntimeValue::Map(entries) => {
                        // For maps, check if key exists (keys are Strings)
                        if let RuntimeValue::Text(key) = &val {
                            Ok(RuntimeValue::Bool(entries.contains_key(key)))
                        } else {
                            Err(format!("Map key must be Text, got {}", val.type_name()))
                        }
                    }
                    RuntimeValue::Text(s) => {
                        // For text, check if substring exists
                        if let RuntimeValue::Text(needle) = &val {
                            Ok(RuntimeValue::Bool(s.contains(needle.as_str())))
                        } else if let RuntimeValue::Char(c) = &val {
                            Ok(RuntimeValue::Bool(s.contains(*c)))
                        } else {
                            Err(format!("Cannot check if Text contains {}", val.type_name()))
                        }
                    }
                    _ => Err(format!("Cannot check contains on {}", coll_val.type_name())),
                }
            }

            Expr::Union { left, right } => {
                let left_val = self.evaluate_expr(left).await?;
                let right_val = self.evaluate_expr(right).await?;
                match (&left_val, &right_val) {
                    (RuntimeValue::Set(a), RuntimeValue::Set(b)) => {
                        let mut result = a.clone();
                        for item in b.iter() {
                            if !result.iter().any(|x| self.values_equal(x, item)) {
                                result.push(item.clone());
                            }
                        }
                        Ok(RuntimeValue::Set(result))
                    }
                    _ => Err(format!("Cannot union {} and {}", left_val.type_name(), right_val.type_name())),
                }
            }

            Expr::Intersection { left, right } => {
                let left_val = self.evaluate_expr(left).await?;
                let right_val = self.evaluate_expr(right).await?;
                match (&left_val, &right_val) {
                    (RuntimeValue::Set(a), RuntimeValue::Set(b)) => {
                        let result: Vec<RuntimeValue> = a.iter()
                            .filter(|item| b.iter().any(|x| self.values_equal(x, item)))
                            .cloned()
                            .collect();
                        Ok(RuntimeValue::Set(result))
                    }
                    _ => Err(format!("Cannot intersect {} and {}", left_val.type_name(), right_val.type_name())),
                }
            }

            Expr::List(items) => {
                // Can't use .map() with async, so manual loop
                let mut values = Vec::with_capacity(items.len());
                for e in items.iter() {
                    values.push(self.evaluate_expr(e).await?);
                }
                Ok(RuntimeValue::List(values))
            }

            Expr::Tuple(items) => {
                let mut values = Vec::with_capacity(items.len());
                for e in items.iter() {
                    values.push(self.evaluate_expr(e).await?);
                }
                Ok(RuntimeValue::Tuple(values))
            }

            Expr::Range { start, end } => {
                let start_val = self.evaluate_expr(start).await?;
                let end_val = self.evaluate_expr(end).await?;
                match (&start_val, &end_val) {
                    (RuntimeValue::Int(s), RuntimeValue::Int(e)) => {
                        let range: Vec<RuntimeValue> = (*s..=*e)
                            .map(RuntimeValue::Int)
                            .collect();
                        Ok(RuntimeValue::List(range))
                    }
                    _ => Err("Range requires Int bounds".to_string()),
                }
            }

            Expr::FieldAccess { object, field } => {
                let obj_val = self.evaluate_expr(object).await?;
                match &obj_val {
                    RuntimeValue::Struct { fields, .. } => {
                        let field_name = self.interner.resolve(*field);
                        fields.get(field_name).cloned()
                            .ok_or_else(|| format!("Field '{}' not found", field_name))
                    }
                    _ => Err(format!("Cannot access field on {}", obj_val.type_name())),
                }
            }

            Expr::New { type_name, init_fields, .. } => {
                let name = self.interner.resolve(*type_name).to_string();

                if name == "Seq" || name == "List" {
                    return Ok(RuntimeValue::List(vec![]));
                }

                if name == "Set" || name == "HashSet" {
                    return Ok(RuntimeValue::Set(vec![]));
                }

                if name == "Map" || name == "HashMap" {
                    return Ok(RuntimeValue::Map(HashMap::new()));
                }

                let mut fields = HashMap::new();
                for (field_sym, field_expr) in init_fields {
                    let field_name = self.interner.resolve(*field_sym).to_string();
                    let field_val = self.evaluate_expr(field_expr).await?;
                    fields.insert(field_name, field_val);
                }
                Ok(RuntimeValue::Struct { type_name: name, fields })
            }

            Expr::NewVariant { variant, fields, .. } => {
                let name = self.interner.resolve(*variant).to_string();
                let mut field_map = HashMap::new();
                for (field_sym, field_expr) in fields {
                    let field_name = self.interner.resolve(*field_sym).to_string();
                    let field_val = self.evaluate_expr(field_expr).await?;
                    field_map.insert(field_name, field_val);
                }
                Ok(RuntimeValue::Struct { type_name: name, fields: field_map })
            }

            Expr::ManifestOf { .. } => {
                Ok(RuntimeValue::List(vec![]))
            }

            Expr::ChunkAt { .. } => {
                Ok(RuntimeValue::Nothing)
            }
        }
    }

    /// Evaluate a literal to a runtime value.
    fn evaluate_literal(&self, lit: &Literal) -> Result<RuntimeValue, String> {
        match lit {
            Literal::Number(n) => Ok(RuntimeValue::Int(*n)),
            Literal::Float(f) => Ok(RuntimeValue::Float(*f)),
            Literal::Text(sym) => Ok(RuntimeValue::Text(self.interner.resolve(*sym).to_string())),
            Literal::Boolean(b) => Ok(RuntimeValue::Bool(*b)),
            Literal::Nothing => Ok(RuntimeValue::Nothing),
            Literal::Char(c) => Ok(RuntimeValue::Char(*c)),
        }
    }

    /// Apply a binary operator.
    fn apply_binary_op(&self, op: BinaryOpKind, left: RuntimeValue, right: RuntimeValue) -> Result<RuntimeValue, String> {
        match op {
            BinaryOpKind::Add => self.apply_add(left, right),
            BinaryOpKind::Subtract => self.apply_subtract(left, right),
            BinaryOpKind::Multiply => self.apply_multiply(left, right),
            BinaryOpKind::Divide => self.apply_divide(left, right),
            BinaryOpKind::Modulo => self.apply_modulo(left, right),
            BinaryOpKind::Eq => Ok(RuntimeValue::Bool(self.values_equal(&left, &right))),
            BinaryOpKind::NotEq => Ok(RuntimeValue::Bool(!self.values_equal(&left, &right))),
            BinaryOpKind::Lt => self.apply_comparison(left, right, |a, b| a < b),
            BinaryOpKind::Gt => self.apply_comparison(left, right, |a, b| a > b),
            BinaryOpKind::LtEq => self.apply_comparison(left, right, |a, b| a <= b),
            BinaryOpKind::GtEq => self.apply_comparison(left, right, |a, b| a >= b),
            BinaryOpKind::And => Ok(RuntimeValue::Bool(left.is_truthy() && right.is_truthy())),
            BinaryOpKind::Or => Ok(RuntimeValue::Bool(left.is_truthy() || right.is_truthy())),
            // Phase 53: String concatenation
            BinaryOpKind::Concat => self.apply_concat(left, right),
        }
    }

    fn apply_add(&self, left: RuntimeValue, right: RuntimeValue) -> Result<RuntimeValue, String> {
        match (&left, &right) {
            (RuntimeValue::Int(a), RuntimeValue::Int(b)) => Ok(RuntimeValue::Int(a + b)),
            (RuntimeValue::Float(a), RuntimeValue::Float(b)) => Ok(RuntimeValue::Float(a + b)),
            (RuntimeValue::Int(a), RuntimeValue::Float(b)) => Ok(RuntimeValue::Float(*a as f64 + b)),
            (RuntimeValue::Float(a), RuntimeValue::Int(b)) => Ok(RuntimeValue::Float(a + *b as f64)),
            (RuntimeValue::Text(a), RuntimeValue::Text(b)) => Ok(RuntimeValue::Text(format!("{}{}", a, b))),
            (RuntimeValue::Text(a), other) => Ok(RuntimeValue::Text(format!("{}{}", a, other.to_display_string()))),
            (other, RuntimeValue::Text(b)) => Ok(RuntimeValue::Text(format!("{}{}", other.to_display_string(), b))),
            _ => Err(format!("Cannot add {} and {}", left.type_name(), right.type_name())),
        }
    }

    /// Phase 53: String concatenation ("combined with")
    fn apply_concat(&self, left: RuntimeValue, right: RuntimeValue) -> Result<RuntimeValue, String> {
        Ok(RuntimeValue::Text(format!("{}{}", left.to_display_string(), right.to_display_string())))
    }

    fn apply_subtract(&self, left: RuntimeValue, right: RuntimeValue) -> Result<RuntimeValue, String> {
        match (&left, &right) {
            (RuntimeValue::Int(a), RuntimeValue::Int(b)) => Ok(RuntimeValue::Int(a - b)),
            (RuntimeValue::Float(a), RuntimeValue::Float(b)) => Ok(RuntimeValue::Float(a - b)),
            (RuntimeValue::Int(a), RuntimeValue::Float(b)) => Ok(RuntimeValue::Float(*a as f64 - b)),
            (RuntimeValue::Float(a), RuntimeValue::Int(b)) => Ok(RuntimeValue::Float(a - *b as f64)),
            _ => Err(format!("Cannot subtract {} from {}", right.type_name(), left.type_name())),
        }
    }

    fn apply_multiply(&self, left: RuntimeValue, right: RuntimeValue) -> Result<RuntimeValue, String> {
        match (&left, &right) {
            (RuntimeValue::Int(a), RuntimeValue::Int(b)) => Ok(RuntimeValue::Int(a * b)),
            (RuntimeValue::Float(a), RuntimeValue::Float(b)) => Ok(RuntimeValue::Float(a * b)),
            (RuntimeValue::Int(a), RuntimeValue::Float(b)) => Ok(RuntimeValue::Float(*a as f64 * b)),
            (RuntimeValue::Float(a), RuntimeValue::Int(b)) => Ok(RuntimeValue::Float(a * *b as f64)),
            _ => Err(format!("Cannot multiply {} and {}", left.type_name(), right.type_name())),
        }
    }

    fn apply_divide(&self, left: RuntimeValue, right: RuntimeValue) -> Result<RuntimeValue, String> {
        match (&left, &right) {
            (RuntimeValue::Int(a), RuntimeValue::Int(b)) => {
                if *b == 0 {
                    return Err("Division by zero".to_string());
                }
                Ok(RuntimeValue::Int(a / b))
            }
            (RuntimeValue::Float(a), RuntimeValue::Float(b)) => {
                if *b == 0.0 {
                    return Err("Division by zero".to_string());
                }
                Ok(RuntimeValue::Float(a / b))
            }
            (RuntimeValue::Int(a), RuntimeValue::Float(b)) => {
                if *b == 0.0 {
                    return Err("Division by zero".to_string());
                }
                Ok(RuntimeValue::Float(*a as f64 / b))
            }
            (RuntimeValue::Float(a), RuntimeValue::Int(b)) => {
                if *b == 0 {
                    return Err("Division by zero".to_string());
                }
                Ok(RuntimeValue::Float(a / *b as f64))
            }
            _ => Err(format!("Cannot divide {} by {}", left.type_name(), right.type_name())),
        }
    }

    fn apply_modulo(&self, left: RuntimeValue, right: RuntimeValue) -> Result<RuntimeValue, String> {
        match (&left, &right) {
            (RuntimeValue::Int(a), RuntimeValue::Int(b)) => {
                if *b == 0 {
                    return Err("Modulo by zero".to_string());
                }
                Ok(RuntimeValue::Int(a % b))
            }
            _ => Err(format!("Cannot compute modulo of {} and {}", left.type_name(), right.type_name())),
        }
    }

    fn apply_comparison<F>(&self, left: RuntimeValue, right: RuntimeValue, cmp: F) -> Result<RuntimeValue, String>
    where
        F: Fn(i64, i64) -> bool,
    {
        match (&left, &right) {
            (RuntimeValue::Int(a), RuntimeValue::Int(b)) => Ok(RuntimeValue::Bool(cmp(*a, *b))),
            _ => Err(format!("Cannot compare {} and {}", left.type_name(), right.type_name())),
        }
    }

    fn values_equal(&self, left: &RuntimeValue, right: &RuntimeValue) -> bool {
        match (left, right) {
            (RuntimeValue::Int(a), RuntimeValue::Int(b)) => a == b,
            (RuntimeValue::Float(a), RuntimeValue::Float(b)) => (a - b).abs() < f64::EPSILON,
            (RuntimeValue::Bool(a), RuntimeValue::Bool(b)) => a == b,
            (RuntimeValue::Text(a), RuntimeValue::Text(b)) => a == b,
            (RuntimeValue::Char(a), RuntimeValue::Char(b)) => a == b,
            (RuntimeValue::Nothing, RuntimeValue::Nothing) => true,
            _ => false,
        }
    }

    /// Call a function (built-in or user-defined).
    #[async_recursion(?Send)]
    async fn call_function(&mut self, function: Symbol, args: &[&'async_recursion Expr<'a>]) -> Result<RuntimeValue, String> {
        let func_name = self.interner.resolve(function);

        // Built-in functions
        match func_name {
            "show" => {
                for arg in args {
                    let val = self.evaluate_expr(arg).await?;
                    self.output.push(val.to_display_string());
                }
                return Ok(RuntimeValue::Nothing);
            }
            "length" => {
                if args.len() != 1 {
                    return Err("length() takes exactly 1 argument".to_string());
                }
                let val = self.evaluate_expr(args[0]).await?;
                return match &val {
                    RuntimeValue::List(items) => Ok(RuntimeValue::Int(items.len() as i64)),
                    RuntimeValue::Text(s) => Ok(RuntimeValue::Int(s.len() as i64)),
                    _ => Err(format!("Cannot get length of {}", val.type_name())),
                };
            }
            "format" => {
                if args.is_empty() {
                    return Ok(RuntimeValue::Text(String::new()));
                }
                let val = self.evaluate_expr(args[0]).await?;
                return Ok(RuntimeValue::Text(val.to_display_string()));
            }
            "abs" => {
                if args.len() != 1 {
                    return Err("abs() takes exactly 1 argument".to_string());
                }
                let val = self.evaluate_expr(args[0]).await?;
                return match val {
                    RuntimeValue::Int(n) => Ok(RuntimeValue::Int(n.abs())),
                    RuntimeValue::Float(f) => Ok(RuntimeValue::Float(f.abs())),
                    _ => Err(format!("abs() requires a number, got {}", val.type_name())),
                };
            }
            "min" => {
                if args.len() != 2 {
                    return Err("min() takes exactly 2 arguments".to_string());
                }
                let a = self.evaluate_expr(args[0]).await?;
                let b = self.evaluate_expr(args[1]).await?;
                return match (&a, &b) {
                    (RuntimeValue::Int(x), RuntimeValue::Int(y)) => Ok(RuntimeValue::Int(*x.min(y))),
                    _ => Err("min() requires integers".to_string()),
                };
            }
            "max" => {
                if args.len() != 2 {
                    return Err("max() takes exactly 2 arguments".to_string());
                }
                let a = self.evaluate_expr(args[0]).await?;
                let b = self.evaluate_expr(args[1]).await?;
                return match (&a, &b) {
                    (RuntimeValue::Int(x), RuntimeValue::Int(y)) => Ok(RuntimeValue::Int(*x.max(y))),
                    _ => Err("max() requires integers".to_string()),
                };
            }
            "copy" => {
                if args.len() != 1 {
                    return Err("copy() takes exactly 1 argument".to_string());
                }
                let val = self.evaluate_expr(args[0]).await?;
                return Ok(val.clone());
            }
            _ => {}
        }

        // User-defined function lookup
        // Need to get the function separately to avoid borrow conflicts
        let func_data = self.functions.get(&function)
            .map(|f| (f.params.clone(), f.body))
            .ok_or_else(|| format!("Unknown function: {}", func_name))?;

        let (params, body) = func_data;

        if args.len() != params.len() {
            return Err(format!(
                "Function {} expects {} arguments, got {}",
                func_name,
                params.len(),
                args.len()
            ));
        }

        // Evaluate arguments before pushing scope
        let mut arg_values = Vec::new();
        for arg in args {
            arg_values.push(self.evaluate_expr(arg).await?);
        }

        // Push new scope and bind parameters
        self.push_scope();
        for ((param_name, _), arg_val) in params.iter().zip(arg_values) {
            self.define(*param_name, arg_val);
        }

        // Execute function body
        let mut return_value = RuntimeValue::Nothing;
        for stmt in body.iter() {
            match self.execute_stmt(stmt).await? {
                ControlFlow::Return(val) => {
                    return_value = val;
                    break;
                }
                ControlFlow::Break => break,
                ControlFlow::Continue => {}
            }
        }

        self.pop_scope();
        Ok(return_value)
    }

    // Scope management

    fn push_scope(&mut self) {
        self.env.push(HashMap::new());
    }

    fn pop_scope(&mut self) {
        if self.env.len() > 1 {
            self.env.pop();
        }
    }

    fn define(&mut self, name: Symbol, value: RuntimeValue) {
        if let Some(scope) = self.env.last_mut() {
            scope.insert(name, value);
        }
    }

    fn assign(&mut self, name: Symbol, value: RuntimeValue) -> Result<(), String> {
        // Search from innermost to outermost scope
        for scope in self.env.iter_mut().rev() {
            if scope.contains_key(&name) {
                scope.insert(name, value);
                return Ok(());
            }
        }
        Err(format!("Undefined variable: {}", self.interner.resolve(name)))
    }

    fn lookup(&self, name: Symbol) -> Result<&RuntimeValue, String> {
        // Search from innermost to outermost scope
        for scope in self.env.iter().rev() {
            if let Some(value) = scope.get(&name) {
                return Ok(value);
            }
        }
        Err(format!("Undefined variable: {}", self.interner.resolve(name)))
    }
}

/// Result from interpretation.
#[derive(Debug, Clone)]
pub struct InterpreterResult {
    pub lines: Vec<String>,
    pub error: Option<String>,
}

```

---

### Learning State Management

**File:** `src/learn_state.rs`

Tracks user progress: lesson completion, XP, streaks, achievements. Persisted to local storage. LearningState struct with serializable progress data.

```rust
//! Tab & Focus State Management for Learn Page
//!
//! Manages the state for the integrated learn page experience:
//! - Tab modes (Lesson, Examples, Practice, Test)
//! - Focus state (which era/module is expanded)
//! - Exercise navigation within modes

/// The four tab modes available for each module
#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
pub enum TabMode {
    #[default]
    Lesson,
    Examples,
    Practice,
    Test,
}

impl TabMode {
    /// Get display label for the tab
    pub fn label(&self) -> &'static str {
        match self {
            TabMode::Lesson => "LESSON",
            TabMode::Examples => "EXAMPLES",
            TabMode::Practice => "PRACTICE",
            TabMode::Test => "TEST",
        }
    }

    /// Get all tab modes in order
    pub fn all() -> [TabMode; 4] {
        [TabMode::Lesson, TabMode::Examples, TabMode::Practice, TabMode::Test]
    }
}

/// State for a single module's tab interface
#[derive(Debug, Clone, Default)]
pub struct ModuleTabState {
    pub module_id: String,
    pub current_tab: TabMode,
    pub exercise_index: usize,
    pub submitted: bool,
}

impl ModuleTabState {
    pub fn new(module_id: &str) -> Self {
        Self {
            module_id: module_id.to_string(),
            current_tab: TabMode::Lesson,
            exercise_index: 0,
            submitted: false,
        }
    }

    /// Switch to a new tab, resetting exercise state
    pub fn switch_tab(&mut self, tab: TabMode) {
        self.current_tab = tab;
        self.exercise_index = 0;
        self.submitted = false;
    }

    /// Reset exercise state without changing tab
    pub fn reset_exercise(&mut self) {
        self.exercise_index = 0;
        self.submitted = false;
    }
}

/// Tracks which era is currently focused (expanded)
#[derive(Debug, Clone, Default)]
pub struct FocusState {
    /// The currently focused era (None = no focus, all eras visible)
    pub focused_era: Option<String>,
    /// The currently expanded module within the focused era
    pub expanded_module: Option<(String, String)>, // (era_id, module_id)
}

impl FocusState {
    pub fn new() -> Self {
        Self::default()
    }

    /// Focus on a specific era
    pub fn focus_era(&mut self, era_id: &str) {
        self.focused_era = Some(era_id.to_string());
    }

    /// Expand a module within an era
    pub fn expand_module(&mut self, era_id: &str, module_id: &str) {
        self.focused_era = Some(era_id.to_string());
        self.expanded_module = Some((era_id.to_string(), module_id.to_string()));
    }

    /// Collapse the current module (but keep era focused)
    pub fn collapse_module(&mut self) {
        self.expanded_module = None;
    }

    /// Unfocus completely (show all eras)
    pub fn unfocus(&mut self) {
        self.focused_era = None;
        self.expanded_module = None;
    }

    /// Check if a specific era is visible (either focused or no focus)
    pub fn is_era_visible(&self, era_id: &str) -> bool {
        match &self.focused_era {
            None => true,
            Some(focused) => focused == era_id,
        }
    }

    /// Check if a specific module is expanded
    pub fn is_module_expanded(&self, era_id: &str, module_id: &str) -> bool {
        match &self.expanded_module {
            None => false,
            Some((e, m)) => e == era_id && m == module_id,
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_tab_modes_all_four_exist() {
        let tabs = TabMode::all();
        assert_eq!(tabs.len(), 4);
        assert_eq!(tabs[0], TabMode::Lesson);
        assert_eq!(tabs[1], TabMode::Examples);
        assert_eq!(tabs[2], TabMode::Practice);
        assert_eq!(tabs[3], TabMode::Test);
    }

    #[test]
    fn test_initial_tab_is_lesson() {
        let state = ModuleTabState::new("test-module");
        assert_eq!(state.current_tab, TabMode::Lesson);
    }

    #[test]
    fn test_tab_switch_resets_exercise_index() {
        let mut state = ModuleTabState::new("test-module");
        state.exercise_index = 5;
        state.submitted = true;

        state.switch_tab(TabMode::Practice);

        assert_eq!(state.current_tab, TabMode::Practice);
        assert_eq!(state.exercise_index, 0);
        assert!(!state.submitted);
    }

    #[test]
    fn test_focus_state_toggles_era() {
        let mut focus = FocusState::new();
        assert!(focus.focused_era.is_none());

        focus.focus_era("first-steps");
        assert_eq!(focus.focused_era, Some("first-steps".to_string()));

        focus.unfocus();
        assert!(focus.focused_era.is_none());
    }

    #[test]
    fn test_is_era_visible_when_focused() {
        let mut focus = FocusState::new();

        // No focus = all eras visible
        assert!(focus.is_era_visible("first-steps"));
        assert!(focus.is_era_visible("mastery"));

        // Focus on one era = only that era visible
        focus.focus_era("first-steps");
        assert!(focus.is_era_visible("first-steps"));
        assert!(!focus.is_era_visible("mastery"));
    }

    #[test]
    fn test_module_expansion() {
        let mut focus = FocusState::new();

        focus.expand_module("first-steps", "introduction");
        assert!(focus.is_module_expanded("first-steps", "introduction"));
        assert!(!focus.is_module_expanded("first-steps", "syllogistic"));

        focus.collapse_module();
        assert!(!focus.is_module_expanded("first-steps", "introduction"));
        // Era should still be focused
        assert!(focus.is_era_visible("first-steps"));
    }
}

```

---

### Struggle Detection

**File:** `src/struggle.rs`

Identifies areas where users need help. Tracks error patterns, offers adaptive hints. StruggleTracker monitors repeated failures on specific concepts.

```rust
//! Struggle Detection Logic
//!
//! Detects when a user is struggling with an exercise based on:
//! - Inactivity (no answer attempt after threshold time)
//! - Wrong attempts (incorrect answers)

/// Reasons why a user might be struggling
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum StruggleReason {
    Inactivity,
    WrongAttempt,
}

impl StruggleReason {
    /// Get a message describing the struggle reason
    pub fn message(&self) -> &'static str {
        match self {
            StruggleReason::Inactivity => "Taking your time? Here's a hint to help you along.",
            StruggleReason::WrongAttempt => "Not quite! Let me help you think through this.",
        }
    }
}

/// Configuration for struggle detection
#[derive(Debug, Clone, Copy)]
pub struct StruggleConfig {
    /// Seconds of inactivity before considering the user stuck
    pub inactivity_threshold_secs: u64,
    /// Number of wrong attempts before showing help
    pub wrong_attempt_threshold: u32,
}

impl Default for StruggleConfig {
    fn default() -> Self {
        Self {
            inactivity_threshold_secs: 5,
            wrong_attempt_threshold: 1,
        }
    }
}

/// Tracks struggle state for an exercise
#[derive(Debug, Clone, Default)]
pub struct StruggleDetector {
    pub config: StruggleConfig,
    pub is_struggling: bool,
    pub reason: Option<StruggleReason>,
    pub wrong_attempts: u32,
    pub inactivity_triggered: bool,
}

impl StruggleDetector {
    pub fn new() -> Self {
        Self::default()
    }

    pub fn with_config(config: StruggleConfig) -> Self {
        Self {
            config,
            ..Default::default()
        }
    }

    /// Record a wrong attempt - may trigger struggle state
    pub fn record_wrong_attempt(&mut self) {
        self.wrong_attempts += 1;
        if self.wrong_attempts >= self.config.wrong_attempt_threshold {
            self.is_struggling = true;
            self.reason = Some(StruggleReason::WrongAttempt);
        }
    }

    /// Record a correct attempt - resets inactivity but keeps struggle state for hints
    pub fn record_correct_attempt(&mut self) {
        // User got it right - they're no longer struggling
        self.is_struggling = false;
        self.inactivity_triggered = false;
    }

    /// Record user activity (typing, clicking) - resets inactivity timer
    pub fn record_activity(&mut self) {
        // Activity resets inactivity detection
        self.inactivity_triggered = false;
    }

    /// Called when inactivity threshold is reached
    pub fn trigger_inactivity(&mut self) {
        if !self.inactivity_triggered {
            self.inactivity_triggered = true;
            self.is_struggling = true;
            // Only set reason if not already struggling from wrong attempts
            if self.reason.is_none() {
                self.reason = Some(StruggleReason::Inactivity);
            }
        }
    }

    /// Reset struggle state (e.g., when moving to next exercise)
    pub fn reset(&mut self) {
        self.is_struggling = false;
        self.reason = None;
        self.wrong_attempts = 0;
        self.inactivity_triggered = false;
    }

    /// Check if we should show hints
    pub fn should_show_hints(&self) -> bool {
        self.is_struggling
    }

    /// Get the current struggle reason
    pub fn reason(&self) -> Option<StruggleReason> {
        self.reason
    }

    /// Get the current struggle reason for display
    pub fn struggle_message(&self) -> Option<&'static str> {
        match self.reason {
            Some(StruggleReason::Inactivity) => Some("Taking your time? Here's a hint to help you along."),
            Some(StruggleReason::WrongAttempt) => Some("Not quite! Let me help you think through this."),
            None => None,
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_no_struggle_initially() {
        let detector = StruggleDetector::new();
        assert!(!detector.is_struggling);
        assert!(detector.reason.is_none());
    }

    #[test]
    fn test_struggle_after_5s_inactivity() {
        let mut detector = StruggleDetector::new();
        assert!(!detector.is_struggling);

        detector.trigger_inactivity();

        assert!(detector.is_struggling);
        assert_eq!(detector.reason, Some(StruggleReason::Inactivity));
    }

    #[test]
    fn test_struggle_after_wrong_attempt() {
        let mut detector = StruggleDetector::new();
        assert!(!detector.is_struggling);

        detector.record_wrong_attempt();

        assert!(detector.is_struggling);
        assert_eq!(detector.reason, Some(StruggleReason::WrongAttempt));
    }

    #[test]
    fn test_reset_clears_struggle() {
        let mut detector = StruggleDetector::new();
        detector.record_wrong_attempt();
        assert!(detector.is_struggling);

        detector.reset();

        assert!(!detector.is_struggling);
        assert!(detector.reason.is_none());
        assert_eq!(detector.wrong_attempts, 0);
    }

    #[test]
    fn test_configurable_threshold() {
        let config = StruggleConfig {
            inactivity_threshold_secs: 10,
            wrong_attempt_threshold: 2,
        };
        let mut detector = StruggleDetector::with_config(config);

        // First wrong attempt shouldn't trigger with threshold of 2
        detector.record_wrong_attempt();
        assert!(!detector.is_struggling);

        // Second wrong attempt should trigger
        detector.record_wrong_attempt();
        assert!(detector.is_struggling);
    }

    #[test]
    fn test_inactivity_only_triggers_once() {
        let mut detector = StruggleDetector::new();

        detector.trigger_inactivity();
        assert!(detector.inactivity_triggered);

        // Triggering again shouldn't change the reason
        detector.reason = None;
        detector.trigger_inactivity();
        assert!(detector.reason.is_none()); // Didn't set it again
    }

    #[test]
    fn test_should_show_hints() {
        let mut detector = StruggleDetector::new();
        assert!(!detector.should_show_hints());

        detector.record_wrong_attempt();
        assert!(detector.should_show_hints());
    }

    #[test]
    fn test_struggle_message() {
        let mut detector = StruggleDetector::new();
        assert!(detector.struggle_message().is_none());

        detector.trigger_inactivity();
        assert!(detector.struggle_message().is_some());
        assert!(detector.struggle_message().unwrap().contains("hint"));
    }
}

```

---

### Symbol Dictionary

**File:** `src/symbol_dict.rs`

Runtime symbol table for interactive features. Maps symbols to definitions and types. Used by workspace for autocomplete and hover info.

```rust
//! Symbol Dictionary Extraction
//!
//! Extracts logical symbols from FOL strings for display in a symbol dictionary.
//! Groups symbols by kind and provides descriptions.

use std::collections::HashSet;

/// Categories of logical symbols
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum SymbolKind {
    Quantifier,
    Connective,
    Variable,
    Predicate,
    Constant,
    Modal,
    Identity,
    Punctuation,
    Temporal,
}

impl SymbolKind {
    pub fn label(&self) -> &'static str {
        match self {
            SymbolKind::Quantifier => "Quantifier",
            SymbolKind::Connective => "Connective",
            SymbolKind::Variable => "Variable",
            SymbolKind::Predicate => "Predicate",
            SymbolKind::Constant => "Constant",
            SymbolKind::Modal => "Modal",
            SymbolKind::Identity => "Identity",
            SymbolKind::Punctuation => "Punctuation",
            SymbolKind::Temporal => "Temporal",
        }
    }
}

/// A single symbol entry in the dictionary
#[derive(Debug, Clone, PartialEq, Eq, Hash)]
pub struct SymbolEntry {
    pub symbol: String,
    pub kind: SymbolKind,
    pub description: String,
}

/// Extract symbols from a FOL logic string
pub fn extract_symbols(logic: &str) -> Vec<SymbolEntry> {
    let mut entries = Vec::new();
    let mut seen: HashSet<String> = HashSet::new();

    // Quantifiers
    if logic.contains("∀") && seen.insert("∀".to_string()) {
        entries.push(SymbolEntry {
            symbol: "∀".to_string(),
            kind: SymbolKind::Quantifier,
            description: "Universal quantifier: \"for all\"".to_string(),
        });
    }
    if logic.contains("∃") && seen.insert("∃".to_string()) {
        entries.push(SymbolEntry {
            symbol: "∃".to_string(),
            kind: SymbolKind::Quantifier,
            description: "Existential quantifier: \"there exists\"".to_string(),
        });
    }
    if logic.contains("∃!") && seen.insert("∃!".to_string()) {
        entries.push(SymbolEntry {
            symbol: "∃!".to_string(),
            kind: SymbolKind::Quantifier,
            description: "Unique existence: \"there exists exactly one\"".to_string(),
        });
    }
    if logic.contains("MOST") && seen.insert("MOST".to_string()) {
        entries.push(SymbolEntry {
            symbol: "MOST".to_string(),
            kind: SymbolKind::Quantifier,
            description: "Generalized quantifier: \"most\"".to_string(),
        });
    }
    if logic.contains("FEW") && seen.insert("FEW".to_string()) {
        entries.push(SymbolEntry {
            symbol: "FEW".to_string(),
            kind: SymbolKind::Quantifier,
            description: "Generalized quantifier: \"few\"".to_string(),
        });
    }

    // Connectives
    if logic.contains("∧") && seen.insert("∧".to_string()) {
        entries.push(SymbolEntry {
            symbol: "∧".to_string(),
            kind: SymbolKind::Connective,
            description: "Conjunction: \"and\"".to_string(),
        });
    }
    if logic.contains("∨") && seen.insert("∨".to_string()) {
        entries.push(SymbolEntry {
            symbol: "∨".to_string(),
            kind: SymbolKind::Connective,
            description: "Disjunction: \"or\"".to_string(),
        });
    }
    if logic.contains("→") && seen.insert("→".to_string()) {
        entries.push(SymbolEntry {
            symbol: "→".to_string(),
            kind: SymbolKind::Connective,
            description: "Implication: \"if...then\"".to_string(),
        });
    }
    if logic.contains("↔") && seen.insert("↔".to_string()) {
        entries.push(SymbolEntry {
            symbol: "↔".to_string(),
            kind: SymbolKind::Connective,
            description: "Biconditional: \"if and only if\"".to_string(),
        });
    }
    if logic.contains("¬") && seen.insert("¬".to_string()) {
        entries.push(SymbolEntry {
            symbol: "¬".to_string(),
            kind: SymbolKind::Connective,
            description: "Negation: \"not\"".to_string(),
        });
    }

    // Modal operators
    if logic.contains("□") && seen.insert("□".to_string()) {
        entries.push(SymbolEntry {
            symbol: "□".to_string(),
            kind: SymbolKind::Modal,
            description: "Necessity: \"it is necessary that\"".to_string(),
        });
    }
    if logic.contains("◇") && seen.insert("◇".to_string()) {
        entries.push(SymbolEntry {
            symbol: "◇".to_string(),
            kind: SymbolKind::Modal,
            description: "Possibility: \"it is possible that\"".to_string(),
        });
    }
    if logic.contains("O_") && seen.insert("O".to_string()) {
        entries.push(SymbolEntry {
            symbol: "O".to_string(),
            kind: SymbolKind::Modal,
            description: "Deontic obligation: \"it ought to be that\"".to_string(),
        });
    }

    // Identity
    if logic.contains(" = ") && seen.insert("=".to_string()) {
        entries.push(SymbolEntry {
            symbol: "=".to_string(),
            kind: SymbolKind::Identity,
            description: "Identity: \"is identical to\"".to_string(),
        });
    }

    // Extract predicates (uppercase letters followed by parenthesis)
    extract_predicates(logic, &mut entries, &mut seen);

    // Extract variables (lowercase x, y, z, etc.)
    extract_variables(logic, &mut entries, &mut seen);

    // Extract constants (uppercase single letters not followed by parenthesis)
    extract_constants(logic, &mut entries, &mut seen);

    entries
}

fn extract_predicates(logic: &str, entries: &mut Vec<SymbolEntry>, seen: &mut HashSet<String>) {
    // Match patterns like "Dog(", "Mortal(", "Loves("
    let chars: Vec<char> = logic.chars().collect();
    let mut i = 0;

    while i < chars.len() {
        if chars[i].is_ascii_uppercase() {
            let start = i;
            while i < chars.len() && (chars[i].is_ascii_alphanumeric() || chars[i] == '_') {
                i += 1;
            }
            if i < chars.len() && chars[i] == '(' {
                let predicate: String = chars[start..i].iter().collect();
                if seen.insert(format!("pred_{}", predicate)) {
                    entries.push(SymbolEntry {
                        symbol: predicate.clone(),
                        kind: SymbolKind::Predicate,
                        description: format!("Predicate: {}", predicate),
                    });
                }
            }
        }
        i += 1;
    }
}

fn extract_variables(logic: &str, entries: &mut Vec<SymbolEntry>, seen: &mut HashSet<String>) {
    // Variables are lowercase letters typically x, y, z, w
    for var in ['x', 'y', 'z', 'w', 'e'] {
        let var_str = var.to_string();
        // Check if variable appears in context (not as part of a word)
        if logic.contains(&format!("({})", var))
            || logic.contains(&format!("({},", var))
            || logic.contains(&format!(", {})", var))
            || logic.contains(&format!("{}.", var))
            || logic.contains(&format!(" {}", var))
        {
            if seen.insert(format!("var_{}", var)) {
                entries.push(SymbolEntry {
                    symbol: var_str,
                    kind: SymbolKind::Variable,
                    description: "Bound variable".to_string(),
                });
            }
        }
    }
}

fn extract_constants(logic: &str, entries: &mut Vec<SymbolEntry>, seen: &mut HashSet<String>) {
    // Constants are uppercase letters like J (John), M (Mary), etc.
    // But not predicates (followed by parenthesis)
    let chars: Vec<char> = logic.chars().collect();
    let mut i = 0;

    while i < chars.len() {
        if chars[i].is_ascii_uppercase() {
            let start = i;
            // Collect the full name (may have numbers like J2)
            while i < chars.len() && (chars[i].is_ascii_alphanumeric()) {
                i += 1;
            }
            // Check if NOT followed by parenthesis (would be predicate)
            if i >= chars.len() || chars[i] != '(' {
                let constant: String = chars[start..i].iter().collect();
                // Skip very long names (likely predicates) and known quantifiers
                if constant.len() <= 3
                    && !["MOST", "FEW", "ALL", "THE"].contains(&constant.as_str())
                    && seen.insert(format!("const_{}", constant))
                {
                    entries.push(SymbolEntry {
                        symbol: constant.clone(),
                        kind: SymbolKind::Constant,
                        description: format!("Constant: {}", constant),
                    });
                }
            }
        }
        i += 1;
    }
}

/// Get symbols grouped by kind for display
pub fn group_symbols_by_kind(entries: &[SymbolEntry]) -> Vec<(SymbolKind, Vec<&SymbolEntry>)> {
    let kinds = [
        SymbolKind::Quantifier,
        SymbolKind::Connective,
        SymbolKind::Modal,
        SymbolKind::Identity,
        SymbolKind::Predicate,
        SymbolKind::Variable,
        SymbolKind::Constant,
    ];

    kinds
        .iter()
        .filter_map(|&kind| {
            let matching: Vec<_> = entries.iter().filter(|e| e.kind == kind).collect();
            if matching.is_empty() {
                None
            } else {
                Some((kind, matching))
            }
        })
        .collect()
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_extract_quantifier_symbols() {
        let logic = "∀x(Dog(x) → Mortal(x))";
        let symbols = extract_symbols(logic);

        let quantifiers: Vec<_> = symbols.iter().filter(|s| s.kind == SymbolKind::Quantifier).collect();
        assert!(quantifiers.iter().any(|s| s.symbol == "∀"), "Should find universal quantifier");
    }

    #[test]
    fn test_extract_existential() {
        let logic = "∃x(Cat(x) ∧ Black(x))";
        let symbols = extract_symbols(logic);

        assert!(symbols.iter().any(|s| s.symbol == "∃"), "Should find existential quantifier");
    }

    #[test]
    fn test_extract_connective_symbols() {
        let logic = "∀x(Dog(x) → (Loyal(x) ∧ Friendly(x)))";
        let symbols = extract_symbols(logic);

        let connectives: Vec<_> = symbols.iter().filter(|s| s.kind == SymbolKind::Connective).collect();
        assert!(connectives.iter().any(|s| s.symbol == "∧"), "Should find conjunction");
        assert!(connectives.iter().any(|s| s.symbol == "→"), "Should find implication");
    }

    #[test]
    fn test_extract_predicate_names() {
        let logic = "∀x(Dog(x) → Mammal(x))";
        let symbols = extract_symbols(logic);

        let predicates: Vec<_> = symbols.iter().filter(|s| s.kind == SymbolKind::Predicate).collect();
        assert!(predicates.iter().any(|s| s.symbol == "Dog"), "Should find Dog predicate");
        assert!(predicates.iter().any(|s| s.symbol == "Mammal"), "Should find Mammal predicate");
    }

    #[test]
    fn test_extract_variable_names() {
        let logic = "∀x∃y(Loves(x, y))";
        let symbols = extract_symbols(logic);

        let variables: Vec<_> = symbols.iter().filter(|s| s.kind == SymbolKind::Variable).collect();
        assert!(variables.iter().any(|s| s.symbol == "x"), "Should find variable x");
        assert!(variables.iter().any(|s| s.symbol == "y"), "Should find variable y");
    }

    #[test]
    fn test_no_duplicate_symbols() {
        let logic = "∀x(Dog(x) → Dog(x))";
        let symbols = extract_symbols(logic);

        let dog_count = symbols.iter().filter(|s| s.symbol == "Dog").count();
        assert_eq!(dog_count, 1, "Should not have duplicate predicates");
    }

    #[test]
    fn test_symbol_has_description() {
        let logic = "∀x(P(x))";
        let symbols = extract_symbols(logic);

        for symbol in &symbols {
            assert!(!symbol.description.is_empty(), "Every symbol should have a description");
        }
    }

    #[test]
    fn test_modal_symbols() {
        let logic = "□(P(x)) ∧ ◇(Q(y))";
        let symbols = extract_symbols(logic);

        assert!(symbols.iter().any(|s| s.symbol == "□"), "Should find necessity operator");
        assert!(symbols.iter().any(|s| s.symbol == "◇"), "Should find possibility operator");
    }

    #[test]
    fn test_group_symbols_by_kind() {
        let logic = "∀x(Dog(x) → ∃y(Loves(x, y)))";
        let symbols = extract_symbols(logic);
        let grouped = group_symbols_by_kind(&symbols);

        // Should have multiple groups
        assert!(!grouped.is_empty(), "Should have grouped symbols");

        // Check quantifiers group exists
        assert!(grouped.iter().any(|(k, _)| *k == SymbolKind::Quantifier), "Should have quantifier group");
    }
}

```

---

### Content Unlocking

**File:** `src/unlock.rs`

Progressive disclosure system. Lessons unlock based on prerequisites and mastery. UnlockState tracks completed lessons and available content.

```rust
//! Module Unlock Logic
//!
//! Rules:
//! - First module in each era is always unlocked
//! - Subsequent modules unlock when the previous module is completed
//! - Last two modules in each era are locked until at least one module has 100% completion

use crate::content::ContentEngine;
use crate::progress::UserProgress;

/// State of a module for the user
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum ModuleState {
    /// Module is locked and cannot be accessed
    Locked,
    /// Module is unlocked but not started
    Available,
    /// Module has been started (score < 50%)
    Started,
    /// Module is in progress (50-89% score)
    Progressing,
    /// Module has been completed but not perfected (90%+ score)
    Completed,
    /// Module has been perfected (100% or 3 stars)
    Perfected,
}

/// Get the current state of a module for the user
pub fn get_module_state(
    progress: &UserProgress,
    engine: &ContentEngine,
    era_id: &str,
    module_id: &str,
) -> ModuleState {
    // Check if locked
    if !check_module_unlocked(progress, engine, era_id, module_id) {
        return ModuleState::Locked;
    }

    // Check progress
    match progress.modules.get(module_id) {
        None => ModuleState::Available,
        Some(mp) => {
            if mp.completed && (mp.best_score >= 90 || mp.stars >= 3) {
                ModuleState::Perfected
            } else if mp.completed {
                ModuleState::Completed
            } else if mp.best_score >= 50 {
                ModuleState::Progressing
            } else if mp.attempts > 0 || mp.best_score > 0 {
                ModuleState::Started
            } else {
                ModuleState::Available
            }
        }
    }
}

/// Check if a specific module is unlocked for the user
pub fn check_module_unlocked(
    progress: &UserProgress,
    engine: &ContentEngine,
    era_id: &str,
    module_id: &str,
) -> bool {
    let Some(era) = engine.get_era(era_id) else {
        return false;
    };

    let module_ids: Vec<&str> = era.modules.iter().map(|m| m.meta.id.as_str()).collect();
    let Some(module_index) = module_ids.iter().position(|&id| id == module_id) else {
        return false;
    };

    let total_modules = module_ids.len();

    // First module is always unlocked
    if module_index == 0 {
        return true;
    }

    // Check if this is one of the last two modules
    let is_final_module = total_modules >= 2 && module_index >= total_modules - 2;

    if is_final_module {
        // Last two modules require at least one module to be 100% complete
        let has_perfect_completion = module_ids.iter().take(total_modules.saturating_sub(2)).any(|&mid| {
            progress.modules.get(mid).map_or(false, |mp| mp.completed && mp.best_score >= 100)
        });

        if !has_perfect_completion {
            return false;
        }
    }

    // Check if previous module is completed
    let prev_module_id = module_ids[module_index - 1];
    progress.modules.get(prev_module_id).map_or(false, |mp| mp.completed)
}

/// Get list of locked module IDs for an era
pub fn get_locked_module_ids(
    progress: &UserProgress,
    engine: &ContentEngine,
    era_id: &str,
) -> Vec<String> {
    let Some(era) = engine.get_era(era_id) else {
        return Vec::new();
    };

    era.modules
        .iter()
        .filter(|m| !check_module_unlocked(progress, engine, era_id, &m.meta.id))
        .map(|m| m.meta.id.clone())
        .collect()
}

/// Check if any module in the era has 100% completion
pub fn has_perfect_module(progress: &UserProgress, engine: &ContentEngine, era_id: &str) -> bool {
    let Some(era) = engine.get_era(era_id) else {
        return false;
    };

    era.modules.iter().any(|m| {
        progress.modules.get(&m.meta.id).map_or(false, |mp| mp.completed && mp.best_score >= 100)
    })
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::progress::ModuleProgress;

    fn make_progress_with_completed(completed_modules: &[(&str, bool, u32)]) -> UserProgress {
        let mut progress = UserProgress::new();
        for (id, completed, score) in completed_modules {
            progress.modules.insert(id.to_string(), ModuleProgress {
                module_id: id.to_string(),
                unlocked: true,
                completed: *completed,
                stars: 0,
                best_score: *score,
                attempts: 1,
            });
        }
        progress
    }

    #[test]
    fn test_first_module_always_unlocked() {
        let progress = UserProgress::new();
        let engine = ContentEngine::new();

        // First module of first era should always be unlocked
        if let Some(era) = engine.eras().first() {
            if let Some(module) = era.modules.first() {
                assert!(check_module_unlocked(&progress, &engine, &era.meta.id, &module.meta.id));
            }
        }
    }

    #[test]
    fn test_module_locked_until_previous_complete() {
        let engine = ContentEngine::new();

        if let Some(era) = engine.eras().first() {
            if era.modules.len() >= 2 {
                let first_id = &era.modules[0].meta.id;
                let second_id = &era.modules[1].meta.id;

                // Without completing first module, second should be locked
                let progress = UserProgress::new();
                assert!(!check_module_unlocked(&progress, &engine, &era.meta.id, second_id));

                // After completing first module, second should be unlocked
                let progress = make_progress_with_completed(&[(first_id.as_str(), true, 80)]);
                assert!(check_module_unlocked(&progress, &engine, &era.meta.id, second_id));
            }
        }
    }

    #[test]
    fn test_last_two_locked_until_one_module_100_complete() {
        let engine = ContentEngine::new();

        // Find an era with at least 4 modules
        for era in engine.eras() {
            if era.modules.len() >= 4 {
                let module_ids: Vec<&str> = era.modules.iter().map(|m| m.meta.id.as_str()).collect();
                let last_module_id = module_ids[module_ids.len() - 1];
                let second_last_id = module_ids[module_ids.len() - 2];

                // Complete all modules except last two, but none at 100%
                let mut completed: Vec<(&str, bool, u32)> = module_ids[..module_ids.len()-2]
                    .iter()
                    .map(|id| (*id, true, 80u32))
                    .collect();

                let progress = make_progress_with_completed(&completed);

                // Last two should still be locked (no 100% completion)
                assert!(!check_module_unlocked(&progress, &engine, &era.meta.id, second_last_id),
                    "Second-to-last module should be locked without 100% completion");
                assert!(!check_module_unlocked(&progress, &engine, &era.meta.id, last_module_id),
                    "Last module should be locked without 100% completion");

                // Now complete one module at 100%
                completed[0].2 = 100;
                let progress = make_progress_with_completed(&completed);

                // Second-to-last should now be unlocked
                assert!(check_module_unlocked(&progress, &engine, &era.meta.id, second_last_id),
                    "Second-to-last module should be unlocked with 100% completion");

                break;
            }
        }
    }

    #[test]
    fn test_get_locked_module_ids() {
        let progress = UserProgress::new();
        let engine = ContentEngine::new();

        if let Some(era) = engine.eras().first() {
            let locked = get_locked_module_ids(&progress, &engine, &era.meta.id);

            // All modules except the first should be locked initially
            assert_eq!(locked.len(), era.modules.len() - 1);

            // First module should NOT be in the locked list
            if let Some(first_module) = era.modules.first() {
                assert!(!locked.contains(&first_module.meta.id));
            }
        }
    }
}

```

---

## Entry Point

Command-line interface and REPL for interactive use.

**Location:** `src/main.rs`

### Application Entry Point

**File:** `src/main.rs`

Web application entry point. Launches Dioxus web UI with Router for SPA navigation. Build with 'dx serve' for development or 'dx build' for production WASM deployment.

```rust
//! LOGOS entry point
//!
//! Dispatches between CLI mode and web UI based on compile features.

#[cfg(all(not(target_arch = "wasm32"), feature = "cli"))]
fn main() {
    if let Err(e) = logos::cli::run_cli() {
        eprintln!("Error: {}", e);
        std::process::exit(1);
    }
}

#[cfg(any(target_arch = "wasm32", not(feature = "cli")))]
fn main() {
    dioxus::launch(logos::ui::App);
}

```

---

## Web Application

Dioxus-based web application with routing and multiple pages.

**Location:** `src/ui/`

**Architecture:**
- Router-based SPA with client-side navigation
- Pages: Home (Quadrivium menu), Workspace (chat interface), Pricing, Learn (curriculum browser), Lesson (problem-solving)
- Components: Reusable UI elements (chat display, input area)
- Problem Generator: Template-based exercise generation with semantic grading
- Fair Source licensing with honor system toggle

### UI: App

**File:** `src/ui/app.rs`

Root application component with Router wrapper and global CSS styles (gradients, glassmorphism, animations).

```rust
use dioxus::prelude::*;
use crate::ui::router::Route;
use crate::ui::state::{LicenseState, RegistryAuthState};
use crate::ui::theme;

const GLOBAL_STYLE: &str = r#"
:root {
    /* Primary colors */
    --color-primary-blue: #667eea;
    --color-primary-purple: #764ba2;
    --color-accent-blue: #60a5fa;
    --color-accent-purple: #a78bfa;

    /* Semantic colors */
    --color-success: #4ade80;
    --color-warning: #f59e0b;
    --color-error: #e06c75;
    --color-info: #60a5fa;

    /* Text colors - accessible grays (lighter for visibility) */
    --text-primary: #f0f0f0;
    --text-secondary: #b0b0b0;
    --text-tertiary: #909090;
    --text-muted: #a0a0a0;
    --text-placeholder: #808080;

    /* Font sizes - +2px for accessibility */
    --font-display-xl: 66px;
    --font-display-lg: 50px;
    --font-display-md: 34px;
    --font-heading-lg: 26px;
    --font-heading-md: 22px;
    --font-heading-sm: 20px;
    --font-body-lg: 18px;
    --font-body-md: 16px;
    --font-body-sm: 15px;
    --font-caption-lg: 14px;
    --font-caption-md: 13px;
    --font-caption-sm: 12px;

    /* Font families */
    --font-mono: 'SF Mono', 'Fira Code', 'Consolas', monospace;
    --font-sans: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif;

    /* Spacing */
    --spacing-xs: 4px;
    --spacing-sm: 8px;
    --spacing-md: 12px;
    --spacing-lg: 16px;
    --spacing-xl: 24px;
    --spacing-xxl: 32px;

    /* Border radius */
    --radius-sm: 4px;
    --radius-md: 8px;
    --radius-lg: 12px;
    --radius-xl: 16px;
    --radius-full: 9999px;
}

* {
    margin: 0;
    padding: 0;
    box-sizing: border-box;
}

html, body {
    height: 100%;
    background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
    color: var(--text-primary);
    font-family: var(--font-sans);
    font-size: var(--font-body-lg);
    overflow-x: hidden;
}

#main {
    min-height: 100vh;
}

a {
    color: inherit;
    text-decoration: none;
}

.chat-area {
    flex: 1;
    overflow-y: auto;
    padding: 30px;
    display: flex;
    flex-direction: column;
    gap: var(--spacing-lg);
}

.message {
    max-width: 75%;
    padding: 14px 20px;
    border-radius: var(--radius-xl);
    line-height: 1.6;
    animation: fadeIn 0.3s ease;
}

@keyframes fadeIn {
    from { opacity: 0; transform: translateY(10px); }
    to { opacity: 1; transform: translateY(0); }
}

.message.user {
    align-self: flex-end;
    background: linear-gradient(135deg, var(--color-primary-blue) 0%, var(--color-primary-purple) 100%);
    color: white;
    border-bottom-right-radius: var(--radius-sm);
    box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
}

.message.system {
    align-self: flex-start;
    background: rgba(255, 255, 255, 0.08);
    border: 1px solid rgba(255, 255, 255, 0.15);
    border-bottom-left-radius: var(--radius-sm);
    font-family: var(--font-mono);
    font-size: var(--font-heading-sm);
    color: #00d4ff;
    text-shadow: 0 0 20px rgba(0, 212, 255, 0.3);
}

.message.error {
    align-self: flex-start;
    background: linear-gradient(135deg, #ff6b6b 0%, #c92a2a 100%);
    color: white;
    border-bottom-left-radius: var(--radius-sm);
    font-style: italic;
    box-shadow: 0 4px 15px rgba(255, 107, 107, 0.3);
}

.input-area {
    background: rgba(0, 0, 0, 0.4);
    backdrop-filter: blur(10px);
    padding: 20px 30px;
    border-top: 1px solid rgba(255, 255, 255, 0.1);
}

.input-row {
    display: flex;
    gap: var(--spacing-md);
    align-items: center;
}

.input-row input {
    flex: 1;
    background: rgba(255, 255, 255, 0.08);
    border: 1px solid rgba(255, 255, 255, 0.2);
    border-radius: var(--radius-lg);
    padding: 14px 20px;
    font-size: var(--font-body-lg);
    color: white;
    outline: none;
    transition: all 0.2s ease;
}

.input-row input::placeholder {
    color: var(--text-placeholder);
}

.input-row input:focus {
    border-color: var(--color-primary-blue);
    box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.2);
}

.input-row button {
    background: linear-gradient(135deg, var(--color-primary-blue) 0%, var(--color-primary-purple) 100%);
    border: none;
    border-radius: var(--radius-lg);
    padding: 14px 28px;
    font-size: var(--font-body-lg);
    font-weight: 600;
    color: white;
    cursor: pointer;
    transition: all 0.2s ease;
    box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
}

.input-row button:hover {
    transform: translateY(-2px);
    box-shadow: 0 6px 20px rgba(102, 126, 234, 0.4);
}

.input-row button:active {
    transform: translateY(0);
}

/* Interactive reveal section */
.reveal-section {
    margin-top: var(--spacing-lg);
    padding-top: var(--spacing-lg);
    border-top: 1px solid rgba(255,255,255,0.06);
}

.reveal-buttons {
    display: flex;
    gap: var(--spacing-md);
    flex-wrap: wrap;
    margin-bottom: var(--spacing-lg);
}

.reveal-btn {
    padding: 10px 16px;
    border-radius: var(--radius-md);
    border: 1px solid rgba(255,255,255,0.15);
    background: rgba(255,255,255,0.05);
    color: var(--text-secondary);
    font-size: var(--font-body-sm);
    font-weight: 500;
    cursor: pointer;
    transition: all 0.2s ease;
    display: inline-flex;
    align-items: center;
    gap: 6px;
}

.reveal-btn:hover {
    background: rgba(255,255,255,0.10);
    color: var(--text-primary);
}

.reveal-btn.active {
    background: linear-gradient(135deg, rgba(96,165,250,0.2), rgba(167,139,250,0.2));
    border-color: rgba(167,139,250,0.4);
    color: var(--text-primary);
}

.revealed-content {
    padding: var(--spacing-lg);
    background: rgba(255,255,255,0.03);
    border: 1px solid rgba(255,255,255,0.08);
    border-radius: var(--radius-lg);
    margin-top: var(--spacing-md);
    animation: fadeIn 0.2s ease;
}

.revealed-label {
    font-size: var(--font-caption-sm);
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    color: var(--text-tertiary);
    margin-bottom: var(--spacing-sm);
}

.revealed-logic {
    font-family: var(--font-mono);
    font-size: var(--font-heading-sm);
    color: var(--color-accent-blue);
    padding: var(--spacing-md);
    background: rgba(96, 165, 250, 0.08);
    border-radius: var(--radius-md);
    margin: var(--spacing-md) 0;
}

/* Socratic hint box */
.socratic-hint-box {
    margin-top: var(--spacing-lg);
    padding: var(--spacing-lg);
    background: linear-gradient(135deg, rgba(167,139,250,0.08), rgba(96,165,250,0.08));
    border: 1px solid rgba(167,139,250,0.2);
    border-radius: var(--radius-lg);
    border-left: 4px solid var(--color-accent-purple);
}

.hint-header {
    display: flex;
    align-items: center;
    gap: var(--spacing-sm);
    margin-bottom: var(--spacing-sm);
    font-size: var(--font-caption-md);
    font-weight: 600;
    color: var(--color-accent-purple);
}

.hint-text {
    color: var(--text-secondary);
    line-height: 1.6;
}

/* Multiple choice options */
.multiple-choice-options {
    display: flex;
    flex-direction: column;
    gap: var(--spacing-sm);
    margin: var(--spacing-lg) 0;
}

.multiple-choice-options .reveal-btn {
    width: 100%;
    text-align: left;
    padding: var(--spacing-md) var(--spacing-lg);
    font-family: var(--font-mono);
}

.multiple-choice-options .reveal-btn.correct {
    background: rgba(74, 222, 128, 0.15);
    border-color: var(--color-success);
}

.multiple-choice-options .reveal-btn.incorrect {
    background: rgba(248, 113, 113, 0.15);
    border-color: var(--color-error);
}

/* Progress indicator */
.exercise-progress {
    display: flex;
    align-items: center;
    gap: var(--spacing-sm);
    font-size: var(--font-caption-md);
    color: var(--text-tertiary);
    margin-bottom: var(--spacing-md);
}

.progress-bar {
    flex: 1;
    height: 4px;
    background: rgba(255,255,255,0.1);
    border-radius: 2px;
    overflow: hidden;
}

.progress-fill {
    height: 100%;
    background: linear-gradient(90deg, var(--color-accent-blue), var(--color-accent-purple));
    border-radius: 2px;
    transition: width 0.3s ease;
}

.practice-score {
    font-weight: 600;
    color: var(--color-success);
}

/* Exercise mode badges */
.exercise-mode-badge {
    display: inline-flex;
    align-items: center;
    gap: 4px;
    padding: 4px 10px;
    border-radius: var(--radius-full);
    font-size: var(--font-caption-sm);
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    margin-right: var(--spacing-md);
}

.exercise-mode-badge.test {
    background: rgba(251, 191, 36, 0.15);
    color: #fbbf24;
}

.exercise-mode-badge.practice {
    background: rgba(74, 222, 128, 0.15);
    color: var(--color-success);
}
"#;

pub fn App() -> Element {
    let license_state = use_context_provider(LicenseState::new);
    let _registry_auth = use_context_provider(RegistryAuthState::new);

    use_effect(move || {
        let mut license_state = license_state.clone();
        spawn(async move {
            if license_state.has_license() && license_state.needs_revalidation() {
                license_state.validate().await;
            }
        });
    });

    rsx! {
        style { "{GLOBAL_STYLE}" }
        Router::<Route> {}
    }
}

```

---

### UI: mod

**File:** `src/ui/mod.rs`

UI module built with Dioxus 0.6.

```rust
pub mod app;
pub mod state;
pub mod components;
pub mod hooks;
pub mod router;
pub mod pages;
pub mod theme;

pub use app::App;
pub use theme::{colors, font_size, font_family, spacing, radius};

```

---

### UI: Router

**File:** `src/ui/router.rs`

Dioxus Router with routes: / (Home), /pricing (Pricing), /studio (Studio), /learn (Learn), /lesson/:era/:module (Lesson), /workspace/:subject (Workspace), /:..route (NotFound 404 handler). Includes NotFound component for graceful 404 handling.

```rust
use dioxus::prelude::*;
use crate::ui::pages::{Landing, Learn, Pricing, Privacy, Profile, Roadmap, Success, Terms, Workspace, Studio, Guide};
use crate::ui::pages::registry::{Registry, PackageDetail};

#[derive(Clone, Routable, Debug, PartialEq)]
pub enum Route {
    #[route("/")]
    Landing {},

    #[route("/pricing")]
    Pricing {},

    #[route("/privacy")]
    Privacy {},

    #[route("/terms")]
    Terms {},

    #[route("/roadmap")]
    Roadmap {},

    #[route("/guide")]
    Guide {},

    #[route("/success")]
    Success {},

    #[route("/studio")]
    Studio {},

    // Integrated Learn page - all learning happens here
    // Replaces: /lesson/:era/:module/:mode and /review
    #[route("/learn")]
    Learn {},

    #[route("/profile")]
    Profile {},

    #[route("/workspace/:subject")]
    Workspace { subject: String },

    // Phase 39: Package Registry
    #[route("/registry")]
    Registry {},

    #[route("/registry/package/:name")]
    PackageDetail { name: String },

    #[route("/:..route")]
    NotFound { route: Vec<String> },
}

#[component]
fn NotFound(route: Vec<String>) -> Element {
    rsx! {
        div {
            style: "min-height: 100vh; display: flex; flex-direction: column; align-items: center; justify-content: center; background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%); color: #e8e8e8;",
            h1 { style: "font-size: 48px; margin-bottom: 16px;", "404" }
            p { style: "color: #888; margin-bottom: 24px;", "Page not found: /{route.join(\"/\")}" }
            Link {
                to: Route::Landing {},
                style: "padding: 12px 24px; background: linear-gradient(135deg, #667eea, #764ba2); border-radius: 8px; color: white; text-decoration: none;",
                "Go Home"
            }
        }
    }
}

```

---

### UI: State

**File:** `src/ui/state.rs`

Application state management with Signal-based reactivity. ChatMessage history and compile integration.

```rust
use dioxus::prelude::*;
use crate::{compile_with_options, CompileOptions, OutputFormat};

const LICENSE_VALIDATOR_URL: &str = "https://api.logicaffeine.com/validate";
const VALIDATION_INTERVAL_MS: f64 = 24.0 * 60.0 * 60.0 * 1000.0; // 24 hours

#[derive(Clone, PartialEq, Debug)]
pub enum LicensePlan {
    None,
    Free,
    Supporter,
    Pro,
    Premium,
    Lifetime,
    Enterprise,
}

impl LicensePlan {
    pub fn from_str(s: &str) -> Self {
        match s.to_lowercase().as_str() {
            "free" => Self::Free,
            "supporter" => Self::Supporter,
            "pro" => Self::Pro,
            "premium" => Self::Premium,
            "lifetime" => Self::Lifetime,
            "enterprise" => Self::Enterprise,
            _ => Self::None,
        }
    }

    pub fn is_commercial(&self) -> bool {
        matches!(self, Self::Pro | Self::Premium | Self::Lifetime | Self::Enterprise)
    }

    pub fn is_paid(&self) -> bool {
        !matches!(self, Self::None | Self::Free)
    }
}

#[derive(Clone, PartialEq)]
pub struct LicenseState {
    pub key: Signal<Option<String>>,
    pub plan: Signal<LicensePlan>,
    pub is_valid: Signal<bool>,
    pub validated_at: Signal<Option<f64>>,
    pub is_validating: Signal<bool>,
}

impl LicenseState {
    pub fn new() -> Self {
        let (key, plan, validated_at) = load_license_from_storage();

        Self {
            key: Signal::new(key),
            plan: Signal::new(plan),
            is_valid: Signal::new(false),
            validated_at: Signal::new(validated_at),
            is_validating: Signal::new(false),
        }
    }

    pub fn has_license(&self) -> bool {
        self.key.read().is_some()
    }

    pub fn is_commercial(&self) -> bool {
        self.plan.read().is_commercial() && *self.is_valid.read()
    }

    pub fn needs_revalidation(&self) -> bool {
        match *self.validated_at.read() {
            Some(timestamp) => {
                let now = js_sys::Date::now();
                now - timestamp > VALIDATION_INTERVAL_MS
            }
            None => true,
        }
    }

    pub fn set_license(&mut self, license_key: String, plan: LicensePlan) {
        self.key.set(Some(license_key.clone()));
        self.plan.set(plan.clone());
        self.is_valid.set(true);
        let now = js_sys::Date::now();
        self.validated_at.set(Some(now));

        save_license_to_storage(&license_key, &plan, now);
    }

    pub fn clear_license(&mut self) {
        self.key.set(None);
        self.plan.set(LicensePlan::None);
        self.is_valid.set(false);
        self.validated_at.set(None);

        clear_license_from_storage();
    }

    pub async fn validate(&mut self) {
        let license_key = match self.key.read().clone() {
            Some(key) => key,
            None => return,
        };

        self.is_validating.set(true);

        match validate_license_async(&license_key).await {
            Ok((is_valid, plan)) => {
                self.is_valid.set(is_valid);
                if is_valid {
                    self.plan.set(plan);
                    let now = js_sys::Date::now();
                    self.validated_at.set(Some(now));
                    save_license_to_storage(&license_key, &self.plan.read(), now);
                }
            }
            Err(_) => {
                self.is_valid.set(false);
            }
        }

        self.is_validating.set(false);
    }
}

async fn validate_license_async(license_key: &str) -> Result<(bool, LicensePlan), String> {
    use gloo_net::http::Request;

    let body = serde_json::json!({ "licenseKey": license_key });

    let response = Request::post(LICENSE_VALIDATOR_URL)
        .header("Content-Type", "application/json")
        .body(body.to_string())
        .map_err(|e| e.to_string())?
        .send()
        .await
        .map_err(|e| e.to_string())?;

    if !response.ok() {
        return Ok((false, LicensePlan::None));
    }

    let data: serde_json::Value = response
        .json()
        .await
        .map_err(|e| e.to_string())?;

    let is_valid = data["valid"].as_bool().unwrap_or(false);
    let plan_str = data["plan"].as_str().unwrap_or("none");
    let plan = LicensePlan::from_str(plan_str);

    Ok((is_valid, plan))
}

fn load_license_from_storage() -> (Option<String>, LicensePlan, Option<f64>) {
    if let Some(window) = web_sys::window() {
        if let Ok(Some(storage)) = window.local_storage() {
            let key = storage.get_item("logos_license_key").ok().flatten();
            let plan_str = storage.get_item("logos_license_plan").ok().flatten().unwrap_or_default();
            let validated_at = storage
                .get_item("logos_license_validated_at")
                .ok()
                .flatten()
                .and_then(|s| s.parse::<f64>().ok());

            let plan = LicensePlan::from_str(&plan_str);
            return (key, plan, validated_at);
        }
    }
    (None, LicensePlan::None, None)
}

fn save_license_to_storage(key: &str, plan: &LicensePlan, validated_at: f64) {
    if let Some(window) = web_sys::window() {
        if let Ok(Some(storage)) = window.local_storage() {
            let _ = storage.set_item("logos_license_key", key);
            let plan_str = format!("{:?}", plan).to_lowercase();
            let _ = storage.set_item("logos_license_plan", &plan_str);
            let _ = storage.set_item("logos_license_validated_at", &validated_at.to_string());
        }
    }
}

fn clear_license_from_storage() {
    if let Some(window) = web_sys::window() {
        if let Ok(Some(storage)) = window.local_storage() {
            let _ = storage.remove_item("logos_license_key");
            let _ = storage.remove_item("logos_license_plan");
            let _ = storage.remove_item("logos_license_validated_at");
        }
    }
}

#[derive(Clone, PartialEq)]
pub struct ChatMessage {
    pub role: Role,
    pub content: String,
}

#[derive(Clone, PartialEq)]
pub enum Role {
    User,
    System,
    Error,
}

#[derive(Clone, Copy)]
pub struct AppState {
    history: Signal<Vec<ChatMessage>>,
}

impl AppState {
    pub fn new() -> Self {
        Self {
            history: Signal::new(vec![ChatMessage {
                role: Role::System,
                content: "The Council is assembled. State your premise.".to_string(),
            }]),
        }
    }

    pub fn add_user_message(&mut self, text: String) {
        self.history.write().push(ChatMessage {
            role: Role::User,
            content: text.clone(),
        });
        self.process_logic(text);
    }

    fn process_logic(&mut self, input: String) {
        let options = CompileOptions { format: OutputFormat::Unicode };

        let response = match compile_with_options(&input, options) {
            Ok(logic) => ChatMessage {
                role: Role::System,
                content: logic,
            },
            Err(e) => {
                let interner = crate::Interner::new();
                let advice = crate::socratic_explanation(&e, &interner);
                ChatMessage {
                    role: Role::Error,
                    content: advice,
                }
            }
        };
        self.history.write().push(response);
    }

    pub fn get_history(&self) -> Vec<ChatMessage> {
        self.history.read().clone()
    }
}

// ============================================================
// Phase 39: GitHub Auth State for Package Registry
// ============================================================

const REGISTRY_API_URL: &str = "https://registry.logicaffeine.com";

#[derive(Clone, PartialEq, Debug, serde::Serialize, serde::Deserialize)]
pub struct GitHubUser {
    pub id: String,
    pub login: String,
    pub name: Option<String>,
    pub avatar_url: Option<String>,
}

#[derive(Clone, PartialEq)]
pub struct RegistryAuthState {
    pub user: Signal<Option<GitHubUser>>,
    pub token: Signal<Option<String>>,
    pub is_loading: Signal<bool>,
}

impl RegistryAuthState {
    pub fn new() -> Self {
        let (token, user) = load_registry_auth_from_storage();
        Self {
            user: Signal::new(user),
            token: Signal::new(token),
            is_loading: Signal::new(false),
        }
    }

    pub fn is_authenticated(&self) -> bool {
        self.token.read().is_some()
    }

    pub fn login(&mut self, token: String, user: GitHubUser) {
        self.token.set(Some(token.clone()));
        self.user.set(Some(user.clone()));
        save_registry_auth_to_storage(&token, &user);
    }

    pub fn logout(&mut self) {
        self.token.set(None);
        self.user.set(None);
        clear_registry_auth_from_storage();
    }

    pub fn get_auth_url() -> String {
        format!("{}/auth/github", REGISTRY_API_URL)
    }
}

fn load_registry_auth_from_storage() -> (Option<String>, Option<GitHubUser>) {
    #[cfg(target_arch = "wasm32")]
    {
        if let Some(window) = web_sys::window() {
            if let Ok(Some(storage)) = window.local_storage() {
                let token = storage.get_item("logos_registry_token").ok().flatten();
                let user_json = storage.get_item("logos_registry_user").ok().flatten();
                let user = user_json.and_then(|j| serde_json::from_str(&j).ok());
                return (token, user);
            }
        }
    }
    (None, None)
}

fn save_registry_auth_to_storage(token: &str, user: &GitHubUser) {
    #[cfg(target_arch = "wasm32")]
    {
        if let Some(window) = web_sys::window() {
            if let Ok(Some(storage)) = window.local_storage() {
                let _ = storage.set_item("logos_registry_token", token);
                if let Ok(json) = serde_json::to_string(user) {
                    let _ = storage.set_item("logos_registry_user", &json);
                }
            }
        }
    }
}

fn clear_registry_auth_from_storage() {
    #[cfg(target_arch = "wasm32")]
    {
        if let Some(window) = web_sys::window() {
            if let Ok(Some(storage)) = window.local_storage() {
                let _ = storage.remove_item("logos_registry_token");
                let _ = storage.remove_item("logos_registry_user");
            }
        }
    }
}

// Package types for registry
#[derive(Clone, PartialEq, Debug, serde::Serialize, serde::Deserialize)]
pub struct RegistryPackage {
    pub name: String,
    pub description: Option<String>,
    pub latest_version: Option<String>,
    pub owner: String,
    pub owner_avatar: Option<String>,
    pub verified: bool,
    pub downloads: u64,
    pub keywords: Vec<String>,
}

#[derive(Clone, PartialEq, Debug, serde::Serialize, serde::Deserialize)]
pub struct PackageVersion {
    pub version: String,
    pub published_at: String,
    pub size: u64,
    pub yanked: bool,
}

#[derive(Clone, PartialEq, Debug, serde::Serialize, serde::Deserialize)]
pub struct PackageDetails {
    pub name: String,
    pub description: Option<String>,
    pub owner: String,
    pub owner_avatar: Option<String>,
    pub repository: Option<String>,
    pub homepage: Option<String>,
    pub license: Option<String>,
    pub keywords: Vec<String>,
    pub verified: bool,
    pub downloads: u64,
    pub readme: Option<String>,
    pub versions: Vec<PackageVersion>,
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_license_plan_from_str() {
        assert_eq!(LicensePlan::from_str("free"), LicensePlan::Free);
        assert_eq!(LicensePlan::from_str("FREE"), LicensePlan::Free);
        assert_eq!(LicensePlan::from_str("Free"), LicensePlan::Free);
        assert_eq!(LicensePlan::from_str("supporter"), LicensePlan::Supporter);
        assert_eq!(LicensePlan::from_str("pro"), LicensePlan::Pro);
        assert_eq!(LicensePlan::from_str("premium"), LicensePlan::Premium);
        assert_eq!(LicensePlan::from_str("lifetime"), LicensePlan::Lifetime);
        assert_eq!(LicensePlan::from_str("enterprise"), LicensePlan::Enterprise);
        assert_eq!(LicensePlan::from_str("unknown"), LicensePlan::None);
        assert_eq!(LicensePlan::from_str(""), LicensePlan::None);
    }

    #[test]
    fn test_license_plan_is_commercial() {
        assert!(!LicensePlan::None.is_commercial());
        assert!(!LicensePlan::Free.is_commercial());
        assert!(!LicensePlan::Supporter.is_commercial());
        assert!(LicensePlan::Pro.is_commercial());
        assert!(LicensePlan::Premium.is_commercial());
        assert!(LicensePlan::Lifetime.is_commercial());
        assert!(LicensePlan::Enterprise.is_commercial());
    }

    #[test]
    fn test_license_plan_is_paid() {
        assert!(!LicensePlan::None.is_paid());
        assert!(!LicensePlan::Free.is_paid());
        assert!(LicensePlan::Supporter.is_paid());
        assert!(LicensePlan::Pro.is_paid());
        assert!(LicensePlan::Premium.is_paid());
        assert!(LicensePlan::Lifetime.is_paid());
        assert!(LicensePlan::Enterprise.is_paid());
    }
}

```

---

### UI: theme

**File:** `src/ui/theme.rs`

UI module built with Dioxus 0.6.

```rust
/// Design tokens for consistent styling across the application.
/// All colors, font sizes, and spacing values should be defined here.

// =============================================================================
// COLORS
// =============================================================================

/// Primary brand colors
pub mod colors {
    // Primary palette
    pub const PRIMARY_BLUE: &str = "#667eea";
    pub const PRIMARY_PURPLE: &str = "#764ba2";
    pub const ACCENT_BLUE: &str = "#60a5fa";
    pub const ACCENT_PURPLE: &str = "#a78bfa";

    // Semantic colors
    pub const SUCCESS: &str = "#4ade80";
    pub const WARNING: &str = "#f59e0b";
    pub const ERROR: &str = "#e06c75";
    pub const INFO: &str = "#60a5fa";

    // Achievement/gamification colors
    pub const XP_GREEN: &str = "#4ade80";
    pub const COMBO_ORANGE: &str = "#f97316";
    pub const COMBO_LIGHT: &str = "#fb923c";
    pub const ACHIEVEMENT_GOLD: &str = "#fbbf24";

    // Syntax highlighting colors
    pub const SYNTAX_QUANTIFIER: &str = "#c678dd";
    pub const SYNTAX_VARIABLE: &str = "#61afef";
    pub const SYNTAX_PREDICATE: &str = "#98c379";
    pub const SYNTAX_CONSTANT: &str = "#e5c07b";
    pub const SYNTAX_DETERMINER: &str = "#56b6c2";
    pub const SYNTAX_CONNECTIVE: &str = "#c678dd";

    // Text colors - UPDATED for better accessibility
    pub const TEXT_PRIMARY: &str = "#f0f0f0";           // Was #e8e8e8, now lighter
    pub const TEXT_SECONDARY: &str = "#b0b0b0";         // Was #888, now lighter
    pub const TEXT_TERTIARY: &str = "#909090";          // Was #666, now lighter
    pub const TEXT_MUTED: &str = "#a0a0a0";             // Was #aaa, kept similar
    pub const TEXT_PLACEHOLDER: &str = "#808080";       // Was darker

    // Text with opacity (for overlays/backgrounds)
    pub const TEXT_HIGH_CONTRAST: &str = "rgba(240,242,245,0.95)";    // Was 0.9
    pub const TEXT_MEDIUM: &str = "rgba(240,242,245,0.80)";           // Was 0.72
    pub const TEXT_LOW: &str = "rgba(240,242,245,0.70)";              // Was 0.65
    pub const TEXT_SUBTLE: &str = "rgba(240,242,245,0.55)";           // Was 0.45
    pub const TEXT_VERY_SUBTLE: &str = "rgba(240,242,245,0.45)";      // Was 0.35

    // Background colors
    pub const BG_DARK: &str = "#060814";
    pub const BG_OVERLAY_DARK: &str = "rgba(0,0,0,0.8)";
    pub const BG_OVERLAY_LIGHT: &str = "rgba(0,0,0,0.25)";
    pub const BG_SUBTLE: &str = "rgba(255,255,255,0.08)";
    pub const BG_VERY_SUBTLE: &str = "rgba(255,255,255,0.04)";
    pub const BG_HOVER: &str = "rgba(255,255,255,0.1)";

    // Border colors
    pub const BORDER_SUBTLE: &str = "rgba(255,255,255,0.1)";
    pub const BORDER_MEDIUM: &str = "rgba(255,255,255,0.2)";
}

// =============================================================================
// TYPOGRAPHY
// =============================================================================

/// Font sizes - UPDATED: all increased by 2px for accessibility
pub mod font_size {
    // Display sizes
    pub const DISPLAY_XL: &str = "66px";    // Was 64px
    pub const DISPLAY_LG: &str = "50px";    // Was 48px
    pub const DISPLAY_MD: &str = "34px";    // Was 32px

    // Heading sizes
    pub const HEADING_LG: &str = "26px";    // Was 24px
    pub const HEADING_MD: &str = "22px";    // Was 20px
    pub const HEADING_SM: &str = "20px";    // Was 18px

    // Body sizes
    pub const BODY_LG: &str = "18px";       // Was 16px
    pub const BODY_MD: &str = "16px";       // Was 14px
    pub const BODY_SM: &str = "15px";       // Was 13px

    // Small/caption sizes
    pub const CAPTION_LG: &str = "14px";    // Was 12px
    pub const CAPTION_MD: &str = "13px";    // Was 11px
    pub const CAPTION_SM: &str = "12px";    // Was 10px
}

/// Font families
pub mod font_family {
    pub const MONO: &str = "'SF Mono', 'Fira Code', 'Consolas', monospace";
    pub const MONO_SYSTEM: &str = "ui-monospace, SFMono-Regular, 'SF Mono', Menlo, Monaco, 'Cascadia Code', monospace";
    pub const SANS: &str = "-apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif";
}

// =============================================================================
// SPACING
// =============================================================================

pub mod spacing {
    pub const XS: &str = "4px";
    pub const SM: &str = "8px";
    pub const MD: &str = "12px";
    pub const LG: &str = "16px";
    pub const XL: &str = "24px";
    pub const XXL: &str = "32px";
}

// =============================================================================
// BORDER RADIUS
// =============================================================================

pub mod radius {
    pub const SM: &str = "4px";
    pub const MD: &str = "8px";
    pub const LG: &str = "12px";
    pub const XL: &str = "16px";
    pub const FULL: &str = "9999px";
}

// =============================================================================
// CSS VARIABLE INJECTION
// =============================================================================

/// Returns a CSS block that defines all theme variables as CSS custom properties.
/// Include this in your root component to make variables available everywhere.
pub fn css_variables() -> &'static str {
    r#"
    :root {
        /* Primary colors */
        --color-primary-blue: #667eea;
        --color-primary-purple: #764ba2;
        --color-accent-blue: #60a5fa;
        --color-accent-purple: #a78bfa;

        /* Semantic colors */
        --color-success: #4ade80;
        --color-warning: #f59e0b;
        --color-error: #e06c75;
        --color-info: #60a5fa;

        /* Text colors - accessible grays */
        --text-primary: #f0f0f0;
        --text-secondary: #b0b0b0;
        --text-tertiary: #909090;
        --text-muted: #a0a0a0;
        --text-placeholder: #808080;

        /* Font sizes - +2px for accessibility */
        --font-display-xl: 66px;
        --font-display-lg: 50px;
        --font-display-md: 34px;
        --font-heading-lg: 26px;
        --font-heading-md: 22px;
        --font-heading-sm: 20px;
        --font-body-lg: 18px;
        --font-body-md: 16px;
        --font-body-sm: 15px;
        --font-caption-lg: 14px;
        --font-caption-md: 13px;
        --font-caption-sm: 12px;

        /* Font families */
        --font-mono: 'SF Mono', 'Fira Code', 'Consolas', monospace;
        --font-sans: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif;

        /* Spacing */
        --spacing-xs: 4px;
        --spacing-sm: 8px;
        --spacing-md: 12px;
        --spacing-lg: 16px;
        --spacing-xl: 24px;
        --spacing-xxl: 32px;

        /* Border radius */
        --radius-sm: 4px;
        --radius-md: 8px;
        --radius-lg: 12px;
        --radius-xl: 16px;
        --radius-full: 9999px;
    }
    "#
}

```

---

### Page: landing

**File:** `src/ui/pages/landing.rs`

Application page component.

```rust
use dioxus::prelude::*;
use crate::ui::router::Route;
use crate::ui::components::main_nav::{MainNav, ActivePage};

const LANDING_STYLE: &str = r#"
body:has(.landing) {
  overflow: hidden;
}

.landing {
  height: 100vh;
  color: var(--text-primary);
  background:
    radial-gradient(1200px 600px at 50% -120px, rgba(167,139,250,0.18), transparent 60%),
    radial-gradient(900px 500px at 15% 30%, rgba(96,165,250,0.18), transparent 60%),
    radial-gradient(800px 450px at 90% 45%, rgba(34,197,94,0.10), transparent 62%),
    linear-gradient(180deg, #070a12, #0b1022 55%, #070a12);
  overflow-x: hidden;
  overflow-y: auto;
  font-family: var(--font-sans);
  position: relative;
}

.bg-orb {
  position: absolute;
  inset: auto;
  width: 520px;
  height: 520px;
  border-radius: var(--radius-full);
  filter: blur(42px);
  opacity: 0.22;
  pointer-events: none;
  animation: float 14s ease-in-out infinite, pulse-glow 10s ease-in-out infinite;
}
.orb1 { top: -220px; left: -160px; background: radial-gradient(circle at 30% 30%, var(--color-accent-blue), transparent 60%); animation-delay: 0s; }
.orb2 { top: 120px; right: -200px; background: radial-gradient(circle at 40% 35%, var(--color-accent-purple), transparent 60%); animation-delay: -5s; }
.orb3 { bottom: -260px; left: 20%; background: radial-gradient(circle at 40% 35%, rgba(34,197,94,0.9), transparent 60%); animation-delay: -10s; }

.container {
  width: 100%;
  max-width: 1120px;
  margin: 0 auto;
  padding: 0 var(--spacing-xl);
}

/* Navigation now handled by MainNav component */

.btn {
  display: inline-flex;
  align-items: center;
  justify-content: center;
  gap: 10px;
  padding: var(--spacing-md) var(--spacing-lg);
  border-radius: var(--radius-lg);
  border: 1px solid rgba(255,255,255,0.10);
  background: rgba(255,255,255,0.05);
  text-decoration: none;
  font-weight: 650;
  font-size: var(--font-body-md);
  transition: transform 0.18s ease, background 0.18s ease, border-color 0.18s ease;
  will-change: transform;
}
.btn:hover { transform: translateY(-1px); background: rgba(255,255,255,0.07); border-color: rgba(255,255,255,0.18); }
.btn:active { transform: translateY(0px); }

.btn-primary {
  background: linear-gradient(135deg, rgba(96,165,250,0.95), rgba(167,139,250,0.95));
  border-color: rgba(255,255,255,0.20);
  color: #060814;
  box-shadow: 0 18px 40px rgba(96,165,250,0.18);
}
.btn-primary:hover {
  background: linear-gradient(135deg, var(--color-accent-blue), var(--color-accent-purple));
}

.btn-ghost {
  background: rgba(255,255,255,0.03);
}

.btn-icon {
  padding: 10px;
  background: rgba(255,255,255,0.03);
}
.btn-icon svg {
  width: 20px;
  height: 20px;
  fill: currentColor;
}

.github-link {
  display: inline-flex;
  align-items: center;
  gap: 6px;
  color: inherit;
  text-decoration: none;
  transition: color 0.2s ease;
}
.github-link:hover {
  color: var(--text-primary);
}

.hero {
  padding: 84px 0 30px;
}

.hero-grid {
  display: grid;
  grid-template-columns: 1.05fr 0.95fr;
  gap: 36px;
  align-items: center;
}

.badge {
  display: inline-flex;
  align-items: center;
  gap: 10px;
  padding: 10px 14px;
  border-radius: var(--radius-full);
  background: rgba(255,255,255,0.06);
  border: 1px solid rgba(255,255,255,0.10);
  backdrop-filter: blur(18px);
  box-shadow: 0 18px 40px rgba(0,0,0,0.25);
  color: var(--text-primary);
  font-size: var(--font-caption-md);
  font-weight: 650;
}
.badge .dot {
  width: 8px;
  height: 8px;
  border-radius: var(--radius-full);
  background: var(--color-success);
  box-shadow: 0 0 0 6px rgba(34,197,94,0.12);
  animation: pulse-glow 2s ease-in-out infinite;
}

.hero .badge { animation: fadeInUp 0.6s ease both; }
.hero .h-title { animation: fadeInUp 0.6s ease 0.08s both; }
.hero .h-sub { animation: fadeInUp 0.6s ease 0.16s both; }
.hero .hero-ctas { animation: fadeInUp 0.6s ease 0.24s both; }
.hero .microcopy { animation: fadeInUp 0.6s ease 0.30s both; }
.hero .kpi { animation: fadeInUp 0.6s ease 0.36s both; }
.hero .demo { animation: fadeInUp 0.8s ease 0.44s both; }

.h-title {
  margin: 18px 0 var(--spacing-md);
  font-size: var(--font-display-xl);
  line-height: 1.04;
  letter-spacing: -2px;
  font-weight: 900;
  background: linear-gradient(180deg, #ffffff 0%, rgba(229,231,235,0.78) 65%, rgba(229,231,235,0.62) 100%);
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
}

.h-sub {
  margin: 0 0 var(--spacing-xl);
  max-width: 580px;
  color: var(--text-secondary);
  font-size: var(--font-body-lg);
  line-height: 1.65;
}

.hero-ctas {
  display: flex;
  gap: var(--spacing-md);
  flex-wrap: wrap;
  margin: 18px 0 14px;
}

.microcopy {
  font-size: var(--font-caption-md);
  color: var(--text-tertiary);
}

.demo {
  border-radius: var(--radius-xl);
  border: 1px solid rgba(255,255,255,0.10);
  background: linear-gradient(180deg, rgba(255,255,255,0.06), rgba(255,255,255,0.03));
  backdrop-filter: blur(18px);
  box-shadow: 0 30px 80px rgba(0,0,0,0.55);
  overflow: hidden;
  position: relative;
}

.demo::before {
  content: "";
  position: absolute;
  inset: -2px;
  background: radial-gradient(600px 280px at 10% 10%, rgba(96,165,250,0.22), transparent 55%),
              radial-gradient(520px 240px at 90% 20%, rgba(167,139,250,0.22), transparent 55%);
  opacity: 0.9;
  pointer-events: none;
}

.demo-head {
  position: relative;
  display: flex;
  align-items: center;
  justify-content: space-between;
  padding: 14px var(--spacing-lg);
  border-bottom: 1px solid rgba(255,255,255,0.06);
  background: rgba(0,0,0,0.10);
}

.win-dots { display: flex; gap: var(--spacing-sm); align-items: center; }
.wdot { width: 11px; height: 11px; border-radius: var(--radius-full); opacity: 0.9; }
.wr { background: #ef4444; } .wy { background: #fbbf24; } .wg { background: #22c55e; }

.demo-label {
  font-size: var(--font-caption-sm);
  color: var(--text-secondary);
  border: 1px solid rgba(255,255,255,0.10);
  padding: 7px 10px;
  border-radius: var(--radius-full);
  background: rgba(255,255,255,0.04);
}

.demo-body {
  position: relative;
  display: grid;
  grid-template-columns: 1fr 1fr;
}

.demo-col {
  padding: 18px 18px 22px;
  min-height: 240px;
}

.demo-col + .demo-col {
  border-left: 1px solid rgba(255,255,255,0.06);
  background: rgba(0,0,0,0.18);
}

.demo-kicker {
  display: flex;
  align-items: center;
  justify-content: space-between;
  margin-bottom: var(--spacing-md);
  font-size: var(--font-caption-sm);
  color: var(--text-secondary);
}

.pill {
  border: 1px solid rgba(255,255,255,0.10);
  background: rgba(255,255,255,0.04);
  padding: 6px 10px;
  border-radius: var(--radius-full);
}

.code {
  font-family: var(--font-mono);
  font-size: var(--font-caption-md);
  line-height: 1.6;
  color: var(--text-primary);
  white-space: pre-wrap;
}

.code.logic { color: var(--color-accent-purple); }

.demo-foot {
  display: flex;
  gap: 10px;
  flex-wrap: wrap;
  padding: 14px var(--spacing-lg);
  border-top: 1px solid rgba(255,255,255,0.06);
  background: rgba(0,0,0,0.12);
  color: var(--text-secondary);
  font-size: var(--font-caption-md);
}

.section {
  padding: 74px 0;
}

.section-title {
  font-size: var(--font-heading-lg);
  letter-spacing: -0.8px;
  margin: 0 0 10px;
}
.section-sub {
  margin: 0 0 var(--spacing-xl);
  color: var(--text-secondary);
  line-height: 1.65;
  max-width: 760px;
}

.grid3 {
  display: grid;
  grid-template-columns: repeat(3, 1fr);
  gap: 18px;
}
.grid2 {
  display: grid;
  grid-template-columns: 1fr 1fr;
  gap: 18px;
}

.card {
  position: relative;
  border-radius: var(--radius-xl);
  border: 1px solid rgba(255,255,255,0.10);
  background: rgba(255,255,255,0.04);
  backdrop-filter: blur(18px);
  padding: 18px;
  transition: transform 0.18s ease, border-color 0.18s ease, background 0.18s ease;
  overflow: hidden;
}
.card::before {
  content: "";
  position: absolute;
  inset: 0;
  border-radius: var(--radius-xl);
  background: linear-gradient(135deg, rgba(96,165,250,0.12), rgba(167,139,250,0.12));
  opacity: 0;
  transition: opacity 0.3s ease;
  pointer-events: none;
}
.card:hover {
  transform: translateY(-3px);
  border-color: rgba(167,139,250,0.28);
  background: rgba(255,255,255,0.06);
}
.card:hover::before {
  opacity: 1;
}

.icon {
  width: 42px; height: 42px;
  border-radius: var(--radius-lg);
  display: grid;
  place-items: center;
  background: rgba(255,255,255,0.06);
  border: 1px solid rgba(255,255,255,0.10);
  margin-bottom: var(--spacing-md);
}

.card h3 {
  margin: 0 0 var(--spacing-sm);
  font-size: var(--font-body-md);
  letter-spacing: -0.2px;
}
.card p {
  margin: 0;
  color: var(--text-secondary);
  line-height: 1.6;
  font-size: var(--font-body-md);
}

.quote {
  font-size: var(--font-body-md);
  line-height: 1.65;
  color: var(--text-primary);
}
.quoter {
  margin-top: 10px;
  color: var(--text-tertiary);
  font-size: var(--font-caption-md);
}

.kpi {
  display: flex;
  gap: 14px;
  flex-wrap: wrap;
  margin-top: 18px;
}
.kpi .pill {
  background: rgba(255,255,255,0.04);
}

.tech-stack {
  display: flex;
  gap: 10px;
  flex-wrap: wrap;
  margin-top: 14px;
}

.tech-badge {
  font-size: var(--font-caption-sm);
  padding: 6px var(--spacing-md);
  border-radius: 6px;
  background: rgba(255,255,255,0.03);
  border: 1px solid rgba(255,255,255,0.08);
  color: var(--text-secondary);
}

.tech-badge.rust {
  background: linear-gradient(135deg, rgba(183,65,14,0.15), rgba(222,165,132,0.10));
  border-color: rgba(222,165,132,0.3);
  color: #dea584;
}

.hello-demo {
  display: flex;
  align-items: center;
  justify-content: center;
  gap: var(--spacing-xl);
  flex-wrap: wrap;
  margin: var(--spacing-xl) 0;
}

.hello-code, .hello-result {
  flex: 1;
  min-width: 280px;
  max-width: 400px;
  border-radius: var(--radius-lg);
  border: 1px solid rgba(255,255,255,0.10);
  background: rgba(0,0,0,0.3);
  overflow: hidden;
}

.code-header {
  padding: 10px 14px;
  font-size: var(--font-caption-sm);
  color: var(--text-secondary);
  background: rgba(255,255,255,0.03);
  border-bottom: 1px solid rgba(255,255,255,0.06);
  font-family: var(--font-mono);
}

.hello-code .code {
  margin: 0;
  padding: var(--spacing-lg);
  font-size: var(--font-body-md);
  line-height: 1.6;
}

.terminal {
  padding: var(--spacing-lg);
  font-family: var(--font-mono);
  font-size: var(--font-body-md);
}

.terminal .prompt {
  color: var(--color-success);
}

.terminal .output {
  color: var(--text-primary);
}

.hello-arrow {
  font-size: 28px;
  color: var(--color-accent-purple);
}

.hello-note {
  text-align: center;
  font-size: var(--font-body-md);
  color: var(--text-secondary);
  margin-top: var(--spacing-sm);
}

.compare-table {
  display: flex;
  flex-direction: column;
  border-radius: var(--radius-lg);
  border: 1px solid rgba(255,255,255,0.10);
  overflow: hidden;
  max-width: 800px;
  margin: 0 auto;
}

.compare-row {
  display: grid;
  grid-template-columns: 1.2fr repeat(4, 1fr);
}

.compare-row.header {
  background: rgba(255,255,255,0.05);
  font-weight: 600;
  font-size: var(--font-caption-md);
}

.compare-row:not(.header) {
  border-top: 1px solid rgba(255,255,255,0.06);
}

.compare-cell {
  padding: var(--spacing-md) 14px;
  font-size: var(--font-caption-md);
  color: var(--text-secondary);
  text-align: center;
}

.compare-cell.label {
  text-align: left;
  color: var(--text-primary);
  font-weight: 500;
}

.compare-cell.highlight {
  background: rgba(167,139,250,0.08);
  color: var(--color-accent-purple);
  font-weight: 500;
}

.compare-row.header .compare-cell.highlight {
  background: rgba(167,139,250,0.15);
}

@media (max-width: 700px) {
  .compare-row {
    grid-template-columns: 1fr 1fr 1fr;
  }
  .compare-cell:nth-child(4),
  .compare-cell:nth-child(5) {
    display: none;
  }
}

.faq-item {
  padding: var(--spacing-lg) var(--spacing-lg) 14px;
  border-radius: var(--radius-xl);
  border: 1px solid rgba(255,255,255,0.10);
  background: rgba(255,255,255,0.03);
}
.faq-q { font-weight: 750; margin-bottom: var(--spacing-sm); }
.faq-a { color: var(--text-secondary); line-height: 1.6; font-size: var(--font-body-md); }

.footer {
  padding: 34px 0 44px;
  border-top: 1px solid rgba(255,255,255,0.06);
  color: var(--text-tertiary);
  font-size: var(--font-caption-md);
}

.footer-row {
  display: flex;
  align-items: center;
  justify-content: space-between;
  gap: var(--spacing-lg);
  flex-wrap: wrap;
}

@media (max-width: 980px) {
  .hero-grid { grid-template-columns: 1fr; }
  .demo-body { grid-template-columns: 1fr; }
  .demo-col + .demo-col { border-left: none; border-top: 1px solid rgba(255,255,255,0.06); }
  .grid3 { grid-template-columns: 1fr; }
  .grid2 { grid-template-columns: 1fr; }
  .h-title { font-size: var(--font-display-lg); }
}

@keyframes fadeInUp {
  from { opacity: 0; transform: translateY(24px); }
  to { opacity: 1; transform: translateY(0); }
}

@keyframes float {
  0%, 100% { transform: translate3d(0, 0, 0); }
  50% { transform: translate3d(0, -20px, 0); }
}

@keyframes pulse-glow {
  0%, 100% { opacity: 0.22; }
  50% { opacity: 0.32; }
}

@keyframes blink {
  50% { opacity: 0; }
}

html { scroll-behavior: smooth; }

.section + .section {
  border-top: 1px solid rgba(255,255,255,0.04);
}

.steps {
  display: flex;
  align-items: center;
  justify-content: center;
  gap: var(--spacing-xl);
  flex-wrap: wrap;
}

.step {
  flex: 1;
  min-width: 200px;
  max-width: 280px;
  text-align: center;
  padding: var(--spacing-xl);
  border-radius: var(--radius-xl);
  background: rgba(255,255,255,0.04);
  border: 1px solid rgba(255,255,255,0.10);
  animation: fadeInUp 0.6s ease both;
}

.step:nth-child(1) { animation-delay: 0s; }
.step:nth-child(3) { animation-delay: 0.1s; }
.step:nth-child(5) { animation-delay: 0.2s; }

.step-num {
  width: 48px;
  height: 48px;
  margin: 0 auto var(--spacing-lg);
  border-radius: 50%;
  background: linear-gradient(135deg, var(--color-accent-blue), var(--color-accent-purple));
  color: #060814;
  font-weight: 800;
  font-size: var(--font-heading-sm);
  display: grid;
  place-items: center;
}

.step h3 {
  margin: 0 0 var(--spacing-sm);
  font-size: var(--font-body-lg);
}

.step p {
  margin: 0;
  color: var(--text-secondary);
  font-size: var(--font-body-md);
  line-height: 1.5;
}

.step-arrow {
  font-size: 24px;
  color: var(--text-tertiary);
}

.grid3 .card:nth-child(1) .icon { background: rgba(96,165,250,0.15); }
.grid3 .card:nth-child(2) .icon { background: rgba(167,139,250,0.15); }
.grid3 .card:nth-child(3) .icon { background: rgba(34,197,94,0.15); }
.grid3 .card:nth-child(4) .icon { background: rgba(251,191,36,0.15); }
.grid3 .card:nth-child(5) .icon { background: rgba(236,72,153,0.15); }
.grid3 .card:nth-child(6) .icon { background: rgba(139,92,246,0.15); }

.demo-col:first-child .code::after {
  content: " ▋";
  animation: blink 1s step-end infinite;
  color: var(--color-accent-blue);
}

@media (max-width: 980px) {
  .hero-grid { grid-template-columns: 1fr; }
  .demo-body { grid-template-columns: 1fr; }
  .demo-col + .demo-col { border-left: none; border-top: 1px solid rgba(255,255,255,0.06); }
  .grid3 { grid-template-columns: 1fr; }
  .grid2 { grid-template-columns: 1fr; }
  .h-title { font-size: var(--font-display-lg); }
  .step-arrow { display: none; }
  .steps { flex-direction: column; }
}

@media (prefers-reduced-motion: reduce) {
  * { transition: none !important; animation: none !important; }
}
"#;

#[component]
pub fn Landing() -> Element {
    rsx! {
        style { "{LANDING_STYLE}" }

        div { class: "landing",
            div { class: "bg-orb orb1" }
            div { class: "bg-orb orb2" }
            div { class: "bg-orb orb3" }

            MainNav { active: ActivePage::Other }

            main { class: "container",
                section { class: "hero",
                    div { class: "hero-grid",
                        div {
                            div { class: "badge",
                                div { class: "dot" }
                                span { "Free for individuals • Commercial licenses available" }
                            }

                            h1 { class: "h-title", "Debug Your Thoughts." }

                            p { class: "h-sub",
                                "Turn everyday English into rigorous First-Order Logic. Verify arguments, surface hidden assumptions, and build rule systems that actually hold up."
                            }

                            div { class: "hero-ctas",
                                Link { to: Route::Learn {}, class: "btn btn-primary", "Start Learning" }
                                Link { to: Route::Studio {}, class: "btn", "Open Studio" }
                                Link { to: Route::Pricing {}, class: "btn btn-ghost", "See Pricing" }
                            }

                            p { class: "microcopy",
                                "Built for people who take thinking seriously: students, researchers, engineers, analysts, and attorneys."
                            }

                            div { class: "kpi",
                                span { class: "pill", "Plain English in" }
                                span { class: "pill", "Formal logic out" }
                                span { class: "pill", "Zero guesswork" }
                            }

                            div { class: "tech-stack",
                                span { class: "tech-badge rust", "Rust-Powered 🦀" }
                                span { class: "tech-badge", "WASM Ready" }
                                span { class: "tech-badge", "Markdown Source" }
                                span { class: "tech-badge", "Proof-Checked" }
                            }
                        }

                        div { class: "demo", id: "product",
                            div { class: "demo-head",
                                div { class: "win-dots",
                                    div { class: "wdot wr" }
                                    div { class: "wdot wy" }
                                    div { class: "wdot wg" }
                                }
                                div { class: "demo-label", "Live Transpilation Preview" }
                            }

                            div { class: "demo-body",
                                div { class: "demo-col",
                                    div { class: "demo-kicker",
                                        span { "Input (English)" }
                                        span { class: "pill", "Plain language" }
                                    }
                                    div { class: "code",
r#"Every user who has a key enters the room.
If a user enters the room, the alarm triggers.
No user who lacks a key can enter the room."# }
                                }

                                div { class: "demo-col",
                                    div { class: "demo-kicker",
                                        span { "Output (First-Order Logic)" }
                                        span { class: "pill", "Machine-checkable" }
                                    }
                                    div { class: "code logic",
r#"1) ∀x((User(x) ∧ ∃y(Key(y) ∧ Has(x,y))) → Enter(x, Room))
2) ∀x((User(x) ∧ Enter(x, Room)) → Trigger(Alarm))
3) ∀x((User(x) ∧ ¬∃y(Key(y) ∧ Has(x,y))) → ¬Enter(x, Room))"# }
                                }
                            }

                            div { class: "demo-foot",
                                span { "Your logic, formalized in milliseconds." }
                            }
                        }
                    }
                }

                section { class: "section how-it-works",
                    h2 { class: "section-title", "How it works" }
                    p { class: "section-sub",
                        "Three steps from thought to proof."
                    }

                    div { class: "steps",
                        div { class: "step",
                            div { class: "step-num", "1" }
                            h3 { "Write in English" }
                            p { "Type your argument, rule, or statement in plain language." }
                        }
                        div { class: "step-arrow", "→" }
                        div { class: "step",
                            div { class: "step-num", "2" }
                            h3 { "Get formal logic" }
                            p { "Instantly see the First-Order Logic representation." }
                        }
                        div { class: "step-arrow", "→" }
                        div { class: "step",
                            div { class: "step-num", "3" }
                            h3 { "Validate & refine" }
                            p { "The tutor surfaces ambiguities. You fix them." }
                        }
                    }
                }

                section { class: "section hello-world",
                    h2 { class: "section-title", "Hello World in LOGOS" }
                    p { class: "section-sub",
                        "Markdown files compile directly to native binaries. No ceremony, no boilerplate."
                    }

                    div { class: "hello-demo",
                        div { class: "hello-code",
                            div { class: "code-header", "hello.md" }
                            pre { class: "code",
r#"# Hello World

To run:
    Show "Hello, World!" to the console."# }
                        }
                        div { class: "hello-arrow", "→" }
                        div { class: "hello-result",
                            div { class: "code-header", "Output" }
                            div { class: "terminal",
                                span { class: "prompt", "$ " }
                                span { "logos run hello.md" }
                                br {}
                                span { class: "output", "Hello, World!" }
                            }
                        }
                    }
                    p { class: "hello-note", "Compiles to a native binary via Rust. Zero runtime overhead." }
                }

                section { class: "section",
                    h2 { class: "section-title", "What you get" }
                    p { class: "section-sub",
                        "LOGICAFFEINE translates intuition into structure — so you can test it, teach it, or ship it."
                    }

                    div { class: "grid3",
                        div { class: "card",
                            div { class: "icon", "⚡" }
                            h3 { "Instant Transpilation" }
                            p { "Type normal English. Get precise logic in seconds — readable enough to learn from, strict enough to verify." }
                        }
                        div { class: "card",
                            div { class: "icon", "🧠" }
                            h3 { "Socratic Tutor" }
                            p { "When your statement is ambiguous, the tutor asks questions that force clarity instead of guessing." }
                        }
                        div { class: "card",
                            div { class: "icon", "🧾" }
                            h3 { "Assumption Surfacing" }
                            p { "Reveal missing premises, hidden quantifiers, and scope mistakes — the usual sources of bad arguments." }
                        }
                        div { class: "card",
                            div { class: "icon", "🧪" }
                            h3 { "Consistency & Validity Checks" }
                            p { "Spot contradictions, invalid inferences, and rule collisions early — before they hit production or policy." }
                        }
                        div { class: "card",
                            div { class: "icon", "🧰" }
                            h3 { "Studio + Curriculum" }
                            p { "Explore freely in Studio, then build mastery in Learn with structured lessons and practice." }
                        }
                        div { class: "card",
                            div { class: "icon", "🔒" }
                            h3 { "Commercial-Ready" }
                            p { "Licensing options for teams and enterprises — with a path toward governance and controlled deployments." }
                        }
                    }
                }

                section { class: "section", id: "for",
                    h2 { class: "section-title", "Who uses LOGICAFFEINE" }
                    p { class: "section-sub",
                        "For people who want their reasoning to survive contact with reality."
                    }

                    div { class: "grid3",
                        div { class: "card",
                            div { class: "icon", "🎓" }
                            h3 { "Students & Educators" }
                            p { "Teach formal reasoning with feedback that's immediate, concrete, and harder to game than multiple choice." }
                        }
                        div { class: "card",
                            div { class: "icon", "⚖️" }
                            h3 { "Law, Policy, Compliance" }
                            p { "Translate policy language into verifiable rules. Reduce ambiguity. Make reviews faster and safer." }
                        }
                        div { class: "card",
                            div { class: "icon", "🛠️" }
                            h3 { "Engineering & Research" }
                            p { "Specify systems, constraints, and invariants in a form you can test — without forcing everyone into formal syntax." }
                        }
                    }
                }

                section { class: "section compare-section",
                    h2 { class: "section-title", "How LOGOS Compares" }
                    p { class: "section-sub",
                        "A new approach to formal reasoning."
                    }

                    div { class: "compare-table",
                        div { class: "compare-row header",
                            div { class: "compare-cell", "Feature" }
                            div { class: "compare-cell highlight", "LOGOS" }
                            div { class: "compare-cell", "Lean 4" }
                            div { class: "compare-cell", "Rust" }
                            div { class: "compare-cell", "Python" }
                        }
                        div { class: "compare-row",
                            div { class: "compare-cell label", "Syntax" }
                            div { class: "compare-cell highlight", "English prose" }
                            div { class: "compare-cell", "Lean DSL" }
                            div { class: "compare-cell", "Symbols" }
                            div { class: "compare-cell", "Symbols" }
                        }
                        div { class: "compare-row",
                            div { class: "compare-cell label", "File Format" }
                            div { class: "compare-cell highlight", "Markdown (.md)" }
                            div { class: "compare-cell", ".lean" }
                            div { class: "compare-cell", ".rs" }
                            div { class: "compare-cell", ".py" }
                        }
                        div { class: "compare-row",
                            div { class: "compare-cell label", "Performance" }
                            div { class: "compare-cell highlight", "Native (via Rust)" }
                            div { class: "compare-cell", "Native" }
                            div { class: "compare-cell", "Native" }
                            div { class: "compare-cell", "Interpreted" }
                        }
                        div { class: "compare-row",
                            div { class: "compare-cell label", "Proofs" }
                            div { class: "compare-cell highlight", "Built-in" }
                            div { class: "compare-cell", "Required" }
                            div { class: "compare-cell", "Optional" }
                            div { class: "compare-cell", "None" }
                        }
                        div { class: "compare-row",
                            div { class: "compare-cell label", "Memory" }
                            div { class: "compare-cell highlight", "Ownership (English)" }
                            div { class: "compare-cell", "GC" }
                            div { class: "compare-cell", "Ownership" }
                            div { class: "compare-cell", "GC" }
                        }
                    }
                }

                section { class: "section", id: "faq",
                    h2 { class: "section-title", "FAQ" }
                    p { class: "section-sub",
                        "Common questions about LOGICAFFEINE."
                    }

                    div { class: "grid2",
                        div { class: "faq-item",
                            div { class: "faq-q", "Is it really free?" }
                            div { class: "faq-a", "Yes — free for individuals. Teams and commercial use should use the licensing options on the Pricing page." }
                        }
                        div { class: "faq-item",
                            div { class: "faq-q", "Do I need to know logic already?" }
                            div { class: "faq-a", "No. Start in Learn. The system introduces concepts progressively and uses examples to teach scope, quantifiers, and structure." }
                        }
                        div { class: "faq-item",
                            div { class: "faq-q", "Is this an AI that \"guesses\"?" }
                            div { class: "faq-a", "The goal is the opposite: to force explicit structure. When language is ambiguous, the tutor prompts clarifying questions." }
                        }
                        div { class: "faq-item",
                            div { class: "faq-q", "Where do I begin?" }
                            div { class: "faq-a", "If you want speed, open Studio. If you want mastery, Start Learning and follow the lessons." }
                        }
                        div { class: "faq-item",
                            div { class: "faq-q", "What is LOGOS written in?" }
                            div { class: "faq-a", "Rust. The entire transpiler, parser, and runtime are written in Rust for maximum performance and safety." }
                        }
                        div { class: "faq-item",
                            div { class: "faq-q", "How fast is it?" }
                            div { class: "faq-a", "Native speed. LOGOS compiles to Rust, which then compiles via LLVM to optimized machine code. Zero interpreter overhead." }
                        }
                    }
                }

                section {
                    class: "section",
                    style: "padding-bottom: 100px;",
                    div {
                        class: "card",
                        style: "padding: 32px; overflow: visible;",
                        h2 { class: "section-title", "Make your reasoning impossible to ignore." }
                        p {
                            class: "section-sub",
                            style: "margin-bottom: 20px;",
                            "Start with the Curriculum, or jump into the Studio. Either way, the product is built to sharpen your mind."
                        }
                        div { class: "hero-ctas",
                            Link { to: Route::Learn {}, class: "btn btn-primary", "Start Learning" }
                            Link { to: Route::Pricing {}, class: "btn btn-ghost", "View Licenses" }
                        }
                    }
                }

                footer { class: "footer",
                    div { class: "footer-row",
                        div { "© 2025 Brahmastra Labs LLC  •  Written in Rust 🦀" }
                        div {
                            a {
                                href: "https://github.com/Brahmastra-Labs/logicaffeine",
                                target: "_blank",
                                class: "github-link",
                                svg {
                                    xmlns: "http://www.w3.org/2000/svg",
                                    width: "16",
                                    height: "16",
                                    view_box: "0 0 24 24",
                                    fill: "currentColor",
                                    path {
                                        d: "M12 0C5.37 0 0 5.37 0 12c0 5.31 3.435 9.795 8.205 11.385.6.105.825-.255.825-.57 0-.285-.015-1.23-.015-2.235-3.015.555-3.795-.735-4.035-1.41-.135-.345-.72-1.41-1.23-1.695-.42-.225-1.02-.78-.015-.795.945-.015 1.62.87 1.845 1.23 1.08 1.815 2.805 1.305 3.495.99.105-.78.42-1.305.765-1.605-2.67-.3-5.46-1.335-5.46-5.925 0-1.305.465-2.385 1.23-3.225-.12-.3-.54-1.53.12-3.18 0 0 1.005-.315 3.3 1.23.96-.27 1.98-.405 3-.405s2.04.135 3 .405c2.295-1.56 3.3-1.23 3.3-1.23.66 1.65.24 2.88.12 3.18.765.84 1.23 1.905 1.23 3.225 0 4.605-2.805 5.625-5.475 5.925.435.375.81 1.095.81 2.22 0 1.605-.015 2.895-.015 3.3 0 .315.225.69.825.57A12.02 12.02 0 0024 12c0-6.63-5.37-12-12-12z"
                                    }
                                }
                                "GitHub"
                            }
                            span { "  •  " }
                            Link { to: Route::Privacy {}, "Privacy Policy" }
                            span { "  •  " }
                            Link { to: Route::Terms {}, "Terms of Use" }
                            span { "  •  " }
                            Link { to: Route::Pricing {}, "Pricing" }
                            span { "  •  " }
                            Link { to: Route::Learn {}, "Learn" }
                        }
                    }
                }
            }
        }
    }
}

```

---

### Page: Learn

**File:** `src/ui/pages/learn.rs`

Curriculum browser with expandable era/module hierarchy. Displays Trivium, Quadrivium, and Metaphysics eras with nested modules.

```rust
use dioxus::prelude::*;
use crate::ui::components::main_nav::{MainNav, ActivePage};
use crate::ui::components::learn_sidebar::{LearnSidebar, ModuleInfo};
use crate::ui::components::symbol_dictionary::SymbolDictionary;
use crate::ui::components::vocab_reference::VocabReference;
use crate::ui::components::guide_code_block::GuideCodeBlock;
use crate::ui::pages::guide::content::ExampleMode;
use crate::content::ContentEngine;
use crate::generator::{Generator, AnswerType, Challenge};
use crate::grader::check_answer;
use crate::struggle::StruggleDetector;
use crate::unlock::check_module_unlocked;
use crate::progress::UserProgress;
use rand::SeedableRng;
use rand::rngs::StdRng;
use std::collections::HashSet;

const LEARN_STYLE: &str = r#"
.learn-page {
    min-height: 100vh;
    color: var(--text-primary);
    background:
        radial-gradient(1200px 600px at 50% -120px, rgba(167,139,250,0.14), transparent 60%),
        radial-gradient(900px 500px at 15% 30%, rgba(96,165,250,0.14), transparent 60%),
        radial-gradient(800px 450px at 90% 45%, rgba(34,197,94,0.08), transparent 62%),
        linear-gradient(180deg, #070a12, #0b1022 55%, #070a12);
    font-family: var(--font-sans);
}

/* Hero */
.learn-hero {
    max-width: 1280px;
    margin: 0 auto;
    padding: 60px var(--spacing-xl) 40px;
}

.learn-hero h1 {
    font-size: var(--font-display-lg);
    font-weight: 900;
    letter-spacing: -1.5px;
    line-height: 1.1;
    background: linear-gradient(180deg, #ffffff 0%, rgba(229,231,235,0.78) 65%, rgba(229,231,235,0.62) 100%);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    margin: 0 0 var(--spacing-lg);
}

.learn-hero p {
    font-size: var(--font-body-lg);
    color: var(--text-secondary);
    max-width: 600px;
    line-height: 1.6;
    margin: 0;
}

.learn-hero-badge {
    display: inline-flex;
    align-items: center;
    gap: var(--spacing-sm);
    padding: var(--spacing-sm) 14px;
    border-radius: var(--radius-full);
    background: rgba(255,255,255,0.06);
    border: 1px solid rgba(255,255,255,0.10);
    font-size: var(--font-caption-md);
    font-weight: 600;
    color: var(--text-primary);
    margin-bottom: var(--spacing-xl);
}

.learn-hero-badge .dot {
    width: 8px;
    height: 8px;
    border-radius: 50%;
    background: var(--color-success);
    box-shadow: 0 0 0 4px rgba(34,197,94,0.15);
}

/* Layout */
.learn-layout {
    max-width: 1280px;
    margin: 0 auto;
    display: flex;
    gap: 48px;
    padding: 0 var(--spacing-xl) 80px;
}

/* Main content */
.learn-content {
    flex: 1;
    min-width: 0;
    max-width: 800px;
}

/* Era sections */
.learn-era {
    margin-bottom: 64px;
    scroll-margin-top: 100px;
}

.learn-era-divider {
    margin: 80px 0 48px;
    padding: var(--spacing-xl) 0;
    border-top: 1px solid rgba(255,255,255,0.08);
}

.learn-era-divider h2 {
    font-size: var(--font-body-md);
    font-weight: 700;
    text-transform: uppercase;
    letter-spacing: 1.5px;
    color: var(--text-tertiary);
    margin: 0;
}

.learn-era-header {
    margin-bottom: var(--spacing-xl);
    padding-bottom: var(--spacing-lg);
    border-bottom: 1px solid rgba(255,255,255,0.08);
}

.learn-era-header h2 {
    font-size: var(--font-display-md);
    font-weight: 800;
    letter-spacing: -0.8px;
    line-height: 1.2;
    background: linear-gradient(180deg, #ffffff 0%, rgba(229,231,235,0.85) 100%);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    margin: 0 0 var(--spacing-sm);
}

.learn-era-header p {
    color: var(--text-secondary);
    font-size: var(--font-body-sm);
    line-height: 1.6;
    margin: 0;
}

/* Module cards */
.learn-modules {
    display: flex;
    flex-direction: column;
    gap: var(--spacing-xl);
}

.learn-module-card {
    background: rgba(255,255,255,0.04);
    border: 1px solid rgba(255,255,255,0.08);
    border-radius: var(--radius-xl);
    padding: var(--spacing-xl);
    transition: all 0.2s ease;
    scroll-margin-top: 100px;
}

.learn-module-card:hover {
    background: rgba(255,255,255,0.06);
    border-color: rgba(255,255,255,0.12);
}

.learn-module-card.locked {
    opacity: 0.6;
    cursor: not-allowed;
    position: relative;
}

.learn-module-card.locked:hover {
    background: rgba(255,255,255,0.04);
    border-color: rgba(255,255,255,0.08);
}

.learn-module-card.locked::after {
    content: '';
    position: absolute;
    inset: 0;
    background: rgba(0, 0, 0, 0.2);
    border-radius: var(--radius-xl);
    pointer-events: none;
}

.locked-badge {
    display: inline-flex;
    align-items: center;
    gap: 6px;
    padding: 4px 12px;
    background: rgba(251, 146, 60, 0.15);
    border: 1px solid rgba(251, 146, 60, 0.3);
    border-radius: var(--radius-full);
    font-size: var(--font-caption-md);
    font-weight: 600;
    color: #fb923c;
}

.locked-badge-icon {
    font-size: 12px;
}

.learn-module-header {
    display: flex;
    justify-content: space-between;
    align-items: flex-start;
    gap: var(--spacing-lg);
    margin-bottom: var(--spacing-lg);
}

.learn-module-info {
    flex: 1;
}

.learn-module-title {
    font-size: var(--font-heading-sm);
    font-weight: 700;
    color: var(--text-primary);
    margin: 0 0 6px;
    display: flex;
    align-items: center;
    gap: 10px;
}

.learn-module-number {
    font-size: var(--font-body-md);
    font-weight: 700;
    color: var(--color-accent-purple);
    opacity: 0.8;
}

.learn-module-desc {
    color: var(--text-secondary);
    font-size: var(--font-body-md);
    line-height: 1.5;
    margin: 0;
}

.learn-module-meta {
    display: flex;
    flex-direction: column;
    align-items: flex-end;
    gap: var(--spacing-sm);
}

.learn-exercise-count {
    font-size: var(--font-caption-md);
    color: var(--text-secondary);
    background: rgba(255,255,255,0.05);
    padding: var(--spacing-xs) 10px;
    border-radius: var(--radius-full);
}

.learn-difficulty {
    display: flex;
    gap: 3px;
}

.learn-difficulty-dot {
    width: 8px;
    height: 8px;
    border-radius: 50%;
    background: rgba(255,255,255,0.15);
}

.learn-difficulty-dot.filled {
    background: linear-gradient(135deg, var(--color-accent-blue), var(--color-accent-purple));
}

/* Preview section */
.learn-module-preview {
    margin-top: var(--spacing-lg);
    padding-top: var(--spacing-lg);
    border-top: 1px solid rgba(255,255,255,0.06);
}

.learn-preview-label {
    font-size: var(--font-caption-sm);
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    color: var(--text-tertiary);
    margin-bottom: var(--spacing-md);
}

/* Action buttons */
.learn-module-actions {
    display: flex;
    gap: 10px;
    margin-top: var(--spacing-xl);
}

.learn-action-btn {
    padding: 10px 18px;
    border-radius: var(--radius-md);
    font-size: var(--font-body-md);
    font-weight: 600;
    cursor: pointer;
    transition: all 0.18s ease;
    text-decoration: none;
    display: inline-flex;
    align-items: center;
    gap: 6px;
    border: 1px solid transparent;
}

.learn-action-btn.primary {
    background: linear-gradient(135deg, rgba(96,165,250,0.9), rgba(167,139,250,0.9));
    color: #060814;
    border-color: rgba(255,255,255,0.1);
}

.learn-action-btn.primary:hover {
    background: linear-gradient(135deg, var(--color-accent-blue), var(--color-accent-purple));
}

.learn-action-btn.secondary {
    background: rgba(255,255,255,0.06);
    color: var(--text-secondary);
    border-color: rgba(255,255,255,0.12);
}

.learn-action-btn.secondary:hover {
    background: rgba(255,255,255,0.10);
    color: var(--text-primary);
}

/* Expanded module state */
.learn-module-card.expanded {
    background: rgba(255,255,255,0.08);
    border-color: rgba(167,139,250,0.3);
    box-shadow: 0 0 40px rgba(167,139,250,0.08);
}

.learn-module-expanded-content {
    margin-top: var(--spacing-xl);
    padding-top: var(--spacing-xl);
    border-top: 1px solid rgba(255,255,255,0.08);
}

/* Mode selector inline card header */
.mode-selector-header {
    display: flex;
    align-items: center;
    justify-content: space-between;
    margin-bottom: var(--spacing-xl);
    padding: var(--spacing-lg);
    background: rgba(255,255,255,0.03);
    border: 1px solid rgba(255,255,255,0.08);
    border-radius: var(--radius-lg);
}

.mode-selector-tabs {
    display: flex;
    gap: var(--spacing-sm);
}

.mode-tab-btn {
    padding: 8px 16px;
    border-radius: var(--radius-md);
    font-size: var(--font-body-sm);
    font-weight: 600;
    cursor: pointer;
    transition: all 0.18s ease;
    border: 1px solid transparent;
    background: rgba(255,255,255,0.05);
    color: var(--text-secondary);
}

.mode-tab-btn:hover {
    background: rgba(255,255,255,0.08);
    color: var(--text-primary);
}

.mode-tab-btn.active {
    background: linear-gradient(135deg, rgba(96,165,250,0.2), rgba(167,139,250,0.2));
    border-color: rgba(96,165,250,0.3);
    color: var(--color-accent-blue);
}

.mode-tab-btn.test {
    background: rgba(251, 191, 36, 0.15);
    border-color: rgba(251, 191, 36, 0.3);
    color: #fbbf24;
}

.mode-stats {
    display: flex;
    gap: var(--spacing-lg);
}

.mode-stat {
    display: flex;
    align-items: center;
    gap: var(--spacing-xs);
    font-size: var(--font-body-sm);
}

.mode-stat-value {
    font-weight: 700;
    color: var(--color-accent-blue);
}

.mode-stat-value.streak {
    color: #fbbf24;
}

.mode-stat-label {
    color: var(--text-tertiary);
}

.combo-multiplier {
    font-weight: 700;
    color: #4ade80;
    margin-left: 2px;
}

.mode-stat.combo {
    background: rgba(251, 191, 36, 0.1);
    padding: 4px 10px;
    border-radius: var(--radius-md);
    border: 1px solid rgba(251, 191, 36, 0.2);
}

/* Content tab selector */
.content-tabs {
    display: flex;
    gap: var(--spacing-sm);
    margin-bottom: var(--spacing-xl);
    border-bottom: 1px solid rgba(255,255,255,0.08);
    padding-bottom: var(--spacing-md);
}

.content-tab-btn {
    padding: 8px 16px;
    border-radius: var(--radius-md) var(--radius-md) 0 0;
    font-size: var(--font-body-sm);
    font-weight: 600;
    cursor: pointer;
    transition: all 0.18s ease;
    border: none;
    background: transparent;
    color: var(--text-tertiary);
    border-bottom: 2px solid transparent;
    margin-bottom: -1px;
}

.content-tab-btn:hover {
    color: var(--text-primary);
}

.content-tab-btn.active {
    color: var(--color-accent-blue);
    border-bottom-color: var(--color-accent-blue);
}

/* Practice tab - green accent */
.content-tab-btn.practice {
    color: var(--color-success);
}

.content-tab-btn.practice:hover {
    color: var(--color-success);
    background: rgba(74, 222, 128, 0.08);
}

.content-tab-btn.practice.active {
    color: var(--color-success);
    border-bottom-color: var(--color-success);
    background: rgba(74, 222, 128, 0.1);
}

/* Test tab - orange/yellow accent */
.content-tab-btn.test {
    color: #fbbf24;
}

.content-tab-btn.test:hover {
    color: #fbbf24;
    background: rgba(251, 191, 36, 0.08);
}

.content-tab-btn.test.active {
    color: #fbbf24;
    border-bottom-color: #fbbf24;
    background: rgba(251, 191, 36, 0.1);
}

/* Lesson section styling */
.lesson-section {
    margin-bottom: var(--spacing-xxl);
    padding-bottom: var(--spacing-xl);
    border-bottom: 1px solid rgba(255,255,255,0.06);
}

.lesson-section:last-child {
    border-bottom: none;
}

.lesson-section-title {
    font-size: 1.25rem;
    font-weight: 700;
    color: var(--text-primary);
    margin-bottom: var(--spacing-lg);
    display: flex;
    align-items: center;
    gap: var(--spacing-sm);
}

.lesson-section-number {
    font-size: 1rem;
    color: var(--color-accent-blue);
    font-weight: 600;
}

.lesson-paragraph {
    font-size: 1rem;
    color: rgba(255, 255, 255, 0.85);
    line-height: 1.75;
    margin-bottom: var(--spacing-lg);
}

.lesson-definition {
    background: rgba(167, 139, 250, 0.08);
    border: 1px solid rgba(167, 139, 250, 0.2);
    border-radius: var(--radius-md);
    padding: var(--spacing-lg);
    margin-bottom: var(--spacing-lg);
}

.lesson-definition-term {
    font-size: 1rem;
    font-weight: 700;
    color: var(--color-accent-purple);
    margin-bottom: var(--spacing-xs);
}

.lesson-definition-text {
    font-size: 1rem;
    color: rgba(255, 255, 255, 0.8);
    line-height: 1.65;
}

.lesson-example {
    background: rgba(96, 165, 250, 0.08);
    border: 1px solid rgba(96, 165, 250, 0.2);
    border-radius: var(--radius-md);
    padding: var(--spacing-lg);
    margin-bottom: var(--spacing-lg);
}

.lesson-example-title {
    font-size: 1rem;
    font-weight: 600;
    color: var(--color-accent-blue);
    margin-bottom: var(--spacing-md);
}

.lesson-example-premise {
    font-size: 1rem;
    color: rgba(255, 255, 255, 0.8);
    padding-left: var(--spacing-lg);
    margin-bottom: var(--spacing-xs);
    line-height: 1.6;
}

.lesson-example-conclusion {
    font-size: 1rem;
    color: var(--text-primary);
    font-weight: 500;
    margin-top: var(--spacing-md);
    padding-left: var(--spacing-lg);
}

.lesson-example-note {
    margin-top: var(--spacing-md);
    padding-top: var(--spacing-md);
    border-top: 1px solid rgba(255,255,255,0.08);
    color: rgba(255, 255, 255, 0.5);
    font-size: 0.9rem;
    font-style: italic;
    line-height: 1.5;
}

/* Symbol glossary block */
.lesson-symbols {
    background: rgba(96, 165, 250, 0.08);
    border: 1px solid rgba(96, 165, 250, 0.2);
    border-radius: var(--radius-lg);
    padding: var(--spacing-lg);
    margin: var(--spacing-lg) 0;
}

.lesson-symbols-title {
    font-weight: 700;
    color: #60a5fa;
    margin-bottom: var(--spacing-md);
    font-size: 0.9rem;
    text-transform: uppercase;
    letter-spacing: 0.5px;
}

.lesson-symbols-grid {
    display: grid;
    grid-template-columns: repeat(auto-fill, minmax(200px, 1fr));
    gap: var(--spacing-md);
}

.lesson-symbol-item {
    display: flex;
    flex-direction: column;
    gap: var(--spacing-sm);
    padding: var(--spacing-md);
    background: rgba(255,255,255,0.03);
    border-radius: var(--radius-md);
    text-align: center;
}

.lesson-symbol-glyph {
    font-size: 2rem;
    font-family: var(--font-mono);
    color: #60a5fa;
    text-align: center;
}

.lesson-symbol-name {
    font-weight: 600;
    color: var(--text-primary);
    font-size: 0.9rem;
}

.lesson-symbol-meaning {
    color: rgba(255, 255, 255, 0.6);
    font-size: 0.85rem;
}

.lesson-symbol-example {
    color: rgba(255, 255, 255, 0.5);
    font-size: 0.8rem;
    font-style: italic;
    margin-top: 4px;
}

/* Quiz block */
.lesson-quiz {
    background: rgba(167, 139, 250, 0.08);
    border: 1px solid rgba(167, 139, 250, 0.2);
    border-radius: var(--radius-lg);
    padding: var(--spacing-lg);
    margin: var(--spacing-lg) 0;
}

.lesson-quiz-question {
    font-weight: 600;
    color: var(--text-primary);
    margin-bottom: var(--spacing-md);
    font-size: 1rem;
}

.lesson-quiz-options {
    display: flex;
    flex-direction: column;
    gap: var(--spacing-sm);
}

.lesson-quiz-option {
    text-align: left;
    padding: var(--spacing-md);
    background: rgba(255,255,255,0.04);
    border: 1px solid rgba(255,255,255,0.1);
    border-radius: var(--radius-md);
    color: var(--text-secondary);
    cursor: pointer;
    transition: all 0.15s ease;
}

.lesson-quiz-option:hover:not(:disabled) {
    background: rgba(255,255,255,0.08);
    border-color: rgba(255,255,255,0.2);
    color: var(--text-primary);
}

.lesson-quiz-option:disabled {
    cursor: default;
}

.lesson-quiz-option.correct {
    background: rgba(74, 222, 128, 0.15);
    border-color: var(--color-success);
    color: var(--color-success);
}

.lesson-quiz-option.incorrect {
    background: rgba(248, 113, 113, 0.15);
    border-color: var(--color-error);
    color: var(--color-error);
}

.lesson-quiz-option.answered {
    opacity: 0.5;
}

.lesson-quiz-explanation {
    margin-top: var(--spacing-md);
    padding-top: var(--spacing-md);
    border-top: 1px solid rgba(255,255,255,0.08);
    color: rgba(255, 255, 255, 0.7);
    font-size: 0.9rem;
    display: none;
}

.lesson-quiz-explanation.visible {
    display: block;
}

.learn-module-close {
    position: absolute;
    top: var(--spacing-lg);
    right: var(--spacing-lg);
    width: 32px;
    height: 32px;
    border-radius: 50%;
    background: rgba(255,255,255,0.08);
    border: 1px solid rgba(255,255,255,0.12);
    color: var(--text-secondary);
    font-size: 18px;
    cursor: pointer;
    display: flex;
    align-items: center;
    justify-content: center;
    transition: all 0.15s ease;
}

.learn-module-close:hover {
    background: rgba(255,255,255,0.15);
    color: var(--text-primary);
}

/* Tab content panels */
.tab-panel {
    padding: var(--spacing-xl) 0;
}

.tab-panel-lesson {
    color: var(--text-primary);
    line-height: 1.7;
}

.tab-panel-lesson h3 {
    font-size: var(--font-heading-sm);
    font-weight: 700;
    margin: var(--spacing-xl) 0 var(--spacing-md);
    color: var(--text-primary);
}

.tab-panel-lesson p {
    margin-bottom: var(--spacing-lg);
    color: var(--text-secondary);
}

/* Examples panel */
.tab-panel-examples {
    padding: var(--spacing-lg) 0;
}

.examples-intro {
    margin-bottom: var(--spacing-xl);
}

.examples-intro h3 {
    font-size: 1.25rem;
    font-weight: 700;
    color: var(--text-primary);
    margin-bottom: var(--spacing-sm);
}

.examples-intro p {
    font-size: 1rem;
    color: rgba(255, 255, 255, 0.7);
    line-height: 1.6;
}

.examples-list {
    display: flex;
    flex-direction: column;
    gap: var(--spacing-xl);
}

.example-card {
    background: rgba(255, 255, 255, 0.03);
    border: 1px solid rgba(255, 255, 255, 0.08);
    border-radius: var(--radius-lg);
    padding: var(--spacing-lg);
}

.example-card .example-sentence {
    font-size: 1rem;
    font-weight: 500;
    color: var(--text-primary);
    margin-bottom: var(--spacing-md);
    padding-bottom: var(--spacing-md);
    border-bottom: 1px solid rgba(255, 255, 255, 0.06);
}

.exercise-card {
    background: rgba(255,255,255,0.04);
    border: 1px solid rgba(255,255,255,0.08);
    border-radius: var(--radius-lg);
    padding: var(--spacing-xl);
    margin-bottom: var(--spacing-lg);
}

.exercise-sentence {
    font-size: 1.15rem;
    font-weight: 500;
    color: var(--text-primary);
    margin-bottom: var(--spacing-lg);
    line-height: 1.5;
}

.exercise-input-row {
    display: flex;
    gap: var(--spacing-md);
}

.exercise-input {
    flex: 1;
    padding: var(--spacing-md) var(--spacing-lg);
    font-size: var(--font-body-md);
    font-family: var(--font-mono);
    background: rgba(255,255,255,0.06);
    border: 2px solid rgba(255,255,255,0.12);
    border-radius: var(--radius-md);
    color: var(--text-primary);
    outline: none;
    transition: border-color 0.2s ease;
}

.exercise-input:focus {
    border-color: var(--color-accent-blue);
}

.exercise-input.correct {
    border-color: var(--color-success);
    background: rgba(74, 222, 128, 0.1);
}

.exercise-input.incorrect {
    border-color: var(--color-error);
    background: rgba(248, 113, 113, 0.1);
}

.exercise-submit-btn {
    padding: var(--spacing-md) var(--spacing-xl);
    background: linear-gradient(135deg, var(--color-accent-blue), var(--color-accent-purple));
    border: none;
    border-radius: var(--radius-md);
    color: #060814;
    font-weight: 600;
    cursor: pointer;
    transition: opacity 0.15s ease;
}

.exercise-submit-btn:hover {
    opacity: 0.9;
}

.exercise-feedback {
    margin-top: var(--spacing-lg);
    padding: var(--spacing-md);
    border-radius: var(--radius-md);
}

.exercise-feedback.correct {
    background: rgba(74, 222, 128, 0.15);
    border: 1px solid rgba(74, 222, 128, 0.3);
    color: var(--color-success);
}

.exercise-feedback.incorrect {
    background: rgba(248, 113, 113, 0.15);
    border: 1px solid rgba(248, 113, 113, 0.3);
    color: var(--color-error);
}

.logic-output {
    font-family: var(--font-mono);
    font-size: var(--font-body-lg);
    padding: var(--spacing-lg);
    background: rgba(96, 165, 250, 0.1);
    border: 1px solid rgba(96, 165, 250, 0.2);
    border-radius: var(--radius-md);
    color: var(--color-accent-blue);
    margin: var(--spacing-lg) 0;
}

/* Responsive */
@media (max-width: 1024px) {
    .learn-layout {
        flex-direction: column;
    }

    .learn-hero h1 {
        font-size: var(--font-display-md);
    }

    .learn-hero {
        padding: 40px var(--spacing-xl) var(--spacing-xxl);
    }
}

@media (max-width: 640px) {
    .learn-hero h1 {
        font-size: var(--font-heading-lg);
    }

    .learn-hero p {
        font-size: var(--font-body-md);
    }

    .learn-era-header h2 {
        font-size: var(--font-heading-lg);
    }

    .learn-module-header {
        flex-direction: column;
    }

    .learn-module-meta {
        flex-direction: row;
        align-items: center;
    }

    .learn-module-actions {
        flex-direction: column;
    }

    .learn-action-btn {
        justify-content: center;
    }
}
"#;

/// Module data with preview example
struct ModuleData {
    id: &'static str,
    title: &'static str,
    description: &'static str,
    exercise_count: u32,
    difficulty: u8,
    preview_code: Option<&'static str>,
}

/// Era data structure
struct EraData {
    id: &'static str,
    title: &'static str,
    description: &'static str,
    modules: Vec<ModuleData>,
}

fn get_curriculum_data() -> Vec<EraData> {
    vec![
        // Era 1: First Steps
        EraData {
            id: "first-steps",
            title: "First Steps",
            description: "Get comfortable with logic. Learn what arguments are, how to spot good reasoning, and the classical foundations.",
            modules: vec![
                ModuleData {
                    id: "introduction",
                    title: "Introduction",
                    description: "Learn foundational concepts: what logic is, valid vs. invalid arguments, and sound reasoning.",
                    exercise_count: 5,
                    difficulty: 1,
                    preview_code: Some("All humans are mortal. Socrates is human. Therefore..."),
                },
                ModuleData {
                    id: "syllogistic",
                    title: "Syllogistic Logic",
                    description: "Translate English into syllogistic notation. Master the classical form of logical reasoning.",
                    exercise_count: 98,
                    difficulty: 1,
                    preview_code: Some("All humans are mortal."),
                },
                ModuleData {
                    id: "definitions",
                    title: "Meaning and Definitions",
                    description: "Understand uses of language, types of definitions, and the analytic/synthetic distinction.",
                    exercise_count: 48,
                    difficulty: 2,
                    preview_code: None,
                },
                ModuleData {
                    id: "fallacies",
                    title: "Fallacies and Argumentation",
                    description: "Identify good arguments vs. fallacious reasoning. Master informal fallacies.",
                    exercise_count: 16,
                    difficulty: 2,
                    preview_code: None,
                },
                ModuleData {
                    id: "inductive",
                    title: "Inductive Reasoning",
                    description: "Master probability, analogical reasoning, Mill's methods, and inference to best explanation.",
                    exercise_count: 12,
                    difficulty: 2,
                    preview_code: Some("90% of observed swans are white..."),
                },
            ],
        },
        // Era 2: Building Blocks
        EraData {
            id: "building-blocks",
            title: "Building Blocks",
            description: "Master the core of formal logic. Propositional connectives, truth tables, and proof construction.",
            modules: vec![
                ModuleData {
                    id: "propositional",
                    title: "Basic Propositional Logic",
                    description: "Master AND, OR, NOT, and IF-THEN connectives. Truth tables, S-rules, and I-rules.",
                    exercise_count: 114,
                    difficulty: 2,
                    preview_code: Some("If John runs, then Mary walks."),
                },
                ModuleData {
                    id: "proofs",
                    title: "Propositional Proofs",
                    description: "Construct formal proofs and refutations. Learn natural deduction and truth trees.",
                    exercise_count: 14,
                    difficulty: 3,
                    preview_code: Some("1. P → Q  2. P  ∴ Q"),
                },
            ],
        },
        // Era 3: Expanding Horizons
        EraData {
            id: "expanding-horizons",
            title: "Expanding Horizons",
            description: "Explore richer logical systems. Quantifiers, modality, obligations, and beliefs.",
            modules: vec![
                ModuleData {
                    id: "quantificational",
                    title: "Basic Quantificational Logic",
                    description: "Master universal and existential quantifiers. Translations, proofs, and refutations.",
                    exercise_count: 12,
                    difficulty: 3,
                    preview_code: Some("All birds fly."),
                },
                ModuleData {
                    id: "relations",
                    title: "Relations and Identity",
                    description: "Extend predicate logic with identity and relations. Handle definite descriptions.",
                    exercise_count: 8,
                    difficulty: 3,
                    preview_code: Some("John loves Mary."),
                },
                ModuleData {
                    id: "modal",
                    title: "Basic Modal Logic",
                    description: "Explore possibility and necessity operators. Express what could be or must be true.",
                    exercise_count: 36,
                    difficulty: 3,
                    preview_code: Some("It is possible that John runs."),
                },
                ModuleData {
                    id: "further_modal",
                    title: "Further Modal Systems",
                    description: "Advanced modal systems including quantified modal logic and temporal operators.",
                    exercise_count: 2,
                    difficulty: 4,
                    preview_code: Some("John will run tomorrow."),
                },
                ModuleData {
                    id: "deontic",
                    title: "Deontic and Imperative Logic",
                    description: "Reason about obligation, permission, and prohibition. The logic of ethics and law.",
                    exercise_count: 38,
                    difficulty: 3,
                    preview_code: Some("John ought to leave."),
                },
                ModuleData {
                    id: "belief",
                    title: "Belief Logic",
                    description: "Express beliefs, knowledge, willing, and rationality. Model propositional attitudes.",
                    exercise_count: 15,
                    difficulty: 3,
                    preview_code: Some("John believes that Mary runs."),
                },
            ],
        },
        // Era 4: Mastery
        EraData {
            id: "mastery",
            title: "Mastery",
            description: "Deep understanding. The philosophy, history, and frontiers of logical thought.",
            modules: vec![
                ModuleData {
                    id: "ethics",
                    title: "A Formalized Ethical Theory",
                    description: "Apply logic to ethics: practical reason, consistency, and the golden rule formalized.",
                    exercise_count: 8,
                    difficulty: 4,
                    preview_code: None,
                },
                ModuleData {
                    id: "metalogic",
                    title: "Metalogic",
                    description: "Study logic about logic: soundness, completeness, and Gödel's incompleteness theorem.",
                    exercise_count: 6,
                    difficulty: 4,
                    preview_code: None,
                },
                ModuleData {
                    id: "history",
                    title: "History of Logic",
                    description: "Trace logic from Aristotle through Frege, Russell, and modern developments.",
                    exercise_count: 8,
                    difficulty: 2,
                    preview_code: None,
                },
                ModuleData {
                    id: "deviant",
                    title: "Deviant Logics",
                    description: "Explore non-classical logics: many-valued, paraconsistent, intuitionist, and relevance logic.",
                    exercise_count: 8,
                    difficulty: 4,
                    preview_code: None,
                },
                ModuleData {
                    id: "philosophy",
                    title: "Philosophy of Logic",
                    description: "Examine philosophical foundations: abstract entities, truth, paradoxes, and logic's scope.",
                    exercise_count: 8,
                    difficulty: 4,
                    preview_code: None,
                },
            ],
        },
    ]
}

/// Expanded module key: (era_id, module_id)
type ExpandedModuleKey = Option<(String, String)>;

#[component]
pub fn Learn() -> Element {
    let mut active_module = use_signal(|| None::<String>);
    // Expanded module state: which module is currently expanded inline
    let mut expanded_module = use_signal::<ExpandedModuleKey>(|| None);

    let eras = get_curriculum_data();

    // For module unlock checking
    let content_engine = ContentEngine::new();
    let user_progress = UserProgress::new(); // TODO: Load from storage

    // Build module info for sidebar
    let sidebar_modules: Vec<ModuleInfo> = eras.iter().flat_map(|era| {
        era.modules.iter().map(|m| ModuleInfo {
            era_id: era.id.to_string(),
            era_title: era.title.to_string(),
            module_id: m.id.to_string(),
            module_title: m.title.to_string(),
            exercise_count: m.exercise_count,
            difficulty: m.difficulty,
        })
    }).collect();

    // Collect all module IDs for intersection observer (used in wasm32 target)
    #[allow(unused_variables)]
    let module_ids: Vec<String> = eras.iter()
        .flat_map(|era| era.modules.iter().map(|m| m.id.to_string()))
        .collect();

    // Set up scroll tracking with IntersectionObserver
    #[cfg(target_arch = "wasm32")]
    {
        use wasm_bindgen::prelude::*;
        use wasm_bindgen::JsCast;

        let module_ids_for_effect = module_ids.clone();

        use_effect(move || {
            let window = match web_sys::window() {
                Some(w) => w,
                None => return,
            };
            let document = match window.document() {
                Some(d) => d,
                None => return,
            };

            // Create a closure that will be called when elements intersect
            // Use RefCell to allow mutation from within Fn closure
            use std::cell::RefCell;
            use std::rc::Rc;

            let active_module_clone = Rc::new(RefCell::new(active_module.clone()));
            let active_module_for_closure = active_module_clone.clone();

            let callback = Closure::<dyn Fn(js_sys::Array, web_sys::IntersectionObserver)>::new(
                move |entries: js_sys::Array, _observer: web_sys::IntersectionObserver| {
                    // Simple approach: when a module crosses the threshold line (enters from below),
                    // it becomes active. The threshold is set so modules activate when their top
                    // reaches ~100px from the top of the viewport.
                    for i in 0..entries.length() {
                        if let Ok(entry) = entries.get(i).dyn_into::<web_sys::IntersectionObserverEntry>() {
                            // Only activate when element is entering (crossing the threshold)
                            if entry.is_intersecting() {
                                let target = entry.target();
                                let id = target.id();
                                if !id.is_empty() {
                                    active_module_for_closure.borrow_mut().set(Some(id));
                                }
                            }
                        }
                    }
                },
            );

            // Create IntersectionObserver options
            let mut options = web_sys::IntersectionObserverInit::new();
            // Root margin: top offset of -100px means the "viewport" starts 100px below the actual top
            // Bottom margin of -90% means only the top 10% of viewport triggers intersection
            // This creates a thin "tripwire" near the top of the screen
            options.root_margin("-100px 0px -90% 0px");
            // Single threshold at 0 - fires once when element crosses the line
            let thresholds = js_sys::Array::new();
            thresholds.push(&JsValue::from(0.0));
            options.threshold(&thresholds);

            // Create the observer
            let observer = match web_sys::IntersectionObserver::new_with_options(
                callback.as_ref().unchecked_ref(),
                &options,
            ) {
                Ok(obs) => obs,
                Err(_) => return,
            };

            // Observe all module cards
            for module_id in &module_ids_for_effect {
                if let Some(element) = document.get_element_by_id(module_id) {
                    observer.observe(&element);
                }
            }

            // Keep callback alive
            callback.forget();
        });
    }

    // Track first era for divider logic
    let mut is_first_era = true;

    rsx! {
        style { "{LEARN_STYLE}" }

        div { class: "learn-page",
            MainNav { active: ActivePage::Learn }

            // Hero
            header { class: "learn-hero",
                div { class: "learn-hero-badge",
                    div { class: "dot" }
                    span { "Interactive Curriculum" }
                }
                h1 { "Learn Logic" }
                p {
                    "Master first-order logic through progressive challenges. Start with the basics and work your way up to advanced reasoning."
                }
            }

            // Main layout
            div { class: "learn-layout",
                // Sidebar
                LearnSidebar {
                    modules: sidebar_modules,
                    active_module: active_module.read().clone(),
                    on_module_click: move |(_era_id, module_id): (String, String)| {
                        active_module.set(Some(module_id));
                    },
                }

                // Content
                main { class: "learn-content",
                    for era in eras.iter() {
                        {
                            // Show divider for all eras except the first
                            let show_divider = !is_first_era;
                            is_first_era = false;

                            rsx! {
                                // Era divider
                                if show_divider {
                                    div { class: "learn-era-divider",
                                        h2 { "{era.title}" }
                                    }
                                }

                                // Era section
                                section {
                                    class: "learn-era",
                                    div { class: "learn-era-header",
                                        h2 { "{era.title}" }
                                        p { "{era.description}" }
                                    }

                                    div { class: "learn-modules",
                                        for (idx, module) in era.modules.iter().enumerate() {
                                            {
                                                let era_id = era.id.to_string();
                                                let module_id = module.id.to_string();
                                                let module_number = idx + 1;

                                                // Check if this module is locked
                                                let is_unlocked = check_module_unlocked(&user_progress, &content_engine, &era_id, &module_id);

                                                // Check if this module is expanded
                                                let is_expanded = expanded_module.read().as_ref()
                                                    .map(|(e, m)| e == era.id && m == module.id)
                                                    .unwrap_or(false);

                                                let card_class = match (is_expanded, is_unlocked) {
                                                    (true, _) => "learn-module-card expanded",
                                                    (false, true) => "learn-module-card",
                                                    (false, false) => "learn-module-card locked",
                                                };

                                                rsx! {
                                                    div {
                                                        class: "{card_class}",
                                                        id: "{module.id}",
                                                        style: if is_expanded { "position: relative;" } else { "" },

                                                        // Close button when expanded
                                                        if is_expanded {
                                                            {
                                                                let module_id_for_scroll = module_id.clone();
                                                                rsx! {
                                                                    button {
                                                                        class: "learn-module-close",
                                                                        onclick: move |_| {
                                                                            expanded_module.set(None);
                                                                            // Scroll to the module card after collapse
                                                                            #[cfg(target_arch = "wasm32")]
                                                                            {
                                                                                let id = module_id_for_scroll.clone();
                                                                                wasm_bindgen_futures::spawn_local(async move {
                                                                                    // Delay to let the DOM update after collapse
                                                                                    gloo_timers::future::TimeoutFuture::new(150).await;
                                                                                    if let Some(window) = web_sys::window() {
                                                                                        if let Some(document) = window.document() {
                                                                                            if let Some(element) = document.get_element_by_id(&id) {
                                                                                                // Get element position and scroll with offset for nav
                                                                                                let rect = element.get_bounding_client_rect();
                                                                                                let scroll_y = window.scroll_y().unwrap_or(0.0);
                                                                                                let target_y = scroll_y + rect.top() - 100.0; // 100px offset for nav
                                                                                                let _ = window.scroll_to_with_scroll_to_options(
                                                                                                    web_sys::ScrollToOptions::new()
                                                                                                        .top(target_y)
                                                                                                        .behavior(web_sys::ScrollBehavior::Smooth)
                                                                                                );
                                                                                            }
                                                                                        }
                                                                                    }
                                                                                });
                                                                            }
                                                                        },
                                                                        "×"
                                                                    }
                                                                }
                                                            }
                                                        }

                                                        div { class: "learn-module-header",
                                                            div { class: "learn-module-info",
                                                                h3 { class: "learn-module-title",
                                                                    span { class: "learn-module-number", "{module_number}." }
                                                                    "{module.title}"
                                                                }
                                                                p { class: "learn-module-desc", "{module.description}" }
                                                            }

                                                            div { class: "learn-module-meta",
                                                                span { class: "learn-exercise-count", "{module.exercise_count} exercises" }
                                                                div { class: "learn-difficulty",
                                                                    for i in 1..=5u8 {
                                                                        div {
                                                                            class: if i <= module.difficulty { "learn-difficulty-dot filled" } else { "learn-difficulty-dot" }
                                                                        }
                                                                    }
                                                                }
                                                            }
                                                        }

                                                        // Show preview only when collapsed
                                                        if !is_expanded {
                                                            if is_unlocked {
                                                                if let Some(preview) = module.preview_code {
                                                                    div { class: "learn-module-preview",
                                                                        div { class: "learn-preview-label", "Try an Example" }
                                                                        GuideCodeBlock {
                                                                            id: format!("preview-{}", module.id),
                                                                            label: "Example".to_string(),
                                                                            mode: ExampleMode::Logic,
                                                                            initial_code: preview.to_string(),
                                                                        }
                                                                    }
                                                                }

                                                                // Action buttons (only when collapsed and unlocked)
                                                                div { class: "learn-module-actions",
                                                                    button {
                                                                        class: "learn-action-btn primary",
                                                                        onclick: {
                                                                            let era = era_id.clone();
                                                                            let module = module_id.clone();
                                                                            move |_| {
                                                                                expanded_module.set(Some((era.clone(), module.clone())));
                                                                            }
                                                                        },
                                                                        "Start Learning"
                                                                    }
                                                                }
                                                            } else {
                                                                // Locked module - show lock badge
                                                                div { class: "learn-module-actions",
                                                                    div { class: "locked-badge",
                                                                        span { class: "locked-badge-icon", "\u{1F512}" }
                                                                        "Complete previous module to unlock"
                                                                    }
                                                                }
                                                            }
                                                        }

                                                        // Expanded content - Interactive exercises
                                                        if is_expanded {
                                                            div { class: "learn-module-expanded-content",
                                                                InteractiveExercisePanel {
                                                                    era_id: era_id.clone(),
                                                                    module_id: module_id.clone(),
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                }
            }

            // Floating vocab reference panel
            VocabReference {}
        }
    }
}

/// What is currently revealed in the exercise - each section can be shown independently
#[derive(Debug, Clone, Copy, PartialEq, Default)]
struct RevealState {
    hint: bool,
    answer: bool,
    symbol_dictionary: bool,
}

impl RevealState {
    fn reset(&mut self) {
        self.hint = false;
        self.answer = false;
        self.symbol_dictionary = false;
    }
}

/// Practice mode state
#[derive(Debug, Clone, Copy, PartialEq, Default)]
enum PracticeMode {
    #[default]
    Practice,
    Test,
}

/// Content view tab state - corresponds to the 4 tabs
#[derive(Debug, Clone, Copy, PartialEq, Default)]
enum ContentView {
    #[default]
    Lesson,
    Examples,
    Practice,
    Test,
}

/// Interactive exercise panel with reveal buttons instead of tabs
#[component]
fn InteractiveExercisePanel(era_id: String, module_id: String) -> Element {
    use crate::content::{ContentBlock, Section};

    let engine = ContentEngine::new();
    let generator = Generator::new();

    // Content view state (Lesson vs Practice)
    let mut content_view = use_signal(ContentView::default);

    // Exercise state
    let mut current_exercise_idx = use_signal(|| 0usize);
    let mut user_answer = use_signal(|| String::new());
    let mut reveal_state = use_signal(RevealState::default);
    let mut feedback = use_signal(|| None::<(bool, String)>);
    let mut score = use_signal(|| 0u32);
    let mut streak = use_signal(|| 0u32);
    let mut correct_count = use_signal(|| 0u32);
    let mut practice_mode = use_signal(PracticeMode::default);
    // Track wrong attempts per exercise - each wrong costs 5 XP, max 10 XP available per exercise
    // After 2 wrong attempts, no XP can be earned from that exercise
    let mut exercise_attempts = use_signal(|| std::collections::HashMap::<usize, u32>::new());
    // Track which exercises have been completed (earned XP) - prevents double XP
    let mut completed_exercises = use_signal(|| std::collections::HashSet::<usize>::new());
    // Track which exercises have had their answer revealed (forfeits XP)
    let mut answer_revealed_exercises = use_signal(|| std::collections::HashSet::<usize>::new());

    // Priority queue for wrong answers - re-queue at position +3
    // When wrong, insert exercise index to be shown again after 3 more exercises
    let mut retry_queue = use_signal(|| std::collections::VecDeque::<usize>::new());
    // Count exercises since last retry to trigger queue pop after 3
    let mut exercises_since_retry = use_signal(|| 0usize);

    // Test mode state
    let mut test_question = use_signal(|| 0usize);
    let mut test_answers = use_signal(|| Vec::<bool>::new());
    let mut test_complete = use_signal(|| false);

    // Struggle detection state
    let mut struggle_detector = use_signal(StruggleDetector::default);
    let mut show_socratic_hint = use_signal(|| false);

    // Lesson quiz state - tracks which quizzes have been answered and their result
    // Key: quiz question string, Value: (selected_index, is_correct)
    let mut quiz_answers = use_signal(|| std::collections::HashMap::<String, (usize, bool)>::new());

    // Stable seed per exercise - only set once when component mounts or exercise changes
    // Use a signal to store the base seed so it doesn't change on re-renders
    let base_seed = use_signal(|| {
        #[cfg(target_arch = "wasm32")]
        { js_sys::Date::now() as u64 }
        #[cfg(not(target_arch = "wasm32"))]
        { 42u64 }
    });

    // Generate challenge from exercise using stable seed
    let module_opt = engine.get_module(&era_id, &module_id);
    let current_challenge: Option<Challenge> = module_opt.as_ref().and_then(|module| {
        let idx = *current_exercise_idx.read();
        let seed = *base_seed.read();
        module.exercises.get(idx).and_then(|ex| {
            // Use exercise index as part of seed to get different sentences per exercise
            // but stable within the same exercise
            let mut rng = StdRng::seed_from_u64(seed.wrapping_add((idx * 1000) as u64));
            generator.generate(ex, &mut rng)
        })
    });

    let total_exercises = module_opt.as_ref().map(|m| m.exercises.len()).unwrap_or(0);
    let current_idx = *current_exercise_idx.read();
    let progress_pct = if total_exercises > 0 {
        ((current_idx + 1) * 100) / total_exercises
    } else {
        0
    };

    // Get the golden answer for validation
    let golden_answer = current_challenge.as_ref().and_then(|ch| {
        match &ch.answer {
            AnswerType::FreeForm { golden_logic } => Some(golden_logic.clone()),
            AnswerType::MultipleChoice { options, correct_index } => {
                options.get(*correct_index).cloned()
            }
            AnswerType::Ambiguity { readings } => readings.first().cloned(),
        }
    });

    // Get hint from exercise
    let hint_text = current_challenge.as_ref().and_then(|ch| ch.hint.clone());

    // Test mode constants
    let test_total = 10usize;
    let is_test_mode = *practice_mode.read() == PracticeMode::Test;
    let current_test_q = *test_question.read();

    // Get sections for lesson content
    let sections: Vec<Section> = module_opt.as_ref()
        .map(|m| m.sections.clone())
        .unwrap_or_default();
    let has_sections = !sections.is_empty();
    let current_view = *content_view.read();

    rsx! {
        div { class: "interactive-exercise-panel",
            // Content tabs (Lesson | Examples | Practice | Test)
            div { class: "content-tabs",
                button {
                    class: if current_view == ContentView::Lesson { "content-tab-btn active" } else { "content-tab-btn" },
                    onclick: move |_| content_view.set(ContentView::Lesson),
                    "Lesson"
                }
                button {
                    class: if current_view == ContentView::Examples { "content-tab-btn active" } else { "content-tab-btn" },
                    onclick: move |_| content_view.set(ContentView::Examples),
                    "Examples"
                }
                button {
                    class: if current_view == ContentView::Practice { "content-tab-btn practice active" } else { "content-tab-btn practice" },
                    onclick: move |_| {
                        content_view.set(ContentView::Practice);
                        practice_mode.set(PracticeMode::Practice);
                    },
                    "Practice"
                }
                button {
                    class: if current_view == ContentView::Test { "content-tab-btn test active" } else { "content-tab-btn test" },
                    onclick: move |_| {
                        content_view.set(ContentView::Test);
                        practice_mode.set(PracticeMode::Test);
                        test_question.set(0);
                        test_answers.set(Vec::new());
                        test_complete.set(false);
                        user_answer.set(String::new());
                        feedback.set(None);
                    },
                    "Test"
                }
            }

            // Lesson content view
            if current_view == ContentView::Lesson {
                div { class: "tab-panel-lesson",
                    if has_sections {
                        for section in sections.iter() {
                            div { class: "lesson-section",
                                h3 { class: "lesson-section-title",
                                    span { class: "lesson-section-number", "{section.id}" }
                                    "{section.title}"
                                }

                                // Render content blocks
                                for block in section.content.iter() {
                                    match block {
                                        ContentBlock::Paragraph { text } => rsx! {
                                            p { class: "lesson-paragraph",
                                                dangerous_inner_html: text.replace("**", "<strong>").replace("**", "</strong>").replace("*", "<em>").replace("*", "</em>")
                                            }
                                        },
                                        ContentBlock::Definition { term, definition } => rsx! {
                                            div { class: "lesson-definition",
                                                div { class: "lesson-definition-term", "{term}" }
                                                div { class: "lesson-definition-text", "{definition}" }
                                            }
                                        },
                                        ContentBlock::Example { title, premises, conclusion, note } => rsx! {
                                            div { class: "lesson-example",
                                                div { class: "lesson-example-title", "{title}" }
                                                for premise in premises.iter() {
                                                    div { class: "lesson-example-premise", "• {premise}" }
                                                }
                                                if let Some(concl) = conclusion {
                                                    div { class: "lesson-example-conclusion", "{concl}" }
                                                }
                                                if let Some(n) = note {
                                                    div { class: "lesson-example-note", "{n}" }
                                                }
                                            }
                                        },
                                        ContentBlock::Symbols { title, symbols } => rsx! {
                                            div { class: "lesson-symbols",
                                                div { class: "lesson-symbols-title", "{title}" }
                                                div { class: "lesson-symbols-grid",
                                                    for sym in symbols.iter() {
                                                        div { class: "lesson-symbol-item",
                                                            span { class: "lesson-symbol-glyph", "{sym.symbol}" }
                                                            div { class: "lesson-symbol-info",
                                                                div { class: "lesson-symbol-name", "{sym.name}" }
                                                                div { class: "lesson-symbol-meaning", "{sym.meaning}" }
                                                                if let Some(example) = &sym.example {
                                                                    div { class: "lesson-symbol-example", "Example: {example}" }
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        },
                                        ContentBlock::Quiz { question, options, correct, explanation } => {
                                            let q_key = question.clone();
                                            let answered = quiz_answers.read().get(&q_key).cloned();
                                            let correct_idx = *correct;
                                            rsx! {
                                                div { class: "lesson-quiz",
                                                    div { class: "lesson-quiz-question", "{question}" }
                                                    div { class: "lesson-quiz-options",
                                                        for (i, opt) in options.iter().enumerate() {
                                                            {
                                                                let q_key_click = q_key.clone();
                                                                let opt_class = match &answered {
                                                                    Some((selected, _)) if *selected == i && i == correct_idx => "lesson-quiz-option correct",
                                                                    Some((selected, _)) if *selected == i => "lesson-quiz-option incorrect",
                                                                    Some(_) if i == correct_idx => "lesson-quiz-option correct",
                                                                    Some(_) => "lesson-quiz-option answered",
                                                                    None => "lesson-quiz-option",
                                                                };
                                                                rsx! {
                                                                    button {
                                                                        class: "{opt_class}",
                                                                        disabled: answered.is_some(),
                                                                        onclick: move |_| {
                                                                            let is_correct = i == correct_idx;
                                                                            quiz_answers.write().insert(q_key_click.clone(), (i, is_correct));
                                                                        },
                                                                        "{opt}"
                                                                    }
                                                                }
                                                            }
                                                        }
                                                    }
                                                    if answered.is_some() {
                                                        if let Some(expl) = explanation {
                                                            div { class: "lesson-quiz-explanation visible", "{expl}" }
                                                        }
                                                    }
                                                }
                                            }
                                        },
                                    }
                                }

                            }
                        }

                        // Start practicing button
                        div { class: "learn-module-actions", style: "justify-content: center; margin-top: var(--spacing-xl);",
                            button {
                                class: "learn-action-btn primary",
                                onclick: move |_| content_view.set(ContentView::Examples),
                                "Try Examples →"
                            }
                        }
                    } else {
                        p { style: "color: var(--text-tertiary); text-align: center; padding: var(--spacing-xl);",
                            "Lesson content coming soon. Click Examples to see interactive demos."
                        }
                    }
                }
            } else if current_view == ContentView::Examples {
                // Examples view - Interactive code execution
                div { class: "tab-panel-examples",
                    div { class: "examples-intro",
                        h3 { "Interactive Examples" }
                        p { "Try translating sentences and see how logic notation works. The symbol dictionary will explain each symbol used." }
                    }

                    // Example sentences to try
                    div { class: "examples-list",
                        {
                            let examples: Vec<(&str, &str)> = vec![
                                ("ex1", "All cats are mammals."),
                                ("ex2", "Socrates is mortal."),
                                ("ex3", "If it rains, the ground is wet."),
                                ("ex4", "Some birds can fly."),
                                ("ex5", "No reptiles are mammals."),
                            ];

                            rsx! {
                                for (id, sentence) in examples {
                                    div { class: "example-card",
                                        key: "{id}",
                                        div { class: "example-sentence", "{sentence}" }
                                        GuideCodeBlock {
                                            id: id.to_string(),
                                            label: "Try it".to_string(),
                                            mode: ExampleMode::Logic,
                                            initial_code: sentence.to_string(),
                                        }
                                    }
                                }
                            }
                        }
                    }

                    // Navigation to Practice
                    div { class: "learn-module-actions", style: "justify-content: center; margin-top: var(--spacing-xl);",
                        button {
                            class: "learn-action-btn primary",
                            onclick: move |_| {
                                content_view.set(ContentView::Practice);
                                practice_mode.set(PracticeMode::Practice);
                            },
                            "Start Practice →"
                        }
                    }
                }
            } else {
                // Practice/Test view
                // Stats header
                div { class: "mode-stats",
                    div { class: "mode-stat",
                        span { class: "mode-stat-value", "{score}" }
                        span { class: "mode-stat-label", " XP" }
                    }
                    if *streak.read() > 0 {
                        {
                            let s = *streak.read();
                            let mult = match s {
                                0 => "1x",
                                1 => "1.25x",
                                2 => "1.5x",
                                3 => "1.75x",
                                _ => "2x",
                            };
                            rsx! {
                                div { class: "mode-stat combo",
                                    span { class: "mode-stat-value streak", "{s}" }
                                    span { class: "mode-stat-label", " streak " }
                                    span { class: "combo-multiplier", "({mult})" }
                                }
                            }
                        }
                    }
                    div { class: "mode-stat",
                        span { class: "mode-stat-value", "{correct_count}" }
                        span { class: "mode-stat-label", " correct" }
                    }
                }

            // Test mode header
            if is_test_mode {
                if *test_complete.read() {
                    // Test results
                    div { class: "test-results",
                        style: "text-align: center; padding: var(--spacing-xxl);",
                        h3 { style: "margin-bottom: var(--spacing-lg); font-size: var(--font-heading-lg);",
                            "Test Complete!"
                        }
                        {
                            let answers = test_answers.read();
                            let correct = answers.iter().filter(|&&c| c).count();
                            let pct = (correct * 100) / test_total;
                            let grade = if pct >= 90 { "A" } else if pct >= 80 { "B" } else if pct >= 70 { "C" } else if pct >= 60 { "D" } else { "F" };
                            rsx! {
                                div { style: "font-size: var(--font-display-md); font-weight: 700; color: var(--color-accent-blue);",
                                    "{correct}/{test_total}"
                                }
                                div { style: "font-size: var(--font-heading-lg); color: var(--text-secondary); margin: var(--spacing-md) 0;",
                                    "Grade: {grade} ({pct}%)"
                                }
                            }
                        }
                        div { class: "learn-module-actions", style: "justify-content: center; margin-top: var(--spacing-xl);",
                            button {
                                class: "learn-action-btn secondary",
                                onclick: move |_| {
                                    practice_mode.set(PracticeMode::Practice);
                                    test_complete.set(false);
                                },
                                "Back to Practice"
                            }
                            button {
                                class: "learn-action-btn primary",
                                onclick: move |_| {
                                    test_question.set(0);
                                    test_answers.set(Vec::new());
                                    test_complete.set(false);
                                    user_answer.set(String::new());
                                    feedback.set(None);
                                },
                                "Retake Test"
                            }
                        }
                    }
                } else {
                    // Test mode progress
                    div { class: "exercise-progress",
                        div { class: "exercise-mode-badge test", "TEST MODE" }
                        span { "Question {current_test_q + 1} of {test_total}" }
                        div { class: "progress-bar",
                            div {
                                class: "progress-fill",
                                style: "width: {((current_test_q + 1) * 100) / test_total}%",
                            }
                        }
                    }
                }
            } else {
                // Practice mode progress
                div { class: "exercise-progress",
                    span { "Exercise {current_idx + 1} of {total_exercises}" }
                    div { class: "progress-bar",
                        div {
                            class: "progress-fill",
                            style: "width: {progress_pct}%",
                        }
                    }
                    span { class: "practice-score", "+{score} XP" }
                    if *correct_count.read() > 0 {
                        span { style: "color: var(--color-success); font-size: var(--font-caption-md);",
                            " ({correct_count} correct)"
                        }
                    }
                }
            }

            // Don't show exercise card when test is complete
            if !(is_test_mode && *test_complete.read()) {
            if let Some(challenge) = current_challenge.as_ref() {
                div { class: "exercise-card",
                    div { class: "exercise-sentence", "{challenge.sentence}" }

                    // Answer input based on exercise type
                    match &challenge.answer {
                        AnswerType::FreeForm { .. } => rsx! {
                            div { class: "exercise-input-row",
                                input {
                                    class: match feedback.read().as_ref() {
                                        Some((true, _)) => "exercise-input correct",
                                        Some((false, _)) => "exercise-input incorrect",
                                        None => "exercise-input",
                                    },
                                    r#type: "text",
                                    placeholder: "Enter your logic translation... (Enter to submit)",
                                    value: "{user_answer}",
                                    oninput: {
                                        move |e: Event<FormData>| {
                                            user_answer.set(e.value());
                                            // Record activity to reset inactivity timer
                                            struggle_detector.write().record_activity();
                                        }
                                    },
                                    onkeydown: {
                                        let golden = golden_answer.clone();
                                        move |e: Event<KeyboardData>| {
                                            if e.key() == Key::Enter {
                                                e.prevent_default();
                                                // Trigger submit logic - same as Check button
                                                let answer = user_answer.read().clone();
                                                if !answer.is_empty() {
                                                    if let Some(ref expected) = golden {
                                                        let result = check_answer(&answer, expected);
                                                        if result.correct {
                                                            // Handle correct answer
                                                            let answer_was_revealed = answer_revealed_exercises.read().contains(&current_idx);
                                                            let already_completed = if is_test_mode { false } else { completed_exercises.read().contains(&current_idx) };

                                                            if answer_was_revealed {
                                                                let cc = *correct_count.read();
                                                                correct_count.set(cc + 1);
                                                                completed_exercises.write().insert(current_idx);
                                                                feedback.set(Some((true, "Correct! (no XP - answer was revealed)".to_string())));
                                                            } else if !already_completed {
                                                                let wrong_count = *exercise_attempts.read().get(&current_idx).unwrap_or(&0);
                                                                let base_xp = 10u32.saturating_sub(wrong_count * 5);
                                                                if base_xp > 0 {
                                                                    let cs = *streak.read();
                                                                    let sc = *score.read();
                                                                    let cc = *correct_count.read();
                                                                    let multiplier = match cs { 0 => 1.0, 1 => 1.25, 2 => 1.5, 3 => 1.75, _ => 2.0 };
                                                                    let xp = ((base_xp as f64) * multiplier).round() as u32;
                                                                    score.set(sc + xp);
                                                                    streak.set(cs + 1);
                                                                    correct_count.set(cc + 1);
                                                                    completed_exercises.write().insert(current_idx);
                                                                    let msg = if multiplier > 1.0 { format!("Correct! +{} XP ({}x combo)", xp, multiplier) } else { format!("Correct! +{} XP", xp) };
                                                                    feedback.set(Some((true, msg)));
                                                                } else {
                                                                    let cc = *correct_count.read();
                                                                    correct_count.set(cc + 1);
                                                                    completed_exercises.write().insert(current_idx);
                                                                    feedback.set(Some((true, "Correct! (no XP - too many attempts)".to_string())));
                                                                }
                                                            } else {
                                                                feedback.set(Some((true, "Correct! (already completed)".to_string())));
                                                            }
                                                            struggle_detector.write().record_correct_attempt();
                                                            show_socratic_hint.set(false);
                                                        } else {
                                                            // Wrong answer
                                                            let attempts = exercise_attempts.read().get(&current_idx).copied().unwrap_or(0);
                                                            exercise_attempts.write().insert(current_idx, attempts + 1);
                                                            let remaining = 10u32.saturating_sub((attempts + 1) * 5);
                                                            let penalty_msg = if remaining > 0 { format!(" (-5 XP, {} remaining)", remaining) } else { " (no XP remaining)".to_string() };
                                                            feedback.set(Some((false, format!("{}{}", result.feedback, penalty_msg))));
                                                            struggle_detector.write().record_wrong_attempt();
                                                            show_socratic_hint.set(true);
                                                            streak.set(0);
                                                            if !is_test_mode {
                                                                let mut queue = retry_queue.write();
                                                                if !queue.contains(&current_idx) { queue.push_back(current_idx); }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    },
                                }
                                button {
                                    class: "exercise-submit-btn",
                                    onclick: {
                                        let golden = golden_answer.clone();
                                        move |_| {
                                            let answer = user_answer.read().clone();
                                            if !answer.is_empty() {
                                                if let Some(ref expected) = golden {
                                                    // Use the real grader
                                                    let result = check_answer(&answer, expected);
                                                    if result.correct {
                                                        // Check if answer was revealed (forfeits XP)
                                                        let answer_was_revealed = answer_revealed_exercises.read().contains(&current_idx);

                                                        // Only check completed_exercises in practice mode, not test mode
                                                        let already_completed = if is_test_mode {
                                                            false // Test mode always gives fresh XP
                                                        } else {
                                                            completed_exercises.read().contains(&current_idx)
                                                        };

                                                        if answer_was_revealed {
                                                            // Answer was revealed - no XP
                                                            let current_correct = *correct_count.read();
                                                            correct_count.set(current_correct + 1);
                                                            completed_exercises.write().insert(current_idx);
                                                            feedback.set(Some((true, "Correct! (no XP - answer was revealed)".to_string())));
                                                        } else if !already_completed {
                                                            // Calculate XP based on wrong attempts (each wrong costs 5 XP)
                                                            let wrong_count = *exercise_attempts.read().get(&current_idx).unwrap_or(&0);
                                                            let base_xp = 10u32.saturating_sub(wrong_count * 5);

                                                            if base_xp > 0 {
                                                                let current_streak = *streak.read();
                                                                let current_score = *score.read();
                                                                let current_correct = *correct_count.read();

                                                                // Combo multiplier: 1.0x, 1.25x, 1.5x, 1.75x, 2.0x
                                                                let multiplier = match current_streak {
                                                                    0 => 1.0,
                                                                    1 => 1.25,
                                                                    2 => 1.5,
                                                                    3 => 1.75,
                                                                    _ => 2.0, // Max 2x
                                                                };
                                                                let xp = ((base_xp as f64) * multiplier).round() as u32;

                                                                score.set(current_score + xp);
                                                                streak.set(current_streak + 1);
                                                                correct_count.set(current_correct + 1);
                                                                completed_exercises.write().insert(current_idx);

                                                                let msg = if multiplier > 1.0 {
                                                                    format!("Correct! +{} XP ({}x combo)", xp, multiplier)
                                                                } else {
                                                                    format!("Correct! +{} XP", xp)
                                                                };
                                                                feedback.set(Some((true, msg)));
                                                            } else {
                                                                // Too many wrong attempts - no XP but still mark complete
                                                                let current_correct = *correct_count.read();
                                                                correct_count.set(current_correct + 1);
                                                                completed_exercises.write().insert(current_idx);
                                                                feedback.set(Some((true, "Correct! (no XP - too many attempts)".to_string())));
                                                            }
                                                        } else {
                                                            // Already earned XP for this exercise
                                                            feedback.set(Some((true, "Correct! (already completed)".to_string())));
                                                        }
                                                        struggle_detector.write().record_correct_attempt();
                                                        show_socratic_hint.set(false);
                                                    } else {
                                                        // Wrong answer - record attempt and show feedback
                                                        let attempts = exercise_attempts.read().get(&current_idx).copied().unwrap_or(0);
                                                        exercise_attempts.write().insert(current_idx, attempts + 1);

                                                        let remaining = 10u32.saturating_sub((attempts + 1) * 5);
                                                        let penalty_msg = if remaining > 0 {
                                                            format!(" (-5 XP, {} remaining)", remaining)
                                                        } else {
                                                            " (no XP remaining)".to_string()
                                                        };

                                                        feedback.set(Some((false, format!("{}{}", result.feedback, penalty_msg))));
                                                        struggle_detector.write().record_wrong_attempt();
                                                        show_socratic_hint.set(true);
                                                        streak.set(0);

                                                        // In practice mode, add wrong exercise to retry queue (at +3 position)
                                                        if !is_test_mode {
                                                            let mut queue = retry_queue.write();
                                                            // Only add if not already in queue
                                                            if !queue.contains(&current_idx) {
                                                                queue.push_back(current_idx);
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    },
                                    "Check"
                                }
                            }
                        },
                        AnswerType::MultipleChoice { options, correct_index } => rsx! {
                            div { class: "multiple-choice-options",
                                for (idx, option) in options.iter().enumerate() {
                                    {
                                        let is_selected = user_answer.read().as_str() == option;
                                        let is_correct_option = idx == *correct_index;
                                        let option_clone = option.clone();
                                        let show_result = feedback.read().is_some();

                                        let btn_class = if show_result && is_selected {
                                            if is_correct_option { "reveal-btn active correct" } else { "reveal-btn active incorrect" }
                                        } else if is_selected {
                                            "reveal-btn active"
                                        } else {
                                            "reveal-btn"
                                        };

                                        rsx! {
                                            button {
                                                class: "{btn_class}",
                                                onclick: {
                                                    let opt = option_clone.clone();
                                                    let correct = is_correct_option;
                                                    move |_| {
                                                        user_answer.set(opt.clone());
                                                        if correct {
                                                            // Check if answer was revealed (forfeits XP)
                                                            let answer_was_revealed = answer_revealed_exercises.read().contains(&current_idx);

                                                            // Only check completed_exercises in practice mode, not test mode
                                                            let already_completed = if is_test_mode {
                                                                false // Test mode always gives fresh XP
                                                            } else {
                                                                completed_exercises.read().contains(&current_idx)
                                                            };

                                                            if answer_was_revealed {
                                                                // Answer was revealed - no XP
                                                                let current_correct = *correct_count.read();
                                                                correct_count.set(current_correct + 1);
                                                                completed_exercises.write().insert(current_idx);
                                                                feedback.set(Some((true, "Correct! (no XP - answer was revealed)".to_string())));
                                                            } else if !already_completed {
                                                                // Calculate XP based on wrong attempts (each wrong costs 5 XP)
                                                                let wrong_count = *exercise_attempts.read().get(&current_idx).unwrap_or(&0);
                                                                let base_xp = 10u32.saturating_sub(wrong_count * 5);

                                                                if base_xp > 0 {
                                                                    let current_streak = *streak.read();
                                                                    let current_score = *score.read();
                                                                    let current_correct = *correct_count.read();

                                                                    // Combo multiplier: 1.0x, 1.25x, 1.5x, 1.75x, 2.0x
                                                                    let multiplier = match current_streak {
                                                                        0 => 1.0,
                                                                        1 => 1.25,
                                                                        2 => 1.5,
                                                                        3 => 1.75,
                                                                        _ => 2.0, // Max 2x
                                                                    };
                                                                    let xp = ((base_xp as f64) * multiplier).round() as u32;

                                                                    score.set(current_score + xp);
                                                                    streak.set(current_streak + 1);
                                                                    correct_count.set(current_correct + 1);
                                                                    completed_exercises.write().insert(current_idx);

                                                                    let msg = if multiplier > 1.0 {
                                                                        format!("Correct! +{} XP ({}x combo)", xp, multiplier)
                                                                    } else {
                                                                        format!("Correct! +{} XP", xp)
                                                                    };
                                                                    feedback.set(Some((true, msg)));
                                                                } else {
                                                                    // Too many wrong attempts - no XP but still mark complete
                                                                    let current_correct = *correct_count.read();
                                                                    correct_count.set(current_correct + 1);
                                                                    completed_exercises.write().insert(current_idx);
                                                                    feedback.set(Some((true, "Correct! (no XP - too many attempts)".to_string())));
                                                                }
                                                            } else {
                                                                feedback.set(Some((true, "Correct! (already completed)".to_string())));
                                                            }
                                                            struggle_detector.write().record_correct_attempt();
                                                            show_socratic_hint.set(false);
                                                        } else {
                                                            // Wrong answer - record attempt and show feedback
                                                            let attempts = exercise_attempts.read().get(&current_idx).copied().unwrap_or(0);
                                                            exercise_attempts.write().insert(current_idx, attempts + 1);

                                                            let remaining = 10u32.saturating_sub((attempts + 1) * 5);
                                                            let penalty_msg = if remaining > 0 {
                                                                format!(" (-5 XP, {} remaining)", remaining)
                                                            } else {
                                                                " (no XP remaining)".to_string()
                                                            };

                                                            feedback.set(Some((false, format!("Not quite.{}", penalty_msg))));
                                                            struggle_detector.write().record_wrong_attempt();
                                                            show_socratic_hint.set(true);
                                                            streak.set(0);

                                                            // In practice mode, add wrong exercise to retry queue
                                                            if !is_test_mode {
                                                                let mut queue = retry_queue.write();
                                                                if !queue.contains(&current_idx) {
                                                                    queue.push_back(current_idx);
                                                                }
                                                            }
                                                        }
                                                    }
                                                },
                                                "{option}"
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        AnswerType::Ambiguity { readings } => rsx! {
                            div { class: "ambiguity-readings",
                                p { class: "exercise-prompt", "This sentence has {readings.len()} possible interpretations:" }
                                for (i, reading) in readings.iter().enumerate() {
                                    div { class: "revealed-logic",
                                        span { class: "revealed-label", "Reading {i + 1}" }
                                        "{reading}"
                                    }
                                }
                            }
                        },
                    }

                    // Show feedback
                    if let Some((is_correct, msg)) = feedback.read().as_ref() {
                        div {
                            class: if *is_correct { "exercise-feedback correct" } else { "exercise-feedback incorrect" },
                            "{msg}"
                        }
                    }

                    // Socratic hint (triggered by wrong answer or inactivity) - NOT in test mode
                    if !is_test_mode && *show_socratic_hint.read() && hint_text.is_some() {
                        div { class: "socratic-hint-box",
                            div { class: "hint-header",
                                "🦉 Socrates says..."
                            }
                            div { class: "hint-text",
                                if let Some(reason) = struggle_detector.read().reason() {
                                    "{reason.message()} "
                                }
                                if let Some(hint) = hint_text.as_ref() {
                                    "{hint}"
                                }
                            }
                        }
                    }

                    // Interactive reveal buttons - NOT in test mode
                    if !is_test_mode {
                    div { class: "reveal-section",
                        div { class: "reveal-buttons",
                            // Show Hint button - toggles independently
                            button {
                                class: if reveal_state.read().hint { "reveal-btn active" } else { "reveal-btn" },
                                onclick: move |_| {
                                    let current = reveal_state.read().hint;
                                    reveal_state.write().hint = !current;
                                },
                                "💡 Show Hint"
                            }

                            // Show Answer button - toggles independently, forfeits XP when revealed
                            button {
                                class: if reveal_state.read().answer { "reveal-btn active" } else { "reveal-btn" },
                                onclick: move |_| {
                                    let current = reveal_state.read().answer;
                                    if !current {
                                        // Revealing answer for first time - forfeit XP for this exercise
                                        answer_revealed_exercises.write().insert(current_idx);
                                    }
                                    reveal_state.write().answer = !current;
                                },
                                "✓ Show Answer (No XP)"
                            }

                            // Symbol Dictionary button (only for FreeForm/Ambiguity) - toggles independently
                            if matches!(&challenge.answer, AnswerType::FreeForm { .. } | AnswerType::Ambiguity { .. }) {
                                button {
                                    class: if reveal_state.read().symbol_dictionary { "reveal-btn active" } else { "reveal-btn" },
                                    onclick: move |_| {
                                        let current = reveal_state.read().symbol_dictionary;
                                        reveal_state.write().symbol_dictionary = !current;
                                    },
                                    "📖 Symbol Dictionary"
                                }
                            }
                        }

                        // Stacked revealed content - each section shows independently
                        if reveal_state.read().hint {
                            div { class: "revealed-content",
                                div { class: "revealed-label", "Hint" }
                                if let Some(hint) = hint_text.as_ref() {
                                    p { "{hint}" }
                                } else {
                                    p { "No hint available for this exercise." }
                                }
                            }
                        }

                        if reveal_state.read().answer {
                            div { class: "revealed-content",
                                div { class: "revealed-label", "Correct Answer" }
                                if let Some(answer) = golden_answer.as_ref() {
                                    div { class: "revealed-logic", "{answer}" }
                                    // Show explanation if available
                                    if let Some(explanation) = challenge.explanation.as_ref() {
                                        p { style: "margin-top: 12px; color: var(--text-secondary);", "{explanation}" }
                                    }
                                }
                            }
                        }

                        if reveal_state.read().symbol_dictionary {
                            div { class: "revealed-content",
                                if let Some(answer) = golden_answer.as_ref() {
                                    SymbolDictionary { logic: answer.clone() }
                                } else {
                                    p { "No logic output to analyze." }
                                }
                            }
                        }
                    }
                    } // end if !is_test_mode

                    // Action buttons
                    div { class: "learn-module-actions", style: "margin-top: 24px;",
                        if is_test_mode {
                            // Test mode: Submit answer and move to next question
                            button {
                                class: "learn-action-btn primary",
                                onclick: {
                                    let golden = golden_answer.clone();
                                    move |_| {
                                        let answer = user_answer.read().clone();
                                        let is_correct = if let Some(ref expected) = golden {
                                            if !answer.is_empty() {
                                                check_answer(&answer, expected).correct
                                            } else {
                                                false
                                            }
                                        } else {
                                            false
                                        };

                                        // Record answer
                                        test_answers.write().push(is_correct);

                                        // Move to next question or complete
                                        let next_q = current_test_q + 1;
                                        if next_q >= test_total {
                                            test_complete.set(true);
                                        } else {
                                            test_question.set(next_q);
                                            // Also advance the exercise index for variety
                                            let next_idx = (current_idx + 1) % total_exercises;
                                            current_exercise_idx.set(next_idx);
                                        }
                                        user_answer.set(String::new());
                                        feedback.set(None);
                                    }
                                },
                                "Submit Answer →"
                            }
                            button {
                                class: "learn-action-btn secondary",
                                onclick: move |_| {
                                    practice_mode.set(PracticeMode::Practice);
                                },
                                "Exit Test"
                            }
                        } else {
                        // Practice mode buttons
                        button {
                            class: "learn-action-btn secondary",
                            onclick: {
                                move |_| {
                                    // Simple linear progression - skip to next
                                    let next = current_idx + 1;
                                    if next < total_exercises {
                                        current_exercise_idx.set(next);
                                    } else {
                                        current_exercise_idx.set(0); // Loop back to start
                                    }
                                    // Reset state
                                    user_answer.set(String::new());
                                    feedback.set(None);
                                    reveal_state.write().reset();
                                    struggle_detector.write().reset();
                                    show_socratic_hint.set(false);
                                }
                            },
                            "Skip →"
                        }

                        if feedback.read().as_ref().map(|(c, _)| *c).unwrap_or(false) {
                            button {
                                class: "learn-action-btn primary",
                                onclick: {
                                    move |_| {
                                        // Simple linear progression after correct answer
                                        let next = current_idx + 1;
                                        if next < total_exercises {
                                            current_exercise_idx.set(next);
                                        } else {
                                            current_exercise_idx.set(0); // Loop back to start
                                        }
                                        user_answer.set(String::new());
                                        feedback.set(None);
                                        reveal_state.write().reset();
                                        struggle_detector.write().reset();
                                        show_socratic_hint.set(false);
                                    }
                                },
                                "Next Exercise →"
                            }
                        }

                        // Show "Take Test" button after 5 correct answers
                        if *correct_count.read() >= 5 {
                            button {
                                class: "learn-action-btn test-ready",
                                style: "background: linear-gradient(135deg, #fbbf24, #f59e0b); margin-left: auto;",
                                onclick: move |_| {
                                    practice_mode.set(PracticeMode::Test);
                                    test_question.set(0);
                                    test_answers.set(Vec::new());
                                    test_complete.set(false);
                                    user_answer.set(String::new());
                                    feedback.set(None);
                                    reveal_state.write().reset();
                                },
                                "🎯 Take Test"
                            }
                        }
                        } // end else (practice mode)
                    }
                }
            } else {
                div { style: "text-align: center; padding: var(--spacing-xl); color: var(--text-secondary);",
                    p { "No exercises available for this module yet." }
                    p { style: "font-size: var(--font-caption-md); margin-top: var(--spacing-md);",
                        "Total loaded: {total_exercises}"
                    }
                }
            }
            } // end if !(is_test_mode && test_complete)
            } // end else (Practice view)
        }
    }
}

```

---

### Page: Lesson

**File:** `src/ui/pages/lesson.rs`

Interactive problem-solving interface. Displays generated challenges, accepts FOL input, provides semantic grading with feedback, and tracks progress through exercises.

```rust
use dioxus::prelude::*;
use crate::ui::router::Route;
use crate::ui::components::mixed_text::MixedText;
use crate::ui::components::xp_popup::XpPopup;
use crate::ui::components::combo_indicator::ComboIndicator;
use crate::ui::components::achievement_toast::AchievementToast;
use crate::ui::components::main_nav::{MainNav, ActivePage};
use crate::content::ContentEngine;
use crate::generator::{Generator, Challenge, AnswerType};
use crate::grader::{check_answer, GradeResult};
use crate::progress::UserProgress;
use crate::game::{XpReward, ComboResult, calculate_xp_reward, update_combo};
use crate::achievements::{Achievement, check_achievements, unlock_achievement};
use crate::audio::{SoundEffect, play_sound};

#[derive(Clone, Copy, PartialEq, Default, Debug)]
pub enum SessionMode {
    Textbook,
    #[default]
    Learning,
    Testing,
}

impl SessionMode {
    pub fn from_str(s: &str) -> Self {
        match s.to_lowercase().as_str() {
            "textbook" | "read" => SessionMode::Textbook,
            "testing" | "test" => SessionMode::Testing,
            _ => SessionMode::Learning,
        }
    }

    pub fn to_str(&self) -> &'static str {
        match self {
            SessionMode::Textbook => "textbook",
            SessionMode::Learning => "learning",
            SessionMode::Testing => "testing",
        }
    }

    pub fn shows_hints(&self) -> bool {
        matches!(self, SessionMode::Learning)
    }

    pub fn shows_immediate_feedback(&self) -> bool {
        matches!(self, SessionMode::Learning)
    }

    pub fn shows_explanation(&self) -> bool {
        matches!(self, SessionMode::Learning)
    }

    pub fn xp_multiplier(&self) -> f64 {
        match self {
            SessionMode::Textbook => 0.0,
            SessionMode::Learning => 0.5,
            SessionMode::Testing => 1.0,
        }
    }
}

const LESSON_STYLE: &str = r#"
.lesson-container {
    min-height: 100vh;
    background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
    color: var(--text-primary);
    display: flex;
    flex-direction: column;
}

.lesson-header {
    padding: var(--spacing-lg) var(--spacing-xl);
    background: rgba(0, 0, 0, 0.2);
    border-bottom: 1px solid rgba(255, 255, 255, 0.08);
    display: flex;
    justify-content: space-between;
    align-items: center;
}

.breadcrumb {
    display: flex;
    align-items: center;
    gap: var(--spacing-sm);
    color: var(--text-secondary);
    font-size: var(--font-body-md);
}

.breadcrumb a {
    color: var(--color-primary-blue);
    text-decoration: none;
}

.progress-info {
    display: flex;
    align-items: center;
    gap: var(--spacing-lg);
}

.progress-bar {
    width: 200px;
    height: 8px;
    background: rgba(255, 255, 255, 0.1);
    border-radius: var(--radius-sm);
    overflow: hidden;
}

.progress-fill {
    height: 100%;
    background: linear-gradient(90deg, var(--color-primary-blue), var(--color-primary-purple));
    transition: width 0.3s ease;
}

.score-display {
    color: var(--color-primary-blue);
    font-weight: 600;
}

.xp-display {
    color: var(--color-success);
    font-weight: 600;
    font-size: var(--font-body-md);
}

.lesson-main {
    flex: 1;
    display: flex;
    flex-direction: column;
    align-items: center;
    justify-content: center;
    padding: 40px var(--spacing-xl);
}

.problem-card {
    background: rgba(255, 255, 255, 0.05);
    border: 1px solid rgba(255, 255, 255, 0.1);
    border-radius: var(--radius-xl);
    padding: 40px;
    max-width: 700px;
    width: 100%;
    position: relative;
}

.combo-row {
    position: absolute;
    top: -40px;
    left: 50%;
    transform: translateX(-50%);
}

.problem-prompt {
    color: var(--text-secondary);
    font-size: var(--font-body-md);
    margin-bottom: var(--spacing-lg);
    text-transform: uppercase;
    letter-spacing: 1px;
}

.problem-sentence {
    font-size: var(--font-heading-lg);
    font-weight: 500;
    color: var(--text-primary);
    margin-bottom: var(--spacing-xxl);
    line-height: 1.4;
}

.answer-input {
    width: 100%;
    padding: var(--spacing-lg) var(--spacing-xl);
    font-size: var(--font-body-lg);
    font-family: var(--font-mono);
    background: rgba(255, 255, 255, 0.08);
    border: 2px solid rgba(255, 255, 255, 0.15);
    border-radius: var(--radius-lg);
    color: var(--text-primary);
    outline: none;
    transition: border-color 0.2s ease;
}

.answer-input:focus {
    border-color: var(--color-primary-blue);
}

.answer-input.correct {
    border-color: var(--color-success);
    background: rgba(74, 222, 128, 0.1);
}

.answer-input.incorrect {
    border-color: var(--color-error);
    background: rgba(248, 113, 113, 0.1);
}

.multiple-choice {
    display: flex;
    flex-direction: column;
    gap: var(--spacing-md);
}

.choice-btn {
    padding: var(--spacing-lg) var(--spacing-xl);
    background: rgba(255, 255, 255, 0.05);
    border: 2px solid rgba(255, 255, 255, 0.1);
    border-radius: var(--radius-lg);
    color: var(--text-primary);
    font-size: var(--font-body-md);
    text-align: left;
    cursor: pointer;
    transition: all 0.2s ease;
}

.choice-btn:hover {
    background: rgba(255, 255, 255, 0.08);
    border-color: var(--color-primary-blue);
}

.choice-btn.selected {
    background: rgba(102, 126, 234, 0.2);
    border-color: var(--color-primary-blue);
}

.choice-btn.correct {
    background: rgba(74, 222, 128, 0.2);
    border-color: var(--color-success);
}

.choice-btn.incorrect {
    background: rgba(248, 113, 113, 0.2);
    border-color: var(--color-error);
}

.action-row {
    display: flex;
    justify-content: space-between;
    align-items: center;
    margin-top: var(--spacing-xl);
}

.hint-btn {
    padding: 10px var(--spacing-xl);
    background: transparent;
    border: 1px solid rgba(255, 255, 255, 0.2);
    border-radius: var(--radius-md);
    color: var(--text-secondary);
    cursor: pointer;
    transition: all 0.2s ease;
}

.hint-btn:hover {
    border-color: var(--color-primary-blue);
    color: var(--color-primary-blue);
}

.submit-btn {
    padding: var(--spacing-md) var(--spacing-xxl);
    background: linear-gradient(135deg, var(--color-primary-blue) 0%, var(--color-primary-purple) 100%);
    border: none;
    border-radius: var(--radius-md);
    color: white;
    font-size: var(--font-body-md);
    font-weight: 600;
    cursor: pointer;
    transition: transform 0.2s ease;
}

.submit-btn:hover {
    transform: scale(1.02);
}

.submit-btn:disabled {
    opacity: 0.5;
    cursor: not-allowed;
}

.feedback-box {
    margin-top: var(--spacing-xl);
    padding: var(--spacing-lg) var(--spacing-xl);
    border-radius: var(--radius-lg);
    font-size: var(--font-body-sm);
}

.feedback-correct {
    background: rgba(74, 222, 128, 0.15);
    border: 1px solid rgba(74, 222, 128, 0.3);
    color: var(--color-success);
}

.feedback-incorrect {
    background: rgba(248, 113, 113, 0.15);
    border: 1px solid rgba(248, 113, 113, 0.3);
    color: var(--color-error);
}

.feedback-partial {
    background: rgba(251, 191, 36, 0.15);
    border: 1px solid rgba(251, 191, 36, 0.3);
    color: var(--color-warning);
}

.hint-box {
    margin-top: var(--spacing-lg);
    padding: var(--spacing-lg) var(--spacing-xl);
    background: rgba(102, 126, 234, 0.1);
    border: 1px solid rgba(102, 126, 234, 0.2);
    border-radius: var(--radius-lg);
    color: var(--color-info);
    font-size: var(--font-body-md);
}

.explanation-box {
    margin-top: var(--spacing-lg);
    padding: var(--spacing-lg) var(--spacing-xl);
    background: rgba(248, 113, 113, 0.08);
    border: 1px solid rgba(248, 113, 113, 0.2);
    border-radius: var(--radius-lg);
    color: #fca5a5;
    font-size: var(--font-body-md);
    line-height: 1.6;
}

.explanation-box strong {
    color: var(--color-error);
    font-weight: 600;
}

.next-btn {
    padding: var(--spacing-md) var(--spacing-xxl);
    background: linear-gradient(135deg, var(--color-success) 0%, #22c55e 100%);
    border: none;
    border-radius: var(--radius-md);
    color: white;
    font-size: var(--font-body-md);
    font-weight: 600;
    cursor: pointer;
}

.complete-message {
    text-align: center;
}

.complete-message h2 {
    font-size: var(--font-display-md);
    color: var(--color-success);
    margin-bottom: var(--spacing-lg);
}

.complete-message p {
    color: var(--text-secondary);
    margin-bottom: var(--spacing-xl);
}

.reading-list {
    display: flex;
    flex-direction: column;
    gap: var(--spacing-sm);
}

.reading-item {
    padding: var(--spacing-md) var(--spacing-lg);
    background: rgba(255, 255, 255, 0.03);
    border: 1px solid rgba(255, 255, 255, 0.08);
    border-radius: var(--radius-md);
    font-family: var(--font-mono);
    font-size: var(--font-body-md);
    color: var(--color-info);
}

.mode-badge {
    padding: var(--spacing-xs) var(--spacing-md);
    border-radius: var(--radius-lg);
    font-size: var(--font-caption-sm);
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.5px;
}

.mode-badge.learning {
    background: rgba(74, 222, 128, 0.2);
    color: var(--color-success);
    border: 1px solid rgba(74, 222, 128, 0.3);
}

.mode-badge.testing {
    background: rgba(251, 146, 60, 0.2);
    color: var(--color-warning);
    border: 1px solid rgba(251, 146, 60, 0.3);
}

.mode-badge.textbook {
    background: rgba(96, 165, 250, 0.2);
    color: var(--color-accent-blue);
    border: 1px solid rgba(96, 165, 250, 0.3);
}

.test-summary {
    margin-top: var(--spacing-xl);
    padding: var(--spacing-xl);
    background: rgba(255, 255, 255, 0.03);
    border-radius: var(--radius-lg);
    border: 1px solid rgba(255, 255, 255, 0.08);
}

.test-summary h3 {
    margin-bottom: var(--spacing-lg);
    color: var(--text-secondary);
    font-size: var(--font-body-md);
    text-transform: uppercase;
    letter-spacing: 1px;
}

.result-item {
    padding: var(--spacing-md);
    margin-bottom: var(--spacing-sm);
    border-radius: var(--radius-md);
    display: flex;
    align-items: flex-start;
    gap: var(--spacing-md);
}

.result-item.correct {
    background: rgba(74, 222, 128, 0.1);
    border: 1px solid rgba(74, 222, 128, 0.2);
}

.result-item.incorrect {
    background: rgba(248, 113, 113, 0.1);
    border: 1px solid rgba(248, 113, 113, 0.2);
}

.result-icon {
    font-size: var(--font-body-lg);
}

.result-content {
    flex: 1;
}

.result-question {
    color: var(--text-primary);
    margin-bottom: var(--spacing-xs);
}

.result-explanation {
    color: var(--text-secondary);
    font-size: var(--font-caption-md);
}

.textbook-container {
    max-width: 700px;
    width: 100%;
}

.textbook-card {
    background: rgba(255, 255, 255, 0.05);
    border: 1px solid rgba(255, 255, 255, 0.1);
    border-radius: var(--radius-xl);
    padding: var(--spacing-xxl);
    margin-bottom: var(--spacing-xl);
}

.textbook-card h2 {
    color: var(--text-primary);
    font-size: var(--font-heading-lg);
    margin-bottom: var(--spacing-lg);
}

.textbook-intro {
    color: var(--text-muted);
    font-size: var(--font-body-md);
    line-height: 1.6;
    margin-bottom: var(--spacing-xl);
}

.example-section {
    margin-top: var(--spacing-xl);
}

.example-section h3 {
    color: var(--color-primary-blue);
    font-size: var(--font-caption-lg);
    text-transform: uppercase;
    letter-spacing: 1px;
    margin-bottom: var(--spacing-lg);
}

.example-item {
    background: rgba(255, 255, 255, 0.03);
    border: 1px solid rgba(255, 255, 255, 0.08);
    border-radius: var(--radius-lg);
    padding: var(--spacing-lg);
    margin-bottom: var(--spacing-md);
}

.example-sentence {
    color: var(--text-primary);
    font-size: var(--font-body-lg);
    margin-bottom: var(--spacing-md);
}

.example-explanation {
    color: var(--text-secondary);
    font-size: var(--font-caption-lg);
    line-height: 1.5;
    padding-left: var(--spacing-lg);
    border-left: 2px solid rgba(102, 126, 234, 0.3);
}

.textbook-nav {
    display: flex;
    justify-content: space-between;
    margin-top: var(--spacing-xl);
}

.textbook-nav-btn {
    padding: var(--spacing-md) var(--spacing-xl);
    background: transparent;
    border: 1px solid rgba(255, 255, 255, 0.2);
    border-radius: var(--radius-md);
    color: var(--text-secondary);
    font-size: var(--font-caption-lg);
    cursor: pointer;
    transition: all 0.2s ease;
}

.textbook-nav-btn:hover {
    border-color: var(--color-primary-blue);
    color: var(--color-primary-blue);
}

.textbook-nav-btn.primary {
    background: linear-gradient(135deg, var(--color-primary-blue) 0%, var(--color-primary-purple) 100%);
    border: none;
    color: white;
}

.textbook-nav-btn.primary:hover {
    transform: scale(1.02);
}

.page-indicator {
    color: var(--text-tertiary);
    font-size: var(--font-caption-lg);
    align-self: center;
}
"#;

#[component]
pub fn Lesson(era: String, module: String, mode: String) -> Element {
    let session_mode = SessionMode::from_str(&mode);

    let mut current_index = use_signal(|| 0usize);
    let mut score = use_signal(|| 0u32);
    let mut answer = use_signal(String::new);
    let mut selected_choice = use_signal(|| None::<usize>);
    let mut submitted = use_signal(|| false);
    let mut grade_result = use_signal(|| None::<GradeResult>);
    let mut show_hint = use_signal(|| false);
    let mut challenges = use_signal(Vec::<Challenge>::new);
    let mut initialized = use_signal(|| false);
    let mut test_results = use_signal(Vec::<(usize, bool, String, Option<String>)>::new);

    let mut progress = use_signal(UserProgress::load);
    let mut show_xp_popup = use_signal(|| false);
    let mut current_xp_reward = use_signal(|| None::<XpReward>);
    let mut combo_result = use_signal(|| ComboResult { new_combo: 0, is_new_record: false, multiplier: 1.0 });
    let mut show_achievement = use_signal(|| false);
    let mut current_achievement = use_signal(|| None::<&'static Achievement>);
    let mut first_try_tracker = use_signal(|| std::collections::HashSet::<usize>::new());
    let mut mistakes_in_module = use_signal(|| 0u32);

    let engine = ContentEngine::new();
    let generator = Generator::new();

    let module_data = engine.get_module(&era, &module);

    if !initialized() {
        if let Some(mod_data) = engine.get_module(&era, &module) {
            let mut rng = rand::thread_rng();
            let generated: Vec<Challenge> = mod_data.exercises.iter()
                .filter_map(|ex| generator.generate(ex, &mut rng))
                .collect();
            challenges.set(generated);
            initialized.set(true);
        }
    }

    let total_exercises = challenges.read().len();
    let progress_pct = if total_exercises > 0 {
        ((current_index() + 1) as f64 / total_exercises as f64 * 100.0) as u32
    } else {
        0
    };

    let module_title = module_data.map(|m| m.meta.title.clone()).unwrap_or_default();
    let era_title = match era.as_str() {
        "first-steps" => "First Steps",
        "building-blocks" => "Building Blocks",
        "expanding-horizons" => "Expanding Horizons",
        "mastery" => "Mastery",
        // Legacy era mappings (deprecated)
        "logic-caffeine" => "Introduction to Logic",
        "trivium" => "Basics",
        "quadrivium" => "Quantifiers",
        "metaphysics" => "Modality & Time",
        "logicaffeine" => "Practice",
        _ => "Logic",
    };

    let progress_style = format!("width: {}%", progress_pct);
    let user_xp = progress.read().xp;
    let user_combo = progress.read().combo;

    rsx! {
        style { "{LESSON_STYLE}" }

        MainNav { active: ActivePage::Learn }

        if show_xp_popup() {
            if let Some(reward) = current_xp_reward() {
                XpPopup {
                    reward: reward.clone(),
                    on_dismiss: move |_| show_xp_popup.set(false)
                }
            }
        }

        if show_achievement() {
            if let Some(achievement) = current_achievement() {
                AchievementToast {
                    achievement: achievement,
                    on_dismiss: move |_| show_achievement.set(false)
                }
            }
        }

        div { class: "lesson-container",
            header { class: "lesson-header",
                nav { class: "breadcrumb",
                    Link { to: Route::Learn {}, "Curriculum" }
                    span { " > " }
                    span { "{era_title}" }
                    span { " > " }
                    span { "{module_title}" }
                    span {
                        class: "mode-badge {session_mode.to_str()}",
                        style: "margin-left: 12px;",
                        "{session_mode.to_str()}"
                    }
                }
                div { class: "progress-info",
                    div { class: "progress-bar",
                        div {
                            class: "progress-fill",
                            style: "{progress_style}",
                        }
                    }
                    if session_mode.xp_multiplier() > 0.0 {
                        span { class: "xp-display", "{user_xp} XP" }
                    }
                    span { class: "score-display", "Score: {score}" }
                }
            }

            main { class: "lesson-main",
                {
                    let challenges_read = challenges.read();
                    let current = current_index();

                    if current >= total_exercises && total_exercises > 0 {
                        let correct_count = test_results.read().iter().filter(|(_, c, _, _)| *c).count();
                        let results_clone = test_results.read().clone();
                        rsx! {
                            div { class: "problem-card complete-message",
                                h2 { "Module Complete!" }
                                p { "You scored {score} points" }
                                if session_mode == SessionMode::Testing {
                                    p { style: "color: #667eea; font-size: 18px; margin-bottom: 8px;",
                                        "Test Results: {correct_count}/{total_exercises} correct"
                                    }
                                }
                                if mistakes_in_module() == 0 && total_exercises > 0 {
                                    p { style: "color: #fbbf24;", "🏆 Flawless! No mistakes!" }
                                }

                                if session_mode == SessionMode::Testing && !results_clone.is_empty() {
                                    div { class: "test-summary",
                                        h3 { "Review Your Answers" }
                                        for (idx, is_correct, sentence, explanation) in results_clone.iter() {
                                            {
                                                let item_class = if *is_correct { "result-item correct" } else { "result-item incorrect" };
                                                let icon = if *is_correct { "✓" } else { "✗" };
                                                rsx! {
                                                    div { class: "{item_class}",
                                                        span { class: "result-icon", "{icon}" }
                                                        div { class: "result-content",
                                                            p { class: "result-question", "Q{idx + 1}: {sentence}" }
                                                            if !is_correct {
                                                                if let Some(expl) = explanation {
                                                                    p { class: "result-explanation", "{expl}" }
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }

                                Link {
                                    class: "submit-btn",
                                    to: Route::Learn {},
                                    "← Back to Curriculum"
                                }
                            }
                        }
                    } else if session_mode == SessionMode::Textbook {
                        let page = current / 5;
                        let total_pages = (challenges_read.len() + 4) / 5;
                        let examples: Vec<_> = challenges_read.iter()
                            .filter_map(|c| {
                                c.explanation.as_ref().map(|e| (c.sentence.clone(), e.clone()))
                            })
                            .skip(page * 5)
                            .take(5)
                            .collect();
                        let era_clone = era.clone();
                        let module_clone = module.clone();
                        rsx! {
                            div { class: "textbook-container",
                                div { class: "textbook-card",
                                    h2 { "{module_title}" }
                                    p { class: "textbook-intro",
                                        "Study the examples below to understand how English sentences translate to first-order logic. Pay attention to the patterns and explanations."
                                    }

                                    div { class: "example-section",
                                        h3 { "Examples" }
                                        for (sentence, explanation) in examples.iter() {
                                            div { class: "example-item",
                                                div { class: "example-sentence",
                                                    MixedText { content: sentence.clone() }
                                                }
                                                div { class: "example-explanation",
                                                    MixedText { content: explanation.clone() }
                                                }
                                            }
                                        }
                                    }

                                    div { class: "textbook-nav",
                                        if page > 0 {
                                            button {
                                                class: "textbook-nav-btn",
                                                onclick: move |_| current_index.set((page - 1) * 5),
                                                "← Previous"
                                            }
                                        } else {
                                            div {}
                                        }

                                        span { class: "page-indicator", "Page {page + 1} of {total_pages}" }

                                        if page + 1 < total_pages {
                                            button {
                                                class: "textbook-nav-btn",
                                                onclick: move |_| current_index.set((page + 1) * 5),
                                                "Next →"
                                            }
                                        } else {
                                            Link {
                                                to: Route::Lesson {
                                                    era: era_clone.clone(),
                                                    module: module_clone.clone(),
                                                    mode: "learning".to_string(),
                                                },
                                                class: "textbook-nav-btn primary",
                                                "Start Practice →"
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    } else if let Some(challenge) = challenges_read.get(current) {
                        let prompt = challenge.prompt.clone();
                        let sentence = challenge.sentence.clone();
                        let hint_text = challenge.hint.clone();
                        let explanation_text = challenge.explanation.clone();
                        let exercise_id = challenge.exercise_id.clone();

                        let input_class = if submitted() {
                            if grade_result().map(|r| r.correct).unwrap_or(false) {
                                "answer-input correct"
                            } else {
                                "answer-input incorrect"
                            }
                        } else {
                            "answer-input"
                        };

                        rsx! {
                            div { class: "problem-card",
                                if user_combo > 0 {
                                    div { class: "combo-row",
                                        ComboIndicator {
                                            combo: user_combo,
                                            multiplier: combo_result().multiplier,
                                            is_new_record: combo_result().is_new_record
                                        }
                                    }
                                }

                                div { class: "problem-prompt", MixedText { content: prompt.clone() } }
                                div { class: "problem-sentence", MixedText { content: sentence.clone() } }

                                {match &challenge.answer {
                                    AnswerType::FreeForm { .. } => rsx! {
                                        input {
                                            class: "{input_class}",
                                            r#type: "text",
                                            placeholder: "Enter your answer in FOL...",
                                            value: "{answer}",
                                            disabled: submitted(),
                                            oninput: move |e| answer.set(e.value()),
                                        }
                                    },
                                    AnswerType::MultipleChoice { options, correct_index } => {
                                        let correct_idx = *correct_index;
                                        let opts = options.clone();
                                        let show_result_colors = session_mode.shows_immediate_feedback();
                                        rsx! {
                                            div { class: "multiple-choice",
                                                for (i, option) in opts.iter().enumerate() {
                                                    {
                                                        let btn_class = if submitted() && show_result_colors {
                                                            if i == correct_idx {
                                                                "choice-btn correct"
                                                            } else if selected_choice() == Some(i) {
                                                                "choice-btn incorrect"
                                                            } else {
                                                                "choice-btn"
                                                            }
                                                        } else if selected_choice() == Some(i) {
                                                            "choice-btn selected"
                                                        } else {
                                                            "choice-btn"
                                                        };
                                                        rsx! {
                                                            button {
                                                                class: "{btn_class}",
                                                                disabled: submitted(),
                                                                onclick: move |_| selected_choice.set(Some(i)),
                                                                MixedText { content: option.clone() }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    },
                                    AnswerType::Ambiguity { readings } => {
                                        let rds = readings.clone();
                                        rsx! {
                                            div { class: "reading-list",
                                                for reading in rds.iter() {
                                                    div { class: "reading-item", "{reading}" }
                                                }
                                            }
                                        }
                                    },
                                }}

                                if session_mode.shows_immediate_feedback() {
                                    if let Some(result) = grade_result() {
                                        {
                                            let fb_class = if result.correct {
                                                "feedback-box feedback-correct"
                                            } else if result.partial {
                                                "feedback-box feedback-partial"
                                            } else {
                                                "feedback-box feedback-incorrect"
                                            };
                                            rsx! {
                                                div { class: "{fb_class}", "{result.feedback}" }
                                            }
                                        }
                                    }
                                }

                                if session_mode.shows_explanation() && submitted() && !grade_result().map(|r| r.correct).unwrap_or(true) {
                                    if let Some(ref expl) = explanation_text {
                                        div { class: "explanation-box",
                                            strong { "Explanation: " }
                                            MixedText { content: expl.clone() }
                                        }
                                    }
                                }

                                if session_mode.shows_hints() && show_hint() && hint_text.is_some() {
                                    div { class: "hint-box", "{hint_text.as_ref().unwrap()}" }
                                }

                                div { class: "action-row",
                                    if session_mode.shows_hints() && !submitted() && hint_text.is_some() {
                                        button {
                                            class: "hint-btn",
                                            onclick: move |_| show_hint.set(true),
                                            "Show Hint"
                                        }
                                    } else {
                                        div {}
                                    }

                                    if submitted() {
                                        button {
                                            class: "next-btn",
                                            onclick: move |_| {
                                                current_index.set(current_index() + 1);
                                                answer.set(String::new());
                                                selected_choice.set(None);
                                                submitted.set(false);
                                                grade_result.set(None);
                                                show_hint.set(false);
                                            },
                                            if current + 1 >= total_exercises {
                                                "Complete Module"
                                            } else {
                                                "Next Problem"
                                            }
                                        }
                                    } else {
                                        {
                                            let can_submit = match &challenge.answer {
                                                AnswerType::FreeForm { .. } => !answer.read().is_empty(),
                                                AnswerType::MultipleChoice { .. } => selected_choice().is_some(),
                                                AnswerType::Ambiguity { .. } => true,
                                            };
                                            let answer_clone = challenge.answer.clone();
                                            let ex_id = exercise_id.clone();
                                            let sentence_for_results = sentence.clone();
                                            let explanation_for_results = explanation_text.clone();
                                            rsx! {
                                                button {
                                                    class: "submit-btn",
                                                    disabled: !can_submit,
                                                    onclick: move |_| {
                                                        let is_correct = match &answer_clone {
                                                            AnswerType::FreeForm { golden_logic } => {
                                                                let result = check_answer(&answer.read(), golden_logic);
                                                                let correct = result.correct;
                                                                if result.correct {
                                                                    score.set(score() + 100);
                                                                } else if result.partial {
                                                                    score.set(score() + result.score);
                                                                }
                                                                grade_result.set(Some(result));
                                                                correct
                                                            }
                                                            AnswerType::MultipleChoice { correct_index, .. } => {
                                                                let correct = selected_choice() == Some(*correct_index);
                                                                let result = if correct {
                                                                    score.set(score() + 100);
                                                                    GradeResult {
                                                                        correct: true,
                                                                        partial: false,
                                                                        score: 100,
                                                                        feedback: "Correct!".to_string(),
                                                                    }
                                                                } else {
                                                                    GradeResult {
                                                                        correct: false,
                                                                        partial: false,
                                                                        score: 0,
                                                                        feedback: "Not quite.".to_string(),
                                                                    }
                                                                };
                                                                grade_result.set(Some(result));
                                                                correct
                                                            }
                                                            AnswerType::Ambiguity { .. } => {
                                                                grade_result.set(Some(GradeResult {
                                                                    correct: true,
                                                                    partial: false,
                                                                    score: 100,
                                                                    feedback: "Good analysis!".to_string(),
                                                                }));
                                                                score.set(score() + 100);
                                                                true
                                                            }
                                                        };

                                                        let is_first_try = !first_try_tracker.read().contains(&current);
                                                        first_try_tracker.write().insert(current);

                                                        {
                                                            let mut prog = progress.write();
                                                            prog.record_attempt(&ex_id, is_correct);

                                                            let cr = update_combo(&mut prog, is_correct);
                                                            combo_result.set(cr.clone());

                                                            if is_correct {
                                                                play_sound(SoundEffect::Correct);

                                                                let xp_mult = session_mode.xp_multiplier();
                                                                if xp_mult > 0.0 {
                                                                    let rng_seed = (prog.xp + current as u64) % 100;
                                                                    let mut reward = calculate_xp_reward(
                                                                        1,
                                                                        cr.new_combo,
                                                                        prog.streak_days,
                                                                        is_first_try,
                                                                        rng_seed,
                                                                    );

                                                                    reward.total = (reward.total as f64 * xp_mult) as u64;
                                                                    prog.xp += reward.total;
                                                                    prog.level = crate::progress::calculate_level(prog.xp);
                                                                    prog.save();

                                                                    current_xp_reward.set(Some(reward));
                                                                    show_xp_popup.set(true);

                                                                    let new_achievements = check_achievements(&prog);
                                                                    if let Some(achievement) = new_achievements.first() {
                                                                        current_achievement.set(Some(*achievement));
                                                                        show_achievement.set(true);
                                                                        unlock_achievement(&mut prog, achievement);
                                                                    }
                                                                }
                                                            } else {
                                                                play_sound(SoundEffect::Incorrect);
                                                                mistakes_in_module.set(mistakes_in_module() + 1);
                                                            }
                                                        }

                                                        if session_mode == SessionMode::Testing {
                                                            test_results.write().push((
                                                                current,
                                                                is_correct,
                                                                sentence_for_results.clone(),
                                                                explanation_for_results.clone(),
                                                            ));
                                                        }

                                                        submitted.set(true);
                                                    },
                                                    "Check Answer"
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    } else {
                        rsx! {
                            div { class: "problem-card",
                                p { "Loading exercises..." }
                            }
                        }
                    }
                }
            }
        }
    }
}

```

---

### Pages: Module

**File:** `src/ui/pages/mod.rs`

Page module exports for Home, Pricing, Workspace, Learn, Lesson, and Studio pages.

```rust
pub mod landing;
pub mod learn;
// Lesson and Review pages are deprecated - functionality moved to Learn page
// Keeping files for reference during Step 9 refactoring
// pub mod lesson;
// pub mod review;
pub mod pricing;
pub mod privacy;
pub mod registry;
pub mod roadmap;
pub mod success;
pub mod terms;
pub mod workspace;
pub mod studio;
pub mod guide;
pub mod profile;

pub use landing::Landing;
pub use learn::Learn;
pub use pricing::Pricing;
pub use privacy::Privacy;
pub use roadmap::Roadmap;
pub use success::Success;
pub use terms::Terms;
pub use workspace::Workspace;
pub use studio::Studio;
pub use guide::Guide;
pub use profile::Profile;

```

---

### Page: Pricing

**File:** `src/ui/pages/pricing.rs`

Commercial licensing information page with Fair Source explanation and enterprise contact details.

```rust
use dioxus::prelude::*;
use crate::ui::router::Route;
use crate::ui::components::main_nav::{MainNav, ActivePage};
use crate::ui::state::LicenseState;

const PRICING_STYLE: &str = r#"
* { box-sizing: border-box; }
a { color: inherit; }

.pricing {
  height: 100vh;
  color: var(--text-primary);
  background:
    radial-gradient(1200px 600px at 50% -120px, rgba(167,139,250,0.18), transparent 60%),
    radial-gradient(900px 500px at 15% 30%, rgba(96,165,250,0.18), transparent 60%),
    radial-gradient(800px 450px at 90% 45%, rgba(34,197,94,0.10), transparent 62%),
    linear-gradient(180deg, #070a12, #0b1022 55%, #070a12);
  overflow-x: hidden;
  overflow-y: auto;
  font-family: var(--font-sans);
  position: relative;
}

.bg-orb {
  position: absolute;
  inset: auto;
  width: 520px;
  height: 520px;
  border-radius: var(--radius-full);
  filter: blur(42px);
  opacity: 0.22;
  pointer-events: none;
  animation: float 14s ease-in-out infinite, pulse-glow 10s ease-in-out infinite;
}
.orb1 { top: -220px; left: -160px; background: radial-gradient(circle at 30% 30%, var(--color-accent-blue), transparent 60%); animation-delay: 0s; }
.orb2 { top: 120px; right: -200px; background: radial-gradient(circle at 40% 35%, var(--color-accent-purple), transparent 60%); animation-delay: -5s; }
.orb3 { bottom: -260px; left: 20%; background: radial-gradient(circle at 40% 35%, rgba(34,197,94,0.9), transparent 60%); animation-delay: -10s; }

@keyframes float {
  0%, 100% { transform: translate3d(0, 0, 0); }
  50% { transform: translate3d(0, -20px, 0); }
}

@keyframes pulse-glow {
  0%, 100% { opacity: 0.22; }
  50% { opacity: 0.32; }
}

@keyframes fadeInUp {
  from { opacity: 0; transform: translateY(24px); }
  to { opacity: 1; transform: translateY(0); }
}

.pricing-container {
  position: relative;
  display: flex;
  flex-direction: column;
  align-items: center;
  padding: 60px var(--spacing-xl);
  max-width: 1000px;
  margin: 0 auto;
}

.pricing-header {
  text-align: center;
  margin-bottom: 50px;
  animation: fadeInUp 0.6s ease both;
}

.pricing-header h1 {
  font-size: var(--font-display-lg);
  font-weight: 900;
  letter-spacing: -2px;
  background: linear-gradient(180deg, #ffffff 0%, rgba(229,231,235,0.78) 65%, rgba(229,231,235,0.62) 100%);
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
  margin-bottom: var(--spacing-lg);
}

.pricing-header p {
  color: var(--text-secondary);
  font-size: var(--font-body-lg);
  line-height: 1.65;
}

.pricing-tiers {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
  gap: var(--spacing-xl);
  width: 100%;
  margin-bottom: 40px;
}

.tier-card {
  position: relative;
  background: rgba(255,255,255,0.04);
  border: 1px solid rgba(255,255,255,0.10);
  border-radius: var(--radius-xl);
  padding: var(--spacing-xxl);
  display: flex;
  flex-direction: column;
  backdrop-filter: blur(18px);
  transition: transform 0.18s ease, border-color 0.18s ease, background 0.18s ease;
  overflow: hidden;
  animation: fadeInUp 0.6s ease both;
}

.tier-card:nth-child(1) { animation-delay: 0.1s; }
.tier-card:nth-child(2) { animation-delay: 0.15s; }
.tier-card:nth-child(3) { animation-delay: 0.2s; }
.tier-card:nth-child(4) { animation-delay: 0.25s; }
.tier-card:nth-child(5) { animation-delay: 0.3s; }

.tier-card::before {
  content: "";
  position: absolute;
  inset: 0;
  border-radius: var(--radius-xl);
  background: linear-gradient(135deg, rgba(96,165,250,0.12), rgba(167,139,250,0.12));
  opacity: 0;
  transition: opacity 0.3s ease;
  pointer-events: none;
}

.tier-card:hover {
  transform: translateY(-3px);
  border-color: rgba(167,139,250,0.28);
  background: rgba(255,255,255,0.06);
}

.tier-card:hover::before {
  opacity: 1;
}

.tier-card.supporter {
  border-color: rgba(167,139,250,0.35);
  background: linear-gradient(135deg, rgba(167,139,250,0.08) 0%, rgba(96,165,250,0.06) 100%);
}

.tier-card.disabled {
  opacity: 0.4;
  pointer-events: none;
  filter: grayscale(0.5);
}

.tier-card.disabled:hover {
  transform: none;
  border-color: rgba(255,255,255,0.10);
  background: rgba(255,255,255,0.04);
}

.tier-card.disabled::before {
  display: none;
}

.tier-card.disabled .btn-primary,
.tier-card.disabled .btn-secondary,
.tier-card.disabled .btn-contact {
  background: rgba(255,255,255,0.08);
  cursor: not-allowed;
  box-shadow: none;
}

.free-license-banner {
  position: relative;
  background: rgba(255,255,255,0.04);
  border: 1px solid rgba(255,255,255,0.10);
  border-radius: var(--radius-xl);
  padding: var(--spacing-xxl);
  margin-bottom: 40px;
  width: 100%;
  text-align: center;
  backdrop-filter: blur(18px);
  animation: fadeInUp 0.6s ease 0.05s both;
}

.free-license-banner.disabled {
  opacity: 0.4;
  pointer-events: none;
  filter: grayscale(0.5);
}

.free-license-banner h2 {
  color: var(--text-primary);
  font-size: var(--font-heading-lg);
  margin-bottom: var(--spacing-md);
  font-weight: 700;
}

.free-license-banner p {
  color: var(--text-secondary);
  margin-bottom: var(--spacing-xl);
  line-height: 1.65;
}

.free-license-banner .btn-free {
  display: inline-block;
  background: linear-gradient(135deg, rgba(96,165,250,0.95), rgba(167,139,250,0.95));
  color: #060814;
  padding: var(--spacing-md) var(--spacing-xxl);
  border-radius: var(--radius-lg);
  font-size: var(--font-body-md);
  font-weight: 650;
  text-decoration: none;
  transition: all 0.2s ease;
  box-shadow: 0 18px 40px rgba(96,165,250,0.18);
}

.free-license-banner .btn-free:hover {
  transform: translateY(-2px);
  box-shadow: 0 6px 20px rgba(96,165,250,0.4);
}

.tier-badge {
  display: inline-block;
  background: linear-gradient(135deg, var(--color-accent-blue), var(--color-accent-purple));
  color: #060814;
  font-size: var(--font-caption-md);
  font-weight: 700;
  padding: 5px var(--spacing-md);
  border-radius: var(--radius-full);
  margin-bottom: var(--spacing-lg);
  align-self: flex-start;
  text-transform: uppercase;
  letter-spacing: 0.5px;
}

.early-access-badge {
  display: inline-block;
  background: linear-gradient(135deg, var(--color-success), #16a34a);
  color: #060814;
  font-size: var(--font-caption-sm);
  font-weight: 700;
  padding: var(--spacing-xs) 10px;
  border-radius: var(--radius-full);
  margin-bottom: var(--spacing-md);
  align-self: flex-start;
  text-transform: uppercase;
  letter-spacing: 0.5px;
}

.coming-soon-badge {
  display: inline-block;
  background: rgba(255,255,255,0.12);
  color: var(--text-secondary);
  font-size: var(--font-caption-sm);
  font-weight: 700;
  padding: var(--spacing-xs) 10px;
  border-radius: var(--radius-full);
  margin-bottom: var(--spacing-md);
  align-self: flex-start;
  text-transform: uppercase;
  letter-spacing: 0.5px;
}

.tier-name {
  color: var(--text-primary);
  font-size: var(--font-heading-lg);
  font-weight: 700;
  margin-bottom: var(--spacing-sm);
}

.tier-revenue {
  color: var(--text-secondary);
  font-size: var(--font-caption-lg);
  margin-bottom: var(--spacing-xl);
}

.tier-price {
  margin-bottom: var(--spacing-sm);
}

.tier-price .amount {
  color: var(--text-primary);
  font-size: var(--font-display-md);
  font-weight: 800;
}

.tier-price .period {
  color: var(--text-secondary);
  font-size: var(--font-body-md);
}

.tier-annual {
  color: var(--color-accent-purple);
  font-size: var(--font-caption-lg);
  margin-bottom: var(--spacing-xl);
}

.tier-features {
  list-style: none;
  padding: 0;
  margin: 0 0 var(--spacing-xl) 0;
  flex-grow: 1;
}

.tier-features li {
  color: var(--text-secondary);
  font-size: var(--font-caption-lg);
  padding: var(--spacing-sm) 0;
  padding-left: var(--spacing-xl);
  position: relative;
  line-height: 1.5;
}

.tier-features li::before {
  content: "✓";
  position: absolute;
  left: 0;
  color: var(--color-accent-purple);
}

.tier-buttons {
  display: flex;
  flex-direction: column;
  gap: var(--spacing-md);
}

.btn-primary {
  display: block;
  background: linear-gradient(135deg, rgba(96,165,250,0.95), rgba(167,139,250,0.95));
  color: #060814;
  padding: var(--spacing-md) var(--spacing-xl);
  border-radius: var(--radius-lg);
  font-size: var(--font-body-md);
  font-weight: 650;
  text-decoration: none;
  text-align: center;
  transition: all 0.2s ease;
  box-shadow: 0 18px 40px rgba(96,165,250,0.18);
}

.btn-primary:hover {
  transform: translateY(-2px);
  box-shadow: 0 6px 20px rgba(96,165,250,0.4);
}

.btn-secondary {
  display: block;
  background: rgba(255,255,255,0.05);
  color: var(--color-accent-purple);
  padding: var(--spacing-md) var(--spacing-xl);
  border: 1px solid rgba(167,139,250,0.3);
  border-radius: var(--radius-lg);
  font-size: var(--font-caption-lg);
  font-weight: 600;
  text-decoration: none;
  text-align: center;
  transition: all 0.2s ease;
}

.btn-secondary:hover {
  background: rgba(167,139,250,0.1);
  border-color: rgba(167,139,250,0.5);
}

.btn-contact {
  display: block;
  background: rgba(255,255,255,0.06);
  color: var(--text-primary);
  padding: var(--spacing-md) var(--spacing-xl);
  border-radius: var(--radius-lg);
  border: 1px solid rgba(255,255,255,0.10);
  font-size: var(--font-body-md);
  font-weight: 600;
  text-decoration: none;
  text-align: center;
  transition: all 0.2s ease;
}

.btn-contact:hover {
  background: rgba(255,255,255,0.10);
  border-color: rgba(255,255,255,0.14);
}

.lifetime-section {
  position: relative;
  background: linear-gradient(135deg, rgba(167,139,250,0.12) 0%, rgba(96,165,250,0.08) 100%);
  border: 1px solid rgba(167,139,250,0.3);
  border-radius: var(--radius-xl);
  padding: 40px;
  text-align: center;
  width: 100%;
  margin-bottom: 40px;
  backdrop-filter: blur(18px);
  animation: fadeInUp 0.6s ease 0.1s both;
  overflow: hidden;
}

.lifetime-section::before {
  content: "";
  position: absolute;
  inset: 0;
  background: radial-gradient(600px 300px at 50% 0%, rgba(167,139,250,0.15), transparent 70%);
  pointer-events: none;
}

.lifetime-section h2 {
  position: relative;
  color: var(--text-primary);
  font-size: var(--font-heading-lg);
  font-weight: 700;
  margin-bottom: var(--spacing-md);
}

.lifetime-section .price {
  position: relative;
  color: var(--color-accent-purple);
  font-size: 42px;
  font-weight: 800;
  margin-bottom: var(--spacing-sm);
}

.lifetime-section .subtext {
  position: relative;
  color: var(--text-secondary);
  font-size: var(--font-caption-lg);
  margin-bottom: var(--spacing-xl);
}

.license-section {
  background: rgba(255,255,255,0.04);
  border: 1px solid rgba(255,255,255,0.10);
  border-radius: var(--radius-xl);
  padding: 40px;
  margin-bottom: 40px;
  width: 100%;
  backdrop-filter: blur(18px);
  animation: fadeInUp 0.6s ease 0.35s both;
}

.license-section h2 {
  color: var(--text-primary);
  font-size: var(--font-heading-lg);
  font-weight: 700;
  margin-bottom: var(--spacing-xl);
}

.license-section h3 {
  color: var(--color-accent-purple);
  font-size: var(--font-body-lg);
  font-weight: 600;
  margin: var(--spacing-xl) 0 var(--spacing-md) 0;
}

.license-section p {
  color: var(--text-secondary);
  line-height: 1.8;
  margin-bottom: var(--spacing-lg);
}

.license-section ul {
  color: var(--text-secondary);
  line-height: 1.8;
  margin-left: var(--spacing-xl);
  margin-bottom: var(--spacing-lg);
}

.license-section li {
  margin-bottom: var(--spacing-sm);
}

.manage-section {
  background: rgba(255,255,255,0.03);
  border: 1px solid rgba(255,255,255,0.10);
  border-radius: var(--radius-xl);
  padding: var(--spacing-xxl);
  text-align: center;
  width: 100%;
  margin-bottom: 40px;
  backdrop-filter: blur(18px);
  animation: fadeInUp 0.6s ease 0.3s both;
}

.manage-section p {
  color: var(--text-secondary);
  margin-bottom: var(--spacing-lg);
  line-height: 1.65;
}

.contact-section {
  background: linear-gradient(135deg, rgba(96,165,250,0.08) 0%, rgba(167,139,250,0.08) 100%);
  border: 1px solid rgba(167,139,250,0.25);
  border-radius: var(--radius-xl);
  padding: 40px;
  text-align: center;
  width: 100%;
  backdrop-filter: blur(18px);
  animation: fadeInUp 0.6s ease 0.4s both;
}

.contact-section h2 {
  color: var(--text-primary);
  font-size: var(--font-heading-lg);
  font-weight: 700;
  margin-bottom: var(--spacing-lg);
}

.contact-section p {
  color: var(--text-secondary);
  margin-bottom: var(--spacing-xl);
  line-height: 1.65;
}

.contact-links {
  display: flex;
  gap: var(--spacing-lg);
  justify-content: center;
  flex-wrap: wrap;
}

.contact-email {
  display: inline-block;
  background: linear-gradient(135deg, rgba(96,165,250,0.95), rgba(167,139,250,0.95));
  color: #060814;
  padding: var(--spacing-md) var(--spacing-xxl);
  border-radius: var(--radius-lg);
  font-size: var(--font-body-md);
  font-weight: 650;
  text-decoration: none;
  transition: all 0.2s ease;
  box-shadow: 0 18px 40px rgba(96,165,250,0.18);
}

.contact-email:hover {
  transform: translateY(-2px);
  box-shadow: 0 6px 20px rgba(96,165,250,0.4);
}

.back-link {
  margin-top: 40px;
  background: rgba(255,255,255,0.05);
  border: 1px solid rgba(255,255,255,0.10);
  border-radius: var(--radius-lg);
  padding: var(--spacing-md) var(--spacing-xl);
  color: var(--text-secondary);
  font-size: var(--font-body-sm);
  font-weight: 600;
  cursor: pointer;
  transition: all 0.2s ease;
}

.back-link:hover {
  background: rgba(255,255,255,0.08);
  color: var(--text-primary);
  border-color: rgba(255,255,255,0.14);
}

.pricing-footer-links {
  display: flex;
  gap: var(--spacing-md);
  align-items: center;
  margin-top: 40px;
}

.github-btn {
  display: flex;
  align-items: center;
  justify-content: center;
  gap: var(--spacing-sm);
  background: rgba(255,255,255,0.05);
  border: 1px solid rgba(255,255,255,0.10);
  border-radius: var(--radius-lg);
  padding: var(--spacing-md) var(--spacing-xl);
  color: var(--text-secondary);
  font-size: var(--font-body-sm);
  font-weight: 600;
  text-decoration: none;
  transition: all 0.2s ease;
}

.github-btn:hover {
  background: rgba(255,255,255,0.08);
  color: var(--text-primary);
  border-color: rgba(255,255,255,0.14);
}

.github-btn svg {
  width: 18px;
  height: 18px;
  fill: currentColor;
}

@media (max-width: 700px) {
  .pricing-header h1 {
    font-size: var(--font-display-md);
  }
  .pricing-tiers {
    grid-template-columns: 1fr;
  }
}

@media (prefers-reduced-motion: reduce) {
  * { transition: none !important; animation: none !important; }
}

.active-license-banner {
  position: relative;
  background: linear-gradient(135deg, rgba(34,197,94,0.15) 0%, rgba(96,165,250,0.10) 100%);
  border: 2px solid rgba(34,197,94,0.5);
  border-radius: var(--radius-xl);
  padding: var(--spacing-xxl);
  margin-bottom: 40px;
  width: 100%;
  text-align: center;
  backdrop-filter: blur(18px);
  animation: fadeInUp 0.6s ease both;
}

.active-license-banner h2 {
  color: var(--color-success);
  font-size: var(--font-heading-lg);
  margin-bottom: var(--spacing-md);
  font-weight: 700;
}

.active-license-banner .plan-badge {
  display: inline-block;
  background: linear-gradient(135deg, var(--color-success), #16a34a);
  color: #060814;
  font-size: var(--font-body-md);
  font-weight: 700;
  padding: var(--spacing-sm) var(--spacing-lg);
  border-radius: var(--radius-full);
  margin-bottom: var(--spacing-lg);
  text-transform: uppercase;
}

.active-license-banner p {
  color: var(--text-secondary);
  margin-bottom: var(--spacing-xl);
  line-height: 1.65;
}
"#;

const STRIPE_FREE_LICENSE: &str = "https://buy.stripe.com/9B63cx77ZgB5cKu40Ue3e06";
const STRIPE_SUPPORTER_MONTHLY: &str = "https://buy.stripe.com/5kQbJ33VN5Wr25Q8hae3e05";
const STRIPE_PRO_MONTHLY: &str = "https://buy.stripe.com/eVq00lgIzckPbGqcxqe3e03";
const STRIPE_PRO_ANNUAL: &str = "https://buy.stripe.com/4gM3cxakb0C76m69lee3e04";
const STRIPE_PREMIUM_MONTHLY: &str = "https://buy.stripe.com/dRm4gB9g73OjfWG2WQe3e01";
const STRIPE_PREMIUM_ANNUAL: &str = "https://buy.stripe.com/5kQ9AVcsjfx1h0K54Ye3e02";
const STRIPE_LIFETIME: &str = "https://buy.stripe.com/8x200l3VN98D7qa1SMe3e00";
const STRIPE_CUSTOMER_PORTAL: &str = "https://billing.stripe.com/p/login/8x200l3VN98D7qa1SMe3e00";

#[component]
pub fn Pricing() -> Element {
    let license_state = use_context::<LicenseState>();
    let has_license = license_state.has_license();
    let plan = license_state.plan.read().clone();

    let plan_name = match plan {
        crate::ui::state::LicensePlan::None => "None",
        crate::ui::state::LicensePlan::Free => "Free",
        crate::ui::state::LicensePlan::Supporter => "Supporter",
        crate::ui::state::LicensePlan::Pro => "Pro",
        crate::ui::state::LicensePlan::Premium => "Premium",
        crate::ui::state::LicensePlan::Lifetime => "Lifetime",
        crate::ui::state::LicensePlan::Enterprise => "Enterprise",
    };

    rsx! {
        style { "{PRICING_STYLE}" }

        div { class: "pricing",
            div { class: "bg-orb orb1" }
            div { class: "bg-orb orb2" }
            div { class: "bg-orb orb3" }

            MainNav { active: ActivePage::Pricing }

            div { class: "pricing-container",
                if has_license {
                    div { class: "active-license-banner",
                        h2 { "Active License" }
                        span { class: "plan-badge", "{plan_name}" }
                        p { "Thank you for supporting LOGOS! Manage your subscription below." }
                        a {
                            class: "btn-primary",
                            href: STRIPE_CUSTOMER_PORTAL,
                            target: "_blank",
                            "Manage Subscription"
                        }
                    }
                }

                div { class: "pricing-header",
                    h1 { "Commercial Licensing" }
                    p { "Business Source License — free for individuals and small teams" }
                }

                div { class: "free-license-banner disabled",
                    h2 { "Free for Small Teams" }
                    p {
                        "Individuals and organizations with fewer than 25 employees can use LOGOS at no cost. "
                        "Get a free license to track your usage and unlock all features."
                    }
                    a {
                        class: "btn-free",
                        href: STRIPE_FREE_LICENSE,
                        target: "_blank",
                        "Get Free License"
                    }
                }

                div { class: "lifetime-section",
                    span { class: "early-access-badge", "Early Access Pricing" }
                    h2 { "Lifetime License" }
                    div { class: "price", "$50/seat" }
                    div { class: "subtext", "One-time payment. Permanent license with Z3 Static Verification." }
                    a {
                        class: "btn-primary",
                        href: STRIPE_LIFETIME,
                        target: "_blank",
                        "Buy Lifetime License"
                    }
                }

                div { class: "pricing-tiers",
                    div { class: "tier-card supporter",
                        span { class: "early-access-badge", "Early Access Pricing" }
                        div { class: "tier-name", "Supporter" }
                        div { class: "tier-revenue", "For individuals and hobbyists" }
                        div { class: "tier-price",
                            span { class: "amount", "$5" }
                            span { class: "period", " /month" }
                        }
                        div { class: "tier-annual", "Optional - personal use is free" }
                        ul { class: "tier-features",
                            li { "Support LOGOS development" }
                            li { "Personal/hobbyist use" }
                            li { "Core feature access" }
                        }
                        div { class: "tier-buttons",
                            a {
                                class: "btn-primary",
                                href: STRIPE_SUPPORTER_MONTHLY,
                                target: "_blank",
                                "Become a Supporter"
                            }
                        }
                    }

                    div { class: "tier-card disabled",
                        span { class: "coming-soon-badge", "Coming Soon" }
                        div { class: "tier-name", "Pro" }
                        div { class: "tier-revenue", "For organizations with 25-100 employees" }
                        div { class: "tier-price",
                            span { class: "amount", "$25" }
                            span { class: "period", " /seat/month" }
                        }
                        div { class: "tier-annual", "or $240/seat/year (save 20%)" }
                        ul { class: "tier-features",
                            li { "Commercial use license" }
                            li { "Z3 Static Verification" }
                            li { "Full feature access" }
                            li { "Regular updates" }
                        }
                        div { class: "tier-buttons",
                            a {
                                class: "btn-primary",
                                href: STRIPE_PRO_MONTHLY,
                                target: "_blank",
                                "Subscribe Monthly"
                            }
                            a {
                                class: "btn-secondary",
                                href: STRIPE_PRO_ANNUAL,
                                target: "_blank",
                                "Subscribe Annually"
                            }
                        }
                    }

                    div { class: "tier-card disabled",
                        span { class: "coming-soon-badge", "Coming Soon" }
                        div { class: "tier-name", "Premium" }
                        div { class: "tier-revenue", "For organizations with 100-500 employees" }
                        div { class: "tier-price",
                            span { class: "amount", "$50" }
                            span { class: "period", " /seat/month" }
                        }
                        div { class: "tier-annual", "or $480/seat/year (save 20%)" }
                        ul { class: "tier-features",
                            li { "Everything in Pro" }
                            li { "Early access to new features" }
                            li { "Custom integrations" }
                        }
                        div { class: "tier-buttons",
                            a {
                                class: "btn-primary",
                                href: STRIPE_PREMIUM_MONTHLY,
                                target: "_blank",
                                "Subscribe Monthly"
                            }
                            a {
                                class: "btn-secondary",
                                href: STRIPE_PREMIUM_ANNUAL,
                                target: "_blank",
                                "Subscribe Annually"
                            }
                        }
                    }

                    div { class: "tier-card disabled",
                        span { class: "coming-soon-badge", "Coming Soon" }
                        div { class: "tier-name", "Enterprise" }
                        div { class: "tier-revenue", "For organizations with 500+ employees" }
                        div { class: "tier-price",
                            span { class: "amount", "Custom" }
                        }
                        div { class: "tier-annual", "Tailored to your needs" }
                        ul { class: "tier-features",
                            li { "Everything in Premium" }
                            li { "On-premise deployment options" }
                            li { "Volume discounts" }
                        }
                        div { class: "tier-buttons",
                            a {
                                class: "btn-contact",
                                href: "mailto:tristen@brahmastra-labs.com",
                                "Contact Sales"
                            }
                        }
                    }

                    div { class: "tier-card disabled",
                        span { class: "coming-soon-badge", "Coming Soon" }
                        div { class: "tier-name", "Support Plans" }
                        div { class: "tier-revenue", "Technical support available separately" }
                        div { class: "tier-price",
                            span { class: "amount", "Custom" }
                        }
                        div { class: "tier-annual", "Tailored to your needs" }
                        ul { class: "tier-features",
                            li { "Priority email support" }
                            li { "Dedicated support" }
                            li { "Custom SLAs" }
                            li { "Training and onboarding" }
                        }
                        div { class: "tier-buttons",
                            a {
                                class: "btn-contact",
                                href: "mailto:tristen@brahmastra-labs.com",
                                "Contact for Pricing"
                            }
                        }
                    }

                    div { class: "tier-card disabled",
                        span { class: "coming-soon-badge", "Coming Soon" }
                        div { class: "tier-name", "Semantic Tokenizer" }
                        div { class: "tier-revenue", "For AI model training" }
                        div { class: "tier-price",
                            span { class: "amount", "Custom" }
                        }
                        div { class: "tier-annual", "Contact us for pricing" }
                        ul { class: "tier-features",
                            li { "License for AI model training" }
                            li { "Commercial training data rights" }
                            li { "Custom volume pricing" }
                        }
                        div { class: "tier-buttons",
                            a {
                                class: "btn-contact",
                                href: "mailto:tristen@brahmastra-labs.com",
                                "Contact for Pricing"
                            }
                        }
                    }
                }

                if !has_license {
                    div { class: "manage-section",
                        p { "Already purchased a license? Access your subscription to update payment methods, view invoices, or download receipts." }
                        a {
                            class: "btn-secondary",
                            href: STRIPE_CUSTOMER_PORTAL,
                            target: "_blank",
                            "Manage Existing Subscription"
                        }
                    }
                }

                div { class: "license-section",
                    h2 { "Business Source License" }

                    p {
                        "LOGOS is released under the Business Source License 1.1. The source code is "
                        "publicly available, and the software is free to use for individuals and small teams."
                    }

                    h3 { "Free Use" }
                    p { "You may use LOGOS at no cost if you are:" }
                    ul {
                        li { "An individual" }
                        li { "An organization with fewer than 25 employees" }
                    }

                    h3 { "Commercial License Required" }
                    p {
                        "If your organization has 25 or more employees and you wish to use "
                        "LOGOS as a Logic Service, a commercial license is required. Select a tier above "
                        "based on your organization's size."
                    }

                    h3 { "Open Source Transition" }
                    p {
                        "On December 24, 2029, LOGOS will transition to the MIT License, "
                        "making it fully open source."
                    }
                }

                div { class: "contact-section",
                    h2 { "Get in Touch" }
                    p { "Questions about licensing, support contracts, or enterprise needs?" }
                    div { class: "contact-links",
                        a {
                            class: "contact-email",
                            href: "mailto:tristen@brahmastra-labs.com",
                            "Enterprise Sales"
                        }
                        a {
                            class: "contact-email",
                            href: "mailto:tristen@brahmastra-labs.com",
                            "Support Inquiries"
                        }
                    }
                }

                div { class: "pricing-footer-links",
                    a {
                        href: "https://github.com/Brahmastra-Labs/logicaffeine",
                        target: "_blank",
                        class: "github-btn",
                        svg {
                            xmlns: "http://www.w3.org/2000/svg",
                            view_box: "0 0 24 24",
                            path {
                                d: "M12 0C5.37 0 0 5.37 0 12c0 5.31 3.435 9.795 8.205 11.385.6.105.825-.255.825-.57 0-.285-.015-1.23-.015-2.235-3.015.555-3.795-.735-4.035-1.41-.135-.345-.72-1.41-1.23-1.695-.42-.225-1.02-.78-.015-.795.945-.015 1.62.87 1.845 1.23 1.08 1.815 2.805 1.305 3.495.99.105-.78.42-1.305.765-1.605-2.67-.3-5.46-1.335-5.46-5.925 0-1.305.465-2.385 1.23-3.225-.12-.3-.54-1.53.12-3.18 0 0 1.005-.315 3.3 1.23.96-.27 1.98-.405 3-.405s2.04.135 3 .405c2.295-1.56 3.3-1.23 3.3-1.23.66 1.65.24 2.88.12 3.18.765.84 1.23 1.905 1.23 3.225 0 4.605-2.805 5.625-5.475 5.925.435.375.81 1.095.81 2.22 0 1.605-.015 2.895-.015 3.3 0 .315.225.69.825.57A12.02 12.02 0 0024 12c0-6.63-5.37-12-12-12z"
                            }
                        }
                        "GitHub"
                    }
                    Link {
                        class: "back-link",
                        to: Route::Landing {},
                        "← Back"
                    }
                }
            }
        }
    }
}

```

---

### Page: privacy

**File:** `src/ui/pages/privacy.rs`

Application page component.

```rust
use dioxus::prelude::*;
use crate::ui::router::Route;
use crate::ui::components::main_nav::{MainNav, ActivePage};

const PRIVACY_HTML: &str = include_str!("../../../privacy.html");

const LEGAL_STYLE: &str = r#"
.legal-container {
    min-height: 100vh;
    display: flex;
    flex-direction: column;
    background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
}

.legal-content {
    flex: 1;
    max-width: 900px;
    margin: 0 auto;
    padding: 40px 20px 60px;
    width: 100%;
}

.legal-content-inner {
    background: rgba(255, 255, 255, 0.98);
    border-radius: 16px;
    padding: 40px;
    box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
}

.legal-footer {
    border-top: 1px solid rgba(255,255,255,0.06);
    padding: 24px 20px;
    text-align: center;
    color: rgba(229,231,235,0.56);
    font-size: 13px;
}

.legal-footer a {
    color: rgba(229,231,235,0.72);
    text-decoration: none;
    margin: 0 8px;
}

.legal-footer a:hover {
    color: #a78bfa;
}

.github-link {
    display: inline-flex;
    align-items: center;
    gap: 6px;
}
"#;

#[component]
pub fn Privacy() -> Element {
    rsx! {
        style { "{LEGAL_STYLE}" }

        div { class: "legal-container",
            MainNav { active: ActivePage::Other, subtitle: Some("Privacy Policy"), show_nav_links: false }

            main { class: "legal-content",
                div {
                    class: "legal-content-inner",
                    dangerous_inner_html: "{PRIVACY_HTML}"
                }
            }

            footer { class: "legal-footer",
                span { "© 2025 Brahmastra Labs LLC" }
                span { " • " }
                a {
                    href: "https://github.com/Brahmastra-Labs/logicaffeine",
                    target: "_blank",
                    class: "github-link",
                    svg {
                        xmlns: "http://www.w3.org/2000/svg",
                        width: "14",
                        height: "14",
                        view_box: "0 0 24 24",
                        fill: "currentColor",
                        path {
                            d: "M12 0C5.37 0 0 5.37 0 12c0 5.31 3.435 9.795 8.205 11.385.6.105.825-.255.825-.57 0-.285-.015-1.23-.015-2.235-3.015.555-3.795-.735-4.035-1.41-.135-.345-.72-1.41-1.23-1.695-.42-.225-1.02-.78-.015-.795.945-.015 1.62.87 1.845 1.23 1.08 1.815 2.805 1.305 3.495.99.105-.78.42-1.305.765-1.605-2.67-.3-5.46-1.335-5.46-5.925 0-1.305.465-2.385 1.23-3.225-.12-.3-.54-1.53.12-3.18 0 0 1.005-.315 3.3 1.23.96-.27 1.98-.405 3-.405s2.04.135 3 .405c2.295-1.56 3.3-1.23 3.3-1.23.66 1.65.24 2.88.12 3.18.765.84 1.23 1.905 1.23 3.225 0 4.605-2.805 5.625-5.475 5.925.435.375.81 1.095.81 2.22 0 1.605-.015 2.895-.015 3.3 0 .315.225.69.825.57A12.02 12.02 0 0024 12c0-6.63-5.37-12-12-12z"
                        }
                    }
                    "GitHub"
                }
                span { " • " }
                Link { to: Route::Privacy {}, "Privacy Policy" }
                span { " • " }
                Link { to: Route::Terms {}, "Terms of Use" }
            }
        }
    }
}

```

---

### Page: profile

**File:** `src/ui/pages/profile.rs`

Application page component.

```rust
//! User Profile page
//!
//! Displays user statistics, progress, and achievements.

use dioxus::prelude::*;
use crate::ui::components::main_nav::{MainNav, ActivePage};
use crate::progress::UserProgress;
use crate::content::ContentEngine;

const PROFILE_STYLE: &str = r#"
.profile-page {
    min-height: 100vh;
    color: var(--text-primary);
    background:
        radial-gradient(1200px 600px at 50% -120px, rgba(167,139,250,0.14), transparent 60%),
        radial-gradient(900px 500px at 15% 30%, rgba(96,165,250,0.14), transparent 60%),
        radial-gradient(800px 450px at 90% 45%, rgba(34,197,94,0.08), transparent 62%),
        linear-gradient(180deg, #070a12, #0b1022 55%, #070a12);
    font-family: var(--font-sans);
}

.profile-hero {
    max-width: 1000px;
    margin: 0 auto;
    padding: 60px var(--spacing-xl) 40px;
    text-align: center;
}

.profile-avatar {
    width: 100px;
    height: 100px;
    border-radius: 50%;
    background: linear-gradient(135deg, var(--color-accent-blue), var(--color-accent-purple));
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 48px;
    margin: 0 auto var(--spacing-lg);
    box-shadow: 0 8px 32px rgba(96, 165, 250, 0.3);
}

.profile-name {
    font-size: var(--font-heading-lg);
    font-weight: 900;
    margin-bottom: var(--spacing-sm);
    background: linear-gradient(180deg, #ffffff 0%, rgba(229,231,235,0.78) 65%);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
}

.profile-title {
    font-size: var(--font-body-lg);
    color: var(--color-accent-purple);
    font-weight: 600;
}

.profile-content {
    max-width: 1000px;
    margin: 0 auto;
    padding: 0 var(--spacing-xl) 80px;
}

.profile-stats {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
    gap: var(--spacing-lg);
    margin-bottom: var(--spacing-xxl);
}

.stat-card {
    background: rgba(255, 255, 255, 0.04);
    border: 1px solid rgba(255, 255, 255, 0.08);
    border-radius: var(--radius-xl);
    padding: var(--spacing-xl);
    text-align: center;
    transition: all 0.2s ease;
}

.stat-card:hover {
    background: rgba(255, 255, 255, 0.06);
    transform: translateY(-2px);
}

.stat-value {
    font-size: var(--font-display-md);
    font-weight: 900;
    background: linear-gradient(135deg, var(--color-accent-blue), var(--color-accent-purple));
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    margin-bottom: var(--spacing-xs);
}

.stat-value.xp {
    background: linear-gradient(135deg, #fbbf24, #f59e0b);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
}

.stat-value.streak {
    background: linear-gradient(135deg, #4ade80, #22c55e);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
}

.stat-value.level {
    background: linear-gradient(135deg, var(--color-accent-purple), #c084fc);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
}

.stat-label {
    font-size: var(--font-body-md);
    color: var(--text-secondary);
    font-weight: 500;
}

.profile-section {
    margin-bottom: var(--spacing-xxl);
}

.profile-section-title {
    font-size: var(--font-heading-sm);
    font-weight: 700;
    margin-bottom: var(--spacing-lg);
    display: flex;
    align-items: center;
    gap: var(--spacing-sm);
}

.progress-card {
    background: rgba(255, 255, 255, 0.04);
    border: 1px solid rgba(255, 255, 255, 0.08);
    border-radius: var(--radius-lg);
    padding: var(--spacing-lg);
    margin-bottom: var(--spacing-md);
}

.progress-era-name {
    font-weight: 600;
    color: var(--text-primary);
    margin-bottom: var(--spacing-sm);
}

.progress-bar-container {
    height: 8px;
    background: rgba(255, 255, 255, 0.08);
    border-radius: var(--radius-full);
    overflow: hidden;
    margin-bottom: var(--spacing-xs);
}

.progress-bar {
    height: 100%;
    background: linear-gradient(90deg, var(--color-accent-blue), var(--color-accent-purple));
    border-radius: var(--radius-full);
    transition: width 0.3s ease;
}

.progress-text {
    font-size: var(--font-caption-md);
    color: var(--text-tertiary);
}

.achievements-grid {
    display: grid;
    grid-template-columns: repeat(auto-fill, minmax(140px, 1fr));
    gap: var(--spacing-md);
}

.achievement-badge {
    background: rgba(255, 255, 255, 0.04);
    border: 1px solid rgba(255, 255, 255, 0.08);
    border-radius: var(--radius-lg);
    padding: var(--spacing-lg);
    text-align: center;
    transition: all 0.2s ease;
}

.achievement-badge:hover {
    background: rgba(255, 255, 255, 0.06);
    transform: scale(1.02);
}

.achievement-badge.locked {
    opacity: 0.4;
    filter: grayscale(100%);
}

.achievement-icon {
    font-size: 32px;
    margin-bottom: var(--spacing-sm);
}

.achievement-name {
    font-size: var(--font-caption-md);
    font-weight: 600;
    color: var(--text-primary);
}

.empty-state {
    text-align: center;
    padding: var(--spacing-xxl);
    color: var(--text-tertiary);
}
"#;

#[component]
pub fn Profile() -> Element {
    let progress = UserProgress::new(); // TODO: Load from storage
    let engine = ContentEngine::new();

    // Calculate totals
    let total_exercises: usize = engine.eras()
        .iter()
        .flat_map(|e| e.modules.iter())
        .map(|m| m.exercises.len())
        .sum();

    let completed_modules = progress.modules.values().filter(|m| m.completed).count();
    let total_modules: usize = engine.eras().iter().map(|e| e.modules.len()).sum();

    rsx! {
        style { "{PROFILE_STYLE}" }
        div { class: "profile-page",
            MainNav { active: ActivePage::Profile }

            // Hero section
            div { class: "profile-hero",
                div { class: "profile-avatar", "L" }
                h1 { class: "profile-name", "Logic Learner" }
                p { class: "profile-title",
                    if progress.title.is_some() {
                        "{progress.title.as_ref().unwrap()}"
                    } else {
                        "Apprentice Logician"
                    }
                }
            }

            // Content
            div { class: "profile-content",
                // Stats grid
                div { class: "profile-stats",
                    div { class: "stat-card",
                        div { class: "stat-value xp", "{progress.xp}" }
                        div { class: "stat-label", "Total XP" }
                    }
                    div { class: "stat-card",
                        div { class: "stat-value level", "Level {progress.level}" }
                        div { class: "stat-label", "Current Level" }
                    }
                    div { class: "stat-card",
                        div { class: "stat-value streak", "{progress.streak_days}" }
                        div { class: "stat-label", "Day Streak" }
                    }
                    div { class: "stat-card",
                        div { class: "stat-value", "{completed_modules}/{total_modules}" }
                        div { class: "stat-label", "Modules Completed" }
                    }
                }

                // Era Progress
                div { class: "profile-section",
                    h2 { class: "profile-section-title", "Progress by Era" }

                    for era in engine.eras() {
                        {
                            let era_modules = era.modules.len();
                            let era_completed = era.modules.iter()
                                .filter(|m| progress.modules.get(&m.meta.id).map_or(false, |p| p.completed))
                                .count();
                            let percent = if era_modules > 0 { (era_completed * 100) / era_modules } else { 0 };

                            rsx! {
                                div { class: "progress-card",
                                    div { class: "progress-era-name", "{era.meta.title}" }
                                    div { class: "progress-bar-container",
                                        div {
                                            class: "progress-bar",
                                            style: "width: {percent}%;",
                                        }
                                    }
                                    div { class: "progress-text", "{era_completed} of {era_modules} modules completed" }
                                }
                            }
                        }
                    }
                }

                // Achievements
                div { class: "profile-section",
                    h2 { class: "profile-section-title", "Achievements" }

                    if progress.achievements.is_empty() {
                        div { class: "empty-state",
                            p { "Complete modules and practice exercises to earn achievements!" }
                        }
                    } else {
                        div { class: "achievements-grid",
                            for achievement in progress.achievements.iter() {
                                div { class: "achievement-badge",
                                    div { class: "achievement-icon", "🏆" }
                                    div { class: "achievement-name", "{achievement}" }
                                }
                            }
                        }
                    }

                    // Show locked achievements
                    div { class: "achievements-grid", style: "margin-top: var(--spacing-lg);",
                        div { class: "achievement-badge locked",
                            div { class: "achievement-icon", "🎯" }
                            div { class: "achievement-name", "First Blood" }
                        }
                        div { class: "achievement-badge locked",
                            div { class: "achievement-icon", "🔥" }
                            div { class: "achievement-name", "7-Day Streak" }
                        }
                        div { class: "achievement-badge locked",
                            div { class: "achievement-icon", "💯" }
                            div { class: "achievement-name", "Perfect Score" }
                        }
                        div { class: "achievement-badge locked",
                            div { class: "achievement-icon", "🧠" }
                            div { class: "achievement-name", "Logic Master" }
                        }
                    }
                }
            }
        }
    }
}

```

---

### Page: review

**File:** `src/ui/pages/review.rs`

Application page component.

```rust
use dioxus::prelude::*;
use crate::ui::router::Route;
use crate::ui::components::mixed_text::MixedText;
use crate::ui::components::xp_popup::XpPopup;
use crate::ui::components::combo_indicator::ComboIndicator;
use crate::ui::components::streak_display::StreakDisplay;
use crate::ui::components::achievement_toast::AchievementToast;
use crate::ui::components::main_nav::{MainNav, ActivePage};
use crate::content::ContentEngine;
use crate::generator::{Generator, Challenge, AnswerType};
use crate::grader::{check_answer, GradeResult};
use crate::progress::UserProgress;
use crate::srs::{ResponseQuality, sm2_update, calculate_next_review, is_due};
use crate::game::{XpReward, ComboResult, StreakStatus, calculate_xp_reward, update_combo, update_streak};
use crate::achievements::{Achievement, check_achievements, unlock_achievement};
use crate::audio::{SoundEffect, play_sound};

const REVIEW_STYLE: &str = r#"
.review-container {
    min-height: 100vh;
    background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
    color: #e8e8e8;
    display: flex;
    flex-direction: column;
}

.review-header {
    padding: 16px 24px;
    background: rgba(0, 0, 0, 0.2);
    border-bottom: 1px solid rgba(255, 255, 255, 0.08);
    display: flex;
    justify-content: space-between;
    align-items: center;
}

.review-title {
    font-size: 20px;
    font-weight: 600;
    color: #a5b4fc;
}

.review-count {
    color: #888;
    font-size: 14px;
}

.review-stats {
    display: flex;
    align-items: center;
    gap: 16px;
}

.xp-display {
    color: #4ade80;
    font-weight: 600;
    font-size: 14px;
}

.combo-row {
    position: absolute;
    top: -40px;
    left: 50%;
    transform: translateX(-50%);
}

.review-main {
    flex: 1;
    display: flex;
    flex-direction: column;
    align-items: center;
    justify-content: center;
    padding: 40px 20px;
}

.review-card {
    background: rgba(255, 255, 255, 0.05);
    border: 1px solid rgba(255, 255, 255, 0.1);
    border-radius: 20px;
    padding: 40px;
    max-width: 700px;
    width: 100%;
    position: relative;
}

.review-prompt {
    color: #888;
    font-size: 14px;
    margin-bottom: 16px;
    text-transform: uppercase;
    letter-spacing: 1px;
}

.review-sentence {
    font-size: 28px;
    font-weight: 500;
    color: #fff;
    margin-bottom: 32px;
    line-height: 1.4;
}

.multiple-choice {
    display: flex;
    flex-direction: column;
    gap: 12px;
}

.choice-btn {
    padding: 16px 20px;
    background: rgba(255, 255, 255, 0.05);
    border: 2px solid rgba(255, 255, 255, 0.1);
    border-radius: 12px;
    color: #e8e8e8;
    font-size: 16px;
    text-align: left;
    cursor: pointer;
    transition: all 0.2s ease;
}

.choice-btn:hover {
    background: rgba(255, 255, 255, 0.08);
    border-color: #667eea;
}

.choice-btn.selected {
    background: rgba(102, 126, 234, 0.2);
    border-color: #667eea;
}

.choice-btn.correct {
    background: rgba(74, 222, 128, 0.2);
    border-color: #4ade80;
}

.choice-btn.incorrect {
    background: rgba(248, 113, 113, 0.2);
    border-color: #f87171;
}

.answer-input {
    width: 100%;
    padding: 16px 20px;
    font-size: 18px;
    font-family: 'SF Mono', 'Fira Code', monospace;
    background: rgba(255, 255, 255, 0.08);
    border: 2px solid rgba(255, 255, 255, 0.15);
    border-radius: 12px;
    color: #e8e8e8;
    outline: none;
}

.answer-input.correct {
    border-color: #4ade80;
    background: rgba(74, 222, 128, 0.1);
}

.answer-input.incorrect {
    border-color: #f87171;
    background: rgba(248, 113, 113, 0.1);
}

.feedback-box {
    margin-top: 20px;
    padding: 16px 20px;
    border-radius: 12px;
}

.feedback-correct {
    background: rgba(74, 222, 128, 0.15);
    border: 1px solid rgba(74, 222, 128, 0.3);
    color: #4ade80;
}

.feedback-incorrect {
    background: rgba(248, 113, 113, 0.15);
    border: 1px solid rgba(248, 113, 113, 0.3);
    color: #f87171;
}

.srs-buttons {
    display: flex;
    gap: 12px;
    margin-top: 24px;
    flex-wrap: wrap;
}

.srs-btn {
    padding: 12px 20px;
    border: 1px solid rgba(255, 255, 255, 0.2);
    border-radius: 8px;
    background: transparent;
    color: #e8e8e8;
    cursor: pointer;
    font-size: 14px;
    transition: all 0.2s ease;
}

.srs-btn:hover {
    background: rgba(255, 255, 255, 0.08);
}

.srs-btn.hard {
    border-color: rgba(248, 113, 113, 0.5);
    color: #f87171;
}

.srs-btn.good {
    border-color: rgba(251, 191, 36, 0.5);
    color: #fbbf24;
}

.srs-btn.easy {
    border-color: rgba(74, 222, 128, 0.5);
    color: #4ade80;
}

.action-row {
    display: flex;
    justify-content: flex-end;
    margin-top: 24px;
}

.submit-btn {
    padding: 12px 32px;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    border: none;
    border-radius: 8px;
    color: white;
    font-size: 16px;
    font-weight: 600;
    cursor: pointer;
}

.submit-btn:disabled {
    opacity: 0.5;
    cursor: not-allowed;
}

.empty-state {
    text-align: center;
    padding: 60px 40px;
}

.empty-state h2 {
    font-size: 28px;
    color: #4ade80;
    margin-bottom: 16px;
}

.empty-state p {
    color: #888;
    margin-bottom: 24px;
}

.back-btn {
    display: inline-block;
    padding: 12px 24px;
    background: linear-gradient(135deg, #667eea, #764ba2);
    border-radius: 8px;
    color: white;
    text-decoration: none;
}
"#;

#[component]
pub fn Review() -> Element {
    let mut current_index = use_signal(|| 0usize);
    let mut answer = use_signal(String::new);
    let mut selected_choice = use_signal(|| None::<usize>);
    let mut submitted = use_signal(|| false);
    let mut grade_result = use_signal(|| None::<GradeResult>);
    let mut due_challenges = use_signal(Vec::<(String, Challenge)>::new);
    let mut initialized = use_signal(|| false);
    let mut progress = use_signal(UserProgress::load);

    let mut show_xp_popup = use_signal(|| false);
    let mut current_xp_reward = use_signal(|| None::<XpReward>);
    let mut combo_result = use_signal(|| ComboResult { new_combo: 0, is_new_record: false, multiplier: 1.0 });
    let mut show_achievement = use_signal(|| false);
    let mut current_achievement = use_signal(|| None::<&'static Achievement>);
    let mut streak_status = use_signal(|| None::<StreakStatus>);
    let mut first_try_tracker = use_signal(|| std::collections::HashSet::<usize>::new());

    let engine = ContentEngine::new();
    let generator = Generator::new();

    if !initialized() {
        let today = get_today();

        {
            let mut prog = progress.write();
            let status = update_streak(&mut prog, &today);
            streak_status.set(Some(status.clone()));

            match &status {
                StreakStatus::Frozen => play_sound(SoundEffect::StreakSaved),
                StreakStatus::Lost { .. } => play_sound(SoundEffect::StreakLost),
                _ => {}
            }

            prog.save();
        }

        let user_progress = progress.read();
        let mut challenges = Vec::new();

        for era in engine.eras() {
            if let Some(era_data) = engine.get_era(&era.meta.id) {
                for module in &era_data.modules {
                    for exercise in &module.exercises {
                        let exercise_id = &exercise.id;
                        let srs_due = user_progress
                            .get_exercise_progress(exercise_id)
                            .map(|ep| is_due(ep.srs.next_review.as_deref(), &today))
                            .unwrap_or(true);

                        if srs_due {
                            let mut rng = rand::thread_rng();
                            if let Some(challenge) = generator.generate(exercise, &mut rng) {
                                challenges.push((exercise_id.clone(), challenge));
                            }
                        }
                    }
                }
            }
        }

        due_challenges.set(challenges);
        initialized.set(true);
    }

    let total_due = due_challenges.read().len();
    let current = current_index();

    let user_xp = progress.read().xp;
    let user_combo = progress.read().combo;
    let user_streak = progress.read().streak_days;
    let user_freezes = progress.read().streak_freezes;

    rsx! {
        style { "{REVIEW_STYLE}" }

        MainNav { active: ActivePage::Learn, subtitle: Some("Daily Review") }

        if show_xp_popup() {
            if let Some(reward) = current_xp_reward() {
                XpPopup {
                    reward: reward.clone(),
                    on_dismiss: move |_| show_xp_popup.set(false)
                }
            }
        }

        if show_achievement() {
            if let Some(achievement) = current_achievement() {
                AchievementToast {
                    achievement: achievement,
                    on_dismiss: move |_| show_achievement.set(false)
                }
            }
        }

        div { class: "review-container",
            header { class: "review-header",
                div {
                    span { class: "review-title", "Daily Review" }
                    span { class: "review-count",
                        if total_due > 0 {
                            " • {current + 1} of {total_due}"
                        } else {
                            ""
                        }
                    }
                }
                div { class: "review-stats",
                    if let Some(status) = streak_status() {
                        StreakDisplay {
                            streak: user_streak,
                            status: status,
                            freezes: user_freezes
                        }
                    }
                    span { class: "xp-display", "{user_xp} XP" }
                }
            }

            main { class: "review-main",
                {
                    let challenges_read = due_challenges.read();

                    if total_due == 0 {
                        rsx! {
                            div { class: "review-card empty-state",
                                h2 { "All caught up!" }
                                p { "No exercises are due for review right now." }
                                Link {
                                    class: "back-btn",
                                    to: Route::Landing {},
                                    "← Back to Home"
                                }
                            }
                        }
                    } else if current >= total_due {
                        rsx! {
                            div { class: "review-card empty-state",
                                h2 { "Review Complete!" }
                                p { "You reviewed {total_due} items." }
                                Link {
                                    class: "back-btn",
                                    to: Route::Landing {},
                                    "← Back to Home"
                                }
                            }
                        }
                    } else if let Some((exercise_id, challenge)) = challenges_read.get(current) {
                        let ex_id = exercise_id.clone();
                        let prompt = challenge.prompt.clone();
                        let sentence = challenge.sentence.clone();

                        let input_class = if submitted() {
                            if grade_result().map(|r| r.correct).unwrap_or(false) {
                                "answer-input correct"
                            } else {
                                "answer-input incorrect"
                            }
                        } else {
                            "answer-input"
                        };

                        rsx! {
                            div { class: "review-card",
                                if user_combo > 0 {
                                    div { class: "combo-row",
                                        ComboIndicator {
                                            combo: user_combo,
                                            multiplier: combo_result().multiplier,
                                            is_new_record: combo_result().is_new_record
                                        }
                                    }
                                }

                                div { class: "review-prompt", MixedText { content: prompt } }
                                div { class: "review-sentence", MixedText { content: sentence } }

                                {match &challenge.answer {
                                    AnswerType::FreeForm { .. } => rsx! {
                                        input {
                                            class: "{input_class}",
                                            r#type: "text",
                                            placeholder: "Enter your answer...",
                                            value: "{answer}",
                                            disabled: submitted(),
                                            oninput: move |e| answer.set(e.value()),
                                        }
                                    },
                                    AnswerType::MultipleChoice { options, correct_index } => {
                                        let correct_idx = *correct_index;
                                        let opts = options.clone();
                                        rsx! {
                                            div { class: "multiple-choice",
                                                for (i, option) in opts.iter().enumerate() {
                                                    {
                                                        let btn_class = if submitted() {
                                                            if i == correct_idx {
                                                                "choice-btn correct"
                                                            } else if selected_choice() == Some(i) {
                                                                "choice-btn incorrect"
                                                            } else {
                                                                "choice-btn"
                                                            }
                                                        } else if selected_choice() == Some(i) {
                                                            "choice-btn selected"
                                                        } else {
                                                            "choice-btn"
                                                        };
                                                        rsx! {
                                                            button {
                                                                class: "{btn_class}",
                                                                disabled: submitted(),
                                                                onclick: move |_| selected_choice.set(Some(i)),
                                                                MixedText { content: option.clone() }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    },
                                    AnswerType::Ambiguity { readings } => {
                                        let rds = readings.clone();
                                        rsx! {
                                            div { class: "reading-list",
                                                for reading in rds.iter() {
                                                    div { class: "reading-item", "{reading}" }
                                                }
                                            }
                                        }
                                    },
                                }}

                                if let Some(result) = grade_result() {
                                    {
                                        let fb_class = if result.correct {
                                            "feedback-box feedback-correct"
                                        } else {
                                            "feedback-box feedback-incorrect"
                                        };
                                        rsx! {
                                            div { class: "{fb_class}", "{result.feedback}" }
                                        }
                                    }
                                }

                                if submitted() {
                                    {
                                        let is_correct = grade_result().map(|r| r.correct).unwrap_or(false);
                                        let ex_id_clone = ex_id.clone();
                                        rsx! {
                                            div { class: "srs-buttons",
                                                button {
                                                    class: "srs-btn hard",
                                                    onclick: move |_| {
                                                        record_srs(&mut progress, &ex_id_clone, ResponseQuality::CorrectDifficult);
                                                        advance_review(&mut current_index, &mut answer, &mut selected_choice, &mut submitted, &mut grade_result);
                                                    },
                                                    "Hard"
                                                }
                                                button {
                                                    class: "srs-btn good",
                                                    onclick: move |_| {
                                                        let quality = if is_correct { ResponseQuality::CorrectHesitation } else { ResponseQuality::Incorrect };
                                                        record_srs(&mut progress, &ex_id, quality);
                                                        advance_review(&mut current_index, &mut answer, &mut selected_choice, &mut submitted, &mut grade_result);
                                                    },
                                                    if is_correct { "Good" } else { "Again" }
                                                }
                                                if is_correct {
                                                    button {
                                                        class: "srs-btn easy",
                                                        onclick: {
                                                            let ex_id_easy = ex_id.clone();
                                                            move |_| {
                                                                record_srs(&mut progress, &ex_id_easy, ResponseQuality::Perfect);
                                                                advance_review(&mut current_index, &mut answer, &mut selected_choice, &mut submitted, &mut grade_result);
                                                            }
                                                        },
                                                        "Easy"
                                                    }
                                                }
                                            }
                                        }
                                    }
                                } else {
                                    {
                                        let can_submit = match &challenge.answer {
                                            AnswerType::FreeForm { .. } => !answer.read().is_empty(),
                                            AnswerType::MultipleChoice { .. } => selected_choice().is_some(),
                                            AnswerType::Ambiguity { .. } => true,
                                        };
                                        let answer_clone = challenge.answer.clone();
                                        let ex_id_submit = ex_id.clone();
                                        rsx! {
                                            div { class: "action-row",
                                                button {
                                                    class: "submit-btn",
                                                    disabled: !can_submit,
                                                    onclick: move |_| {
                                                        let is_correct = match &answer_clone {
                                                            AnswerType::FreeForm { golden_logic } => {
                                                                let result = check_answer(&answer.read(), golden_logic);
                                                                let correct = result.correct;
                                                                grade_result.set(Some(result));
                                                                correct
                                                            }
                                                            AnswerType::MultipleChoice { correct_index, .. } => {
                                                                let correct = selected_choice() == Some(*correct_index);
                                                                let result = if correct {
                                                                    GradeResult {
                                                                        correct: true,
                                                                        partial: false,
                                                                        score: 100,
                                                                        feedback: "Correct!".to_string(),
                                                                    }
                                                                } else {
                                                                    GradeResult {
                                                                        correct: false,
                                                                        partial: false,
                                                                        score: 0,
                                                                        feedback: "Not quite.".to_string(),
                                                                    }
                                                                };
                                                                grade_result.set(Some(result));
                                                                correct
                                                            }
                                                            AnswerType::Ambiguity { .. } => {
                                                                grade_result.set(Some(GradeResult {
                                                                    correct: true,
                                                                    partial: false,
                                                                    score: 100,
                                                                    feedback: "Good analysis!".to_string(),
                                                                }));
                                                                true
                                                            }
                                                        };

                                                        let is_first_try = !first_try_tracker.read().contains(&current);
                                                        first_try_tracker.write().insert(current);

                                                        {
                                                            let mut prog = progress.write();
                                                            prog.record_attempt(&ex_id_submit, is_correct);

                                                            let cr = update_combo(&mut prog, is_correct);
                                                            combo_result.set(cr.clone());

                                                            if is_correct {
                                                                play_sound(SoundEffect::Correct);

                                                                let rng_seed = (prog.xp + current as u64) % 100;
                                                                let reward = calculate_xp_reward(
                                                                    1,
                                                                    cr.new_combo,
                                                                    prog.streak_days,
                                                                    is_first_try,
                                                                    rng_seed,
                                                                );

                                                                prog.xp += reward.total;
                                                                prog.level = crate::progress::calculate_level(prog.xp);
                                                                prog.save();

                                                                current_xp_reward.set(Some(reward));
                                                                show_xp_popup.set(true);

                                                                let new_achievements = check_achievements(&prog);
                                                                if let Some(achievement) = new_achievements.first() {
                                                                    current_achievement.set(Some(*achievement));
                                                                    show_achievement.set(true);
                                                                    unlock_achievement(&mut prog, achievement);
                                                                }
                                                            } else {
                                                                play_sound(SoundEffect::Incorrect);
                                                            }
                                                        }

                                                        submitted.set(true);
                                                    },
                                                    "Check Answer"
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    } else {
                        rsx! {
                            div { class: "review-card",
                                p { "Loading..." }
                            }
                        }
                    }
                }
            }
        }
    }
}

fn record_srs(progress: &mut Signal<UserProgress>, exercise_id: &str, quality: ResponseQuality) {
    let today = get_today();
    let mut user_progress = progress.write();

    user_progress.record_attempt(exercise_id, quality.is_correct());

    if let Some(ep) = user_progress.exercises.get_mut(exercise_id) {
        sm2_update(&mut ep.srs, quality);
        ep.srs.next_review = Some(calculate_next_review(&today, ep.srs.interval));
    }

    user_progress.save();
}

fn advance_review(
    current_index: &mut Signal<usize>,
    answer: &mut Signal<String>,
    selected_choice: &mut Signal<Option<usize>>,
    submitted: &mut Signal<bool>,
    grade_result: &mut Signal<Option<GradeResult>>,
) {
    current_index.set(current_index() + 1);
    answer.set(String::new());
    selected_choice.set(None);
    submitted.set(false);
    grade_result.set(None);
}

fn get_today() -> String {
    #[cfg(target_arch = "wasm32")]
    {
        use wasm_bindgen::prelude::*;

        #[wasm_bindgen]
        extern "C" {
            #[wasm_bindgen(js_namespace = Date, js_name = now)]
            fn date_now() -> f64;
        }

        let ms = date_now() as i64;
        let days_since_epoch = ms / 86400000;
        let year = 1970 + (days_since_epoch / 365) as i32;
        let day_of_year = (days_since_epoch % 365) as i32;
        let month = (day_of_year / 30).min(11) + 1;
        let day = (day_of_year % 30) + 1;
        format!("{:04}-{:02}-{:02}", year, month, day)
    }

    #[cfg(not(target_arch = "wasm32"))]
    {
        "2025-01-01".to_string()
    }
}

```

---

### Page: roadmap

**File:** `src/ui/pages/roadmap.rs`

Application page component.

```rust
use dioxus::prelude::*;
use crate::ui::router::Route;
use crate::ui::components::main_nav::{MainNav, ActivePage};

// (label, english, simple_fol, unicode)
const MILESTONE_EXAMPLES: &[&[(&str, &str, &str, &str)]] = &[
    // Phase 1: Core Transpiler
    &[
        ("Universal", "Every user who has a key enters the room.",
            "For all x: User(x) and HasKey(x) implies Enter(x, Room)",
            "∀x((User(x) ∧ HasKey(x)) → Enter(x, Room))"),
        ("Conditional", "If a user enters the room, the alarm triggers.",
            "Enter(User, Room) implies Trigger(Alarm)",
            "(Enter(User, Room) → Trigger(Alarm))"),
        ("Negation", "No user who lacks a key can enter.",
            "For all x: User(x) and LacksKey(x) implies not Enter(x)",
            "∀x((User(x) ∧ LacksKey(x)) → ¬Enter(x))"),
    ],
    // Phase 2: Web Platform
    &[
        ("Interactive", "Check that the answer equals expected.",
            "Assert: answer equals expected",
            "Assert(Eq(answer, expected))"),
        ("Feedback", "Show the hint to the learner.",
            "Display hint to learner",
            "Display(hint, learner)"),
    ],
    // Phase 3: Imperative Language
    &[
        ("Function", "## To greet (name: Text) -> Text:\n    Return \"Hello, \" combined with name.",
            "fn greet(name: &str) -> String { ... }",
            "fn greet(name: &str) -> String {\n    format!(\"Hello, {}\", name)\n}"),
        ("Struct", "A Point has:\n    an x which is Int\n    a y which is Int",
            "struct Point { x: i64, y: i64 }",
            "struct Point {\n    x: i64,\n    y: i64,\n}"),
        ("I/O", "Read input from the console.\nShow \"Hello!\" to the console.",
            "read_line(); println!(\"Hello!\");",
            "io::stdin().read_line(&mut buf)?;\nprintln!(\"Hello!\");"),
    ],
    // Phase 4: Type System
    &[
        ("Refinement", "Let age be an Int where it > 0.",
            "let age: PosInt = 25; // runtime check",
            "let age = 25;\ndebug_assert!(age > 0);"),
        ("Generic", "A Box has: a contents which is Generic.",
            "struct Box<T> { contents: T }",
            "struct Box<T> {\n    contents: T,\n}"),
        ("Enum", "A Color is one of: Red, Green, Blue.",
            "enum Color { Red, Green, Blue }",
            "enum Color {\n    Red,\n    Green,\n    Blue,\n}"),
    ],
    // Phase 5: Concurrency
    &[
        ("Channel", "Let pipe be a new Pipe of Int.\nSend 42 into pipe.",
            "let (tx, rx) = channel(); tx.send(42);",
            "let (tx, rx) = channel::<i64>();\ntx.send(42).await;"),
        ("Agent", "Spawn a Worker called 'w1'.\nSend Ping to 'w1'.",
            "spawn(Worker, \"w1\"); send(Ping, \"w1\");",
            "let w1 = tokio::spawn(worker());\ntx.send(Ping).await;"),
        ("Parallel", "Attempt all of the following:\n    Process A.\n    Process B.",
            "join!(process_a(), process_b())",
            "tokio::join!(\n    process_a(),\n    process_b()\n);"),
    ],
    // Phase 6: Distributed Systems
    &[
        ("CRDT", "Let counter be a new Shared GCounter.\nIncrease counter by 10.",
            "let counter = GCounter::new();\ncounter.increment(10);",
            "let counter = GCounter::new();\ncounter.increment_by(self_id, 10);"),
        ("Persist", "Mount data at \"state.json\".",
            "Persistent::mount(\"state.json\")",
            "let data = Persistent::<T>::mount(\"state.json\").await?;"),
        ("Sync", "Sync counter on 'metrics'.",
            "gossip.sync(counter, \"metrics\")",
            "gossip.subscribe(\"metrics\");\ngossip.publish(counter);"),
    ],
    // Phase 7: Security
    &[
        ("Policy", "## Policy\nA User can publish the Document if user's role equals \"editor\".",
            "fn can_publish(user, doc) -> bool",
            "impl User {\n    fn can_publish(&self, _: &Document) -> bool {\n        self.role == \"editor\"\n    }\n}"),
        ("Check", "Check that user can publish the doc.",
            "check!(user.can_publish(doc))",
            "if !user.can_publish(&doc) {\n    panic!(\"unauthorized\");\n}"),
    ],
    // Phase 8: Proof Assistant
    &[
        ("Trust", "Trust that n > 0 because \"positive input\".",
            "// @requires n > 0",
            "debug_assert!(n > 0, \"positive input\");"),
        ("Termination", "While n > 0 (decreasing n):\n    Set n to n minus 1.",
            "while n > 0 { n -= 1; } // terminates",
            "// Proven: metric 'n' decreases each iteration\nwhile n > 0 { n -= 1; }"),
    ],
    // Phase 9: Universal Compilation
    &[
        ("WASM", "Compile for the web.",
            "largo build --target wasm",
            "// Coming soon: direct LOGOS → WASM"),
        ("IDE", "Open the Live Codex.",
            "largo codex",
            "// Coming soon: real-time proof visualization"),
    ],
];

const ROADMAP_STYLE: &str = r#"
.roadmap-container {
    min-height: 100vh;
    background: linear-gradient(135deg, #070a12 0%, #0b1022 50%, #070a12 100%);
    color: #e5e7eb;
    font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, sans-serif;
}

.roadmap-nav {
    position: sticky;
    top: 0;
    z-index: 50;
    backdrop-filter: blur(18px);
    background: linear-gradient(180deg, rgba(7,10,18,0.72), rgba(7,10,18,0.44));
    border-bottom: 1px solid rgba(255,255,255,0.06);
    padding: 16px 20px;
}

.roadmap-nav-inner {
    max-width: 1000px;
    margin: 0 auto;
    display: flex;
    align-items: center;
    justify-content: space-between;
}

.roadmap-brand {
    display: flex;
    align-items: center;
    gap: 12px;
    text-decoration: none;
    color: #e5e7eb;
}

.roadmap-logo {
    width: 36px;
    height: 36px;
    border-radius: 12px;
    background:
        radial-gradient(circle at 30% 30%, rgba(96,165,250,0.85), transparent 55%),
        radial-gradient(circle at 65% 60%, rgba(167,139,250,0.85), transparent 55%),
        rgba(255,255,255,0.06);
    border: 1px solid rgba(255,255,255,0.10);
}

.roadmap-brand-name {
    font-weight: 800;
    font-size: 14px;
    letter-spacing: -0.5px;
}

.roadmap-back {
    color: #a78bfa;
    text-decoration: none;
    font-size: 14px;
    padding: 8px 16px;
    border-radius: 8px;
    border: 1px solid rgba(167,139,250,0.3);
    transition: all 0.2s ease;
}

.roadmap-back:hover {
    background: rgba(167,139,250,0.1);
    border-color: rgba(167,139,250,0.5);
}

.roadmap-hero {
    text-align: center;
    padding: 60px 20px 40px;
    max-width: 800px;
    margin: 0 auto;
}

.roadmap-hero h1 {
    font-size: 42px;
    font-weight: 800;
    letter-spacing: -1px;
    background: linear-gradient(180deg, #ffffff 0%, rgba(229,231,235,0.78) 100%);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    margin-bottom: 12px;
}

.roadmap-hero .version {
    display: inline-block;
    font-size: 14px;
    padding: 6px 14px;
    border-radius: 20px;
    background: rgba(167,139,250,0.15);
    border: 1px solid rgba(167,139,250,0.3);
    color: #a78bfa;
    margin-bottom: 16px;
}

.roadmap-hero p {
    color: rgba(229,231,235,0.72);
    font-size: 18px;
    line-height: 1.6;
}

.timeline {
    max-width: 700px;
    margin: 0 auto;
    padding: 0 20px 80px;
    position: relative;
}

.timeline::before {
    content: "";
    position: absolute;
    left: 28px;
    top: 0;
    bottom: 80px;
    width: 3px;
    background: linear-gradient(
        180deg,
        #22c55e 0%,
        #22c55e 76%,
        #a78bfa 80%,
        #a78bfa 88%,
        rgba(255,255,255,0.15) 92%,
        rgba(255,255,255,0.08) 100%
    );
    border-radius: 2px;
}

.milestone {
    position: relative;
    padding-left: 70px;
    margin-bottom: 40px;
}

.milestone-dot {
    position: absolute;
    left: 16px;
    top: 4px;
    width: 24px;
    height: 24px;
    border-radius: 50%;
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 12px;
    font-weight: 600;
}

.milestone-dot.done {
    background: linear-gradient(135deg, #22c55e, #16a34a);
    box-shadow: 0 0 20px rgba(34,197,94,0.4);
}

.milestone-dot.progress {
    background: linear-gradient(135deg, #a78bfa, #8b5cf6);
    box-shadow: 0 0 20px rgba(167,139,250,0.4);
    animation: pulse 2s ease-in-out infinite;
}

.milestone-dot.planned {
    background: rgba(255,255,255,0.1);
    border: 2px solid rgba(255,255,255,0.2);
}

@keyframes pulse {
    0%, 100% { transform: scale(1); }
    50% { transform: scale(1.1); }
}

.milestone-content {
    background: rgba(255,255,255,0.03);
    border: 1px solid rgba(255,255,255,0.08);
    border-radius: 16px;
    padding: 24px;
    transition: all 0.2s ease;
}

.milestone-content:hover {
    background: rgba(255,255,255,0.05);
    border-color: rgba(255,255,255,0.12);
}

.milestone-header {
    display: flex;
    align-items: center;
    gap: 12px;
    margin-bottom: 12px;
}

.milestone-title {
    font-size: 20px;
    font-weight: 700;
    color: #fff;
}

.milestone-badge {
    font-size: 11px;
    font-weight: 600;
    padding: 4px 10px;
    border-radius: 12px;
    text-transform: uppercase;
    letter-spacing: 0.5px;
}

.milestone-badge.done {
    background: rgba(34,197,94,0.15);
    color: #22c55e;
    border: 1px solid rgba(34,197,94,0.3);
}

.milestone-badge.progress {
    background: rgba(167,139,250,0.15);
    color: #a78bfa;
    border: 1px solid rgba(167,139,250,0.3);
}

.milestone-badge.planned {
    background: rgba(255,255,255,0.05);
    color: rgba(255,255,255,0.5);
    border: 1px solid rgba(255,255,255,0.1);
}

.milestone-desc {
    color: rgba(229,231,235,0.72);
    font-size: 14px;
    line-height: 1.6;
    margin-bottom: 16px;
}

.milestone-features {
    display: flex;
    flex-wrap: wrap;
    gap: 8px;
}

.feature-tag {
    font-size: 12px;
    padding: 6px 12px;
    border-radius: 8px;
    background: rgba(255,255,255,0.04);
    border: 1px solid rgba(255,255,255,0.08);
    color: rgba(229,231,235,0.8);
}

.feature-tag.done {
    background: rgba(34,197,94,0.08);
    border-color: rgba(34,197,94,0.2);
    color: #86efac;
}

.roadmap-footer {
    border-top: 1px solid rgba(255,255,255,0.06);
    padding: 24px 20px;
    text-align: center;
    color: rgba(229,231,235,0.56);
    font-size: 13px;
}

.roadmap-footer a {
    color: rgba(229,231,235,0.72);
    text-decoration: none;
    margin: 0 8px;
}

.roadmap-footer a:hover {
    color: #a78bfa;
}

.roadmap-nav-links {
    display: flex;
    align-items: center;
    gap: 12px;
}

.roadmap-github {
    display: flex;
    align-items: center;
    justify-content: center;
    width: 36px;
    height: 36px;
    border-radius: 8px;
    border: 1px solid rgba(255,255,255,0.1);
    background: rgba(255,255,255,0.03);
    color: rgba(229,231,235,0.72);
    transition: all 0.2s ease;
}

.roadmap-github:hover {
    background: rgba(255,255,255,0.08);
    color: #e5e7eb;
    border-color: rgba(255,255,255,0.2);
}

.roadmap-github svg {
    width: 18px;
    height: 18px;
    fill: currentColor;
}

.github-link {
    display: inline-flex;
    align-items: center;
    gap: 6px;
}

@media (max-width: 600px) {
    .timeline::before {
        left: 18px;
    }
    .milestone {
        padding-left: 50px;
    }
    .milestone-dot {
        left: 6px;
        width: 20px;
        height: 20px;
    }
    .milestone-title {
        font-size: 18px;
    }
}

.milestone-examples {
    margin-top: 16px;
    border-top: 1px solid rgba(255,255,255,0.06);
    padding-top: 16px;
}

.milestone-tabs {
    display: flex;
    gap: 6px;
    margin-bottom: 12px;
    flex-wrap: wrap;
}

.milestone-tab {
    padding: 6px 12px;
    border-radius: 6px;
    border: 1px solid rgba(255,255,255,0.1);
    background: rgba(255,255,255,0.03);
    color: #94a3b8;
    cursor: pointer;
    font-size: 12px;
    font-weight: 500;
    transition: all 0.2s ease;
}

.milestone-tab:hover {
    background: rgba(255,255,255,0.08);
    color: #e8e8e8;
}

.milestone-tab.active {
    background: linear-gradient(135deg, #667eea, #764ba2);
    color: white;
    border-color: transparent;
}

.milestone-code {
    background: rgba(0,0,0,0.25);
    border-radius: 8px;
    padding: 16px;
    font-family: 'SF Mono', 'Fira Code', 'Consolas', monospace;
    font-size: 13px;
}

.milestone-english {
    color: #e8e8e8;
    font-style: italic;
    margin-bottom: 8px;
    white-space: pre-wrap;
    line-height: 1.5;
}

.milestone-arrow {
    color: #667eea;
    margin: 8px 0;
    font-size: 16px;
}

.milestone-output {
    color: #98c379;
    white-space: pre-wrap;
    line-height: 1.4;
}

.format-toggle {
    display: flex;
    gap: 4px;
    margin-bottom: 8px;
}

.format-btn {
    padding: 3px 8px;
    border-radius: 4px;
    border: 1px solid rgba(255,255,255,0.1);
    background: rgba(255,255,255,0.03);
    color: #64748b;
    cursor: pointer;
    font-size: 10px;
    font-weight: 500;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    transition: all 0.15s ease;
}

.format-btn:hover {
    background: rgba(255,255,255,0.06);
    color: #94a3b8;
}

.format-btn.active {
    background: rgba(102,126,234,0.2);
    border-color: rgba(102,126,234,0.4);
    color: #a5b4fc;
}
"#;

#[component]
fn MilestoneExamples(index: usize) -> Element {
    let mut active = use_signal(|| 0usize);
    let mut use_unicode = use_signal(|| false);
    let examples = MILESTONE_EXAMPLES[index];

    rsx! {
        div { class: "milestone-examples",
            div { class: "milestone-tabs",
                for (i, (label, _, _, _)) in examples.iter().enumerate() {
                    button {
                        key: "{i}",
                        class: if active() == i { "milestone-tab active" } else { "milestone-tab" },
                        onclick: move |_| active.set(i),
                        "{label}"
                    }
                }
            }
            div { class: "milestone-code",
                div { class: "milestone-english", "\"{examples[active()].1}\"" }
                div { class: "milestone-arrow", "↓" }
                div { class: "format-toggle",
                    button {
                        class: if !use_unicode() { "format-btn active" } else { "format-btn" },
                        onclick: move |_| use_unicode.set(false),
                        "Simple"
                    }
                    button {
                        class: if use_unicode() { "format-btn active" } else { "format-btn" },
                        onclick: move |_| use_unicode.set(true),
                        "Unicode"
                    }
                }
                div { class: "milestone-output",
                    if use_unicode() {
                        "{examples[active()].3}"
                    } else {
                        "{examples[active()].2}"
                    }
                }
            }
        }
    }
}

#[component]
pub fn Roadmap() -> Element {
    rsx! {
        style { "{ROADMAP_STYLE}" }

        div { class: "roadmap-container",
            MainNav { active: ActivePage::Roadmap }

            section { class: "roadmap-hero",
                h1 { "LOGOS Roadmap" }
                p { "From English sentences to distributed systems. A complete programming language with formal verification." }
            }

            div { class: "timeline",
                // Phase 1: Core Transpiler - DONE
                div { class: "milestone",
                    div { class: "milestone-dot done", "✓" }
                    div { class: "milestone-content",
                        div { class: "milestone-header",
                            span { class: "milestone-title", "Core Transpiler" }
                            span { class: "milestone-badge done", "Complete" }
                        }
                        p { class: "milestone-desc",
                            "The foundation: parse English, produce First-Order Logic. 53+ linguistic phenomena from garden paths to discourse."
                        }
                        div { class: "milestone-features",
                            span { class: "feature-tag done", "Lexer" }
                            span { class: "feature-tag done", "Parser" }
                            span { class: "feature-tag done", "AST" }
                            span { class: "feature-tag done", "Transpiler" }
                            span { class: "feature-tag done", "Quantifiers" }
                            span { class: "feature-tag done", "Modals" }
                            span { class: "feature-tag done", "Aspect/Tense" }
                        }
                        MilestoneExamples { index: 0 }
                    }
                }

                // Phase 2: Web Platform - DONE
                div { class: "milestone",
                    div { class: "milestone-dot done", "✓" }
                    div { class: "milestone-content",
                        div { class: "milestone-header",
                            span { class: "milestone-title", "Web Platform" }
                            span { class: "milestone-badge done", "Complete" }
                        }
                        p { class: "milestone-desc",
                            "Learn logic interactively. Structured curriculum, free-form studio, and gamification to keep you engaged."
                        }
                        div { class: "milestone-features",
                            span { class: "feature-tag done", "Dioxus WASM" }
                            span { class: "feature-tag done", "Learn Mode" }
                            span { class: "feature-tag done", "Studio" }
                            span { class: "feature-tag done", "Achievements" }
                            span { class: "feature-tag done", "Streaks" }
                        }
                        MilestoneExamples { index: 1 }
                    }
                }

                // Phase 3: Imperative Language - DONE
                div { class: "milestone",
                    div { class: "milestone-dot done", "✓" }
                    div { class: "milestone-content",
                        div { class: "milestone-header",
                            span { class: "milestone-title", "Imperative Language" }
                            span { class: "milestone-badge done", "Complete" }
                        }
                        p { class: "milestone-desc",
                            "A complete programming language. Functions, structs, enums, pattern matching, standard library, and I/O."
                        }
                        div { class: "milestone-features",
                            span { class: "feature-tag done", "Functions" }
                            span { class: "feature-tag done", "Structs" }
                            span { class: "feature-tag done", "Enums" }
                            span { class: "feature-tag done", "Pattern Matching" }
                            span { class: "feature-tag done", "Stdlib" }
                            span { class: "feature-tag done", "I/O" }
                        }
                        MilestoneExamples { index: 2 }
                    }
                }

                // Phase 4: Type System - DONE
                div { class: "milestone",
                    div { class: "milestone-dot done", "✓" }
                    div { class: "milestone-content",
                        div { class: "milestone-header",
                            span { class: "milestone-title", "Type System" }
                            span { class: "milestone-badge done", "Complete" }
                        }
                        p { class: "milestone-desc",
                            "Refinement types, generics, and type inference. Catch bugs at compile time with English type syntax."
                        }
                        div { class: "milestone-features",
                            span { class: "feature-tag done", "Refinement Types" }
                            span { class: "feature-tag done", "Generics" }
                            span { class: "feature-tag done", "Type Inference" }
                            span { class: "feature-tag done", "Sum Types" }
                            span { class: "feature-tag done", "Constraints" }
                        }
                        MilestoneExamples { index: 3 }
                    }
                }

                // Phase 5: Concurrency - DONE
                div { class: "milestone",
                    div { class: "milestone-dot done", "✓" }
                    div { class: "milestone-content",
                        div { class: "milestone-header",
                            span { class: "milestone-title", "Concurrency & Actors" }
                            span { class: "milestone-badge done", "Complete" }
                        }
                        p { class: "milestone-desc",
                            "Go-like concurrency with channels, agents, and structured parallelism. Select with timeout, async/await."
                        }
                        div { class: "milestone-features",
                            span { class: "feature-tag done", "Channels" }
                            span { class: "feature-tag done", "Agents" }
                            span { class: "feature-tag done", "Tasks" }
                            span { class: "feature-tag done", "Parallel" }
                            span { class: "feature-tag done", "Select" }
                        }
                        MilestoneExamples { index: 4 }
                    }
                }

                // Phase 6: Distributed Systems - DONE
                div { class: "milestone",
                    div { class: "milestone-dot done", "✓" }
                    div { class: "milestone-content",
                        div { class: "milestone-header",
                            span { class: "milestone-title", "Distributed Systems" }
                            span { class: "milestone-badge done", "Complete" }
                        }
                        p { class: "milestone-desc",
                            "CRDTs, P2P networking, and persistent storage. Build local-first apps with automatic conflict resolution."
                        }
                        div { class: "milestone-features",
                            span { class: "feature-tag done", "CRDTs" }
                            span { class: "feature-tag done", "P2P" }
                            span { class: "feature-tag done", "Persistence" }
                            span { class: "feature-tag done", "GossipSub" }
                            span { class: "feature-tag done", "Distributed<T>" }
                        }
                        MilestoneExamples { index: 5 }
                    }
                }

                // Phase 7: Security & Policies - DONE
                div { class: "milestone",
                    div { class: "milestone-dot done", "✓" }
                    div { class: "milestone-content",
                        div { class: "milestone-header",
                            span { class: "milestone-title", "Security & Policies" }
                            span { class: "milestone-badge done", "Complete" }
                        }
                        p { class: "milestone-desc",
                            "Capability-based security with policy blocks. Define who can do what in plain English."
                        }
                        div { class: "milestone-features",
                            span { class: "feature-tag done", "Policy Blocks" }
                            span { class: "feature-tag done", "Capabilities" }
                            span { class: "feature-tag done", "Check Guards" }
                            span { class: "feature-tag done", "Predicates" }
                        }
                        MilestoneExamples { index: 6 }
                    }
                }

                // Phase 8: Proof Assistant - IN PROGRESS
                div { class: "milestone",
                    div { class: "milestone-dot progress", "◐" }
                    div { class: "milestone-content",
                        div { class: "milestone-header",
                            span { class: "milestone-title", "Proof Assistant" }
                            span { class: "milestone-badge progress", "In Progress" }
                        }
                        p { class: "milestone-desc",
                            "Curry-Howard in English. Trust statements, termination proofs, and optional Z3 verification."
                        }
                        div { class: "milestone-features",
                            span { class: "feature-tag done", "Trust Statements" }
                            span { class: "feature-tag done", "Termination Proofs" }
                            span { class: "feature-tag done", "Z3 Integration" }
                            span { class: "feature-tag", "Auto Tactic" }
                            span { class: "feature-tag", "Induction" }
                        }
                        MilestoneExamples { index: 7 }
                    }
                }

                // Phase 9: Universal Compilation - PLANNED
                div { class: "milestone",
                    div { class: "milestone-dot planned" }
                    div { class: "milestone-content",
                        div { class: "milestone-header",
                            span { class: "milestone-title", "Universal Compilation" }
                            span { class: "milestone-badge planned", "Planned" }
                        }
                        p { class: "milestone-desc",
                            "Compile to WASM for the web. The Live Codex IDE for real-time proof visualization."
                        }
                        div { class: "milestone-features",
                            span { class: "feature-tag", "WASM Target" }
                            span { class: "feature-tag", "Live Codex IDE" }
                        }
                        MilestoneExamples { index: 8 }
                    }
                }
            }

            footer { class: "roadmap-footer",
                span { "© 2026 Brahmastra Labs LLC  •  Written in Rust 🦀" }
                span { " • " }
                a {
                    href: "https://github.com/Brahmastra-Labs/logicaffeine",
                    target: "_blank",
                    class: "github-link",
                    svg {
                        xmlns: "http://www.w3.org/2000/svg",
                        width: "14",
                        height: "14",
                        view_box: "0 0 24 24",
                        fill: "currentColor",
                        path {
                            d: "M12 0C5.37 0 0 5.37 0 12c0 5.31 3.435 9.795 8.205 11.385.6.105.825-.255.825-.57 0-.285-.015-1.23-.015-2.235-3.015.555-3.795-.735-4.035-1.41-.135-.345-.72-1.41-1.23-1.695-.42-.225-1.02-.78-.015-.795.945-.015 1.62.87 1.845 1.23 1.08 1.815 2.805 1.305 3.495.99.105-.78.42-1.305.765-1.605-2.67-.3-5.46-1.335-5.46-5.925 0-1.305.465-2.385 1.23-3.225-.12-.3-.54-1.53.12-3.18 0 0 1.005-.315 3.3 1.23.96-.27 1.98-.405 3-.405s2.04.135 3 .405c2.295-1.56 3.3-1.23 3.3-1.23.66 1.65.24 2.88.12 3.18.765.84 1.23 1.905 1.23 3.225 0 4.605-2.805 5.625-5.475 5.925.435.375.81 1.095.81 2.22 0 1.605-.015 2.895-.015 3.3 0 .315.225.69.825.57A12.02 12.02 0 0024 12c0-6.63-5.37-12-12-12z"
                        }
                    }
                    "GitHub"
                }
                span { " • " }
                Link { to: Route::Privacy {}, "Privacy" }
                span { " • " }
                Link { to: Route::Terms {}, "Terms" }
                span { " • " }
                Link { to: Route::Pricing {}, "Pricing" }
            }
        }
    }
}

```

---

### Page: Studio

**File:** `src/ui/pages/studio.rs`

Live transpilation sandbox with AST visualization, portal animations, and real-time English-to-FOL conversion. Header nav uses Link components for client-side routing to Home and Learn pages.

```rust
use dioxus::prelude::*;
use crate::{compile_for_ui, CompileResult};
use crate::ui::components::editor::LiveEditor;
use crate::ui::components::logic_output::{LogicOutput, OutputFormat};
use crate::ui::components::ast_tree::AstTree;
use crate::ui::components::socratic_guide::{SocraticGuide, GuideMode, get_success_message, get_context_hint};
use crate::ui::components::main_nav::{MainNav, ActivePage};

const STUDIO_STYLE: &str = r#"
.studio-container {
    display: flex;
    flex-direction: column;
    height: 100vh;
    background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
    color: #e8e8e8;
}

.studio-header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    padding: 16px 24px;
    background: rgba(0, 0, 0, 0.2);
    border-bottom: 1px solid rgba(255, 255, 255, 0.08);
}

.studio-logo {
    display: flex;
    align-items: center;
    gap: 12px;
}

.studio-logo-icon {
    font-size: 24px;
}

.studio-logo-text {
    font-size: 20px;
    font-weight: 700;
    background: linear-gradient(135deg, #667eea, #764ba2);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    background-clip: text;
}

.studio-nav {
    display: flex;
    gap: 8px;
}

.studio-nav-btn {
    padding: 8px 16px;
    border-radius: 8px;
    border: 1px solid rgba(255, 255, 255, 0.15);
    background: rgba(255, 255, 255, 0.05);
    color: #888;
    font-size: 14px;
    cursor: pointer;
    transition: all 0.2s ease;
    text-decoration: none;
}

.studio-nav-btn:hover {
    background: rgba(255, 255, 255, 0.1);
    color: #e8e8e8;
}

.studio-main {
    flex: 1;
    display: flex;
    overflow: hidden;
}

.studio-panel {
    background: rgba(0, 0, 0, 0.3);
    display: flex;
    flex-direction: column;
    overflow: hidden;
    min-width: 200px;
}

.panel-header {
    padding: 12px 16px;
    border-bottom: 1px solid rgba(255, 255, 255, 0.08);
    font-size: 12px;
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    color: #888;
    display: flex;
    justify-content: space-between;
    align-items: center;
    flex-shrink: 0;
}

.panel-content {
    flex: 1;
    overflow: auto;
}

.panel-resizer {
    width: 6px;
    background: rgba(255, 255, 255, 0.05);
    cursor: col-resize;
    transition: background 0.2s ease;
    flex-shrink: 0;
}

.panel-resizer:hover,
.panel-resizer.active {
    background: rgba(102, 126, 234, 0.5);
}

.format-toggle {
    display: flex;
    gap: 4px;
    background: rgba(255, 255, 255, 0.05);
    border-radius: 6px;
    padding: 2px;
}

.format-btn {
    padding: 4px 10px;
    border: none;
    background: transparent;
    color: #888;
    font-size: 11px;
    border-radius: 4px;
    cursor: pointer;
    transition: all 0.2s ease;
}

.format-btn:hover {
    color: #e8e8e8;
}

.format-btn.active {
    background: rgba(255, 255, 255, 0.1);
    color: #e8e8e8;
}

.studio-footer {
    background: rgba(0, 0, 0, 0.3);
    border-top: 1px solid rgba(255, 255, 255, 0.08);
}

@media (max-width: 768px) {
    .studio-main {
        flex-direction: column;
    }
    .panel-resizer {
        width: 100%;
        height: 6px;
        cursor: row-resize;
    }
    .studio-panel {
        min-width: unset;
        min-height: 150px;
    }
}
"#;

#[component]
pub fn Studio() -> Element {
    let mut input = use_signal(String::new);
    let mut result = use_signal(|| CompileResult {
        logic: None,
        simple_logic: None,
        ast: None,
        readings: Vec::new(),
        tokens: Vec::new(),
        error: None,
    });
    let mut format = use_signal(|| OutputFormat::SimpleFOL);

    let mut left_width = use_signal(|| 35.0f64);
    let mut right_width = use_signal(|| 25.0f64);
    let mut resizing = use_signal(|| None::<&'static str>);

    let handle_input = move |new_value: String| {
        input.set(new_value.clone());
        if !new_value.trim().is_empty() {
            let compiled = compile_for_ui(&new_value);
            result.set(compiled);
        } else {
            result.set(CompileResult {
                logic: None,
                simple_logic: None,
                ast: None,
                readings: Vec::new(),
                tokens: Vec::new(),
                error: None,
            });
        }
    };

    let current_result = result.read();
    let guide_mode = if let Some(err) = &current_result.error {
        GuideMode::Error(err.clone())
    } else if current_result.logic.is_some() {
        let msg = get_success_message(current_result.readings.len());
        if let Some(hint) = get_context_hint(&input.read()) {
            GuideMode::Info(format!("{} {}", msg, hint))
        } else {
            GuideMode::Success(msg)
        }
    } else {
        GuideMode::Idle
    };

    let left_w = *left_width.read();
    let right_w = *right_width.read();
    let center_w = 100.0 - left_w - right_w;

    let handle_mouse_move = move |evt: MouseEvent| {
        if let Some(which) = *resizing.read() {
            let window = web_sys::window().unwrap();
            let width = window.inner_width().unwrap().as_f64().unwrap();
            let coords = evt.data().client_coordinates();
            let x: f64 = coords.x;
            let pct: f64 = (x / width) * 100.0;

            match which {
                "left" => {
                    let new_left: f64 = pct.clamp(15.0, 60.0);
                    left_width.set(new_left);
                }
                "right" => {
                    let new_right: f64 = (100.0 - pct).clamp(15.0, 40.0);
                    right_width.set(new_right);
                }
                _ => {}
            }
        }
    };

    let handle_mouse_up = move |_: MouseEvent| {
        resizing.set(None);
    };

    let current_format = *format.read();

    rsx! {
        style { "{STUDIO_STYLE}" }

        div {
            class: "studio-container",
            onmousemove: handle_mouse_move,
            onmouseup: handle_mouse_up,
            onmouseleave: handle_mouse_up,

            MainNav { active: ActivePage::Studio }

            main { class: "studio-main",
                section {
                    class: "studio-panel",
                    style: "width: {left_w}%;",
                    div { class: "panel-header",
                        span { "English Input" }
                    }
                    div { class: "panel-content",
                        LiveEditor {
                            on_change: handle_input,
                            placeholder: Some("Type an English sentence...".to_string()),
                        }
                    }
                }

                div {
                    class: if resizing.read().is_some() { "panel-resizer active" } else { "panel-resizer" },
                    onmousedown: move |_| resizing.set(Some("left")),
                }

                section {
                    class: "studio-panel",
                    style: "width: {center_w}%;",
                    div { class: "panel-header",
                        span { "Logic Output" }
                        div { class: "format-toggle",
                            button {
                                class: if current_format == OutputFormat::SimpleFOL { "format-btn active" } else { "format-btn" },
                                onclick: move |_| format.set(OutputFormat::SimpleFOL),
                                "Simple"
                            }
                            button {
                                class: if current_format == OutputFormat::Unicode { "format-btn active" } else { "format-btn" },
                                onclick: move |_| format.set(OutputFormat::Unicode),
                                "Full"
                            }
                            button {
                                class: if current_format == OutputFormat::LaTeX { "format-btn active" } else { "format-btn" },
                                onclick: move |_| format.set(OutputFormat::LaTeX),
                                "LaTeX"
                            }
                        }
                    }
                    div { class: "panel-content",
                        LogicOutput {
                            logic: current_result.logic.clone(),
                            simple_logic: current_result.simple_logic.clone(),
                            readings: current_result.readings.clone(),
                            error: current_result.error.clone(),
                            format: current_format,
                        }
                    }
                }

                div {
                    class: if resizing.read().is_some() { "panel-resizer active" } else { "panel-resizer" },
                    onmousedown: move |_| resizing.set(Some("right")),
                }

                aside {
                    class: "studio-panel",
                    style: "width: {right_w}%;",
                    div { class: "panel-header",
                        span { "AST Inspector" }
                    }
                    div { class: "panel-content",
                        AstTree {
                            ast: current_result.ast.clone(),
                        }
                    }
                }
            }

            footer { class: "studio-footer",
                SocraticGuide {
                    mode: guide_mode,
                    on_hint_request: None,
                }
            }
        }
    }
}

```

---

### Page: success

**File:** `src/ui/pages/success.rs`

Application page component.

```rust
use dioxus::prelude::*;
use crate::ui::router::Route;
use crate::ui::state::{LicenseState, LicensePlan};
use crate::ui::components::main_nav::{MainNav, ActivePage};

const LICENSE_API_URL: &str = "https://api.logicaffeine.com/session";

const SUCCESS_STYLE: &str = r#"
.success-container {
    min-height: 100vh;
    display: flex;
    flex-direction: column;
    align-items: center;
    justify-content: center;
    padding: 60px 20px;
    text-align: center;
    max-width: 600px;
    margin: 0 auto;
}

.success-icon {
    width: 80px;
    height: 80px;
    background: linear-gradient(135deg, #00d4ff 0%, #7b2cbf 100%);
    border-radius: 50%;
    display: flex;
    align-items: center;
    justify-content: center;
    margin-bottom: 32px;
    font-size: 40px;
}

.success-title {
    font-size: 36px;
    font-weight: 700;
    color: #fff;
    margin-bottom: 16px;
}

.success-message {
    color: #aaa;
    font-size: 18px;
    line-height: 1.6;
    margin-bottom: 32px;
}

.license-box {
    background: rgba(0, 212, 255, 0.1);
    border: 1px solid rgba(0, 212, 255, 0.3);
    border-radius: 12px;
    padding: 24px;
    margin-bottom: 32px;
    width: 100%;
    max-width: 400px;
}

.license-label {
    color: #00d4ff;
    font-size: 14px;
    font-weight: 600;
    margin-bottom: 12px;
    text-transform: uppercase;
    letter-spacing: 1px;
}

.license-key {
    background: rgba(0, 0, 0, 0.3);
    border: 1px solid rgba(255, 255, 255, 0.1);
    border-radius: 8px;
    padding: 16px;
    font-family: monospace;
    font-size: 14px;
    color: #fff;
    word-break: break-all;
    margin-bottom: 12px;
}

.copy-btn {
    background: linear-gradient(135deg, #00d4ff 0%, #7b2cbf 100%);
    color: white;
    border: none;
    padding: 10px 20px;
    border-radius: 8px;
    font-size: 14px;
    font-weight: 600;
    cursor: pointer;
    transition: all 0.2s ease;
}

.copy-btn:hover {
    transform: translateY(-1px);
    box-shadow: 0 4px 12px rgba(0, 212, 255, 0.3);
}

.license-saved {
    color: #4ade80;
    font-size: 13px;
    margin-top: 12px;
}

.success-actions {
    display: flex;
    flex-direction: column;
    gap: 16px;
    width: 100%;
    max-width: 320px;
}

.btn-primary {
    display: block;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    padding: 16px 32px;
    border-radius: 12px;
    font-size: 16px;
    font-weight: 600;
    text-decoration: none;
    text-align: center;
    transition: all 0.2s ease;
}

.btn-primary:hover {
    transform: translateY(-2px);
    box-shadow: 0 6px 20px rgba(102, 126, 234, 0.4);
}

.btn-secondary {
    display: block;
    background: transparent;
    color: #667eea;
    padding: 16px 32px;
    border: 1px solid #667eea;
    border-radius: 12px;
    font-size: 16px;
    font-weight: 500;
    text-decoration: none;
    text-align: center;
    transition: all 0.2s ease;
}

.btn-secondary:hover {
    background: rgba(102, 126, 234, 0.1);
}

.success-note {
    margin-top: 40px;
    padding: 20px;
    background: rgba(255, 255, 255, 0.05);
    border-radius: 12px;
    border: 1px solid rgba(255, 255, 255, 0.1);
}

.success-note p {
    color: #888;
    font-size: 14px;
    margin: 0;
}

.success-note a {
    color: #00d4ff;
    text-decoration: none;
}

.success-note a:hover {
    text-decoration: underline;
}

.loading-spinner {
    width: 40px;
    height: 40px;
    border: 3px solid rgba(0, 212, 255, 0.3);
    border-top: 3px solid #00d4ff;
    border-radius: 50%;
    animation: spin 1s linear infinite;
    margin: 20px auto;
}

@keyframes spin {
    0% { transform: rotate(0deg); }
    100% { transform: rotate(360deg); }
}

.error-message {
    color: #ef4444;
    background: rgba(239, 68, 68, 0.1);
    border: 1px solid rgba(239, 68, 68, 0.3);
    border-radius: 8px;
    padding: 16px;
    margin-bottom: 24px;
}
"#;

const STRIPE_CUSTOMER_PORTAL: &str = "https://billing.stripe.com/p/login/8x200l3VN98D7qa1SMe3e00";

fn get_session_id_from_url() -> Option<String> {
    let window = web_sys::window()?;
    let location = window.location();
    let search = location.search().ok()?;

    let params = web_sys::UrlSearchParams::new_with_str(&search).ok()?;
    params.get("session_id")
}

fn save_license_to_storage(license_key: &str, plan: &str) {
    if let Some(window) = web_sys::window() {
        if let Ok(Some(storage)) = window.local_storage() {
            let _ = storage.set_item("logos_license_key", license_key);
            let _ = storage.set_item("logos_license_plan", plan);
            let timestamp = js_sys::Date::now().to_string();
            let _ = storage.set_item("logos_license_validated_at", &timestamp);
        }
    }
}

fn copy_to_clipboard(text: &str) {
    if let Some(window) = web_sys::window() {
        let clipboard = window.navigator().clipboard();
        let _ = clipboard.write_text(text);
    }
}

#[derive(Clone, PartialEq)]
enum LicenseStatus {
    Loading,
    Success { subscription_id: String, plan: String },
    Error(String),
    NoSession,
}

async fn fetch_license_from_session(session_id: String) -> LicenseStatus {
    use gloo_net::http::Request;

    let body = serde_json::json!({ "sessionId": session_id });

    let response = Request::post(LICENSE_API_URL)
        .header("Content-Type", "application/json")
        .body(body.to_string())
        .unwrap()
        .send()
        .await;

    match response {
        Ok(resp) => {
            if resp.ok() {
                match resp.json::<serde_json::Value>().await {
                    Ok(data) => {
                        let subscription_id = data["subscriptionId"]
                            .as_str()
                            .unwrap_or("")
                            .to_string();
                        let plan = data["plan"]
                            .as_str()
                            .unwrap_or("unknown")
                            .to_string();
                        LicenseStatus::Success { subscription_id, plan }
                    }
                    Err(_) => LicenseStatus::Error("Failed to parse response".to_string()),
                }
            } else {
                LicenseStatus::Error("License lookup failed".to_string())
            }
        }
        Err(e) => LicenseStatus::Error(format!("Network error: {}", e)),
    }
}

#[component]
pub fn Success() -> Element {
    let mut license_status = use_signal(|| LicenseStatus::Loading);
    let mut copied = use_signal(|| false);
    let mut saved = use_signal(|| false);
    let license_state = use_context::<LicenseState>();

    use_effect(move || {
        let mut license_state = license_state.clone();
        spawn(async move {
            if let Some(session_id) = get_session_id_from_url() {
                let result = fetch_license_from_session(session_id).await;
                if let LicenseStatus::Success { ref subscription_id, ref plan } = result {
                    save_license_to_storage(subscription_id, plan);
                    license_state.set_license(
                        subscription_id.clone(),
                        LicensePlan::from_str(plan),
                    );
                    saved.set(true);
                }
                license_status.set(result);
            } else {
                license_status.set(LicenseStatus::NoSession);
            }
        });
    });

    let on_copy = move |_| {
        if let LicenseStatus::Success { ref subscription_id, .. } = *license_status.read() {
            copy_to_clipboard(subscription_id);
            copied.set(true);
        }
    };

    let (has_license, license_key) = match &*license_status.read() {
        LicenseStatus::Success { subscription_id, .. } => (true, subscription_id.clone()),
        _ => (false, String::new()),
    };

    let is_loading = matches!(*license_status.read(), LicenseStatus::Loading);

    rsx! {
        style { "{SUCCESS_STYLE}" }

        MainNav { active: ActivePage::Pricing, subtitle: Some("Payment Complete"), show_nav_links: false }

        div { class: "success-container",
            div { class: "success-icon", "✓" }

            h1 { class: "success-title", "Thank You!" }

            p { class: "success-message",
                "Your payment was successful. Welcome to logicaffeine! "
                "You now have access to use LOGOS for commercial purposes."
            }

            if is_loading {
                div { class: "loading-spinner" }
                p { class: "success-message", "Retrieving your license..." }
            }

            match &*license_status.read() {
                LicenseStatus::Error(msg) => rsx! {
                    div { class: "error-message", "{msg}" }
                },
                LicenseStatus::NoSession => rsx! {
                    div { class: "error-message", "No checkout session found. Please try again." }
                },
                _ => rsx! {}
            }

            if has_license {
                div { class: "license-box",
                    div { class: "license-label", "Your License Key" }
                    div { class: "license-key", "{license_key}" }
                    button {
                        class: "copy-btn",
                        onclick: on_copy,
                        if *copied.read() { "Copied!" } else { "Copy to Clipboard" }
                    }
                    if *saved.read() {
                        div { class: "license-saved",
                            "✓ License saved to your browser"
                        }
                    }
                }
            }

            div { class: "success-actions",
                Link {
                    class: "btn-primary",
                    to: Route::Studio {},
                    "Open Studio"
                }

                a {
                    class: "btn-secondary",
                    href: STRIPE_CUSTOMER_PORTAL,
                    target: "_blank",
                    "Manage Subscription"
                }
            }

            div { class: "success-note",
                p {
                    "Save your license key somewhere safe. "
                    "Need help? Contact us at "
                    a { href: "mailto:tristen@brahmastra-labs.com", "tristen@brahmastra-labs.com" }
                    "."
                }
            }
        }
    }
}

```

---

### Page: terms

**File:** `src/ui/pages/terms.rs`

Application page component.

```rust
use dioxus::prelude::*;
use crate::ui::router::Route;
use crate::ui::components::main_nav::{MainNav, ActivePage};

const TERMS_HTML: &str = include_str!("../../../terms.html");

const LEGAL_STYLE: &str = r#"
.legal-container {
    min-height: 100vh;
    display: flex;
    flex-direction: column;
    background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
}

.legal-content {
    flex: 1;
    max-width: 900px;
    margin: 0 auto;
    padding: 40px 20px 60px;
    width: 100%;
}

.legal-content-inner {
    background: rgba(255, 255, 255, 0.98);
    border-radius: 16px;
    padding: 40px;
    box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
}

.legal-footer {
    border-top: 1px solid rgba(255,255,255,0.06);
    padding: 24px 20px;
    text-align: center;
    color: rgba(229,231,235,0.56);
    font-size: 13px;
}

.legal-footer a {
    color: rgba(229,231,235,0.72);
    text-decoration: none;
    margin: 0 8px;
}

.legal-footer a:hover {
    color: #a78bfa;
}

.github-link {
    display: inline-flex;
    align-items: center;
    gap: 6px;
}
"#;

#[component]
pub fn Terms() -> Element {
    rsx! {
        style { "{LEGAL_STYLE}" }

        div { class: "legal-container",
            MainNav { active: ActivePage::Other, subtitle: Some("Terms of Use"), show_nav_links: false }

            main { class: "legal-content",
                div {
                    class: "legal-content-inner",
                    dangerous_inner_html: "{TERMS_HTML}"
                }
            }

            footer { class: "legal-footer",
                span { "© 2025 Brahmastra Labs LLC" }
                span { " • " }
                a {
                    href: "https://github.com/Brahmastra-Labs/logicaffeine",
                    target: "_blank",
                    class: "github-link",
                    svg {
                        xmlns: "http://www.w3.org/2000/svg",
                        width: "14",
                        height: "14",
                        view_box: "0 0 24 24",
                        fill: "currentColor",
                        path {
                            d: "M12 0C5.37 0 0 5.37 0 12c0 5.31 3.435 9.795 8.205 11.385.6.105.825-.255.825-.57 0-.285-.015-1.23-.015-2.235-3.015.555-3.795-.735-4.035-1.41-.135-.345-.72-1.41-1.23-1.695-.42-.225-1.02-.78-.015-.795.945-.015 1.62.87 1.845 1.23 1.08 1.815 2.805 1.305 3.495.99.105-.78.42-1.305.765-1.605-2.67-.3-5.46-1.335-5.46-5.925 0-1.305.465-2.385 1.23-3.225-.12-.3-.54-1.53.12-3.18 0 0 1.005-.315 3.3 1.23.96-.27 1.98-.405 3-.405s2.04.135 3 .405c2.295-1.56 3.3-1.23 3.3-1.23.66 1.65.24 2.88.12 3.18.765.84 1.23 1.905 1.23 3.225 0 4.605-2.805 5.625-5.475 5.925.435.375.81 1.095.81 2.22 0 1.605-.015 2.895-.015 3.3 0 .315.225.69.825.57A12.02 12.02 0 0024 12c0-6.63-5.37-12-12-12z"
                        }
                    }
                    "GitHub"
                }
                span { " • " }
                Link { to: Route::Privacy {}, "Privacy Policy" }
                span { " • " }
                Link { to: Route::Terms {}, "Terms of Use" }
            }
        }
    }
}

```

---

### Page: Workspace

**File:** `src/ui/pages/workspace.rs`

Three-column learning interface: sidebar (lesson tree, history), center (chat/proof interface), right panel (AST inspector).

```rust
use dioxus::prelude::*;
use crate::ui::state::AppState;
use crate::ui::components::chat::ChatDisplay;
use crate::ui::components::input::InputArea;
use crate::ui::components::main_nav::{MainNav, ActivePage};

const WORKSPACE_STYLE: &str = r#"
.workspace {
    height: 100vh;
    display: flex;
    flex-direction: column;
}

.workspace-header {
    background: rgba(0, 0, 0, 0.3);
    backdrop-filter: blur(10px);
    padding: 16px 24px;
    border-bottom: 1px solid rgba(255, 255, 255, 0.1);
    display: flex;
    justify-content: space-between;
    align-items: center;
}

.workspace-header .breadcrumb {
    display: flex;
    align-items: center;
    gap: 8px;
}

.workspace-header .breadcrumb a {
    color: #888;
    text-decoration: none;
    font-size: 14px;
}

.workspace-header .breadcrumb a:hover {
    color: #00d4ff;
}

.workspace-header .breadcrumb span {
    color: #666;
}

.workspace-header h1 {
    font-size: 20px;
    font-weight: 600;
    background: linear-gradient(90deg, #00d4ff, #7b2cbf);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
}

.workspace-content {
    flex: 1;
    display: flex;
    overflow: hidden;
}

.sidebar {
    width: 260px;
    background: rgba(0, 0, 0, 0.2);
    border-right: 1px solid rgba(255, 255, 255, 0.1);
    padding: 20px;
    overflow-y: auto;
}

.sidebar h3 {
    color: #888;
    font-size: 12px;
    text-transform: uppercase;
    letter-spacing: 1px;
    margin-bottom: 16px;
}

.lesson-tree {
    list-style: none;
}

.lesson-tree li {
    padding: 10px 12px;
    margin-bottom: 4px;
    border-radius: 8px;
    color: #aaa;
    font-size: 14px;
    cursor: pointer;
    transition: all 0.2s ease;
}

.lesson-tree li:hover {
    background: rgba(255, 255, 255, 0.05);
    color: #fff;
}

.lesson-tree li.active {
    background: rgba(102, 126, 234, 0.2);
    color: #667eea;
}

.lesson-tree li.locked {
    opacity: 0.4;
    cursor: not-allowed;
}

.main-area {
    flex: 1;
    display: flex;
    flex-direction: column;
    overflow: hidden;
}

.inspector {
    width: 300px;
    background: rgba(0, 0, 0, 0.2);
    border-left: 1px solid rgba(255, 255, 255, 0.1);
    padding: 20px;
    overflow-y: auto;
}

.inspector h3 {
    color: #888;
    font-size: 12px;
    text-transform: uppercase;
    letter-spacing: 1px;
    margin-bottom: 16px;
}

.inspector-placeholder {
    color: #666;
    font-size: 14px;
    font-style: italic;
    text-align: center;
    padding: 40px 20px;
}

@media (max-width: 900px) {
    .sidebar, .inspector {
        display: none;
    }
}
"#;

#[component]
pub fn Workspace(subject: String) -> Element {
    let mut state = use_context_provider(|| Signal::new(AppState::new()));

    let title = match subject.as_str() {
        "logic" => "First-Order Logic",
        "english" => "English",
        "coding" => "Coding",
        "math" => "Mathematics",
        _ => "Workspace",
    };

    rsx! {
        style { "{WORKSPACE_STYLE}" }

        MainNav { active: ActivePage::Studio, subtitle: Some(title) }

        div { class: "workspace",
            div { class: "workspace-content",
                div { class: "sidebar",
                    h3 { "The Path" }
                    ul { class: "lesson-tree",
                        li { class: "active", "1. Basic Propositions" }
                        li { "2. Connectives" }
                        li { "3. Quantifiers" }
                        li { "4. Predicates" }
                        li { class: "locked", "5. Modal Logic" }
                        li { class: "locked", "6. Temporal Logic" }
                    }

                    h3 { style: "margin-top: 32px;", "History" }
                    p { style: "color: #666; font-size: 13px;", "Your recent sessions will appear here." }
                }

                div { class: "main-area",
                    ChatDisplay { messages: state.read().get_history() }
                    InputArea { on_send: move |text| state.write().add_user_message(text) }
                }

                div { class: "inspector",
                    h3 { "AST Inspector" }
                    div { class: "inspector-placeholder",
                        "Parse a sentence to see its abstract syntax tree visualization here."
                    }
                }
            }
        }
    }
}

```

---

### Registry: Browse

**File:** `src/ui/pages/registry/browse.rs`

Package registry browser. Lists available LOGOS packages with search and filtering.

```rust
//! Phase 39: Registry Browse Page
//!
//! Main page for browsing and searching packages.

use dioxus::prelude::*;
use crate::ui::router::Route;
use crate::ui::state::{RegistryAuthState, RegistryPackage, GitHubUser};
use crate::ui::components::main_nav::{MainNav, ActivePage};

const REGISTRY_API_URL: &str = "https://registry.logicaffeine.com";

const REGISTRY_STYLE: &str = r#"
.registry-container {
    min-height: 100vh;
    background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
    color: #e8e8e8;
    font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
}

.registry-header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    padding: 24px 48px;
    border-bottom: 1px solid rgba(255,255,255,0.1);
}

.header-left {
    display: flex;
    align-items: center;
    gap: 24px;
}

.header-left h1 {
    font-size: 24px;
    font-weight: 700;
    background: linear-gradient(135deg, #667eea, #764ba2);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    margin: 0;
}

.back-link {
    color: #888;
    text-decoration: none;
    font-size: 14px;
}

.back-link:hover {
    color: #fff;
}

.login-btn {
    display: inline-flex;
    align-items: center;
    gap: 8px;
    padding: 10px 20px;
    background: #24292e;
    color: white;
    text-decoration: none;
    border-radius: 8px;
    font-size: 14px;
    font-weight: 500;
    transition: background 0.2s;
}

.login-btn:hover {
    background: #2f363d;
}

.user-menu {
    display: flex;
    align-items: center;
    gap: 12px;
}

.user-avatar {
    width: 36px;
    height: 36px;
    border-radius: 50%;
    border: 2px solid rgba(255,255,255,0.2);
}

.user-name {
    font-size: 14px;
    color: #e8e8e8;
}

.logout-btn {
    padding: 6px 12px;
    background: transparent;
    border: 1px solid rgba(255,255,255,0.2);
    color: #888;
    border-radius: 6px;
    cursor: pointer;
    font-size: 13px;
}

.logout-btn:hover {
    border-color: rgba(255,255,255,0.4);
    color: #fff;
}

.search-section {
    padding: 48px;
    text-align: center;
}

.search-title {
    font-size: 32px;
    font-weight: 700;
    margin-bottom: 8px;
}

.search-subtitle {
    color: #888;
    margin-bottom: 32px;
}

.search-bar {
    width: 100%;
    max-width: 600px;
    padding: 16px 24px;
    font-size: 16px;
    background: rgba(255,255,255,0.05);
    border: 1px solid rgba(255,255,255,0.1);
    border-radius: 12px;
    color: #fff;
    outline: none;
    transition: border-color 0.2s, box-shadow 0.2s;
}

.search-bar:focus {
    border-color: #667eea;
    box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.2);
}

.search-bar::placeholder {
    color: #666;
}

.package-grid {
    display: grid;
    grid-template-columns: repeat(auto-fill, minmax(320px, 1fr));
    gap: 24px;
    padding: 0 48px 48px;
}

.package-card {
    background: rgba(255,255,255,0.03);
    border: 1px solid rgba(255,255,255,0.08);
    border-radius: 12px;
    padding: 24px;
    text-decoration: none;
    color: inherit;
    transition: transform 0.2s, border-color 0.2s, background 0.2s;
}

.package-card:hover {
    transform: translateY(-2px);
    border-color: rgba(102, 126, 234, 0.4);
    background: rgba(255,255,255,0.05);
}

.package-header {
    display: flex;
    justify-content: space-between;
    align-items: flex-start;
    margin-bottom: 12px;
}

.package-name {
    font-size: 18px;
    font-weight: 600;
    color: #fff;
    margin: 0;
    display: flex;
    align-items: center;
    gap: 8px;
}

.verified-badge {
    display: inline-flex;
    align-items: center;
    gap: 4px;
    background: linear-gradient(135deg, #22c55e, #16a34a);
    color: white;
    font-size: 11px;
    font-weight: 700;
    padding: 3px 8px;
    border-radius: 999px;
}

.package-version {
    font-size: 13px;
    color: #888;
    background: rgba(255,255,255,0.05);
    padding: 4px 8px;
    border-radius: 4px;
}

.package-description {
    color: #aaa;
    font-size: 14px;
    line-height: 1.5;
    margin-bottom: 16px;
    display: -webkit-box;
    -webkit-line-clamp: 2;
    -webkit-box-orient: vertical;
    overflow: hidden;
}

.package-meta {
    display: flex;
    gap: 16px;
    font-size: 13px;
    color: #666;
}

.package-meta span {
    display: flex;
    align-items: center;
    gap: 4px;
}

.package-keywords {
    display: flex;
    gap: 6px;
    flex-wrap: wrap;
    margin-top: 12px;
}

.keyword-tag {
    font-size: 11px;
    padding: 3px 8px;
    background: rgba(102, 126, 234, 0.15);
    color: #667eea;
    border-radius: 4px;
}

.loading-spinner {
    text-align: center;
    padding: 48px;
    color: #888;
}

.error-message {
    text-align: center;
    padding: 48px;
    color: #f87171;
}

.empty-state {
    text-align: center;
    padding: 48px;
    color: #888;
}

.stats-section {
    display: flex;
    justify-content: center;
    gap: 48px;
    padding: 24px 48px;
    border-bottom: 1px solid rgba(255,255,255,0.1);
}

.stat-item {
    text-align: center;
}

.stat-value {
    font-size: 24px;
    font-weight: 700;
    color: #667eea;
}

.stat-label {
    font-size: 13px;
    color: #666;
}
"#;

#[component]
pub fn Registry() -> Element {
    let mut auth_state = use_context::<RegistryAuthState>();
    let auth_state_for_check = auth_state.clone();
    let mut packages = use_signal(Vec::<RegistryPackage>::new);
    let mut search_query = use_signal(String::new);
    let mut is_loading = use_signal(|| true);
    let mut error = use_signal(|| None::<String>);

    // Check for OAuth callback params in URL
    use_effect(move || {
        #[cfg(target_arch = "wasm32")]
        {
            if let Some(window) = web_sys::window() {
                if let Ok(search) = window.location().search() {
                    if let Ok(params) = web_sys::UrlSearchParams::new_with_str(&search) {
                        if let Some(token) = params.get("token") {
                            if let Some(login) = params.get("login") {
                                // Login successful
                                let user = GitHubUser {
                                    id: String::new(),
                                    login: login.clone(),
                                    name: None,
                                    avatar_url: None,
                                };
                                auth_state.login(token, user);

                                // Clear URL params
                                if let Ok(history) = window.history() {
                                    let _ = history.replace_state_with_url(
                                        &wasm_bindgen::JsValue::NULL,
                                        "",
                                        Some("/registry"),
                                    );
                                }
                            }
                        }

                        if let Some(err) = params.get("error") {
                            error.set(Some(err));
                            // Clear URL params
                            if let Ok(history) = window.history() {
                                let _ = history.replace_state_with_url(
                                    &wasm_bindgen::JsValue::NULL,
                                    "",
                                    Some("/registry"),
                                );
                            }
                        }
                    }
                }
            }
        }
    });

    // Fetch packages
    use_effect(move || {
        spawn(async move {
            is_loading.set(true);
            match fetch_packages(None).await {
                Ok(pkgs) => packages.set(pkgs),
                Err(e) => error.set(Some(e)),
            }
            is_loading.set(false);
        });
    });

    let filtered_packages: Vec<RegistryPackage> = {
        let query = search_query.read().to_lowercase();
        if query.is_empty() {
            packages.read().clone()
        } else {
            packages
                .read()
                .iter()
                .filter(|p| {
                    p.name.to_lowercase().contains(&query)
                        || p.description
                            .as_ref()
                            .map(|d| d.to_lowercase().contains(&query))
                            .unwrap_or(false)
                        || p.keywords.iter().any(|k| k.to_lowercase().contains(&query))
                })
                .cloned()
                .collect()
        }
    };

    rsx! {
        style { "{REGISTRY_STYLE}" }

        div { class: "registry-container",
            MainNav {
                active: ActivePage::Registry,
                subtitle: Some("Package Registry"),
            }

            // Registry auth section (kept separate from main nav)
            header { class: "registry-header",
                div { class: "header-left",
                    h1 { "Package Registry" }
                }
                div { class: "header-right",
                    if auth_state_for_check.is_authenticated() {
                        UserMenu { auth_state: auth_state_for_check.clone() }
                    } else {
                        a {
                            class: "login-btn",
                            href: "{RegistryAuthState::get_auth_url()}",
                            // GitHub icon
                            svg {
                                width: "20",
                                height: "20",
                                view_box: "0 0 24 24",
                                fill: "currentColor",
                                path {
                                    d: "M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"
                                }
                            }
                            "Login with GitHub"
                        }
                    }
                }
            }

            div { class: "search-section",
                h2 { class: "search-title", "Find LOGOS Packages" }
                p { class: "search-subtitle", "Discover libraries to enhance your logic programs" }
                input {
                    class: "search-bar",
                    r#type: "search",
                    placeholder: "Search packages by name, description, or keyword...",
                    value: "{search_query}",
                    oninput: move |e| search_query.set(e.value()),
                }
            }

            if *is_loading.read() {
                div { class: "loading-spinner", "Loading packages..." }
            } else if let Some(err) = error.read().as_ref() {
                div { class: "error-message", "Error: {err}" }
            } else if filtered_packages.is_empty() {
                div { class: "empty-state",
                    if search_query.read().is_empty() {
                        "No packages published yet. Be the first!"
                    } else {
                        "No packages match your search."
                    }
                }
            } else {
                div { class: "package-grid",
                    for package in filtered_packages {
                        PackageCard { package: package }
                    }
                }
            }
        }
    }
}

#[component]
fn PackageCard(package: RegistryPackage) -> Element {
    rsx! {
        Link {
            to: Route::PackageDetail { name: package.name.clone() },
            class: "package-card",
            div { class: "package-header",
                h3 { class: "package-name",
                    "{package.name}"
                    if package.verified {
                        span { class: "verified-badge", "Official" }
                    }
                }
                if let Some(version) = &package.latest_version {
                    span { class: "package-version", "v{version}" }
                }
            }
            p { class: "package-description",
                "{package.description.as_deref().unwrap_or(\"No description\")}"
            }
            div { class: "package-meta",
                span { "{package.downloads} downloads" }
                span { "by {package.owner}" }
            }
            if !package.keywords.is_empty() {
                div { class: "package-keywords",
                    for keyword in package.keywords.iter().take(3) {
                        span { class: "keyword-tag", "{keyword}" }
                    }
                }
            }
        }
    }
}

#[component]
fn UserMenu(auth_state: RegistryAuthState) -> Element {
    let user = auth_state.user.read().clone();
    let auth_for_logout = auth_state.clone();

    rsx! {
        div { class: "user-menu",
            if let Some(u) = user.as_ref() {
                if let Some(avatar) = &u.avatar_url {
                    img {
                        class: "user-avatar",
                        src: "{avatar}",
                        alt: "{u.login}"
                    }
                }
                span { class: "user-name", "{u.login}" }
            }
            button {
                class: "logout-btn",
                onclick: move |_| {
                    let mut auth = auth_for_logout.clone();
                    auth.logout();
                },
                "Logout"
            }
        }
    }
}

async fn fetch_packages(search: Option<&str>) -> Result<Vec<RegistryPackage>, String> {
    #[cfg(target_arch = "wasm32")]
    {
        use gloo_net::http::Request;

        let url = match search {
            Some(q) if !q.is_empty() => format!("{}/packages?search={}", REGISTRY_API_URL, q),
            _ => format!("{}/packages", REGISTRY_API_URL),
        };

        let response = Request::get(&url)
            .send()
            .await
            .map_err(|e| e.to_string())?;

        if !response.ok() {
            return Err("Failed to fetch packages".to_string());
        }

        #[derive(serde::Deserialize)]
        struct PackagesResponse {
            packages: Vec<RegistryPackage>,
        }

        let data: PackagesResponse = response.json().await.map_err(|e| e.to_string())?;
        Ok(data.packages)
    }

    #[cfg(not(target_arch = "wasm32"))]
    {
        Ok(vec![])
    }
}

```

---

### Registry: Module

**File:** `src/ui/pages/registry/mod.rs`

Registry pages module exports for Browse and PackageDetail pages.

```rust
//! Phase 39: Package Registry UI
//!
//! Browse, search, and view LOGOS packages.

pub mod browse;
pub mod package_detail;

pub use browse::Registry;
pub use package_detail::PackageDetail;

```

---

### Registry: Package Detail

**File:** `src/ui/pages/registry/package_detail.rs`

Individual package view showing metadata, versions, dependencies, and documentation.

```rust
//! Phase 39: Package Detail Page
//!
//! View package README, versions, and dependencies.

use dioxus::prelude::*;
use crate::ui::router::Route;
use crate::ui::state::PackageDetails;
use crate::ui::components::main_nav::{MainNav, ActivePage};

const REGISTRY_API_URL: &str = "https://registry.logicaffeine.com";

const DETAIL_STYLE: &str = r#"
.detail-container {
    min-height: 100vh;
    background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
    color: #e8e8e8;
    font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
}

.detail-header {
    padding: 24px 48px;
    border-bottom: 1px solid rgba(255,255,255,0.1);
}

.back-link {
    color: #888;
    text-decoration: none;
    font-size: 14px;
    margin-bottom: 16px;
    display: inline-block;
}

.back-link:hover {
    color: #fff;
}

.package-title {
    display: flex;
    align-items: center;
    gap: 16px;
    margin-bottom: 8px;
}

.package-title h1 {
    font-size: 32px;
    font-weight: 700;
    margin: 0;
}

.verified-badge {
    display: inline-flex;
    align-items: center;
    gap: 4px;
    background: linear-gradient(135deg, #22c55e, #16a34a);
    color: white;
    font-size: 12px;
    font-weight: 700;
    padding: 4px 12px;
    border-radius: 999px;
}

.package-meta {
    display: flex;
    gap: 24px;
    color: #888;
    font-size: 14px;
}

.package-meta a {
    color: #667eea;
    text-decoration: none;
}

.package-meta a:hover {
    text-decoration: underline;
}

.detail-content {
    display: grid;
    grid-template-columns: 1fr 320px;
    gap: 48px;
    padding: 48px;
}

.main-content {
    min-width: 0;
}

.tab-nav {
    display: flex;
    gap: 4px;
    margin-bottom: 24px;
    border-bottom: 1px solid rgba(255,255,255,0.1);
    padding-bottom: 0;
}

.tab-btn {
    padding: 12px 24px;
    background: transparent;
    border: none;
    color: #888;
    font-size: 14px;
    cursor: pointer;
    border-bottom: 2px solid transparent;
    margin-bottom: -1px;
    transition: color 0.2s, border-color 0.2s;
}

.tab-btn:hover {
    color: #fff;
}

.tab-btn.active {
    color: #667eea;
    border-bottom-color: #667eea;
}

.readme-content {
    background: rgba(255,255,255,0.03);
    border: 1px solid rgba(255,255,255,0.08);
    border-radius: 12px;
    padding: 32px;
    line-height: 1.7;
}

.readme-content h1, .readme-content h2, .readme-content h3 {
    color: #fff;
    margin-top: 24px;
    margin-bottom: 12px;
}

.readme-content code {
    background: rgba(255,255,255,0.1);
    padding: 2px 6px;
    border-radius: 4px;
    font-size: 0.9em;
}

.readme-content pre {
    background: rgba(0,0,0,0.3);
    padding: 16px;
    border-radius: 8px;
    overflow-x: auto;
}

.versions-list {
    background: rgba(255,255,255,0.03);
    border: 1px solid rgba(255,255,255,0.08);
    border-radius: 12px;
    overflow: hidden;
}

.version-item {
    display: flex;
    justify-content: space-between;
    align-items: center;
    padding: 16px 24px;
    border-bottom: 1px solid rgba(255,255,255,0.05);
}

.version-item:last-child {
    border-bottom: none;
}

.version-name {
    font-weight: 600;
    color: #fff;
}

.version-meta {
    display: flex;
    gap: 16px;
    font-size: 13px;
    color: #666;
}

.yanked-badge {
    background: rgba(239, 68, 68, 0.2);
    color: #ef4444;
    padding: 2px 8px;
    border-radius: 4px;
    font-size: 11px;
}

.sidebar {
    position: sticky;
    top: 24px;
}

.sidebar-section {
    background: rgba(255,255,255,0.03);
    border: 1px solid rgba(255,255,255,0.08);
    border-radius: 12px;
    padding: 24px;
    margin-bottom: 24px;
}

.sidebar-section h3 {
    font-size: 14px;
    font-weight: 600;
    color: #888;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    margin: 0 0 16px;
}

.install-cmd {
    display: block;
    background: rgba(0,0,0,0.3);
    padding: 12px 16px;
    border-radius: 8px;
    font-family: monospace;
    font-size: 14px;
    color: #22c55e;
    word-break: break-all;
}

.meta-item {
    display: flex;
    justify-content: space-between;
    padding: 8px 0;
    font-size: 14px;
    border-bottom: 1px solid rgba(255,255,255,0.05);
}

.meta-item:last-child {
    border-bottom: none;
}

.meta-label {
    color: #888;
}

.meta-value {
    color: #fff;
}

.meta-value a {
    color: #667eea;
    text-decoration: none;
}

.meta-value a:hover {
    text-decoration: underline;
}

.loading-spinner {
    text-align: center;
    padding: 48px;
    color: #888;
}

.error-message {
    text-align: center;
    padding: 48px;
    color: #f87171;
}

.keywords-list {
    display: flex;
    flex-wrap: wrap;
    gap: 8px;
}

.keyword-tag {
    font-size: 12px;
    padding: 4px 10px;
    background: rgba(102, 126, 234, 0.15);
    color: #667eea;
    border-radius: 4px;
}
"#;

#[derive(Clone, PartialEq)]
enum DetailTab {
    Readme,
    Versions,
}

#[component]
pub fn PackageDetail(name: String) -> Element {
    let mut details = use_signal(|| None::<PackageDetails>);
    let mut error = use_signal(|| None::<String>);
    let mut is_loading = use_signal(|| true);
    let mut active_tab = use_signal(|| DetailTab::Readme);

    // Fetch package details
    use_effect({
        let name = name.clone();
        move || {
            let name = name.clone();
            spawn(async move {
                is_loading.set(true);
                match fetch_package_details(&name).await {
                    Ok(d) => details.set(Some(d)),
                    Err(e) => error.set(Some(e)),
                }
                is_loading.set(false);
            });
        }
    });

    rsx! {
        style { "{DETAIL_STYLE}" }

        MainNav { active: ActivePage::Registry, subtitle: Some("Package Details") }

        div { class: "detail-container",
            if *is_loading.read() {
                div { class: "loading-spinner", "Loading package..." }
            } else if let Some(err) = error.read().as_ref() {
                div { class: "error-message",
                    p { "Error: {err}" }
                }
            } else if let Some(pkg) = details.read().as_ref() {
                // Header
                header { class: "detail-header",
                    div { class: "package-title",
                        h1 { "{pkg.name}" }
                        if pkg.verified {
                            span { class: "verified-badge", "Official" }
                        }
                    }
                    div { class: "package-meta",
                        span { "by {pkg.owner}" }
                        if let Some(repo) = &pkg.repository {
                            a { href: "{repo}", target: "_blank", "Repository" }
                        }
                        if let Some(license) = &pkg.license {
                            span { "{license}" }
                        }
                    }
                }

                // Content
                div { class: "detail-content",
                    main { class: "main-content",
                        nav { class: "tab-nav",
                            button {
                                class: if *active_tab.read() == DetailTab::Readme { "tab-btn active" } else { "tab-btn" },
                                onclick: move |_| active_tab.set(DetailTab::Readme),
                                "README"
                            }
                            button {
                                class: if *active_tab.read() == DetailTab::Versions { "tab-btn active" } else { "tab-btn" },
                                onclick: move |_| active_tab.set(DetailTab::Versions),
                                "Versions ({pkg.versions.len()})"
                            }
                        }

                        match *active_tab.read() {
                            DetailTab::Readme => rsx! {
                                div { class: "readme-content",
                                    if let Some(readme) = &pkg.readme {
                                        // Note: In production, render markdown properly
                                        pre { "{readme}" }
                                    } else {
                                        p { "No README available." }
                                    }
                                }
                            },
                            DetailTab::Versions => rsx! {
                                div { class: "versions-list",
                                    for version in pkg.versions.iter() {
                                        div { class: "version-item",
                                            span { class: "version-name",
                                                "v{version.version}"
                                                if version.yanked {
                                                    span { class: "yanked-badge", "yanked" }
                                                }
                                            }
                                            div { class: "version-meta",
                                                span { "{format_size(version.size)}" }
                                                span { "{version.published_at}" }
                                            }
                                        }
                                    }
                                }
                            },
                        }
                    }

                    aside { class: "sidebar",
                        div { class: "sidebar-section",
                            h3 { "Install" }
                            code { class: "install-cmd", "largo add {pkg.name}" }
                        }

                        div { class: "sidebar-section",
                            h3 { "Details" }
                            div { class: "meta-item",
                                span { class: "meta-label", "Downloads" }
                                span { class: "meta-value", "{pkg.downloads}" }
                            }
                            if !pkg.versions.is_empty() {
                                div { class: "meta-item",
                                    span { class: "meta-label", "Latest" }
                                    span { class: "meta-value", "v{pkg.versions[0].version}" }
                                }
                            }
                            if let Some(homepage) = &pkg.homepage {
                                div { class: "meta-item",
                                    span { class: "meta-label", "Homepage" }
                                    span { class: "meta-value",
                                        a { href: "{homepage}", target: "_blank", "Link" }
                                    }
                                }
                            }
                        }

                        if !pkg.keywords.is_empty() {
                            div { class: "sidebar-section",
                                h3 { "Keywords" }
                                div { class: "keywords-list",
                                    for keyword in pkg.keywords.iter() {
                                        span { class: "keyword-tag", "{keyword}" }
                                    }
                                }
                            }
                        }
                    }
                }
            }
        }
    }
}

fn format_size(bytes: u64) -> String {
    if bytes < 1024 {
        format!("{} B", bytes)
    } else if bytes < 1024 * 1024 {
        format!("{:.1} KB", bytes as f64 / 1024.0)
    } else {
        format!("{:.1} MB", bytes as f64 / (1024.0 * 1024.0))
    }
}

async fn fetch_package_details(name: &str) -> Result<PackageDetails, String> {
    #[cfg(target_arch = "wasm32")]
    {
        use gloo_net::http::Request;

        let url = format!("{}/packages/{}", REGISTRY_API_URL, name);

        let response = Request::get(&url)
            .send()
            .await
            .map_err(|e| e.to_string())?;

        if !response.ok() {
            return Err("Package not found".to_string());
        }

        response.json().await.map_err(|e| e.to_string())
    }

    #[cfg(not(target_arch = "wasm32"))]
    {
        Err("Not available in non-WASM builds".to_string())
    }
}

```

---

### Component: achievement_toast

**File:** `src/ui/components/achievement_toast.rs`

Reusable UI component.

```rust
use dioxus::prelude::*;
use crate::achievements::Achievement;
use crate::audio::{SoundEffect, play_sound};

const ACHIEVEMENT_STYLE: &str = r#"
.achievement-overlay {
    position: fixed;
    top: 0;
    left: 0;
    right: 0;
    bottom: 0;
    background: rgba(0, 0, 0, 0.8);
    display: flex;
    align-items: center;
    justify-content: center;
    z-index: 2000;
    animation: overlay-fade 0.3s ease-out;
}

@keyframes overlay-fade {
    from { opacity: 0; }
    to { opacity: 1; }
}

.achievement-card {
    background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
    border: 2px solid #fbbf24;
    border-radius: 20px;
    padding: 40px 60px;
    text-align: center;
    box-shadow: 0 0 60px rgba(251, 191, 36, 0.4);
    animation: card-appear 0.5s ease-out;
}

@keyframes card-appear {
    0% { transform: scale(0.5) translateY(50px); opacity: 0; }
    70% { transform: scale(1.05) translateY(0); }
    100% { transform: scale(1) translateY(0); opacity: 1; }
}

.achievement-icon {
    font-size: 64px;
    margin-bottom: 16px;
    animation: icon-bounce 0.5s ease-out 0.3s both;
}

@keyframes icon-bounce {
    0% { transform: scale(0); }
    50% { transform: scale(1.3); }
    100% { transform: scale(1); }
}

.achievement-label {
    font-size: 14px;
    color: #fbbf24;
    text-transform: uppercase;
    letter-spacing: 2px;
    margin-bottom: 8px;
}

.achievement-title {
    font-size: 32px;
    font-weight: 700;
    color: #fff;
    margin-bottom: 12px;
}

.achievement-description {
    font-size: 16px;
    color: #888;
    margin-bottom: 24px;
}

.achievement-reward {
    font-size: 24px;
    color: #4ade80;
    font-weight: 600;
    margin-bottom: 16px;
}

.achievement-title-unlock {
    background: linear-gradient(90deg, #fbbf24, #f59e0b);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    background-clip: text;
    font-size: 18px;
    font-weight: 600;
    margin-bottom: 24px;
}

.achievement-dismiss {
    padding: 12px 32px;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    border: none;
    border-radius: 8px;
    color: white;
    font-size: 16px;
    font-weight: 600;
    cursor: pointer;
    transition: transform 0.2s ease;
}

.achievement-dismiss:hover {
    transform: scale(1.05);
}

.particles {
    position: absolute;
    top: 0;
    left: 0;
    right: 0;
    bottom: 0;
    pointer-events: none;
    overflow: hidden;
}

.particle {
    position: absolute;
    font-size: 24px;
    animation: particle-fall 2s ease-out forwards;
}

@keyframes particle-fall {
    0% { transform: translateY(-50px) rotate(0deg); opacity: 1; }
    100% { transform: translateY(100vh) rotate(720deg); opacity: 0; }
}
"#;

#[component]
pub fn AchievementToast(achievement: &'static Achievement, on_dismiss: EventHandler<()>) -> Element {
    use_effect(move || {
        play_sound(SoundEffect::Achievement);
    });

    rsx! {
        style { "{ACHIEVEMENT_STYLE}" }
        div {
            class: "achievement-overlay",
            onclick: move |_| on_dismiss.call(()),
            div { class: "particles",
                for i in 0..20 {
                    span {
                        class: "particle",
                        style: "left: {(i * 5) % 100}%; animation-delay: {i as f32 * 0.1}s;",
                        if i % 3 == 0 { "⭐" } else if i % 3 == 1 { "✨" } else { "🎉" }
                    }
                }
            }
            div { class: "achievement-card",
                div { class: "achievement-icon", "🏆" }
                div { class: "achievement-label", "Achievement Unlocked" }
                div { class: "achievement-title", "{achievement.title}" }
                div { class: "achievement-description", "{achievement.description}" }
                div { class: "achievement-reward", "+{achievement.xp_reward} XP" }
                if let Some(title) = achievement.unlocks_title {
                    div { class: "achievement-title-unlock",
                        "Title Unlocked: {title}"
                    }
                }
                if achievement.grants_freeze {
                    div { class: "achievement-title-unlock",
                        "🛡️ +1 Streak Freeze!"
                    }
                }
                button {
                    class: "achievement-dismiss",
                    onclick: move |e| {
                        e.stop_propagation();
                        on_dismiss.call(());
                    },
                    "Continue"
                }
            }
        }
    }
}

```

---

### Component: app_navbar

**File:** `src/ui/components/app_navbar.rs`

Reusable UI component.

```rust
use dioxus::prelude::*;
use crate::ui::router::Route;

const APP_NAVBAR_STYLE: &str = r#"
.app-navbar {
    display: flex;
    justify-content: space-between;
    align-items: center;
    padding: 12px 24px;
    background: rgba(0, 0, 0, 0.25);
    border-bottom: 1px solid rgba(255, 255, 255, 0.08);
    backdrop-filter: blur(12px);
}

.app-navbar-brand {
    display: flex;
    align-items: center;
    gap: 10px;
    text-decoration: none;
    color: inherit;
}

.app-navbar-logo {
    width: 28px;
    height: 28px;
    border-radius: 8px;
    background:
        radial-gradient(circle at 30% 30%, rgba(96,165,250,0.85), transparent 55%),
        radial-gradient(circle at 65% 60%, rgba(167,139,250,0.85), transparent 55%),
        rgba(255,255,255,0.06);
    border: 1px solid rgba(255,255,255,0.10);
}

.app-navbar-title {
    font-size: 16px;
    font-weight: 700;
    background: linear-gradient(135deg, #667eea, #764ba2);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    background-clip: text;
}

.app-navbar-nav {
    display: flex;
    gap: 8px;
    align-items: center;
}

.app-navbar-link {
    display: inline-flex;
    align-items: center;
    gap: 6px;
    padding: 8px 14px;
    border-radius: 8px;
    border: 1px solid rgba(255, 255, 255, 0.10);
    background: rgba(255, 255, 255, 0.04);
    color: #888;
    font-size: 13px;
    text-decoration: none;
    transition: all 0.2s ease;
}

.app-navbar-link:hover {
    background: rgba(255, 255, 255, 0.08);
    border-color: rgba(255, 255, 255, 0.15);
    color: #e8e8e8;
}

.app-navbar-link.site-link {
    color: #667eea;
}

.app-navbar-link.site-link:hover {
    color: #8b9cf7;
}
"#;

#[derive(Props, Clone, PartialEq)]
pub struct AppNavbarProps {
    #[props(default)]
    pub title: Option<String>,
}

#[component]
pub fn AppNavbar(props: AppNavbarProps) -> Element {
    let title = props.title.unwrap_or_else(|| "LOGOS".to_string());

    rsx! {
        style { "{APP_NAVBAR_STYLE}" }

        nav { class: "app-navbar",
            Link {
                class: "app-navbar-brand",
                to: Route::Landing {},
                div { class: "app-navbar-logo" }
                span { class: "app-navbar-title", "{title}" }
            }

            div { class: "app-navbar-nav",
                Link {
                    class: "app-navbar-link site-link",
                    to: Route::Landing {},
                    "← Home"
                }
            }
        }
    }
}

```

---

### Component: ast_tree

**File:** `src/ui/components/ast_tree.rs`

Reusable UI component.

```rust
use dioxus::prelude::*;
use crate::AstNode;

const TREE_STYLE: &str = r#"
.ast-tree-container {
    display: flex;
    flex-direction: column;
    height: 100%;
    overflow: auto;
    padding: 16px;
}

.ast-tree-empty {
    color: #666;
    font-style: italic;
    text-align: center;
    padding: 40px 20px;
}

.ast-node {
    margin-left: 16px;
    position: relative;
}

.ast-node:before {
    content: '';
    position: absolute;
    left: -12px;
    top: 0;
    height: 100%;
    width: 1px;
    background: rgba(255, 255, 255, 0.1);
}

.ast-node:last-child:before {
    height: 12px;
}

.ast-node-label {
    display: flex;
    align-items: center;
    gap: 6px;
    padding: 4px 8px;
    border-radius: 4px;
    cursor: pointer;
    transition: background 0.15s ease;
    position: relative;
}

.ast-node-label:hover {
    background: rgba(255, 255, 255, 0.05);
}

.ast-node-label:before {
    content: '';
    position: absolute;
    left: -12px;
    top: 50%;
    width: 8px;
    height: 1px;
    background: rgba(255, 255, 255, 0.1);
}

.ast-node-toggle {
    width: 16px;
    height: 16px;
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 10px;
    color: #666;
    transition: transform 0.15s ease;
}

.ast-node-toggle.expanded {
    transform: rotate(90deg);
}

.ast-node-text {
    font-family: 'SF Mono', 'Fira Code', 'Consolas', monospace;
    font-size: 13px;
}

.ast-node-type {
    font-size: 10px;
    padding: 2px 6px;
    border-radius: 3px;
    background: rgba(255, 255, 255, 0.08);
    color: #888;
}

.ast-node-type.quantifier { background: rgba(198, 120, 221, 0.2); color: #c678dd; }
.ast-node-type.predicate { background: rgba(152, 195, 121, 0.2); color: #98c379; }
.ast-node-type.binary_op { background: rgba(198, 120, 221, 0.2); color: #c678dd; }
.ast-node-type.unary_op { background: rgba(224, 108, 117, 0.2); color: #e06c75; }
.ast-node-type.constant { background: rgba(229, 192, 123, 0.2); color: #e5c07b; }
.ast-node-type.variable { background: rgba(97, 175, 239, 0.2); color: #61afef; }
.ast-node-type.modal { background: rgba(86, 182, 194, 0.2); color: #56b6c2; }
.ast-node-type.lambda { background: rgba(224, 108, 117, 0.2); color: #e06c75; }

.ast-children {
    display: none;
}

.ast-children.expanded {
    display: block;
}

.ast-root {
    margin-left: 0;
}

.ast-root:before {
    display: none;
}

.ast-root > .ast-node-label:before {
    display: none;
}
"#;

#[component]
pub fn AstTree(ast: Option<AstNode>) -> Element {
    rsx! {
        style { "{TREE_STYLE}" }

        div { class: "ast-tree-container",
            if let Some(node) = ast {
                AstNodeView { node: node, is_root: true }
            } else {
                div { class: "ast-tree-empty",
                    "Parse a sentence to see its AST..."
                }
            }
        }
    }
}

#[component]
fn AstNodeView(node: AstNode, is_root: bool) -> Element {
    let mut expanded = use_signal(|| true);
    let has_children = !node.children.is_empty();

    let node_class = if is_root { "ast-node ast-root" } else { "ast-node" };
    let toggle_class = if *expanded.read() { "ast-node-toggle expanded" } else { "ast-node-toggle" };
    let children_class = if *expanded.read() { "ast-children expanded" } else { "ast-children" };
    let type_class = format!("ast-node-type {}", node.node_type);

    rsx! {
        div { class: "{node_class}",
            div {
                class: "ast-node-label",
                onclick: move |_| {
                    if has_children {
                        let current = *expanded.read();
                        expanded.set(!current);
                    }
                },
                if has_children {
                    span { class: "{toggle_class}", "\u{25B6}" }
                } else {
                    span { class: "ast-node-toggle", "\u{2022}" }
                }
                span { class: "ast-node-text", "{node.label}" }
                span { class: "{type_class}", "{node.node_type}" }
            }

            if has_children {
                div { class: "{children_class}",
                    for child in node.children.iter() {
                        AstNodeView { node: child.clone(), is_root: false }
                    }
                }
            }
        }
    }
}

```

---

### Component: ChatDisplay

**File:** `src/ui/components/chat.rs`

Renders chat message history with role-based styling (user, system, error).

```rust
use dioxus::prelude::*;
use crate::ui::state::{ChatMessage, Role};

#[component]
pub fn ChatDisplay(messages: Vec<ChatMessage>) -> Element {
    rsx! {
        div { class: "chat-area",
            for (i, msg) in messages.iter().enumerate() {
                div {
                    key: "{i}",
                    class: match msg.role {
                        Role::User => "message user",
                        Role::System => "message system",
                        Role::Error => "message error",
                    },
                    "{msg.content}"
                }
            }
        }
    }
}

```

---

### Component: combo_indicator

**File:** `src/ui/components/combo_indicator.rs`

Reusable UI component.

```rust
use dioxus::prelude::*;

const COMBO_STYLE: &str = r#"
.combo-record {
    position: absolute;
    top: -24px;
    left: 50%;
    transform: translateX(-50%);
    font-size: 12px;
    color: #fbbf24;
    font-weight: 600;
    animation: record-flash 1.5s ease-out forwards;
    white-space: nowrap;
    pointer-events: none;
}

@keyframes record-flash {
    0% { opacity: 0; transform: translateX(-50%) translateY(10px) scale(0.8); }
    20% { opacity: 1; transform: translateX(-50%) translateY(0) scale(1.1); }
    40% { opacity: 1; transform: translateX(-50%) translateY(0) scale(1); }
    100% { opacity: 0; transform: translateX(-50%) translateY(-10px) scale(0.9); }
}
.combo-indicator {
    display: flex;
    align-items: center;
    gap: 8px;
    padding: 8px 16px;
    background: rgba(249, 115, 22, 0.15);
    border: 1px solid rgba(249, 115, 22, 0.3);
    border-radius: 24px;
    animation: combo-pulse 0.3s ease-out;
}

@keyframes combo-pulse {
    0% { transform: scale(1); }
    50% { transform: scale(1.1); }
    100% { transform: scale(1); }
}

.combo-flames {
    display: flex;
    gap: 2px;
}

.flame {
    font-size: 16px;
    animation: flame-dance 0.5s ease-in-out infinite alternate;
}

.flame:nth-child(2) { animation-delay: 0.1s; }
.flame:nth-child(3) { animation-delay: 0.2s; }

@keyframes flame-dance {
    from { transform: translateY(0) scale(1); }
    to { transform: translateY(-2px) scale(1.1); }
}

.combo-count {
    font-size: 20px;
    font-weight: 700;
    color: #f97316;
}

.combo-multiplier {
    font-size: 14px;
    color: #fb923c;
    font-weight: 500;
}

.combo-wrapper {
    position: relative;
    display: inline-flex;
}
"#;

#[component]
pub fn ComboIndicator(combo: u32, multiplier: f64, is_new_record: bool) -> Element {
    let mut show_record = use_signal(|| false);
    let mut last_record_combo = use_signal(|| 0u32);

    if is_new_record && combo > last_record_combo() {
        show_record.set(true);
        last_record_combo.set(combo);

        spawn(async move {
            gloo_timers::future::TimeoutFuture::new(1500).await;
            show_record.set(false);
        });
    }

    if combo == 0 {
        return rsx! {};
    }

    let flame_count = (combo.min(5)) as usize;

    rsx! {
        style { "{COMBO_STYLE}" }
        div { class: "combo-wrapper",
            if show_record() {
                div { class: "combo-record", "NEW RECORD!" }
            }
            div { class: "combo-indicator",
                div { class: "combo-flames",
                    for _ in 0..flame_count {
                        span { class: "flame", "🔥" }
                    }
                }
                span { class: "combo-count", "{combo}x" }
                span { class: "combo-multiplier", "({multiplier:.1}x)" }
            }
        }
    }
}

```

---

### Component: editor

**File:** `src/ui/components/editor.rs`

Reusable UI component.

```rust
use dioxus::prelude::*;
use wasm_bindgen::prelude::*;

#[wasm_bindgen]
extern "C" {
    #[wasm_bindgen(js_namespace = window, js_name = initCodeMirror)]
    fn init_codemirror(element_id: &str, on_change: &Closure<dyn FnMut(String)>) -> JsValue;

    #[wasm_bindgen(js_namespace = window, js_name = setCodeMirrorValue)]
    fn set_codemirror_value(editor: &JsValue, value: &str);

    #[wasm_bindgen(js_namespace = window, js_name = getCodeMirrorValue)]
    fn get_codemirror_value(editor: &JsValue) -> String;
}

const EDITOR_STYLE: &str = r#"
.editor-container {
    flex: 1;
    display: flex;
    flex-direction: column;
    min-height: 200px;
    padding: 16px;
}

.editor-wrapper {
    flex: 1;
    background: rgba(255, 255, 255, 0.08);
    border: 1px solid rgba(255, 255, 255, 0.2);
    border-radius: 12px;
    overflow: hidden;
}

.editor-fallback {
    width: 100%;
    height: 100%;
    min-height: 150px;
    background: rgba(255, 255, 255, 0.08);
    border: 1px solid rgba(255, 255, 255, 0.2);
    border-radius: 12px;
    padding: 16px;
    font-size: 16px;
    font-family: 'SF Mono', 'Fira Code', 'Consolas', monospace;
    color: #e8e8e8;
    resize: none;
    outline: none;
}

.editor-fallback:focus {
    border-color: #667eea;
    box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.2);
}

.editor-fallback::placeholder {
    color: #666;
}
"#;

#[component]
pub fn Editor(
    value: String,
    on_change: EventHandler<String>,
    placeholder: Option<String>,
) -> Element {
    let placeholder_text = placeholder.unwrap_or_else(|| "Type an English sentence...".to_string());

    rsx! {
        style { "{EDITOR_STYLE}" }

        div { class: "editor-container",
            textarea {
                class: "editor-fallback",
                placeholder: "{placeholder_text}",
                value: "{value}",
                oninput: move |evt| on_change.call(evt.value()),
            }
        }
    }
}

#[component]
pub fn LiveEditor(
    on_change: EventHandler<String>,
    placeholder: Option<String>,
) -> Element {
    let mut text = use_signal(String::new);
    let placeholder_text = placeholder.unwrap_or_else(|| "Type an English sentence...".to_string());

    let handle_input = move |evt: Event<FormData>| {
        let new_value = evt.value();
        text.set(new_value.clone());
        on_change.call(new_value);
    };

    rsx! {
        style { "{EDITOR_STYLE}" }

        div { class: "editor-container",
            textarea {
                class: "editor-fallback",
                placeholder: "{placeholder_text}",
                value: "{text}",
                oninput: handle_input,
                spellcheck: "false",
                autocomplete: "off",
                autocapitalize: "off",
            }
        }
    }
}

```

---

### Component: guide_code_block

**File:** `src/ui/components/guide_code_block.rs`

Reusable UI component.

```rust
//! Interactive code block component for the Programmer's Guide.
//!
//! Features:
//! - Editable code area
//! - Run button (Logic mode: FOL output, Imperative mode: interpreter)
//! - Copy button
//! - Reset button
//! - Output panel

use dioxus::prelude::*;
use crate::ui::pages::guide::content::ExampleMode;
use crate::compile_for_ui;
use crate::interpret_for_ui;

const CODE_BLOCK_STYLE: &str = r#"
.guide-code-block {
    border-radius: 16px;
    border: 1px solid rgba(255,255,255,0.10);
    background: rgba(0,0,0,0.35);
    overflow: hidden;
    margin: 20px 0;
    box-shadow: 0 8px 32px rgba(0,0,0,0.3);
}

.guide-code-header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    padding: 12px 16px;
    background: rgba(255,255,255,0.04);
    border-bottom: 1px solid rgba(255,255,255,0.08);
}

.guide-code-label {
    display: flex;
    align-items: center;
    gap: 10px;
}

.guide-code-title {
    font-size: 13px;
    font-weight: 600;
    color: rgba(229,231,235,0.9);
}

.guide-code-mode {
    font-size: 11px;
    padding: 4px 10px;
    border-radius: 999px;
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.5px;
}

.guide-code-mode.logic {
    background: rgba(167,139,250,0.2);
    color: #a78bfa;
    border: 1px solid rgba(167,139,250,0.3);
}

.guide-code-mode.imperative {
    background: rgba(34,197,94,0.2);
    color: #22c55e;
    border: 1px solid rgba(34,197,94,0.3);
}

.guide-code-actions {
    display: flex;
    gap: 8px;
}

.guide-code-btn {
    padding: 8px 14px;
    border-radius: 8px;
    border: 1px solid rgba(255,255,255,0.12);
    background: rgba(255,255,255,0.06);
    color: rgba(229,231,235,0.8);
    font-size: 12px;
    font-weight: 600;
    cursor: pointer;
    transition: all 0.2s ease;
    display: flex;
    align-items: center;
    gap: 6px;
}

.guide-code-btn:hover {
    background: rgba(255,255,255,0.10);
    border-color: rgba(255,255,255,0.20);
    color: #fff;
}

.guide-code-btn:active {
    transform: scale(0.97);
}

.guide-code-btn.primary {
    background: linear-gradient(135deg, rgba(96,165,250,0.9), rgba(167,139,250,0.9));
    border-color: rgba(255,255,255,0.2);
    color: #060814;
}

.guide-code-btn.primary:hover {
    background: linear-gradient(135deg, #60a5fa, #a78bfa);
}

.guide-code-btn.running {
    opacity: 0.7;
    cursor: wait;
}

.guide-code-editor {
    position: relative;
}

.guide-code-textarea {
    width: 100%;
    min-height: 80px;
    padding: 16px;
    background: transparent;
    border: none;
    color: rgba(229,231,235,0.95);
    font-family: ui-monospace, SFMono-Regular, 'SF Mono', Menlo, Monaco, 'Cascadia Code', monospace;
    font-size: 14px;
    line-height: 1.7;
    resize: vertical;
    outline: none;
    tab-size: 4;
}

.guide-code-textarea::placeholder {
    color: rgba(229,231,235,0.3);
}

.guide-code-output {
    border-top: 1px solid rgba(255,255,255,0.08);
    background: rgba(0,0,0,0.25);
}

.guide-code-output-header {
    display: flex;
    align-items: center;
    justify-content: space-between;
    padding: 10px 16px;
    font-size: 11px;
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    color: rgba(229,231,235,0.5);
    border-bottom: 1px solid rgba(255,255,255,0.06);
}

.guide-code-output-content {
    padding: 16px;
    font-family: ui-monospace, SFMono-Regular, 'SF Mono', Menlo, Monaco, monospace;
    font-size: 14px;
    line-height: 1.6;
    white-space: pre-wrap;
    word-break: break-word;
}

.guide-code-output-content.success {
    color: #a78bfa;
}

.guide-code-output-content.error {
    color: #f87171;
}

.guide-code-output-content.info {
    color: rgba(229,231,235,0.7);
}

.guide-code-copied {
    position: absolute;
    top: 50%;
    left: 50%;
    transform: translate(-50%, -50%);
    padding: 8px 16px;
    background: rgba(34,197,94,0.9);
    color: #fff;
    border-radius: 8px;
    font-size: 13px;
    font-weight: 600;
    animation: fadeInOut 1.5s ease forwards;
    pointer-events: none;
}

@keyframes fadeInOut {
    0% { opacity: 0; transform: translate(-50%, -50%) scale(0.9); }
    15% { opacity: 1; transform: translate(-50%, -50%) scale(1); }
    85% { opacity: 1; }
    100% { opacity: 0; }
}

.guide-code-placeholder {
    padding: 24px 16px;
    text-align: center;
    color: rgba(229,231,235,0.4);
    font-size: 13px;
}
"#;

#[derive(Props, Clone, PartialEq)]
pub struct GuideCodeBlockProps {
    pub id: String,
    pub label: String,
    pub mode: ExampleMode,
    pub initial_code: String,
}

#[component]
pub fn GuideCodeBlock(props: GuideCodeBlockProps) -> Element {
    let mut code = use_signal(|| props.initial_code.clone());
    let mut output = use_signal(String::new);
    let mut output_type = use_signal(|| "info".to_string());
    let mut is_running = use_signal(|| false);
    let mut show_copied = use_signal(|| false);
    let mut has_run = use_signal(|| false);

    let initial_code = props.initial_code.clone();
    let mode = props.mode;
    let id = props.id.clone();

    // Run handler
    let handle_run = move |_| {
        is_running.set(true);
        has_run.set(true);

        let current_code = code.read().clone();

        match mode {
            ExampleMode::Logic => {
                // Use compile_for_ui for Logic mode
                let result = compile_for_ui(&current_code);
                if let Some(logic) = result.logic {
                    output.set(logic);
                    output_type.set("success".to_string());
                } else if let Some(err) = result.error {
                    output.set(err);
                    output_type.set("error".to_string());
                } else {
                    output.set("No output".to_string());
                    output_type.set("info".to_string());
                }
            }
            ExampleMode::Imperative => {
                // Phase 55: interpret_for_ui is now async for VFS support
                spawn(async move {
                    let result = interpret_for_ui(&current_code).await;
                    if let Some(err) = result.error {
                        output.set(err);
                        output_type.set("error".to_string());
                    } else if result.lines.is_empty() {
                        output.set("(no output)".to_string());
                        output_type.set("info".to_string());
                    } else {
                        output.set(result.lines.join("\n"));
                        output_type.set("success".to_string());
                    }
                    is_running.set(false);
                });
                return;
            }
        }

        is_running.set(false);
    };

    // Copy handler
    let handle_copy = move |_| {
        let code_to_copy = code.read().clone();

        #[cfg(target_arch = "wasm32")]
        {
            if let Some(window) = web_sys::window() {
                let clipboard = window.navigator().clipboard();
                let _ = clipboard.write_text(&code_to_copy);
                show_copied.set(true);

                // Reset after animation
                spawn(async move {
                    gloo_timers::future::TimeoutFuture::new(1500).await;
                    show_copied.set(false);
                });
            }
        }

        #[cfg(not(target_arch = "wasm32"))]
        {
            let _ = code_to_copy;
            show_copied.set(true);
        }
    };

    // Reset handler
    let handle_reset = {
        let initial = initial_code.clone();
        move |_| {
            code.set(initial.clone());
            output.set(String::new());
            has_run.set(false);
        }
    };

    let mode_class = match mode {
        ExampleMode::Logic => "logic",
        ExampleMode::Imperative => "imperative",
    };

    let mode_label = match mode {
        ExampleMode::Logic => "Logic",
        ExampleMode::Imperative => "Run",
    };

    // Calculate rows based on code line count for textarea auto-sizing
    let line_count = code.read().lines().count();
    let rows = (line_count + 2).max(4) as i64; // minimum 4 rows, +2 for editing room

    rsx! {
        style { "{CODE_BLOCK_STYLE}" }

        div {
            class: "guide-code-block",
            id: "{id}",

            // Header
            div { class: "guide-code-header",
                div { class: "guide-code-label",
                    span { class: "guide-code-title", "{props.label}" }
                    span { class: "guide-code-mode {mode_class}",
                        match mode {
                            ExampleMode::Logic => "Logic Mode",
                            ExampleMode::Imperative => "Imperative",
                        }
                    }
                }

                div { class: "guide-code-actions",
                    button {
                        class: if *is_running.read() { "guide-code-btn primary running" } else { "guide-code-btn primary" },
                        onclick: handle_run,
                        disabled: *is_running.read(),
                        if *is_running.read() {
                            "Running..."
                        } else {
                            "{mode_label}"
                        }
                    }
                    button {
                        class: "guide-code-btn",
                        onclick: handle_copy,
                        "Copy"
                    }
                    button {
                        class: "guide-code-btn",
                        onclick: handle_reset,
                        "Reset"
                    }
                }
            }

            // Editor
            div { class: "guide-code-editor",
                textarea {
                    class: "guide-code-textarea",
                    rows: rows,
                    value: "{code}",
                    oninput: move |evt| code.set(evt.value()),
                    spellcheck: "false",
                    autocomplete: "off",
                    autocapitalize: "off",
                }

                if *show_copied.read() {
                    div { class: "guide-code-copied", "Copied!" }
                }
            }

            // Output (only show if has run)
            if *has_run.read() {
                div { class: "guide-code-output",
                    div { class: "guide-code-output-header",
                        span { "Output" }
                    }
                    div {
                        class: "guide-code-output-content {output_type}",
                        "{output}"
                    }
                }
            }
        }
    }
}

```

---

### Component: guide_sidebar

**File:** `src/ui/components/guide_sidebar.rs`

Reusable UI component.

```rust
//! Sidebar navigation component for the Programmer's Guide.
//!
//! Features:
//! - Sticky positioning
//! - Sections grouped by Part
//! - Active section highlighting
//! - Click navigation with anchor links

use dioxus::prelude::*;

const SIDEBAR_STYLE: &str = r#"
.guide-sidebar {
    position: sticky;
    top: 90px;
    width: 260px;
    max-height: calc(100vh - 120px);
    overflow-y: auto;
    flex-shrink: 0;
    padding: 4px 0;

    /* Custom scrollbar */
    scrollbar-width: thin;
    scrollbar-color: rgba(255,255,255,0.1) transparent;
}

.guide-sidebar::-webkit-scrollbar {
    width: 6px;
}

.guide-sidebar::-webkit-scrollbar-track {
    background: transparent;
}

.guide-sidebar::-webkit-scrollbar-thumb {
    background: rgba(255,255,255,0.1);
    border-radius: 3px;
}

.guide-sidebar::-webkit-scrollbar-thumb:hover {
    background: rgba(255,255,255,0.2);
}

.sidebar-part {
    margin-bottom: 24px;
}

.sidebar-part:last-child {
    margin-bottom: 0;
}

.sidebar-part-title {
    font-size: 11px;
    font-weight: 700;
    text-transform: uppercase;
    letter-spacing: 0.8px;
    color: rgba(229,231,235,0.45);
    padding: 0 16px;
    margin-bottom: 10px;
}

.sidebar-section {
    display: block;
    padding: 9px 16px;
    margin: 2px 8px;
    border-radius: 8px;
    color: rgba(229,231,235,0.65);
    font-size: 13px;
    font-weight: 500;
    text-decoration: none;
    transition: all 0.18s ease;
    cursor: pointer;
    border-left: 2px solid transparent;
}

.sidebar-section:hover {
    background: rgba(255,255,255,0.05);
    color: rgba(229,231,235,0.9);
}

.sidebar-section.active {
    background: rgba(167,139,250,0.12);
    color: #a78bfa;
    border-left-color: #a78bfa;
    font-weight: 600;
}

.sidebar-section-number {
    display: inline-block;
    min-width: 22px;
    color: rgba(229,231,235,0.35);
    font-weight: 500;
}

.sidebar-section.active .sidebar-section-number {
    color: rgba(167,139,250,0.7);
}

@media (max-width: 1024px) {
    .guide-sidebar {
        display: none;
    }
}

/* Mobile sidebar toggle - shown on mobile */
.sidebar-mobile-toggle {
    display: none;
    position: fixed;
    bottom: 24px;
    right: 24px;
    width: 56px;
    height: 56px;
    border-radius: 50%;
    background: linear-gradient(135deg, #60a5fa, #a78bfa);
    border: none;
    color: #060814;
    font-size: 24px;
    cursor: pointer;
    box-shadow: 0 8px 32px rgba(0,0,0,0.4);
    z-index: 100;
    transition: transform 0.2s ease;
}

.sidebar-mobile-toggle:hover {
    transform: scale(1.05);
}

@media (max-width: 1024px) {
    .sidebar-mobile-toggle {
        display: flex;
        align-items: center;
        justify-content: center;
    }
}
"#;

/// Information about a section for the sidebar
#[derive(Clone, PartialEq, Debug)]
pub struct SectionInfo {
    pub id: String,
    pub number: u8,
    pub title: String,
    pub part: String,
}

#[derive(Props, Clone, PartialEq)]
pub struct GuideSidebarProps {
    pub sections: Vec<SectionInfo>,
    pub active_section: String,
    pub on_section_click: EventHandler<String>,
}

#[component]
pub fn GuideSidebar(props: GuideSidebarProps) -> Element {
    // Group sections by part
    let grouped = group_sections_by_part(&props.sections);

    rsx! {
        style { "{SIDEBAR_STYLE}" }

        nav { class: "guide-sidebar",
            for (part, sections) in grouped {
                div { class: "sidebar-part",
                    h4 { class: "sidebar-part-title", "{part}" }

                    for section in sections {
                        {
                            let section_id = section.id.clone();
                            let is_active = props.active_section == section.id;
                            let class_name = if is_active {
                                "sidebar-section active"
                            } else {
                                "sidebar-section"
                            };

                            rsx! {
                                a {
                                    class: "{class_name}",
                                    href: "#{section_id}",
                                    onclick: {
                                        let id = section.id.clone();
                                        let handler = props.on_section_click.clone();
                                        move |evt: Event<MouseData>| {
                                            evt.prevent_default();
                                            handler.call(id.clone());

                                            // Smooth scroll to section
                                            #[cfg(target_arch = "wasm32")]
                                            {
                                                if let Some(window) = web_sys::window() {
                                                    if let Some(document) = window.document() {
                                                        if let Some(element) = document.get_element_by_id(&id) {
                                                            let options = web_sys::ScrollIntoViewOptions::new();
                                                            options.set_behavior(web_sys::ScrollBehavior::Smooth);
                                                            options.set_block(web_sys::ScrollLogicalPosition::Start);
                                                            let _ = element.scroll_into_view_with_scroll_into_view_options(&options);
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    },
                                    span { class: "sidebar-section-number", "{section.number}." }
                                    " {section.title}"
                                }
                            }
                        }
                    }
                }
            }
        }
    }
}

/// Groups sections by their part name, preserving order
fn group_sections_by_part(sections: &[SectionInfo]) -> Vec<(String, Vec<SectionInfo>)> {
    let mut result: Vec<(String, Vec<SectionInfo>)> = Vec::new();

    for section in sections {
        if let Some((_, group)) = result.iter_mut().find(|(part, _)| part == &section.part) {
            group.push(section.clone());
        } else {
            result.push((section.part.clone(), vec![section.clone()]));
        }
    }

    result
}

/// Mobile sidebar toggle button component
#[component]
pub fn SidebarMobileToggle(on_toggle: EventHandler<()>) -> Element {
    rsx! {
        button {
            class: "sidebar-mobile-toggle",
            onclick: move |_| on_toggle.call(()),
            title: "Toggle navigation",
            "☰"
        }
    }
}

```

---

### Component: InputArea

**File:** `src/ui/components/input.rs`

Text input with Enter key submission and Transpile button.

```rust
use dioxus::prelude::*;

#[component]
pub fn InputArea(on_send: EventHandler<String>) -> Element {
    let mut text = use_signal(String::new);

    let mut submit = move || {
        let current_text = text.read().clone();
        if !current_text.trim().is_empty() {
            on_send.call(current_text);
            text.set(String::new());
        }
    };

    rsx! {
        div { class: "input-area",
            div { class: "input-row",
                input {
                    placeholder: "Type an English sentence...",
                    value: "{text}",
                    oninput: move |evt| text.set(evt.value()),
                    onkeydown: move |evt| {
                        if evt.key() == Key::Enter {
                            submit();
                        }
                    }
                }
                button {
                    onclick: move |_| submit(),
                    "Transpile →"
                }
            }
        }
    }
}

```

---

### Component: katex

**File:** `src/ui/components/katex.rs`

Reusable UI component.

```rust
use dioxus::prelude::*;
use wasm_bindgen::prelude::*;

#[wasm_bindgen]
extern "C" {
    #[wasm_bindgen(js_namespace = window, js_name = renderKaTeX)]
    fn render_katex(element_id: &str, latex: &str, display_mode: bool);
}

static KATEX_COUNTER: std::sync::atomic::AtomicU64 = std::sync::atomic::AtomicU64::new(0);

fn next_katex_id() -> String {
    let id = KATEX_COUNTER.fetch_add(1, std::sync::atomic::Ordering::Relaxed);
    format!("katex-{}", id)
}

#[component]
pub fn KatexSpan(latex: String, #[props(default = false)] display: bool) -> Element {
    let element_id = use_signal(|| next_katex_id());

    use_effect(move || {
        let id = element_id.read().clone();
        let latex = latex.clone();
        render_katex(&id, &latex, display);
    });

    rsx! {
        span {
            id: "{element_id}",
            class: if display { "katex-display" } else { "katex-inline" }
        }
    }
}

#[derive(Debug, Clone, PartialEq)]
pub enum TextPart {
    Plain(String),
    Latex { content: String, display: bool },
}

pub fn parse_latex_in_text(text: &str) -> Vec<TextPart> {
    let mut parts = Vec::new();
    let mut remaining = text;

    while !remaining.is_empty() {
        let display_pos = remaining.find("$$");
        let inline_pos = remaining.find('$');

        match (display_pos, inline_pos) {
            (Some(d), Some(i)) if d <= i => {
                if d > 0 {
                    parts.push(TextPart::Plain(remaining[..d].to_string()));
                }
                remaining = &remaining[d + 2..];
                if let Some(end) = remaining.find("$$") {
                    parts.push(TextPart::Latex {
                        content: remaining[..end].to_string(),
                        display: true,
                    });
                    remaining = &remaining[end + 2..];
                } else {
                    parts.push(TextPart::Plain(format!("$${}", remaining)));
                    break;
                }
            }
            (_, Some(i)) => {
                if i > 0 {
                    parts.push(TextPart::Plain(remaining[..i].to_string()));
                }
                remaining = &remaining[i + 1..];
                if let Some(end) = remaining.find('$') {
                    parts.push(TextPart::Latex {
                        content: remaining[..end].to_string(),
                        display: false,
                    });
                    remaining = &remaining[end + 1..];
                } else {
                    parts.push(TextPart::Plain(format!("${}", remaining)));
                    break;
                }
            }
            (Some(d), None) => {
                if d > 0 {
                    parts.push(TextPart::Plain(remaining[..d].to_string()));
                }
                remaining = &remaining[d + 2..];
                if let Some(end) = remaining.find("$$") {
                    parts.push(TextPart::Latex {
                        content: remaining[..end].to_string(),
                        display: true,
                    });
                    remaining = &remaining[end + 2..];
                } else {
                    parts.push(TextPart::Plain(format!("$${}", remaining)));
                    break;
                }
            }
            (None, None) => {
                parts.push(TextPart::Plain(remaining.to_string()));
                break;
            }
        }
    }

    parts
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_parse_plain_text() {
        let parts = parse_latex_in_text("Hello world");
        assert_eq!(parts.len(), 1);
        assert_eq!(parts[0], TextPart::Plain("Hello world".to_string()));
    }

    #[test]
    fn test_parse_inline_latex() {
        let parts = parse_latex_in_text("The formula $x + y$ is simple");
        assert_eq!(parts.len(), 3);
        assert_eq!(parts[0], TextPart::Plain("The formula ".to_string()));
        assert_eq!(parts[1], TextPart::Latex { content: "x + y".to_string(), display: false });
        assert_eq!(parts[2], TextPart::Plain(" is simple".to_string()));
    }

    #[test]
    fn test_parse_display_latex() {
        let parts = parse_latex_in_text("Consider: $$\\forall x$$ as shown");
        assert_eq!(parts.len(), 3);
        assert_eq!(parts[0], TextPart::Plain("Consider: ".to_string()));
        assert_eq!(parts[1], TextPart::Latex { content: "\\forall x".to_string(), display: true });
        assert_eq!(parts[2], TextPart::Plain(" as shown".to_string()));
    }

    #[test]
    fn test_parse_mixed() {
        let parts = parse_latex_in_text("$A$ and $B$ implies $$A \\land B$$");
        assert_eq!(parts.len(), 5);
        assert_eq!(parts[0], TextPart::Latex { content: "A".to_string(), display: false });
        assert_eq!(parts[1], TextPart::Plain(" and ".to_string()));
        assert_eq!(parts[2], TextPart::Latex { content: "B".to_string(), display: false });
        assert_eq!(parts[3], TextPart::Plain(" implies ".to_string()));
        assert_eq!(parts[4], TextPart::Latex { content: "A \\land B".to_string(), display: true });
    }

    #[test]
    fn test_unclosed_inline() {
        let parts = parse_latex_in_text("Start $unclosed");
        assert_eq!(parts.len(), 2);
        assert_eq!(parts[0], TextPart::Plain("Start ".to_string()));
        assert_eq!(parts[1], TextPart::Plain("$unclosed".to_string()));
    }
}

```

---

### Component: learn_sidebar

**File:** `src/ui/components/learn_sidebar.rs`

Reusable UI component.

```rust
//! Sidebar navigation component for the Learn/Curriculum page.
//!
//! Features:
//! - Sticky positioning
//! - Eras grouped with modules
//! - Active module highlighting
//! - Click navigation with scroll behavior
//! - Difficulty indicators

use dioxus::prelude::*;

const SIDEBAR_STYLE: &str = r#"
.learn-sidebar {
    position: sticky;
    top: 90px;
    width: 280px;
    max-height: calc(100vh - 120px);
    overflow-y: auto;
    flex-shrink: 0;
    padding: var(--spacing-sm) 0;

    /* Custom scrollbar */
    scrollbar-width: thin;
    scrollbar-color: rgba(255,255,255,0.1) transparent;
}

.learn-sidebar::-webkit-scrollbar {
    width: 6px;
}

.learn-sidebar::-webkit-scrollbar-track {
    background: transparent;
}

.learn-sidebar::-webkit-scrollbar-thumb {
    background: rgba(255,255,255,0.1);
    border-radius: 3px;
}

.learn-sidebar::-webkit-scrollbar-thumb:hover {
    background: rgba(255,255,255,0.2);
}

.learn-sidebar-era {
    margin-bottom: var(--spacing-xl);
}

.learn-sidebar-era:last-child {
    margin-bottom: 0;
}

.learn-sidebar-era-title {
    font-size: var(--font-caption-md);
    font-weight: 700;
    text-transform: uppercase;
    letter-spacing: 0.8px;
    color: var(--text-tertiary);
    padding: 0 var(--spacing-lg);
    margin-bottom: var(--spacing-sm);
    display: flex;
    align-items: center;
    gap: var(--spacing-sm);
}

.learn-sidebar-era-title::before {
    content: "";
    width: 8px;
    height: 8px;
    border-radius: 50%;
    background: linear-gradient(135deg, var(--color-accent-blue), var(--color-accent-purple));
    opacity: 0.6;
}

.learn-sidebar-module {
    display: flex;
    align-items: center;
    justify-content: space-between;
    padding: 10px var(--spacing-lg);
    margin: 2px var(--spacing-sm);
    border-radius: var(--radius-md);
    color: var(--text-secondary);
    font-size: var(--font-body-md);
    font-weight: 500;
    text-decoration: none;
    transition: all 0.18s ease;
    cursor: pointer;
    border-left: 3px solid transparent;
}

.learn-sidebar-module:hover {
    background: rgba(255,255,255,0.06);
    color: var(--text-primary);
}

.learn-sidebar-module.active {
    background: rgba(96,165,250,0.15);
    color: var(--color-accent-blue);
    border-left-color: var(--color-accent-blue);
    font-weight: 600;
}

.learn-sidebar-module-name {
    flex: 1;
    white-space: nowrap;
    overflow: hidden;
    text-overflow: ellipsis;
}

.learn-sidebar-difficulty {
    display: flex;
    gap: 2px;
    margin-left: var(--spacing-sm);
    flex-shrink: 0;
}

.learn-sidebar-dot {
    width: 6px;
    height: 6px;
    border-radius: 50%;
    background: rgba(255,255,255,0.15);
}

.learn-sidebar-dot.filled {
    background: linear-gradient(135deg, var(--color-accent-blue), var(--color-accent-purple));
}

.learn-sidebar-module.active .learn-sidebar-dot {
    background: rgba(96,165,250,0.3);
}

.learn-sidebar-module.active .learn-sidebar-dot.filled {
    background: var(--color-accent-blue);
}

.learn-sidebar-count {
    font-size: var(--font-caption-md);
    color: var(--text-muted);
    margin-left: 6px;
    flex-shrink: 0;
}

.learn-sidebar-module.active .learn-sidebar-count {
    color: rgba(96,165,250,0.7);
}

@media (max-width: 1024px) {
    .learn-sidebar {
        display: none;
    }
}
"#;

/// Information about a module for the sidebar
#[derive(Clone, PartialEq, Debug)]
pub struct ModuleInfo {
    pub era_id: String,
    pub era_title: String,
    pub module_id: String,
    pub module_title: String,
    pub exercise_count: u32,
    pub difficulty: u8,
}

#[derive(Props, Clone, PartialEq)]
pub struct LearnSidebarProps {
    pub modules: Vec<ModuleInfo>,
    pub active_module: Option<String>,
    pub on_module_click: EventHandler<(String, String)>, // (era_id, module_id)
}

#[component]
pub fn LearnSidebar(props: LearnSidebarProps) -> Element {
    // Group modules by era
    let grouped = group_modules_by_era(&props.modules);

    rsx! {
        style { "{SIDEBAR_STYLE}" }

        nav { class: "learn-sidebar",
            for (era_id, era_title, modules) in grouped {
                div { class: "learn-sidebar-era",
                    h4 { class: "learn-sidebar-era-title", "{era_title}" }

                    for module in modules {
                        {
                            let is_active = props.active_module.as_ref() == Some(&module.module_id);
                            let class_name = if is_active {
                                "learn-sidebar-module active"
                            } else {
                                "learn-sidebar-module"
                            };

                            let era_for_click = era_id.clone();
                            let mod_for_click = module.module_id.clone();

                            rsx! {
                                a {
                                    class: "{class_name}",
                                    href: "#{module.module_id}",
                                    onclick: {
                                        let era = era_for_click.clone();
                                        let module_id = mod_for_click.clone();
                                        let handler = props.on_module_click.clone();
                                        move |evt: Event<MouseData>| {
                                            evt.prevent_default();
                                            handler.call((era.clone(), module_id.clone()));

                                            // Smooth scroll to section
                                            #[cfg(target_arch = "wasm32")]
                                            {
                                                if let Some(window) = web_sys::window() {
                                                    if let Some(document) = window.document() {
                                                        if let Some(element) = document.get_element_by_id(&module_id) {
                                                            let options = web_sys::ScrollIntoViewOptions::new();
                                                            options.set_behavior(web_sys::ScrollBehavior::Smooth);
                                                            options.set_block(web_sys::ScrollLogicalPosition::Start);
                                                            let _ = element.scroll_into_view_with_scroll_into_view_options(&options);
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    },
                                    span { class: "learn-sidebar-module-name", "{module.module_title}" }

                                    // Difficulty dots
                                    div { class: "learn-sidebar-difficulty",
                                        for i in 1..=5u8 {
                                            div {
                                                class: if i <= module.difficulty { "learn-sidebar-dot filled" } else { "learn-sidebar-dot" }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                }
            }
        }
    }
}

/// Groups modules by their era, preserving order
fn group_modules_by_era(modules: &[ModuleInfo]) -> Vec<(String, String, Vec<ModuleInfo>)> {
    let mut result: Vec<(String, String, Vec<ModuleInfo>)> = Vec::new();

    for module in modules {
        if let Some((_, _, group)) = result.iter_mut().find(|(era_id, _, _)| era_id == &module.era_id) {
            group.push(module.clone());
        } else {
            result.push((module.era_id.clone(), module.era_title.clone(), vec![module.clone()]));
        }
    }

    result
}

```

---

### Component: logic_output

**File:** `src/ui/components/logic_output.rs`

Reusable UI component.

```rust
use dioxus::prelude::*;

const OUTPUT_STYLE: &str = r#"
.logic-output-container {
    display: flex;
    flex-direction: column;
    height: 100%;
    padding: 16px;
}

.reading-selector {
    display: flex;
    align-items: center;
    gap: 8px;
    margin-bottom: 12px;
}

.reading-selector span {
    color: #888;
    font-size: 14px;
}

.reading-btn {
    width: 28px;
    height: 28px;
    border-radius: 6px;
    border: 1px solid rgba(255, 255, 255, 0.2);
    background: rgba(255, 255, 255, 0.08);
    color: #888;
    font-size: 12px;
    cursor: pointer;
    transition: all 0.2s ease;
}

.reading-btn:hover {
    background: rgba(255, 255, 255, 0.15);
    color: #e8e8e8;
}

.reading-btn.active {
    background: linear-gradient(135deg, #667eea, #764ba2);
    border-color: transparent;
    color: white;
}

.logic-display {
    flex: 1;
    background: rgba(255, 255, 255, 0.08);
    border: 1px solid rgba(255, 255, 255, 0.2);
    border-radius: 12px;
    padding: 20px;
    font-family: 'SF Mono', 'Fira Code', 'Consolas', monospace;
    font-size: 18px;
    line-height: 1.6;
    color: #e8e8e8;
    overflow: auto;
}

.logic-display.empty {
    color: #666;
    font-style: italic;
    display: flex;
    align-items: center;
    justify-content: center;
}

.logic-display.error {
    border-color: rgba(224, 108, 117, 0.3);
    color: #e06c75;
}

.logic-quantifier { color: #c678dd; font-weight: 500; }
.logic-variable { color: #61afef; }
.logic-predicate { color: #98c379; }
.logic-connective { color: #c678dd; }
.logic-constant { color: #e5c07b; }
.logic-paren { color: #abb2bf; }
"#;

#[derive(Clone, Copy, PartialEq, Default)]
pub enum OutputFormat {
    #[default]
    Unicode,
    SimpleFOL,
    LaTeX,
}

#[component]
pub fn LogicOutput(
    logic: Option<String>,
    simple_logic: Option<String>,
    readings: Vec<String>,
    error: Option<String>,
    format: OutputFormat,
) -> Element {
    let mut current_reading = use_signal(|| 0usize);

    let total_readings = readings.len().max(1);
    let display_logic = if !readings.is_empty() {
        let idx = (*current_reading.read()).min(readings.len().saturating_sub(1));
        Some(readings.get(idx).cloned().unwrap_or_default())
    } else {
        logic.clone()
    };

    let formatted_output = match format {
        OutputFormat::SimpleFOL => simple_logic.clone().unwrap_or_default(),
        OutputFormat::LaTeX => display_logic.as_ref().map(|l| convert_to_latex(l)).unwrap_or_default(),
        OutputFormat::Unicode => display_logic.clone().unwrap_or_default(),
    };

    rsx! {
        style { "{OUTPUT_STYLE}" }

        div { class: "logic-output-container",
            if total_readings > 1 {
                div { class: "reading-selector",
                    span { "Reading" }
                    for i in 0..total_readings {
                        button {
                            class: if *current_reading.read() == i { "reading-btn active" } else { "reading-btn" },
                            onclick: move |_| current_reading.set(i),
                            "{i + 1}"
                        }
                    }
                    span { "of {total_readings}" }
                }
            }

            if let Some(err) = &error {
                div { class: "logic-display error",
                    "{err}"
                }
            } else if formatted_output.is_empty() {
                div { class: "logic-display empty",
                    "Type a sentence to see its logical form..."
                }
            } else {
                div { class: "logic-display",
                    dangerous_inner_html: highlight_logic(&formatted_output)
                }
            }
        }
    }
}

fn convert_to_latex(unicode: &str) -> String {
    unicode
        .replace('\u{2200}', "\\forall ")
        .replace('\u{2203}', "\\exists ")
        .replace('\u{00AC}', "\\neg ")
        .replace('\u{2227}', "\\land ")
        .replace('\u{2228}', "\\lor ")
        .replace('\u{2192}', "\\rightarrow ")
        .replace('\u{2194}', "\\leftrightarrow ")
        .replace('\u{22A5}', "\\bot ")
        .replace('\u{22A4}', "\\top ")
}

pub fn highlight_logic(logic: &str) -> String {
    let mut result = String::new();
    let mut chars = logic.chars().peekable();

    while let Some(c) = chars.next() {
        match c {
            '\u{2200}' | '\u{2203}' => {
                result.push_str(&format!(r#"<span class="logic-quantifier">{}</span>"#, c));
            }
            '\u{00AC}' | '\u{2227}' | '\u{2228}' | '\u{2192}' | '\u{2194}' => {
                result.push_str(&format!(r#"<span class="logic-connective">{}</span>"#, c));
            }
            '(' | ')' | '[' | ']' => {
                result.push_str(&format!(r#"<span class="logic-paren">{}</span>"#, c));
            }
            'a'..='z' if chars.peek().map(|n| !n.is_alphabetic()).unwrap_or(true) => {
                result.push_str(&format!(r#"<span class="logic-variable">{}</span>"#, c));
            }
            'A'..='Z' => {
                let mut word = String::from(c);
                while let Some(&next) = chars.peek() {
                    if next.is_alphanumeric() {
                        word.push(chars.next().unwrap());
                    } else {
                        break;
                    }
                }
                if word.chars().next().map(|c| c.is_uppercase()).unwrap_or(false)
                    && word.len() > 1
                    && word.chars().skip(1).all(|c| c.is_lowercase() || c.is_numeric())
                {
                    result.push_str(&format!(r#"<span class="logic-constant">{}</span>"#, word));
                } else {
                    result.push_str(&format!(r#"<span class="logic-predicate">{}</span>"#, word));
                }
            }
            _ => result.push(c),
        }
    }

    result
}

```

---

### Component: main_nav

**File:** `src/ui/components/main_nav.rs`

Reusable UI component.

```rust
//! Unified navigation component for consistent header across all pages.
//!
//! Features:
//! - Logo and brand name
//! - Navigation links with active underline indicator
//! - GitHub icon and CTA buttons
//! - Responsive design

use dioxus::prelude::*;
use crate::ui::router::Route;

/// Embedded logo SVG
const LOGO_SVG: &str = include_str!("../../../assets/logo.svg");

/// Navigation item definition
#[derive(Clone, PartialEq)]
pub struct NavItem {
    pub label: &'static str,
    pub route: Route,
}

/// Which page is currently active
#[derive(Clone, Copy, PartialEq, Default)]
pub enum ActivePage {
    #[default]
    Guide,
    Learn,
    Studio,
    Roadmap,
    Pricing,
    Registry,
    Profile,
    Other,
}

impl ActivePage {
    /// Determine the active page from a Route
    pub fn from_route(route: &Route) -> Self {
        match route {
            Route::Landing {} => ActivePage::Other,
            Route::Guide {} => ActivePage::Guide,
            Route::Learn {} => ActivePage::Learn,
            Route::Studio {} => ActivePage::Studio,
            Route::Workspace { .. } => ActivePage::Studio,
            Route::Roadmap {} => ActivePage::Roadmap,
            Route::Pricing {} => ActivePage::Pricing,
            Route::Success {} => ActivePage::Pricing,
            Route::Registry {} => ActivePage::Registry,
            Route::PackageDetail { .. } => ActivePage::Registry,
            Route::Profile {} => ActivePage::Profile,
            _ => ActivePage::Other,
        }
    }
}

const MAIN_NAV_STYLE: &str = r#"
.main-nav {
    position: sticky;
    top: 0;
    z-index: 50;
    backdrop-filter: blur(18px);
    background: linear-gradient(180deg, rgba(7,10,18,0.72), rgba(7,10,18,0.44));
    border-bottom: 1px solid rgba(255,255,255,0.06);
}

.main-nav-inner {
    display: flex;
    align-items: center;
    justify-content: space-between;
    padding: var(--spacing-lg) var(--spacing-xl);
    max-width: 1280px;
    margin: 0 auto;
    gap: var(--spacing-lg);
}

.main-nav-brand {
    display: flex;
    align-items: center;
    gap: var(--spacing-md);
    text-decoration: none;
    color: var(--text-primary);
}

.main-nav-logo {
    width: 64px;
    height: 64px;
    border-radius: var(--radius-lg);
    overflow: hidden;
}

.main-nav-logo svg {
    width: 100%;
    height: 100%;
    filter: invert(1);
}

.main-nav-brand-text {
    display: flex;
    flex-direction: column;
    line-height: 1.05;
}

.main-nav-brand-name {
    font-weight: 800;
    letter-spacing: -0.5px;
    font-size: var(--font-body-md);
}

.main-nav-brand-subtitle {
    font-size: var(--font-caption-sm);
    color: var(--text-tertiary);
}

.main-nav-links {
    display: flex;
    gap: var(--spacing-xs);
    align-items: center;
}

.main-nav-link {
    position: relative;
    text-decoration: none;
    padding: 10px 14px;
    font-size: var(--font-body-md);
    font-weight: 500;
    color: var(--text-secondary);
    transition: color 0.18s ease;
    border-radius: var(--radius-md);
}

.main-nav-link:hover {
    color: var(--text-primary);
    background: rgba(255,255,255,0.04);
}

/* Active underline indicator */
.main-nav-link::after {
    content: "";
    position: absolute;
    bottom: 2px;
    left: 14px;
    right: 14px;
    height: 2px;
    background: linear-gradient(90deg, var(--color-accent-blue), var(--color-accent-purple));
    border-radius: 2px;
    opacity: 0;
    transform: scaleX(0);
    transition: opacity 0.18s ease, transform 0.18s ease;
}

.main-nav-link.active {
    color: var(--text-primary);
}

.main-nav-link.active::after {
    opacity: 1;
    transform: scaleX(1);
}

.main-nav-cta {
    display: flex;
    gap: 10px;
    align-items: center;
}

.main-nav-btn {
    display: inline-flex;
    align-items: center;
    justify-content: center;
    gap: var(--spacing-sm);
    padding: 10px var(--spacing-lg);
    border-radius: var(--radius-lg);
    border: 1px solid rgba(255,255,255,0.10);
    background: rgba(255,255,255,0.05);
    text-decoration: none;
    font-weight: 600;
    font-size: var(--font-body-md);
    color: var(--text-primary);
    transition: transform 0.18s ease, background 0.18s ease, border-color 0.18s ease;
}

.main-nav-btn:hover {
    transform: translateY(-1px);
    background: rgba(255,255,255,0.08);
    border-color: rgba(255,255,255,0.18);
}

.main-nav-btn.primary {
    background: linear-gradient(135deg, rgba(96,165,250,0.95), rgba(167,139,250,0.95));
    border-color: rgba(255,255,255,0.20);
    color: #060814;
    box-shadow: 0 12px 30px rgba(96,165,250,0.18);
}

.main-nav-btn.primary:hover {
    background: linear-gradient(135deg, rgba(96,165,250,1.0), rgba(167,139,250,1.0));
}

.main-nav-btn.ghost {
    background: rgba(255,255,255,0.03);
}

.main-nav-btn-icon {
    padding: 10px;
    background: rgba(255,255,255,0.03);
}

.main-nav-btn-icon svg {
    width: 20px;
    height: 20px;
    fill: currentColor;
}

/* Responsive */
@media (max-width: 980px) {
    .main-nav-links {
        display: none;
    }
    .main-nav-brand-text {
        display: none;
    }
}

@media (max-width: 640px) {
    .main-nav-inner {
        padding: var(--spacing-md) var(--spacing-lg);
    }
    .main-nav-btn {
        padding: var(--spacing-sm) var(--spacing-md);
        font-size: var(--font-caption-md);
    }
}
"#;

/// Main navigation component with consistent styling and active page underline
#[component]
pub fn MainNav(
    /// The currently active page
    #[props(default)]
    active: ActivePage,
    /// Optional subtitle for the brand (e.g., "Programmer's Guide")
    #[props(default)]
    subtitle: Option<&'static str>,
    /// Whether to show the full nav links (default true)
    #[props(default = true)]
    show_nav_links: bool,
) -> Element {
    rsx! {
        style { "{MAIN_NAV_STYLE}" }

        header { class: "main-nav",
            div { class: "main-nav-inner",
                // Brand
                Link {
                    to: Route::Landing {},
                    class: "main-nav-brand",
                    div {
                        class: "main-nav-logo",
                        dangerous_inner_html: "{LOGO_SVG}"
                    }
                    div { class: "main-nav-brand-text",
                        span { class: "main-nav-brand-name", "LOGICAFFEINE" }
                        if let Some(sub) = subtitle {
                            span { class: "main-nav-brand-subtitle", "{sub}" }
                        } else {
                            span { class: "main-nav-brand-subtitle", "Debug your thoughts." }
                        }
                    }
                }

                // Navigation links with active underline
                if show_nav_links {
                    nav { class: "main-nav-links",
                        Link {
                            to: Route::Guide {},
                            class: if active == ActivePage::Guide { "main-nav-link active" } else { "main-nav-link" },
                            "Guide"
                        }
                        Link {
                            to: Route::Learn {},
                            class: if active == ActivePage::Learn { "main-nav-link active" } else { "main-nav-link" },
                            "Learn"
                        }
                        Link {
                            to: Route::Studio {},
                            class: if active == ActivePage::Studio { "main-nav-link active" } else { "main-nav-link" },
                            "Studio"
                        }
                        Link {
                            to: Route::Roadmap {},
                            class: if active == ActivePage::Roadmap { "main-nav-link active" } else { "main-nav-link" },
                            "Roadmap"
                        }
                        Link {
                            to: Route::Pricing {},
                            class: if active == ActivePage::Pricing { "main-nav-link active" } else { "main-nav-link" },
                            "Pricing"
                        }
                    }
                }

                // CTA buttons
                div { class: "main-nav-cta",
                    // GitHub button
                    a {
                        href: "https://github.com/Brahmastra-Labs/logicaffeine",
                        target: "_blank",
                        class: "main-nav-btn main-nav-btn-icon",
                        title: "View on GitHub",
                        svg {
                            xmlns: "http://www.w3.org/2000/svg",
                            view_box: "0 0 24 24",
                            path {
                                d: "M12 0C5.37 0 0 5.37 0 12c0 5.31 3.435 9.795 8.205 11.385.6.105.825-.255.825-.57 0-.285-.015-1.23-.015-2.235-3.015.555-3.795-.735-4.035-1.41-.135-.345-.72-1.41-1.23-1.695-.42-.225-1.02-.78-.015-.795.945-.015 1.62.87 1.845 1.23 1.08 1.815 2.805 1.305 3.495.99.105-.78.42-1.305.765-1.605-2.67-.3-5.46-1.335-5.46-5.925 0-1.305.465-2.385 1.23-3.225-.12-.3-.54-1.53.12-3.18 0 0 1.005-.315 3.3 1.23.96-.27 1.98-.405 3-.405s2.04.135 3 .405c2.295-1.56 3.3-1.23 3.3-1.23.66 1.65.24 2.88.12 3.18.765.84 1.23 1.905 1.23 3.225 0 4.605-2.805 5.625-5.475 5.925.435.375.81 1.095.81 2.22 0 1.605-.015 2.895-.015 3.3 0 .315.225.69.825.57A12.02 12.02 0 0024 12c0-6.63-5.37-12-12-12z"
                            }
                        }
                    }
                    // Profile button
                    Link {
                        to: Route::Profile {},
                        class: if active == ActivePage::Profile { "main-nav-btn main-nav-btn-icon active" } else { "main-nav-btn main-nav-btn-icon" },
                        title: "Your Profile",
                        svg {
                            xmlns: "http://www.w3.org/2000/svg",
                            view_box: "0 0 24 24",
                            path {
                                d: "M12 12c2.21 0 4-1.79 4-4s-1.79-4-4-4-4 1.79-4 4 1.79 4 4 4zm0 2c-2.67 0-8 1.34-8 4v2h16v-2c0-2.66-5.33-4-8-4z"
                            }
                        }
                    }
                }
            }
        }
    }
}

```

---

### Component: mixed_text

**File:** `src/ui/components/mixed_text.rs`

Reusable UI component.

```rust
use dioxus::prelude::*;
use super::katex::{KatexSpan, TextPart, parse_latex_in_text};

#[component]
pub fn MixedText(content: String) -> Element {
    let parts = parse_latex_in_text(&content);

    rsx! {
        span { class: "mixed-text",
            for (i, part) in parts.iter().enumerate() {
                match part {
                    TextPart::Plain(text) => rsx! {
                        span { key: "{i}", "{text}" }
                    },
                    TextPart::Latex { content, display } => rsx! {
                        KatexSpan { key: "{i}", latex: content.clone(), display: *display }
                    },
                }
            }
        }
    }
}

```

---

### Component: mod

**File:** `src/ui/components/mod.rs`

Reusable UI component.

```rust
pub mod app_navbar;
pub mod chat;
pub mod input;
pub mod editor;
pub mod logic_output;
pub mod ast_tree;
pub mod socratic_guide;
pub mod katex;
pub mod mixed_text;
pub mod xp_popup;
pub mod combo_indicator;
pub mod streak_display;
pub mod achievement_toast;
pub mod mode_selector;
pub mod guide_code_block;
pub mod guide_sidebar;
pub mod learn_sidebar;
pub mod main_nav;
pub mod module_tabs;
pub mod symbol_dictionary;
pub mod vocab_reference;

```

---

### Component: mode_selector

**File:** `src/ui/components/mode_selector.rs`

Reusable UI component.

```rust
use dioxus::prelude::*;

const MODE_SELECTOR_STYLE: &str = r#"
.mode-overlay {
    position: fixed;
    top: 0;
    left: 0;
    right: 0;
    bottom: 0;
    background: rgba(0, 0, 0, 0.8);
    display: flex;
    align-items: center;
    justify-content: center;
    z-index: 1000;
    animation: fade-in 0.2s ease-out;
}

@keyframes fade-in {
    from { opacity: 0; }
    to { opacity: 1; }
}

.mode-dialog {
    background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
    border: 1px solid rgba(255, 255, 255, 0.1);
    border-radius: 20px;
    padding: 32px;
    max-width: 600px;
    width: 90%;
    animation: slide-up 0.3s ease-out;
}

@keyframes slide-up {
    from { transform: translateY(20px); opacity: 0; }
    to { transform: translateY(0); opacity: 1; }
}

.mode-dialog h2 {
    color: #e8e8e8;
    font-size: 24px;
    margin-bottom: 8px;
    text-align: center;
}

.mode-dialog p {
    color: #888;
    font-size: 14px;
    text-align: center;
    margin-bottom: 24px;
}

.mode-options {
    display: flex;
    flex-direction: column;
    gap: 12px;
}

.mode-option {
    display: flex;
    align-items: center;
    gap: 16px;
    padding: 20px;
    background: rgba(255, 255, 255, 0.03);
    border: 2px solid rgba(255, 255, 255, 0.08);
    border-radius: 12px;
    cursor: pointer;
    transition: all 0.2s ease;
}

.mode-option:hover {
    background: rgba(255, 255, 255, 0.06);
    border-color: rgba(255, 255, 255, 0.15);
    transform: translateX(4px);
}

.mode-option.textbook:hover {
    border-color: rgba(96, 165, 250, 0.5);
}

.mode-option.learning:hover {
    border-color: rgba(74, 222, 128, 0.5);
}

.mode-option.testing:hover {
    border-color: rgba(251, 146, 60, 0.5);
}

.mode-icon {
    width: 48px;
    height: 48px;
    display: flex;
    align-items: center;
    justify-content: center;
    border-radius: 12px;
    font-size: 24px;
}

.mode-icon.textbook {
    background: rgba(96, 165, 250, 0.2);
}

.mode-icon.learning {
    background: rgba(74, 222, 128, 0.2);
}

.mode-icon.testing {
    background: rgba(251, 146, 60, 0.2);
}

.mode-info {
    flex: 1;
}

.mode-info h3 {
    color: #e8e8e8;
    font-size: 18px;
    margin-bottom: 4px;
}

.mode-info p {
    color: #888;
    font-size: 13px;
    text-align: left;
    margin: 0;
}

.mode-arrow {
    color: #666;
    font-size: 20px;
}

.mode-cancel {
    display: block;
    width: 100%;
    margin-top: 16px;
    padding: 12px;
    background: transparent;
    border: 1px solid rgba(255, 255, 255, 0.1);
    border-radius: 8px;
    color: #888;
    font-size: 14px;
    cursor: pointer;
    transition: all 0.2s ease;
}

.mode-cancel:hover {
    border-color: rgba(255, 255, 255, 0.2);
    color: #aaa;
}

.recommended-badge {
    background: rgba(74, 222, 128, 0.2);
    color: #4ade80;
    padding: 2px 8px;
    border-radius: 4px;
    font-size: 10px;
    font-weight: 600;
    text-transform: uppercase;
    margin-left: 8px;
}
"#;

#[derive(Clone, PartialEq)]
pub struct ModeInfo {
    pub era: String,
    pub module: String,
    pub title: String,
}

#[component]
pub fn ModeSelector(
    info: ModeInfo,
    on_select: EventHandler<String>,
    on_cancel: EventHandler<()>,
) -> Element {
    rsx! {
        style { "{MODE_SELECTOR_STYLE}" }
        div {
            class: "mode-overlay",
            onclick: move |_| on_cancel.call(()),
            div {
                class: "mode-dialog",
                onclick: move |e| e.stop_propagation(),
                h2 { "{info.title}" }
                p { "Choose how you want to approach this module" }

                div { class: "mode-options",
                    button {
                        class: "mode-option textbook",
                        onclick: move |_| on_select.call("textbook".to_string()),
                        div { class: "mode-icon textbook", "📖" }
                        div { class: "mode-info",
                            h3 { "Read" }
                            p { "Study the concepts and examples before practicing" }
                        }
                        span { class: "mode-arrow", "→" }
                    }

                    button {
                        class: "mode-option learning",
                        onclick: move |_| on_select.call("learning".to_string()),
                        div { class: "mode-icon learning", "🎓" }
                        div { class: "mode-info",
                            h3 {
                                "Practice"
                                span { class: "recommended-badge", "Recommended" }
                            }
                            p { "Learn with hints and immediate feedback on your answers" }
                        }
                        span { class: "mode-arrow", "→" }
                    }

                    button {
                        class: "mode-option testing",
                        onclick: move |_| on_select.call("testing".to_string()),
                        div { class: "mode-icon testing", "📋" }
                        div { class: "mode-info",
                            h3 { "Test" }
                            p { "Prove your knowledge with no hints - see results at the end" }
                        }
                        span { class: "mode-arrow", "→" }
                    }
                }

                button {
                    class: "mode-cancel",
                    onclick: move |_| on_cancel.call(()),
                    "Cancel"
                }
            }
        }
    }
}

```

---

### Component: module_tabs

**File:** `src/ui/components/module_tabs.rs`

Reusable UI component.

```rust
//! Module Tab Bar component for the integrated Learn page.
//!
//! Displays tabs: LESSON | EXAMPLES | PRACTICE ∞ | TEST 📝
//! allowing users to switch between different learning modes within a module.

use dioxus::prelude::*;
use crate::learn_state::TabMode;

const MODULE_TABS_STYLE: &str = r#"
.module-tabs {
    display: flex;
    gap: 4px;
    padding: 4px;
    background: rgba(255, 255, 255, 0.03);
    border-radius: 12px;
    border: 1px solid rgba(255, 255, 255, 0.08);
    width: fit-content;
}

.module-tab {
    padding: 10px 18px;
    border-radius: 8px;
    border: none;
    background: transparent;
    color: rgba(229, 231, 235, 0.56);
    font-size: 12px;
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    cursor: pointer;
    transition: all 0.2s ease;
    white-space: nowrap;
}

.module-tab:hover:not(.locked):not(.active) {
    color: rgba(229, 231, 235, 0.85);
    background: rgba(255, 255, 255, 0.05);
}

.module-tab.active {
    background: linear-gradient(135deg, rgba(96, 165, 250, 0.2), rgba(167, 139, 250, 0.2));
    color: #e5e7eb;
    box-shadow: 0 2px 8px rgba(96, 165, 250, 0.15);
}

.module-tab.locked {
    opacity: 0.4;
    cursor: not-allowed;
}

.module-tab.lesson.active {
    background: linear-gradient(135deg, rgba(96, 165, 250, 0.25), rgba(96, 165, 250, 0.15));
}

.module-tab.examples.active {
    background: linear-gradient(135deg, rgba(167, 139, 250, 0.25), rgba(167, 139, 250, 0.15));
}

.module-tab.practice.active {
    background: linear-gradient(135deg, rgba(74, 222, 128, 0.25), rgba(74, 222, 128, 0.15));
}

.module-tab.test.active {
    background: linear-gradient(135deg, rgba(251, 146, 60, 0.25), rgba(251, 146, 60, 0.15));
}

/* Compact variant for inline use */
.module-tabs.compact {
    padding: 2px;
    gap: 2px;
}

.module-tabs.compact .module-tab {
    padding: 6px 12px;
    font-size: 11px;
}
"#;

/// Props for the ModuleTabs component
#[derive(Props, Clone, PartialEq)]
pub struct ModuleTabsProps {
    /// Currently active tab
    current: TabMode,
    /// Handler called when user clicks a tab
    on_change: EventHandler<TabMode>,
    /// Tabs that should be locked (disabled)
    #[props(default)]
    locked_tabs: Vec<TabMode>,
    /// Use compact variant
    #[props(default = false)]
    compact: bool,
}

/// Tab bar for switching between module learning modes
#[component]
pub fn ModuleTabs(props: ModuleTabsProps) -> Element {
    let container_class = if props.compact {
        "module-tabs compact"
    } else {
        "module-tabs"
    };

    rsx! {
        style { "{MODULE_TABS_STYLE}" }
        div { class: "{container_class}",
            for tab in TabMode::all() {
                {
                    let is_active = tab == props.current;
                    let is_locked = props.locked_tabs.contains(&tab);
                    let tab_class_name = match tab {
                        TabMode::Lesson => "lesson",
                        TabMode::Examples => "examples",
                        TabMode::Practice => "practice",
                        TabMode::Test => "test",
                    };
                    let class = format!(
                        "module-tab {}{}{}",
                        tab_class_name,
                        if is_active { " active" } else { "" },
                        if is_locked { " locked" } else { "" }
                    );

                    rsx! {
                        button {
                            key: "{tab_class_name}",
                            class: "{class}",
                            disabled: is_locked,
                            onclick: {
                                let on_change = props.on_change.clone();
                                move |_| {
                                    if !is_locked {
                                        on_change.call(tab);
                                    }
                                }
                            },
                            "{tab.label()}"
                        }
                    }
                }
            }
        }
    }
}

/// Individual tab button component for custom layouts
#[component]
pub fn TabButton(
    tab: TabMode,
    is_active: bool,
    #[props(default = false)] is_locked: bool,
    on_click: EventHandler<TabMode>,
) -> Element {
    let tab_class_name = match tab {
        TabMode::Lesson => "lesson",
        TabMode::Examples => "examples",
        TabMode::Practice => "practice",
        TabMode::Test => "test",
    };
    let class = format!(
        "module-tab {}{}{}",
        tab_class_name,
        if is_active { " active" } else { "" },
        if is_locked { " locked" } else { "" }
    );

    rsx! {
        style { "{MODULE_TABS_STYLE}" }
        button {
            class: "{class}",
            disabled: is_locked,
            onclick: move |_| {
                if !is_locked {
                    on_click.call(tab);
                }
            },
            "{tab.label()}"
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_tab_class_names() {
        // Verify class name generation logic
        assert!(TabMode::Lesson.label().contains("LESSON"));
        assert!(TabMode::Practice.label().contains("PRACTICE"));
    }
}

```

---

### Component: socratic_guide

**File:** `src/ui/components/socratic_guide.rs`

Reusable UI component.

```rust
use dioxus::prelude::*;

const GUIDE_STYLE: &str = r#"
.socratic-guide {
    display: flex;
    align-items: flex-start;
    gap: 12px;
    padding: 16px 20px;
    background: rgba(255, 255, 255, 0.03);
    border-top: 1px solid rgba(255, 255, 255, 0.08);
    min-height: 60px;
}

.guide-avatar {
    width: 36px;
    height: 36px;
    border-radius: 50%;
    background: linear-gradient(135deg, #667eea, #764ba2);
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 18px;
    flex-shrink: 0;
}

.guide-content {
    flex: 1;
    display: flex;
    flex-direction: column;
    gap: 4px;
}

.guide-label {
    font-size: 11px;
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    color: #667eea;
}

.guide-message {
    font-size: 14px;
    line-height: 1.5;
    color: #c8c8c8;
}

.guide-message.error {
    color: #e06c75;
}

.guide-message.hint {
    color: #98c379;
}

.guide-message.info {
    color: #61afef;
}

.guide-message code {
    font-family: 'SF Mono', 'Fira Code', 'Consolas', monospace;
    background: rgba(255, 255, 255, 0.08);
    padding: 2px 6px;
    border-radius: 4px;
    font-size: 13px;
}

.guide-actions {
    display: flex;
    gap: 8px;
    margin-top: 8px;
}

.guide-btn {
    padding: 6px 12px;
    border-radius: 6px;
    border: 1px solid rgba(255, 255, 255, 0.15);
    background: rgba(255, 255, 255, 0.05);
    color: #888;
    font-size: 12px;
    cursor: pointer;
    transition: all 0.2s ease;
}

.guide-btn:hover {
    background: rgba(255, 255, 255, 0.1);
    color: #e8e8e8;
}

.guide-btn.primary {
    background: linear-gradient(135deg, #667eea, #764ba2);
    border-color: transparent;
    color: white;
}

.guide-btn.primary:hover {
    opacity: 0.9;
}

.guide-empty {
    color: #666;
    font-style: italic;
}
"#;

#[derive(Clone, PartialEq)]
pub enum GuideMode {
    Idle,
    Success(String),
    Error(String),
    Hint(String),
    Info(String),
}

impl Default for GuideMode {
    fn default() -> Self {
        GuideMode::Idle
    }
}

#[component]
pub fn SocraticGuide(
    mode: GuideMode,
    on_hint_request: Option<EventHandler<()>>,
) -> Element {
    let (message_class, label, message) = match &mode {
        GuideMode::Idle => {
            return rsx! {
                style { "{GUIDE_STYLE}" }
                div { class: "socratic-guide",
                    div { class: "guide-avatar", "\u{1F989}" }
                    div { class: "guide-content",
                        div { class: "guide-label", "Socrates" }
                        div { class: "guide-message guide-empty",
                            "Type a sentence to begin your journey into logic..."
                        }
                    }
                }
            }
        }
        GuideMode::Success(msg) => ("guide-message", "Analysis", msg.clone()),
        GuideMode::Error(msg) => ("guide-message error", "Something to consider", msg.clone()),
        GuideMode::Hint(msg) => ("guide-message hint", "Hint", msg.clone()),
        GuideMode::Info(msg) => ("guide-message info", "Observation", msg.clone()),
    };

    rsx! {
        style { "{GUIDE_STYLE}" }

        div { class: "socratic-guide",
            div { class: "guide-avatar", "\u{1F989}" }
            div { class: "guide-content",
                div { class: "guide-label", "{label}" }
                div { class: "{message_class}",
                    dangerous_inner_html: format_guide_message(&message)
                }
                if on_hint_request.is_some() && matches!(mode, GuideMode::Error(_)) {
                    div { class: "guide-actions",
                        button {
                            class: "guide-btn",
                            onclick: move |_| {
                                if let Some(handler) = &on_hint_request {
                                    handler.call(());
                                }
                            },
                            "Show me a hint"
                        }
                    }
                }
            }
        }
    }
}

fn format_guide_message(message: &str) -> String {
    let mut result = message.to_string();

    let code_patterns = [
        ("\u{2200}", "<code>\u{2200}</code>"),
        ("\u{2203}", "<code>\u{2203}</code>"),
        ("\u{2227}", "<code>\u{2227}</code>"),
        ("\u{2228}", "<code>\u{2228}</code>"),
        ("\u{2192}", "<code>\u{2192}</code>"),
        ("\u{00AC}", "<code>\u{00AC}</code>"),
    ];

    for (pattern, replacement) in &code_patterns {
        result = result.replace(pattern, replacement);
    }

    result
}

pub fn get_success_message(readings_count: usize) -> String {
    match readings_count {
        0 => "Hmm, I couldn't parse that sentence. Let me think about why...".to_string(),
        1 => "This sentence has a single, unambiguous logical form.".to_string(),
        2 => format!(
            "Interesting! This sentence is ambiguous. I found {} different readings. \
            Click the reading buttons above to explore each interpretation.",
            readings_count
        ),
        n => format!(
            "Fascinating complexity! I discovered {} different ways to interpret this sentence. \
            Each represents a valid logical reading of your input.",
            n
        ),
    }
}

pub fn get_context_hint(input: &str) -> Option<String> {
    let lower = input.to_lowercase();

    if lower.starts_with("every") || lower.starts_with("all") {
        Some("Universal quantification (\u{2200}) asserts something about ALL members of a set.".to_string())
    } else if lower.starts_with("some") || lower.starts_with("a ") {
        Some("Existential quantification (\u{2203}) asserts the EXISTENCE of at least one entity.".to_string())
    } else if lower.contains(" loves ") || lower.contains(" sees ") {
        Some("Transitive verbs create two-place predicates relating a subject to an object.".to_string())
    } else if lower.contains(" is ") && lower.contains(" not ") {
        Some("Negation (\u{00AC}) inverts the truth value of the proposition it scopes over.".to_string())
    } else {
        None
    }
}

```

---

### Component: streak_display

**File:** `src/ui/components/streak_display.rs`

Reusable UI component.

```rust
use dioxus::prelude::*;
use crate::game::StreakStatus;

const STREAK_STYLE: &str = r#"
.streak-display {
    display: flex;
    align-items: center;
    gap: 8px;
    padding: 6px 12px;
    border-radius: 20px;
    font-size: 14px;
    font-weight: 500;
}

.streak-active {
    background: rgba(249, 115, 22, 0.15);
    border: 1px solid rgba(249, 115, 22, 0.3);
    color: #f97316;
}

.streak-at-risk {
    background: rgba(248, 113, 113, 0.15);
    border: 1px solid rgba(248, 113, 113, 0.3);
    color: #f87171;
    animation: risk-pulse 1s ease-in-out infinite;
}

@keyframes risk-pulse {
    0%, 100% { opacity: 1; }
    50% { opacity: 0.7; }
}

.streak-frozen {
    background: rgba(56, 189, 248, 0.15);
    border: 1px solid rgba(56, 189, 248, 0.3);
    color: #38bdf8;
}

.streak-lost {
    background: rgba(107, 114, 128, 0.15);
    border: 1px solid rgba(107, 114, 128, 0.3);
    color: #9ca3af;
}

.streak-icon {
    font-size: 16px;
}

.streak-count {
    font-weight: 600;
}

.streak-label {
    color: #888;
    font-size: 12px;
}

.freeze-tokens {
    display: flex;
    gap: 4px;
    margin-left: 8px;
    padding-left: 8px;
    border-left: 1px solid rgba(255, 255, 255, 0.1);
}

.freeze-token {
    font-size: 12px;
    opacity: 0.8;
}

.freeze-token.empty {
    opacity: 0.3;
}
"#;

#[component]
pub fn StreakDisplay(streak: u32, status: StreakStatus, freezes: u8) -> Element {
    let (class, icon, text) = match status {
        StreakStatus::Active { days } => {
            ("streak-display streak-active", "🔥", format!("{} day streak", days))
        }
        StreakStatus::AtRisk => {
            ("streak-display streak-at-risk", "⚠️", "Streak at risk!".to_string())
        }
        StreakStatus::Frozen => {
            ("streak-display streak-frozen", "🛡️", format!("{} days (frozen)", streak))
        }
        StreakStatus::Lost { was } => {
            ("streak-display streak-lost", "💔", format!("Lost {} day streak", was))
        }
    };

    rsx! {
        style { "{STREAK_STYLE}" }
        div { class: "{class}",
            span { class: "streak-icon", "{icon}" }
            span { class: "streak-count", "{text}" }
            div { class: "freeze-tokens",
                for i in 0..3u8 {
                    span {
                        class: if i < freezes { "freeze-token" } else { "freeze-token empty" },
                        "🛡️"
                    }
                }
            }
        }
    }
}

```

---

### Component: symbol_dictionary

**File:** `src/ui/components/symbol_dictionary.rs`

Reusable UI component.

```rust
//! Symbol Dictionary component for displaying FOL symbol meanings.
//!
//! Automatically extracts symbols from a First-Order Logic formula
//! and displays them grouped by category with descriptions.

use dioxus::prelude::*;
use crate::symbol_dict::{extract_symbols, group_symbols_by_kind, SymbolKind};

const SYMBOL_DICT_STYLE: &str = r#"
.symbol-dictionary {
    background: rgba(255, 255, 255, 0.03);
    border: 1px solid rgba(255, 255, 255, 0.08);
    border-radius: 12px;
    padding: 16px;
    margin-top: 16px;
}

.symbol-dictionary.collapsed {
    padding: 12px 16px;
    cursor: pointer;
}

.symbol-dictionary.collapsed:hover {
    background: rgba(255, 255, 255, 0.05);
}

.symbol-dict-header {
    display: flex;
    align-items: center;
    justify-content: space-between;
    font-size: 12px;
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    color: rgba(229, 231, 235, 0.56);
    margin-bottom: 12px;
}

.symbol-dictionary.collapsed .symbol-dict-header {
    margin-bottom: 0;
}

.symbol-dict-toggle {
    color: rgba(229, 231, 235, 0.4);
    font-size: 14px;
    cursor: pointer;
    transition: transform 0.2s ease;
}

.symbol-dictionary.collapsed .symbol-dict-toggle {
    transform: rotate(-90deg);
}

.symbol-dict-content {
    display: flex;
    flex-direction: column;
    gap: 16px;
}

.symbol-group {
    margin-bottom: 0;
}

.symbol-group-title {
    font-size: 11px;
    font-weight: 600;
    color: #a78bfa;
    margin-bottom: 8px;
    text-transform: uppercase;
    letter-spacing: 0.5px;
}

.symbol-group-title.quantifier {
    color: #60a5fa;
}

.symbol-group-title.connective {
    color: #f472b6;
}

.symbol-group-title.modal {
    color: #c084fc;
}

.symbol-group-title.predicate {
    color: #4ade80;
}

.symbol-group-title.variable {
    color: #fbbf24;
}

.symbol-group-title.constant {
    color: #fb923c;
}

.symbol-entries {
    display: flex;
    flex-direction: column;
    gap: 4px;
}

.symbol-entry {
    display: flex;
    align-items: center;
    gap: 12px;
    padding: 8px 10px;
    border-radius: 6px;
    transition: background 0.15s ease;
}

.symbol-entry:hover {
    background: rgba(255, 255, 255, 0.05);
}

.symbol-glyph {
    font-size: 18px;
    font-family: 'SF Mono', 'Fira Code', 'JetBrains Mono', monospace;
    color: #60a5fa;
    min-width: 32px;
    text-align: center;
}

.symbol-glyph.quantifier {
    color: #60a5fa;
}

.symbol-glyph.connective {
    color: #f472b6;
}

.symbol-glyph.modal {
    color: #c084fc;
}

.symbol-glyph.predicate {
    color: #4ade80;
}

.symbol-glyph.variable {
    color: #fbbf24;
}

.symbol-glyph.constant {
    color: #fb923c;
}

.symbol-desc {
    font-size: 13px;
    color: rgba(229, 231, 235, 0.72);
}

.symbol-dictionary-empty {
    color: rgba(229, 231, 235, 0.4);
    font-size: 13px;
    text-align: center;
    padding: 8px;
}

/* Compact inline variant */
.symbol-dictionary.inline {
    padding: 12px;
    margin-top: 8px;
}

.symbol-dictionary.inline .symbol-dict-header {
    margin-bottom: 8px;
}

.symbol-dictionary.inline .symbol-entries {
    flex-direction: row;
    flex-wrap: wrap;
    gap: 8px;
}

.symbol-dictionary.inline .symbol-entry {
    padding: 4px 8px;
    background: rgba(255, 255, 255, 0.03);
    border-radius: 4px;
}

.symbol-dictionary.inline .symbol-glyph {
    font-size: 14px;
    min-width: 20px;
}

.symbol-dictionary.inline .symbol-desc {
    font-size: 11px;
}
"#;

/// Props for the SymbolDictionary component
#[derive(Props, Clone, PartialEq)]
pub struct SymbolDictionaryProps {
    /// The FOL formula to extract symbols from
    logic: String,
    /// Whether to start collapsed
    #[props(default = false)]
    collapsed: bool,
    /// Use compact inline variant
    #[props(default = false)]
    inline: bool,
}

/// Symbol Dictionary component that auto-generates from FOL output
#[component]
pub fn SymbolDictionary(props: SymbolDictionaryProps) -> Element {
    let mut is_collapsed = use_signal(|| props.collapsed);

    let symbols = extract_symbols(&props.logic);

    if symbols.is_empty() {
        return rsx! { "" };
    }

    let grouped = group_symbols_by_kind(&symbols);

    let container_class = format!(
        "symbol-dictionary{}{}",
        if *is_collapsed.read() { " collapsed" } else { "" },
        if props.inline { " inline" } else { "" }
    );

    rsx! {
        style { "{SYMBOL_DICT_STYLE}" }
        div {
            class: "{container_class}",
            onclick: move |_| {
                if *is_collapsed.read() {
                    is_collapsed.set(false);
                }
            },

            div { class: "symbol-dict-header",
                span { "Symbol Dictionary" }
                span {
                    class: "symbol-dict-toggle",
                    onclick: move |e| {
                        e.stop_propagation();
                        let current = *is_collapsed.read();
                        is_collapsed.set(!current);
                    },
                    "▼"
                }
            }

            if !*is_collapsed.read() {
                div { class: "symbol-dict-content",
                    for (kind, entries) in grouped {
                        {
                            let kind_class = match kind {
                                SymbolKind::Quantifier => "quantifier",
                                SymbolKind::Connective => "connective",
                                SymbolKind::Modal => "modal",
                                SymbolKind::Predicate => "predicate",
                                SymbolKind::Variable => "variable",
                                SymbolKind::Constant => "constant",
                                SymbolKind::Temporal => "temporal",
                                SymbolKind::Identity => "connective",
                                SymbolKind::Punctuation => "variable",
                            };

                            rsx! {
                                div { class: "symbol-group",
                                    key: "{kind_class}",
                                    div { class: "symbol-group-title {kind_class}",
                                        "{kind.label()}"
                                    }
                                    div { class: "symbol-entries",
                                        for entry in entries {
                                            div { class: "symbol-entry",
                                                key: "{entry.symbol}",
                                                span { class: "symbol-glyph {kind_class}",
                                                    "{entry.symbol}"
                                                }
                                                span { class: "symbol-desc",
                                                    "{entry.description}"
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                }
            }
        }
    }
}

/// Compact inline symbol legend for quick reference
#[component]
pub fn SymbolLegend(logic: String) -> Element {
    rsx! {
        SymbolDictionary {
            logic: logic,
            inline: true,
            collapsed: false,
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_symbol_kind_class_names() {
        assert_eq!(SymbolKind::Quantifier.label(), "Quantifier");
        assert_eq!(SymbolKind::Connective.label(), "Connective");
    }
}

```

---

### Component: vocab_reference

**File:** `src/ui/components/vocab_reference.rs`

Reusable UI component.

```rust
//! Vocabulary Reference component
//!
//! A collapsible reference panel showing all common logic symbols
//! and vocabulary terms, accessible from anywhere in the learning experience.

use dioxus::prelude::*;

const VOCAB_REFERENCE_STYLE: &str = r#"
.vocab-reference-toggle {
    position: fixed;
    bottom: 24px;
    right: 24px;
    width: 48px;
    height: 48px;
    border-radius: 50%;
    background: linear-gradient(135deg, var(--color-accent-blue), var(--color-accent-purple));
    border: none;
    color: #060814;
    font-size: 24px;
    cursor: pointer;
    display: flex;
    align-items: center;
    justify-content: center;
    box-shadow: 0 4px 20px rgba(96, 165, 250, 0.3);
    transition: transform 0.2s ease, box-shadow 0.2s ease;
    z-index: 1000;
}

.vocab-reference-toggle:hover {
    transform: scale(1.05);
    box-shadow: 0 6px 24px rgba(96, 165, 250, 0.4);
}

.vocab-reference-toggle.active {
    background: rgba(255, 255, 255, 0.1);
    color: var(--text-primary);
}

.vocab-reference-panel {
    position: fixed;
    bottom: 84px;
    right: 24px;
    width: 360px;
    max-height: 70vh;
    background: linear-gradient(180deg, #0d1424 0%, #0a0f1a 100%);
    border: 1px solid rgba(255, 255, 255, 0.12);
    border-radius: var(--radius-xl);
    box-shadow: 0 20px 60px rgba(0, 0, 0, 0.5), 0 0 30px rgba(96, 165, 250, 0.1);
    z-index: 999;
    overflow: hidden;
    animation: slideUp 0.2s ease;
}

@keyframes slideUp {
    from {
        opacity: 0;
        transform: translateY(16px);
    }
    to {
        opacity: 1;
        transform: translateY(0);
    }
}

.vocab-panel-header {
    display: flex;
    align-items: center;
    justify-content: space-between;
    padding: var(--spacing-lg);
    border-bottom: 1px solid rgba(255, 255, 255, 0.08);
    background: rgba(255, 255, 255, 0.03);
}

.vocab-panel-title {
    font-size: var(--font-body-lg);
    font-weight: 700;
    color: var(--text-primary);
    display: flex;
    align-items: center;
    gap: var(--spacing-sm);
}

.vocab-panel-close {
    width: 28px;
    height: 28px;
    border-radius: 50%;
    background: rgba(255, 255, 255, 0.08);
    border: 1px solid rgba(255, 255, 255, 0.12);
    color: var(--text-secondary);
    font-size: 14px;
    cursor: pointer;
    display: flex;
    align-items: center;
    justify-content: center;
    transition: all 0.15s ease;
}

.vocab-panel-close:hover {
    background: rgba(255, 255, 255, 0.15);
    color: var(--text-primary);
}

.vocab-panel-content {
    padding: var(--spacing-lg);
    max-height: calc(70vh - 60px);
    overflow-y: auto;
}

.vocab-section {
    margin-bottom: var(--spacing-xl);
}

.vocab-section:last-child {
    margin-bottom: 0;
}

.vocab-section-title {
    font-size: var(--font-caption-md);
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    margin-bottom: var(--spacing-md);
    display: flex;
    align-items: center;
    gap: var(--spacing-xs);
}

.vocab-section-title.quantifiers {
    color: #60a5fa;
}

.vocab-section-title.connectives {
    color: #f472b6;
}

.vocab-section-title.predicates {
    color: #4ade80;
}

.vocab-section-title.terms {
    color: #a78bfa;
}

.vocab-items {
    display: flex;
    flex-direction: column;
    gap: var(--spacing-xs);
}

.vocab-item {
    display: flex;
    align-items: center;
    gap: var(--spacing-md);
    padding: var(--spacing-sm) var(--spacing-md);
    background: rgba(255, 255, 255, 0.03);
    border-radius: var(--radius-md);
    transition: background 0.15s ease;
}

.vocab-item:hover {
    background: rgba(255, 255, 255, 0.06);
}

.vocab-symbol {
    font-family: var(--font-mono);
    font-size: var(--font-body-lg);
    min-width: 36px;
    text-align: center;
    font-weight: 600;
}

.vocab-symbol.quantifier {
    color: #60a5fa;
}

.vocab-symbol.connective {
    color: #f472b6;
}

.vocab-symbol.predicate {
    color: #4ade80;
}

.vocab-info {
    flex: 1;
}

.vocab-name {
    font-size: var(--font-body-sm);
    font-weight: 600;
    color: var(--text-primary);
}

.vocab-meaning {
    font-size: var(--font-caption-md);
    color: var(--text-tertiary);
}

.vocab-term-item {
    padding: var(--spacing-md);
    background: rgba(255, 255, 255, 0.03);
    border-radius: var(--radius-md);
    margin-bottom: var(--spacing-sm);
}

.vocab-term-name {
    font-weight: 600;
    color: var(--color-accent-purple);
    margin-bottom: var(--spacing-xs);
}

.vocab-term-def {
    font-size: var(--font-body-sm);
    color: var(--text-secondary);
    line-height: 1.5;
}

/* Search box */
.vocab-search {
    margin-bottom: var(--spacing-lg);
}

.vocab-search-input {
    width: 100%;
    padding: var(--spacing-sm) var(--spacing-md);
    background: rgba(255, 255, 255, 0.06);
    border: 1px solid rgba(255, 255, 255, 0.12);
    border-radius: var(--radius-md);
    color: var(--text-primary);
    font-size: var(--font-body-sm);
    outline: none;
    transition: border-color 0.2s ease;
}

.vocab-search-input:focus {
    border-color: var(--color-accent-blue);
}

.vocab-search-input::placeholder {
    color: var(--text-tertiary);
}
"#;

/// Symbol entry for the reference
struct SymbolRef {
    symbol: &'static str,
    name: &'static str,
    meaning: &'static str,
    category: &'static str,
}

/// Vocabulary term entry
struct VocabTerm {
    term: &'static str,
    definition: &'static str,
}

/// Get all reference symbols
fn get_symbols() -> Vec<SymbolRef> {
    vec![
        // Quantifiers
        SymbolRef { symbol: "∀", name: "Universal", meaning: "for all", category: "quantifier" },
        SymbolRef { symbol: "∃", name: "Existential", meaning: "there exists", category: "quantifier" },
        SymbolRef { symbol: "∃!", name: "Unique", meaning: "there exists exactly one", category: "quantifier" },
        // Connectives
        SymbolRef { symbol: "∧", name: "Conjunction", meaning: "and", category: "connective" },
        SymbolRef { symbol: "∨", name: "Disjunction", meaning: "or", category: "connective" },
        SymbolRef { symbol: "→", name: "Implication", meaning: "if...then", category: "connective" },
        SymbolRef { symbol: "↔", name: "Biconditional", meaning: "if and only if", category: "connective" },
        SymbolRef { symbol: "¬", name: "Negation", meaning: "not", category: "connective" },
        // Modal
        SymbolRef { symbol: "□", name: "Necessity", meaning: "necessarily", category: "connective" },
        SymbolRef { symbol: "◇", name: "Possibility", meaning: "possibly", category: "connective" },
        // Identity
        SymbolRef { symbol: "=", name: "Identity", meaning: "equals", category: "predicate" },
        SymbolRef { symbol: "≠", name: "Non-identity", meaning: "not equal to", category: "predicate" },
    ]
}

/// Get vocabulary terms
fn get_vocab_terms() -> Vec<VocabTerm> {
    vec![
        VocabTerm {
            term: "Predicate",
            definition: "A property or relation, written as a capitalized name with arguments in parentheses. E.g., Happy(alice)"
        },
        VocabTerm {
            term: "Constant",
            definition: "A name for a specific individual, written in lowercase. E.g., alice, bob, socrates"
        },
        VocabTerm {
            term: "Variable",
            definition: "A placeholder that can refer to any individual, typically x, y, z"
        },
        VocabTerm {
            term: "Valid Argument",
            definition: "An argument where the conclusion necessarily follows from the premises"
        },
        VocabTerm {
            term: "Sound Argument",
            definition: "A valid argument with premises that are actually true"
        },
        VocabTerm {
            term: "Domain",
            definition: "The set of all objects that variables can refer to"
        },
        VocabTerm {
            term: "Scope",
            definition: "The part of a formula to which a quantifier or connective applies"
        },
    ]
}

/// Props for VocabReference
#[derive(Props, Clone, PartialEq)]
pub struct VocabReferenceProps {
    /// Whether to show the panel initially
    #[props(default = false)]
    pub initial_open: bool,
}

/// Vocabulary Reference floating panel
#[component]
pub fn VocabReference(props: VocabReferenceProps) -> Element {
    let mut is_open = use_signal(|| props.initial_open);
    let mut search_query = use_signal(|| String::new());

    let symbols = get_symbols();
    let vocab_terms = get_vocab_terms();

    // Filter based on search
    let query = search_query.read().to_lowercase();
    let filtered_symbols: Vec<_> = if query.is_empty() {
        symbols.iter().collect()
    } else {
        symbols.iter().filter(|s| {
            s.symbol.to_lowercase().contains(&query) ||
            s.name.to_lowercase().contains(&query) ||
            s.meaning.to_lowercase().contains(&query)
        }).collect()
    };

    let filtered_terms: Vec<_> = if query.is_empty() {
        vocab_terms.iter().collect()
    } else {
        vocab_terms.iter().filter(|t| {
            t.term.to_lowercase().contains(&query) ||
            t.definition.to_lowercase().contains(&query)
        }).collect()
    };

    // Group symbols by category
    let quantifiers: Vec<_> = filtered_symbols.iter().filter(|s| s.category == "quantifier").collect();
    let connectives: Vec<_> = filtered_symbols.iter().filter(|s| s.category == "connective").collect();
    let predicates: Vec<_> = filtered_symbols.iter().filter(|s| s.category == "predicate").collect();

    rsx! {
        style { "{VOCAB_REFERENCE_STYLE}" }

        // Toggle button
        button {
            class: if *is_open.read() { "vocab-reference-toggle active" } else { "vocab-reference-toggle" },
            onclick: move |_| {
                let current = *is_open.read();
                is_open.set(!current);
            },
            title: "Symbol & Vocabulary Reference",
            if *is_open.read() { "×" } else { "📖" }
        }

        // Panel
        if *is_open.read() {
            div { class: "vocab-reference-panel",
                // Header
                div { class: "vocab-panel-header",
                    div { class: "vocab-panel-title",
                        "📖 Reference"
                    }
                    button {
                        class: "vocab-panel-close",
                        onclick: move |_| is_open.set(false),
                        "×"
                    }
                }

                // Content
                div { class: "vocab-panel-content",
                    // Search
                    div { class: "vocab-search",
                        input {
                            class: "vocab-search-input",
                            r#type: "text",
                            placeholder: "Search symbols or terms...",
                            value: "{search_query}",
                            oninput: move |e| search_query.set(e.value()),
                        }
                    }

                    // Quantifiers
                    if !quantifiers.is_empty() {
                        div { class: "vocab-section",
                            div { class: "vocab-section-title quantifiers", "Quantifiers" }
                            div { class: "vocab-items",
                                for sym in quantifiers {
                                    div { class: "vocab-item",
                                        span { class: "vocab-symbol quantifier", "{sym.symbol}" }
                                        div { class: "vocab-info",
                                            div { class: "vocab-name", "{sym.name}" }
                                            div { class: "vocab-meaning", "{sym.meaning}" }
                                        }
                                    }
                                }
                            }
                        }
                    }

                    // Connectives
                    if !connectives.is_empty() {
                        div { class: "vocab-section",
                            div { class: "vocab-section-title connectives", "Connectives" }
                            div { class: "vocab-items",
                                for sym in connectives {
                                    div { class: "vocab-item",
                                        span { class: "vocab-symbol connective", "{sym.symbol}" }
                                        div { class: "vocab-info",
                                            div { class: "vocab-name", "{sym.name}" }
                                            div { class: "vocab-meaning", "{sym.meaning}" }
                                        }
                                    }
                                }
                            }
                        }
                    }

                    // Predicates
                    if !predicates.is_empty() {
                        div { class: "vocab-section",
                            div { class: "vocab-section-title predicates", "Predicates & Relations" }
                            div { class: "vocab-items",
                                for sym in predicates {
                                    div { class: "vocab-item",
                                        span { class: "vocab-symbol predicate", "{sym.symbol}" }
                                        div { class: "vocab-info",
                                            div { class: "vocab-name", "{sym.name}" }
                                            div { class: "vocab-meaning", "{sym.meaning}" }
                                        }
                                    }
                                }
                            }
                        }
                    }

                    // Vocabulary Terms
                    if !filtered_terms.is_empty() {
                        div { class: "vocab-section",
                            div { class: "vocab-section-title terms", "Key Terms" }
                            for term in filtered_terms {
                                div { class: "vocab-term-item",
                                    div { class: "vocab-term-name", "{term.term}" }
                                    div { class: "vocab-term-def", "{term.definition}" }
                                }
                            }
                        }
                    }
                }
            }
        }
    }
}

```

---

### Component: xp_popup

**File:** `src/ui/components/xp_popup.rs`

Reusable UI component.

```rust
use dioxus::prelude::*;
use crate::game::XpReward;
use crate::audio::{SoundEffect, play_sound};

const XP_POPUP_STYLE: &str = r#"
.xp-popup {
    position: fixed;
    top: 50%;
    left: 50%;
    transform: translate(-50%, -50%);
    z-index: 1000;
    cursor: pointer;
    animation: xp-appear 2s ease-out forwards;
}

@keyframes xp-appear {
    0% { opacity: 0; transform: translate(-50%, -50%) scale(0.5); }
    10% { opacity: 1; transform: translate(-50%, -50%) scale(1.1); }
    20% { opacity: 1; transform: translate(-50%, -50%) scale(1); }
    80% { opacity: 1; transform: translate(-50%, -50%) scale(1); }
    100% { opacity: 0; transform: translate(-50%, -50%) scale(0.9) translateY(-20px); }
}

.xp-popup-content {
    background: rgba(0, 0, 0, 0.9);
    border: 2px solid #667eea;
    border-radius: 16px;
    padding: 24px 40px;
    text-align: center;
    box-shadow: 0 0 40px rgba(102, 126, 234, 0.4);
}

.xp-total {
    font-size: 48px;
    font-weight: 700;
    color: #4ade80;
    margin-bottom: 8px;
}

.xp-total.critical {
    color: #fbbf24;
    text-shadow: 0 0 20px #fbbf24;
    animation: critical-pulse 0.5s ease-in-out infinite alternate;
}

@keyframes critical-pulse {
    from { text-shadow: 0 0 20px #fbbf24; }
    to { text-shadow: 0 0 40px #fbbf24, 0 0 60px #f59e0b; }
}

.xp-breakdown {
    display: flex;
    flex-direction: column;
    gap: 4px;
    font-size: 14px;
    color: #888;
}

.xp-line {
    display: flex;
    justify-content: space-between;
    gap: 16px;
}

.xp-line.combo { color: #f97316; }
.xp-line.streak { color: #06b6d4; }
.xp-line.critical { color: #fbbf24; font-weight: 600; }
.xp-line.first-try { color: #a78bfa; }
"#;

#[component]
pub fn XpPopup(reward: XpReward, on_dismiss: EventHandler<()>) -> Element {
    use_effect(move || {
        if reward.is_critical {
            play_sound(SoundEffect::CriticalHit);
        } else {
            play_sound(SoundEffect::XpGain);
        }
    });

    use_effect(move || {
        let handler = on_dismiss.clone();
        spawn(async move {
            gloo_timers::future::TimeoutFuture::new(2000).await;
            handler.call(());
        });
    });

    let total_class = if reward.is_critical { "xp-total critical" } else { "xp-total" };

    rsx! {
        style { "{XP_POPUP_STYLE}" }
        div {
            class: "xp-popup",
            onclick: move |_| on_dismiss.call(()),
            div { class: "xp-popup-content",
                div { class: "{total_class}", "+{reward.total} XP" }
                div { class: "xp-breakdown",
                    div { class: "xp-line",
                        span { "Base" }
                        span { "+{reward.base}" }
                    }
                    if reward.combo_bonus > 0 {
                        div { class: "xp-line combo",
                            span { "Combo Bonus" }
                            span { "+{reward.combo_bonus}" }
                        }
                    }
                    if reward.streak_bonus > 0 {
                        div { class: "xp-line streak",
                            span { "Streak Bonus" }
                            span { "+{reward.streak_bonus}" }
                        }
                    }
                    if reward.first_try_bonus > 0 {
                        div { class: "xp-line first-try",
                            span { "First Try" }
                            span { "+{reward.first_try_bonus}" }
                        }
                    }
                    if reward.critical_bonus > 0 {
                        div { class: "xp-line critical",
                            span { "CRITICAL!" }
                            span { "+{reward.critical_bonus}" }
                        }
                    }
                }
            }
        }
    }
}

```

---

### Hooks: Module

**File:** `src/ui/hooks/mod.rs`

Custom React-style hooks for Dioxus. Reusable stateful logic patterns.

```rust
//! Custom Dioxus hooks for the Logicaffeine UI.
//!
//! This module provides reusable hooks for common UI patterns.

pub mod use_inactivity_timer;

pub use use_inactivity_timer::{use_inactivity_timer, InactivityState};

```

---

### Hook: Inactivity Timer

**File:** `src/ui/hooks/use_inactivity_timer.rs`

Detects user inactivity for session timeout warnings and auto-save triggers.

```rust
//! Inactivity timer hook for detecting when users need help.
//!
//! This hook monitors user activity and triggers a callback when the user
//! has been inactive for a specified duration. Used to trigger Socratic hints
//! when students are struggling.

use dioxus::prelude::*;

/// Default inactivity threshold (5 seconds)
pub const DEFAULT_INACTIVITY_THRESHOLD_MS: u64 = 5000;

/// State returned by the inactivity timer hook
#[derive(Debug, Clone, Copy, PartialEq)]
pub struct InactivityState {
    /// Whether the user is currently inactive (threshold exceeded)
    pub is_inactive: bool,
    /// Duration of inactivity in milliseconds
    pub inactive_duration_ms: u64,
}

impl Default for InactivityState {
    fn default() -> Self {
        Self {
            is_inactive: false,
            inactive_duration_ms: 0,
        }
    }
}

/// Hook that tracks user inactivity and triggers when threshold is exceeded.
///
/// # Arguments
/// * `threshold_ms` - Milliseconds of inactivity before triggering
/// * `on_inactive` - Callback invoked when user becomes inactive
///
/// # Returns
/// A tuple of:
/// - `InactivityState` - Current inactivity state
/// - `reset_fn` - Function to call when user performs an action
///
/// # Example
/// ```ignore
/// let (inactivity, reset_activity) = use_inactivity_timer(5000, move || {
///     // Show hint to user
/// });
///
/// // In input handler:
/// oninput: move |_| reset_activity(),
/// ```
#[cfg(target_arch = "wasm32")]
pub fn use_inactivity_timer(
    threshold_ms: u64,
    on_inactive: impl Fn() + 'static,
) -> (Signal<InactivityState>, impl FnMut()) {
    use gloo_timers::callback::Interval;

    let mut state = use_signal(InactivityState::default);
    let mut last_activity_time = use_signal(|| js_sys::Date::now());
    let mut callback_triggered = use_signal(|| false);

    // Store the callback in a resource that lives for the component lifetime
    let on_inactive = std::rc::Rc::new(on_inactive);
    let on_inactive_clone = on_inactive.clone();

    // Set up interval to check inactivity
    use_effect(move || {
        let on_inactive = on_inactive_clone.clone();

        let interval = Interval::new(1000, move || {
            let now = js_sys::Date::now();
            let last = *last_activity_time.read();
            let elapsed_ms = (now - last) as u64;

            let is_inactive = elapsed_ms >= threshold_ms;

            // Update state
            state.set(InactivityState {
                is_inactive,
                inactive_duration_ms: elapsed_ms,
            });

            // Trigger callback once when becoming inactive
            if is_inactive && !*callback_triggered.read() {
                callback_triggered.set(true);
                on_inactive();
            }
        });

        // Keep interval alive by forgetting it (cleanup handled by component unmount)
        std::mem::forget(interval);
    });

    // Reset function to call when user is active
    let reset_activity = move || {
        #[cfg(target_arch = "wasm32")]
        {
            last_activity_time.set(js_sys::Date::now());
        }
        callback_triggered.set(false);
        state.set(InactivityState::default());
    };

    (state, reset_activity)
}

/// Non-WASM fallback that does nothing (for testing)
#[cfg(not(target_arch = "wasm32"))]
pub fn use_inactivity_timer(
    _threshold_ms: u64,
    _on_inactive: impl Fn() + 'static,
) -> (Signal<InactivityState>, impl FnMut()) {
    let state = use_signal(InactivityState::default);
    let reset_activity = || {};
    (state, reset_activity)
}

/// Simpler version that just returns whether user is inactive
#[cfg(target_arch = "wasm32")]
pub fn use_is_inactive(threshold_ms: u64) -> Signal<bool> {
    use gloo_timers::callback::Interval;

    let mut is_inactive = use_signal(|| false);
    let mut last_activity_time = use_signal(|| js_sys::Date::now());

    use_effect(move || {
        let interval = Interval::new(1000, move || {
            let now = js_sys::Date::now();
            let last = *last_activity_time.read();
            let elapsed_ms = (now - last) as u64;

            is_inactive.set(elapsed_ms >= threshold_ms);
        });

        // Keep interval alive by forgetting it (cleanup handled by component unmount)
        std::mem::forget(interval);
    });

    is_inactive
}

#[cfg(not(target_arch = "wasm32"))]
pub fn use_is_inactive(_threshold_ms: u64) -> Signal<bool> {
    use_signal(|| false)
}

/// Hook to get a function that resets the activity timer
/// Call this in oninput, onclick, onkeydown handlers
#[cfg(target_arch = "wasm32")]
pub fn use_activity_resetter() -> (Signal<f64>, impl FnMut()) {
    let last_activity = use_signal(|| js_sys::Date::now());

    let reset = {
        let mut last_activity = last_activity;
        move || {
            last_activity.set(js_sys::Date::now());
        }
    };

    (last_activity, reset)
}

#[cfg(not(target_arch = "wasm32"))]
pub fn use_activity_resetter() -> (Signal<f64>, impl FnMut()) {
    let last_activity = use_signal(|| 0.0);
    let reset = || {};
    (last_activity, reset)
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_inactivity_state_default() {
        let state = InactivityState::default();
        assert!(!state.is_inactive);
        assert_eq!(state.inactive_duration_ms, 0);
    }

    #[test]
    fn test_default_threshold() {
        assert_eq!(DEFAULT_INACTIVITY_THRESHOLD_MS, 5000);
    }
}

```

---

### Guide: Content

**File:** `src/ui/pages/guide/content.rs`

Markdown content and examples for guide sections. Static documentation data.

```rust
//! Embedded guide content for the Programmer's Guide page.
//!
//! Contains all 24 sections from PROGRAMMERS_LANGUAGE_STARTER.md as Rust constants.
//! WASM cannot read files at runtime, so we embed the content at compile time.

/// Mode for code examples - determines how "Run" executes them
#[derive(Clone, Copy, PartialEq, Debug)]
pub enum ExampleMode {
    /// Logic mode: compile to First-Order Logic (FOL)
    Logic,
    /// Imperative mode: execute via WASM interpreter
    Imperative,
}

/// A code example within a section
#[derive(Clone, Debug)]
pub struct CodeExample {
    pub id: &'static str,
    pub label: &'static str,
    pub mode: ExampleMode,
    pub code: &'static str,
}

/// A section of the guide
#[derive(Clone, Debug)]
pub struct Section {
    pub id: &'static str,
    pub number: u8,
    pub title: &'static str,
    pub part: &'static str,
    pub content: &'static str,
    pub examples: &'static [CodeExample],
}

/// All guide sections organized by part
pub const SECTIONS: &[Section] = &[
    // ============================================================
    // Part I: Programming in LOGOS (Sections 1-17)
    // ============================================================

    Section {
        id: "introduction",
        number: 1,
        title: "Introduction",
        part: "Part I: Programming in LOGOS",
        content: r#"
### What is LOGOS?

LOGOS is a programming language where you write code in natural English. Instead of cryptic symbols and arcane syntax, you express your ideas in sentences that read like plain prose—and those sentences compile into efficient, executable programs.

LOGOS has two modes:

| Mode | What It Does | Output |
|------|--------------|--------|
| **Imperative Mode** | Write executable programs | Rust code (compiled to native binaries) |
| **Logic Mode** | Translate English to formal logic | First-Order Logic notation |

This guide focuses primarily on **Imperative Mode**—using LOGOS as a programming language. Part III covers Logic Mode for those interested in formal semantics.

### The Vision

The name LOGOS comes from the Greek λόγος, meaning "word," "reason," and "principle." In LOGOS, these concepts unify:

- **Words** become executable code
- **Reason** becomes verifiable logic
- **Principles** become formal proofs

When you write LOGOS, you're not writing comments that describe code—you're writing sentences that *are* the code.

### How to Read This Guide

**If you're new to programming:**
- Read each section in order
- Try every example yourself
- Don't skip ahead—each concept builds on the previous

**If you're an experienced programmer:**
- Use the Table of Contents to jump to what interests you
- The Quick Reference section provides rapid lookup
- The Complete Examples show real-world patterns
"#,
        examples: &[],
    },

    Section {
        id: "getting-started",
        number: 2,
        title: "Getting Started",
        part: "Part I: Programming in LOGOS",
        content: r#"
### Hello World

Every programming journey begins with Hello World. In LOGOS:
"#,
        examples: &[
            CodeExample {
                id: "hello-world",
                label: "Hello World",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Show "Hello, World!"."#,
            },
            CodeExample {
                id: "program-structure",
                label: "Program Structure",
                mode: ExampleMode::Imperative,
                code: r#"## Definition
A Point has:
    an x: Int.
    a y: Int.

## To greet (name: Text) -> Text:
    Return "Hello, " + name + "!".

## Main
Let p be a new Point with x 10 and y 20.
Let message be greet("World").
Show message."#,
            },
            CodeExample {
                id: "first-program",
                label: "Your First Real Program",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let name be "Alice".
Let age be 25.
Show "Name: " + name.
Show "Age: " + age."#,
            },
        ],
    },

    Section {
        id: "variables-and-types",
        number: 3,
        title: "Variables and Types",
        part: "Part I: Programming in LOGOS",
        content: r#"
Variables are containers that hold values. In LOGOS, you create and modify variables using natural English sentences.

### Creating Variables

Use `Let` to create a new variable. The word `be` assigns a value to the variable.

### Changing Values

Use `Set` to change an existing variable. The difference between `Let` and `Set`:
- `Let` creates a *new* variable
- `Set` modifies an *existing* variable

### Primitive Types

| Type | Description | Examples |
|------|-------------|----------|
| `Int` | Whole numbers | `5`, `-10`, `0`, `1000000` |
| `Bool` | True or false | `true`, `false` |
| `Text` | Strings of characters | `"Hello"`, `"LOGOS"`, `""` |
| `Float` / `Real` | Decimal numbers | `3.14`, `-0.5`, `98.6` |
| `Char` | Single character | see examples below |
| `Byte` | 8-bit unsigned (0-255) | `42: Byte`, `255: Byte` |

### Characters (Char)

Characters represent single Unicode characters, wrapped in backticks. See the example below.

### Bytes (Byte)

Bytes are 8-bit unsigned integers (0-255), useful for binary data and low-level operations.

### Type Annotations

Usually, LOGOS infers the type from the value you assign. But you can be explicit with `: Type`.
"#,
        examples: &[
            CodeExample {
                id: "creating-variables",
                label: "Creating Variables",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let x be 5.
Let name be "Bob".
Let is_active be true.
Let temperature be 98.6.
Show x.
Show name."#,
            },
            CodeExample {
                id: "changing-variables",
                label: "Changing Variables",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let x be 5.
Show x.

Set x to 10.
Show x.

Set x to x + 1.
Show x."#,
            },
            CodeExample {
                id: "text-concat",
                label: "Text Concatenation",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let first be "Hello".
Let second be "World".
Let message be first + ", " + second + "!".
Show message."#,
            },
            CodeExample {
                id: "char-literals",
                label: "Character Literals",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let letter be `a`.
Let newline be `\n`.
Let tab be `\t`.
Let escaped be `\\`.
Show letter.
Show "Char type uses backticks"."#,
            },
            CodeExample {
                id: "byte-type",
                label: "Byte Type",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let max: Byte be 255.
Let min: Byte be 0.
Let mid: Byte be 128.
Show max.
Show min.
Show mid."#,
            },
        ],
    },

    Section {
        id: "operators",
        number: 4,
        title: "Operators and Expressions",
        part: "Part I: Programming in LOGOS",
        content: r#"
Operators let you combine values into expressions. LOGOS supports both symbolic operators (like `+`) and English words (like `plus`).

### Arithmetic

| Operation | Symbol | English |
|-----------|--------|---------|
| Addition | `+` | `plus` |
| Subtraction | `-` | `minus` |
| Multiplication | `*` | `times` |
| Division | `/` | `divided by` |
| Modulo | `%` | `modulo` |

### Comparisons

| Operation | Symbol | English |
|-----------|--------|---------|
| Less than | `<` | `is less than` |
| Greater than | `>` | `is greater than` |
| Less or equal | `<=` | `is at most` |
| Greater or equal | `>=` | `is at least` |
| Equal | `==` | `equals` |
| Not equal | `!=` | `is not` |

### Logical Operators

| Operation | Keyword | Meaning |
|-----------|---------|---------|
| AND | `and` | Both must be true |
| OR | `or` | At least one must be true |
| NOT | `not` | Inverts true/false |
"#,
        examples: &[
            CodeExample {
                id: "arithmetic",
                label: "Arithmetic Operations",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let a be 10.
Let b be 3.

Let sum be a + b.
Let diff be a - b.
Let prod be a * b.
Let quot be a / b.
Let rem be a % b.

Show "Sum: " + sum.
Show "Difference: " + diff.
Show "Product: " + prod.
Show "Quotient: " + quot.
Show "Remainder: " + rem."#,
            },
            CodeExample {
                id: "comparisons",
                label: "Comparisons",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let x be 5.
Let y be 10.

Show x is less than y.
Show x is greater than y.
Show x equals 5.
Show x is at most 5.
Show x is at least 5."#,
            },
            CodeExample {
                id: "logical",
                label: "Logical Operators",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let a be true.
Let b be false.

Show a and b.
Show a or b.
Show not a."#,
            },
        ],
    },

    Section {
        id: "control-flow",
        number: 5,
        title: "Control Flow",
        part: "Part I: Programming in LOGOS",
        content: r#"
Control flow determines which code runs and in what order. LOGOS provides conditionals and loops using natural English syntax.

### Conditionals

Use `If` to execute code only when a condition is true. The colon (`:`) after the condition opens an indented block.

### If/Otherwise

Use `Otherwise` to handle the false case.

### While Loops

Use `While` to repeat code as long as a condition is true.

### For-Each Loops

Use `Repeat for` to iterate over collections.
"#,
        examples: &[
            CodeExample {
                id: "if-otherwise",
                label: "If/Otherwise",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let temperature be 72.

If temperature is greater than 80:
    Show "It's hot!".
Otherwise:
    Show "It's comfortable."."#,
            },
            CodeExample {
                id: "while-loop",
                label: "While Loop",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let count be 1.

While count is at most 5:
    Show count.
    Set count to count + 1."#,
            },
            CodeExample {
                id: "for-each",
                label: "For-Each Loop",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let numbers be [1, 2, 3, 4, 5].

Repeat for n in numbers:
    Show n."#,
            },
            CodeExample {
                id: "grading",
                label: "Grading Example",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let score be 85.

If score is at least 90:
    Show "Grade: A".
If score is at least 80 and score is less than 90:
    Show "Grade: B".
If score is at least 70 and score is less than 80:
    Show "Grade: C".
If score is less than 70:
    Show "Grade: F"."#,
            },
        ],
    },

    Section {
        id: "functions",
        number: 6,
        title: "Functions",
        part: "Part I: Programming in LOGOS",
        content: r#"
Functions are reusable blocks of code. In LOGOS, you define functions using natural English headers that describe what the function does.

### Defining Functions

A function definition starts with `## To` followed by the function name.

### Parameters

Functions can accept parameters—values passed in when the function is called. Use `and` to separate multiple parameters.

### Return Values

Use `-> Type` to specify what the function returns.

### Recursion

Functions can call themselves. This is called recursion. Every recursive function needs:
1. A **base case** — when to stop recursing
2. A **recursive case** — calling itself with a "smaller" problem
"#,
        examples: &[
            CodeExample {
                id: "simple-function",
                label: "Simple Function",
                mode: ExampleMode::Imperative,
                code: r#"## To greet (name: Text):
    Show "Hello, " + name + "!".

## Main
greet("Alice").
greet("Bob")."#,
            },
            CodeExample {
                id: "function-return",
                label: "Function with Return",
                mode: ExampleMode::Imperative,
                code: r#"## To add (a: Int) and (b: Int) -> Int:
    Return a + b.

## Main
Let sum be add(3, 5).
Show sum."#,
            },
            CodeExample {
                id: "factorial",
                label: "Recursive Factorial",
                mode: ExampleMode::Imperative,
                code: r#"## To factorial (n: Int) -> Int:
    If n is at most 1:
        Return 1.
    Return n * factorial(n - 1).

## Main
Show factorial(5)."#,
            },
        ],
    },

    Section {
        id: "collections",
        number: 7,
        title: "Collections",
        part: "Part I: Programming in LOGOS",
        content: r#"
Collections hold multiple values. LOGOS provides four main collection types:

| Collection | Description | Index Type |
|------------|-------------|------------|
| `Seq of T` | Ordered list | Int (1-based) |
| `Map of K to V` | Key-value pairs | Any key type |
| `Set of T` | Unique elements | N/A (membership) |
| `Tuple` | Fixed-size, mixed types | Int (1-based) |

### Creating Lists

Create a list with square brackets, or create an empty list with a type.

### Accessing Elements

LOGOS uses **1-based indexing**. The first element is at position 1, not 0. Why? Because that's how humans count.

### Modifying Collections

- `Push` to add an element to the end
- `Pop` to remove and get the last element
- `copy of` to create a deep copy

### Slicing

Extract a portion of a list with `through`. Slicing is **inclusive** on both ends.

### Maps (Dictionaries)

Maps store key-value pairs. Unlike lists which use integer indexing, maps use keys of any type.

**Create a map:**
`Let prices be a new Map of Text to Int.`

**Access a value by key:**
`Let cost be prices["iron"].`

**Set a value by key:**
`Set prices["iron"] to 100.`

Maps are useful for lookups, caches, and associating data without needing a struct.

### Bracket Syntax

Both lists and maps support bracket indexing as an alternative to `item X of`:

| English Style | Bracket Style |
|---------------|---------------|
| `item 1 of items` | `items[1]` |
| `item "iron" of prices` | `prices["iron"]` |
| `Set item "key" of map to val.` | `Set map["key"] to val.` |

Both compile to the same code—use whichever reads better in context.

### Sets

Sets store unique elements with no duplicates. Unlike lists, sets have no order and no index.

**Create a set:**
`Let numbers be a new Set of Int.`

**Add elements:**
`Add 5 to numbers.`

**Remove elements:**
`Remove 5 from numbers.`

**Check membership:**
`If numbers contains 5:` or `If 5 in numbers:`

**Set operations:**
- `a union b` — elements in either set
- `a intersection b` — elements in both sets

### Tuples

Tuples are fixed-size collections that can hold values of different types. Unlike lists, tuples can mix integers, text, and other types in a single collection.

**Create a tuple:**
`Let point be (10, 20).`
`Let record be ("Alice", 25, true).`

**Access elements (1-indexed):**
`Let x be point[1].` or `Let x be item 1 of point.`

**Get length:**
`Let size be length of record.`

Tuples are useful for returning multiple values from functions or grouping related but differently-typed data without defining a struct.
"#,
        examples: &[
            CodeExample {
                id: "creating-lists",
                label: "Creating Lists",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let numbers be [1, 2, 3, 4, 5].
Let names be ["Alice", "Bob", "Charlie"].
Show numbers.
Show names."#,
            },
            CodeExample {
                id: "accessing-elements",
                label: "Accessing Elements (1-indexed)",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let fruits be ["apple", "banana", "cherry"].

Let first be item 1 of fruits.
Let second be item 2 of fruits.
Let third be item 3 of fruits.

Show first.
Show second.
Show third."#,
            },
            CodeExample {
                id: "push-pop",
                label: "Push and Pop",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let numbers be [1, 2, 3].
Push 4 to numbers.
Push 5 to numbers.
Show numbers."#,
            },
            CodeExample {
                id: "list-iteration",
                label: "Iterating and Accumulating",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let numbers be [10, 20, 30, 40, 50].
Let total be 0.

Repeat for n in numbers:
    Set total to total + n.

Show "Total: " + total."#,
            },
            CodeExample {
                id: "map-create",
                label: "Creating Maps",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let prices be a new Map of Text to Int.
Set prices["iron"] to 10.
Set prices["copper"] to 25.
Set prices["gold"] to 100.
Show "Iron: " + prices["iron"].
Show "Copper: " + prices["copper"].
Show "Gold: " + prices["gold"]."#,
            },
            CodeExample {
                id: "map-access",
                label: "Map Access",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let inventory be a new Map of Text to Int.
Set inventory["wood"] to 50.
Set inventory["stone"] to 30.

Let wood_count be inventory["wood"].
Show "Wood: " + wood_count."#,
            },
            CodeExample {
                id: "map-update",
                label: "Map Update",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let scores be a new Map of Text to Int.
Set scores["Alice"] to 100.
Show "Initial: " + scores["Alice"].

Set scores["Alice"] to 150.
Show "Updated: " + scores["Alice"]."#,
            },
            CodeExample {
                id: "bracket-syntax",
                label: "Bracket Syntax",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let items be [10, 20, 30].
Let prices be a new Map of Text to Int.

Set prices["iron"] to 5.
Set prices["gold"] to 100.

Show items[1].
Show prices["iron"].
Set items[2] to 99.
Show items[2]."#,
            },
            CodeExample {
                id: "set-create",
                label: "Creating Sets",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let numbers be a new Set of Int.
Add 1 to numbers.
Add 2 to numbers.
Add 3 to numbers.
Add 1 to numbers.
Show numbers."#,
            },
            CodeExample {
                id: "set-contains",
                label: "Set Membership",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let primes be a new Set of Int.
Add 2 to primes.
Add 3 to primes.
Add 5 to primes.
Add 7 to primes.

If primes contains 3:
    Show "3 is prime".
If primes contains 4:
    Show "4 is prime".
Otherwise:
    Show "4 is not prime"."#,
            },
            CodeExample {
                id: "set-remove",
                label: "Adding and Removing",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let colors be a new Set of Text.
Add "red" to colors.
Add "green" to colors.
Add "blue" to colors.
Show colors.

Remove "green" from colors.
Show colors."#,
            },
            CodeExample {
                id: "set-operations",
                label: "Set Operations",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let a be a new Set of Int.
Let b be a new Set of Int.

Add 1 to a. Add 2 to a. Add 3 to a.
Add 2 to b. Add 3 to b. Add 4 to b.

Let both be a intersection b.
Let either be a union b.
Show "Intersection: " + both.
Show "Union: " + either."#,
            },
            CodeExample {
                id: "tuple-create",
                label: "Creating Tuples",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let point be (10, 20).
Let record be ("Alice", 25, true).
Show point.
Show record."#,
            },
            CodeExample {
                id: "tuple-access",
                label: "Accessing Tuple Elements",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let data be ("answer", 42).
Let label be data[1].
Let value be data[2].
Show label.
Show value."#,
            },
            CodeExample {
                id: "tuple-mixed",
                label: "Mixed-Type Tuples",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let person be ("Bob", 30, 5.9).
Show item 1 of person.
Show item 2 of person.
Show item 3 of person.
Show length of person."#,
            },
        ],
    },

    Section {
        id: "user-types",
        number: 8,
        title: "User-Defined Types",
        part: "Part I: Programming in LOGOS",
        content: r#"
Beyond primitive types and collections, LOGOS lets you define your own types to model your problem domain.

### Structs

A struct (structure) groups related values together. Define one in a `## Definition` block using `A [TypeName] has:` syntax.

### Creating Instances

Use `a new [Type] with [fields]` to create instances.

### Accessing Fields

Use `'s` (possessive) to access fields.

### Enums

An enum (enumeration) defines a type that can be one of several variants using `A [TypeName] is either:` syntax.

### Pattern Matching

Use `Inspect` to handle different enum variants with `When` clauses.
"#,
        examples: &[
            CodeExample {
                id: "struct-basic",
                label: "Basic Struct",
                mode: ExampleMode::Imperative,
                code: r#"## Definition
A Point has:
    an x: Int.
    a y: Int.

## Main
Let p be a new Point with x 10 and y 20.
Show p's x.
Show p's y."#,
            },
            CodeExample {
                id: "struct-person",
                label: "Person Struct",
                mode: ExampleMode::Imperative,
                code: r#"## Definition
A Person has:
    a name: Text.
    an age: Int.

## Main
Let alice be a new Person with name "Alice" and age 25.
Show alice's name.
Show alice's age."#,
            },
            CodeExample {
                id: "enum-direction",
                label: "Simple Enum",
                mode: ExampleMode::Imperative,
                code: r#"## Definition
A Direction is either:
    North.
    South.
    East.
    West.

## Main
Let heading be North.
Show heading."#,
            },
        ],
    },

    Section {
        id: "generics",
        number: 9,
        title: "Generics",
        part: "Part I: Programming in LOGOS",
        content: r#"
Generics let you write types and functions that work with any type, not just specific ones.

### Generic Types

Define a generic type with `[T]` in the type name. The `[T]` is a placeholder that gets replaced with a real type when you use it.

### Multiple Type Parameters

You can have multiple type parameters like `[A]` and `[B]`.

### Generic Collections

Collections are generic types. `Seq of Int` is a sequence of integers.

### Nested Generics

You can nest generic types like `Seq of (Seq of Int)` for a matrix.
"#,
        examples: &[
            CodeExample {
                id: "generic-box",
                label: "Generic Box",
                mode: ExampleMode::Imperative,
                code: r#"## Definition
A Box of [T] has:
    a contents: T.

## Main
Let int_box be a new Box of Int with contents 42.
Let text_box be a new Box of Text with contents "Hello".

Show int_box's contents.
Show text_box's contents."#,
            },
            CodeExample {
                id: "generic-pair",
                label: "Generic Pair",
                mode: ExampleMode::Imperative,
                code: r#"## Definition
A Pair of [A] and [B] has:
    a first: A.
    a second: B.

## Main
Let p be a new Pair of Int and Text with first 1 and second "one".
Show p's first.
Show p's second."#,
            },
        ],
    },

    Section {
        id: "memory-ownership",
        number: 10,
        title: "Memory and Ownership",
        part: "Part I: Programming in LOGOS",
        content: r#"
LOGOS provides memory safety through an ownership system expressed in natural English. Instead of cryptic symbols, you use verbs that describe what you're doing with data.

### The Three Verbs

| Verb | Meaning | What Happens |
|------|---------|--------------|
| `Give` | Transfer ownership | The original variable can no longer be used |
| `Show` | Temporary read access | The function can look but not modify |
| `Let modify` | Temporary write access | The function can change the data |

### Ownership Rules

1. **Single Owner:** Every value has exactly one owner at a time
2. **Move Semantics:** `Give` transfers ownership—you can't use it after
3. **Borrow Checking:** References (`Show`) can't outlive the owner
4. **Exclusive Mutation:** Only one `Let modify` at a time

### Common Patterns

- Copy first, then give
- Show multiple times (all OK - just reading)
- Sequential mutation

### The `copy of` Expression

Use `copy of` to create a deep clone of a value. This lets you keep using the original while giving away the copy.
"#,
        examples: &[
            CodeExample {
                id: "ownership-show",
                label: "Show (Borrow)",
                mode: ExampleMode::Imperative,
                code: r#"## To display (data: Text):
    Show "Displaying: " + data.

## Main
Let profile be "User Profile Data".
Show profile to display.
Show profile."#,
            },
            CodeExample {
                id: "ownership-give",
                label: "Give (Move Ownership)",
                mode: ExampleMode::Imperative,
                code: r#"## To consume (data: Text):
    Show "Consumed: " + data.

## Main
Let message be "Important data".
Give message to consume.
Show "Message was transferred"."#,
            },
            CodeExample {
                id: "ownership-copy",
                label: "Copy Before Giving",
                mode: ExampleMode::Imperative,
                code: r#"## To process (data: Text):
    Show "Processing: " + data.

## Main
Let original be "Keep this".
Let duplicate be copy of original.
Give duplicate to process.
Show "Original still here: " + original."#,
            },
        ],
    },

    Section {
        id: "zones",
        number: 11,
        title: "The Zone System",
        part: "Part I: Programming in LOGOS",
        content: r#"
For high-performance scenarios, LOGOS provides **Zones**—memory regions where allocations are fast and cleanup is instant.

### Why Zones?

| Operation | Normal Heap | Zone |
|-----------|-------------|------|
| Allocate | O(log n) | O(1) |
| Deallocate individual | O(log n) | N/A |
| Free everything | O(n) | O(1) |

### The Hotel California Rule

**"What happens in the Zone, stays in the Zone."**

References to zone-allocated data cannot escape. To get data out of a zone, make an explicit copy.

### Zone Configuration

**Default size:** 4 KB (4096 bytes) when not specified.

**Specifying size:** Use `of size` with units:

| Unit | Example | Bytes |
|------|---------|-------|
| B | `of size 256 B` | 256 |
| KB | `of size 64 KB` | 65,536 |
| MB | `of size 2 MB` | 2,097,152 |
| GB | `of size 1 GB` | 1,073,741,824 |

### Zone Types

| Zone Type | Syntax | Access | Use Case |
|-----------|--------|--------|----------|
| Heap | `Inside a zone called "X":` | Read/Write | Temporary data |
| Heap (sized) | `Inside a zone called "X" of size 2 MB:` | Read/Write | Large temporary data |
| Mapped | `Inside a zone called "X" mapped from "file.bin":` | Read-only | Large file processing |

### When to Use Zones

Use zones when:
- Processing large amounts of temporary data
- Performance is critical (games, simulations)
- Memory allocation patterns are predictable
- You want instant cleanup
"#,
        examples: &[
            CodeExample {
                id: "zone-basic",
                label: "Basic Zone (4KB default)",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Inside a zone called "WorkSpace":
    Let temp_data be [1, 2, 3, 4, 5].
    Show temp_data.
Show "Zone freed!"."#,
            },
            CodeExample {
                id: "zone-sized-mb",
                label: "Zone with Size (MB)",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Inside a zone called "LargeBuffer" of size 2 MB:
    Let data be [1, 2, 3, 4, 5].
    Show data."#,
            },
            CodeExample {
                id: "zone-sized-kb",
                label: "Zone with Size (KB)",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Inside a zone called "SmallArena" of size 64 KB:
    Let x be 42.
    Let y be 100.
    Show x + y."#,
            },
            CodeExample {
                id: "zone-mapped",
                label: "Memory-Mapped Zone (Compiled Only)",
                mode: ExampleMode::Imperative,
                code: r#"## To process_file (path: Text):
    Inside a zone called "Data" mapped from path:
        Show "Processing: " + path.

## Main
process_file("config.bin").
process_file("assets.bin")."#,
            },
        ],
    },

    Section {
        id: "concurrency",
        number: 12,
        title: "Concurrency",
        part: "Part I: Programming in LOGOS",
        content: r#"
LOGOS provides safe concurrency through structured patterns. No data races, no deadlocks.

### Concurrent Patterns Overview

| Pattern | Syntax | Use For | Compiles To |
|---------|--------|---------|-------------|
| **Async Join** | `Attempt all of the following:` | Wait for all I/O tasks | tokio::join! |
| **Parallel CPU** | `Simultaneously:` | CPU-bound computation | rayon::join / threads |
| **Spawn Task** | `Launch a task to...` | Fire-and-forget work | tokio::spawn |
| **Channels** | `Pipe of Type` | Message passing | tokio::mpsc |
| **Select** | `Await the first of:` | Race operations | tokio::select! |

### Attempt All (Async I/O)

Use `Attempt all of the following:` for I/O operations that wait on external resources. All operations run concurrently, and the program waits until all complete.

Variables declared in concurrent blocks are captured and returned as a tuple.

### Simultaneously (Parallel CPU)

Use `Simultaneously:` for CPU-intensive work. Computations run in parallel on different CPU cores.

- 2 tasks → uses `rayon::join` (work-stealing thread pool)
- 3+ tasks → uses `std::thread::spawn` (dedicated threads)

### Tasks (Green Threads)

Use `Launch a task to...` to spawn a green thread that runs concurrently. For fire-and-forget work, just launch:

`Launch a task to process(data).`

To control the task later (cancel, await), capture a handle:

`Let worker be Launch a task to process(data).`

Stop a running task with:

`Stop worker.`

### Channels (Pipes)

Pipes are Go-style channels for message passing between tasks.

**Create a channel:**
`Let jobs be a new Pipe of Int.`

**Send into a channel (blocking):**
`Send value into jobs.`

**Receive from a channel (blocking):**
`Receive item from jobs.`

**Non-blocking variants:**
`Try to send value into jobs.`
`Try to receive item from jobs.`

### Select (Racing Operations)

Use `Await the first of:` to race multiple operations. The first one to complete wins:

```
Await the first of:
    Receive msg from inbox:
        Show msg.
    After 5 seconds:
        Show "timeout".
```

**Branch types:**
- `Receive var from pipe:` — wait for channel message
- `After N seconds:` — timeout branch

### Ownership and Concurrency

The ownership system prevents data races. Multiple reads are OK, but concurrent writes are prevented.

**Note:** Tasks, Pipes, and Select require compilation—they don't run in the browser playground.
"#,
        examples: &[
            CodeExample {
                id: "concurrent-async",
                label: "Async Concurrent (Attempt All)",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Attempt all of the following:
    Let a be 10.
    Let b be 20.
Show "a = " + a.
Show "b = " + b.
Show "Sum: " + (a + b)."#,
            },
            CodeExample {
                id: "parallel-cpu",
                label: "Parallel CPU (Simultaneously)",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Simultaneously:
    Let x be 100.
    Let y be 200.
Show "x = " + x.
Show "y = " + y.
Show "Product: " + (x * y)."#,
            },
            CodeExample {
                id: "parallel-three-tasks",
                label: "Three Parallel Tasks",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Simultaneously:
    Let a be 1.
    Let b be 2.
    Let c be 3.
Show "Sum: " + (a + b + c)."#,
            },
            CodeExample {
                id: "concurrent-in-function",
                label: "Concurrency in Functions",
                mode: ExampleMode::Imperative,
                code: r#"## To compute_parallel -> Int:
    Simultaneously:
        Let x be 5.
        Let y be 10.
    Return x + y.

## Main
Let result be compute_parallel().
Show "Result: " + result."#,
            },
            CodeExample {
                id: "launch-task",
                label: "Launch Task (Compiled Only)",
                mode: ExampleMode::Imperative,
                code: r#"## To worker (id: Int):
    Show "Worker " + id + " started".

## Main
Launch a task to worker(1).
Launch a task to worker(2).
Show "Tasks launched"."#,
            },
            CodeExample {
                id: "task-with-handle",
                label: "Task with Handle (Compiled Only)",
                mode: ExampleMode::Imperative,
                code: r#"## To long_running:
    Show "Working...".

## Main
Let job be Launch a task to long_running.
Show "Task spawned".
Stop job.
Show "Task cancelled"."#,
            },
            CodeExample {
                id: "pipe-send-receive",
                label: "Pipe Communication (Compiled Only)",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let messages be a new Pipe of Int.
Send 42 into messages.
Send 100 into messages.
Receive x from messages.
Show "Got: " + x."#,
            },
            CodeExample {
                id: "select-timeout",
                label: "Select with Timeout (Compiled Only)",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let inbox be a new Pipe of Text.

Await the first of:
    Receive msg from inbox:
        Show "Message: " + msg.
    After 2 seconds:
        Show "No message received"."#,
            },
        ],
    },

    Section {
        id: "crdt",
        number: 13,
        title: "Distributed Types (CRDTs)",
        part: "Part I: Programming in LOGOS",
        content: r#"
### What are CRDTs?

CRDTs (Conflict-free Replicated Data Types) are data structures that can be replicated across multiple computers and merged without coordination. No matter what order updates arrive, the final state converges to the same result.

### Why CRDTs Matter

| Challenge | Traditional Approach | CRDT Approach |
|-----------|---------------------|---------------|
| Network partition | Data loss or conflicts | Automatic merge |
| Concurrent edits | Last-write-wins (data loss) | Semantic merge |
| Offline support | Sync conflicts | Seamless reconciliation |

### Shared Structs

Mark a struct as `Shared` to enable automatic merge support. The compiler generates a `merge` method that combines two instances.

### Built-in CRDT Types

| Type | Description | Operations |
|------|-------------|------------|
| `ConvergentCount` | Counter that only grows | `Increase` |
| `Tally` | Counter that grows and shrinks | `Increase`, `Decrease` |
| `LastWriteWins of T` | Register with timestamp-based conflict resolution | `Set` |
| `Divergent T` | Register that preserves concurrent values | `Set`, `Resolve` |
| `SharedSet of T` | Set with add/remove support | `Add`, `Remove`, `contains` |
| `SharedSequence of T` | Ordered list (RGA algorithm) | `Append`, `length of` |
| `CollaborativeSequence of T` | Text-optimized sequence (YATA) | `Append`, `length of` |
| `SharedMap from K to V` | Key-value CRDT map | `[]` access and assignment |

### ConvergentCount

A grow-only counter (G-Counter). Multiple replicas can increment independently, and when merged, the total reflects all increments. Useful for view counts, likes, or any monotonically increasing metric.

### Tally

A bidirectional counter (PN-Counter) that supports both increment and decrement. Unlike ConvergentCount, values can go up and down—even negative. Useful for scores, balances, and temperatures.

### LastWriteWins

A register that resolves conflicts by timestamp. The most recent write wins. Works with any type: `Text`, `Int`, `Bool`, etc.

### Divergent

A multi-value register that preserves all concurrent writes instead of silently picking a winner. When replicas write different values concurrently, both are kept until you explicitly `Resolve` the conflict. Useful for collaborative editing where conflicts should be visible.

### SharedSet

An observed-remove set (OR-Set) that supports both adding and removing elements. By default uses **add-wins** semantics: if one replica adds while another removes, the element stays.

**Configuring bias:**
- `SharedSet (AddWins) of T` — concurrent add beats remove (default)
- `SharedSet (RemoveWins) of T` — concurrent remove beats add

### SharedSequence

An ordered CRDT list using the RGA (Replicated Growable Array) algorithm. Elements maintain their order across replicas. Useful for ordered lists, chat history, and document lines.

### CollaborativeSequence

A text-optimized sequence using the YATA algorithm. Better conflict resolution for concurrent insertions at the same position. Ideal for collaborative text editing. Alternative syntax: `SharedSequence (YATA) of T`.

### SharedMap

A key-value CRDT map (OR-Map). Keys can be added and removed, and values are themselves CRDTs that merge recursively. Alternative syntax: `ORMap from K to V`.

### Merge Operations

Use `Merge source into target` to combine two CRDT instances. The target is updated in place with the merged state.

### Persistence

CRDTs can be persisted to disk using the `Persistent` type modifier and `Mount` statement. Data is stored in append-only journal files (`.lsf` format) with automatic compaction.

**The Persistent Type:**

`Persistent Counter` wraps a Shared struct with journaling. All mutations are durably recorded.

**The Mount Statement:**

`Mount [variable] at [path].`

or

`Let x be mounted at "path/to/data.lsf".`

This loads existing state from the journal file (if present) or creates a new one. Changes are automatically persisted.

### Network Synchronization

CRDTs become powerful when synchronized across the network. Use `Sync` to subscribe a variable to a GossipSub topic.

**The Sync Statement:**

`Sync [variable] on [topic].`

- `variable` — A mutable variable containing a Shared struct
- `topic` — A string or variable naming the GossipSub topic

**What Sync Does:**
1. Subscribes to the topic for incoming messages
2. Spawns a background task to merge incoming updates
3. Broadcasts the full state after any mutation

### Persistence + Network

For the best of both worlds, combine `Persistent` types with `Sync`. The Distributed runtime ensures:
- Local changes are journaled before broadcast
- Remote updates are merged and persisted
- Data survives restarts

**Note:** Programs using `Sync` or `Mount` require compilation—they don't run in the browser playground.
"#,
        examples: &[
            CodeExample {
                id: "crdt-basic",
                label: "Basic Shared Struct",
                mode: ExampleMode::Imperative,
                code: r#"## Definition
A Counter is Shared and has:
    a points, which is ConvergentCount.

## Main
Let c be a new Counter.
Increase c's points by 10.
Show c's points."#,
            },
            CodeExample {
                id: "crdt-lww",
                label: "Last-Write-Wins Register",
                mode: ExampleMode::Imperative,
                code: r#"## Definition
A Profile is Shared and has:
    a name, which is LastWriteWins of Text.
    a score, which is LastWriteWins of Int.

## Main
Let p be a new Profile.
Set p's name to "Alice".
Set p's score to 100.
Show p's name.
Show p's score."#,
            },
            CodeExample {
                id: "crdt-merge",
                label: "Merging Replicas",
                mode: ExampleMode::Imperative,
                code: r#"## Definition
A Stats is Shared and has:
    a views, which is ConvergentCount.

## Main
Let local be a new Stats.
Increase local's views by 100.

Let remote be a new Stats.
Increase remote's views by 50.

Merge remote into local.
Show local's views."#,
            },
            CodeExample {
                id: "crdt-sync-counter",
                label: "Synced Counter (Compiled Only)",
                mode: ExampleMode::Imperative,
                code: r#"## Definition
A GameScore is Shared and has:
    a points, which is ConvergentCount.

## Main
Let mutable score be a new GameScore.
Sync score on "game-leaderboard".
Increase score's points by 100.
Show score's points."#,
            },
            CodeExample {
                id: "crdt-sync-profile",
                label: "Synced Profile (Compiled Only)",
                mode: ExampleMode::Imperative,
                code: r#"## Definition
A Profile is Shared and has:
    a name, which is LastWriteWins of Text.
    a level, which is ConvergentCount.

## Main
Let mutable p be a new Profile.
Sync p on "player-data".
Increase p's level by 1.
Show p's level."#,
            },
            CodeExample {
                id: "crdt-persistent",
                label: "Persistent Counter (Compiled Only)",
                mode: ExampleMode::Imperative,
                code: r#"## Definition
A Counter is Shared and has:
    a value, which is ConvergentCount.

## Main
Let mutable c: Persistent Counter be mounted at "counter.lsf".
Increase c's value by 1.
Show c's value."#,
            },
            CodeExample {
                id: "crdt-tally",
                label: "Tally (Bidirectional Counter)",
                mode: ExampleMode::Imperative,
                code: r#"## Definition
A Score is Shared and has:
    a points, which is a Tally.

## Main
Let mutable s be a new Score.
Increase s's points by 100.
Decrease s's points by 30.
Show s's points."#,
            },
            CodeExample {
                id: "crdt-divergent",
                label: "Divergent (Multi-Value Register)",
                mode: ExampleMode::Imperative,
                code: r#"## Definition
A WikiPage is Shared and has:
    a title, which is Divergent Text.

## Main
Let mutable page be a new WikiPage.
Set page's title to "Draft".
Show page's title.
Resolve page's title to "Final".
Show page's title."#,
            },
            CodeExample {
                id: "crdt-sharedset",
                label: "SharedSet (Add/Remove Set)",
                mode: ExampleMode::Imperative,
                code: r#"## Definition
A Party is Shared and has:
    a guests, which is a SharedSet of Text.

## Main
Let mutable p be a new Party.
Add "Alice" to p's guests.
Add "Bob" to p's guests.
Remove "Alice" from p's guests.
If p's guests contains "Bob":
    Show "Bob is invited".
Show length of p's guests."#,
            },
            CodeExample {
                id: "crdt-sharedset-bias",
                label: "SharedSet with Bias",
                mode: ExampleMode::Imperative,
                code: r#"## Definition
A Moderation is Shared and has:
    a tags, which is a SharedSet (AddWins) of Text.
    a blocked, which is a SharedSet (RemoveWins) of Text.

## Main
Let mutable m be a new Moderation.
Add "safe" to m's tags.
Add "spammer" to m's blocked.
Show m's tags.
Show m's blocked."#,
            },
            CodeExample {
                id: "crdt-sequence",
                label: "SharedSequence (Ordered List)",
                mode: ExampleMode::Imperative,
                code: r#"## Definition
A Document is Shared and has:
    a lines, which is a SharedSequence of Text.

## Main
Let mutable doc be a new Document.
Append "Line 1" to doc's lines.
Append "Line 2" to doc's lines.
Append "Line 3" to doc's lines.
Show length of doc's lines."#,
            },
            CodeExample {
                id: "crdt-collaborative",
                label: "CollaborativeSequence (Text)",
                mode: ExampleMode::Imperative,
                code: r#"## Definition
A Editor is Shared and has:
    a text, which is a CollaborativeSequence of Text.

## Main
Let mutable e be a new Editor.
Append "Hello" to e's text.
Append " " to e's text.
Append "World" to e's text.
Show length of e's text."#,
            },
            CodeExample {
                id: "crdt-sharedmap",
                label: "SharedMap (Key-Value CRDT)",
                mode: ExampleMode::Imperative,
                code: r#"## Definition
A Inventory is Shared and has:
    an items, which is a SharedMap from Text to Int.

## Main
Let mutable inv be a new Inventory.
Set inv's items["wood"] to 50.
Set inv's items["stone"] to 30.
Show inv's items["wood"]."#,
            },
        ],
    },

    Section {
        id: "security",
        number: 14,
        title: "Policy-Based Security",
        part: "Part I: Programming in LOGOS",
        content: r#"
### Security in Natural Language

LOGOS lets you express security policies as natural English sentences. These compile into efficient runtime checks that can never be optimized away.

### Policy Blocks

Define security rules in `## Policy` blocks. Policies define **predicates** (conditions on a single entity) and **capabilities** (permissions involving multiple entities).

### Predicates

A predicate is a boolean condition on a subject:

`A User is admin if the user's role equals "admin".`

This generates a method `is_admin()` on the User type.

### Capabilities

A capability defines what a subject can do with an object:

`A User can publish the Document if the user is admin.`

This generates a method `can_publish(&Document)` on the User type.

### Check Statements

Use `Check` to enforce security at runtime. **Unlike `Assert`, Check statements are mandatory and can never be optimized away.**

| Statement | Debug Build | Release Build |
|-----------|-------------|---------------|
| `Assert` | Runs | Can be optimized out |
| `Check` | Runs | **Always runs** |

### Policy Composition

Policies can use `AND` and `OR` to combine conditions, and can reference other predicates.
"#,
        examples: &[
            CodeExample {
                id: "security-predicate",
                label: "Simple Predicate",
                mode: ExampleMode::Imperative,
                code: r#"## Definition
A User has:
    a role: Text.

## Policy
A User is admin if the user's role equals "admin".

## Main
Let u be a new User with role "admin".
Check that u is admin.
Show "Access granted"."#,
            },
            CodeExample {
                id: "security-capability",
                label: "Capability with Object",
                mode: ExampleMode::Imperative,
                code: r#"## Definition
A User has:
    a name: Text.
    a role: Text.

A Document has:
    an owner: Text.

## Policy
A User is admin if the user's role equals "admin".
A User can edit the Document if:
    The user is admin, OR
    The user's name equals the document's owner.

## Main
Let alice be a new User with name "Alice" and role "editor".
Let doc be a new Document with owner "Alice".
Check that alice can edit doc.
Show "Edit permitted"."#,
            },
        ],
    },

    Section {
        id: "networking",
        number: 15,
        title: "P2P Networking",
        part: "Part I: Programming in LOGOS",
        content: r#"
LOGOS includes built-in peer-to-peer networking primitives for building distributed applications.

**Note:** Networking features require compilation—they don't run in the browser playground.

### Core Concepts

| Concept | Description |
|---------|-------------|
| **Address** | libp2p multiaddr format: `/ip4/127.0.0.1/tcp/8000` |
| **Listen** | Bind to an address to accept connections |
| **Connect** | Dial a peer at an address |
| **PeerAgent** | A handle to a remote peer |
| **Send** | Transmit a message to a peer |
| **Sync** | Subscribe a CRDT to a GossipSub topic |

### Portable Types

Messages sent over the network must be **Portable**. Mark your struct with `is Portable` to enable network serialization.

### Address Format

LOGOS uses libp2p multiaddresses:

| Address | Meaning |
|---------|---------|
| `/ip4/0.0.0.0/tcp/8000` | Listen on all interfaces, port 8000 |
| `/ip4/127.0.0.1/tcp/8000` | Localhost only, port 8000 |
| `/ip4/192.168.1.5/tcp/8000` | Specific IP address |
| `/ip4/0.0.0.0/tcp/0` | Listen on any available port |

### Automatic Peer Discovery (mDNS)

When you `Listen`, LOGOS automatically enables **mDNS** (multicast DNS) for local network peer discovery. Peers on the same LAN will discover each other without manual configuration.

- Works on WiFi networks, local development
- No configuration required—just Listen
- Peers are auto-connected when discovered

### GossipSub (Pub/Sub)

The `Sync` statement uses **GossipSub**, a pub/sub protocol for broadcasting messages to topic subscribers:

- Topics are strings (e.g., `"game-scores"`, `"player-data"`)
- When you mutate a synced variable, the full state broadcasts to all subscribers
- Incoming messages are automatically merged in the background
- Retry with exponential backoff: 1s, 2s, 4s, 8s, 16s

### File Transfer

For large file transfers, LOGOS provides **FileSipper**—a chunked transfer protocol:

| Component | Description |
|-----------|-------------|
| **FileSipper** | Zero-copy file chunker (1 MB default chunks) |
| **FileManifest** | Describes file: chunk count, SHA256 hashes |
| **FileChunk** | Individual chunk with verification hash |

This enables resumable transfers over unreliable networks.

### Building a P2P Application

1. Define Portable message types
2. Listen on an address (server)
3. Connect to peers (client)
4. Create PeerAgent handles
5. Send messages
6. Use `Sync` for automatic CRDT replication
"#,
        examples: &[
            CodeExample {
                id: "network-listen",
                label: "Server: Listen for Connections",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Listen on "/ip4/0.0.0.0/tcp/8000".
Show "Server listening on port 8000"."#,
            },
            CodeExample {
                id: "network-connect",
                label: "Client: Connect to Peer",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let server_addr be "/ip4/127.0.0.1/tcp/8000".
Connect to server_addr.
Show "Connected to server"."#,
            },
            CodeExample {
                id: "network-peer-agent",
                label: "Creating a Remote Handle",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let remote be a PeerAgent at "/ip4/127.0.0.1/tcp/8000".
Show "Remote peer handle created"."#,
            },
            CodeExample {
                id: "network-send-message",
                label: "Sending a Message",
                mode: ExampleMode::Imperative,
                code: r#"## Definition
A Greeting is Portable and has:
    a message (Text).

## Main
Let remote be a PeerAgent at "/ip4/127.0.0.1/tcp/8000".
Let msg be a new Greeting with message "Hello, peer!".
Show "Sending: " + msg's message.
Send msg to remote."#,
            },
            CodeExample {
                id: "network-distributed",
                label: "Persistent + Synced (Compiled Only)",
                mode: ExampleMode::Imperative,
                code: r#"## Definition
A Counter is Shared and has:
    a value, which is ConvergentCount.

## Main
Listen on "/ip4/0.0.0.0/tcp/0".
Let mutable c: Persistent Counter be mounted at "counter.lsf".
Sync c on "shared-counter".
Increase c's value by 1.
Show c's value."#,
            },
            CodeExample {
                id: "network-mdns",
                label: "Automatic Peer Discovery",
                mode: ExampleMode::Imperative,
                code: r#"## Definition
A GameState is Shared and has:
    a score, which is ConvergentCount.

## Main
Listen on "/ip4/0.0.0.0/tcp/0".
Show "Listening... mDNS will auto-discover peers".

Let mutable state be a new GameState.
Sync state on "game-session".
Show "Synced to game-session topic"."#,
            },
            CodeExample {
                id: "network-file-transfer",
                label: "File Transfer Pattern",
                mode: ExampleMode::Imperative,
                code: r#"## Definition
A FileRequest is Portable and has:
    a filename: Text.
    a chunk_index: Int.

A FileResponse is Portable and has:
    a data: Text.
    a is_last: Bool.

## Main
Listen on "/ip4/0.0.0.0/tcp/8000".
Show "File server ready".
Show "Supports resumable chunked transfers"."#,
            },
        ],
    },

    Section {
        id: "error-handling",
        number: 16,
        title: "Error Handling",
        part: "Part I: Programming in LOGOS",
        content: r#"
LOGOS uses **Socratic error messages**—friendly, educational feedback that teaches while it corrects.

### The Philosophy

Instead of cryptic compiler errors, LOGOS explains:
1. **What** went wrong
2. **Where** it happened
3. **Why** it's a problem
4. **How** to fix it

### The Failure Type

Functions that might fail return a `Result`. Use pattern matching to handle success and failure cases.

### Error Propagation

Errors propagate naturally through return values. Handle them where appropriate.

### Defensive Programming

Use assertions and guards to prevent errors before they happen.
"#,
        examples: &[
            CodeExample {
                id: "defensive-divide",
                label: "Safe Division with Guard",
                mode: ExampleMode::Imperative,
                code: r#"## To safe_divide (a: Int) and (b: Int) -> Int:
    If b equals 0:
        Show "Error: Cannot divide by zero".
        Return 0.
    Return a / b.

## Main
Let result be safe_divide(10, 2).
Show "10 / 2 = " + result.
Let bad be safe_divide(5, 0).
Show "Result after error: " + bad."#,
            },
            CodeExample {
                id: "validation-example",
                label: "Input Validation",
                mode: ExampleMode::Imperative,
                code: r#"## To validate_age (age: Int) -> Bool:
    If age is less than 0:
        Show "Error: Age cannot be negative".
        Return false.
    If age is greater than 150:
        Show "Error: Age seems unrealistic".
        Return false.
    Return true.

## Main
Let valid be validate_age(25).
Show "Age 25 valid: " + valid.
Let invalid be validate_age(-5).
Show "Age -5 valid: " + invalid."#,
            },
        ],
    },

    Section {
        id: "advanced-features",
        number: 17,
        title: "Advanced Features",
        part: "Part I: Programming in LOGOS",
        content: r#"
### Refinement Types

Refinement types add constraints to base types. The constraint is checked at runtime or compile time with Z3.

### Assertions

Use `Assert` to verify conditions in your code. If the assertion fails, the program stops with an error message.

### Trust with Reason

Use `Trust` when you know something is true but the compiler can't verify it. The `because` clause documents why you believe the condition holds.

### Modules

Organize code across multiple files with `Use`.
"#,
        examples: &[
            CodeExample {
                id: "refinement-types",
                label: "Refinement Types",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let positive: Int where it > 0 be 5.
Let percentage: Int where it >= 0 and it <= 100 be 85.
Show positive.
Show percentage."#,
            },
            CodeExample {
                id: "assertions",
                label: "Assertions",
                mode: ExampleMode::Imperative,
                code: r#"## To divide_safe (a: Int) and (b: Int) -> Int:
    Assert that b is not 0.
    Return a / b.

## Main
Let result be divide_safe(10, 2).
Show result."#,
            },
        ],
    },

    // ============================================================
    // Part II: Project Structure (Sections 18-20)
    // ============================================================

    Section {
        id: "modules",
        number: 18,
        title: "Modules",
        part: "Part II: Project Structure",
        content: r#"
Organize large programs across multiple files using the module system.

### Importing Modules

Use `Use` to import a module.

### Qualified Access

Access module contents with the possessive `'s`.

### Creating Modules

Each `.md` file is a module. The filename becomes the module name.

### Visibility

By default, all definitions are public. Mark fields private with no `public` modifier.
"#,
        examples: &[
            CodeExample {
                id: "module-import",
                label: "Importing Modules (Compiled Only)",
                mode: ExampleMode::Imperative,
                code: r#"## To square (n: Int) -> Int:
    Return n * n.

## Main
Let x be 5.
Let result be square(x).
Show "5 squared = " + result."#,
            },
        ],
    },

    Section {
        id: "cli-largo",
        number: 19,
        title: "The CLI: largo",
        part: "Part II: Project Structure",
        content: r#"
LOGOS projects are built with `largo`, the LOGOS build tool.

### Creating a Project

| Command | Description |
|---------|-------------|
| `largo new <name>` | Create a new project in a new directory |
| `largo init` | Initialize a project in the current directory |

This creates a `Largo.toml` manifest and `src/main.lg` entry point.

### Build Commands

| Command | Description |
|---------|-------------|
| `largo build` | Compile the project to a native binary |
| `largo build --release` | Compile with optimizations |
| `largo run` | Build and run |
| `largo check` | Type-check without compiling |
| `largo verify` | Run Z3 static verification (Pro+ license required) |
| `largo build --verify` | Build with verification |

### Package Registry

Publish and manage packages on the LOGOS registry:

| Command | Description |
|---------|-------------|
| `largo login` | Authenticate with the registry |
| `largo publish` | Publish your package |
| `largo publish --dry-run` | Validate without publishing |
| `largo logout` | Log out from the registry |

### Project Manifest

The `Largo.toml` file defines package metadata and dependencies:

```toml
[package]
name = "myproject"
version = "0.1.0"
entry = "src/main.lg"

[dependencies]
```
"#,
        examples: &[],
    },

    Section {
        id: "stdlib",
        number: 20,
        title: "Standard Library",
        part: "Part II: Project Structure",
        content: r#"
LOGOS provides built-in functions for common operations.

### Currently Available

These built-ins work in both the playground and compiled programs:

- `Show x.` — Output values to the console
- `length of x` — Get the length of a list or text
- `format(x)` — Convert any value to text
- `abs(n)` — Absolute value of a number
- `min(a, b)` — Minimum of two integers
- `max(a, b)` — Maximum of two integers

### Coming Soon

Additional modules are planned for future releases:

- **File** — `read`, `write`, `exists` for file operations
- **Time** — `now`, `sleep` for timing and delays
- **Random** — `randomInt`, `randomFloat`, `choice`
- **Env** — Environment variables and command-line arguments

These will be available in compiled programs. Some features may have limited support in the browser playground due to WASM constraints.
"#,
        examples: &[
            CodeExample {
                id: "stdlib-example",
                label: "Standard Library",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let nums be [5, -3, 8, -1, 4].
Let text be "Hello".

Show "Built-in functions:".
Show "length of nums = " + format(length of nums).
Show "length of text = " + format(length of text).
Show "abs(-42) = " + format(abs(-42)).
Show "min(10, 3) = " + format(min(10, 3)).
Show "max(10, 3) = " + format(max(10, 3))."#,
            },
        ],
    },

    // ============================================================
    // Part III: Logic Mode (Section 21)
    // ============================================================

    Section {
        id: "logic-mode",
        number: 21,
        title: "Logic Mode",
        part: "Part III: Logic Mode",
        content: r#"
LOGOS can translate English sentences into First-Order Logic (FOL). This is useful for formal verification, knowledge representation, and understanding the logical structure of natural language.

### Quantifiers

| English | Symbol | Output |
|---------|--------|--------|
| All X are Y | `∀` | `∀x(X(x) → Y(x))` |
| Some X is Y | `∃` | `∃x(X(x) ∧ Y(x))` |
| No X is Y | `¬∃` | `¬∃x(X(x) ∧ Y(x))` |

### Connectives

| English | Symbol |
|---------|--------|
| and | `∧` |
| or | `∨` |
| not | `¬` |
| if...then | `→` |
| if and only if | `↔` |

### Modals

| English | Symbol |
|---------|--------|
| can, may, might | `◇` (possibility) |
| must | `□` (necessity) |

### Tense and Aspect

- `PAST(P)` — past tense
- `FUT(P)` — future tense
- `PROG(P)` — progressive aspect
- `PERF(P)` — perfect aspect
"#,
        examples: &[
            CodeExample {
                id: "logic-universal",
                label: "Universal Quantifier",
                mode: ExampleMode::Logic,
                code: "All birds fly.",
            },
            CodeExample {
                id: "logic-existential",
                label: "Existential Quantifier",
                mode: ExampleMode::Logic,
                code: "Some cats sleep.",
            },
            CodeExample {
                id: "logic-negative",
                label: "Negative Quantifier",
                mode: ExampleMode::Logic,
                code: "No fish fly.",
            },
            CodeExample {
                id: "logic-conditional",
                label: "Conditional",
                mode: ExampleMode::Logic,
                code: "If John runs, then Mary walks.",
            },
            CodeExample {
                id: "logic-modal",
                label: "Modal Operators",
                mode: ExampleMode::Logic,
                code: "John can swim.",
            },
        ],
    },

    // ============================================================
    // Part IV: Proofs and Verification (Sections 22-23)
    // ============================================================

    Section {
        id: "assertions-trust",
        number: 22,
        title: "Assertions and Trust",
        part: "Part IV: Proofs and Verification",
        content: r#"
LOGOS bridges imperative programming with formal verification through assertions and proof statements.

### Assert

Use `Assert` to verify conditions at runtime. If an assertion fails, the program stops with a clear error message.

### Trust with Justification

Use `Trust` for conditions the compiler can't verify automatically. The `because` clause is **mandatory**—it documents your reasoning.

### Trust Generates Debug Assertions

In development builds, `Trust` becomes a `debug_assert!`. In release builds, it generates no code—the trust is assumed.

### Auditing Trust Statements

Find all trust statements in your codebase with `largo audit`.

### Proof Blocks (Advanced)

For formal verification, use theorem blocks with proofs documented in comments.
"#,
        examples: &[
            CodeExample {
                id: "assert-example",
                label: "Assert",
                mode: ExampleMode::Imperative,
                code: r#"## To withdraw (amount: Int) from (balance: Int) -> Int:
    Assert that amount is greater than 0.
    Assert that amount is at most balance.
    Return balance - amount.

## Main
Let result be withdraw(50, 100).
Show result."#,
            },
            CodeExample {
                id: "trust-example",
                label: "Trust with Justification",
                mode: ExampleMode::Imperative,
                code: r#"## To process_positive (n: Int) -> Int:
    Trust that n is greater than 0 because "caller guarantees positive input".
    Return n * 2.

## Main
Let result be process_positive(5).
Show result."#,
            },
        ],
    },

    Section {
        id: "z3-verification",
        number: 23,
        title: "Z3 Static Verification",
        part: "Part IV: Proofs and Verification",
        content: r#"
LOGOS can use the Z3 SMT solver to verify refinement types at compile time.

### What is Z3?

Z3 is a theorem prover. Instead of checking constraints at runtime, Z3 proves (or disproves) them at compile time.

| Approach | When Checked | If Violated |
|----------|--------------|-------------|
| Runtime assertion | When code runs | Program crashes |
| Z3 verification | At compile time | Compilation fails |

### Variable Tracking

Z3 tracks constraints through variable assignments.

### Compound Predicates

Multiple constraints can be combined.

### Function Preconditions

Z3 verifies function contracts.

### Enabling Z3 Verification

Enable with `largo build --verify` or in `Largo.toml`.

### What Z3 Can Prove

| Constraint Type | Example | Z3 Support |
|-----------------|---------|------------|
| Integer bounds | `it > 0`, `it < 100` | Full |
| Equality | `it == 5` | Full |
| Arithmetic | `it * 2 < 100` | Full |
| Boolean logic | `it > 0 and it < 10` | Full |
"#,
        examples: &[
            CodeExample {
                id: "z3-refinement",
                label: "Z3 Refinement Types",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let positive: Int where it > 0 be 5.
Let bounded: Int where it >= 0 and it <= 100 be 85.
Show "Positive: " + positive.
Show "Bounded: " + bounded."#,
            },
        ],
    },

    // ============================================================
    // Part V: Reference (Sections 24-25)
    // ============================================================

    Section {
        id: "complete-examples",
        number: 24,
        title: "Complete Examples",
        part: "Part V: Reference",
        content: r#"
This section contains complete, runnable programs demonstrating various LOGOS features.

### Mergesort

A complete, recursive sorting algorithm.

### Factorial

Classic recursive example.

### Working with Structs

A complete example with custom types.

### Collection Processing

Common patterns for working with collections.
"#,
        examples: &[
            CodeExample {
                id: "example-factorial",
                label: "Factorial",
                mode: ExampleMode::Imperative,
                code: r#"## To factorial (n: Int) -> Int:
    If n is at most 1:
        Return 1.
    Return n * factorial(n - 1).

## Main
Let result be factorial(5).
Show "5! = " + result."#,
            },
            CodeExample {
                id: "example-fibonacci",
                label: "Fibonacci",
                mode: ExampleMode::Imperative,
                code: r#"## To fib (n: Int) -> Int:
    If n is at most 1:
        Return n.
    Return fib(n - 1) + fib(n - 2).

## Main
Show "Fibonacci sequence:".
Let i be 0.
While i is less than 10:
    Show fib(i).
    Set i to i + 1."#,
            },
            CodeExample {
                id: "example-filter",
                label: "Filter Positive Numbers",
                mode: ExampleMode::Imperative,
                code: r#"## Main
Let data be [-2, 5, -1, 8, 3, -4, 7].
Let positives be a new Seq of Int.

Repeat for n in data:
    If n is greater than 0:
        Push n to positives.

Show "Positives: " + positives."#,
            },
        ],
    },

    Section {
        id: "quick-reference",
        number: 25,
        title: "Quick Reference",
        part: "Part V: Reference",
        content: r#"
### Syntax Cheat Sheet

**Variables:**
- `Let x be 5.` — Create variable
- `Set x to 10.` — Change variable
- `Let x: Int be 5.` — With type annotation

**Control Flow:**
- `If condition:` ... `Otherwise:` — Conditional
- `While condition:` — While loop
- `Repeat for item in items:` — For-each loop
- `Return value.` — Return from function

**Functions:**
- `## To name (param: Type) -> ReturnType:` — Define function

**Structs:**
- `A TypeName has:` ... — Define struct
- `Let x be a new TypeName with field1 value1.` — Create instance
- `x's field` — Access field

**Enums:**
- `A TypeName is either:` ... — Define enum
- `Inspect x: When Variant:` ... — Pattern match

**Primitive Types:**

| Type | Description | Examples |
|------|-------------|----------|
| `Int` | Whole numbers | `5`, `-10`, `0` |
| `Bool` | True or false | `true`, `false` |
| `Text` | Strings | `"Hello"`, `""` |
| `Float` / `Real` | Decimals | `3.14`, `-0.5` |
| `Char` | Single character | backtick syntax |
| `Byte` | 8-bit unsigned | `42: Byte`, `255: Byte` |

**Lists (Seq):**
- `[1, 2, 3]` — List literal
- `item 1 of items` or `items[1]` — Access (1-indexed)
- `Push value to items.` — Add to end
- `length of items` — Get length

**Maps:**
- `Map of K to V` — Map type (key-value pairs)
- `a new Map of Text to Int` — Create empty map
- `item "key" of map` or `map["key"]` — Get value by key
- `Set item "key" of map to val.` or `Set map["key"] to val.` — Set value

**Sets:**
- `Set of T` — Set type (unique elements)
- `a new Set of Int` — Create empty set
- `Add x to set.` — Add element
- `Remove x from set.` — Remove element
- `set contains x` — Check membership
- `a union b` — Elements in either set
- `a intersection b` — Elements in both sets

**Tuples:**
- `(1, "two", 3.0)` — Tuple literal (mixed types allowed)
- `t[1]` or `item 1 of t` — Access (1-indexed)
- `length of t` — Get tuple size

### Ownership Verbs

| Verb | Meaning |
|------|---------|
| `Give x to f.` | Move ownership |
| `Show x to f.` | Borrow (read) |
| `Let f modify x.` | Mutable borrow |
| `copy of x` | Clone |

### Zones

**Basic syntax:**
- `Inside a zone called "Name":` — 4KB default zone
- `Inside a zone called "Name" of size 2 MB:` — Sized heap zone
- `Inside a zone called "Name" mapped from "file.bin":` — Memory-mapped file

**Size units:** B, KB, MB, GB

### Concurrency

**Async I/O:**
- `Attempt all of the following:` — Concurrent async tasks (tokio::join!)

**Parallel CPU:**
- `Simultaneously:` — Parallel computation (rayon/threads)

**Tasks (Compiled Only):**
- `Launch a task to f(args).` — Fire-and-forget spawn
- `Let h be Launch a task to f(args).` — Spawn with handle
- `Stop h.` — Abort a running task

**Channels/Pipes (Compiled Only):**
- `Let p be a new Pipe of Int.` — Create bounded channel
- `Send x into p.` — Blocking send
- `Receive x from p.` — Blocking receive
- `Try to send/receive` — Non-blocking variants

**Select (Compiled Only):**
- `Await the first of:` — Race multiple operations
- `Receive x from p:` — Channel receive branch
- `After N seconds:` — Timeout branch

### Distributed Types (CRDTs)

**Shared Structs:**
- `A Counter is Shared and has:` — CRDT-enabled struct

**CRDT Field Types:**
- `ConvergentCount` — Grow-only counter (`Increase`)
- `Tally` — Bidirectional counter (`Increase`, `Decrease`)
- `LastWriteWins of T` — Timestamp-based register (`Set`)
- `Divergent T` — Multi-value register (`Set`, `Resolve`)
- `SharedSet of T` — Add/remove set (`Add`, `Remove`, `contains`)
- `SharedSet (AddWins) of T` — Set where add wins conflicts
- `SharedSet (RemoveWins) of T` — Set where remove wins conflicts
- `SharedSequence of T` — Ordered list RGA (`Append`)
- `CollaborativeSequence of T` — Text-optimized YATA (`Append`)
- `SharedSequence (YATA) of T` — Alternate YATA syntax
- `SharedMap from K to V` — Key-value CRDT (`[]` access)
- `ORMap from K to V` — Alternate map syntax

**CRDT Operations:**
- `Increase x's field by amount.` — Increment counter
- `Decrease x's field by amount.` — Decrement Tally
- `Set x's field to value.` — Set register value
- `Resolve x's field to value.` — Resolve Divergent conflict
- `Add value to x's field.` — Add to SharedSet
- `Remove value from x's field.` — Remove from SharedSet
- `Append value to x's field.` — Append to sequence
- `Merge source into target.` — Combine two CRDT instances

**Persistence (Compiled Only):**
- `Persistent Counter` — Type with automatic journaling
- `Let x be mounted at "data.lsf".` — Load/create persistent CRDT
- `Mount x at "path".` — Mount statement for persistence

**Network Sync (Compiled Only):**
- `Sync mutable_var on "topic".` — Subscribe to GossipSub topic for auto-sync

### P2P Networking

**Server/Client:**
- `Listen on "/ip4/0.0.0.0/tcp/8000".` — Bind to address
- `Listen on "/ip4/0.0.0.0/tcp/0".` — Listen on any available port
- `Connect to addr.` — Dial a peer
- `Let remote be a PeerAgent at addr.` — Create remote handle
- `Send msg to remote.` — Transmit message

**Portable Types:**
- `A Message is Portable and has:` — Network-serializable struct

**Automatic Discovery:**
- mDNS auto-discovers peers on local network when you Listen
- Peers are automatically connected when discovered

**GossipSub (via Sync):**
- Topics broadcast state changes to all subscribers
- Retry with exponential backoff (1s, 2s, 4s, 8s, 16s)

**File Transfer:**
- FileSipper for chunked transfers (1 MB chunks)
- FileManifest with SHA256 hashes for verification
- Enables resumable transfers

### Security

**Policy Blocks:**
- `## Policy` — Define security rules
- `A User is admin if...` — Define a predicate
- `A User can edit the Doc if...` — Define a capability

**Security Enforcement:**
- `Check that user is admin.` — Mandatory runtime check (never optimized out)
- `Assert that x > 0.` — Debug-only assertion (can be optimized out)

### Logic Mode Symbols

| English | Symbol |
|---------|--------|
| All | `∀` |
| Some | `∃` |
| and | `∧` |
| or | `∨` |
| not | `¬` |
| if...then | `→` |
| can/may | `◇` |
| must | `□` |
"#,
        examples: &[],
    },
];

/// Get all sections
pub fn get_all_sections() -> &'static [Section] {
    SECTIONS
}

/// Get sections by part
pub fn get_sections_by_part(part: &str) -> Vec<&'static Section> {
    SECTIONS.iter().filter(|s| s.part == part).collect()
}

/// Get a section by ID
pub fn get_section_by_id(id: &str) -> Option<&'static Section> {
    SECTIONS.iter().find(|s| s.id == id)
}

/// Get all unique part names in order
pub fn get_parts() -> Vec<&'static str> {
    let mut parts = Vec::new();
    for section in SECTIONS {
        if parts.last() != Some(&section.part) {
            parts.push(section.part);
        }
    }
    parts
}

```

---

### Guide: Module

**File:** `src/ui/pages/guide/mod.rs`

Documentation browser and interactive tutorials module.

```rust
//! Programmer's Guide page.
//!
//! A beautiful, interactive guide to the LOGOS programming language with:
//! - 22 sections from PROGRAMMERS_LANGUAGE_STARTER.md
//! - Sticky sidebar navigation
//! - Interactive code examples with Run/Copy/Reset
//! - Dual mode: Logic (FOL output) and Imperative (WASM execution)

pub mod content;

use dioxus::prelude::*;
use crate::ui::router::Route;
use crate::ui::components::guide_code_block::GuideCodeBlock;
use crate::ui::components::guide_sidebar::{GuideSidebar, SectionInfo};
use crate::ui::components::main_nav::{MainNav, ActivePage};
use content::SECTIONS;

const GUIDE_STYLE: &str = r#"
.guide-page {
    min-height: 100vh;
    color: var(--text-primary);
    background:
        radial-gradient(1200px 600px at 50% -120px, rgba(167,139,250,0.14), transparent 60%),
        radial-gradient(900px 500px at 15% 30%, rgba(96,165,250,0.14), transparent 60%),
        radial-gradient(800px 450px at 90% 45%, rgba(34,197,94,0.08), transparent 62%),
        linear-gradient(180deg, #070a12, #0b1022 55%, #070a12);
    font-family: var(--font-sans);
}

/* Navigation - now handled by MainNav component */

/* Hero */
.guide-hero {
    max-width: 1280px;
    margin: 0 auto;
    padding: 60px var(--spacing-xl) 40px;
}

.guide-hero h1 {
    font-size: var(--font-display-lg);
    font-weight: 900;
    letter-spacing: -1.5px;
    line-height: 1.1;
    background: linear-gradient(180deg, #ffffff 0%, rgba(229,231,235,0.78) 65%, rgba(229,231,235,0.62) 100%);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    margin: 0 0 var(--spacing-lg);
}

.guide-hero p {
    font-size: var(--font-body-lg);
    color: var(--text-secondary);
    max-width: 600px;
    line-height: 1.6;
    margin: 0;
}

.guide-hero-badge {
    display: inline-flex;
    align-items: center;
    gap: var(--spacing-sm);
    padding: var(--spacing-sm) 14px;
    border-radius: var(--radius-full);
    background: rgba(255,255,255,0.06);
    border: 1px solid rgba(255,255,255,0.10);
    font-size: var(--font-caption-md);
    font-weight: 600;
    color: var(--text-primary);
    margin-bottom: var(--spacing-xl);
}

.guide-hero-badge .dot {
    width: 8px;
    height: 8px;
    border-radius: 50%;
    background: var(--color-success);
    box-shadow: 0 0 0 4px rgba(34,197,94,0.15);
}

/* Layout */
.guide-layout {
    max-width: 1280px;
    margin: 0 auto;
    display: flex;
    gap: 48px;
    padding: 0 var(--spacing-xl) 80px;
}

/* Main content */
.guide-content {
    flex: 1;
    min-width: 0;
    max-width: 800px;
}

/* Section styling */
.guide-section {
    margin-bottom: 64px;
    scroll-margin-top: 100px;
}

.guide-section h2 {
    font-size: var(--font-display-md);
    font-weight: 800;
    letter-spacing: -0.8px;
    line-height: 1.2;
    background: linear-gradient(180deg, #ffffff 0%, rgba(229,231,235,0.85) 100%);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    margin: 0 0 var(--spacing-xl);
    padding-bottom: var(--spacing-lg);
    border-bottom: 1px solid rgba(255,255,255,0.08);
}

.guide-section h3 {
    font-size: var(--font-heading-sm);
    font-weight: 700;
    color: var(--text-primary);
    margin: var(--spacing-xxl) 0 var(--spacing-lg);
}

.guide-section p {
    color: var(--text-secondary);
    font-size: var(--font-body-sm);
    line-height: 1.75;
    margin: 0 0 var(--spacing-lg);
}

.guide-section ul,
.guide-section ol {
    color: var(--text-secondary);
    font-size: var(--font-body-sm);
    line-height: 1.75;
    padding-left: var(--spacing-xl);
    margin: 0 0 var(--spacing-lg);
}

.guide-section li {
    margin-bottom: var(--spacing-sm);
}

.guide-section code {
    font-family: var(--font-mono);
    background: rgba(255,255,255,0.08);
    padding: 3px 7px;
    border-radius: var(--radius-sm);
    font-size: 0.9em;
    color: var(--color-accent-purple);
}

.guide-section strong {
    color: var(--text-primary);
    font-weight: 600;
}

/* Tables */
.guide-section table {
    width: 100%;
    border-collapse: collapse;
    margin: var(--spacing-xl) 0;
    font-size: var(--font-body-md);
    border-radius: var(--radius-lg);
    overflow: hidden;
    border: 1px solid rgba(255,255,255,0.08);
}

.guide-section th {
    text-align: left;
    padding: 14px var(--spacing-lg);
    background: rgba(255,255,255,0.05);
    color: var(--text-primary);
    font-weight: 600;
    border-bottom: 1px solid rgba(255,255,255,0.08);
}

.guide-section td {
    padding: var(--spacing-md) var(--spacing-lg);
    color: var(--text-secondary);
    border-bottom: 1px solid rgba(255,255,255,0.05);
}

.guide-section tr:last-child td {
    border-bottom: none;
}

.guide-section tr:hover td {
    background: rgba(255,255,255,0.02);
}

/* Part dividers */
.guide-part-divider {
    margin: 80px 0 48px;
    padding: var(--spacing-xl) 0;
    border-top: 1px solid rgba(255,255,255,0.08);
}

.guide-part-divider h2 {
    font-size: var(--font-body-md);
    font-weight: 700;
    text-transform: uppercase;
    letter-spacing: 1.5px;
    color: var(--text-tertiary);
    margin: 0;
    background: none;
    -webkit-text-fill-color: currentColor;
    border-bottom: none;
    padding-bottom: 0;
}

/* Section number */
.section-number {
    display: inline-block;
    font-size: var(--font-body-md);
    font-weight: 700;
    color: var(--color-accent-purple);
    margin-right: var(--spacing-sm);
    opacity: 0.8;
}

/* Examples container */
.guide-examples {
    margin-top: var(--spacing-xl);
}

/* Responsive */
@media (max-width: 1024px) {
    .guide-layout {
        flex-direction: column;
    }

    .guide-hero h1 {
        font-size: var(--font-display-md);
    }

    .guide-hero {
        padding: 40px var(--spacing-xl) var(--spacing-xxl);
    }
}

@media (max-width: 640px) {
    .guide-hero h1 {
        font-size: var(--font-heading-lg);
    }

    .guide-hero p {
        font-size: var(--font-body-md);
    }

    .guide-section h2 {
        font-size: var(--font-heading-lg);
    }
}
"#;

#[component]
pub fn Guide() -> Element {
    let mut active_section = use_signal(|| "introduction".to_string());

    // Build section info for sidebar
    let sections_info: Vec<SectionInfo> = SECTIONS.iter().map(|s| SectionInfo {
        id: s.id.to_string(),
        number: s.number,
        title: s.title.to_string(),
        part: s.part.to_string(),
    }).collect();

    // Collect all section IDs for intersection observer
    #[allow(unused_variables)]
    let section_ids: Vec<String> = SECTIONS.iter().map(|s| s.id.to_string()).collect();

    // Set up scroll tracking with IntersectionObserver
    #[cfg(target_arch = "wasm32")]
    {
        use wasm_bindgen::prelude::*;
        use wasm_bindgen::JsCast;

        let section_ids_for_effect = section_ids.clone();

        use_effect(move || {
            let window = match web_sys::window() {
                Some(w) => w,
                None => return,
            };
            let document = match window.document() {
                Some(d) => d,
                None => return,
            };

            // Use RefCell to allow mutation from within Fn closure
            use std::cell::RefCell;
            use std::rc::Rc;

            let active_section_clone = Rc::new(RefCell::new(active_section.clone()));
            let active_section_for_closure = active_section_clone.clone();

            let callback = Closure::<dyn Fn(js_sys::Array, web_sys::IntersectionObserver)>::new(
                move |entries: js_sys::Array, _observer: web_sys::IntersectionObserver| {
                    // Simple approach: when a section crosses the threshold line,
                    // it becomes active
                    for i in 0..entries.length() {
                        if let Ok(entry) = entries.get(i).dyn_into::<web_sys::IntersectionObserverEntry>() {
                            if entry.is_intersecting() {
                                let target = entry.target();
                                let id = target.id();
                                if !id.is_empty() {
                                    active_section_for_closure.borrow_mut().set(id);
                                }
                            }
                        }
                    }
                },
            );

            // Create IntersectionObserver options
            let mut options = web_sys::IntersectionObserverInit::new();
            // Root margin creates a thin "tripwire" near the top of the screen
            options.root_margin("-100px 0px -90% 0px");
            let thresholds = js_sys::Array::new();
            thresholds.push(&JsValue::from(0.0));
            options.threshold(&thresholds);

            // Create the observer
            let observer = match web_sys::IntersectionObserver::new_with_options(
                callback.as_ref().unchecked_ref(),
                &options,
            ) {
                Ok(obs) => obs,
                Err(_) => return,
            };

            // Observe all sections
            for section_id in &section_ids_for_effect {
                if let Some(element) = document.get_element_by_id(section_id) {
                    observer.observe(&element);
                }
            }

            // Keep callback alive
            callback.forget();
        });
    }

    // Track current part for dividers
    let mut current_part = String::new();

    rsx! {
        style { "{GUIDE_STYLE}" }

        div { class: "guide-page",
            // Navigation
            MainNav {
                active: ActivePage::Guide,
                subtitle: Some("Programmer's Guide"),
            }

            // Hero
            header { class: "guide-hero",
                div { class: "guide-hero-badge",
                    div { class: "dot" }
                    span { "Interactive Guide" }
                }
                h1 { "LOGOS Language Guide" }
                p {
                    "Write English. Get Logic. Run Code. A comprehensive guide to programming in LOGOS, from basics to advanced features."
                }
            }

            // Main layout
            div { class: "guide-layout",
                // Sidebar
                GuideSidebar {
                    sections: sections_info,
                    active_section: active_section.read().clone(),
                    on_section_click: move |id: String| {
                        active_section.set(id);
                    },
                }

                // Content
                main { class: "guide-content",
                    for section in SECTIONS.iter() {
                        {
                            // Check if we need a part divider
                            let show_divider = section.part != current_part && section.number > 1;
                            current_part = section.part.to_string();

                            rsx! {
                                // Part divider
                                if show_divider {
                                    div { class: "guide-part-divider",
                                        h2 { "{section.part}" }
                                    }
                                }

                                // Section
                                section {
                                    id: "{section.id}",
                                    class: "guide-section",

                                    h2 {
                                        span { class: "section-number", "{section.number}." }
                                        "{section.title}"
                                    }

                                    // Render content as HTML
                                    div {
                                        dangerous_inner_html: render_markdown(section.content)
                                    }

                                    // Render code examples
                                    if !section.examples.is_empty() {
                                        div { class: "guide-examples",
                                            for example in section.examples.iter() {
                                                GuideCodeBlock {
                                                    id: example.id.to_string(),
                                                    label: example.label.to_string(),
                                                    mode: example.mode,
                                                    initial_code: example.code.to_string(),
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                }
            }
        }
    }
}

/// Simple markdown to HTML converter
/// Handles: headers, paragraphs, lists, tables, inline code, bold
fn render_markdown(content: &str) -> String {
    let mut html = String::new();
    let mut in_list = false;
    let mut in_table = false;
    let mut in_table_header = false;

    for line in content.lines() {
        let trimmed = line.trim();

        // Skip empty lines
        if trimmed.is_empty() {
            if in_list {
                html.push_str("</ul>");
                in_list = false;
            }
            if in_table {
                html.push_str("</tbody></table>");
                in_table = false;
            }
            continue;
        }

        // Headers
        if trimmed.starts_with("### ") {
            if in_list { html.push_str("</ul>"); in_list = false; }
            if in_table { html.push_str("</tbody></table>"); in_table = false; }
            html.push_str(&format!("<h3>{}</h3>", inline_markdown(&trimmed[4..])));
            continue;
        }

        // Table row
        if trimmed.starts_with('|') && trimmed.ends_with('|') {
            // Check if this is a separator row (|---|---|)
            if trimmed.contains("---") {
                in_table_header = false;
                continue;
            }

            if !in_table {
                html.push_str("<table><thead>");
                in_table = true;
                in_table_header = true;
            }

            let cells: Vec<&str> = trimmed[1..trimmed.len()-1]
                .split('|')
                .map(|s| s.trim())
                .collect();

            if in_table_header {
                html.push_str("<tr>");
                for cell in &cells {
                    html.push_str(&format!("<th>{}</th>", inline_markdown(cell)));
                }
                html.push_str("</tr></thead><tbody>");
            } else {
                html.push_str("<tr>");
                for cell in &cells {
                    html.push_str(&format!("<td>{}</td>", inline_markdown(cell)));
                }
                html.push_str("</tr>");
            }
            continue;
        }

        // Close table if not a table row
        if in_table && !trimmed.starts_with('|') {
            html.push_str("</tbody></table>");
            in_table = false;
        }

        // List items
        if trimmed.starts_with("- ") || trimmed.starts_with("* ") {
            if !in_list {
                html.push_str("<ul>");
                in_list = true;
            }
            html.push_str(&format!("<li>{}</li>", inline_markdown(&trimmed[2..])));
            continue;
        }

        // Numbered list
        if trimmed.chars().next().map_or(false, |c| c.is_ascii_digit()) {
            if let Some(dot_pos) = trimmed.find(". ") {
                if !in_list {
                    html.push_str("<ul>");
                    in_list = true;
                }
                html.push_str(&format!("<li>{}</li>", inline_markdown(&trimmed[dot_pos + 2..])));
                continue;
            }
        }

        // Close list if not a list item
        if in_list {
            html.push_str("</ul>");
            in_list = false;
        }

        // Paragraph
        html.push_str(&format!("<p>{}</p>", inline_markdown(trimmed)));
    }

    // Close any open tags
    if in_list {
        html.push_str("</ul>");
    }
    if in_table {
        html.push_str("</tbody></table>");
    }

    html
}

/// Process inline markdown: **bold**, `code`, [links]
fn inline_markdown(text: &str) -> String {
    let mut result = text.to_string();

    // Escape HTML entities
    result = result.replace('&', "&amp;");
    result = result.replace('<', "&lt;");
    result = result.replace('>', "&gt;");

    // Bold: **text**
    while let Some(start) = result.find("**") {
        if let Some(end) = result[start + 2..].find("**") {
            let before = &result[..start];
            let inner = &result[start + 2..start + 2 + end];
            let after = &result[start + 2 + end + 2..];
            result = format!("{}<strong>{}</strong>{}", before, inner, after);
        } else {
            break;
        }
    }

    // Inline code: `code`
    while let Some(start) = result.find('`') {
        if let Some(end) = result[start + 1..].find('`') {
            let before = &result[..start];
            let inner = &result[start + 1..start + 1 + end];
            let after = &result[start + 1 + end + 1..];
            result = format!("{}<code>{}</code>{}", before, inner, after);
        } else {
            break;
        }
    }

    result
}

```

---

## Problem Generator

The Problem Generator transforms LOGOS from a sandbox into an interactive teaching tool with curriculum-based exercises.

**Location:** `src/content.rs`, `src/generator.rs`, `src/grader.rs`, `src/runtime_lexicon.rs`

**Architecture:**
```
┌─────────────────────────────────────────────────────────────────────────────┐
│                         Problem Generator Pipeline                           │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   ┌───────────┐    ┌───────────┐    ┌───────────┐    ┌───────────┐        │
│   │ Curriculum│───▶│ Generator │───▶│ Challenge │───▶│  Grader   │        │
│   │   JSON    │    │  Engine   │    │           │    │           │        │
│   └───────────┘    └─────┬─────┘    └───────────┘    └─────┬─────┘        │
│                          │                                  │              │
│                          ▼                                  ▼              │
│                    ┌───────────┐                      ┌───────────┐        │
│                    │  Runtime  │                      │ Semantic  │        │
│                    │  Lexicon  │                      │ Equality  │        │
│                    └───────────┘                      └───────────┘        │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### Curriculum Structure

Filesystem-based curriculum organization embedded at compile time via `include_dir`.

```
assets/curriculum/
├── 01_trivium/                    # Era I: Naming
│   ├── meta.json                  # Era metadata (id, title, description)
│   ├── 01_atomic/                 # Module: Predication
│   │   ├── meta.json              # Module metadata (pedagogy, order)
│   │   ├── ex_01_adjectives.json  # Exercise: {ProperName} is {Adjective}
│   │   └── ex_02_intransitive.json
│   ├── 02_relations/              # Module: Transitive verbs
│   └── 03_negation/               # Module: Negation
├── 02_quadrivium/                 # Era II: Quantification
│   ├── 01_universal/              # ∀x patterns
│   ├── 02_existential/            # ∃x patterns
│   └── 03_scope/                  # Scope ambiguity
└── 03_metaphysics/                # Era III: Modality & Time
    ├── 01_modality/               # □ and ◇ operators
    └── 02_time/                   # Past and Future operators
```

**Exercise Schema:**
```json
{
  "id": "ex_01",
  "type": "translation",
  "difficulty": 1,
  "prompt": "Translate this observation:",
  "template": "{ProperName} is {Adjective}.",
  "constraints": { "Adjective": ["Intersective"] },
  "hint": "Apply the adjective as a predicate to the constant."
}
```

### Template Slots

| Slot | Example | Constraints |
|------|---------|-------------|
| `{ProperName}` | John, Mary | Proper nouns from lexicon |
| `{Noun}` | dog, cat | Common nouns, filterable by sort |
| `{Noun:Plural}` | dogs, cats | Plural form of common noun |
| `{Verb}` | runs, sleeps | Intransitive verbs |
| `{Verb:Past}` | ran, slept | Past tense form |
| `{Adjective}` | happy, tall | Intersective by default |

### Semantic Grading

The grader performs semantic equivalence checking, not string matching:

1. **Unicode normalization**: `\forall` → `∀`, `->` → `→`, `&` → `∧`
2. **Whitespace removal**: `∀x ( P(x) )` → `∀x(P(x))`
3. **Commutativity**: `P ∧ Q` equals `Q ∧ P`
4. **Structural similarity**: Partial credit for close attempts

**Grading Results:**
| Score | Meaning |
|-------|---------|
| 100 | Correct (semantically equivalent) |
| 35-50 | Partial (close structure) |
| 0 | Incorrect |

### Content Engine

**File:** `src/content.rs`

Loads curriculum from embedded JSON files. Uses include_dir to embed assets/curriculum/ at compile time. Provides ContentEngine for querying eras, modules, and exercises.

```rust
use include_dir::{include_dir, Dir};
use serde::Deserialize;
use std::collections::HashMap;

static CURRICULUM_DIR: Dir = include_dir!("$CARGO_MANIFEST_DIR/assets/curriculum");

#[derive(Debug, Clone, Deserialize)]
pub struct EraMeta {
    pub id: String,
    pub title: String,
    pub description: String,
    pub order: u32,
}

#[derive(Debug, Clone, Deserialize)]
pub struct ModuleMeta {
    pub id: String,
    pub title: String,
    pub pedagogy: String,
    pub order: u32,
}

#[derive(Debug, Clone, Deserialize)]
pub struct ExerciseConfig {
    pub id: String,
    #[serde(rename = "type")]
    pub exercise_type: ExerciseType,
    pub difficulty: u32,
    pub prompt: String,
    #[serde(default)]
    pub template: Option<String>,
    #[serde(default)]
    pub constraints: HashMap<String, Vec<String>>,
    #[serde(default)]
    pub hint: Option<String>,
    #[serde(default)]
    pub explanation: Option<String>,
    #[serde(default)]
    pub options: Option<Vec<String>>,
    #[serde(default)]
    pub correct: Option<usize>,
}

#[derive(Debug, Clone, Deserialize, PartialEq)]
#[serde(rename_all = "snake_case")]
pub enum ExerciseType {
    Translation,
    MultipleChoice,
    Ambiguity,
}

/// A symbol definition for the glossary
#[derive(Debug, Clone, Deserialize)]
pub struct SymbolDef {
    pub symbol: String,
    pub name: String,
    pub meaning: String,
    #[serde(default)]
    pub example: Option<String>,
}

/// A content block within a section (paragraph, definition, example, etc.)
#[derive(Debug, Clone, Deserialize)]
#[serde(tag = "type", rename_all = "snake_case")]
pub enum ContentBlock {
    Paragraph {
        text: String,
    },
    Definition {
        term: String,
        definition: String,
    },
    Example {
        title: String,
        #[serde(default)]
        premises: Vec<String>,
        #[serde(default)]
        conclusion: Option<String>,
        #[serde(default)]
        note: Option<String>,
    },
    /// Symbol glossary block - shows relevant symbols for this section
    Symbols {
        title: String,
        symbols: Vec<SymbolDef>,
    },
    /// Quiz question embedded in the lesson
    Quiz {
        question: String,
        options: Vec<String>,
        correct: usize,
        #[serde(default)]
        explanation: Option<String>,
    },
}

/// A lesson section with structured content
#[derive(Debug, Clone, Deserialize)]
pub struct Section {
    pub id: String,
    pub title: String,
    pub order: u32,
    #[serde(default)]
    pub content: Vec<ContentBlock>,
    #[serde(default)]
    pub key_symbols: Vec<String>,
}

#[derive(Debug, Clone)]
pub struct Module {
    pub meta: ModuleMeta,
    pub exercises: Vec<ExerciseConfig>,
    pub sections: Vec<Section>,
}

#[derive(Debug, Clone)]
pub struct Era {
    pub meta: EraMeta,
    pub modules: Vec<Module>,
}

#[derive(Debug, Clone)]
pub struct Curriculum {
    pub eras: Vec<Era>,
}

pub struct ContentEngine {
    pub curriculum: Curriculum,
}

impl ContentEngine {
    pub fn new() -> Self {
        let curriculum = Self::load_curriculum();
        Self { curriculum }
    }

    fn load_curriculum() -> Curriculum {
        let mut eras = Vec::new();

        for era_entry in CURRICULUM_DIR.dirs() {
            if let Some(era) = Self::load_era(era_entry) {
                eras.push(era);
            }
        }

        eras.sort_by_key(|e| e.meta.order);
        Curriculum { eras }
    }

    fn load_era(era_dir: &Dir) -> Option<Era> {
        // era_dir.path() returns "01_trivium", file paths are "01_trivium/meta.json"
        let era_path = era_dir.path().to_string_lossy();
        let meta_path = format!("{}/meta.json", era_path);
        let meta_file = era_dir.get_file(&meta_path)?;
        let meta_content = meta_file.contents_utf8()?;
        let meta: EraMeta = serde_json::from_str(meta_content).ok()?;

        let mut modules = Vec::new();
        for module_entry in era_dir.dirs() {
            if let Some(module) = Self::load_module(module_entry) {
                modules.push(module);
            }
        }

        modules.sort_by_key(|m| m.meta.order);
        Some(Era { meta, modules })
    }

    fn load_module(module_dir: &Dir) -> Option<Module> {
        // module_dir.path() returns "01_trivium/01_atomic"
        let module_path = module_dir.path().to_string_lossy();
        let meta_path = format!("{}/meta.json", module_path);
        let meta_file = module_dir.get_file(&meta_path)?;
        let meta_content = meta_file.contents_utf8()?;
        let meta: ModuleMeta = serde_json::from_str(meta_content).ok()?;

        let mut exercises = Vec::new();
        let mut sections = Vec::new();

        for file in module_dir.files() {
            if let Some(name) = file.path().file_name() {
                let name_str = name.to_string_lossy();
                if name_str.starts_with("ex_") && name_str.ends_with(".json") {
                    // Load exercise
                    if let Some(content) = file.contents_utf8() {
                        if let Ok(exercise) = serde_json::from_str::<ExerciseConfig>(content) {
                            exercises.push(exercise);
                        }
                    }
                } else if name_str.starts_with("sec_") && name_str.ends_with(".json") {
                    // Load section
                    if let Some(content) = file.contents_utf8() {
                        if let Ok(section) = serde_json::from_str::<Section>(content) {
                            sections.push(section);
                        }
                    }
                }
            }
        }

        exercises.sort_by(|a, b| a.id.cmp(&b.id));
        sections.sort_by_key(|s| s.order);
        Some(Module { meta, exercises, sections })
    }

    pub fn get_era(&self, era_id: &str) -> Option<&Era> {
        self.curriculum.eras.iter().find(|e| e.meta.id == era_id)
    }

    pub fn get_module(&self, era_id: &str, module_id: &str) -> Option<&Module> {
        self.get_era(era_id)?
            .modules
            .iter()
            .find(|m| m.meta.id == module_id)
    }

    pub fn get_exercise(&self, era_id: &str, module_id: &str, exercise_id: &str) -> Option<&ExerciseConfig> {
        self.get_module(era_id, module_id)?
            .exercises
            .iter()
            .find(|e| e.id == exercise_id)
    }

    pub fn eras(&self) -> &[Era] {
        &self.curriculum.eras
    }

    pub fn era_count(&self) -> usize {
        self.curriculum.eras.len()
    }

    pub fn module_count(&self, era_id: &str) -> usize {
        self.get_era(era_id).map(|e| e.modules.len()).unwrap_or(0)
    }

    pub fn exercise_count(&self, era_id: &str, module_id: &str) -> usize {
        self.get_module(era_id, module_id)
            .map(|m| m.exercises.len())
            .unwrap_or(0)
    }
}

impl Default for ContentEngine {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_dir_contents() {
        // Debug: print what's in the embedded directory
        println!("Files in CURRICULUM_DIR:");
        for f in CURRICULUM_DIR.files() {
            println!("  file: {:?}", f.path());
        }
        println!("Dirs in CURRICULUM_DIR:");
        for d in CURRICULUM_DIR.dirs() {
            println!("  era dir: {:?}", d.path());
            for f in d.files() {
                println!("    era file: {:?}", f.path());
            }
            for module_d in d.dirs() {
                println!("    module dir: {:?}", module_d.path());
                for f in module_d.files() {
                    println!("      module file: {:?}", f.path());
                }
            }
        }
        assert!(!CURRICULUM_DIR.dirs().collect::<Vec<_>>().is_empty(), "Should have embedded directories");
    }

    #[test]
    fn test_curriculum_loads() {
        let engine = ContentEngine::new();
        assert!(engine.era_count() >= 4, "Should have at least 4 eras (got {})", engine.era_count());
    }

    #[test]
    fn test_first_steps_era_exists() {
        let engine = ContentEngine::new();
        let era = engine.get_era("first-steps");
        assert!(era.is_some(), "First Steps era should exist");
        assert_eq!(era.unwrap().meta.title, "First Steps");
    }

    #[test]
    fn test_building_blocks_era_exists() {
        let engine = ContentEngine::new();
        let era = engine.get_era("building-blocks");
        assert!(era.is_some(), "Building Blocks era should exist");
        assert_eq!(era.unwrap().meta.title, "Building Blocks");
    }

    #[test]
    fn test_expanding_horizons_era_exists() {
        let engine = ContentEngine::new();
        let era = engine.get_era("expanding-horizons");
        assert!(era.is_some(), "Expanding Horizons era should exist");
        assert_eq!(era.unwrap().meta.title, "Expanding Horizons");
    }

    #[test]
    fn test_mastery_era_exists() {
        let engine = ContentEngine::new();
        let era = engine.get_era("mastery");
        assert!(era.is_some(), "Mastery era should exist");
        assert_eq!(era.unwrap().meta.title, "Mastery");
    }

    #[test]
    fn test_introduction_module_exists() {
        let engine = ContentEngine::new();
        let module = engine.get_module("first-steps", "introduction");
        assert!(module.is_some(), "Introduction module should exist");
        assert_eq!(module.unwrap().meta.title, "Introduction");
    }

    #[test]
    fn test_syllogistic_module_exists() {
        let engine = ContentEngine::new();
        let module = engine.get_module("first-steps", "syllogistic");
        assert!(module.is_some(), "Syllogistic module should exist");
        let m = module.unwrap();
        assert_eq!(m.meta.title, "Syllogistic Logic");
        assert!(m.exercises.len() >= 90, "Should have at least 90 exercises (got {})", m.exercises.len());
    }

    #[test]
    fn test_propositional_module_exists() {
        let engine = ContentEngine::new();
        let module = engine.get_module("building-blocks", "propositional");
        assert!(module.is_some(), "Propositional module should exist");
        let m = module.unwrap();
        assert_eq!(m.meta.title, "Basic Propositional Logic");
        assert!(m.exercises.len() >= 100, "Should have at least 100 exercises (got {})", m.exercises.len());
    }

    #[test]
    fn test_exercises_load() {
        let engine = ContentEngine::new();
        let count = engine.exercise_count("first-steps", "syllogistic");
        assert!(count >= 90, "Syllogistic module should have at least 90 exercises");
    }

    #[test]
    fn test_exercise_has_explanation() {
        let engine = ContentEngine::new();
        let ex = engine.get_exercise("first-steps", "syllogistic", "A_1.1");
        assert!(ex.is_some(), "Exercise A_1.1 should exist");
        let exercise = ex.unwrap();
        assert!(exercise.explanation.is_some(), "Exercise should have explanation");
        assert!(exercise.options.is_some(), "Exercise should have options");
        assert_eq!(exercise.exercise_type, ExerciseType::MultipleChoice);
    }

    #[test]
    fn test_all_eras_have_modules() {
        let engine = ContentEngine::new();

        // First Steps: 5 modules
        let first_steps_modules = ["introduction", "syllogistic", "definitions", "fallacies", "inductive"];
        for module in first_steps_modules {
            assert!(engine.get_module("first-steps", module).is_some(), "first-steps/{} should exist", module);
        }

        // Building Blocks: 2 modules
        let building_blocks_modules = ["propositional", "proofs"];
        for module in building_blocks_modules {
            assert!(engine.get_module("building-blocks", module).is_some(), "building-blocks/{} should exist", module);
        }

        // Expanding Horizons: 6 modules
        let expanding_modules = ["quantificational", "relations", "modal", "further_modal", "deontic", "belief"];
        for module in expanding_modules {
            assert!(engine.get_module("expanding-horizons", module).is_some(), "expanding-horizons/{} should exist", module);
        }

        // Mastery: 5 modules
        let mastery_modules = ["ethics", "metalogic", "history", "deviant", "philosophy"];
        for module in mastery_modules {
            assert!(engine.get_module("mastery", module).is_some(), "mastery/{} should exist", module);
        }
    }
}

```

---

### Generator Engine

**File:** `src/generator.rs`

Template-based problem generation. Fills slots like {ProperName}, {Verb}, {Adjective} using runtime lexicon queries with constraint filtering. Applies morphological transforms for modifiers like :Plural and :Past.

```rust
use crate::content::{ExerciseConfig, ExerciseType};
use crate::runtime_lexicon::{LexiconIndex, pluralize, present_3s, past_tense, gerund};
use crate::compile;
use rand::Rng;
use rand::seq::SliceRandom;
use std::collections::HashMap;

pub struct Generator {
    lexicon: LexiconIndex,
}

#[derive(Debug, Clone)]
pub struct Challenge {
    pub exercise_id: String,
    pub prompt: String,
    pub sentence: String,
    pub answer: AnswerType,
    pub hint: Option<String>,
    pub explanation: Option<String>,
}

#[derive(Debug, Clone)]
pub enum AnswerType {
    FreeForm {
        golden_logic: String,
    },
    MultipleChoice {
        options: Vec<String>,
        correct_index: usize,
    },
    Ambiguity {
        readings: Vec<String>,
    },
}

impl Generator {
    pub fn new() -> Self {
        Self {
            lexicon: LexiconIndex::new(),
        }
    }

    pub fn generate(&self, exercise: &ExerciseConfig, rng: &mut impl Rng) -> Option<Challenge> {
        match exercise.exercise_type {
            ExerciseType::Translation => self.generate_translation(exercise, rng),
            ExerciseType::MultipleChoice => self.generate_multiple_choice(exercise, rng),
            ExerciseType::Ambiguity => self.generate_ambiguity(exercise, rng),
        }
    }

    fn generate_translation(&self, exercise: &ExerciseConfig, rng: &mut impl Rng) -> Option<Challenge> {
        let template = exercise.template.as_ref()?;
        let sentence = self.fill_template(template, &exercise.constraints, rng)?;

        let golden_logic = compile(&sentence).ok()?;

        Some(Challenge {
            exercise_id: exercise.id.clone(),
            prompt: exercise.prompt.clone(),
            sentence,
            answer: AnswerType::FreeForm { golden_logic },
            hint: exercise.hint.clone(),
            explanation: exercise.explanation.clone(),
        })
    }

    fn generate_multiple_choice(&self, exercise: &ExerciseConfig, rng: &mut impl Rng) -> Option<Challenge> {
        let options = exercise.options.clone()?;
        let correct_index = exercise.correct?;

        let sentence = if let Some(template) = &exercise.template {
            self.fill_template(template, &exercise.constraints, rng)?
        } else {
            exercise.prompt.clone()
        };

        Some(Challenge {
            exercise_id: exercise.id.clone(),
            prompt: exercise.prompt.clone(),
            sentence,
            answer: AnswerType::MultipleChoice { options, correct_index },
            hint: exercise.hint.clone(),
            explanation: exercise.explanation.clone(),
        })
    }

    fn generate_ambiguity(&self, exercise: &ExerciseConfig, rng: &mut impl Rng) -> Option<Challenge> {
        let template = exercise.template.as_ref()?;
        let sentence = self.fill_template(template, &exercise.constraints, rng)?;

        let readings = crate::compile_all_scopes(&sentence).ok()?;

        Some(Challenge {
            exercise_id: exercise.id.clone(),
            prompt: exercise.prompt.clone(),
            sentence,
            answer: AnswerType::Ambiguity { readings },
            hint: exercise.hint.clone(),
            explanation: exercise.explanation.clone(),
        })
    }

    fn fill_template(&self, template: &str, constraints: &HashMap<String, Vec<String>>, rng: &mut impl Rng) -> Option<String> {
        let mut result = template.to_string();
        let mut used_names: HashMap<String, String> = HashMap::new();

        while let Some(start) = result.find('{') {
            let end = result[start..].find('}')? + start;
            let slot = &result[start + 1..end];

            let (slot_type, modifier) = if let Some(colon_pos) = slot.find(':') {
                (&slot[..colon_pos], Some(&slot[colon_pos + 1..]))
            } else {
                (slot, None)
            };

            let slot_constraints = constraints.get(slot_type).map(|v| v.as_slice()).unwrap_or(&[]);
            let word = self.fill_slot(slot_type, slot_constraints, modifier, &mut used_names, rng)?;

            result = format!("{}{}{}", &result[..start], word, &result[end + 1..]);
        }

        Some(result)
    }

    fn fill_slot(
        &self,
        slot_type: &str,
        constraints: &[String],
        modifier: Option<&str>,
        used_names: &mut HashMap<String, String>,
        rng: &mut impl Rng,
    ) -> Option<String> {
        match slot_type {
            "ProperName" => {
                let key = format!("ProperName_{}", used_names.len());
                if let Some(existing) = used_names.get(&key) {
                    return Some(existing.clone());
                }

                let proper_nouns = self.lexicon.proper_nouns();
                let available: Vec<_> = proper_nouns
                    .iter()
                    .filter(|n| !used_names.values().any(|v| v == &n.lemma))
                    .copied()
                    .collect();

                let entry = if !available.is_empty() {
                    available.choose(rng)?
                } else {
                    proper_nouns.choose(rng)?
                };
                let name = entry.lemma.clone();
                used_names.insert(key, name.clone());
                Some(name)
            }
            "Noun" => {
                let nouns = if constraints.is_empty() {
                    self.lexicon.common_nouns()
                } else {
                    let mut filtered = Vec::new();
                    for constraint in constraints {
                        filtered.extend(self.lexicon.nouns_with_feature(constraint));
                    }
                    filtered
                };

                let entry = nouns.choose(rng)?;
                let word = entry.lemma.to_lowercase();

                match modifier {
                    Some("Plural") => Some(pluralize(entry)),
                    _ => Some(word),
                }
            }
            "Verb" => {
                let verbs = if constraints.contains(&"Intransitive".to_string()) {
                    self.lexicon.intransitive_verbs()
                } else if constraints.contains(&"Transitive".to_string()) {
                    self.lexicon.transitive_verbs()
                } else {
                    let mut result = Vec::new();
                    for constraint in constraints {
                        result.extend(self.lexicon.verbs_with_feature(constraint));
                    }
                    if result.is_empty() {
                        self.lexicon.intransitive_verbs()
                    } else {
                        result
                    }
                };

                let entry = verbs.choose(rng)?;

                match modifier {
                    Some("Past") => Some(past_tense(entry)),
                    Some("Gerund") => Some(gerund(entry)),
                    Some("Present3s") => Some(present_3s(entry)),
                    _ => Some(entry.lemma.to_lowercase()),
                }
            }
            "Adjective" => {
                let adjectives = if constraints.contains(&"Intersective".to_string()) {
                    self.lexicon.intersective_adjectives()
                } else if constraints.is_empty() {
                    self.lexicon.intersective_adjectives()
                } else {
                    let mut result = Vec::new();
                    for constraint in constraints {
                        result.extend(self.lexicon.adjectives_with_feature(constraint));
                    }
                    result
                };

                let entry = adjectives.choose(rng)?;
                Some(entry.lemma.to_lowercase())
            }
            _ => Some("thing".to_string()),
        }
    }
}

impl Default for Generator {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::content::ContentEngine;
    use rand::SeedableRng;
    use rand::rngs::StdRng;

    #[test]
    fn test_generate_translation_challenge() {
        let engine = ContentEngine::new();
        let generator = Generator::new();
        let mut rng = StdRng::seed_from_u64(42);

        // Use introduction module which has Translation exercises
        let exercise = engine.get_exercise("first-steps", "introduction", "I_1.1");
        assert!(exercise.is_some(), "Exercise first-steps/introduction/I_1.1 should exist");
        let exercise = exercise.unwrap();
        let challenge = generator.generate(exercise, &mut rng);

        assert!(challenge.is_some(), "Should generate a challenge");
        let challenge = challenge.unwrap();
        assert!(!challenge.sentence.is_empty(), "Sentence should not be empty");

        if let AnswerType::FreeForm { golden_logic } = &challenge.answer {
            assert!(!golden_logic.is_empty(), "Golden logic should not be empty");
        } else {
            panic!("Expected FreeForm answer type");
        }
    }

    #[test]
    fn test_generate_multiple_choice() {
        let engine = ContentEngine::new();
        let generator = Generator::new();
        let mut rng = StdRng::seed_from_u64(42);

        // Use syllogistic module which has MultipleChoice exercises
        let exercise = engine.get_exercise("first-steps", "syllogistic", "A_1.1");
        assert!(exercise.is_some(), "Exercise first-steps/syllogistic/A_1.1 should exist");
        let exercise = exercise.unwrap();
        let challenge = generator.generate(exercise, &mut rng);

        assert!(challenge.is_some(), "Should generate a challenge");
        let challenge = challenge.unwrap();

        if let AnswerType::MultipleChoice { options, correct_index } = &challenge.answer {
            assert_eq!(options.len(), 4, "Should have 4 options");
            assert!(*correct_index < options.len(), "Correct index should be within options range");
        } else {
            panic!("Expected MultipleChoice answer type");
        }
    }

    #[test]
    fn test_fill_template_proper_names() {
        let generator = Generator::new();
        let mut rng = StdRng::seed_from_u64(42);

        let constraints = HashMap::new();
        let result = generator.fill_template("{ProperName} runs.", &constraints, &mut rng);

        assert!(result.is_some());
        let sentence = result.unwrap();
        assert!(sentence.ends_with(" runs."), "Template should be filled: {}", sentence);
        assert!(!sentence.starts_with("{"), "Slot should be replaced");
    }

    #[test]
    fn test_fill_template_with_modifier() {
        let generator = Generator::new();
        let mut rng = StdRng::seed_from_u64(42);

        let constraints = HashMap::new();
        let result = generator.fill_template("All {Noun:Plural} run.", &constraints, &mut rng);

        assert!(result.is_some());
        let sentence = result.unwrap();
        assert!(!sentence.contains("{"), "All slots should be filled: {}", sentence);
    }

    #[test]
    fn test_deterministic_with_seed() {
        let generator = Generator::new();
        let mut rng1 = StdRng::seed_from_u64(12345);
        let mut rng2 = StdRng::seed_from_u64(12345);

        let constraints = HashMap::new();
        let result1 = generator.fill_template("{ProperName} is {Adjective}.", &constraints, &mut rng1);
        let result2 = generator.fill_template("{ProperName} is {Adjective}.", &constraints, &mut rng2);

        assert_eq!(result1, result2, "Same seed should produce same output");
    }

    #[test]
    fn test_all_introduction_exercises() {
        let engine = ContentEngine::new();
        let generator = Generator::new();

        let module = engine.get_module("first-steps", "introduction");
        assert!(module.is_some(), "Introduction module should exist");
        let module = module.unwrap();

        println!("Introduction module has {} exercises", module.exercises.len());

        for (i, exercise) in module.exercises.iter().enumerate() {
            let mut rng = StdRng::seed_from_u64(42 + i as u64);
            println!("Exercise {}: id={}, type={:?}", i, exercise.id, exercise.exercise_type);

            let challenge = generator.generate(exercise, &mut rng);
            if challenge.is_none() {
                println!("  FAILED to generate challenge!");
                if let Some(template) = &exercise.template {
                    println!("  Template: {}", template);
                    let filled = generator.fill_template(template, &exercise.constraints, &mut StdRng::seed_from_u64(42));
                    println!("  Filled template: {:?}", filled);
                    if let Some(sentence) = filled {
                        let compiled = crate::compile(&sentence);
                        println!("  Compile result: {:?}", compiled);
                    }
                }
            } else {
                println!("  OK: {:?}", challenge.as_ref().map(|c| &c.sentence));
            }
            assert!(challenge.is_some(), "Exercise {} ({}) should generate a challenge", i, exercise.id);
        }
    }

    #[test]
    fn test_all_exercises_across_all_modules() {
        let engine = ContentEngine::new();
        let generator = Generator::new();

        let mut total_exercises = 0;
        let mut successful = 0;
        let mut failed_exercises = Vec::new();

        for era in engine.eras() {
            for module in &era.modules {
                if let Some(m) = engine.get_module(&era.meta.id, &module.meta.id) {
                    for (i, exercise) in m.exercises.iter().enumerate() {
                        total_exercises += 1;
                        let mut rng = StdRng::seed_from_u64(42 + i as u64);

                        let challenge = generator.generate(exercise, &mut rng);
                        if challenge.is_some() {
                            successful += 1;
                        } else {
                            failed_exercises.push(format!("{}/{}/{}", era.meta.id, module.meta.id, exercise.id));
                        }
                    }
                }
            }
        }

        println!("Total exercises: {}", total_exercises);
        println!("Successful: {}", successful);
        println!("Failed: {}", failed_exercises.len());

        if !failed_exercises.is_empty() {
            println!("\nFailed exercises:");
            for ex in &failed_exercises {
                println!("  - {}", ex);
            }
        }

        // Allow some failures for now, but ensure most work
        let success_rate = successful as f64 / total_exercises as f64;
        assert!(success_rate >= 0.8, "At least 80% of exercises should generate (got {:.1}%)", success_rate * 100.0);
    }
}

```

---

### Answer Grader

**File:** `src/grader.rs`

Semantic equivalence checking for FOL answers. Normalizes Unicode, handles commutativity of ∧/∨, and provides partial credit scoring. Uses structural AST comparison after normalization.

```rust

#[derive(Debug, Clone)]
pub struct GradeResult {
    pub correct: bool,
    pub partial: bool,
    pub score: u32,
    pub feedback: String,
}

impl GradeResult {
    pub fn correct() -> Self {
        Self {
            correct: true,
            partial: false,
            score: 100,
            feedback: "Correct!".to_string(),
        }
    }

    pub fn partial(feedback: String, score: u32) -> Self {
        Self {
            correct: false,
            partial: true,
            score,
            feedback,
        }
    }

    pub fn incorrect(feedback: String) -> Self {
        Self {
            correct: false,
            partial: false,
            score: 0,
            feedback,
        }
    }
}

pub fn check_answer(user_input: &str, expected: &str) -> GradeResult {
    let user_normalized = normalize_logic(user_input);
    let expected_normalized = normalize_logic(expected);

    if user_normalized == expected_normalized {
        return GradeResult::correct();
    }

    let user_parsed = parse_to_normalized_ast(user_input);
    let expected_parsed = parse_to_normalized_ast(expected);

    match (user_parsed, expected_parsed) {
        (Some(user_ast), Some(expected_ast)) => {
            if structural_eq(&user_ast, &expected_ast) {
                return GradeResult::correct();
            }

            let similarity = structural_similarity(&user_ast, &expected_ast);
            if similarity > 0.7 {
                GradeResult::partial(
                    "Close! Check your quantifier or connective structure.".to_string(),
                    (similarity * 50.0) as u32,
                )
            } else if similarity > 0.4 {
                GradeResult::partial(
                    "Partially correct. Review the logical structure.".to_string(),
                    (similarity * 30.0) as u32,
                )
            } else {
                GradeResult::incorrect(
                    "Not quite. Consider the relationship between subject and predicate.".to_string(),
                )
            }
        }
        (None, _) => GradeResult::incorrect(
            "Could not parse your answer. Check syntax.".to_string(),
        ),
        (_, None) => GradeResult::incorrect(
            "Internal error: could not parse expected answer.".to_string(),
        ),
    }
}

fn normalize_logic(input: &str) -> String {
    let mut result = input.to_string();

    result = result.replace("\\forall", "∀");
    result = result.replace("\\exists", "∃");
    result = result.replace("\\neg", "¬");
    result = result.replace("\\land", "∧");
    result = result.replace("\\lor", "∨");
    result = result.replace("\\supset", "→");
    result = result.replace("\\equiv", "↔");
    result = result.replace("\\Box", "□");
    result = result.replace("\\Diamond", "◇");

    // Order matters: replace <-> before ->
    result = result.replace("<->", "↔");
    result = result.replace("->", "→");
    result = result.replace("&", "∧");
    result = result.replace("|", "∨");
    result = result.replace("~", "¬");
    result = result.replace("!", "¬");

    result = result.chars().filter(|c| !c.is_whitespace()).collect();

    result
}

#[derive(Debug, Clone)]
struct NormalizedExpr {
    kind: NormalizedKind,
}

#[derive(Debug, Clone)]
enum NormalizedKind {
    Predicate { name: String, arity: usize },
    Quantifier { kind: String, body: Box<NormalizedExpr> },
    Binary { op: String, left: Box<NormalizedExpr>, right: Box<NormalizedExpr> },
    Unary { op: String, operand: Box<NormalizedExpr> },
    Atom(String),
}

fn parse_to_normalized_ast(input: &str) -> Option<NormalizedExpr> {
    let normalized = normalize_logic(input);

    if normalized.starts_with('∀') || normalized.starts_with('∃') {
        let quantifier = if normalized.starts_with('∀') { "∀" } else { "∃" };
        let rest = &normalized[quantifier.len()..];

        if let Some(paren_start) = rest.find('(') {
            let body = &rest[paren_start..];
            if let Some(inner) = extract_balanced(body) {
                return Some(NormalizedExpr {
                    kind: NormalizedKind::Quantifier {
                        kind: quantifier.to_string(),
                        body: Box::new(parse_to_normalized_ast(&inner)?),
                    },
                });
            }
        }
    }

    if let Some(impl_pos) = find_main_connective(&normalized, "→") {
        let left = &normalized[..impl_pos];
        let right = &normalized[impl_pos + "→".len()..];
        return Some(NormalizedExpr {
            kind: NormalizedKind::Binary {
                op: "→".to_string(),
                left: Box::new(parse_to_normalized_ast(left)?),
                right: Box::new(parse_to_normalized_ast(right)?),
            },
        });
    }

    if let Some(and_pos) = find_main_connective(&normalized, "∧") {
        let left = &normalized[..and_pos];
        let right = &normalized[and_pos + "∧".len()..];
        return Some(NormalizedExpr {
            kind: NormalizedKind::Binary {
                op: "∧".to_string(),
                left: Box::new(parse_to_normalized_ast(left)?),
                right: Box::new(parse_to_normalized_ast(right)?),
            },
        });
    }

    if normalized.starts_with('¬') {
        let operand = &normalized["¬".len()..];
        return Some(NormalizedExpr {
            kind: NormalizedKind::Unary {
                op: "¬".to_string(),
                operand: Box::new(parse_to_normalized_ast(operand)?),
            },
        });
    }

    if let Some(paren_pos) = normalized.find('(') {
        let name = &normalized[..paren_pos];
        let args = &normalized[paren_pos..];
        let arity = args.matches(',').count() + 1;
        return Some(NormalizedExpr {
            kind: NormalizedKind::Predicate {
                name: name.to_string(),
                arity,
            },
        });
    }

    Some(NormalizedExpr {
        kind: NormalizedKind::Atom(normalized),
    })
}

fn extract_balanced(s: &str) -> Option<String> {
    if !s.starts_with('(') {
        return None;
    }

    let mut depth = 0;
    let mut end = 0;

    for (i, c) in s.chars().enumerate() {
        match c {
            '(' => depth += 1,
            ')' => {
                depth -= 1;
                if depth == 0 {
                    end = i;
                    break;
                }
            }
            _ => {}
        }
    }

    if depth == 0 && end > 0 {
        Some(s[1..end].to_string())
    } else {
        None
    }
}

fn find_main_connective(s: &str, connective: &str) -> Option<usize> {
    let mut depth = 0;
    let mut byte_idx = 0;

    for c in s.chars() {
        match c {
            '(' => depth += 1,
            ')' => depth -= 1,
            _ if depth == 0 && s[byte_idx..].starts_with(connective) => {
                return Some(byte_idx);
            }
            _ => {}
        }
        byte_idx += c.len_utf8();
    }

    None
}

fn structural_eq(a: &NormalizedExpr, b: &NormalizedExpr) -> bool {
    match (&a.kind, &b.kind) {
        (NormalizedKind::Predicate { name: n1, arity: a1 }, NormalizedKind::Predicate { name: n2, arity: a2 }) => {
            n1 == n2 && a1 == a2
        }
        (NormalizedKind::Quantifier { kind: k1, body: b1 }, NormalizedKind::Quantifier { kind: k2, body: b2 }) => {
            k1 == k2 && structural_eq(b1, b2)
        }
        (NormalizedKind::Binary { op: o1, left: l1, right: r1 }, NormalizedKind::Binary { op: o2, left: l2, right: r2 }) => {
            if o1 != o2 {
                return false;
            }
            if structural_eq(l1, l2) && structural_eq(r1, r2) {
                return true;
            }
            if o1 == "∧" || o1 == "∨" {
                structural_eq(l1, r2) && structural_eq(r1, l2)
            } else {
                false
            }
        }
        (NormalizedKind::Unary { op: o1, operand: op1 }, NormalizedKind::Unary { op: o2, operand: op2 }) => {
            o1 == o2 && structural_eq(op1, op2)
        }
        (NormalizedKind::Atom(a1), NormalizedKind::Atom(a2)) => a1 == a2,
        _ => false,
    }
}

fn structural_similarity(a: &NormalizedExpr, b: &NormalizedExpr) -> f64 {
    match (&a.kind, &b.kind) {
        (NormalizedKind::Predicate { name: n1, arity: a1 }, NormalizedKind::Predicate { name: n2, arity: a2 }) => {
            let name_match = if n1 == n2 { 0.7 } else { 0.0 };
            let arity_match = if a1 == a2 { 0.3 } else { 0.0 };
            name_match + arity_match
        }
        (NormalizedKind::Quantifier { kind: k1, body: b1 }, NormalizedKind::Quantifier { kind: k2, body: b2 }) => {
            let kind_match = if k1 == k2 { 0.4 } else { 0.0 };
            let body_sim = structural_similarity(b1, b2);
            kind_match + body_sim * 0.6
        }
        (NormalizedKind::Binary { op: o1, left: l1, right: r1 }, NormalizedKind::Binary { op: o2, left: l2, right: r2 }) => {
            let op_match = if o1 == o2 { 0.3 } else { 0.0 };
            let left_sim = structural_similarity(l1, l2);
            let right_sim = structural_similarity(r1, r2);
            op_match + (left_sim + right_sim) * 0.35
        }
        (NormalizedKind::Unary { op: o1, operand: op1 }, NormalizedKind::Unary { op: o2, operand: op2 }) => {
            let op_match = if o1 == o2 { 0.3 } else { 0.0 };
            op_match + structural_similarity(op1, op2) * 0.7
        }
        (NormalizedKind::Atom(a1), NormalizedKind::Atom(a2)) => {
            if a1 == a2 { 1.0 } else { 0.0 }
        }
        _ => 0.0,
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_exact_match() {
        let result = check_answer("∀x(D(x) → B(x))", "∀x(D(x) → B(x))");
        assert!(result.correct, "Exact match should be correct");
    }

    #[test]
    fn test_whitespace_normalization() {
        let result = check_answer("∀x( D(x) → B(x) )", "∀x(D(x)→B(x))");
        assert!(result.correct, "Whitespace should be normalized");
    }

    #[test]
    fn test_latex_to_unicode() {
        let result = check_answer("\\forall x(D(x) \\supset B(x))", "∀x(D(x) → B(x))");
        assert!(result.correct, "LaTeX should normalize to Unicode");
    }

    #[test]
    fn test_ascii_shortcuts() {
        let result = check_answer("D(x) & B(x)", "D(x) ∧ B(x)");
        assert!(result.correct, "ASCII & should match ∧");
    }

    #[test]
    fn test_commutative_conjunction() {
        let result = check_answer("∃x(B(x) ∧ D(x))", "∃x(D(x) ∧ B(x))");
        assert!(result.correct, "Conjunction should be commutative");
    }

    #[test]
    fn test_wrong_quantifier() {
        let result = check_answer("∃x(D(x) → B(x))", "∀x(D(x) → B(x))");
        assert!(!result.correct, "Wrong quantifier should not match");
        assert!(result.partial, "Should get partial credit");
    }

    #[test]
    fn test_wrong_connective() {
        let result = check_answer("∀x(D(x) ∧ B(x))", "∀x(D(x) → B(x))");
        assert!(!result.correct, "Wrong connective should not match");
        assert!(result.partial, "Should get partial credit for structure");
    }

    #[test]
    fn test_completely_wrong() {
        let result = check_answer("P(a)", "∀x(D(x) → B(x))");
        assert!(!result.correct);
        assert!(!result.partial);
    }

    #[test]
    fn test_normalize_arrow() {
        let normalized = normalize_logic("A -> B");
        assert_eq!(normalized, "A→B");
    }

    #[test]
    fn test_normalize_biconditional() {
        let normalized = normalize_logic("A <-> B");
        assert_eq!(normalized, "A↔B");
    }
}

```

---

### Runtime Lexicon

**File:** `src/runtime_lexicon.rs`

Runtime access to lexicon data for the generator. Provides query APIs: nouns_with_feature(), verbs_with_feature(), nouns_with_sort(), proper_nouns(), common_nouns(). Loads from embedded lexicon.json.

```rust
use rand::seq::SliceRandom;
use serde::Deserialize;
use std::collections::HashMap;

const LEXICON_JSON: &str = include_str!("../assets/lexicon.json");

#[derive(Deserialize, Debug)]
pub struct LexiconData {
    pub nouns: Vec<NounEntry>,
    pub verbs: Vec<VerbEntry>,
    pub adjectives: Vec<AdjectiveEntry>,
}

#[derive(Deserialize, Debug, Clone)]
pub struct NounEntry {
    pub lemma: String,
    #[serde(default)]
    pub forms: HashMap<String, String>,
    #[serde(default)]
    pub features: Vec<String>,
    #[serde(default)]
    pub sort: Option<String>,
}

#[derive(Deserialize, Debug, Clone)]
pub struct VerbEntry {
    pub lemma: String,
    pub class: String,
    #[serde(default)]
    pub forms: HashMap<String, String>,
    #[serde(default)]
    pub features: Vec<String>,
}

#[derive(Deserialize, Debug, Clone)]
pub struct AdjectiveEntry {
    pub lemma: String,
    #[serde(default)]
    pub regular: bool,
    #[serde(default)]
    pub features: Vec<String>,
}

pub struct LexiconIndex {
    data: LexiconData,
}

impl LexiconIndex {
    pub fn new() -> Self {
        let data: LexiconData = serde_json::from_str(LEXICON_JSON)
            .expect("Failed to parse lexicon.json");
        Self { data }
    }

    pub fn proper_nouns(&self) -> Vec<&NounEntry> {
        self.data.nouns.iter()
            .filter(|n| n.features.iter().any(|f| f == "Proper"))
            .collect()
    }

    pub fn common_nouns(&self) -> Vec<&NounEntry> {
        self.data.nouns.iter()
            .filter(|n| !n.features.iter().any(|f| f == "Proper"))
            .collect()
    }

    pub fn nouns_with_feature(&self, feature: &str) -> Vec<&NounEntry> {
        self.data.nouns.iter()
            .filter(|n| n.features.iter().any(|f| f.eq_ignore_ascii_case(feature)))
            .collect()
    }

    pub fn nouns_with_sort(&self, sort: &str) -> Vec<&NounEntry> {
        self.data.nouns.iter()
            .filter(|n| n.sort.as_ref().map(|s| s.eq_ignore_ascii_case(sort)).unwrap_or(false))
            .collect()
    }

    pub fn verbs_with_feature(&self, feature: &str) -> Vec<&VerbEntry> {
        self.data.verbs.iter()
            .filter(|v| v.features.iter().any(|f| f.eq_ignore_ascii_case(feature)))
            .collect()
    }

    pub fn verbs_with_class(&self, class: &str) -> Vec<&VerbEntry> {
        self.data.verbs.iter()
            .filter(|v| v.class.eq_ignore_ascii_case(class))
            .collect()
    }

    pub fn intransitive_verbs(&self) -> Vec<&VerbEntry> {
        self.data.verbs.iter()
            .filter(|v| {
                !v.features.iter().any(|f|
                    f.eq_ignore_ascii_case("Transitive") ||
                    f.eq_ignore_ascii_case("Ditransitive")
                )
            })
            .collect()
    }

    pub fn transitive_verbs(&self) -> Vec<&VerbEntry> {
        self.data.verbs.iter()
            .filter(|v| {
                v.features.iter().any(|f| f.eq_ignore_ascii_case("Transitive")) ||
                v.features.iter().any(|f| f.eq_ignore_ascii_case("Ditransitive"))
            })
            .collect()
    }

    pub fn adjectives_with_feature(&self, feature: &str) -> Vec<&AdjectiveEntry> {
        self.data.adjectives.iter()
            .filter(|a| a.features.iter().any(|f| f.eq_ignore_ascii_case(feature)))
            .collect()
    }

    pub fn intersective_adjectives(&self) -> Vec<&AdjectiveEntry> {
        self.adjectives_with_feature("Intersective")
    }

    pub fn random_proper_noun(&self, rng: &mut impl rand::Rng) -> Option<&NounEntry> {
        self.proper_nouns().choose(rng).copied()
    }

    pub fn random_common_noun(&self, rng: &mut impl rand::Rng) -> Option<&NounEntry> {
        self.common_nouns().choose(rng).copied()
    }

    pub fn random_verb(&self, rng: &mut impl rand::Rng) -> Option<&VerbEntry> {
        self.data.verbs.choose(rng)
    }

    pub fn random_intransitive_verb(&self, rng: &mut impl rand::Rng) -> Option<&VerbEntry> {
        self.intransitive_verbs().choose(rng).copied()
    }

    pub fn random_transitive_verb(&self, rng: &mut impl rand::Rng) -> Option<&VerbEntry> {
        self.transitive_verbs().choose(rng).copied()
    }

    pub fn random_adjective(&self, rng: &mut impl rand::Rng) -> Option<&AdjectiveEntry> {
        self.data.adjectives.choose(rng)
    }

    pub fn random_intersective_adjective(&self, rng: &mut impl rand::Rng) -> Option<&AdjectiveEntry> {
        self.intersective_adjectives().choose(rng).copied()
    }
}

pub fn pluralize(noun: &NounEntry) -> String {
    if let Some(plural) = noun.forms.get("plural") {
        plural.clone()
    } else {
        let lemma = noun.lemma.to_lowercase();
        if lemma.ends_with('s') || lemma.ends_with('x') ||
           lemma.ends_with("ch") || lemma.ends_with("sh") {
            format!("{}es", lemma)
        } else if lemma.ends_with('y') && !lemma.ends_with("ay") &&
                  !lemma.ends_with("ey") && !lemma.ends_with("oy") && !lemma.ends_with("uy") {
            format!("{}ies", &lemma[..lemma.len()-1])
        } else {
            format!("{}s", lemma)
        }
    }
}

pub fn present_3s(verb: &VerbEntry) -> String {
    if let Some(form) = verb.forms.get("present3s") {
        form.clone()
    } else {
        let lemma = verb.lemma.to_lowercase();
        if lemma.ends_with('s') || lemma.ends_with('x') ||
           lemma.ends_with("ch") || lemma.ends_with("sh") || lemma.ends_with('o') {
            format!("{}es", lemma)
        } else if lemma.ends_with('y') && !lemma.ends_with("ay") &&
                  !lemma.ends_with("ey") && !lemma.ends_with("oy") && !lemma.ends_with("uy") {
            format!("{}ies", &lemma[..lemma.len()-1])
        } else {
            format!("{}s", lemma)
        }
    }
}

pub fn past_tense(verb: &VerbEntry) -> String {
    if let Some(form) = verb.forms.get("past") {
        form.clone()
    } else {
        let lemma = verb.lemma.to_lowercase();
        if lemma.ends_with('e') {
            format!("{}d", lemma)
        } else if lemma.ends_with('y') && !lemma.ends_with("ay") &&
                  !lemma.ends_with("ey") && !lemma.ends_with("oy") && !lemma.ends_with("uy") {
            format!("{}ied", &lemma[..lemma.len()-1])
        } else {
            format!("{}ed", lemma)
        }
    }
}

pub fn gerund(verb: &VerbEntry) -> String {
    if let Some(form) = verb.forms.get("gerund") {
        form.clone()
    } else {
        let lemma = verb.lemma.to_lowercase();
        if lemma.ends_with('e') && !lemma.ends_with("ee") {
            format!("{}ing", &lemma[..lemma.len()-1])
        } else {
            format!("{}ing", lemma)
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_lexicon_loads() {
        let index = LexiconIndex::new();
        assert!(!index.proper_nouns().is_empty());
        assert!(!index.common_nouns().is_empty());
        assert!(!index.intersective_adjectives().is_empty());
    }

    #[test]
    fn test_proper_nouns() {
        let index = LexiconIndex::new();
        let proper = index.proper_nouns();
        assert!(proper.iter().any(|n| n.lemma == "John"));
        assert!(proper.iter().any(|n| n.lemma == "Mary"));
    }

    #[test]
    fn test_intersective_adjectives() {
        let index = LexiconIndex::new();
        let adj = index.intersective_adjectives();
        assert!(adj.iter().any(|a| a.lemma == "Happy"));
        assert!(adj.iter().any(|a| a.lemma == "Red"));
    }

    #[test]
    fn test_pluralize() {
        let noun = NounEntry {
            lemma: "Dog".to_string(),
            forms: HashMap::new(),
            features: vec![],
            sort: None,
        };
        assert_eq!(pluralize(&noun), "dogs");

        let noun_irregular = NounEntry {
            lemma: "Man".to_string(),
            forms: [("plural".to_string(), "men".to_string())].into(),
            features: vec![],
            sort: None,
        };
        assert_eq!(pluralize(&noun_irregular), "men");
    }

    #[test]
    fn test_present_3s() {
        let verb = VerbEntry {
            lemma: "Run".to_string(),
            class: "Activity".to_string(),
            forms: HashMap::new(),
            features: vec![],
        };
        assert_eq!(present_3s(&verb), "runs");
    }
}

```

---

## Logos Core Runtime

Embedded runtime library for compiled LOGOS programs. Provides type aliases and IO functions per the Spec.

**Location:** `logos_core/src/`

### Runtime Library

**File:** `logos_core/src/lib.rs`

Entry point for logos_core crate. Conditional compilation: network, storage, memory, file, time, random, env gated with #[cfg(not(wasm32))] for native-only. CRDT and fs modules work cross-platform.

```rust
//! LOGOS Runtime Library

pub mod io;
pub mod types;
// Phase 53: Virtual File System (cross-platform)
pub mod fs;
// Phase 49: CRDT primitives (cross-platform)
pub mod crdt;
// Phase 55: Persistent storage (cross-platform, uses async-lock)
pub mod storage;
// Phase 56: Distributed<T> - unified persistence + network (cross-platform)
pub mod distributed;
// Phase 57: Polymorphic indexing (Vec + HashMap)
pub mod indexing;

// Native-only modules
#[cfg(not(target_arch = "wasm32"))]
pub mod file;
#[cfg(not(target_arch = "wasm32"))]
pub mod time;
#[cfg(not(target_arch = "wasm32"))]
pub mod random;
#[cfg(not(target_arch = "wasm32"))]
pub mod env;
#[cfg(not(target_arch = "wasm32"))]
pub mod memory;
#[cfg(not(target_arch = "wasm32"))]
pub mod network;
// Phase 54: Go-like concurrency primitives (native only)
#[cfg(not(target_arch = "wasm32"))]
pub mod concurrency;

// Phase 51: Re-export tokio for async main support (native only)
#[cfg(not(target_arch = "wasm32"))]
pub use tokio;

pub fn panic_with(reason: &str) -> ! {
    panic!("{}", reason);
}

pub mod fmt {
    pub fn format<T: std::fmt::Display>(x: T) -> String {
        format!("{}", x)
    }
}

pub mod prelude {
    pub use crate::io::{show, read_line, println, eprintln, print, Showable};
    pub use crate::types::{Nat, Int, Real, Text, Bool, Unit, Char, Byte, Seq, Map, Set, LogosContains, Value, Tuple};
    pub use crate::panic_with;
    pub use crate::fmt::format;
    // Phase 57: Polymorphic indexing traits
    pub use crate::indexing::{LogosIndex, LogosIndexMut};
    // Phase 49: CRDT primitives
    pub use crate::crdt::{GCounter, LWWRegister, Merge};
    // Phase 56: Distributed<T>
    pub use crate::distributed::Distributed;

    // Native-only prelude exports
    #[cfg(not(target_arch = "wasm32"))]
    pub use crate::file::{read, write};
    #[cfg(not(target_arch = "wasm32"))]
    pub use crate::time::{now, sleep};
    #[cfg(not(target_arch = "wasm32"))]
    pub use crate::random::{randomInt, randomFloat};
    #[cfg(not(target_arch = "wasm32"))]
    pub use crate::env::{get, args};
    #[cfg(not(target_arch = "wasm32"))]
    pub use crate::memory::Zone;
    #[cfg(not(target_arch = "wasm32"))]
    pub use crate::network::{FileSipper, FileManifest, FileChunk};
    // Phase 54: Go-like concurrency primitives
    #[cfg(not(target_arch = "wasm32"))]
    pub use crate::concurrency::{
        spawn, TaskHandle,
        Pipe, PipeSender, PipeReceiver,
        check_preemption, reset_preemption_timer,
    };
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_format() {
        assert_eq!(fmt::format(42), "42");
        assert_eq!(fmt::format("hello"), "hello");
    }

    #[test]
    fn test_type_aliases() {
        let _n: types::Nat = 42;
        let _i: types::Int = -42;
        let _r: types::Real = 3.14;
        let _t: types::Text = String::from("hello");
        let _b: types::Bool = true;
        let _u: types::Unit = ();
    }
}

```

---

### Type Aliases & Collections

**File:** `logos_core/src/types.rs`

Type aliases per Spec §10.6.1: Nat→u64, Int→i64, Real→f64, Text→String, Bool→bool, Unit→(), Char→char, Byte→u8. Collections: Seq<T>→Vec<T>, Map<K,V>→HashMap, Set<T>→HashSet. Value enum for heterogeneous tuples with Showable impl and arithmetic operators. LogosContains trait for polymorphic contains.

```rust
//! Core Type Definitions (Spec 3.2)

use std::hash::Hash;

pub type Nat = u64;
pub type Int = i64;
pub type Real = f64;
pub type Text = String;
pub type Bool = bool;
pub type Unit = ();
pub type Char = char;
pub type Byte = u8;

// Phase 30: Collections
pub type Seq<T> = Vec<T>;

// Phase 57: Map type alias
pub type Map<K, V> = std::collections::HashMap<K, V>;

// Set collection type
pub type Set<T> = std::collections::HashSet<T>;

/// Unified contains trait for all collection types
pub trait LogosContains<T> {
    fn logos_contains(&self, value: &T) -> bool;
}

impl<T: PartialEq> LogosContains<T> for Vec<T> {
    fn logos_contains(&self, value: &T) -> bool {
        self.contains(value)
    }
}

impl<T: Eq + Hash> LogosContains<T> for std::collections::HashSet<T> {
    fn logos_contains(&self, value: &T) -> bool {
        self.contains(value)
    }
}

impl<K: Eq + Hash, V> LogosContains<K> for std::collections::HashMap<K, V> {
    fn logos_contains(&self, key: &K) -> bool {
        self.contains_key(key)
    }
}

impl LogosContains<&str> for String {
    fn logos_contains(&self, value: &&str) -> bool {
        self.contains(*value)
    }
}

impl LogosContains<char> for String {
    fn logos_contains(&self, value: &char) -> bool {
        self.contains(*value)
    }
}

// Phase 49b: LogosContains for CRDT ORSet
impl<T: Eq + Hash + Clone, B: crate::crdt::SetBias> LogosContains<T>
    for crate::crdt::ORSet<T, B>
{
    fn logos_contains(&self, value: &T) -> bool {
        self.contains(value)
    }
}

/// Dynamic value type for heterogeneous collections (tuples)
#[derive(Clone, Debug, PartialEq)]
pub enum Value {
    Int(i64),
    Float(f64),
    Bool(bool),
    Text(String),
    Char(char),
    Nothing,
}

impl std::fmt::Display for Value {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            Value::Int(n) => write!(f, "{}", n),
            Value::Float(n) => write!(f, "{}", n),
            Value::Bool(b) => write!(f, "{}", b),
            Value::Text(s) => write!(f, "{}", s),
            Value::Char(c) => write!(f, "{}", c),
            Value::Nothing => write!(f, "nothing"),
        }
    }
}

// Conversion traits for Value
impl From<i64> for Value {
    fn from(n: i64) -> Self { Value::Int(n) }
}

impl From<f64> for Value {
    fn from(n: f64) -> Self { Value::Float(n) }
}

impl From<bool> for Value {
    fn from(b: bool) -> Self { Value::Bool(b) }
}

impl From<String> for Value {
    fn from(s: String) -> Self { Value::Text(s) }
}

impl From<&str> for Value {
    fn from(s: &str) -> Self { Value::Text(s.to_string()) }
}

impl From<char> for Value {
    fn from(c: char) -> Self { Value::Char(c) }
}

/// Tuple type: Vec of heterogeneous Values (uses LogosIndex from indexing module)
pub type Tuple = Vec<Value>;

// Implement Showable for Value
impl crate::io::Showable for Value {
    fn format_show(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
        match self {
            Value::Int(n) => write!(f, "{}", n),
            Value::Float(n) => write!(f, "{}", n),
            Value::Bool(b) => write!(f, "{}", b),
            Value::Text(s) => write!(f, "{}", s),
            Value::Char(c) => write!(f, "{}", c),
            Value::Nothing => write!(f, "nothing"),
        }
    }
}

// Arithmetic operations for Value
impl std::ops::Add for Value {
    type Output = Value;

    fn add(self, other: Value) -> Value {
        match (self, other) {
            (Value::Int(a), Value::Int(b)) => Value::Int(a + b),
            (Value::Float(a), Value::Float(b)) => Value::Float(a + b),
            (Value::Int(a), Value::Float(b)) => Value::Float(a as f64 + b),
            (Value::Float(a), Value::Int(b)) => Value::Float(a + b as f64),
            (Value::Text(a), Value::Text(b)) => Value::Text(format!("{}{}", a, b)),
            _ => panic!("Cannot add these value types"),
        }
    }
}

impl std::ops::Sub for Value {
    type Output = Value;

    fn sub(self, other: Value) -> Value {
        match (self, other) {
            (Value::Int(a), Value::Int(b)) => Value::Int(a - b),
            (Value::Float(a), Value::Float(b)) => Value::Float(a - b),
            (Value::Int(a), Value::Float(b)) => Value::Float(a as f64 - b),
            (Value::Float(a), Value::Int(b)) => Value::Float(a - b as f64),
            _ => panic!("Cannot subtract these value types"),
        }
    }
}

impl std::ops::Mul for Value {
    type Output = Value;

    fn mul(self, other: Value) -> Value {
        match (self, other) {
            (Value::Int(a), Value::Int(b)) => Value::Int(a * b),
            (Value::Float(a), Value::Float(b)) => Value::Float(a * b),
            (Value::Int(a), Value::Float(b)) => Value::Float(a as f64 * b),
            (Value::Float(a), Value::Int(b)) => Value::Float(a * b as f64),
            _ => panic!("Cannot multiply these value types"),
        }
    }
}

impl std::ops::Div for Value {
    type Output = Value;

    fn div(self, other: Value) -> Value {
        match (self, other) {
            (Value::Int(a), Value::Int(b)) => Value::Int(a / b),
            (Value::Float(a), Value::Float(b)) => Value::Float(a / b),
            (Value::Int(a), Value::Float(b)) => Value::Float(a as f64 / b),
            (Value::Float(a), Value::Int(b)) => Value::Float(a / b as f64),
            _ => panic!("Cannot divide these value types"),
        }
    }
}

```

---

### Polymorphic Indexing

**File:** `logos_core/src/indexing.rs`

LogosIndex and LogosIndexMut traits for 1-based indexing. Implementations for Vec<T> (converts 1-based to 0-based) and HashMap<K,V> (key-based). Enables 'item N of collection' and bracket access t[N] syntax.

```rust
//! Phase 57: Polymorphic Indexing
//!
//! Provides trait-based indexing that handles:
//! - Vec<T> with i64 (1-based, converted to 0-based)
//! - HashMap<K, V> with K (pass-through)

use std::collections::HashMap;
use std::hash::Hash;

/// Get element by index (immutable).
pub trait LogosIndex<I> {
    type Output;
    fn logos_get(&self, index: I) -> Self::Output;
}

/// Set element by index (mutable).
pub trait LogosIndexMut<I>: LogosIndex<I> {
    fn logos_set(&mut self, index: I, value: Self::Output);
}

// === Vec<T> with i64 (1-based indexing) ===

impl<T: Clone> LogosIndex<i64> for Vec<T> {
    type Output = T;

    fn logos_get(&self, index: i64) -> T {
        if index < 1 {
            panic!("Index {} is invalid: LOGOS uses 1-based indexing (minimum is 1)", index);
        }
        let idx = (index - 1) as usize;
        if idx >= self.len() {
            panic!("Index {} is out of bounds for seq of length {}", index, self.len());
        }
        self[idx].clone()
    }
}

impl<T: Clone> LogosIndexMut<i64> for Vec<T> {
    fn logos_set(&mut self, index: i64, value: T) {
        if index < 1 {
            panic!("Index {} is invalid: LOGOS uses 1-based indexing (minimum is 1)", index);
        }
        let idx = (index - 1) as usize;
        if idx >= self.len() {
            panic!("Index {} is out of bounds for seq of length {}", index, self.len());
        }
        self[idx] = value;
    }
}

// === HashMap<K, V> with K (key-based indexing) ===

impl<K: Eq + Hash, V: Clone> LogosIndex<K> for HashMap<K, V> {
    type Output = V;

    fn logos_get(&self, key: K) -> V {
        self.get(&key).cloned().expect("Key not found in map")
    }
}

impl<K: Eq + Hash, V: Clone> LogosIndexMut<K> for HashMap<K, V> {
    fn logos_set(&mut self, key: K, value: V) {
        self.insert(key, value);
    }
}

// === &str convenience for HashMap<String, V> ===

impl<V: Clone> LogosIndex<&str> for HashMap<String, V> {
    type Output = V;

    fn logos_get(&self, key: &str) -> V {
        self.get(key).cloned().expect("Key not found in map")
    }
}

impl<V: Clone> LogosIndexMut<&str> for HashMap<String, V> {
    fn logos_set(&mut self, key: &str, value: V) {
        self.insert(key.to_string(), value);
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn vec_1_based_indexing() {
        let v = vec![10, 20, 30];
        assert_eq!(LogosIndex::logos_get(&v, 1i64), 10);
        assert_eq!(LogosIndex::logos_get(&v, 2i64), 20);
        assert_eq!(LogosIndex::logos_get(&v, 3i64), 30);
    }

    #[test]
    #[should_panic(expected = "1-based indexing")]
    fn vec_zero_index_panics() {
        let v = vec![10, 20, 30];
        let _ = LogosIndex::logos_get(&v, 0i64);
    }

    #[test]
    fn vec_set_1_based() {
        let mut v = vec![10, 20, 30];
        LogosIndexMut::logos_set(&mut v, 2i64, 99);
        assert_eq!(v, vec![10, 99, 30]);
    }

    #[test]
    fn hashmap_string_key() {
        let mut m: HashMap<String, i64> = HashMap::new();
        m.insert("iron".to_string(), 42);
        assert_eq!(LogosIndex::logos_get(&m, "iron".to_string()), 42);
    }

    #[test]
    fn hashmap_str_key() {
        let mut m: HashMap<String, i64> = HashMap::new();
        m.insert("iron".to_string(), 42);
        assert_eq!(LogosIndex::logos_get(&m, "iron"), 42);
    }

    #[test]
    fn hashmap_set_key() {
        let mut m: HashMap<String, i64> = HashMap::new();
        LogosIndexMut::logos_set(&mut m, "iron", 42i64);
        assert_eq!(m.get("iron"), Some(&42));
    }
}

```

---

### IO Functions

**File:** `logos_core/src/io.rs`

Standard IO per Spec §10.5. Defines Showable trait for custom formatting (primitives display without quotes, Vec/Option display with brackets). show() takes reference and uses Showable; read_line() for input; println/eprintln/print for standard output.

```rust
//! IO Operations (Spec 10.5)

use std::fmt::{self, Display};

/// Custom trait for LOGOS Show verb - provides clean, natural output.
/// Primitives display without quotes, collections display with brackets.
pub trait Showable {
    fn format_show(&self, f: &mut fmt::Formatter) -> fmt::Result;
}

// Primitives: use Display formatting
impl Showable for i32 {
    fn format_show(&self, f: &mut fmt::Formatter) -> fmt::Result {
        Display::fmt(self, f)
    }
}

impl Showable for i64 {
    fn format_show(&self, f: &mut fmt::Formatter) -> fmt::Result {
        Display::fmt(self, f)
    }
}

impl Showable for u64 {
    fn format_show(&self, f: &mut fmt::Formatter) -> fmt::Result {
        Display::fmt(self, f)
    }
}

impl Showable for usize {
    fn format_show(&self, f: &mut fmt::Formatter) -> fmt::Result {
        Display::fmt(self, f)
    }
}

impl Showable for f64 {
    fn format_show(&self, f: &mut fmt::Formatter) -> fmt::Result {
        Display::fmt(self, f)
    }
}

impl Showable for bool {
    fn format_show(&self, f: &mut fmt::Formatter) -> fmt::Result {
        Display::fmt(self, f)
    }
}

impl Showable for u8 {
    fn format_show(&self, f: &mut fmt::Formatter) -> fmt::Result {
        Display::fmt(self, f)
    }
}

impl Showable for char {
    fn format_show(&self, f: &mut fmt::Formatter) -> fmt::Result {
        Display::fmt(self, f)
    }
}

impl Showable for String {
    fn format_show(&self, f: &mut fmt::Formatter) -> fmt::Result {
        Display::fmt(self, f)
    }
}

impl Showable for &str {
    fn format_show(&self, f: &mut fmt::Formatter) -> fmt::Result {
        Display::fmt(self, f)
    }
}

// Sequences: bracket notation with recursive formatting
impl<T: Showable> Showable for Vec<T> {
    fn format_show(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "[")?;
        for (i, item) in self.iter().enumerate() {
            if i > 0 {
                write!(f, ", ")?;
            }
            item.format_show(f)?;
        }
        write!(f, "]")
    }
}

// Slices: same as Vec
impl<T: Showable> Showable for [T] {
    fn format_show(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "[")?;
        for (i, item) in self.iter().enumerate() {
            if i > 0 {
                write!(f, ", ")?;
            }
            item.format_show(f)?;
        }
        write!(f, "]")
    }
}

// Reference to slice
impl<T: Showable> Showable for &[T] {
    fn format_show(&self, f: &mut fmt::Formatter) -> fmt::Result {
        (*self).format_show(f)
    }
}

// Option type: shows "nothing" or the value
impl<T: Showable> Showable for Option<T> {
    fn format_show(&self, f: &mut fmt::Formatter) -> fmt::Result {
        match self {
            Some(v) => v.format_show(f),
            None => write!(f, "nothing"),
        }
    }
}

/// The Show verb - prints value with natural formatting
/// Takes a reference to avoid moving the value.
pub fn show<T: Showable>(value: &T) {
    struct Wrapper<'a, T>(&'a T);
    impl<T: Showable> Display for Wrapper<'_, T> {
        fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
            self.0.format_show(f)
        }
    }
    println!("{}", Wrapper(value));
}

pub fn read_line() -> String {
    let mut buffer = String::new();
    std::io::stdin().read_line(&mut buffer).unwrap_or(0);
    buffer.trim().to_string()
}

pub fn print<T: Display>(x: T) {
    print!("{}", x);
}

pub fn eprintln<T: Display>(x: T) {
    eprintln!("{}", x);
}

pub fn println<T: Display>(x: T) {
    println!("{}", x);
}

```

---

### File I/O

**File:** `logos_core/src/file.rs`

File system operations. read(path) returns Result<String, String>, write(path, content) writes text to file.

```rust
//! File I/O module for LOGOS standard library.

use std::fs;

/// Read file contents as text.
pub fn read(path: String) -> Result<String, String> {
    fs::read_to_string(&path).map_err(|e| format!("Failed to read '{}': {}", path, e))
}

/// Write text to a file.
pub fn write(path: String, content: String) -> Result<(), String> {
    fs::write(&path, &content).map_err(|e| format!("Failed to write '{}': {}", path, e))
}

```

---

### Time Functions

**File:** `logos_core/src/time.rs`

Time utilities. now() returns current Unix timestamp as u64, sleep(ms) pauses execution.

```rust
//! Time module for LOGOS standard library.

use std::time::{SystemTime, UNIX_EPOCH, Duration};
use std::thread;

/// Get current time as milliseconds since Unix epoch.
pub fn now() -> u64 {
    SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .unwrap_or(Duration::ZERO)
        .as_millis() as u64
}

/// Sleep for the given number of milliseconds.
pub fn sleep(ms: u64) {
    thread::sleep(Duration::from_millis(ms));
}

```

---

### Random Numbers

**File:** `logos_core/src/random.rs`

Random number generation using rand crate. random_int(min, max) for integers, random_float() for 0.0-1.0 floats.

```rust
//! Random number module for LOGOS standard library.

use rand::Rng;

/// Generate a random integer in the range [min, max].
pub fn randomInt(min: i64, max: i64) -> i64 {
    let mut rng = rand::thread_rng();
    rng.gen_range(min..=max)
}

/// Generate a random float in the range [0.0, 1.0).
pub fn randomFloat() -> f64 {
    let mut rng = rand::thread_rng();
    rng.gen()
}

```

---

### Environment

**File:** `logos_core/src/env.rs`

Environment access. get(key) retrieves environment variable, args() returns command-line arguments as Vec<String>.

```rust
//! Environment module for LOGOS standard library.

use std::env as std_env;

/// Get an environment variable by name.
pub fn get(key: String) -> Option<String> {
    std_env::var(&key).ok()
}

/// Get command-line arguments.
pub fn args() -> Vec<String> {
    std_env::args().collect()
}

```

---

### Zone Memory Management

**File:** `logos_core/src/memory.rs`

Phase 8.5 & 8.6: Zone-based memory. Zone enum with Heap (bumpalo arena) and Mapped (memmap2 file) variants. new_heap(capacity) for arena allocation, new_mapped(path) for zero-copy file IO. alloc()/alloc_slice() for heap zones, as_slice() for mapped zones. reset() for bulk deallocation. Implements 'Hotel California' rule: values can enter but cannot escape.

```rust
//! Phase 8.5 & 8.6: Zone-based Memory Management
//!
//! Zones provide region-based allocation with O(1) allocation and bulk deallocation.
//! Two backing strategies are supported:
//! - Heap: Fast arena allocation via bumpalo
//! - Mapped: Zero-copy file mapping via memmap2

use std::fs::File;
use std::io;
use std::path::Path;

/// A memory region for batch allocation and bulk deallocation.
///
/// Zones implement the "Hotel California" rule: values can enter but cannot
/// escape. This enables safe O(1) deallocation when the zone goes out of scope.
pub enum Zone {
    /// Dynamic heap-allocated arena (Scratchpad).
    /// Use for temporary allocations that can be bulk-freed.
    Heap(bumpalo::Bump),
    /// Memory-mapped file (Zero-copy IO).
    /// Provides read-only access to file contents without loading into memory.
    Mapped(memmap2::Mmap),
}

impl Zone {
    /// Create a new empty zone on the heap with pre-sized capacity.
    ///
    /// # Example
    /// ```ignore
    /// let zone = Zone::new_heap(1024 * 1024); // 1 MB arena
    /// let x = zone.alloc(42);
    /// ```
    pub fn new_heap(capacity_bytes: usize) -> Self {
        Zone::Heap(bumpalo::Bump::with_capacity(capacity_bytes))
    }

    /// Create a new zone backed by a memory-mapped file.
    ///
    /// # Safety
    /// The file should not be modified by other processes while mapped.
    /// Standard mmap safety caveats apply.
    ///
    /// # Example
    /// ```ignore
    /// let zone = Zone::new_mapped("data.bin")?;
    /// let bytes = zone.as_slice();
    /// ```
    pub fn new_mapped<P: AsRef<Path>>(path: P) -> io::Result<Self> {
        let file = File::open(path)?;
        // SAFETY: We assume the file is not concurrently modified by other
        // processes in a way that causes undefined behavior.
        let mmap = unsafe { memmap2::Mmap::map(&file)? };
        Ok(Zone::Mapped(mmap))
    }

    /// Allocate a value inside the zone.
    ///
    /// Returns a reference with lifetime tied to the zone.
    /// Only valid for Heap zones; Mapped zones are read-only.
    ///
    /// # Panics
    /// Panics if called on a Mapped zone.
    pub fn alloc<T>(&self, val: T) -> &T {
        match self {
            Zone::Heap(bump) => bump.alloc(val),
            Zone::Mapped(_) => panic!(
                "Cannot allocate into a read-only Mapped Zone. \
                 Use Zone::new_heap() for allocations."
            ),
        }
    }

    /// Allocate a slice inside the zone.
    ///
    /// Only valid for Heap zones.
    ///
    /// # Panics
    /// Panics if called on a Mapped zone.
    pub fn alloc_slice<T: Copy>(&self, vals: &[T]) -> &[T] {
        match self {
            Zone::Heap(bump) => bump.alloc_slice_copy(vals),
            Zone::Mapped(_) => panic!(
                "Cannot allocate into a read-only Mapped Zone. \
                 Use Zone::new_heap() for allocations."
            ),
        }
    }

    /// Get a reference to the mapped memory as a byte slice.
    ///
    /// Only valid for Mapped zones.
    ///
    /// # Panics
    /// Panics if called on a Heap zone.
    pub fn as_slice(&self) -> &[u8] {
        match self {
            Zone::Heap(_) => panic!(
                "Heap zones do not have a flat byte slice representation. \
                 Use Zone::new_mapped() for file access."
            ),
            Zone::Mapped(mmap) => &mmap[..],
        }
    }

    /// Reset the zone, deallocating all allocations.
    ///
    /// For Heap zones, this resets the bump allocator.
    /// For Mapped zones, this is a no-op.
    pub fn reset(&mut self) {
        if let Zone::Heap(bump) = self {
            bump.reset();
        }
    }

    /// Returns true if this is a Heap zone.
    pub fn is_heap(&self) -> bool {
        matches!(self, Zone::Heap(_))
    }

    /// Returns true if this is a Mapped zone.
    pub fn is_mapped(&self) -> bool {
        matches!(self, Zone::Mapped(_))
    }

    /// Returns the current allocated bytes for Heap zones.
    /// Returns the file size for Mapped zones.
    pub fn allocated_bytes(&self) -> usize {
        match self {
            Zone::Heap(bump) => bump.allocated_bytes(),
            Zone::Mapped(mmap) => mmap.len(),
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::io::Write;

    #[test]
    fn test_heap_zone_alloc() {
        let zone = Zone::new_heap(1024);
        let x = zone.alloc(42i64);
        assert_eq!(*x, 42);

        let y = zone.alloc(String::from("hello"));
        assert_eq!(y, "hello");
    }

    #[test]
    fn test_heap_zone_alloc_slice() {
        let zone = Zone::new_heap(1024);
        let data = [1, 2, 3, 4, 5];
        let slice = zone.alloc_slice(&data);
        assert_eq!(slice, &[1, 2, 3, 4, 5]);
    }

    #[test]
    fn test_heap_zone_reset() {
        let mut zone = Zone::new_heap(1024);
        let _ = zone.alloc(42);
        let before = zone.allocated_bytes();
        assert!(before > 0);

        zone.reset();
        // After reset, we can allocate again from the beginning
        let _ = zone.alloc(42);
    }

    #[test]
    fn test_mapped_zone() {
        // Create a temp file
        let mut temp = tempfile::NamedTempFile::new().unwrap();
        temp.write_all(b"Hello, Zone!").unwrap();
        temp.flush().unwrap();

        let zone = Zone::new_mapped(temp.path()).unwrap();
        assert!(zone.is_mapped());
        assert_eq!(zone.as_slice(), b"Hello, Zone!");
    }

    #[test]
    #[should_panic(expected = "Cannot allocate into a read-only Mapped Zone")]
    fn test_mapped_zone_alloc_panics() {
        let mut temp = tempfile::NamedTempFile::new().unwrap();
        temp.write_all(b"test").unwrap();
        temp.flush().unwrap();

        let zone = Zone::new_mapped(temp.path()).unwrap();
        let _ = zone.alloc(42); // Should panic
    }

    #[test]
    #[should_panic(expected = "Heap zones do not have a flat byte slice")]
    fn test_heap_zone_as_slice_panics() {
        let zone = Zone::new_heap(1024);
        let _ = zone.as_slice(); // Should panic
    }

    #[test]
    fn test_zone_type_checks() {
        let heap = Zone::new_heap(1024);
        assert!(heap.is_heap());
        assert!(!heap.is_mapped());

        let mut temp = tempfile::NamedTempFile::new().unwrap();
        temp.write_all(b"test").unwrap();
        temp.flush().unwrap();

        let mapped = Zone::new_mapped(temp.path()).unwrap();
        assert!(mapped.is_mapped());
        assert!(!mapped.is_heap());
    }
}

```

---

### CRDT Module Exports

**File:** `logos_core/src/crdt/mod.rs`

Exports Merge trait, GCounter, and LWWRegister for eventually consistent distributed state.

```rust
//! CRDT (Conflict-free Replicated Data Types) for LOGOS
//!
//! Phase 49: Native support for eventually consistent distributed state.
//!
//! CRDTs provide automatic conflict resolution for distributed state synchronization.
//! Any two replicas can be merged to produce the same result regardless of order.
//!
//! Phase 52: Added `Synced<T>` wrapper for automatic GossipSub replication.
//!
//! Wave 1: Added causal infrastructure (VClock, Dot, DotContext) and delta support.

mod gcounter;
mod lww;
mod merge;
mod replica;

// Wave 1: Causal infrastructure
pub mod causal;

// Wave 1: Delta CRDT support
mod delta;
mod delta_buffer;

// Wave 2: Additional CRDTs
mod pncounter;
mod mvregister;

// Wave 3: Complex CRDTs
mod orset;
mod ormap;
pub mod sequence;

// Phase 52: Synced wrapper uses tokio and network - native only
#[cfg(not(target_arch = "wasm32"))]
mod sync;

pub use gcounter::GCounter;
pub use lww::LWWRegister;
pub use merge::Merge;

// Wave 1: Export replica utilities
pub use replica::{generate_replica_id, ReplicaId};

// Wave 1: Export causal types
pub use causal::{Dot, DotContext, VClock};

// Wave 1: Export delta types
pub use delta::DeltaCrdt;
pub use delta_buffer::DeltaBuffer;

// Wave 2: Export additional CRDTs
pub use pncounter::PNCounter;
pub use mvregister::MVRegister;

// Wave 3: Export complex CRDTs
pub use orset::{AddWins, ORSet, RemoveWins, SetBias};
pub use ormap::ORMap;
pub use sequence::{RGA, YATA};

#[cfg(not(target_arch = "wasm32"))]
pub use sync::Synced;

```

---

### Merge Trait

**File:** `logos_core/src/crdt/merge.rs`

Core CRDT interface. Four properties: commutative (a ⊔ b = b ⊔ a), associative ((a ⊔ b) ⊔ c = a ⊔ (b ⊔ c)), idempotent (a ⊔ a = a), and identity (a ⊔ ⊥ = a). All CRDT types implement this trait.

```rust
//! The Merge trait for CRDTs

/// A type that can be merged with another instance of itself.
///
/// The merge operation must satisfy CRDT properties:
/// - **Commutative**: `a.merge(b) == b.merge(a)` (result is the same regardless of order)
/// - **Associative**: `a.merge(b.merge(c)) == a.merge(b).merge(c)`
/// - **Idempotent**: `a.merge(a) == a` (merging with self has no effect)
///
/// These properties ensure that replicas converge to the same state
/// regardless of message ordering or delivery.
pub trait Merge {
    /// Merge another instance into self.
    ///
    /// After merging, `self` contains the combined state of both instances.
    fn merge(&mut self, other: &Self);
}

```

---

### GCounter (Grow-only Counter)

**File:** `logos_core/src/crdt/gcounter.rs`

Increment-only distributed counter. Maintains per-replica counts in HashMap. Merge takes max count per replica ID. Platform-specific replica ID: uuid::Uuid on native, getrandom bytes on WASM. PartialEq<u64/i32> for ergonomic assertions.

```rust
//! G-Counter (Grow-only Counter) CRDT
//!
//! A counter that can only be incremented, never decremented.
//! Each replica maintains its own local count, and the total value
//! is the sum of all replica counts.
//!
//! Wave 1.1: Migrated from String to u64 ReplicaId for efficiency.

use super::replica::{generate_replica_id, ReplicaId};
use super::Merge;
use crate::io::Showable;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::fmt;

/// A grow-only counter that supports distributed increment operations.
///
/// Each replica has a unique ID and maintains its own count.
/// The total value is the sum across all replicas.
/// Merging takes the maximum count for each replica ID.
#[derive(Debug, Clone, Default, Serialize, Deserialize, PartialEq)]
pub struct GCounter {
    /// Map from replica ID to local count
    counts: HashMap<ReplicaId, u64>,
    /// This replica's ID (set on first increment)
    replica_id: ReplicaId,
}

impl GCounter {
    /// Create a new empty counter.
    pub fn new() -> Self {
        Self {
            counts: HashMap::new(),
            replica_id: generate_replica_id(),
        }
    }

    /// Create a counter with a specific replica ID.
    pub fn with_replica_id(id: ReplicaId) -> Self {
        Self {
            counts: HashMap::new(),
            replica_id: id,
        }
    }

    /// Increment the counter by the given amount.
    pub fn increment(&mut self, amount: u64) {
        *self.counts.entry(self.replica_id).or_insert(0) += amount;
    }

    /// Get the current value (sum of all replica counts).
    pub fn value(&self) -> u64 {
        self.counts.values().sum()
    }

    /// Get the replica ID for this counter.
    pub fn replica_id(&self) -> ReplicaId {
        self.replica_id
    }
}

impl Merge for GCounter {
    /// Merge another counter into this one.
    ///
    /// For each replica ID, takes the maximum count between the two counters.
    /// This ensures convergence: merging A into B or B into A yields the same result.
    fn merge(&mut self, other: &Self) {
        for (&replica, &count) in &other.counts {
            let entry = self.counts.entry(replica).or_insert(0);
            *entry = (*entry).max(count);
        }
    }
}

impl Showable for GCounter {
    fn format_show(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "{}", self.value())
    }
}

/// Phase 52: Allow comparing GCounter to integers for ergonomic conditionals
impl PartialEq<u64> for GCounter {
    fn eq(&self, other: &u64) -> bool {
        self.value() == *other
    }
}

impl PartialEq<i32> for GCounter {
    fn eq(&self, other: &i32) -> bool {
        self.value() == (*other as u64)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_gcounter_new() {
        let c = GCounter::new();
        assert_eq!(c.value(), 0);
    }

    #[test]
    fn test_gcounter_increment() {
        let mut c = GCounter::with_replica_id(1);
        c.increment(5);
        c.increment(3);
        assert_eq!(c.value(), 8);
    }

    #[test]
    fn test_gcounter_merge_disjoint() {
        let mut c1 = GCounter::with_replica_id(1);
        let mut c2 = GCounter::with_replica_id(2);

        c1.increment(5);
        c2.increment(3);

        c1.merge(&c2);
        assert_eq!(c1.value(), 8);
    }

    #[test]
    fn test_gcounter_merge_commutative() {
        let mut c1 = GCounter::with_replica_id(1);
        let mut c2 = GCounter::with_replica_id(2);

        c1.increment(5);
        c2.increment(3);

        let mut c1_copy = c1.clone();
        let mut c2_copy = c2.clone();

        c1_copy.merge(&c2);
        c2_copy.merge(&c1);

        assert_eq!(c1_copy.value(), c2_copy.value());
    }

    #[test]
    fn test_gcounter_merge_idempotent() {
        let mut c1 = GCounter::with_replica_id(1);
        c1.increment(5);

        let before = c1.value();
        c1.merge(&c1.clone());
        assert_eq!(c1.value(), before);
    }

    #[test]
    fn test_gcounter_merge_same_replica() {
        // When two counters have the same replica ID (simulating sync after divergence)
        let mut c1 = GCounter::with_replica_id(1);
        let mut c2 = GCounter::with_replica_id(1);

        c1.increment(5);
        c2.increment(3);

        // After merge, should have max(5, 3) = 5
        c1.merge(&c2);
        assert_eq!(c1.value(), 5);
    }
}

```

---

### LWWRegister (Last-Write-Wins Register)

**File:** `logos_core/src/crdt/lww.rs`

Generic register for any Clone type. Resolves conflicts by microsecond-precision UNIX timestamp. Higher timestamp wins on merge. Useful for user-facing fields like names, descriptions.

```rust
//! Last-Write-Wins Register CRDT
//!
//! A register that resolves conflicts using timestamps.
//! The value with the highest timestamp wins on merge.

use super::Merge;
use crate::io::Showable;
use serde::{Deserialize, Serialize};
use std::fmt;
use std::time::{SystemTime, UNIX_EPOCH};

/// A register that resolves conflicts using "last write wins" semantics.
///
/// Each write records a timestamp, and on merge the value with
/// the higher timestamp is kept.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct LWWRegister<T> {
    value: T,
    /// Microseconds since UNIX epoch
    timestamp: u64,
}

impl<T: Default> Default for LWWRegister<T> {
    fn default() -> Self {
        Self::new(T::default())
    }
}

impl<T> LWWRegister<T> {
    /// Create a new register with the given initial value.
    pub fn new(value: T) -> Self {
        Self {
            value,
            timestamp: Self::now(),
        }
    }

    fn now() -> u64 {
        SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap()
            .as_micros() as u64
    }

    /// Set a new value (updates timestamp to now).
    pub fn set(&mut self, value: T) {
        self.value = value;
        self.timestamp = Self::now();
    }

    /// Get the current value.
    pub fn get(&self) -> &T {
        &self.value
    }

    /// Get the timestamp of the last write.
    pub fn timestamp(&self) -> u64 {
        self.timestamp
    }
}

impl<T: Clone> Merge for LWWRegister<T> {
    /// Merge another register into this one.
    ///
    /// The value with the higher timestamp wins.
    /// If timestamps are equal, the other value wins (arbitrary but deterministic).
    fn merge(&mut self, other: &Self) {
        if other.timestamp >= self.timestamp {
            self.value = other.value.clone();
            self.timestamp = other.timestamp;
        }
    }
}

impl<T: Showable> Showable for LWWRegister<T> {
    fn format_show(&self, f: &mut fmt::Formatter) -> fmt::Result {
        self.value.format_show(f)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_lww_new() {
        let reg = LWWRegister::new("hello".to_string());
        assert_eq!(reg.get(), "hello");
    }

    #[test]
    fn test_lww_set() {
        let mut reg = LWWRegister::new("hello".to_string());
        reg.set("world".to_string());
        assert_eq!(reg.get(), "world");
    }

    #[test]
    fn test_lww_merge_newer_wins() {
        let r1 = LWWRegister::new("old".to_string());
        std::thread::sleep(std::time::Duration::from_millis(1));
        let r2 = LWWRegister::new("new".to_string());

        let mut r1_copy = r1.clone();
        r1_copy.merge(&r2);
        assert_eq!(r1_copy.get(), "new");
    }

    #[test]
    fn test_lww_merge_older_loses() {
        let r1 = LWWRegister::new("old".to_string());
        std::thread::sleep(std::time::Duration::from_millis(1));
        let r2 = LWWRegister::new("new".to_string());

        let mut r2_copy = r2.clone();
        r2_copy.merge(&r1);
        // r2 had higher timestamp, so it keeps its value
        assert_eq!(r2_copy.get(), "new");
    }

    #[test]
    fn test_lww_merge_idempotent() {
        let reg = LWWRegister::new("test".to_string());
        let mut reg_copy = reg.clone();
        reg_copy.merge(&reg);
        assert_eq!(reg_copy.get(), "test");
    }

    #[test]
    fn test_lww_with_int() {
        let mut reg = LWWRegister::new(42i64);
        assert_eq!(*reg.get(), 42);
        reg.set(100);
        assert_eq!(*reg.get(), 100);
    }

    #[test]
    fn test_lww_with_bool() {
        let mut reg = LWWRegister::new(false);
        assert_eq!(*reg.get(), false);
        reg.set(true);
        assert_eq!(*reg.get(), true);
    }
}

```

---

### Synced<T> Wrapper (Phase 52)

**File:** `logos_core/src/crdt/sync.rs`

Auto-replicating CRDT wrapper for GossipSub. Wraps Arc<Mutex<T>> for thread-safe shared state. mutate() triggers publish to topic, background task merges incoming messages. new() spawns subscriber task.

```rust
//! Phase 52: Synced wrapper for automatic CRDT replication
//!
//! The `Synced<T>` wrapper provides automatic GossipSub-based replication
//! for any type that implements `Merge + Serialize + DeserializeOwned`.
//!
//! When a `Synced<T>` is mutated, the change is automatically broadcast
//! to all subscribers on the same topic. When a message is received,
//! it's automatically merged into the local state.

use super::Merge;
use crate::network::{gossip, wire};
use serde::{de::DeserializeOwned, Serialize};
use std::sync::Arc;
use tokio::sync::Mutex;

/// A synced CRDT that automatically replicates over GossipSub.
///
/// # Example
///
/// ```ignore
/// let counter = GCounter::new();
/// let synced = Synced::new(counter, "game-scores").await;
///
/// // Mutations are automatically broadcast
/// synced.mutate(|c| c.increment(5)).await;
/// ```
pub struct Synced<T: Merge + Serialize + DeserializeOwned + Clone + Send + 'static> {
    inner: Arc<Mutex<T>>,
    topic: String,
}

impl<T: Merge + Serialize + DeserializeOwned + Clone + Send + 'static> Synced<T> {
    /// Create a new synced wrapper and subscribe to the topic.
    ///
    /// This:
    /// 1. Subscribes to the GossipSub topic (awaited, ensures mesh membership)
    /// 2. Spawns a background task to receive and merge incoming messages
    pub async fn new(initial: T, topic: &str) -> Self {
        let inner = Arc::new(Mutex::new(initial));
        let topic_str = topic.to_string();

        // Subscribe FIRST, await completion to ensure mesh membership
        let mut rx = gossip::subscribe(&topic_str).await;

        // THEN spawn background merge task
        let inner_clone = Arc::clone(&inner);
        tokio::spawn(async move {
            while let Some(bytes) = rx.recv().await {
                match wire::decode::<T>(&bytes) {
                    Ok(incoming) => {
                        let mut guard = inner_clone.lock().await;
                        guard.merge(&incoming);
                    }
                    Err(e) => {
                        eprintln!("[gossip] Deserialization failed: {:?}", e);
                    }
                }
            }
        });

        Self {
            inner,
            topic: topic_str,
        }
    }

    /// Get mutable access to the inner value, publishing after mutation.
    ///
    /// The closure receives a mutable reference to the inner value.
    /// After the closure returns, the full state is broadcast to the topic.
    pub async fn mutate<F, R>(&self, f: F) -> R
    where
        F: FnOnce(&mut T) -> R,
    {
        let mut guard = self.inner.lock().await;
        let result = f(&mut *guard);

        // Publish full state after mutation
        let state = guard.clone();
        drop(guard); // Release lock before async publish

        gossip::publish(&self.topic, &state).await;

        result
    }

    /// Get immutable access to the current state.
    ///
    /// Returns a clone of the current state. For frequent reads,
    /// consider using `mutate` to batch operations.
    pub async fn get(&self) -> T {
        self.inner.lock().await.clone()
    }

    /// Get the topic this CRDT is synchronized on.
    pub fn topic(&self) -> &str {
        &self.topic
    }
}

// =============================================================================
// Test infrastructure (compiles out in release)
// =============================================================================

#[cfg(test)]
impl<T: Merge + Serialize + DeserializeOwned + Clone + Send + 'static> Synced<T> {
    /// Get a clone of the inner state for test inspection.
    ///
    /// This allows tests to verify the internal state without going through
    /// the normal mutation/publish flow.
    pub async fn inspect_inner(&self) -> T {
        self.inner.lock().await.clone()
    }

    /// Get the inner Arc for direct manipulation in tests.
    pub fn inner_arc(&self) -> Arc<Mutex<T>> {
        Arc::clone(&self.inner)
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::crdt::GCounter;

    #[tokio::test]
    async fn test_synced_creation() {
        let counter = GCounter::new();
        let synced = Synced::new(counter, "test-topic").await;
        assert_eq!(synced.topic(), "test-topic");
    }

    #[tokio::test]
    async fn test_synced_mutate() {
        let counter = GCounter::new();
        let synced = Synced::new(counter, "test-mutate").await;

        synced.mutate(|c| c.increment(10)).await;

        let value = synced.get().await;
        assert_eq!(value.value(), 10);
    }

    #[tokio::test]
    async fn test_synced_get() {
        let counter = GCounter::with_replica_id("node1".to_string());
        let synced = Synced::new(counter, "test-get").await;

        synced.mutate(|c| c.increment(5)).await;
        synced.mutate(|c| c.increment(3)).await;

        let value = synced.get().await;
        assert_eq!(value.value(), 8);
    }
}

```

---

### Network Module Exports

**File:** `logos_core/src/network/mod.rs`

Exports Phase 48 (file chunking), Phase 51 (P2P mesh), and Phase 52 (GossipSub) primitives. Public API: FileSipper, FileManifest, listen, connect, send, PeerAgent, MeshNode, gossip_publish, gossip_subscribe.

```rust
//! Phase 48 & 51 & 52: Network primitives for LOGOS distributed system.
//!
//! This module provides:
//! - Zero-copy file chunking and resumable transfer protocols (Phase 48)
//! - P2P networking primitives for agent communication (Phase 51)
//! - GossipSub pub/sub for automatic CRDT replication (Phase 52)

mod sipping;
pub mod wire;
mod protocol;
mod behaviour;
mod mesh;
pub mod gossip;
#[cfg(test)]
mod e2e_tests;

pub use sipping::{FileSipper, FileManifest, FileChunk, DEFAULT_CHUNK_SIZE};
pub use mesh::{listen, connect, send, local_peer_id, PeerAgent, MeshNode, NetworkError};
pub use mesh::{gossip_publish, gossip_subscribe};

```

---

### Mesh Node (libp2p Swarm)

**File:** `logos_core/src/network/mesh.rs`

Core P2P implementation using libp2p 0.54. MeshNode manages global swarm via OnceLock. MeshCommand enum: Listen, Connect, Send, GossipSubscribe, GossipPublish. Event loop handles mDNS discovery (auto-dials peers), request-response, and GossipSub message routing to gossip::on_message().

```rust
//! Phase 51: P2P Networking primitives for LOGOS distributed systems.
//!
//! This module provides the mesh networking layer using libp2p (QUIC-first).
//! Supports Listen/Connect statements and PeerAgent remote handles.
//! Phase 52: Added GossipSub for pub/sub messaging.

use crate::network::behaviour::{MeshBehaviour, MeshBehaviourEvent};
use crate::network::protocol::{LogosRequest, LogosResponse};
use crate::network::wire;
use crate::network::gossip;
use futures::prelude::*;
use libp2p::gossipsub;
use libp2p::request_response::{self, OutboundRequestId};
use libp2p::swarm::SwarmEvent;
use libp2p::{Multiaddr, PeerId, Swarm};
use serde::{de::DeserializeOwned, Serialize};
use std::collections::HashMap;
use std::fmt;
use std::sync::OnceLock;
use tokio::sync::{mpsc, oneshot, Mutex};

/// Phase 52: Global command channel for gossip operations
static GOSSIP_TX: OnceLock<mpsc::Sender<MeshCommand>> = OnceLock::new();

/// Error type for network operations.
#[derive(Debug, Clone)]
pub enum NetworkError {
    /// Failed to establish connection
    ConnectionFailed(String),
    /// Failed to send message
    SendFailed(String),
    /// Operation timed out
    Timeout,
    /// Peer not found at address
    PeerNotFound(String),
    /// Serialization/deserialization failed
    SerializationFailed(String),
    /// Invalid multiaddr format
    InvalidAddress(String),
    /// Mesh node not initialized
    NotInitialized,
    /// Internal error
    Internal(String),
}

impl fmt::Display for NetworkError {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            Self::ConnectionFailed(addr) => write!(f, "Connection failed to {}", addr),
            Self::SendFailed(reason) => write!(f, "Send failed: {}", reason),
            Self::Timeout => write!(f, "Network operation timed out"),
            Self::PeerNotFound(addr) => write!(f, "Peer not found: {}", addr),
            Self::SerializationFailed(reason) => write!(f, "Serialization failed: {}", reason),
            Self::InvalidAddress(addr) => write!(f, "Invalid address: {}", addr),
            Self::NotInitialized => write!(f, "Mesh node not initialized"),
            Self::Internal(msg) => write!(f, "Internal error: {}", msg),
        }
    }
}

impl std::error::Error for NetworkError {}

impl From<wire::WireError> for NetworkError {
    fn from(e: wire::WireError) -> Self {
        NetworkError::SerializationFailed(e.to_string())
    }
}

/// Handle for a remote agent on the mesh network.
///
/// Created via `Let remote be a PeerAgent at "multiaddr"`.
/// Used with `Send` to transmit messages across the network.
#[derive(Debug, Clone)]
pub struct PeerAgent {
    /// The remote peer's ID (if known)
    pub peer_id: Option<PeerId>,
    /// The multiaddr string for the peer
    addr: Multiaddr,
}

impl PeerAgent {
    /// Create a new PeerAgent handle for a remote address.
    ///
    /// # Arguments
    /// * `addr` - A multiaddr string (e.g., "/ip4/127.0.0.1/tcp/8000")
    ///
    /// # Returns
    /// * `Ok(PeerAgent)` if the address is valid
    /// * `Err(NetworkError)` if the address format is invalid
    pub fn new(addr: &str) -> Result<Self, NetworkError> {
        if addr.is_empty() {
            return Err(NetworkError::InvalidAddress(
                "Address cannot be empty".to_string(),
            ));
        }

        let multiaddr: Multiaddr = addr
            .parse()
            .map_err(|e| NetworkError::InvalidAddress(format!("{}: {}", addr, e)))?;

        // Try to extract peer ID from multiaddr if present (e.g., /p2p/QmXyz...)
        let peer_id = multiaddr.iter().find_map(|proto| {
            if let libp2p::multiaddr::Protocol::P2p(id) = proto {
                Some(id)
            } else {
                None
            }
        });

        Ok(Self {
            peer_id,
            addr: multiaddr,
        })
    }

    /// Get the address of this peer as a string.
    pub fn addr(&self) -> String {
        self.addr.to_string()
    }

    /// Get the multiaddr.
    pub fn multiaddr(&self) -> &Multiaddr {
        &self.addr
    }
}

/// Commands sent to the mesh event loop.
enum MeshCommand {
    Listen {
        addr: Multiaddr,
        response: oneshot::Sender<Result<Multiaddr, NetworkError>>,
    },
    Dial {
        addr: Multiaddr,
        response: oneshot::Sender<Result<(), NetworkError>>,
    },
    Send {
        peer_id: PeerId,
        data: Vec<u8>,
        response: oneshot::Sender<Result<Vec<u8>, NetworkError>>,
    },
    GetListenAddrs {
        response: oneshot::Sender<Vec<Multiaddr>>,
    },
    // Phase 52: GossipSub commands
    GossipSubscribe {
        topic: String,
    },
    GossipPublish {
        topic: String,
        data: Vec<u8>,
        retry_count: u8,  // Track retries to prevent infinite loops
    },
}

/// The mesh node - manages the libp2p swarm.
pub struct MeshNode {
    /// Channel to send commands to the event loop
    command_tx: mpsc::Sender<MeshCommand>,
    /// Local peer ID
    local_peer_id: PeerId,
}

impl MeshNode {
    /// Create and start a new mesh node.
    ///
    /// Spawns a background task to run the swarm event loop.
    pub async fn new() -> Result<Self, NetworkError> {
        let (command_tx, command_rx) = mpsc::channel(256);

        // Build the swarm with keypair for GossipSub message signing
        let swarm = libp2p::SwarmBuilder::with_new_identity()
            .with_tokio()
            .with_tcp(
                libp2p::tcp::Config::default(),
                libp2p::noise::Config::new,
                libp2p::yamux::Config::default,
            )
            .map_err(|e| NetworkError::Internal(format!("TCP setup failed: {}", e)))?
            .with_quic()
            .with_behaviour(|key| MeshBehaviour::new(key.public().to_peer_id(), key))
            .map_err(|e| NetworkError::Internal(format!("Behaviour setup failed: {}", e)))?
            .build();

        let local_peer_id = *swarm.local_peer_id();

        // Phase 52: Store command channel for gossip functions
        let command_tx_clone = command_tx.clone();
        GOSSIP_TX.get_or_init(|| command_tx_clone);

        // Spawn the event loop
        tokio::spawn(Self::event_loop(swarm, command_rx));

        Ok(Self {
            command_tx,
            local_peer_id,
        })
    }

    /// The main event loop for the mesh node.
    async fn event_loop(mut swarm: Swarm<MeshBehaviour>, mut command_rx: mpsc::Receiver<MeshCommand>) {
        // Track pending outbound requests
        let mut pending_requests: HashMap<OutboundRequestId, oneshot::Sender<Result<Vec<u8>, NetworkError>>> =
            HashMap::new();

        // Track pending dials (by multiaddr string -> response sender)
        let mut pending_dials: HashMap<String, oneshot::Sender<Result<(), NetworkError>>> =
            HashMap::new();

        // Track known peers by address
        let mut addr_to_peer: HashMap<String, PeerId> = HashMap::new();

        loop {
            tokio::select! {
                // Handle commands from the API
                Some(cmd) = command_rx.recv() => {
                    match cmd {
                        MeshCommand::Listen { addr, response } => {
                            match swarm.listen_on(addr.clone()) {
                                Ok(_) => {
                                    // Will send actual address once we get NewListenAddr event
                                    // For now, send the requested address
                                    let _ = response.send(Ok(addr));
                                }
                                Err(e) => {
                                    let _ = response.send(Err(NetworkError::Internal(e.to_string())));
                                }
                            }
                        }
                        MeshCommand::Dial { addr, response } => {
                            let addr_str = addr.to_string();
                            match swarm.dial(addr) {
                                Ok(_) => {
                                    pending_dials.insert(addr_str, response);
                                }
                                Err(e) => {
                                    let _ = response.send(Err(NetworkError::ConnectionFailed(e.to_string())));
                                }
                            }
                        }
                        MeshCommand::Send { peer_id, data, response } => {
                            let request_id = swarm.behaviour_mut()
                                .request_response
                                .send_request(&peer_id, LogosRequest(data));
                            pending_requests.insert(request_id, response);
                        }
                        MeshCommand::GetListenAddrs { response } => {
                            let addrs: Vec<Multiaddr> = swarm.listeners().cloned().collect();
                            let _ = response.send(addrs);
                        }
                        // Phase 52: GossipSub commands
                        MeshCommand::GossipSubscribe { topic } => {
                            match swarm.behaviour_mut().subscribe(&topic) {
                                Ok(_) => {
                                    eprintln!("[GOSSIP] Subscribed to '{}'", topic);
                                }
                                Err(e) => {
                                    eprintln!("[GOSSIP] Subscribe failed: {:?}", e);
                                }
                            }
                        }
                        MeshCommand::GossipPublish { topic, data, retry_count } => {
                            // Test hook: drop message if network is paused
                            #[cfg(test)]
                            if test_control::is_paused() {
                                eprintln!("[GOSSIP] Network paused, dropping publish to '{}'", topic);
                                continue;
                            }

                            const MAX_RETRIES: u8 = 5;
                            match swarm.behaviour_mut().publish(&topic, data.clone()) {
                                Ok(_) => {
                                    eprintln!("[GOSSIP] Published to '{}'", topic);
                                }
                                Err(gossipsub::PublishError::InsufficientPeers) if retry_count < MAX_RETRIES => {
                                    // Retry with delay - spawn a task to re-queue the publish
                                    eprintln!("[GOSSIP] InsufficientPeers, scheduling retry ({}/{})", retry_count + 1, MAX_RETRIES);
                                    #[cfg(test)]
                                    test_control::increment_retry();
                                    if let Some(tx) = GOSSIP_TX.get() {
                                        let tx = tx.clone();
                                        let topic = topic.clone();
                                        let data = data.clone();
                                        let next_retry = retry_count + 1;
                                        tokio::spawn(async move {
                                            // Wait for mesh to form (exponential backoff: 1s, 2s, 4s, 8s, 16s)
                                            let delay = std::time::Duration::from_secs(1 << retry_count);
                                            tokio::time::sleep(delay).await;
                                            let _ = tx.send(MeshCommand::GossipPublish { topic, data, retry_count: next_retry }).await;
                                        });
                                    }
                                }
                                Err(e) => {
                                    eprintln!("[GOSSIP] Publish failed after {} retries: {:?}", retry_count, e);
                                }
                            }
                        }
                    }
                }

                // Handle swarm events
                event = swarm.select_next_some() => {
                    match event {
                        SwarmEvent::NewListenAddr { address, .. } => {
                            eprintln!("[MESH] Listening on {}", address);
                        }
                        SwarmEvent::ConnectionEstablished { peer_id, endpoint, .. } => {
                            let addr = endpoint.get_remote_address().to_string();
                            eprintln!("[MESH] Connected to {} at {}", peer_id, addr);
                            addr_to_peer.insert(addr.clone(), peer_id);

                            // Complete any pending dial for this address
                            if let Some(response) = pending_dials.remove(&addr) {
                                let _ = response.send(Ok(()));
                            }
                        }
                        SwarmEvent::ConnectionClosed { peer_id, .. } => {
                            eprintln!("[MESH] Disconnected from {}", peer_id);
                        }
                        SwarmEvent::Behaviour(MeshBehaviourEvent::RequestResponse(event)) => {
                            match event {
                                request_response::Event::Message { peer, message } => {
                                    match message {
                                        request_response::Message::Request { request, channel, .. } => {
                                            eprintln!("[MESH] Received request from {}", peer);
                                            // Echo the request back as response for now
                                            let _ = swarm.behaviour_mut()
                                                .request_response
                                                .send_response(channel, LogosResponse(request.0));
                                        }
                                        request_response::Message::Response { request_id, response } => {
                                            if let Some(sender) = pending_requests.remove(&request_id) {
                                                let _ = sender.send(Ok(response.0));
                                            }
                                        }
                                    }
                                }
                                request_response::Event::OutboundFailure { request_id, error, .. } => {
                                    if let Some(sender) = pending_requests.remove(&request_id) {
                                        let _ = sender.send(Err(NetworkError::SendFailed(error.to_string())));
                                    }
                                }
                                request_response::Event::InboundFailure { error, .. } => {
                                    eprintln!("[MESH] Inbound request failed: {}", error);
                                }
                                request_response::Event::ResponseSent { .. } => {}
                            }
                        }
                        SwarmEvent::Behaviour(MeshBehaviourEvent::Mdns(event)) => {
                            match event {
                                libp2p::mdns::Event::Discovered(peers) => {
                                    for (peer_id, addr) in peers {
                                        eprintln!("[MESH] mDNS discovered {} at {}", peer_id, addr);
                                        // Only dial if not already connected
                                        if !swarm.is_connected(&peer_id) {
                                            // Dial using the full multiaddr for better reliability
                                            if let Err(e) = swarm.dial(addr.clone()) {
                                                eprintln!("[MESH] Failed to dial {}: {:?}", addr, e);
                                            } else {
                                                eprintln!("[MESH] Dialing {}", addr);
                                            }
                                        }
                                        swarm.add_peer_address(peer_id, addr.clone());
                                        addr_to_peer.insert(addr.to_string(), peer_id);
                                    }
                                }
                                libp2p::mdns::Event::Expired(peers) => {
                                    for (peer_id, addr) in peers {
                                        eprintln!("[MESH] mDNS expired {} at {}", peer_id, addr);
                                    }
                                }
                            }
                        }
                        // Phase 52: GossipSub events
                        SwarmEvent::Behaviour(MeshBehaviourEvent::Gossipsub(event)) => {
                            match event {
                                gossipsub::Event::Message { message, .. } => {
                                    let topic = message.topic.as_str().to_string();
                                    let data = message.data;
                                    eprintln!("[GOSSIP] Received {} bytes on '{}'", data.len(), topic);
                                    // Route to subscription handler
                                    tokio::spawn(async move {
                                        gossip::on_message(&topic, data).await;
                                    });
                                }
                                gossipsub::Event::Subscribed { peer_id, topic } => {
                                    eprintln!("[GOSSIP] {} subscribed to {}", peer_id, topic);
                                }
                                gossipsub::Event::Unsubscribed { peer_id, topic } => {
                                    eprintln!("[GOSSIP] {} unsubscribed from {}", peer_id, topic);
                                }
                                _ => {}
                            }
                        }
                        _ => {}
                    }
                }
            }
        }
    }

    /// Listen on an address.
    pub async fn listen(&self, addr: &str) -> Result<Multiaddr, NetworkError> {
        let multiaddr: Multiaddr = addr
            .parse()
            .map_err(|e| NetworkError::InvalidAddress(format!("{}: {}", addr, e)))?;

        let (tx, rx) = oneshot::channel();
        self.command_tx
            .send(MeshCommand::Listen {
                addr: multiaddr,
                response: tx,
            })
            .await
            .map_err(|_| NetworkError::Internal("Command channel closed".to_string()))?;

        rx.await
            .map_err(|_| NetworkError::Internal("Response channel closed".to_string()))?
    }

    /// Dial a remote peer.
    pub async fn dial(&self, addr: &str) -> Result<(), NetworkError> {
        let multiaddr: Multiaddr = addr
            .parse()
            .map_err(|e| NetworkError::InvalidAddress(format!("{}: {}", addr, e)))?;

        let (tx, rx) = oneshot::channel();
        self.command_tx
            .send(MeshCommand::Dial {
                addr: multiaddr,
                response: tx,
            })
            .await
            .map_err(|_| NetworkError::Internal("Command channel closed".to_string()))?;

        rx.await
            .map_err(|_| NetworkError::Internal("Response channel closed".to_string()))?
    }

    /// Send a message to a peer and await response.
    pub async fn send_bytes(
        &self,
        peer_id: PeerId,
        data: Vec<u8>,
    ) -> Result<Vec<u8>, NetworkError> {
        let (tx, rx) = oneshot::channel();
        self.command_tx
            .send(MeshCommand::Send {
                peer_id,
                data,
                response: tx,
            })
            .await
            .map_err(|_| NetworkError::Internal("Command channel closed".to_string()))?;

        rx.await
            .map_err(|_| NetworkError::Internal("Response channel closed".to_string()))?
    }

    /// Send a serializable message to a peer.
    pub async fn send<T: Serialize, R: DeserializeOwned>(
        &self,
        peer: &PeerAgent,
        msg: &T,
    ) -> Result<R, NetworkError> {
        let peer_id = peer
            .peer_id
            .ok_or_else(|| NetworkError::PeerNotFound("No peer ID in address".to_string()))?;

        let data = wire::encode(msg)?;
        let response_bytes = self.send_bytes(peer_id, data).await?;
        let response: R = wire::decode(&response_bytes)?;
        Ok(response)
    }

    /// Get the local peer ID.
    pub fn local_peer_id(&self) -> PeerId {
        self.local_peer_id
    }

    /// Get current listening addresses.
    pub async fn listen_addrs(&self) -> Vec<Multiaddr> {
        let (tx, rx) = oneshot::channel();
        if self
            .command_tx
            .send(MeshCommand::GetListenAddrs { response: tx })
            .await
            .is_err()
        {
            return vec![];
        }
        rx.await.unwrap_or_default()
    }
}

// =============================================================================
// Global MESH instance for simple API
// =============================================================================

static MESH: OnceLock<Mutex<Option<MeshNode>>> = OnceLock::new();

/// Initialize the global mesh node.
async fn ensure_mesh() -> Result<(), NetworkError> {
    let mutex = MESH.get_or_init(|| Mutex::new(None));
    let mut guard = mutex.lock().await;
    if guard.is_none() {
        *guard = Some(MeshNode::new().await?);
    }
    Ok(())
}

/// Get a reference to the global mesh node.
async fn get_mesh() -> Result<tokio::sync::MutexGuard<'static, Option<MeshNode>>, NetworkError> {
    ensure_mesh().await?;
    let mutex = MESH.get().ok_or(NetworkError::NotInitialized)?;
    Ok(mutex.lock().await)
}

/// Listen for incoming connections on the specified address.
///
/// # Arguments
/// * `addr` - A multiaddr string (e.g., "/ip4/0.0.0.0/tcp/8000")
///
/// # Example (LOGOS)
/// ```logos
/// Listen on "/ip4/0.0.0.0/tcp/8000".
/// ```
pub async fn listen(addr: &str) -> Result<(), NetworkError> {
    if addr.is_empty() {
        return Err(NetworkError::InvalidAddress(
            "Address cannot be empty".to_string(),
        ));
    }

    let guard = get_mesh().await?;
    let mesh = guard.as_ref().ok_or(NetworkError::NotInitialized)?;
    mesh.listen(addr).await?;
    Ok(())
}

/// Connect to a remote peer at the specified address.
///
/// # Arguments
/// * `addr` - A multiaddr string (e.g., "/ip4/127.0.0.1/tcp/8000")
///
/// # Example (LOGOS)
/// ```logos
/// Connect to "/ip4/127.0.0.1/tcp/8000".
/// ```
pub async fn connect(addr: &str) -> Result<(), NetworkError> {
    if addr.is_empty() {
        return Err(NetworkError::InvalidAddress(
            "Address cannot be empty".to_string(),
        ));
    }

    let guard = get_mesh().await?;
    let mesh = guard.as_ref().ok_or(NetworkError::NotInitialized)?;
    mesh.dial(addr).await
}

/// Send a serializable message to a peer agent.
///
/// # Example (LOGOS)
/// ```logos
/// Let remote be a PeerAgent at "/ip4/127.0.0.1/tcp/8000/p2p/QmXyz...".
/// Send msg to remote.
/// ```
pub async fn send<T: Serialize>(peer: &PeerAgent, msg: &T) -> Result<(), NetworkError> {
    let guard = get_mesh().await?;
    let mesh = guard.as_ref().ok_or(NetworkError::NotInitialized)?;

    let peer_id = peer
        .peer_id
        .ok_or_else(|| NetworkError::PeerNotFound("No peer ID in address".to_string()))?;

    let data = wire::encode(msg)?;
    let _ = mesh.send_bytes(peer_id, data).await?;
    Ok(())
}

/// Get the local peer ID.
pub async fn local_peer_id() -> Result<PeerId, NetworkError> {
    let guard = get_mesh().await?;
    let mesh = guard.as_ref().ok_or(NetworkError::NotInitialized)?;
    Ok(mesh.local_peer_id())
}

// =============================================================================
// Phase 52: GossipSub public API
// =============================================================================

/// Publish data to a GossipSub topic.
///
/// # Example (LOGOS)
/// ```logos
/// Sync state on "game-room".
/// Increase state's clicks by 1.  // Auto-publishes via GossipSub
/// ```
pub async fn gossip_publish(topic: &str, data: Vec<u8>) {
    // Ensure mesh is initialized
    if ensure_mesh().await.is_err() {
        eprintln!("[GOSSIP] Mesh not initialized, cannot publish");
        return;
    }

    if let Some(tx) = GOSSIP_TX.get() {
        if tx.send(MeshCommand::GossipPublish {
            topic: topic.to_string(),
            data,
            retry_count: 0,
        }).await.is_err() {
            eprintln!("[GOSSIP] Command channel closed");
        }
    }
}

/// Subscribe to a GossipSub topic.
///
/// # Example (LOGOS)
/// ```logos
/// Sync state on "game-room".  // Auto-subscribes to topic
/// ```
pub async fn gossip_subscribe(topic: &str) {
    // Ensure mesh is initialized
    if ensure_mesh().await.is_err() {
        eprintln!("[GOSSIP] Mesh not initialized, cannot subscribe");
        return;
    }

    if let Some(tx) = GOSSIP_TX.get() {
        if tx.send(MeshCommand::GossipSubscribe {
            topic: topic.to_string(),
        }).await.is_err() {
            eprintln!("[GOSSIP] Command channel closed");
        }
    }
}

// =============================================================================
// Test infrastructure (compiles out in release)
// =============================================================================

#[cfg(test)]
pub mod test_control {
    use std::sync::atomic::{AtomicBool, AtomicU32, Ordering};
    use std::sync::OnceLock;

    pub struct MeshTestControl {
        pub pause_publish: AtomicBool,
        pub pause_receive: AtomicBool,
        pub retry_count: AtomicU32,
    }

    static CONTROL: OnceLock<MeshTestControl> = OnceLock::new();

    pub fn get() -> &'static MeshTestControl {
        CONTROL.get_or_init(|| MeshTestControl {
            pause_publish: AtomicBool::new(false),
            pause_receive: AtomicBool::new(false),
            retry_count: AtomicU32::new(0),
        })
    }

    pub fn pause_network() {
        get().pause_publish.store(true, Ordering::SeqCst);
    }

    pub fn resume_network() {
        get().pause_publish.store(false, Ordering::SeqCst);
    }

    pub fn is_paused() -> bool {
        get().pause_publish.load(Ordering::Relaxed)
    }

    pub fn increment_retry() {
        get().retry_count.fetch_add(1, Ordering::Relaxed);
    }

    pub fn get_retry_count() -> u32 {
        get().retry_count.load(Ordering::Relaxed)
    }

    pub fn reset_retry_count() {
        get().retry_count.store(0, Ordering::Relaxed);
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_peer_agent_new() {
        let peer = PeerAgent::new("/ip4/127.0.0.1/tcp/8000");
        assert!(peer.is_ok());
        let peer = peer.unwrap();
        assert_eq!(peer.addr(), "/ip4/127.0.0.1/tcp/8000");
        assert!(peer.peer_id.is_none()); // No /p2p/ component
    }

    #[test]
    fn test_peer_agent_empty_fails() {
        let peer = PeerAgent::new("");
        assert!(peer.is_err());
    }

    #[test]
    fn test_peer_agent_invalid_fails() {
        let peer = PeerAgent::new("not-a-multiaddr");
        assert!(peer.is_err());
    }

    #[tokio::test]
    async fn test_mesh_node_creation() {
        let node = MeshNode::new().await;
        assert!(node.is_ok());
        let node = node.unwrap();
        // Peer ID should be valid
        assert!(!node.local_peer_id().to_string().is_empty());
    }

    #[tokio::test]
    async fn test_listen_empty_fails() {
        // This tests the early return before mesh initialization
        let result = listen("").await;
        assert!(matches!(result, Err(NetworkError::InvalidAddress(_))));
    }

    #[tokio::test]
    async fn test_connect_empty_fails() {
        // This tests the early return before mesh initialization
        let result = connect("").await;
        assert!(matches!(result, Err(NetworkError::InvalidAddress(_))));
    }
}

```

---

### LOGOS Protocol Codec

**File:** `logos_core/src/network/protocol.rs`

/logos/mesh/1.0.0 stream protocol. LogosCodec implements async length-prefixed framing. 16MB max message size. LogosRequest/LogosResponse wire types.

```rust
//! Logos mesh protocol codec for libp2p request-response.
//!
//! Defines the protocol identifier and codec for reading/writing
//! length-prefixed binary frames over libp2p streams.

use async_trait::async_trait;
use futures::prelude::*;
use libp2p::request_response::Codec;
use libp2p::StreamProtocol;
use std::io;

/// The Logos mesh protocol identifier.
pub const LOGOS_PROTOCOL: StreamProtocol = StreamProtocol::new("/logos/mesh/1.0.0");

/// Maximum message size (16 MB).
pub const MAX_MESSAGE_SIZE: usize = 16 * 1024 * 1024;

/// Codec for encoding/decoding Logos mesh messages.
///
/// Uses length-prefixed framing: 4-byte big-endian length followed by payload.
#[derive(Debug, Clone, Default)]
pub struct LogosCodec;

/// A request on the Logos mesh (bincode-encoded bytes).
#[derive(Debug, Clone)]
pub struct LogosRequest(pub Vec<u8>);

/// A response on the Logos mesh (bincode-encoded bytes).
#[derive(Debug, Clone)]
pub struct LogosResponse(pub Vec<u8>);

#[async_trait]
impl Codec for LogosCodec {
    type Protocol = StreamProtocol;
    type Request = LogosRequest;
    type Response = LogosResponse;

    async fn read_request<T>(&mut self, _: &Self::Protocol, io: &mut T) -> io::Result<Self::Request>
    where
        T: AsyncRead + Unpin + Send,
    {
        let bytes = read_length_prefixed(io, MAX_MESSAGE_SIZE).await?;
        Ok(LogosRequest(bytes))
    }

    async fn read_response<T>(
        &mut self,
        _: &Self::Protocol,
        io: &mut T,
    ) -> io::Result<Self::Response>
    where
        T: AsyncRead + Unpin + Send,
    {
        let bytes = read_length_prefixed(io, MAX_MESSAGE_SIZE).await?;
        Ok(LogosResponse(bytes))
    }

    async fn write_request<T>(
        &mut self,
        _: &Self::Protocol,
        io: &mut T,
        req: Self::Request,
    ) -> io::Result<()>
    where
        T: AsyncWrite + Unpin + Send,
    {
        write_length_prefixed(io, &req.0).await
    }

    async fn write_response<T>(
        &mut self,
        _: &Self::Protocol,
        io: &mut T,
        res: Self::Response,
    ) -> io::Result<()>
    where
        T: AsyncWrite + Unpin + Send,
    {
        write_length_prefixed(io, &res.0).await
    }
}

/// Read a length-prefixed message from the stream.
async fn read_length_prefixed<T>(io: &mut T, max_size: usize) -> io::Result<Vec<u8>>
where
    T: AsyncRead + Unpin,
{
    let mut len_buf = [0u8; 4];
    io.read_exact(&mut len_buf).await?;
    let len = u32::from_be_bytes(len_buf) as usize;

    if len > max_size {
        return Err(io::Error::new(
            io::ErrorKind::InvalidData,
            format!("Message too large: {} > {}", len, max_size),
        ));
    }

    let mut buf = vec![0u8; len];
    io.read_exact(&mut buf).await?;
    Ok(buf)
}

/// Write a length-prefixed message to the stream.
async fn write_length_prefixed<T>(io: &mut T, data: &[u8]) -> io::Result<()>
where
    T: AsyncWrite + Unpin,
{
    let len = data.len() as u32;
    io.write_all(&len.to_be_bytes()).await?;
    io.write_all(data).await?;
    io.flush().await?;
    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_protocol_name() {
        assert_eq!(LOGOS_PROTOCOL.as_ref(), "/logos/mesh/1.0.0");
    }
}

```

---

### Wire Serialization

**File:** `logos_core/src/network/wire.rs`

Bincode-based LogosWire abstraction. encode<T: Serialize>() and decode<T: DeserializeOwned>(). WireError enum for encode/decode failures. Designed for future migration to rkyv.

```rust
//! LogosWire: Bincode-based wire serialization for P2P messaging.
//!
//! Provides a simple abstraction over bincode for encoding/decoding
//! messages on the wire. Designed for easy future migration to rkyv
//! if zero-copy performance becomes necessary.

use serde::{de::DeserializeOwned, Serialize};
use std::fmt;

/// Error type for wire serialization/deserialization.
#[derive(Debug, Clone)]
pub enum WireError {
    /// Failed to encode message to bytes
    Encode(String),
    /// Failed to decode bytes to message
    Decode(String),
}

impl fmt::Display for WireError {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            Self::Encode(msg) => write!(f, "Wire encode error: {}", msg),
            Self::Decode(msg) => write!(f, "Wire decode error: {}", msg),
        }
    }
}

impl std::error::Error for WireError {}

/// Encode a serializable message to bytes.
///
/// # Example
/// ```
/// use serde::{Serialize, Deserialize};
/// use logos_core::network::wire;
///
/// #[derive(Serialize, Deserialize, PartialEq, Debug)]
/// struct Ping { id: u32 }
///
/// let msg = Ping { id: 42 };
/// let bytes = wire::encode(&msg).unwrap();
/// let decoded: Ping = wire::decode(&bytes).unwrap();
/// assert_eq!(msg, decoded);
/// ```
pub fn encode<T: Serialize>(msg: &T) -> Result<Vec<u8>, WireError> {
    bincode::serialize(msg).map_err(|e| WireError::Encode(e.to_string()))
}

/// Decode bytes to a deserializable message.
pub fn decode<T: DeserializeOwned>(bytes: &[u8]) -> Result<T, WireError> {
    bincode::deserialize(bytes).map_err(|e| WireError::Decode(e.to_string()))
}

#[cfg(test)]
mod tests {
    use super::*;
    use serde::{Deserialize, Serialize};

    #[derive(Serialize, Deserialize, PartialEq, Debug)]
    struct TestMessage {
        id: u32,
        content: String,
    }

    #[test]
    fn test_roundtrip() {
        let msg = TestMessage {
            id: 42,
            content: "hello mesh".to_string(),
        };
        let bytes = encode(&msg).unwrap();
        let decoded: TestMessage = decode(&bytes).unwrap();
        assert_eq!(msg, decoded);
    }

    #[test]
    fn test_decode_invalid_bytes() {
        let bytes = vec![0xFF, 0xFF, 0xFF];
        let result: Result<TestMessage, _> = decode(&bytes);
        assert!(result.is_err());
    }
}

```

---

### Mesh Behaviour

**File:** `logos_core/src/network/behaviour.rs`

Combined libp2p NetworkBehaviour. Integrates request-response, mDNS discovery, and GossipSub pub/sub. MeshBehaviour struct derives NetworkBehaviour with three sub-behaviours. gossipsub::Behaviour with MessageAuthenticity::Signed.

```rust
//! Mesh network behaviour combining request-response, mDNS, and GossipSub.

use crate::network::protocol::{LogosCodec, LOGOS_PROTOCOL};
use libp2p::gossipsub::{self, IdentTopic, MessageAuthenticity};
use libp2p::identity::Keypair;
use libp2p::mdns;
use libp2p::request_response::{self, ProtocolSupport};
use libp2p::swarm::NetworkBehaviour;
use std::time::Duration;

/// Combined network behaviour for the Logos mesh.
///
/// Integrates:
/// - Request-response: For sending messages between agents
/// - mDNS: For local peer discovery
/// - GossipSub: For pub/sub messaging (Phase 52)
#[derive(NetworkBehaviour)]
pub struct MeshBehaviour {
    /// Request-response protocol for agent communication
    pub request_response: request_response::Behaviour<LogosCodec>,
    /// mDNS for local network peer discovery
    pub mdns: mdns::tokio::Behaviour,
    /// GossipSub for pub/sub messaging (Phase 52)
    pub gossipsub: gossipsub::Behaviour,
}

impl MeshBehaviour {
    /// Create a new mesh behaviour with default configuration.
    pub fn new(local_peer_id: libp2p::PeerId, keypair: &Keypair) -> Self {
        // Configure request-response
        let rr_config = request_response::Config::default()
            .with_request_timeout(Duration::from_secs(30));

        let request_response = request_response::Behaviour::new(
            [(LOGOS_PROTOCOL, ProtocolSupport::Full)],
            rr_config,
        );

        // Configure mDNS
        let mdns_config = mdns::Config::default();
        let mdns = mdns::tokio::Behaviour::new(mdns_config, local_peer_id)
            .expect("Failed to create mDNS behaviour");

        // Phase 52: Configure GossipSub
        let gossipsub_config = gossipsub::ConfigBuilder::default()
            .heartbeat_interval(Duration::from_secs(1))
            .validation_mode(gossipsub::ValidationMode::Strict)
            .build()
            .expect("Valid gossipsub config");

        let gossipsub = gossipsub::Behaviour::new(
            MessageAuthenticity::Signed(keypair.clone()),
            gossipsub_config,
        ).expect("Valid gossipsub behaviour");

        Self {
            request_response,
            mdns,
            gossipsub,
        }
    }

    /// Subscribe to a GossipSub topic.
    pub fn subscribe(&mut self, topic: &str) -> Result<bool, gossipsub::SubscriptionError> {
        let topic = IdentTopic::new(topic);
        self.gossipsub.subscribe(&topic)
    }

    /// Publish to a GossipSub topic.
    pub fn publish(&mut self, topic: &str, data: Vec<u8>) -> Result<gossipsub::MessageId, gossipsub::PublishError> {
        let topic = IdentTopic::new(topic);
        self.gossipsub.publish(topic, data)
    }
}

```

---

### GossipSub Pub/Sub (Phase 52)

**File:** `logos_core/src/network/gossip.rs`

GossipSub publish/subscribe for automatic CRDT replication. Static SUBSCRIPTIONS registry. publish<T>() broadcasts encoded state, subscribe_and_merge<T>() handles incoming merges. on_message() routes data to Synced<T> instances.

```rust
//! Phase 52: GossipSub pub/sub for CRDT synchronization
//!
//! This module provides automatic CRDT replication over GossipSub.
//! When a CRDT is synced on a topic:
//! 1. Local changes are broadcast to all subscribers
//! 2. Remote changes are received and merged automatically

use crate::crdt::Merge;
use crate::network::wire;
use once_cell::sync::Lazy;
use serde::{de::DeserializeOwned, Serialize};
use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::{mpsc, Mutex};

/// Topic subscriptions: topic -> channel for incoming messages
static SUBSCRIPTIONS: Lazy<Mutex<HashMap<String, mpsc::Sender<Vec<u8>>>>> =
    Lazy::new(|| Mutex::new(HashMap::new()));

/// Subscribe to a topic. Returns a receiver for incoming messages.
///
/// This registers the subscription locally and forwards it to the mesh node.
/// The returned receiver will receive raw message bytes.
pub async fn subscribe(topic: &str) -> mpsc::Receiver<Vec<u8>> {
    let (tx, rx) = mpsc::channel::<Vec<u8>>(256);

    // Register subscription
    {
        let mut subs = SUBSCRIPTIONS.lock().await;
        subs.insert(topic.to_string(), tx);
    }

    // Forward subscription to mesh node
    crate::network::gossip_subscribe(topic).await;

    rx
}

/// Publish a message to a GossipSub topic.
///
/// The message is serialized with bincode and broadcast to all subscribers
/// on the mesh network.
pub async fn publish<T: Serialize>(topic: &str, data: &T) {
    let bytes = match wire::encode(data) {
        Ok(b) => b,
        Err(e) => {
            eprintln!("[gossip] Serialization failed: {:?}", e);
            return;
        }
    };

    // Forward to mesh node's gossipsub behaviour
    crate::network::gossip_publish(topic, bytes).await;
}

/// Phase 56: Publish raw bytes (already encoded) to avoid double-encoding.
///
/// Used by Distributed<T> which serializes once for both journaling and network.
pub async fn publish_raw(topic: &str, data: Vec<u8>) -> Result<(), String> {
    crate::network::gossip_publish(topic, data).await;
    Ok(())
}

/// Phase 56: Get the local peer ID for echo detection.
///
/// Returns None if the mesh node is not initialized.
pub async fn local_peer_id() -> Option<String> {
    match crate::network::local_peer_id().await {
        Ok(peer_id) => Some(peer_id.to_string()),
        Err(_) => None,
    }
}

/// Subscribe to a topic and auto-merge incoming messages.
///
/// This function blocks until the subscription is cancelled.
/// Incoming messages are deserialized and merged into the target.
pub async fn subscribe_and_merge<T: Merge + DeserializeOwned + Send + 'static>(
    topic: &str,
    target: Arc<Mutex<T>>,
) {
    let (tx, mut rx) = mpsc::channel::<Vec<u8>>(256);

    // Register subscription
    {
        let mut subs = SUBSCRIPTIONS.lock().await;
        subs.insert(topic.to_string(), tx);
    }

    // Forward subscription to mesh node
    crate::network::gossip_subscribe(topic).await;

    // Process incoming messages
    while let Some(bytes) = rx.recv().await {
        match wire::decode::<T>(&bytes) {
            Ok(incoming) => {
                let mut guard = target.lock().await;
                guard.merge(&incoming);
            }
            Err(e) => {
                eprintln!("[gossip] Deserialization failed: {:?}", e);
            }
        }
    }
}

/// Called by mesh node when a GossipSub message arrives.
///
/// Routes the message to the appropriate subscription channel.
pub async fn on_message(topic: &str, data: Vec<u8>) {
    // Test hook: log received messages
    #[cfg(test)]
    test_hooks::log_received(topic, &data);

    let subs = SUBSCRIPTIONS.lock().await;
    if let Some(tx) = subs.get(topic) {
        if tx.send(data).await.is_err() {
            eprintln!("[gossip] Failed to forward message to subscriber");
        }
    }
}

/// Unsubscribe from a topic.
///
/// This removes the subscription and stops receiving messages.
#[allow(dead_code)]
pub async fn unsubscribe(topic: &str) {
    let mut subs = SUBSCRIPTIONS.lock().await;
    subs.remove(topic);
    // Note: Should also tell mesh node to unsubscribe from gossipsub
}

// =============================================================================
// Test infrastructure (compiles out in release)
// =============================================================================

#[cfg(test)]
pub mod test_hooks {
    use once_cell::sync::Lazy;
    use std::sync::Mutex;

    pub struct MessageLog {
        pub received: Vec<(String, Vec<u8>)>,
    }

    static LOG: Lazy<Mutex<MessageLog>> = Lazy::new(|| {
        Mutex::new(MessageLog {
            received: Vec::new(),
        })
    });

    pub fn log_received(topic: &str, data: &[u8]) {
        if let Ok(mut log) = LOG.lock() {
            log.received.push((topic.to_string(), data.to_vec()));
        }
    }

    pub fn get_received() -> Vec<(String, Vec<u8>)> {
        LOG.lock().map(|l| l.received.clone()).unwrap_or_default()
    }

    pub fn clear_log() {
        if let Ok(mut log) = LOG.lock() {
            log.received.clear();
        }
    }

    pub fn received_count() -> usize {
        LOG.lock().map(|l| l.received.len()).unwrap_or(0)
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::crdt::GCounter;

    #[tokio::test]
    async fn test_subscriptions_registry() {
        let counter = Arc::new(Mutex::new(GCounter::new()));

        // Spawn a subscription task
        let topic = "test-sub";
        let counter_clone = Arc::clone(&counter);
        let handle = tokio::spawn(async move {
            // This would block forever in real use, but we'll cancel it
            tokio::select! {
                _ = subscribe_and_merge::<GCounter>(topic, counter_clone) => {}
                _ = tokio::time::sleep(std::time::Duration::from_millis(100)) => {}
            }
        });

        // Wait a bit for subscription to register
        tokio::time::sleep(std::time::Duration::from_millis(50)).await;

        // Check subscription exists
        let subs = SUBSCRIPTIONS.lock().await;
        assert!(subs.contains_key(topic), "Subscription should be registered");
        drop(subs);

        // Cleanup
        handle.abort();
    }
}

```

---

### File Sipper (Phase 48)

**File:** `logos_core/src/network/sipping.rs`

Zero-copy file chunking for resumable transfers. FileSipper uses memory-mapped zones. FileManifest describes chunks with SHA256 hashes. Default 1MB chunk size.

```rust
//! Sipping Protocol: Zero-copy file chunking for resumable transfers.
//!
//! The Sipping protocol slices memory-mapped files into chunks with SHA256 hashes,
//! enabling resumable, verifiable file transfers over unreliable networks.

use crate::memory::Zone;
use sha2::{Sha256, Digest};
use serde::{Serialize, Deserialize};

/// Default chunk size: 1 MB
pub const DEFAULT_CHUNK_SIZE: usize = 1024 * 1024;

/// Manifest describing a file's chunks for resumable transfer.
///
/// The manifest contains:
/// - A unique file ID for this transfer session
/// - Total file size and chunk count
/// - SHA256 hashes for each chunk (enables verification and deduplication)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FileManifest {
    pub file_id: String,
    pub total_size: u64,
    pub chunk_size: usize,
    pub chunk_count: usize,
    pub chunk_hashes: Vec<[u8; 32]>,
}

/// A single chunk of file data with its hash for verification.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FileChunk {
    pub file_id: String,
    pub index: usize,
    pub data: Vec<u8>,
    pub hash: [u8; 32],
}

/// Zero-copy file chunking using memory-mapped zones.
///
/// FileSipper wraps a memory-mapped Zone and provides:
/// - Zero-copy chunk access via slicing
/// - SHA256 hashing for verification
/// - Manifest generation for resumable transfers
///
/// # Example
/// ```ignore
/// let zone = Zone::new_mapped("large_file.bin")?;
/// let sipper = FileSipper::from_zone(&zone);
/// let manifest = sipper.manifest();
/// let chunk = sipper.get_chunk(0);
/// ```
pub struct FileSipper<'a> {
    zone: &'a Zone,
    chunk_size: usize,
    file_id: String,
}

impl<'a> FileSipper<'a> {
    /// Create sipper from a mapped zone with default chunk size (1 MB).
    pub fn from_zone(zone: &'a Zone) -> Self {
        Self {
            zone,
            chunk_size: DEFAULT_CHUNK_SIZE,
            file_id: uuid::Uuid::new_v4().to_string(),
        }
    }

    /// Create sipper with custom chunk size.
    pub fn with_chunk_size(zone: &'a Zone, chunk_size: usize) -> Self {
        Self {
            zone,
            chunk_size,
            file_id: uuid::Uuid::new_v4().to_string(),
        }
    }

    /// Get the file ID for this sipper session.
    pub fn file_id(&self) -> &str {
        &self.file_id
    }

    /// Get number of chunks in the file.
    pub fn chunk_count(&self) -> usize {
        let size = self.zone.allocated_bytes();
        if size == 0 {
            0
        } else {
            (size + self.chunk_size - 1) / self.chunk_size
        }
    }

    /// Zero-copy slice of chunk at index (0-indexed).
    ///
    /// Returns the raw bytes of the chunk without copying.
    /// The last chunk may be smaller than chunk_size.
    pub fn get_chunk(&self, index: usize) -> &[u8] {
        let slice = self.zone.as_slice();
        let start = index * self.chunk_size;
        let end = (start + self.chunk_size).min(slice.len());
        if start >= slice.len() {
            &[]
        } else {
            &slice[start..end]
        }
    }

    /// Compute SHA256 hash of a specific chunk.
    pub fn hash_chunk(&self, index: usize) -> [u8; 32] {
        let chunk = self.get_chunk(index);
        let mut hasher = Sha256::new();
        hasher.update(chunk);
        hasher.finalize().into()
    }

    /// Generate manifest with all chunk hashes.
    ///
    /// The manifest enables:
    /// - Resumable transfers (client can request missing chunks)
    /// - Verification (client can verify each chunk's hash)
    /// - Deduplication (identical chunks have identical hashes)
    pub fn manifest(&self) -> FileManifest {
        let slice = self.zone.as_slice();
        let chunk_count = self.chunk_count();
        let hashes: Vec<[u8; 32]> = (0..chunk_count)
            .map(|i| self.hash_chunk(i))
            .collect();

        FileManifest {
            file_id: self.file_id.clone(),
            total_size: slice.len() as u64,
            chunk_size: self.chunk_size,
            chunk_count,
            chunk_hashes: hashes,
        }
    }

    /// Get chunk as FileChunk struct (includes hash for verification).
    ///
    /// This copies the data into the FileChunk. Use `get_chunk()` for
    /// zero-copy access when you don't need the hash included.
    pub fn get_chunk_with_hash(&self, index: usize) -> FileChunk {
        let data = self.get_chunk(index).to_vec();
        let hash = self.hash_chunk(index);
        FileChunk {
            file_id: self.file_id.clone(),
            index,
            data,
            hash,
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::io::Write;
    use tempfile::NamedTempFile;

    fn create_test_file(size: usize) -> NamedTempFile {
        let mut file = NamedTempFile::new().unwrap();
        let data: Vec<u8> = (0..size).map(|i| (i % 256) as u8).collect();
        file.write_all(&data).unwrap();
        file.flush().unwrap();
        file
    }

    #[test]
    fn test_chunk_count_empty() {
        // Create empty file
        let file = NamedTempFile::new().unwrap();
        let zone = Zone::new_mapped(file.path()).unwrap();
        let sipper = FileSipper::from_zone(&zone);
        assert_eq!(sipper.chunk_count(), 0);
    }

    #[test]
    fn test_chunk_count_small_file() {
        let file = create_test_file(100);
        let zone = Zone::new_mapped(file.path()).unwrap();
        let sipper = FileSipper::from_zone(&zone);
        assert_eq!(sipper.chunk_count(), 1); // 100 bytes < 1 MB
    }

    #[test]
    fn test_manifest_has_correct_size() {
        let file = create_test_file(1000);
        let zone = Zone::new_mapped(file.path()).unwrap();
        let sipper = FileSipper::from_zone(&zone);
        let manifest = sipper.manifest();

        assert_eq!(manifest.total_size, 1000);
        assert_eq!(manifest.chunk_count, 1);
        assert_eq!(manifest.chunk_hashes.len(), 1);
    }

    #[test]
    fn test_chunk_hash_is_consistent() {
        let file = create_test_file(500);
        let zone = Zone::new_mapped(file.path()).unwrap();
        let sipper = FileSipper::from_zone(&zone);

        let hash1 = sipper.hash_chunk(0);
        let hash2 = sipper.hash_chunk(0);
        assert_eq!(hash1, hash2, "Same chunk should have same hash");
    }

    #[test]
    fn test_custom_chunk_size() {
        let file = create_test_file(1000);
        let zone = Zone::new_mapped(file.path()).unwrap();
        let sipper = FileSipper::with_chunk_size(&zone, 100);

        assert_eq!(sipper.chunk_count(), 10); // 1000 / 100 = 10 chunks

        let manifest = sipper.manifest();
        assert_eq!(manifest.chunk_count, 10);
        assert_eq!(manifest.chunk_hashes.len(), 10);
    }
}

```

---

### Virtual File System

**File:** `logos_core/src/fs/mod.rs`

Platform-agnostic file operations. Vfs trait with conditional Send+Sync (native) vs ?Send (WASM). NativeVfs uses tokio::fs. PlatformVfs type alias for ergonomic cross-platform code.

```rust
//! Phase 53: Virtual File System Abstraction
//!
//! Provides platform-agnostic async file operations.
//! - Native: tokio::fs with atomic operations
//! - WASM: OPFS (Origin Private File System) via web-sys

#[cfg(target_arch = "wasm32")]
mod opfs;

#[cfg(target_arch = "wasm32")]
pub use opfs::OpfsVfs;

use async_trait::async_trait;
use std::io;

#[cfg(not(target_arch = "wasm32"))]
use std::path::PathBuf;

/// Error type for VFS operations
#[derive(Debug)]
pub enum VfsError {
    NotFound(String),
    PermissionDenied(String),
    AlreadyExists(String),
    IoError(io::Error),
    SerializationError(String),
    JournalCorrupted(String),
}

impl std::fmt::Display for VfsError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            VfsError::NotFound(s) => write!(f, "Not found: {}", s),
            VfsError::PermissionDenied(s) => write!(f, "Permission denied: {}", s),
            VfsError::AlreadyExists(s) => write!(f, "Already exists: {}", s),
            VfsError::IoError(e) => write!(f, "IO error: {}", e),
            VfsError::SerializationError(s) => write!(f, "Serialization error: {}", s),
            VfsError::JournalCorrupted(s) => write!(f, "Journal corrupted: {}", s),
        }
    }
}

impl std::error::Error for VfsError {}

impl From<io::Error> for VfsError {
    fn from(e: io::Error) -> Self {
        match e.kind() {
            io::ErrorKind::NotFound => VfsError::NotFound(e.to_string()),
            io::ErrorKind::PermissionDenied => VfsError::PermissionDenied(e.to_string()),
            io::ErrorKind::AlreadyExists => VfsError::AlreadyExists(e.to_string()),
            _ => VfsError::IoError(e),
        }
    }
}

pub type VfsResult<T> = Result<T, VfsError>;

/// Virtual File System trait for platform-agnostic file operations.
///
/// On native platforms, requires Send+Sync for thread-safe access.
/// On WASM, these bounds are relaxed since JS is single-threaded.
#[cfg(not(target_arch = "wasm32"))]
#[async_trait]
pub trait Vfs: Send + Sync {
    /// Read entire file contents as bytes.
    async fn read(&self, path: &str) -> VfsResult<Vec<u8>>;

    /// Read file contents as UTF-8 string.
    async fn read_to_string(&self, path: &str) -> VfsResult<String>;

    /// Write bytes to file (atomic on native, best-effort on WASM).
    async fn write(&self, path: &str, contents: &[u8]) -> VfsResult<()>;

    /// Append bytes to file (atomic append semantics).
    async fn append(&self, path: &str, contents: &[u8]) -> VfsResult<()>;

    /// Check if file exists.
    async fn exists(&self, path: &str) -> VfsResult<bool>;

    /// Delete a file.
    async fn remove(&self, path: &str) -> VfsResult<()>;

    /// Create directory and all parent directories.
    async fn create_dir_all(&self, path: &str) -> VfsResult<()>;

    /// Atomically rename a file (for journal compaction).
    async fn rename(&self, from: &str, to: &str) -> VfsResult<()>;
}

/// WASM version of VFS trait without Send+Sync (JS is single-threaded).
#[cfg(target_arch = "wasm32")]
#[async_trait(?Send)]
pub trait Vfs {
    /// Read entire file contents as bytes.
    async fn read(&self, path: &str) -> VfsResult<Vec<u8>>;

    /// Read file contents as UTF-8 string.
    async fn read_to_string(&self, path: &str) -> VfsResult<String>;

    /// Write bytes to file (atomic on native, best-effort on WASM).
    async fn write(&self, path: &str, contents: &[u8]) -> VfsResult<()>;

    /// Append bytes to file (atomic append semantics).
    async fn append(&self, path: &str, contents: &[u8]) -> VfsResult<()>;

    /// Check if file exists.
    async fn exists(&self, path: &str) -> VfsResult<bool>;

    /// Delete a file.
    async fn remove(&self, path: &str) -> VfsResult<()>;

    /// Create directory and all parent directories.
    async fn create_dir_all(&self, path: &str) -> VfsResult<()>;

    /// Atomically rename a file (for journal compaction).
    async fn rename(&self, from: &str, to: &str) -> VfsResult<()>;
}

/// Native filesystem VFS using tokio::fs.
#[cfg(not(target_arch = "wasm32"))]
pub struct NativeVfs {
    /// Base directory for all operations (sandbox root).
    base_dir: PathBuf,
}

#[cfg(not(target_arch = "wasm32"))]
impl NativeVfs {
    /// Create a new NativeVfs rooted at the given directory.
    pub fn new<P: Into<PathBuf>>(base_dir: P) -> Self {
        Self {
            base_dir: base_dir.into(),
        }
    }

    /// Resolve a virtual path to an absolute filesystem path.
    fn resolve(&self, path: &str) -> PathBuf {
        // Security: Prevent path traversal attacks
        let clean = path.trim_start_matches('/').trim_start_matches("../");
        self.base_dir.join(clean)
    }
}

#[cfg(not(target_arch = "wasm32"))]
#[async_trait]
impl Vfs for NativeVfs {
    async fn read(&self, path: &str) -> VfsResult<Vec<u8>> {
        let full_path = self.resolve(path);
        tokio::fs::read(&full_path).await.map_err(VfsError::from)
    }

    async fn read_to_string(&self, path: &str) -> VfsResult<String> {
        let full_path = self.resolve(path);
        tokio::fs::read_to_string(&full_path).await.map_err(VfsError::from)
    }

    async fn write(&self, path: &str, contents: &[u8]) -> VfsResult<()> {
        let full_path = self.resolve(path);

        // Ensure parent directory exists
        if let Some(parent) = full_path.parent() {
            tokio::fs::create_dir_all(parent).await?;
        }

        // Atomic write: write to temp file, then rename
        let temp_path = full_path.with_extension("tmp");
        tokio::fs::write(&temp_path, contents).await?;
        tokio::fs::rename(&temp_path, &full_path).await?;

        Ok(())
    }

    async fn append(&self, path: &str, contents: &[u8]) -> VfsResult<()> {
        use tokio::io::AsyncWriteExt;

        let full_path = self.resolve(path);

        // Ensure parent directory exists
        if let Some(parent) = full_path.parent() {
            tokio::fs::create_dir_all(parent).await?;
        }

        let mut file = tokio::fs::OpenOptions::new()
            .create(true)
            .append(true)
            .open(&full_path)
            .await?;

        file.write_all(contents).await?;
        file.sync_all().await?;

        Ok(())
    }

    async fn exists(&self, path: &str) -> VfsResult<bool> {
        let full_path = self.resolve(path);
        Ok(full_path.exists())
    }

    async fn remove(&self, path: &str) -> VfsResult<()> {
        let full_path = self.resolve(path);
        tokio::fs::remove_file(&full_path).await.map_err(VfsError::from)
    }

    async fn create_dir_all(&self, path: &str) -> VfsResult<()> {
        let full_path = self.resolve(path);
        tokio::fs::create_dir_all(&full_path).await.map_err(VfsError::from)
    }

    async fn rename(&self, from: &str, to: &str) -> VfsResult<()> {
        let from_path = self.resolve(from);
        let to_path = self.resolve(to);
        tokio::fs::rename(&from_path, &to_path).await.map_err(VfsError::from)
    }
}

/// Type alias for platform-specific VFS.
#[cfg(not(target_arch = "wasm32"))]
pub type PlatformVfs = NativeVfs;

#[cfg(target_arch = "wasm32")]
pub type PlatformVfs = OpfsVfs;

/// Get the platform-default VFS instance.
///
/// - Native: Returns NativeVfs rooted at current directory
/// - WASM: Returns OpfsVfs rooted at OPFS root
#[cfg(not(target_arch = "wasm32"))]
pub fn get_platform_vfs() -> NativeVfs {
    NativeVfs::new(".")
}

#[cfg(target_arch = "wasm32")]
pub async fn get_platform_vfs() -> VfsResult<OpfsVfs> {
    OpfsVfs::new().await
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::TempDir;

    #[tokio::test]
    async fn test_native_vfs_read_write() {
        let temp = TempDir::new().unwrap();
        let vfs = NativeVfs::new(temp.path());

        vfs.write("test.txt", b"hello world").await.unwrap();
        let content = vfs.read_to_string("test.txt").await.unwrap();

        assert_eq!(content, "hello world");
    }

    #[tokio::test]
    async fn test_native_vfs_append() {
        let temp = TempDir::new().unwrap();
        let vfs = NativeVfs::new(temp.path());

        vfs.append("log.txt", b"line1\n").await.unwrap();
        vfs.append("log.txt", b"line2\n").await.unwrap();

        let content = vfs.read_to_string("log.txt").await.unwrap();
        assert_eq!(content, "line1\nline2\n");
    }

    #[tokio::test]
    async fn test_native_vfs_nested_dirs() {
        let temp = TempDir::new().unwrap();
        let vfs = NativeVfs::new(temp.path());

        vfs.write("a/b/c/file.txt", b"deep").await.unwrap();
        let content = vfs.read_to_string("a/b/c/file.txt").await.unwrap();

        assert_eq!(content, "deep");
    }
}

```

---

### OPFS VFS (WASM)

**File:** `logos_core/src/fs/opfs.rs`

Origin Private File System for browser persistence. OpfsVfs implements async Vfs trait using web-sys bindings. navigator.storage.getDirectory() root, FileSystemWritableFileStream for writes.

```rust
//! Phase 54: OPFS (Origin Private File System) implementation for WASM.
//!
//! Provides browser persistence using the File System Access API.
//! All paths are relative to the OPFS root (no traversal possible).

#![cfg(target_arch = "wasm32")]

use super::{Vfs, VfsError, VfsResult};
use async_trait::async_trait;
use wasm_bindgen::prelude::*;
use wasm_bindgen_futures::JsFuture;
use web_sys::{FileSystemDirectoryHandle, FileSystemFileHandle, FileSystemWritableFileStream};

/// VFS backed by the browser's Origin Private File System.
///
/// OPFS provides a private, sandboxed file system per origin that persists
/// across page reloads. This gives LOGOS the same persistence semantics
/// in the browser as native apps have on disk.
#[derive(Clone)]
pub struct OpfsVfs {
    root: FileSystemDirectoryHandle,
}

impl OpfsVfs {
    /// Create a new OPFS VFS rooted at the origin's private filesystem.
    ///
    /// This requires a secure context (HTTPS or localhost).
    pub async fn new() -> VfsResult<Self> {
        let window = web_sys::window()
            .ok_or_else(|| VfsError::PermissionDenied("No window object".into()))?;
        let navigator = window.navigator();
        let storage = navigator.storage();

        let promise = storage.get_directory();
        let root = JsFuture::from(promise)
            .await
            .map_err(|e| VfsError::PermissionDenied(format!("OPFS access denied: {:?}", e)))?
            .unchecked_into::<FileSystemDirectoryHandle>();

        Ok(Self { root })
    }

    /// Navigate to a directory, optionally creating intermediate directories.
    async fn get_dir(&self, path: &str, create: bool) -> VfsResult<FileSystemDirectoryHandle> {
        let path = path.trim_start_matches('/');
        if path.is_empty() {
            return Ok(self.root.clone());
        }

        let mut current = self.root.clone();
        for segment in path.split('/') {
            if segment.is_empty() || segment == "." {
                continue;
            }
            if segment == ".." {
                // OPFS doesn't allow traversal above root - just skip
                continue;
            }

            let opts = web_sys::FileSystemGetDirectoryOptions::new();
            opts.set_create(create);

            let promise = current.get_directory_handle_with_options(segment, &opts);
            current = JsFuture::from(promise)
                .await
                .map_err(|e| {
                    if !create {
                        VfsError::NotFound(format!("Directory not found: {}", path))
                    } else {
                        VfsError::IoError(std::io::Error::new(
                            std::io::ErrorKind::Other,
                            format!("Failed to get directory: {:?}", e),
                        ))
                    }
                })?
                .unchecked_into::<FileSystemDirectoryHandle>();
        }

        Ok(current)
    }

    /// Get file handle at path.
    async fn get_file(&self, path: &str, create: bool) -> VfsResult<FileSystemFileHandle> {
        let path = path.trim_start_matches('/');

        // Split path into parent directory and filename
        let (parent_path, filename) = match path.rfind('/') {
            Some(idx) => (&path[..idx], &path[idx + 1..]),
            None => ("", path),
        };

        // Get parent directory
        let parent = self.get_dir(parent_path, create).await?;

        // Get file handle
        let opts = web_sys::FileSystemGetFileOptions::new();
        opts.set_create(create);

        let promise = parent.get_file_handle_with_options(filename, &opts);
        JsFuture::from(promise)
            .await
            .map(|v| v.unchecked_into::<FileSystemFileHandle>())
            .map_err(|_| VfsError::NotFound(path.into()))
    }

    /// Extract parent path from a file path.
    fn parent_path(path: &str) -> Option<&str> {
        let path = path.trim_start_matches('/');
        path.rfind('/').map(|idx| &path[..idx])
    }
}

#[async_trait(?Send)]
impl Vfs for OpfsVfs {
    async fn read(&self, path: &str) -> VfsResult<Vec<u8>> {
        let file_handle = self.get_file(path, false).await?;

        let promise = file_handle.get_file();
        let file: web_sys::File = JsFuture::from(promise)
            .await
            .map_err(|_| VfsError::NotFound(path.into()))?
            .unchecked_into();

        let promise = file.array_buffer();
        let array_buffer = JsFuture::from(promise)
            .await
            .map_err(|e| {
                VfsError::IoError(std::io::Error::new(
                    std::io::ErrorKind::Other,
                    format!("Read failed: {:?}", e),
                ))
            })?;

        let uint8_array = js_sys::Uint8Array::new(&array_buffer);
        Ok(uint8_array.to_vec())
    }

    async fn read_to_string(&self, path: &str) -> VfsResult<String> {
        let bytes = self.read(path).await?;
        String::from_utf8(bytes).map_err(|e| VfsError::SerializationError(e.to_string()))
    }

    async fn write(&self, path: &str, contents: &[u8]) -> VfsResult<()> {
        // Ensure parent directory exists
        if let Some(parent) = Self::parent_path(path) {
            self.create_dir_all(parent).await?;
        }

        let file_handle = self.get_file(path, true).await?;

        // Create writable stream (truncates by default)
        let promise = file_handle.create_writable();
        let writable: FileSystemWritableFileStream = JsFuture::from(promise)
            .await
            .map_err(|e| VfsError::PermissionDenied(format!("Create writable failed: {:?}", e)))?
            .unchecked_into();

        // Write content
        let data = js_sys::Uint8Array::from(contents);
        let promise = writable.write_with_buffer_source(&data)
            .map_err(|e| VfsError::IoError(std::io::Error::new(
                std::io::ErrorKind::Other,
                format!("Write setup failed: {:?}", e),
            )))?;
        JsFuture::from(promise).await.map_err(|e| {
            VfsError::IoError(std::io::Error::new(
                std::io::ErrorKind::Other,
                format!("Write failed: {:?}", e),
            ))
        })?;

        // Close stream
        let promise = writable.close();
        JsFuture::from(promise).await.map_err(|e| {
            VfsError::IoError(std::io::Error::new(
                std::io::ErrorKind::Other,
                format!("Close failed: {:?}", e),
            ))
        })?;

        Ok(())
    }

    async fn append(&self, path: &str, contents: &[u8]) -> VfsResult<()> {
        // OPFS doesn't have native append - read existing, concat, write
        let existing = match self.read(path).await {
            Ok(data) => data,
            Err(VfsError::NotFound(_)) => Vec::new(),
            Err(e) => return Err(e),
        };

        let mut combined = existing;
        combined.extend_from_slice(contents);
        self.write(path, &combined).await
    }

    async fn exists(&self, path: &str) -> VfsResult<bool> {
        match self.get_file(path, false).await {
            Ok(_) => Ok(true),
            Err(VfsError::NotFound(_)) => Ok(false),
            Err(e) => Err(e),
        }
    }

    async fn remove(&self, path: &str) -> VfsResult<()> {
        let path = path.trim_start_matches('/');

        // Split into parent and filename
        let (parent_path, filename) = match path.rfind('/') {
            Some(idx) => (&path[..idx], &path[idx + 1..]),
            None => ("", path),
        };

        let parent = self.get_dir(parent_path, false).await?;

        let promise = parent.remove_entry(filename);
        JsFuture::from(promise)
            .await
            .map_err(|_| VfsError::NotFound(path.into()))?;

        Ok(())
    }

    async fn create_dir_all(&self, path: &str) -> VfsResult<()> {
        self.get_dir(path, true).await?;
        Ok(())
    }

    async fn rename(&self, from: &str, to: &str) -> VfsResult<()> {
        // OPFS doesn't have native rename - read, write, delete
        let content = self.read(from).await?;
        self.write(to, &content).await?;
        self.remove(from).await?;
        Ok(())
    }
}

```

---

### Go-like Concurrency Primitives

**File:** `logos_core/src/concurrency.rs`

Green thread and channel primitives. TaskHandle<T> wraps JoinHandle with is_finished()/abort(). Pipe<T>::new(cap) creates bounded mpsc channel split into PipeSender/PipeReceiver. spawn() for ergonomic task creation. check_preemption() for 10ms cooperative yielding in long loops.

```rust
//! Phase 54: Go-like Concurrency Primitives
//!
//! This module provides green thread primitives for LOGOS:
//! - `TaskHandle<T>`: Wrapper around tokio::task::JoinHandle with abort/completion tracking
//! - `Pipe<T>`: Bounded channel with sender/receiver split (Go-like channels)
//! - `check_preemption()`: Cooperative yielding for long-running computations
//! - `spawn()`: Ergonomic task spawning

use std::cell::RefCell;
use std::future::Future;
use std::pin::Pin;
use std::task::{Context, Poll};
use std::time::Instant;

use tokio::sync::mpsc;
use tokio::task::JoinHandle;

// Re-export error types for ergonomic API
pub use tokio::sync::mpsc::error::{SendError, TryRecvError, TrySendError};
pub use tokio::task::JoinError;

// =============================================================================
// TaskHandle<T> - Wrapper around JoinHandle with abort/completion tracking
// =============================================================================

/// Handle to a spawned async task.
///
/// Wraps `tokio::task::JoinHandle<T>` with a LOGOS-friendly API.
///
/// # Example
/// ```ignore
/// let handle = spawn(async { expensive_computation() });
/// // Do other work...
/// if handle.is_finished() {
///     let result = handle.await?;
/// }
/// ```
pub struct TaskHandle<T> {
    inner: JoinHandle<T>,
}

impl<T> TaskHandle<T> {
    /// Create a new TaskHandle wrapping a JoinHandle.
    pub(crate) fn new(handle: JoinHandle<T>) -> Self {
        Self { inner: handle }
    }

    /// Check if the task has completed.
    ///
    /// Returns `true` if the task has finished (successfully or with error),
    /// `false` if still running.
    pub fn is_finished(&self) -> bool {
        self.inner.is_finished()
    }

    /// Abort the task.
    ///
    /// The task will be cancelled at the next await point.
    /// If the task has already completed, this has no effect.
    pub fn abort(&self) {
        self.inner.abort();
    }
}

impl<T> Future for TaskHandle<T> {
    type Output = Result<T, JoinError>;

    fn poll(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {
        Pin::new(&mut self.inner).poll(cx)
    }
}

// =============================================================================
// spawn() - Ergonomic task spawning
// =============================================================================

/// Spawn an async task and return a handle to it.
///
/// This is a thin wrapper around `tokio::spawn` that returns
/// a `TaskHandle<T>` for LOGOS codegen.
///
/// # Example
/// ```ignore
/// let handle = spawn(async {
///     expensive_computation().await
/// });
/// let result = handle.await?;
/// ```
pub fn spawn<F, T>(future: F) -> TaskHandle<T>
where
    F: Future<Output = T> + Send + 'static,
    T: Send + 'static,
{
    TaskHandle::new(tokio::spawn(future))
}

// =============================================================================
// Pipe<T> - Bounded channel with sender/receiver split
// =============================================================================

/// A bounded channel for communication between tasks.
///
/// `Pipe<T>` provides Go-like channel semantics with a capacity limit.
/// Unlike Go, sender and receiver are split for Rust's ownership model.
///
/// # Example
/// ```ignore
/// let (tx, rx) = Pipe::<String>::new(16);
///
/// spawn(async move {
///     tx.send("hello".to_string()).await.unwrap();
/// });
///
/// let msg = rx.recv().await;
/// ```
pub struct Pipe<T>(std::marker::PhantomData<T>);

impl<T> Pipe<T> {
    /// Create a new bounded channel with the specified capacity.
    ///
    /// Returns a (Sender, Receiver) pair.
    pub fn new(capacity: usize) -> (PipeSender<T>, PipeReceiver<T>) {
        let (tx, rx) = mpsc::channel(capacity);
        (PipeSender { inner: tx }, PipeReceiver { inner: rx })
    }
}

/// Sender half of a Pipe.
///
/// Can be cloned to create multiple senders.
#[derive(Clone)]
pub struct PipeSender<T> {
    inner: mpsc::Sender<T>,
}

impl<T> PipeSender<T> {
    /// Send a value asynchronously.
    ///
    /// Waits if the channel is full. Returns error if all receivers dropped.
    pub async fn send(&self, val: T) -> Result<(), SendError<T>> {
        self.inner.send(val).await
    }

    /// Try to send a value without blocking.
    ///
    /// Returns immediately with an error if the channel is full or closed.
    pub fn try_send(&self, val: T) -> Result<(), TrySendError<T>> {
        self.inner.try_send(val)
    }

    /// Check if the receiver has been dropped.
    pub fn is_closed(&self) -> bool {
        self.inner.is_closed()
    }

    /// Get the current capacity of the channel.
    pub fn capacity(&self) -> usize {
        self.inner.capacity()
    }
}

/// Receiver half of a Pipe.
///
/// Cannot be cloned - only one receiver per channel.
pub struct PipeReceiver<T> {
    inner: mpsc::Receiver<T>,
}

impl<T> PipeReceiver<T> {
    /// Receive a value asynchronously.
    ///
    /// Returns `None` if all senders have been dropped and the channel is empty.
    pub async fn recv(&mut self) -> Option<T> {
        self.inner.recv().await
    }

    /// Try to receive a value without blocking.
    ///
    /// Returns immediately with an error if the channel is empty or closed.
    pub fn try_recv(&mut self) -> Result<T, TryRecvError> {
        self.inner.try_recv()
    }

    /// Close the receiver.
    ///
    /// Prevents further values from being sent. Existing values can still be received.
    pub fn close(&mut self) {
        self.inner.close()
    }
}

// =============================================================================
// check_preemption() - The "Nanny" function for cooperative scheduling
// =============================================================================

/// Preemption threshold: yield if more than 10ms since last yield
const PREEMPTION_THRESHOLD_MS: u128 = 10;

thread_local! {
    static LAST_YIELD: RefCell<Instant> = RefCell::new(Instant::now());
}

/// Reset the preemption timer (useful for tests).
pub fn reset_preemption_timer() {
    LAST_YIELD.with(|cell| {
        *cell.borrow_mut() = Instant::now();
    });
}

/// Check if we should yield to other tasks.
///
/// This is the "Nanny" function for cooperative multitasking.
/// If more than 10ms have elapsed since the last yield point,
/// yields control via `tokio::task::yield_now()` and resets the timer.
///
/// # Usage
///
/// Insert calls to `check_preemption().await` in long-running loops
/// to ensure fair scheduling with other async tasks.
///
/// ```ignore
/// for i in 0..1_000_000 {
///     heavy_computation(i);
///     check_preemption().await;  // Yield if >10ms elapsed
/// }
/// ```
pub async fn check_preemption() {
    let should_yield = LAST_YIELD.with(|cell| {
        let last = *cell.borrow();
        last.elapsed().as_millis() >= PREEMPTION_THRESHOLD_MS
    });

    if should_yield {
        tokio::task::yield_now().await;
        LAST_YIELD.with(|cell| {
            *cell.borrow_mut() = Instant::now();
        });
    }
}

// =============================================================================
// Tests - TDD: These define the expected behavior
// =============================================================================

#[cfg(test)]
mod tests {
    use super::*;
    use std::time::Duration;

    // -------------------------------------------------------------------------
    // TaskHandle tests
    // -------------------------------------------------------------------------

    #[tokio::test]
    async fn test_task_handle_creation_and_completion() {
        let handle = spawn(async { 42 });

        // Task should complete quickly
        tokio::time::sleep(Duration::from_millis(10)).await;
        assert!(handle.is_finished());
    }

    #[tokio::test]
    async fn test_task_handle_await_result() {
        let handle = spawn(async { 42 });
        let result = handle.await;
        assert_eq!(result.unwrap(), 42);
    }

    #[tokio::test]
    async fn test_task_handle_is_finished_initially_false() {
        let handle = spawn(async {
            tokio::time::sleep(Duration::from_millis(100)).await;
            42
        });

        // Should not be finished immediately
        assert!(!handle.is_finished());

        // Cleanup
        handle.abort();
    }

    #[tokio::test]
    async fn test_task_handle_abort() {
        let handle = spawn(async {
            tokio::time::sleep(Duration::from_secs(10)).await;
            42
        });

        handle.abort();

        // Wait a bit for abort to take effect
        tokio::time::sleep(Duration::from_millis(10)).await;
        assert!(handle.is_finished());

        // Awaiting should return JoinError
        let result = handle.await;
        assert!(result.is_err());
    }

    #[tokio::test]
    async fn test_spawn_returns_task_handle() {
        let handle: TaskHandle<i32> = spawn(async { 1 + 1 });
        let result = handle.await.unwrap();
        assert_eq!(result, 2);
    }

    #[tokio::test]
    async fn test_spawn_with_captured_values() {
        let x = 10;
        let y = 20;
        let handle = spawn(async move { x + y });
        let result = handle.await.unwrap();
        assert_eq!(result, 30);
    }

    #[tokio::test]
    async fn test_spawn_with_complex_return_type() {
        let handle = spawn(async { vec![1, 2, 3] });
        let result = handle.await.unwrap();
        assert_eq!(result, vec![1, 2, 3]);
    }

    // -------------------------------------------------------------------------
    // Pipe tests
    // -------------------------------------------------------------------------

    #[tokio::test]
    async fn test_pipe_send_recv() {
        let (tx, mut rx) = Pipe::<i32>::new(16);

        tx.send(42).await.unwrap();
        let received = rx.recv().await;

        assert_eq!(received, Some(42));
    }

    #[tokio::test]
    async fn test_pipe_recv_none_when_closed() {
        let (tx, mut rx) = Pipe::<i32>::new(16);

        drop(tx);

        let received = rx.recv().await;
        assert_eq!(received, None);
    }

    #[tokio::test]
    async fn test_pipe_try_send_success() {
        let (tx, mut rx) = Pipe::<i32>::new(16);

        assert!(tx.try_send(42).is_ok());
        assert_eq!(rx.recv().await, Some(42));
    }

    #[tokio::test]
    async fn test_pipe_try_send_full() {
        let (tx, _rx) = Pipe::<i32>::new(1);

        assert!(tx.try_send(1).is_ok());
        // Channel is now full
        assert!(matches!(tx.try_send(2), Err(TrySendError::Full(_))));
    }

    #[tokio::test]
    async fn test_pipe_try_recv_empty() {
        let (_tx, mut rx) = Pipe::<i32>::new(16);

        // Channel is empty
        assert!(matches!(rx.try_recv(), Err(TryRecvError::Empty)));
    }

    #[tokio::test]
    async fn test_pipe_sender_clone() {
        let (tx, mut rx) = Pipe::<i32>::new(16);
        let tx2 = tx.clone();

        tx.send(1).await.unwrap();
        tx2.send(2).await.unwrap();

        assert_eq!(rx.recv().await, Some(1));
        assert_eq!(rx.recv().await, Some(2));
    }

    #[tokio::test]
    async fn test_pipe_is_closed() {
        let (tx, rx) = Pipe::<i32>::new(16);

        assert!(!tx.is_closed());
        drop(rx);
        assert!(tx.is_closed());
    }

    #[tokio::test]
    async fn test_pipe_receiver_close() {
        let (tx, mut rx) = Pipe::<i32>::new(16);

        rx.close();

        // Sender should now fail
        assert!(tx.send(42).await.is_err());
    }

    // -------------------------------------------------------------------------
    // check_preemption tests
    // -------------------------------------------------------------------------

    #[tokio::test]
    async fn test_check_preemption_no_yield_initially() {
        // Reset timer
        reset_preemption_timer();

        // Should not yield if called immediately
        let start = Instant::now();
        check_preemption().await;
        let elapsed = start.elapsed();

        // Should be nearly instant (no actual yield)
        assert!(elapsed.as_millis() < 5);
    }

    #[tokio::test]
    async fn test_check_preemption_yields_after_threshold() {
        // Reset timer
        reset_preemption_timer();

        // Simulate 15ms of computation
        std::thread::sleep(Duration::from_millis(15));

        // This should yield
        check_preemption().await;

        // Timer should be reset - next call should not yield
        let start = Instant::now();
        check_preemption().await;
        let elapsed = start.elapsed();
        assert!(elapsed.as_millis() < 5);
    }

    // -------------------------------------------------------------------------
    // Integration tests
    // -------------------------------------------------------------------------

    #[tokio::test]
    async fn test_spawn_with_pipe_communication() {
        let (tx, mut rx) = Pipe::<String>::new(16);

        let producer = spawn(async move {
            for i in 0..5 {
                tx.send(format!("message {}", i)).await.unwrap();
                check_preemption().await;
            }
        });

        let mut received = Vec::new();
        while let Some(msg) = rx.recv().await {
            received.push(msg);
        }

        producer.await.unwrap();
        assert_eq!(received.len(), 5);
    }

    #[tokio::test]
    async fn test_multiple_producers_single_consumer() {
        let (tx, mut rx) = Pipe::<i32>::new(32);

        let tx1 = tx.clone();
        let tx2 = tx.clone();
        drop(tx); // Drop original

        let p1 = spawn(async move {
            for i in 0..10 {
                tx1.send(i).await.unwrap();
            }
        });

        let p2 = spawn(async move {
            for i in 10..20 {
                tx2.send(i).await.unwrap();
            }
        });

        // Wait for producers
        p1.await.unwrap();
        p2.await.unwrap();

        // Collect all messages
        let mut values = Vec::new();
        while let Some(v) = rx.recv().await {
            values.push(v);
        }

        values.sort();
        assert_eq!(values, (0..20).collect::<Vec<_>>());
    }

    #[tokio::test]
    async fn test_task_abort_with_pipe() {
        let (tx, mut rx) = Pipe::<i32>::new(16);

        let producer = spawn(async move {
            for i in 0.. {
                if tx.send(i).await.is_err() {
                    break;
                }
                check_preemption().await;
            }
        });

        // Receive a few messages
        for _ in 0..5 {
            rx.recv().await;
        }

        // Abort the producer
        producer.abort();

        // Close receiver - this will cause sender to fail
        rx.close();

        // Ensure task was aborted
        let result = producer.await;
        assert!(result.is_err());
    }
}

```

---


## Logos Verification Crate

**Location:** `logos_verification/`

Z3-based static verification for LOGOS Assert statements. Premium feature requiring Pro+ license.

### Architecture

- **Smart Full Mapping**: Int/Bool → direct Z3 sorts; Object → uninterpreted sort; Predicates/Modals/Temporals → Apply (uninterpreted functions)
- Z3 reasons structurally without semantic knowledge
- Validity check: P is valid iff NOT(P) is UNSAT

### Verification Crate Entry

**File:** `logos_verification/src/lib.rs`

Re-exports VerifyExpr, VerifyOp, VerifyType, Verifier, VerificationSession, LicensePlan, LicenseValidator, VerificationError. Smart Full Mapping strategy documentation.

```rust
//! LOGOS Static Verification
//!
//! Z3-based static verification for LOGOS programs.
//! Requires a Pro, Premium, Lifetime, or Enterprise license.
//!
//! # Overview
//!
//! This crate provides compile-time verification of LOGOS assertions using
//! the Z3 SMT solver. It can detect contradictions, prove bounds, and
//! generate counter-examples when verification fails.
//!
//! # Architecture
//!
//! The verification system uses a lightweight IR (Intermediate Representation)
//! to avoid circular dependencies. The main `logos` crate translates its AST
//! into this IR before passing it to the verifier.
//!
//! **Smart Full Mapping Strategy:**
//! - `Int`, `Bool` → direct Z3 sorts
//! - `Object` → uninterpreted sort for entities
//! - Predicates, Modals, Temporals → `Apply` (uninterpreted functions)
//! - Z3 reasons structurally without semantic knowledge
//!
//! # License Requirement
//!
//! Verification is a premium feature. License keys are Stripe subscription IDs
//! (`sub_*` format) validated against `api.logicaffeine.com/validate`.

pub mod error;
pub mod ir;
pub mod license;
pub mod solver;

pub use error::{VerificationError, VerificationErrorKind, VerificationResult};
pub use ir::{VerifyExpr, VerifyOp, VerifyType};
pub use license::{LicensePlan, LicenseValidator};
pub use solver::{Verifier, VerificationSession};

```

---

### Verification IR

**File:** `logos_verification/src/ir.rs`

Lightweight AST for Z3 encoding. VerifyType (Int, Bool, Object), VerifyOp (arithmetic, comparison, logic), VerifyExpr (Int, Bool, Var, Binary, Not, ForAll, Exists, Apply). Convenience methods: eq, gt, lt, gte, lte, neq, and, or, implies. Apply is the 'catch-all' for uninterpreted functions.

```rust
//! Verification IR (Intermediate Representation)
//!
//! A lightweight AST for Z3 verification that decouples from the main LOGOS AST.
//! This avoids circular dependencies: logos depends on logos_verification,
//! so logos_verification cannot depend on logos.
//!
//! **Strategy: Smart Full Mapping with Uninterpreted Functions**
//!
//! Complex types (Modals, Temporals, Predicates) become uninterpreted functions.
//! Z3 can reason about their structure without semantic understanding.
//! E.g., if `Possible(A) -> Possible(B)` and `Possible(A)`, Z3 deduces `Possible(B)`.

/// Type declarations for verification variables.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum VerifyType {
    /// Integer type (maps to Z3 Int sort)
    Int,
    /// Boolean type (maps to Z3 Bool sort)
    Bool,
    /// Opaque object type for entities (maps to uninterpreted sort)
    Object,
}

/// Binary operations in the verification IR.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum VerifyOp {
    // Arithmetic (Int -> Int)
    Add,
    Sub,
    Mul,
    Div,

    // Comparison (Int -> Bool)
    Eq,
    Neq,
    Gt,
    Lt,
    Gte,
    Lte,

    // Logic (Bool -> Bool)
    And,
    Or,
    Implies,
}

/// Expression AST for verification.
///
/// This IR is designed to be easily encodable into Z3 ASTs.
#[derive(Debug, Clone, PartialEq)]
pub enum VerifyExpr {
    /// Integer literal
    Int(i64),

    /// Boolean literal
    Bool(bool),

    /// Variable reference
    Var(String),

    /// Binary operation
    Binary {
        op: VerifyOp,
        left: Box<VerifyExpr>,
        right: Box<VerifyExpr>,
    },

    /// Logical negation
    Not(Box<VerifyExpr>),

    /// Universal quantifier: forall x: T. P(x)
    ForAll {
        vars: Vec<(String, VerifyType)>,
        body: Box<VerifyExpr>,
    },

    /// Existential quantifier: exists x: T. P(x)
    Exists {
        vars: Vec<(String, VerifyType)>,
        body: Box<VerifyExpr>,
    },

    /// Uninterpreted function application (the "catch-all")
    ///
    /// Used for predicates, modals, temporals, etc. that we can't
    /// directly encode semantically. Z3 treats these as opaque functions
    /// and reasons about them structurally.
    ///
    /// Examples:
    /// - `Mortal(socrates)` -> `Apply { name: "Mortal", args: [Var("socrates")] }`
    /// - `Possible(P)` -> `Apply { name: "Possible", args: [P] }`
    Apply {
        name: String,
        args: Vec<VerifyExpr>,
    },
}

impl VerifyExpr {
    /// Create a variable reference.
    pub fn var(name: impl Into<String>) -> Self {
        VerifyExpr::Var(name.into())
    }

    /// Create an integer literal.
    pub fn int(n: i64) -> Self {
        VerifyExpr::Int(n)
    }

    /// Create a boolean literal.
    pub fn bool(b: bool) -> Self {
        VerifyExpr::Bool(b)
    }

    /// Create a binary operation.
    pub fn binary(op: VerifyOp, left: VerifyExpr, right: VerifyExpr) -> Self {
        VerifyExpr::Binary {
            op,
            left: Box::new(left),
            right: Box::new(right),
        }
    }

    /// Create a negation.
    pub fn not(expr: VerifyExpr) -> Self {
        VerifyExpr::Not(Box::new(expr))
    }

    /// Create an uninterpreted function application.
    pub fn apply(name: impl Into<String>, args: Vec<VerifyExpr>) -> Self {
        VerifyExpr::Apply {
            name: name.into(),
            args,
        }
    }

    /// Create a universal quantifier.
    pub fn forall(vars: Vec<(String, VerifyType)>, body: VerifyExpr) -> Self {
        VerifyExpr::ForAll {
            vars,
            body: Box::new(body),
        }
    }

    /// Create an existential quantifier.
    pub fn exists(vars: Vec<(String, VerifyType)>, body: VerifyExpr) -> Self {
        VerifyExpr::Exists {
            vars,
            body: Box::new(body),
        }
    }

    // Convenience methods for common operations

    /// x == y
    pub fn eq(left: VerifyExpr, right: VerifyExpr) -> Self {
        Self::binary(VerifyOp::Eq, left, right)
    }

    /// x > y
    pub fn gt(left: VerifyExpr, right: VerifyExpr) -> Self {
        Self::binary(VerifyOp::Gt, left, right)
    }

    /// x < y
    pub fn lt(left: VerifyExpr, right: VerifyExpr) -> Self {
        Self::binary(VerifyOp::Lt, left, right)
    }

    /// x >= y
    pub fn gte(left: VerifyExpr, right: VerifyExpr) -> Self {
        Self::binary(VerifyOp::Gte, left, right)
    }

    /// x <= y
    pub fn lte(left: VerifyExpr, right: VerifyExpr) -> Self {
        Self::binary(VerifyOp::Lte, left, right)
    }

    /// x != y
    pub fn neq(left: VerifyExpr, right: VerifyExpr) -> Self {
        Self::binary(VerifyOp::Neq, left, right)
    }

    /// x && y
    pub fn and(left: VerifyExpr, right: VerifyExpr) -> Self {
        Self::binary(VerifyOp::And, left, right)
    }

    /// x || y
    pub fn or(left: VerifyExpr, right: VerifyExpr) -> Self {
        Self::binary(VerifyOp::Or, left, right)
    }

    /// x -> y (implication)
    pub fn implies(left: VerifyExpr, right: VerifyExpr) -> Self {
        Self::binary(VerifyOp::Implies, left, right)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_verify_expr_construction() {
        // Test that we can construct expressions
        let x = VerifyExpr::var("x");
        let five = VerifyExpr::int(5);
        let ten = VerifyExpr::int(10);

        // x > 5
        let gt = VerifyExpr::gt(x.clone(), five);
        assert!(matches!(gt, VerifyExpr::Binary { op: VerifyOp::Gt, .. }));

        // x == 10
        let eq = VerifyExpr::eq(x.clone(), ten);
        assert!(matches!(eq, VerifyExpr::Binary { op: VerifyOp::Eq, .. }));
    }

    #[test]
    fn test_uninterpreted_function() {
        // Mortal(x)
        let mortal_x = VerifyExpr::apply("Mortal", vec![VerifyExpr::var("x")]);
        assert!(matches!(mortal_x, VerifyExpr::Apply { name, args } if name == "Mortal" && args.len() == 1));
    }

    #[test]
    fn test_implication() {
        // Mortal(x) -> Human(x)
        let mortal = VerifyExpr::apply("Mortal", vec![VerifyExpr::var("x")]);
        let human = VerifyExpr::apply("Human", vec![VerifyExpr::var("x")]);
        let impl_expr = VerifyExpr::implies(mortal, human);

        assert!(matches!(impl_expr, VerifyExpr::Binary { op: VerifyOp::Implies, .. }));
    }

    #[test]
    fn test_quantifier() {
        // forall x: Object. Mortal(x) -> Human(x)
        let body = VerifyExpr::implies(
            VerifyExpr::apply("Mortal", vec![VerifyExpr::var("x")]),
            VerifyExpr::apply("Human", vec![VerifyExpr::var("x")]),
        );
        let forall = VerifyExpr::forall(
            vec![("x".to_string(), VerifyType::Object)],
            body,
        );

        assert!(matches!(forall, VerifyExpr::ForAll { vars, .. } if vars.len() == 1));
    }
}

```

---

### Z3 Solver Wrapper

**File:** `logos_verification/src/solver.rs`

Verifier struct with check_bool(), check_int_greater_than(), check_int_less_than(), check_int_equals(). VerificationSession for incremental constraint building with declare(), assume(), verify(). verify_with_binding() for scoped refinement type checking. Encoder converts VerifyExpr to Z3 ASTs.

```rust
//! Z3 solver wrapper for LOGOS verification.

use std::collections::HashMap;

use z3::ast::{Ast, Bool, Dynamic, Int};
use z3::{Config, Context, FuncDecl, SatResult, Solver, Sort};

use crate::error::{CounterExample, VerificationError, VerificationResult};
use crate::ir::{VerifyExpr, VerifyOp, VerifyType};

/// The Z3-based verifier.
pub struct Verifier {
    cfg: Config,
}

impl Verifier {
    /// Create a new verifier.
    pub fn new() -> Self {
        let mut cfg = Config::new();
        // Set a reasonable timeout (10 seconds)
        cfg.set_param_value("timeout", "10000");
        Self { cfg }
    }

    /// Check if a boolean value is valid (i.e., always true).
    ///
    /// This is the most basic verification: `true` is valid, `false` is not.
    pub fn check_bool(&self, value: bool) -> VerificationResult {
        let ctx = Context::new(&self.cfg);
        let solver = Solver::new(&ctx);

        let assertion = Bool::from_bool(&ctx, value);

        // To prove P is valid: check if NOT(P) is UNSAT
        // If NOT(P) is unsatisfiable, then P is always true
        solver.assert(&assertion.not());

        match solver.check() {
            SatResult::Unsat => Ok(()), // NOT(P) is impossible -> P is valid
            SatResult::Sat => {
                // NOT(P) is satisfiable -> P is not always true
                Err(VerificationError::contradiction(
                    "The assertion is not always true.",
                    None,
                ))
            }
            SatResult::Unknown => Err(VerificationError::solver_unknown()),
        }
    }

    /// Verify that an integer variable satisfies a constraint.
    ///
    /// Given a value and a bound, checks if `value > bound` or `value < bound` etc.
    pub fn check_int_greater_than(&self, value: i64, bound: i64) -> VerificationResult {
        let ctx = Context::new(&self.cfg);
        let solver = Solver::new(&ctx);

        let v = z3::ast::Int::from_i64(&ctx, value);
        let b = z3::ast::Int::from_i64(&ctx, bound);
        let assertion = v.gt(&b);

        // To prove P is valid: check if NOT(P) is UNSAT
        solver.assert(&assertion.not());

        match solver.check() {
            SatResult::Unsat => Ok(()),
            SatResult::Sat => {
                Err(VerificationError::bounds_violation(
                    "value",
                    format!("> {}", bound),
                    format!("{}", value),
                ))
            }
            SatResult::Unknown => Err(VerificationError::solver_unknown()),
        }
    }

    /// Verify that an integer variable satisfies a constraint.
    pub fn check_int_less_than(&self, value: i64, bound: i64) -> VerificationResult {
        let ctx = Context::new(&self.cfg);
        let solver = Solver::new(&ctx);

        let v = z3::ast::Int::from_i64(&ctx, value);
        let b = z3::ast::Int::from_i64(&ctx, bound);
        let assertion = v.lt(&b);

        solver.assert(&assertion.not());

        match solver.check() {
            SatResult::Unsat => Ok(()),
            SatResult::Sat => Err(VerificationError::bounds_violation(
                "value",
                format!("< {}", bound),
                format!("{}", value),
            )),
            SatResult::Unknown => Err(VerificationError::solver_unknown()),
        }
    }

    /// Verify that two integer values are equal.
    pub fn check_int_equals(&self, left: i64, right: i64) -> VerificationResult {
        let ctx = Context::new(&self.cfg);
        let solver = Solver::new(&ctx);

        let l = z3::ast::Int::from_i64(&ctx, left);
        let r = z3::ast::Int::from_i64(&ctx, right);
        let assertion = l._eq(&r);

        solver.assert(&assertion.not());

        match solver.check() {
            SatResult::Unsat => Ok(()),
            SatResult::Sat => Err(VerificationError::contradiction(
                format!("{} is not equal to {}", left, right),
                Some(CounterExample {
                    assignments: vec![
                        ("left".to_string(), format!("{}", left)),
                        ("right".to_string(), format!("{}", right)),
                    ],
                }),
            )),
            SatResult::Unknown => Err(VerificationError::solver_unknown()),
        }
    }

    /// Create a verification context for more complex proofs.
    pub fn context(&self) -> VerificationContext {
        let ctx = Context::new(&self.cfg);
        VerificationContext::new(ctx)
    }
}

impl Default for Verifier {
    fn default() -> Self {
        Self::new()
    }
}

/// A verification context for building up constraints incrementally.
pub struct VerificationContext {
    ctx: Context,
}

impl VerificationContext {
    fn new(ctx: Context) -> Self {
        Self { ctx }
    }

    /// Get the underlying Z3 context.
    pub fn z3_context(&self) -> &Context {
        &self.ctx
    }

    /// Create a new solver for this context.
    pub fn solver(&self) -> Solver {
        Solver::new(&self.ctx)
    }

    /// Create a boolean constant.
    pub fn bool_val(&self, value: bool) -> Bool {
        Bool::from_bool(&self.ctx, value)
    }

    /// Create an integer constant.
    pub fn int_val(&self, value: i64) -> z3::ast::Int {
        z3::ast::Int::from_i64(&self.ctx, value)
    }

    /// Create a named boolean variable.
    pub fn bool_var(&self, name: &str) -> Bool {
        Bool::new_const(&self.ctx, name)
    }

    /// Create a named integer variable.
    pub fn int_var(&self, name: &str) -> z3::ast::Int {
        z3::ast::Int::new_const(&self.ctx, name)
    }

    /// Check if an assertion is valid (always true).
    pub fn check_valid(&self, solver: &Solver, assertion: &Bool) -> VerificationResult {
        solver.push();
        solver.assert(&assertion.not());

        let result = match solver.check() {
            SatResult::Unsat => Ok(()),
            SatResult::Sat => {
                // Counter-example extraction will be implemented in Phase 2
                // when we have variable tracking
                Err(VerificationError::contradiction(
                    "Assertion is not valid",
                    None,
                ))
            }
            SatResult::Unknown => Err(VerificationError::solver_unknown()),
        };

        solver.pop(1);
        result
    }
}

// ============================================================
// Phase 2: Verification Session with IR Support
// ============================================================

/// A verification session for working with the Verification IR.
///
/// This provides a higher-level API that works with `VerifyExpr` instead
/// of raw Z3 types, making it suitable for use from the main logos crate.
///
/// Each verification call creates a fresh Z3 context to avoid lifetime issues.
pub struct VerificationSession {
    vars: HashMap<String, VerifyType>,
    assumptions: Vec<VerifyExpr>,
}

impl VerificationSession {
    /// Create a new verification session.
    pub fn new() -> Self {
        Self {
            vars: HashMap::new(),
            assumptions: Vec::new(),
        }
    }

    /// Declare a variable with a type.
    pub fn declare(&mut self, name: &str, ty: VerifyType) {
        self.vars.insert(name.to_string(), ty);
    }

    /// Add an assumption (constraint).
    pub fn assume(&mut self, expr: &VerifyExpr) {
        self.assumptions.push(expr.clone());
    }

    /// Verify a predicate with a temporary variable binding.
    /// Used for refinement type checking.
    ///
    /// This creates a scoped context where `var_name = value` is assumed,
    /// then verifies that `predicate` holds.
    pub fn verify_with_binding(
        &self,
        var_name: &str,
        var_type: VerifyType,
        value: &VerifyExpr,
        predicate: &VerifyExpr,
    ) -> VerificationResult {
        // Create a fresh Z3 context
        let mut cfg = Config::new();
        cfg.set_param_value("timeout", "10000");
        let ctx = Context::new(&cfg);
        let solver = Solver::new(&ctx);

        // Copy existing vars and add the bound variable
        let mut vars = self.vars.clone();
        vars.insert(var_name.to_string(), var_type);

        let encoder = Encoder::new(&ctx, &vars);

        // Add all existing assumptions
        for assumption in &self.assumptions {
            let ast = encoder.encode(assumption);
            if let Some(b) = ast.as_bool() {
                solver.assert(&b);
            }
        }

        // Add the binding: var_name == value
        let binding = VerifyExpr::eq(
            VerifyExpr::var(var_name),
            value.clone(),
        );
        let binding_ast = encoder.encode(&binding);
        if let Some(b) = binding_ast.as_bool() {
            solver.assert(&b);
        }

        // Verify the predicate
        let pred_ast = encoder.encode(predicate);
        let assertion = pred_ast.as_bool().ok_or_else(|| {
            VerificationError::solver_error("Refinement predicate must be boolean")
        })?;

        solver.push();
        solver.assert(&assertion.not());

        let result = match solver.check() {
            SatResult::Unsat => Ok(()),
            SatResult::Sat => Err(VerificationError::refinement_violation(
                var_name,
                "The value does not satisfy the refinement predicate.",
            )),
            SatResult::Unknown => Err(VerificationError::solver_unknown()),
        };

        solver.pop(1);
        result
    }

    /// Verify that an assertion is valid given current assumptions.
    ///
    /// Uses the standard validity check: P is valid iff NOT(P) is unsatisfiable.
    pub fn verify(&self, expr: &VerifyExpr) -> VerificationResult {
        // Create a fresh Z3 context for this verification
        let mut cfg = Config::new();
        cfg.set_param_value("timeout", "10000");
        let ctx = Context::new(&cfg);
        let solver = Solver::new(&ctx);

        // Create an encoder for this context
        let encoder = Encoder::new(&ctx, &self.vars);

        // Add all assumptions
        for assumption in &self.assumptions {
            let ast = encoder.encode(assumption);
            if let Some(b) = ast.as_bool() {
                solver.assert(&b);
            }
        }

        // Encode the assertion we want to verify
        let ast = encoder.encode(expr);
        let assertion = ast.as_bool().ok_or_else(|| {
            VerificationError::solver_error("Assertion must be boolean")
        })?;

        // To prove P is valid: check if NOT(P) is UNSAT
        solver.push();
        solver.assert(&assertion.not());

        let result = match solver.check() {
            SatResult::Unsat => Ok(()),
            SatResult::Sat => {
                Err(VerificationError::contradiction(
                    "Assertion cannot be proven valid",
                    None,
                ))
            }
            SatResult::Unknown => Err(VerificationError::solver_unknown()),
        };

        solver.pop(1);
        result
    }
}

impl Default for VerificationSession {
    fn default() -> Self {
        Self::new()
    }
}

/// Internal encoder that converts VerifyExpr to Z3 AST.
struct Encoder<'ctx> {
    ctx: &'ctx Context,
    vars: &'ctx HashMap<String, VerifyType>,
}

impl<'ctx> Encoder<'ctx> {
    fn new(ctx: &'ctx Context, vars: &'ctx HashMap<String, VerifyType>) -> Self {
        Self { ctx, vars }
    }

    fn encode(&self, expr: &VerifyExpr) -> Dynamic<'ctx> {
        match expr {
            VerifyExpr::Int(n) => Dynamic::from_ast(&Int::from_i64(self.ctx, *n)),
            VerifyExpr::Bool(b) => Dynamic::from_ast(&Bool::from_bool(self.ctx, *b)),

            VerifyExpr::Var(name) => {
                let ty = self.vars.get(name).copied().unwrap_or(VerifyType::Int);
                match ty {
                    VerifyType::Int => Dynamic::from_ast(&Int::new_const(self.ctx, name.as_str())),
                    VerifyType::Bool => Dynamic::from_ast(&Bool::new_const(self.ctx, name.as_str())),
                    VerifyType::Object => {
                        // For Object types, use Int as a placeholder
                        Dynamic::from_ast(&Int::new_const(self.ctx, name.as_str()))
                    }
                }
            }

            VerifyExpr::Binary { op, left, right } => {
                let l = self.encode(left);
                let r = self.encode(right);
                self.encode_binary(op, l, r)
            }

            VerifyExpr::Not(inner) => {
                let i = self.encode(inner);
                if let Some(b) = i.as_bool() {
                    Dynamic::from_ast(&b.not())
                } else {
                    i
                }
            }

            VerifyExpr::Apply { name, args } => {
                self.encode_apply(name, args)
            }

            VerifyExpr::ForAll { vars: _, body } => {
                // Simplified: just encode the body
                self.encode(body)
            }

            VerifyExpr::Exists { vars: _, body } => {
                self.encode(body)
            }
        }
    }

    fn encode_binary(&self, op: &VerifyOp, l: Dynamic<'ctx>, r: Dynamic<'ctx>) -> Dynamic<'ctx> {
        match op {
            // Arithmetic
            VerifyOp::Add => {
                if let (Some(li), Some(ri)) = (l.as_int(), r.as_int()) {
                    Dynamic::from_ast(&(li + ri))
                } else {
                    l
                }
            }
            VerifyOp::Sub => {
                if let (Some(li), Some(ri)) = (l.as_int(), r.as_int()) {
                    Dynamic::from_ast(&(li - ri))
                } else {
                    l
                }
            }
            VerifyOp::Mul => {
                if let (Some(li), Some(ri)) = (l.as_int(), r.as_int()) {
                    Dynamic::from_ast(&(li * ri))
                } else {
                    l
                }
            }
            VerifyOp::Div => {
                if let (Some(li), Some(ri)) = (l.as_int(), r.as_int()) {
                    Dynamic::from_ast(&(li / ri))
                } else {
                    l
                }
            }

            // Comparison
            VerifyOp::Gt => {
                if let (Some(li), Some(ri)) = (l.as_int(), r.as_int()) {
                    Dynamic::from_ast(&li.gt(&ri))
                } else {
                    Dynamic::from_ast(&Bool::from_bool(self.ctx, false))
                }
            }
            VerifyOp::Lt => {
                if let (Some(li), Some(ri)) = (l.as_int(), r.as_int()) {
                    Dynamic::from_ast(&li.lt(&ri))
                } else {
                    Dynamic::from_ast(&Bool::from_bool(self.ctx, false))
                }
            }
            VerifyOp::Gte => {
                if let (Some(li), Some(ri)) = (l.as_int(), r.as_int()) {
                    Dynamic::from_ast(&li.ge(&ri))
                } else {
                    Dynamic::from_ast(&Bool::from_bool(self.ctx, false))
                }
            }
            VerifyOp::Lte => {
                if let (Some(li), Some(ri)) = (l.as_int(), r.as_int()) {
                    Dynamic::from_ast(&li.le(&ri))
                } else {
                    Dynamic::from_ast(&Bool::from_bool(self.ctx, false))
                }
            }

            // Equality
            VerifyOp::Eq => Dynamic::from_ast(&l._eq(&r)),
            VerifyOp::Neq => Dynamic::from_ast(&l._eq(&r).not()),

            // Logic
            VerifyOp::And => {
                if let (Some(lb), Some(rb)) = (l.as_bool(), r.as_bool()) {
                    Dynamic::from_ast(&Bool::and(self.ctx, &[&lb, &rb]))
                } else {
                    Dynamic::from_ast(&Bool::from_bool(self.ctx, false))
                }
            }
            VerifyOp::Or => {
                if let (Some(lb), Some(rb)) = (l.as_bool(), r.as_bool()) {
                    Dynamic::from_ast(&Bool::or(self.ctx, &[&lb, &rb]))
                } else {
                    Dynamic::from_ast(&Bool::from_bool(self.ctx, false))
                }
            }
            VerifyOp::Implies => {
                if let (Some(lb), Some(rb)) = (l.as_bool(), r.as_bool()) {
                    Dynamic::from_ast(&lb.implies(&rb))
                } else {
                    Dynamic::from_ast(&Bool::from_bool(self.ctx, true))
                }
            }
        }
    }

    fn encode_apply(&self, name: &str, args: &[VerifyExpr]) -> Dynamic<'ctx> {
        let int_sort = Sort::int(self.ctx);
        let domain: Vec<&Sort> = args.iter().map(|_| &int_sort).collect();
        let range = Sort::bool(self.ctx);

        let func_decl = FuncDecl::new(self.ctx, name, &domain, &range);

        let encoded_args: Vec<Dynamic> = args.iter().map(|a| self.encode(a)).collect();
        let arg_refs: Vec<&dyn Ast> = encoded_args.iter().map(|a| a as &dyn Ast).collect();

        Dynamic::from_ast(&func_decl.apply(&arg_refs))
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_tautology() {
        let verifier = Verifier::new();
        assert!(verifier.check_bool(true).is_ok());
    }

    #[test]
    fn test_contradiction() {
        let verifier = Verifier::new();
        assert!(verifier.check_bool(false).is_err());
    }

    #[test]
    fn test_int_greater_than_valid() {
        let verifier = Verifier::new();
        assert!(verifier.check_int_greater_than(10, 5).is_ok());
    }

    #[test]
    fn test_int_greater_than_invalid() {
        let verifier = Verifier::new();
        assert!(verifier.check_int_greater_than(3, 5).is_err());
    }

    #[test]
    fn test_int_equals_valid() {
        let verifier = Verifier::new();
        assert!(verifier.check_int_equals(42, 42).is_ok());
    }

    #[test]
    fn test_int_equals_invalid() {
        let verifier = Verifier::new();
        assert!(verifier.check_int_equals(1, 2).is_err());
    }

    #[test]
    fn test_context_api() {
        let verifier = Verifier::new();
        let vctx = verifier.context();
        let solver = vctx.solver();

        // P ∨ ¬P is a tautology
        let p = vctx.bool_var("p");
        let tautology = Bool::or(vctx.z3_context(), &[&p, &p.not()]);

        assert!(vctx.check_valid(&solver, &tautology).is_ok());
    }

    #[test]
    fn test_context_contradiction() {
        let verifier = Verifier::new();
        let vctx = verifier.context();
        let solver = vctx.solver();

        // P ∧ ¬P is a contradiction (not valid)
        let p = vctx.bool_var("p");
        let contradiction = Bool::and(vctx.z3_context(), &[&p, &p.not()]);

        assert!(vctx.check_valid(&solver, &contradiction).is_err());
    }

    // ============================================================
    // Phase 2: VerificationSession Tests
    // ============================================================

    #[test]
    fn test_session_integer_bounds() {
        let mut session = VerificationSession::new();

        // Declare x as Int
        session.declare("x", VerifyType::Int);

        // Assume: x = 10
        session.assume(&VerifyExpr::eq(
            VerifyExpr::var("x"),
            VerifyExpr::int(10),
        ));

        // Verify: x > 5 (should pass)
        let result = session.verify(&VerifyExpr::gt(
            VerifyExpr::var("x"),
            VerifyExpr::int(5),
        ));
        assert!(result.is_ok(), "10 > 5 should be provable");
    }

    #[test]
    fn test_session_integer_contradiction() {
        let mut session = VerificationSession::new();

        // Declare x as Int
        session.declare("x", VerifyType::Int);

        // Assume: x = 10
        session.assume(&VerifyExpr::eq(
            VerifyExpr::var("x"),
            VerifyExpr::int(10),
        ));

        // Verify: x < 5 (should FAIL)
        let result = session.verify(&VerifyExpr::lt(
            VerifyExpr::var("x"),
            VerifyExpr::int(5),
        ));
        assert!(result.is_err(), "10 < 5 should not be provable");
    }

    #[test]
    fn test_session_uninterpreted_functions() {
        let mut session = VerificationSession::new();

        // Declare x as Object
        session.declare("x", VerifyType::Object);

        // Assume: Mortal(x) -> Human(x)
        session.assume(&VerifyExpr::implies(
            VerifyExpr::apply("Mortal", vec![VerifyExpr::var("x")]),
            VerifyExpr::apply("Human", vec![VerifyExpr::var("x")]),
        ));

        // Assume: Mortal(x)
        session.assume(&VerifyExpr::apply("Mortal", vec![VerifyExpr::var("x")]));

        // Verify: Human(x) - Z3 should deduce this structurally
        let result = session.verify(&VerifyExpr::apply("Human", vec![VerifyExpr::var("x")]));
        assert!(result.is_ok(), "Should deduce Human(x) from Mortal(x) and Mortal(x)->Human(x)");
    }

    #[test]
    fn test_session_modal_structural_reasoning() {
        let mut session = VerificationSession::new();

        // Declare A and B as Objects (representing propositions)
        session.declare("A", VerifyType::Object);
        session.declare("B", VerifyType::Object);

        // Assume: Possible(A) -> Possible(B)
        session.assume(&VerifyExpr::implies(
            VerifyExpr::apply("Possible", vec![VerifyExpr::var("A")]),
            VerifyExpr::apply("Possible", vec![VerifyExpr::var("B")]),
        ));

        // Assume: Possible(A)
        session.assume(&VerifyExpr::apply("Possible", vec![VerifyExpr::var("A")]));

        // Verify: Possible(B)
        let result = session.verify(&VerifyExpr::apply("Possible", vec![VerifyExpr::var("B")]));
        assert!(result.is_ok(), "Should deduce Possible(B) from modus ponens");
    }

    #[test]
    fn test_session_arithmetic() {
        let mut session = VerificationSession::new();

        // Declare x and y
        session.declare("x", VerifyType::Int);
        session.declare("y", VerifyType::Int);

        // Assume: x = 5, y = 3
        session.assume(&VerifyExpr::eq(VerifyExpr::var("x"), VerifyExpr::int(5)));
        session.assume(&VerifyExpr::eq(VerifyExpr::var("y"), VerifyExpr::int(3)));

        // Verify: x + y > 7 (5 + 3 = 8 > 7)
        let sum = VerifyExpr::binary(
            VerifyOp::Add,
            VerifyExpr::var("x"),
            VerifyExpr::var("y"),
        );
        let result = session.verify(&VerifyExpr::gt(sum, VerifyExpr::int(7)));
        assert!(result.is_ok(), "5 + 3 > 7 should be provable");
    }

    #[test]
    fn test_session_logic_and_or() {
        let mut session = VerificationSession::new();

        // Declare p and q as Bool
        session.declare("p", VerifyType::Bool);
        session.declare("q", VerifyType::Bool);

        // Assume: p = true, q = false
        session.assume(&VerifyExpr::eq(VerifyExpr::var("p"), VerifyExpr::bool(true)));
        session.assume(&VerifyExpr::eq(VerifyExpr::var("q"), VerifyExpr::bool(false)));

        // Verify: p || q (true || false = true)
        let result = session.verify(&VerifyExpr::or(
            VerifyExpr::var("p"),
            VerifyExpr::var("q"),
        ));
        assert!(result.is_ok(), "true || false should be provable");

        // Verify: !(p && q) (!(true && false) = true)
        let result = session.verify(&VerifyExpr::not(VerifyExpr::and(
            VerifyExpr::var("p"),
            VerifyExpr::var("q"),
        )));
        assert!(result.is_ok(), "!(true && false) should be provable");
    }
}

```

---

### License Validation

**File:** `logos_verification/src/license.rs`

LicensePlan enum (None, Free, Supporter, Pro, Premium, Lifetime, Enterprise) with can_verify() method. LicenseValidator validates Stripe subscription IDs (sub_*) against api.logicaffeine.com/validate with 24-hour caching.

```rust
//! License validation for LOGOS verification.
//!
//! Uses the existing Stripe-based license system. License keys are
//! Stripe subscription IDs (`sub_*` format).

use serde::{Deserialize, Serialize};
use std::fs;
use std::path::PathBuf;
use std::time::{SystemTime, UNIX_EPOCH};

use crate::error::{VerificationError, VerificationResult};

/// The license validation API endpoint.
const LICENSE_API: &str = "https://api.logicaffeine.com/validate";

/// Cache duration in seconds (24 hours).
const CACHE_DURATION_SECS: u64 = 24 * 60 * 60;

/// License plan tiers.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
#[serde(rename_all = "lowercase")]
pub enum LicensePlan {
    None,
    Free,
    Supporter,
    Pro,
    Premium,
    Lifetime,
    Enterprise,
}

impl LicensePlan {
    /// Check if this plan allows verification.
    pub fn can_verify(&self) -> bool {
        matches!(
            self,
            Self::Pro | Self::Premium | Self::Lifetime | Self::Enterprise
        )
    }

    /// Parse a plan from a string.
    pub fn from_str(s: &str) -> Self {
        match s.to_lowercase().as_str() {
            "free" => Self::Free,
            "supporter" => Self::Supporter,
            "pro" => Self::Pro,
            "premium" => Self::Premium,
            "lifetime" => Self::Lifetime,
            "enterprise" => Self::Enterprise,
            _ => Self::None,
        }
    }
}

impl std::fmt::Display for LicensePlan {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            Self::None => write!(f, "None"),
            Self::Free => write!(f, "Free"),
            Self::Supporter => write!(f, "Supporter"),
            Self::Pro => write!(f, "Pro"),
            Self::Premium => write!(f, "Premium"),
            Self::Lifetime => write!(f, "Lifetime"),
            Self::Enterprise => write!(f, "Enterprise"),
        }
    }
}

/// Cached license validation result.
#[derive(Debug, Serialize, Deserialize)]
struct CachedLicense {
    key: String,
    plan: String,
    valid: bool,
    validated_at: u64,
}

/// Response from the license validation API.
#[derive(Debug, Deserialize)]
struct LicenseResponse {
    valid: bool,
    #[serde(default)]
    plan: Option<String>,
    #[serde(default)]
    error: Option<String>,
}

/// License validator that checks keys against the API with caching.
pub struct LicenseValidator {
    cache_path: PathBuf,
}

impl LicenseValidator {
    /// Create a new license validator.
    pub fn new() -> Self {
        let cache_dir = dirs::cache_dir()
            .unwrap_or_else(|| PathBuf::from("."))
            .join("logos");

        // Ensure cache directory exists
        let _ = fs::create_dir_all(&cache_dir);

        Self {
            cache_path: cache_dir.join("verification_license.json"),
        }
    }

    /// Validate a license key.
    ///
    /// Returns the plan if valid, or an error if invalid or network fails.
    pub fn validate(&self, key: &str) -> VerificationResult<LicensePlan> {
        // Check key format
        if !key.starts_with("sub_") {
            return Err(VerificationError::license_invalid(
                "Invalid license key format. Keys should start with 'sub_'.",
            ));
        }

        // Check cache first
        if let Some(cached) = self.load_cache() {
            if cached.key == key && self.is_cache_fresh(&cached) {
                let plan = LicensePlan::from_str(&cached.plan);
                if cached.valid && plan.can_verify() {
                    return Ok(plan);
                } else if !cached.valid {
                    return Err(VerificationError::license_invalid("License key is invalid"));
                } else {
                    return Err(VerificationError::insufficient_plan(plan.to_string()));
                }
            }
        }

        // Validate with API
        match self.validate_with_api(key) {
            Ok((valid, plan)) => {
                // Cache the result
                self.save_cache(key, &plan.to_string().to_lowercase(), valid);

                if valid && plan.can_verify() {
                    Ok(plan)
                } else if !valid {
                    Err(VerificationError::license_invalid("License key is invalid"))
                } else {
                    Err(VerificationError::insufficient_plan(plan.to_string()))
                }
            }
            Err(e) => {
                // If network fails, try to use stale cache
                if let Some(cached) = self.load_cache() {
                    if cached.key == key {
                        eprintln!(
                            "Warning: Could not validate license ({}). Using cached result.",
                            e
                        );
                        let plan = LicensePlan::from_str(&cached.plan);
                        if cached.valid && plan.can_verify() {
                            return Ok(plan);
                        }
                    }
                }
                Err(VerificationError::license_invalid(format!(
                    "Could not validate license: {}",
                    e
                )))
            }
        }
    }

    /// Validate the key against the API.
    fn validate_with_api(&self, key: &str) -> Result<(bool, LicensePlan), String> {
        let response = ureq::post(LICENSE_API)
            .set("Content-Type", "application/json")
            .send_json(ureq::json!({ "licenseKey": key }))
            .map_err(|e| format!("Network error: {}", e))?;

        let body: LicenseResponse = response
            .into_json()
            .map_err(|e| format!("Invalid response: {}", e))?;

        if let Some(error) = body.error {
            return Err(error);
        }

        let plan = body
            .plan
            .map(|p| LicensePlan::from_str(&p))
            .unwrap_or(LicensePlan::None);

        Ok((body.valid, plan))
    }

    /// Load cached license validation.
    fn load_cache(&self) -> Option<CachedLicense> {
        let content = fs::read_to_string(&self.cache_path).ok()?;
        serde_json::from_str(&content).ok()
    }

    /// Save license validation to cache.
    fn save_cache(&self, key: &str, plan: &str, valid: bool) {
        let now = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap_or_default()
            .as_secs();

        let cached = CachedLicense {
            key: key.to_string(),
            plan: plan.to_string(),
            valid,
            validated_at: now,
        };

        if let Ok(json) = serde_json::to_string_pretty(&cached) {
            let _ = fs::write(&self.cache_path, json);
        }
    }

    /// Check if the cache is still fresh (< 24 hours).
    fn is_cache_fresh(&self, cached: &CachedLicense) -> bool {
        let now = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap_or_default()
            .as_secs();

        now.saturating_sub(cached.validated_at) < CACHE_DURATION_SECS
    }
}

impl Default for LicenseValidator {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_plan_can_verify() {
        assert!(!LicensePlan::None.can_verify());
        assert!(!LicensePlan::Free.can_verify());
        assert!(!LicensePlan::Supporter.can_verify());
        assert!(LicensePlan::Pro.can_verify());
        assert!(LicensePlan::Premium.can_verify());
        assert!(LicensePlan::Lifetime.can_verify());
        assert!(LicensePlan::Enterprise.can_verify());
    }

    #[test]
    fn test_invalid_key_format() {
        let validator = LicenseValidator::new();
        let result = validator.validate("invalid_key");
        assert!(result.is_err());
    }
}

```

---

### Verification Errors

**File:** `logos_verification/src/error.rs`

VerificationError with Socratic explanations. Kinds: ContradictoryAssertion, BoundsViolation, RefinementViolation, LicenseRequired, LicenseInvalid, LicenseInsufficientPlan, SolverUnknown, SolverError. CounterExample provides failing variable assignments.

```rust
//! Verification error types with Socratic error messages.

use std::fmt;

/// Result type for verification operations.
pub type VerificationResult<T = ()> = Result<T, VerificationError>;

/// A verification error with Socratic explanation.
#[derive(Debug)]
pub struct VerificationError {
    pub kind: VerificationErrorKind,
    pub span: Option<(usize, usize)>,
    pub explanation: String,
    pub counterexample: Option<CounterExample>,
}

/// The kind of verification error.
#[derive(Debug, Clone, PartialEq)]
pub enum VerificationErrorKind {
    /// An assertion that can never be true.
    ContradictoryAssertion,

    /// A variable violates its declared bounds.
    BoundsViolation {
        var: String,
        expected: String,
        found: String,
    },

    /// A refinement type predicate is not satisfied.
    RefinementViolation { type_name: String },

    /// Verification requires a license key.
    LicenseRequired,

    /// The license key is invalid or expired.
    LicenseInvalid { reason: String },

    /// The license plan doesn't include verification.
    LicenseInsufficientPlan { current: String },

    /// Z3 returned unknown (timeout or undecidable).
    SolverUnknown,

    /// Z3 initialization or internal error.
    SolverError { message: String },

    /// Phase 44: Loop termination cannot be proven.
    TerminationViolation {
        variant: String,
        reason: String,
    },
}

/// A counter-example showing why verification failed.
#[derive(Debug, Clone)]
pub struct CounterExample {
    /// Variable assignments that make the assertion false.
    pub assignments: Vec<(String, String)>,
}

impl fmt::Display for CounterExample {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        for (var, val) in &self.assignments {
            write!(f, "{} = {}", var, val)?;
            if self.assignments.len() > 1 {
                write!(f, ", ")?;
            }
        }
        Ok(())
    }
}

impl fmt::Display for VerificationError {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match &self.kind {
            VerificationErrorKind::ContradictoryAssertion => {
                writeln!(f, "This assertion can never be true.")?;
                writeln!(f)?;
                writeln!(f, "{}", self.explanation)?;
                if let Some(ce) = &self.counterexample {
                    writeln!(f)?;
                    writeln!(f, "Counter-example: {}", ce)?;
                }
            }
            VerificationErrorKind::BoundsViolation { var, expected, found } => {
                writeln!(f, "Value '{}' violates its constraint.", var)?;
                writeln!(f)?;
                writeln!(f, "Expected: {}", expected)?;
                writeln!(f, "But found possible value: {}", found)?;
            }
            VerificationErrorKind::RefinementViolation { type_name } => {
                writeln!(f, "Value does not satisfy refinement type '{}'.", type_name)?;
                writeln!(f)?;
                writeln!(f, "{}", self.explanation)?;
            }
            VerificationErrorKind::LicenseRequired => {
                writeln!(f, "Verification requires a license key.")?;
                writeln!(f)?;
                writeln!(f, "Use --license <key> or set the LOGOS_LICENSE environment variable.")?;
                writeln!(f, "Get a license at https://logicaffeine.com/pricing")?;
            }
            VerificationErrorKind::LicenseInvalid { reason } => {
                writeln!(f, "License validation failed: {}", reason)?;
            }
            VerificationErrorKind::LicenseInsufficientPlan { current } => {
                writeln!(f, "Verification requires Pro, Premium, Lifetime, or Enterprise plan.")?;
                writeln!(f)?;
                writeln!(f, "Current plan: {}", current)?;
                writeln!(f, "Upgrade at https://logicaffeine.com/pricing")?;
            }
            VerificationErrorKind::SolverUnknown => {
                writeln!(f, "The solver could not determine if the assertion is valid.")?;
                writeln!(f)?;
                writeln!(f, "This may be due to complexity or timeout.")?;
            }
            VerificationErrorKind::SolverError { message } => {
                writeln!(f, "Solver error: {}", message)?;
            }
            VerificationErrorKind::TerminationViolation { variant, reason } => {
                writeln!(f, "Cannot prove loop terminates.")?;
                writeln!(f)?;
                writeln!(f, "Variant '{}' does not strictly decrease: {}", variant, reason)?;
            }
        }
        Ok(())
    }
}

impl std::error::Error for VerificationError {}

impl VerificationError {
    /// Create a license required error.
    pub fn license_required() -> Self {
        Self {
            kind: VerificationErrorKind::LicenseRequired,
            span: None,
            explanation: String::new(),
            counterexample: None,
        }
    }

    /// Create a license invalid error.
    pub fn license_invalid(reason: impl Into<String>) -> Self {
        Self {
            kind: VerificationErrorKind::LicenseInvalid {
                reason: reason.into(),
            },
            span: None,
            explanation: String::new(),
            counterexample: None,
        }
    }

    /// Create an insufficient plan error.
    pub fn insufficient_plan(current: impl Into<String>) -> Self {
        Self {
            kind: VerificationErrorKind::LicenseInsufficientPlan {
                current: current.into(),
            },
            span: None,
            explanation: String::new(),
            counterexample: None,
        }
    }

    /// Create a contradictory assertion error.
    pub fn contradiction(explanation: impl Into<String>, counterexample: Option<CounterExample>) -> Self {
        Self {
            kind: VerificationErrorKind::ContradictoryAssertion,
            span: None,
            explanation: explanation.into(),
            counterexample,
        }
    }

    /// Create a bounds violation error.
    pub fn bounds_violation(
        var: impl Into<String>,
        expected: impl Into<String>,
        found: impl Into<String>,
    ) -> Self {
        Self {
            kind: VerificationErrorKind::BoundsViolation {
                var: var.into(),
                expected: expected.into(),
                found: found.into(),
            },
            span: None,
            explanation: String::new(),
            counterexample: None,
        }
    }

    /// Create a solver unknown error.
    pub fn solver_unknown() -> Self {
        Self {
            kind: VerificationErrorKind::SolverUnknown,
            span: None,
            explanation: String::new(),
            counterexample: None,
        }
    }

    /// Create a solver error.
    pub fn solver_error(message: impl Into<String>) -> Self {
        Self {
            kind: VerificationErrorKind::SolverError {
                message: message.into(),
            },
            span: None,
            explanation: String::new(),
            counterexample: None,
        }
    }

    /// Create a refinement type violation error.
    pub fn refinement_violation(type_name: impl Into<String>, explanation: impl Into<String>) -> Self {
        Self {
            kind: VerificationErrorKind::RefinementViolation {
                type_name: type_name.into(),
            },
            span: None,
            explanation: explanation.into(),
            counterexample: None,
        }
    }

    /// Set the span for this error.
    pub fn with_span(mut self, start: usize, end: usize) -> Self {
        self.span = Some((start, end));
        self
    }

    /// Phase 44: Create a termination violation error.
    pub fn termination_violation(variant: impl Into<String>, reason: impl Into<String>) -> Self {
        Self {
            kind: VerificationErrorKind::TerminationViolation {
                variant: variant.into(),
                reason: reason.into(),
            },
            span: None,
            explanation: String::new(),
            counterexample: None,
        }
    }
}

```

---

## Examples

Example programs demonstrating LOGOS capabilities.

**Location:** `examples/`

### Demo: Transpiler Showcase

**File:** `examples/demo.rs`

Interactive demonstration of LOGICAFFEINE's English-to-FOL transpilation. Shows basic predication, temporal logic, aspectual operators, quantifiers, modals, relative clauses, and more with live output.

```rust
use logos::{compile, compile_all_scopes, compile_with_options, CompileOptions, OutputFormat};

fn main() {
    println!("═══════════════════════════════════════════════════════════════════");
    println!("                    LOGICAFFEINE 1.0 DEMO");
    println!("              Montague Semantics + Lambda Calculus");
    println!("═══════════════════════════════════════════════════════════════════\n");

    section("BASIC PREDICATION");
    demo(&[
        "John runs.",
        "Mary sleeps.",
        "Socrates thinks.",
        "The dog barks.",
    ]);

    section("TEMPORAL LOGIC (Past/Future)");
    demo(&[
        "John ran.",
        "John runs.",
        "John will run.",
        "Mary jumped.",
        "The dog barked.",
        "The cat will sleep.",
        "Socrates taught Plato.",
    ]);

    section("ASPECTUAL OPERATORS (Progressive)");
    demo(&[
        "John is running.",
        "Mary is sleeping.",
        "John was running.",
        "The dog was barking.",
        "Mary is reading.",
    ]);

    section("DEFINITENESS (Russell's Descriptions)");
    demo(&[
        "A dog barks.",
        "The dog barks.",
        "A cat sleeps.",
        "The cat ran.",
        "A man loves Mary.",
        "The king is bald.",
        "The president speaks.",
    ]);

    section("UNIVERSAL & EXISTENTIAL QUANTIFIERS");
    demo(&[
        "All men are mortal.",
        "Some cats are black.",
        "No dogs are cats.",
        "All birds fly.",
        "Some philosophers are wise.",
        "No fish can walk.",
        "Every student studies.",
    ]);

    section("GENERALIZED QUANTIFIERS");
    demo(&[
        "Most dogs bark.",
        "Few cats swim.",
        "Three dogs ran.",
        "At least two birds fly.",
        "At most five cats sleep.",
    ]);

    section("BINARY RELATIONS");
    demo(&[
        "John loves Mary.",
        "Mary loves John.",
        "Socrates taught Plato.",
        "The cat chased the mouse.",
        "Bill sees John.",
    ]);

    section("TERNARY RELATIONS (Ditransitives)");
    demo(&[
        "John gave the book to Mary.",
        "Mary sent a letter to John.",
    ]);

    section("REFLEXIVE BINDING");
    demo(&[
        "John loves himself.",
        "Mary sees herself.",
        "John gave the book to himself.",
        "The cat cleaned itself.",
    ]);

    section("RELATIVE CLAUSES (Subject Gap)");
    demo(&[
        "All dogs that bark are loud.",
        "All cats that sleep are lazy.",
        "All men who think are wise.",
        "All birds that fly are free.",
    ]);

    section("RELATIVE CLAUSES (Object Gap)");
    demo(&[
        "The cat that the dog chased ran.",
        "The man who Mary loves left.",
        "The book that John read is good.",
    ]);

    section("ADJECTIVES AS PREDICATES");
    demo(&[
        "All happy dogs are friendly.",
        "All old men are wise.",
        "Some tall women are athletes.",
        "All big cats are dangerous.",
    ]);

    section("MODAL OPERATORS (Alethic)");
    demo(&[
        "All cats must sleep.",
        "Some birds can fly.",
        "John can swim.",
        "All code cannot run.",
        "Mary can dance.",
    ]);

    section("MODAL OPERATORS (Deontic)");
    demo(&[
        "All students should study.",
        "John may leave.",
        "Mary should work.",
    ]);

    section("IDENTITY STATEMENTS");
    demo(&[
        "Clark is equal to Superman.",
        "Socrates is identical to Socrates.",
        "Hesperus is equal to Phosphorus.",
        "Bruce is equal to Batman.",
    ]);

    section("LOGICAL CONNECTIVES");
    demo(&[
        "John runs and Mary sleeps.",
        "John runs or Mary sleeps.",
        "If John runs, then Mary sleeps.",
        "A if and only if B.",
        "All men are mortal and some cats are black.",
    ]);

    section("WH-QUESTIONS");
    demo(&[
        "Who loves Mary?",
        "What does John love?",
    ]);

    section("YES/NO QUESTIONS");
    demo(&[
        "Does John love Mary?",
        "Does the dog bark?",
    ]);

    section("PASSIVE VOICE");
    demo(&[
        "Mary was loved by John.",
        "The book was read.",
    ]);

    println!("\n═══════════════════════════════════════════════════════════════════");
    println!("                    SCOPE AMBIGUITY ANALYSIS");
    println!("═══════════════════════════════════════════════════════════════════\n");

    scope_demo("All dogs bark.");
    scope_demo("John loves Mary.");
    scope_demo("All men are mortal.");
    scope_demo("Some cats are black.");

    println!("\n═══════════════════════════════════════════════════════════════════");
    println!("                       LaTeX OUTPUT");
    println!("═══════════════════════════════════════════════════════════════════\n");

    let latex_options = CompileOptions {
        format: OutputFormat::LaTeX,
    };

    let latex_examples = vec![
        "All men are mortal.",
        "John ran.",
        "John was running.",
        "The dog barks.",
        "A if and only if B.",
        "Who loves Mary?",
    ];

    for input in &latex_examples {
        println!("Input:  \"{}\"", input);
        match compile_with_options(input, latex_options) {
            Ok(output) => println!("LaTeX:  {}\n", output),
            Err(e) => println!("Error:  {:?}\n", e),
        }
    }

    section("COMPARATIVES (Degree Semantics)");
    demo(&[
        "John is taller than Mary.",
        "The dog is faster than the cat.",
        "Mary is smarter than John.",
        "Bill is older than Bob.",
    ]);

    section("SUPERLATIVES");
    demo(&[
        "John is the tallest man.",
        "Rex is the fastest dog.",
        "Mary is the smartest student.",
    ]);

    section("PLURALS & AGGREGATION (Mereology)");
    demo(&[
        "John and Mary met.",
        "John and Mary ran.",
        "The students gathered.",
        "Bill and Bob collaborated.",
    ]);

    section("EXISTENTIAL CLAIMS");
    demo(&["God is."]);

    section("SCOPAL ADVERBS");
    demo(&[
        "John almost died.",
        "Mary nearly won.",
        "John allegedly stole.",
        "Bill probably left.",
    ]);

    section("CONTROL THEORY (Subject Control)");
    demo(&[
        "John wants to run.",
        "Mary tried to leave.",
        "Bill hopes to win.",
        "John decided to stay.",
    ]);

    section("CONTROL THEORY (Object Control)");
    demo(&[
        "John persuaded Mary to leave.",
        "Bill forced John to run.",
        "Mary convinced Bill to stay.",
    ]);

    section("CONTROL THEORY (Promise - Special Case)");
    demo(&["John promised Mary to leave."]);

    section("PRESUPPOSITION TRIGGERS");
    demo(&[
        "John stopped smoking.",
        "Mary started running.",
        "John regrets leaving.",
        "Bill stopped working.",
        "Mary started singing.",
    ]);

    section("FOCUS OPERATORS");
    demo(&[
        "Only John loves Mary.",
        "Even John ran.",
        "Only Mary left.",
        "Even Bill won.",
    ]);

    section("MANNER ADVERBS (Neo-Davidsonian)");
    demo(&[
        "John ran quickly.",
        "Mary spoke loudly.",
        "Bill worked carefully.",
    ]);

    section("COUNTERFACTUALS");
    demo(&["If John had run, Mary would sleep."]);

    section("POSSESSION (Genitive Case)");
    demo(&[
        "John's dog barks.",
        "Mary's cat sleeps.",
        "The king's horse ran.",
        "The dog of John barks.",
        "John loves Mary's cat.",
        "John's dog chased the cat.",
    ]);

    section("DITRANSITIVE PASSIVES");
    demo(&[
        "The book was given to Mary by John.",
        "The letter was sent to Bill by Mary.",
        "The story was told to the children by the teacher.",
    ]);

    section("RAISING VERBS (vs Control)");
    demo(&[
        "John seems to sleep.",
        "Mary appears to run.",
        "John happens to win.",
        "John wants to run.",
    ]);

    section("TEMPORAL ADVERBS (Time Coordinates)");
    demo(&[
        "John ran yesterday.",
        "Mary runs today.",
        "Bill will leave tomorrow.",
        "John runs now.",
    ]);

    section("NON-INTERSECTIVE ADJECTIVES");
    demo(&[
        "A fake gun is dangerous.",
        "A former senator spoke.",
        "The alleged thief escaped.",
    ]);

    section("INTERSECTIVE VS NON-INTERSECTIVE");
    demo(&[
        "A red ball bounced.",
        "A fake ball bounced.",
    ]);

    println!("═══════════════════════════════════════════════════════════════════");
    println!("                         SUMMARY");
    println!("═══════════════════════════════════════════════════════════════════");
    println!("Logicaffeine 1.0 supports:");
    println!("  • First-Order Logic with N-ary predicates");
    println!("  • Temporal operators (P, F) for tense");
    println!("  • Aspectual operators (Prog, Perf)");
    println!("  • Russell's definite descriptions");
    println!("  • Generalized quantifiers (Most, Few, Cardinal, AtLeast, AtMost)");
    println!("  • Modal logic (Alethic □/◇, Deontic O/P)");
    println!("  • Lambda calculus (β-reduction)");
    println!("  • Scope ambiguity enumeration");
    println!("  • Wh-questions as lambda abstractions");
    println!("  • Comparatives & Superlatives (Degree Semantics)");
    println!("  • Plurals & Aggregation (Mereology)");
    println!("  • Scopal Adverbs (Almost, Nearly, Allegedly, Probably)");
    println!("  • Manner Adverbs (Neo-Davidsonian event semantics)");
    println!("  • Existential claims (bare copula)");
    println!("  • Control Theory (PRO binding - Subject/Object control)");
    println!("  • Presupposition triggers (Stop, Start, Regret)");
    println!("  • Focus operators (Only, Even)");
    println!("  • Counterfactual conditionals");
    println!("  • Reflexive binding (himself, herself, itself)");
    println!("  • Relative clauses (subject-gap & object-gap)");
    println!("  • Passive voice");
    println!("  • Identity statements");
    println!("  • Possession / Genitive case ('s and 'of' constructions)");
    println!("  • Ditransitive passives ('given to X by Y')");
    println!("  • Raising verbs (seem, appear, happen) vs Control verbs");
    println!("  • Temporal adverbs (yesterday, today, tomorrow, now)");
    println!("  • Non-intersective adjectives (fake, former, alleged)");
    println!("═══════════════════════════════════════════════════════════════════\n");
}

fn section(title: &str) {
    println!("--- {} ---\n", title);
}

fn demo(sentences: &[&str]) {
    for input in sentences {
        println!("  \"{}\"", input);
        match compile(input) {
            Ok(output) => println!("  → {}\n", output),
            Err(e) => println!("  → Error: {:?}\n", e),
        }
    }
}

fn scope_demo(input: &str) {
    println!("Input: \"{}\"", input);
    match compile_all_scopes(input) {
        Ok(readings) => {
            println!("Readings: {}", readings.len());
            for (i, reading) in readings.iter().enumerate() {
                println!("  [{}] {}", i + 1, reading);
            }
        }
        Err(e) => println!("Error: {:?}", e),
    }
    println!();
}

```

---

### Demo: Mergesort Compilation

**File:** `examples/compile_mergesort.rs`

End-to-end example compiling a complete LOGOS mergesort implementation to Rust. Demonstrates function definitions, collection operations, comparison operators, and recursive algorithms.

```rust
use logos::compile::compile_to_rust;

fn main() {
    let source = r#"## To Merge (left: Seq of Int) and (right: Seq of Int) -> Seq of Int:
    Let result be a new Seq of Int.
    Let i be 1.
    Let j be 1.
    Let n_left be length of left.
    Let n_right be length of right.

    While i is at most n_left and j is at most n_right:
        Let l_val be item i of left.
        Let r_val be item j of right.

        If l_val is less than r_val:
            Push l_val to result.
            Set i to i + 1.
        Otherwise:
            Push r_val to result.
            Set j to j + 1.

    While i is at most n_left:
        Let v be item i of left.
        Push v to result.
        Set i to i + 1.

    While j is at most n_right:
        Let v be item j of right.
        Push v to result.
        Set j to j + 1.

    Return result.

## To MergeSort (items: Seq of Int) -> Seq of Int:
    Let n be length of items.
    If n is less than 2:
        Return copy of items.

    Let mid be n / 2.
    Let left_slice be items 1 through mid.
    Let right_slice be items (mid + 1) through n.

    Let sorted_left be MergeSort(copy of left_slice).
    Let sorted_right be MergeSort(copy of right_slice).

    Return Merge(sorted_left, sorted_right).

## Main
    Let numbers be a new Seq of Int.
    Push 3 to numbers.
    Push 1 to numbers.
    Push 4 to numbers.
    Push 1 to numbers.
    Push 5 to numbers.
    Push 9 to numbers.
    Push 2 to numbers.
    Push 6 to numbers.

    Show numbers.
    Let sorted be MergeSort(numbers).
    Show sorted."#;

    match compile_to_rust(source) {
        Ok(rust_code) => {
            print!("{}", rust_code);
        }
        Err(e) => {
            eprintln!("Compilation error: {:?}", e);
            std::process::exit(1);
        }
    }
}

```

---

## Additional Modules

Any additional source files not explicitly categorized above.

### Module: achievements

**File:** `src/achievements.rs`

Additional source module.

```rust
use crate::progress::UserProgress;

#[derive(Debug, Clone, PartialEq, Eq)]
pub struct Achievement {
    pub id: &'static str,
    pub title: &'static str,
    pub description: &'static str,
    pub xp_reward: u64,
    pub unlocks_title: Option<&'static str>,
    pub grants_freeze: bool,
}

pub const ACHIEVEMENTS: &[Achievement] = &[
    Achievement {
        id: "first_blood",
        title: "First Blood",
        description: "Answer your first question correctly",
        xp_reward: 50,
        unlocks_title: None,
        grants_freeze: false,
    },
    Achievement {
        id: "combo_5",
        title: "On Fire",
        description: "Get a 5-answer combo",
        xp_reward: 100,
        unlocks_title: None,
        grants_freeze: false,
    },
    Achievement {
        id: "combo_10",
        title: "Unstoppable",
        description: "Get a 10-answer combo",
        xp_reward: 250,
        unlocks_title: Some("Logic Machine"),
        grants_freeze: false,
    },
    Achievement {
        id: "combo_25",
        title: "Terminator",
        description: "Get a 25-answer combo",
        xp_reward: 500,
        unlocks_title: Some("Automaton"),
        grants_freeze: false,
    },
    Achievement {
        id: "streak_3",
        title: "Getting Started",
        description: "Maintain a 3-day streak",
        xp_reward: 75,
        unlocks_title: None,
        grants_freeze: false,
    },
    Achievement {
        id: "streak_7",
        title: "Week Warrior",
        description: "Maintain a 7-day streak",
        xp_reward: 200,
        unlocks_title: Some("Dedicated"),
        grants_freeze: true,
    },
    Achievement {
        id: "streak_14",
        title: "Fortnight Fighter",
        description: "Maintain a 14-day streak",
        xp_reward: 400,
        unlocks_title: None,
        grants_freeze: true,
    },
    Achievement {
        id: "streak_30",
        title: "Monthly Master",
        description: "Maintain a 30-day streak",
        xp_reward: 1000,
        unlocks_title: Some("Logician"),
        grants_freeze: true,
    },
    Achievement {
        id: "perfect_module",
        title: "Flawless",
        description: "Complete a module with no mistakes",
        xp_reward: 300,
        unlocks_title: None,
        grants_freeze: false,
    },
    Achievement {
        id: "century",
        title: "Century",
        description: "Answer 100 questions correctly",
        xp_reward: 500,
        unlocks_title: Some("Scholar"),
        grants_freeze: false,
    },
    Achievement {
        id: "millennium",
        title: "Millennium",
        description: "Answer 1000 questions correctly",
        xp_reward: 2000,
        unlocks_title: Some("Sage"),
        grants_freeze: false,
    },
    Achievement {
        id: "level_10",
        title: "Double Digits",
        description: "Reach level 10",
        xp_reward: 300,
        unlocks_title: None,
        grants_freeze: false,
    },
    Achievement {
        id: "level_25",
        title: "Quarter Century",
        description: "Reach level 25",
        xp_reward: 750,
        unlocks_title: Some("Adept"),
        grants_freeze: false,
    },
    Achievement {
        id: "level_50",
        title: "Half Century",
        description: "Reach level 50",
        xp_reward: 1500,
        unlocks_title: Some("Grandmaster"),
        grants_freeze: false,
    },
];

pub fn get_achievement(id: &str) -> Option<&'static Achievement> {
    ACHIEVEMENTS.iter().find(|a| a.id == id)
}

pub fn check_achievements(progress: &UserProgress) -> Vec<&'static Achievement> {
    let mut newly_unlocked = Vec::new();

    for achievement in ACHIEVEMENTS {
        if progress.achievements.contains(achievement.id) {
            continue;
        }

        let earned = match achievement.id {
            "first_blood" => total_correct(progress) >= 1,
            "combo_5" => progress.best_combo >= 5,
            "combo_10" => progress.best_combo >= 10,
            "combo_25" => progress.best_combo >= 25,
            "streak_3" => progress.streak_days >= 3,
            "streak_7" => progress.streak_days >= 7,
            "streak_14" => progress.streak_days >= 14,
            "streak_30" => progress.streak_days >= 30,
            "century" => total_correct(progress) >= 100,
            "millennium" => total_correct(progress) >= 1000,
            "level_10" => progress.level >= 10,
            "level_25" => progress.level >= 25,
            "level_50" => progress.level >= 50,
            "perfect_module" => false, // Checked separately in lesson completion
            _ => false,
        };

        if earned {
            newly_unlocked.push(achievement);
        }
    }

    newly_unlocked
}

fn total_correct(progress: &UserProgress) -> u32 {
    progress.exercises.values().map(|e| e.correct_count).sum()
}

pub fn unlock_achievement(progress: &mut UserProgress, achievement: &Achievement) {
    progress.achievements.insert(achievement.id.to_string());
    progress.xp += achievement.xp_reward;
    progress.level = crate::progress::calculate_level(progress.xp);

    if let Some(title) = achievement.unlocks_title {
        if progress.title.is_none() {
            progress.title = Some(title.to_string());
        }
    }

    if achievement.grants_freeze && progress.streak_freezes < 3 {
        progress.streak_freezes += 1;
    }

    progress.save();
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_get_achievement() {
        let achievement = get_achievement("first_blood");
        assert!(achievement.is_some());
        assert_eq!(achievement.unwrap().title, "First Blood");
    }

    #[test]
    fn test_achievement_not_found() {
        let achievement = get_achievement("nonexistent");
        assert!(achievement.is_none());
    }

    #[test]
    fn test_check_achievements_first_blood() {
        let mut progress = UserProgress::new();
        progress.record_attempt("test", true);

        let newly_unlocked = check_achievements(&progress);
        assert!(newly_unlocked.iter().any(|a| a.id == "first_blood"));
    }

    #[test]
    fn test_check_achievements_combo() {
        let mut progress = UserProgress::new();
        progress.best_combo = 5;

        let newly_unlocked = check_achievements(&progress);
        assert!(newly_unlocked.iter().any(|a| a.id == "combo_5"));
        assert!(!newly_unlocked.iter().any(|a| a.id == "combo_10"));
    }

    #[test]
    fn test_streak_achievements_grant_freeze() {
        let streak_7 = get_achievement("streak_7").unwrap();
        assert!(streak_7.grants_freeze);

        let first_blood = get_achievement("first_blood").unwrap();
        assert!(!first_blood.grants_freeze);
    }
}

```

---

### Module: audio

**File:** `src/audio.rs`

Additional source module.

```rust
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum SoundEffect {
    XpGain,
    CriticalHit,
    ComboUp,
    ComboBreak,
    Achievement,
    LevelUp,
    StreakSaved,
    StreakLost,
    Correct,
    Incorrect,
}

impl SoundEffect {
    pub fn as_str(&self) -> &'static str {
        match self {
            Self::XpGain => "xp_gain",
            Self::CriticalHit => "critical",
            Self::ComboUp => "combo_up",
            Self::ComboBreak => "combo_break",
            Self::Achievement => "achievement",
            Self::LevelUp => "level_up",
            Self::StreakSaved => "streak_saved",
            Self::StreakLost => "streak_lost",
            Self::Correct => "correct",
            Self::Incorrect => "incorrect",
        }
    }
}

#[cfg(target_arch = "wasm32")]
mod wasm {
    use super::SoundEffect;
    use wasm_bindgen::prelude::*;

    #[wasm_bindgen]
    extern "C" {
        #[wasm_bindgen(js_namespace = window, js_name = playSound)]
        fn play_sound_js(effect: &str);
    }

    pub fn play_sound(effect: SoundEffect) {
        play_sound_js(effect.as_str());
    }
}

#[cfg(target_arch = "wasm32")]
pub use wasm::play_sound;

#[cfg(not(target_arch = "wasm32"))]
pub fn play_sound(_effect: SoundEffect) {
    // No-op on non-wasm targets
}

```

---

### Module: cli

**File:** `src/cli.rs`

Additional source module.

```rust
//! Phase 37/39: LOGOS CLI (largo)
//!
//! Command-line interface for the LOGOS build system and package registry.

use clap::{Parser, Subcommand};
use std::env;
use std::fs;
use std::io::{self, Write};
use std::path::PathBuf;

use crate::compile::compile_project;
use crate::project::build::{self, find_project_root, BuildConfig};
use crate::project::manifest::Manifest;
use crate::project::credentials::{Credentials, get_token};
use crate::project::registry::{
    RegistryClient, PublishMetadata, create_tarball, is_git_dirty,
};

#[derive(Parser)]
#[command(name = "largo")]
#[command(about = "The LOGOS build tool", long_about = None)]
#[command(version)]
pub struct Cli {
    #[command(subcommand)]
    pub command: Commands,
}

#[derive(Subcommand)]
pub enum Commands {
    /// Create a new LOGOS project
    New {
        /// Project name
        name: String,
    },
    /// Initialize a LOGOS project in the current directory
    Init {
        /// Project name (defaults to directory name)
        #[arg(long)]
        name: Option<String>,
    },
    /// Build the current project
    Build {
        /// Build in release mode
        #[arg(long, short)]
        release: bool,

        /// Run Z3 static verification (requires Pro+ license)
        #[arg(long)]
        verify: bool,

        /// License key for verification (or set LOGOS_LICENSE env var)
        #[arg(long)]
        license: Option<String>,
    },
    /// Verify the project without building (requires Pro+ license)
    Verify {
        /// License key (or set LOGOS_LICENSE env var)
        #[arg(long)]
        license: Option<String>,
    },
    /// Build and run the current project
    Run {
        /// Build in release mode
        #[arg(long, short)]
        release: bool,
    },
    /// Check the project for errors without building
    Check,

    // Phase 39: Package Registry Commands
    /// Publish the package to the registry
    Publish {
        /// Registry URL (defaults to registry.logicaffeine.com)
        #[arg(long)]
        registry: Option<String>,

        /// Perform all checks without actually publishing
        #[arg(long)]
        dry_run: bool,

        /// Allow publishing with uncommitted changes
        #[arg(long)]
        allow_dirty: bool,
    },
    /// Log in to the package registry
    Login {
        /// Registry URL
        #[arg(long)]
        registry: Option<String>,

        /// Token to store (reads from stdin if not provided)
        #[arg(long)]
        token: Option<String>,
    },
    /// Log out from the package registry
    Logout {
        /// Registry URL
        #[arg(long)]
        registry: Option<String>,
    },
}

/// Entry point for the CLI
pub fn run_cli() -> Result<(), Box<dyn std::error::Error>> {
    let cli = Cli::parse();

    match cli.command {
        Commands::New { name } => cmd_new(&name),
        Commands::Init { name } => cmd_init(name.as_deref()),
        Commands::Build { release, verify, license } => cmd_build(release, verify, license),
        Commands::Run { release } => cmd_run(release),
        Commands::Check => cmd_check(),
        Commands::Verify { license } => cmd_verify(license),
        Commands::Publish { registry, dry_run, allow_dirty } => {
            cmd_publish(registry.as_deref(), dry_run, allow_dirty)
        }
        Commands::Login { registry, token } => cmd_login(registry.as_deref(), token),
        Commands::Logout { registry } => cmd_logout(registry.as_deref()),
    }
}

fn cmd_new(name: &str) -> Result<(), Box<dyn std::error::Error>> {
    let project_dir = PathBuf::from(name);

    if project_dir.exists() {
        return Err(format!("Directory '{}' already exists", project_dir.display()).into());
    }

    // Create project structure
    fs::create_dir_all(&project_dir)?;
    fs::create_dir_all(project_dir.join("src"))?;

    // Write Largo.toml
    let manifest = Manifest::new(name);
    fs::write(project_dir.join("Largo.toml"), manifest.to_toml()?)?;

    // Write src/main.lg
    let main_lg = r#"# Main

A simple LOGOS program.

## Main

Show "Hello, world!".
"#;
    fs::write(project_dir.join("src/main.lg"), main_lg)?;

    // Write .gitignore
    fs::write(project_dir.join(".gitignore"), "/target\n")?;

    println!("Created LOGOS project '{}'", name);
    println!("  cd {}", project_dir.display());
    println!("  largo run");

    Ok(())
}

fn cmd_init(name: Option<&str>) -> Result<(), Box<dyn std::error::Error>> {
    let current_dir = env::current_dir()?;
    let project_name = name
        .map(String::from)
        .or_else(|| {
            current_dir
                .file_name()
                .and_then(|n| n.to_str())
                .map(String::from)
        })
        .unwrap_or_else(|| "project".to_string());

    if current_dir.join("Largo.toml").exists() {
        return Err("Largo.toml already exists".into());
    }

    // Create src directory if needed
    fs::create_dir_all(current_dir.join("src"))?;

    // Write Largo.toml
    let manifest = Manifest::new(&project_name);
    fs::write(current_dir.join("Largo.toml"), manifest.to_toml()?)?;

    // Write src/main.lg if it doesn't exist
    let main_path = current_dir.join("src/main.lg");
    if !main_path.exists() {
        let main_lg = r#"# Main

A simple LOGOS program.

## Main

Show "Hello, world!".
"#;
        fs::write(main_path, main_lg)?;
    }

    println!("Initialized LOGOS project '{}'", project_name);

    Ok(())
}

fn cmd_build(
    release: bool,
    verify: bool,
    license: Option<String>,
) -> Result<(), Box<dyn std::error::Error>> {
    let current_dir = env::current_dir()?;
    let project_root =
        find_project_root(&current_dir).ok_or("Not in a LOGOS project (Largo.toml not found)")?;

    // Run verification if requested
    if verify {
        run_verification(&project_root, license.as_deref())?;
    }

    let config = BuildConfig {
        project_dir: project_root,
        release,
    };

    let result = build::build(config)?;

    let mode = if release { "release" } else { "debug" };
    println!("Built {} [{}]", result.binary_path.display(), mode);

    Ok(())
}

fn cmd_verify(license: Option<String>) -> Result<(), Box<dyn std::error::Error>> {
    let current_dir = env::current_dir()?;
    let project_root =
        find_project_root(&current_dir).ok_or("Not in a LOGOS project (Largo.toml not found)")?;

    run_verification(&project_root, license.as_deref())?;
    println!("Verification passed");
    Ok(())
}

#[cfg(feature = "verification")]
fn run_verification(
    project_root: &std::path::Path,
    license: Option<&str>,
) -> Result<(), Box<dyn std::error::Error>> {
    use logos_verification::{LicenseValidator, Verifier};

    // Get license key from argument or environment
    let license_key = license
        .map(String::from)
        .or_else(|| env::var("LOGOS_LICENSE").ok());

    let license_key = license_key.ok_or(
        "Verification requires a license key.\n\
         Use --license <key> or set LOGOS_LICENSE environment variable.\n\
         Get a license at https://logicaffeine.com/pricing",
    )?;

    // Validate license
    println!("Validating license...");
    let validator = LicenseValidator::new();
    let plan = validator.validate(&license_key)?;
    println!("License valid ({})", plan);

    // Load and parse the project
    let manifest = Manifest::load(project_root)?;
    let entry_path = project_root.join(&manifest.package.entry);
    let source = fs::read_to_string(&entry_path)?;

    // For now, just verify that Z3 works
    // TODO: Implement full AST encoding in Phase 2
    println!("Running Z3 verification...");
    let verifier = Verifier::new();

    // Basic smoke test - verify that true is valid
    verifier.check_bool(true)?;

    Ok(())
}

#[cfg(not(feature = "verification"))]
fn run_verification(
    _project_root: &std::path::Path,
    _license: Option<&str>,
) -> Result<(), Box<dyn std::error::Error>> {
    Err("Verification requires the 'verification' feature.\n\
         Rebuild with: cargo build --features verification"
        .into())
}

fn cmd_run(release: bool) -> Result<(), Box<dyn std::error::Error>> {
    let current_dir = env::current_dir()?;
    let project_root =
        find_project_root(&current_dir).ok_or("Not in a LOGOS project (Largo.toml not found)")?;

    let config = BuildConfig {
        project_dir: project_root,
        release,
    };

    let result = build::build(config)?;
    let exit_code = build::run(&result)?;

    if exit_code != 0 {
        std::process::exit(exit_code);
    }

    Ok(())
}

fn cmd_check() -> Result<(), Box<dyn std::error::Error>> {
    let current_dir = env::current_dir()?;
    let project_root =
        find_project_root(&current_dir).ok_or("Not in a LOGOS project (Largo.toml not found)")?;

    let manifest = Manifest::load(&project_root)?;
    let entry_path = project_root.join(&manifest.package.entry);

    // Just compile to Rust without building
    compile_project(&entry_path)?;

    println!("Check passed");
    Ok(())
}

// ============================================================
// Phase 39: Registry Commands
// ============================================================

fn cmd_publish(
    registry: Option<&str>,
    dry_run: bool,
    allow_dirty: bool,
) -> Result<(), Box<dyn std::error::Error>> {
    let current_dir = env::current_dir()?;
    let project_root =
        find_project_root(&current_dir).ok_or("Not in a LOGOS project (Largo.toml not found)")?;

    // Load manifest
    let manifest = Manifest::load(&project_root)?;
    let name = &manifest.package.name;
    let version = &manifest.package.version;

    println!("Packaging {} v{}", name, version);

    // Determine registry URL
    let registry_url = registry.unwrap_or(RegistryClient::default_url());

    // Get authentication token
    let token = get_token(registry_url).ok_or_else(|| {
        format!(
            "No authentication token found for {}.\n\
             Run 'largo login' or set LOGOS_TOKEN environment variable.",
            registry_url
        )
    })?;

    // Verify the package
    let entry_path = project_root.join(&manifest.package.entry);
    if !entry_path.exists() {
        return Err(format!(
            "Entry point '{}' not found",
            manifest.package.entry
        ).into());
    }

    // Check for uncommitted changes
    if !allow_dirty && is_git_dirty(&project_root) {
        return Err(
            "Working directory has uncommitted changes.\n\
             Use --allow-dirty to publish anyway.".into()
        );
    }

    // Create tarball
    println!("Creating package tarball...");
    let tarball = create_tarball(&project_root)?;
    println!("  Package size: {} bytes", tarball.len());

    // Read README if present
    let readme = project_root.join("README.md");
    let readme_content = if readme.exists() {
        fs::read_to_string(&readme).ok()
    } else {
        None
    };

    // Build metadata
    let metadata = PublishMetadata {
        name: name.clone(),
        version: version.clone(),
        description: manifest.package.description.clone(),
        repository: None, // Could add to manifest later
        homepage: None,
        license: None,
        keywords: vec![],
        entry_point: manifest.package.entry.clone(),
        dependencies: manifest
            .dependencies
            .iter()
            .map(|(k, v)| (k.clone(), v.to_string()))
            .collect(),
        readme: readme_content,
    };

    if dry_run {
        println!("\n[dry-run] Would publish to {}", registry_url);
        println!("[dry-run] Package validated successfully");
        return Ok(());
    }

    // Upload to registry
    println!("Uploading to {}...", registry_url);
    let client = RegistryClient::new(registry_url, &token);
    let result = client.publish(name, version, &tarball, &metadata)?;

    println!(
        "\nPublished {} v{} to {}",
        result.package, result.version, registry_url
    );
    println!("  SHA256: {}", result.sha256);

    Ok(())
}

fn cmd_login(
    registry: Option<&str>,
    token: Option<String>,
) -> Result<(), Box<dyn std::error::Error>> {
    let registry_url = registry.unwrap_or(RegistryClient::default_url());

    // Get token from argument or stdin
    let token = match token {
        Some(t) => t,
        None => {
            println!("To get a token, visit: {}/auth/github", registry_url);
            println!("Then generate an API token from your profile.");
            println!();
            print!("Enter token for {}: ", registry_url);
            io::stdout().flush()?;

            let mut line = String::new();
            io::stdin().read_line(&mut line)?;
            line.trim().to_string()
        }
    };

    if token.is_empty() {
        return Err("Token cannot be empty".into());
    }

    // Validate token with registry
    println!("Validating token...");
    let client = RegistryClient::new(registry_url, &token);
    let user_info = client.validate_token()?;

    // Save to credentials file
    let mut creds = Credentials::load().unwrap_or_default();
    creds.set_token(registry_url, &token);
    creds.save()?;

    println!("Logged in as {} to {}", user_info.login, registry_url);

    Ok(())
}

fn cmd_logout(registry: Option<&str>) -> Result<(), Box<dyn std::error::Error>> {
    let registry_url = registry.unwrap_or(RegistryClient::default_url());

    let mut creds = Credentials::load().unwrap_or_default();

    if creds.get_token(registry_url).is_none() {
        println!("Not logged in to {}", registry_url);
        return Ok(());
    }

    creds.remove_token(registry_url);
    creds.save()?;

    println!("Logged out from {}", registry_url);

    Ok(())
}

```

---

### Module: codegen

**File:** `src/codegen.rs`

Additional source module.

```rust
use std::collections::{HashMap, HashSet};
use std::fmt::Write;

use crate::analysis::registry::{FieldDef, FieldType, TypeDef, TypeRegistry, VariantDef};
use crate::analysis::policy::{PolicyRegistry, PredicateDef, CapabilityDef, PolicyCondition};
use crate::ast::logic::{LogicExpr, NumberKind, Term};
use crate::ast::stmt::{BinaryOpKind, Expr, Literal, ReadSource, Stmt, TypeExpr};
use crate::formatter::RustFormatter;
use crate::intern::{Interner, Symbol};
use crate::registry::SymbolRegistry;

// =============================================================================
// Phase 43C: Refinement Type Enforcement
// =============================================================================

/// Tracks refinement type constraints across scopes for mutation enforcement.
/// When a variable with a refinement type is defined, we register its constraint.
/// When that variable is mutated via `Set`, we re-emit the assertion.
/// Phase 50: Also tracks variable types for capability Check resolution.
pub struct RefinementContext<'a> {
    /// Stack of scopes. Each scope maps variable Symbol to (bound_var, predicate).
    scopes: Vec<HashMap<Symbol, (Symbol, &'a LogicExpr<'a>)>>,
    /// Phase 50: Maps variable name Symbol to type name (for capability resolution)
    /// e.g., "doc" -> "Document" allows "Check that user can publish the document" to resolve to &doc
    variable_types: HashMap<Symbol, String>,
}

impl<'a> RefinementContext<'a> {
    pub fn new() -> Self {
        Self {
            scopes: vec![HashMap::new()],
            variable_types: HashMap::new(),
        }
    }

    fn push_scope(&mut self) {
        self.scopes.push(HashMap::new());
    }

    fn pop_scope(&mut self) {
        self.scopes.pop();
    }

    fn register(&mut self, var: Symbol, bound_var: Symbol, predicate: &'a LogicExpr<'a>) {
        if let Some(scope) = self.scopes.last_mut() {
            scope.insert(var, (bound_var, predicate));
        }
    }

    fn get_constraint(&self, var: Symbol) -> Option<(Symbol, &'a LogicExpr<'a>)> {
        for scope in self.scopes.iter().rev() {
            if let Some(entry) = scope.get(&var) {
                return Some(*entry);
            }
        }
        None
    }

    /// Phase 50: Register a variable with its type for capability resolution
    fn register_variable_type(&mut self, var: Symbol, type_name: String) {
        self.variable_types.insert(var, type_name);
    }

    /// Phase 50: Find a variable name by its type (for resolving "the document" to "doc")
    fn find_variable_by_type(&self, type_name: &str, interner: &Interner) -> Option<String> {
        let type_lower = type_name.to_lowercase();
        for (var_sym, var_type) in &self.variable_types {
            if var_type.to_lowercase() == type_lower {
                return Some(interner.resolve(*var_sym).to_string());
            }
        }
        None
    }
}

/// Emits a debug_assert for a refinement predicate, substituting the bound variable.
fn emit_refinement_check(
    var_name: &str,
    bound_var: Symbol,
    predicate: &LogicExpr,
    interner: &Interner,
    indent_str: &str,
    output: &mut String,
) {
    let assertion = codegen_assertion(predicate, interner);
    let bound = interner.resolve(bound_var);
    let check = if bound == var_name {
        assertion
    } else {
        replace_word(&assertion, bound, var_name)
    };
    writeln!(output, "{}debug_assert!({});", indent_str, check).unwrap();
}

/// Word-boundary replacement to substitute bound variable with actual variable.
fn replace_word(text: &str, from: &str, to: &str) -> String {
    let mut result = String::with_capacity(text.len());
    let mut word = String::new();
    for c in text.chars() {
        if c.is_alphanumeric() || c == '_' {
            word.push(c);
        } else {
            if !word.is_empty() {
                result.push_str(if word == from { to } else { &word });
                word.clear();
            }
            result.push(c);
        }
    }
    if !word.is_empty() {
        result.push_str(if word == from { to } else { &word });
    }
    result
}

// =============================================================================
// Phase 56: Mount+Sync Detection for Distributed<T>
// =============================================================================

/// Tracks which variables have Mount and/or Sync statements.
/// Used to detect when a variable needs Distributed<T> instead of separate wrappers.
#[derive(Debug, Default)]
pub struct VariableCapabilities {
    /// Variable has a Mount statement
    mounted: bool,
    /// Variable has a Sync statement
    synced: bool,
    /// Path expression for Mount (as generated code string)
    mount_path: Option<String>,
    /// Topic expression for Sync (as generated code string)
    sync_topic: Option<String>,
}

/// Helper to create an empty VariableCapabilities map (for tests).
pub fn empty_var_caps() -> HashMap<Symbol, VariableCapabilities> {
    HashMap::new()
}

/// Pre-scan statements to detect variables that have both Mount and Sync.
/// Returns a map from variable Symbol to its capabilities.
fn analyze_variable_capabilities<'a>(
    stmts: &[Stmt<'a>],
    interner: &Interner,
) -> HashMap<Symbol, VariableCapabilities> {
    let mut caps: HashMap<Symbol, VariableCapabilities> = HashMap::new();
    let empty_synced = HashSet::new();

    for stmt in stmts {
        match stmt {
            Stmt::Mount { var, path } => {
                let entry = caps.entry(*var).or_default();
                entry.mounted = true;
                entry.mount_path = Some(codegen_expr(path, interner, &empty_synced));
            }
            Stmt::Sync { var, topic } => {
                let entry = caps.entry(*var).or_default();
                entry.synced = true;
                entry.sync_topic = Some(codegen_expr(topic, interner, &empty_synced));
            }
            // Recursively check nested blocks (Block<'a> is &[Stmt<'a>])
            Stmt::If { then_block, else_block, .. } => {
                let nested = analyze_variable_capabilities(then_block, interner);
                for (var, cap) in nested {
                    let entry = caps.entry(var).or_default();
                    if cap.mounted { entry.mounted = true; entry.mount_path = cap.mount_path; }
                    if cap.synced { entry.synced = true; entry.sync_topic = cap.sync_topic; }
                }
                if let Some(else_b) = else_block {
                    let nested = analyze_variable_capabilities(else_b, interner);
                    for (var, cap) in nested {
                        let entry = caps.entry(var).or_default();
                        if cap.mounted { entry.mounted = true; entry.mount_path = cap.mount_path; }
                        if cap.synced { entry.synced = true; entry.sync_topic = cap.sync_topic; }
                    }
                }
            }
            Stmt::While { body, .. } | Stmt::Repeat { body, .. } => {
                let nested = analyze_variable_capabilities(body, interner);
                for (var, cap) in nested {
                    let entry = caps.entry(var).or_default();
                    if cap.mounted { entry.mounted = true; entry.mount_path = cap.mount_path; }
                    if cap.synced { entry.synced = true; entry.sync_topic = cap.sync_topic; }
                }
            }
            _ => {}
        }
    }

    caps
}

/// Phase 51: Detect if any statements require async execution.
/// Returns true if the program needs #[tokio::main] async fn main().
fn requires_async(stmts: &[Stmt]) -> bool {
    stmts.iter().any(|s| requires_async_stmt(s))
}

fn requires_async_stmt(stmt: &Stmt) -> bool {
    match stmt {
        // Phase 9: Concurrent blocks use tokio::join!
        Stmt::Concurrent { tasks } => true,
        // Phase 51: Network operations and Sleep are async
        Stmt::Listen { .. } => true,
        Stmt::ConnectTo { .. } => true,
        Stmt::Sleep { .. } => true,
        // Phase 52: Sync is async (GossipSub subscription)
        Stmt::Sync { .. } => true,
        // Phase 53: Mount is async (VFS file operations)
        Stmt::Mount { .. } => true,
        // Phase 53: File I/O is async (VFS operations)
        Stmt::ReadFrom { source: ReadSource::File(_), .. } => true,
        Stmt::WriteFile { .. } => true,
        // Phase 54: Go-like concurrency is async
        Stmt::LaunchTask { .. } => true,
        Stmt::LaunchTaskWithHandle { .. } => true,
        Stmt::SendPipe { .. } => true,
        Stmt::ReceivePipe { .. } => true,
        Stmt::Select { .. } => true,
        // While and Repeat are now always async due to check_preemption()
        // (handled below in recursive check)
        // Recursively check nested blocks
        Stmt::If { then_block, else_block, .. } => {
            then_block.iter().any(|s| requires_async_stmt(s))
                || else_block.map_or(false, |b| b.iter().any(|s| requires_async_stmt(s)))
        }
        Stmt::While { body, .. } => body.iter().any(|s| requires_async_stmt(s)),
        Stmt::Repeat { body, .. } => body.iter().any(|s| requires_async_stmt(s)),
        Stmt::Zone { body, .. } => body.iter().any(|s| requires_async_stmt(s)),
        Stmt::Parallel { tasks } => tasks.iter().any(|s| requires_async_stmt(s)),
        Stmt::FunctionDef { body, .. } => body.iter().any(|s| requires_async_stmt(s)),
        _ => false,
    }
}

/// Phase 53: Detect if any statements require VFS (Virtual File System).
/// Returns true if the program uses file operations or persistent storage.
fn requires_vfs(stmts: &[Stmt]) -> bool {
    stmts.iter().any(|s| requires_vfs_stmt(s))
}

fn requires_vfs_stmt(stmt: &Stmt) -> bool {
    match stmt {
        // Phase 53: Mount uses VFS for persistent storage
        Stmt::Mount { .. } => true,
        // Phase 53: File I/O uses VFS
        Stmt::ReadFrom { source: ReadSource::File(_), .. } => true,
        Stmt::WriteFile { .. } => true,
        // Recursively check nested blocks
        Stmt::If { then_block, else_block, .. } => {
            then_block.iter().any(|s| requires_vfs_stmt(s))
                || else_block.map_or(false, |b| b.iter().any(|s| requires_vfs_stmt(s)))
        }
        Stmt::While { body, .. } => body.iter().any(|s| requires_vfs_stmt(s)),
        Stmt::Repeat { body, .. } => body.iter().any(|s| requires_vfs_stmt(s)),
        Stmt::Zone { body, .. } => body.iter().any(|s| requires_vfs_stmt(s)),
        Stmt::Concurrent { tasks } => tasks.iter().any(|s| requires_vfs_stmt(s)),
        Stmt::Parallel { tasks } => tasks.iter().any(|s| requires_vfs_stmt(s)),
        Stmt::FunctionDef { body, .. } => body.iter().any(|s| requires_vfs_stmt(s)),
        _ => false,
    }
}

/// Phase 49b: Extract root identifier from expression for mutability analysis.
/// Works with both simple identifiers and field accesses.
fn get_root_identifier_for_mutability(expr: &Expr) -> Option<Symbol> {
    match expr {
        Expr::Identifier(sym) => Some(*sym),
        Expr::FieldAccess { object, .. } => get_root_identifier_for_mutability(object),
        _ => None,
    }
}

/// Grand Challenge: Collect all variables that need `let mut` in Rust.
/// This includes:
/// - Variables that are targets of `Set` statements (reassignment)
/// - Variables that are targets of `Push` statements (mutation via push)
/// - Variables that are targets of `Pop` statements (mutation via pop)
fn collect_mutable_vars(stmts: &[Stmt]) -> HashSet<Symbol> {
    let mut targets = HashSet::new();
    for stmt in stmts {
        collect_mutable_vars_stmt(stmt, &mut targets);
    }
    targets
}

fn collect_mutable_vars_stmt(stmt: &Stmt, targets: &mut HashSet<Symbol>) {
    match stmt {
        Stmt::Set { target, .. } => {
            targets.insert(*target);
        }
        Stmt::Push { collection, .. } => {
            // If collection is an identifier, it needs to be mutable
            if let Expr::Identifier(sym) = collection {
                targets.insert(*sym);
            }
        }
        Stmt::Pop { collection, .. } => {
            // If collection is an identifier, it needs to be mutable
            if let Expr::Identifier(sym) = collection {
                targets.insert(*sym);
            }
        }
        Stmt::Add { collection, .. } => {
            // If collection is an identifier (Set) or field access, root needs to be mutable
            if let Some(sym) = get_root_identifier_for_mutability(collection) {
                targets.insert(sym);
            }
        }
        Stmt::Remove { collection, .. } => {
            // If collection is an identifier (Set) or field access, root needs to be mutable
            if let Some(sym) = get_root_identifier_for_mutability(collection) {
                targets.insert(sym);
            }
        }
        Stmt::SetIndex { collection, .. } => {
            // If collection is an identifier, it needs to be mutable
            if let Expr::Identifier(sym) = collection {
                targets.insert(*sym);
            }
        }
        Stmt::If { then_block, else_block, .. } => {
            for s in *then_block {
                collect_mutable_vars_stmt(s, targets);
            }
            if let Some(else_stmts) = else_block {
                for s in *else_stmts {
                    collect_mutable_vars_stmt(s, targets);
                }
            }
        }
        Stmt::While { body, .. } => {
            for s in *body {
                collect_mutable_vars_stmt(s, targets);
            }
        }
        Stmt::Repeat { body, .. } => {
            for s in *body {
                collect_mutable_vars_stmt(s, targets);
            }
        }
        Stmt::Zone { body, .. } => {
            for s in *body {
                collect_mutable_vars_stmt(s, targets);
            }
        }
        // Phase 9: Structured Concurrency blocks
        Stmt::Concurrent { tasks } | Stmt::Parallel { tasks } => {
            for s in *tasks {
                collect_mutable_vars_stmt(s, targets);
            }
        }
        // Phase 49b: CRDT operations require mutable access
        Stmt::IncreaseCrdt { object, .. } | Stmt::DecreaseCrdt { object, .. } => {
            // Extract root variable from field access (e.g., g.score -> g)
            if let Some(sym) = get_root_identifier_for_mutability(object) {
                targets.insert(sym);
            }
        }
        Stmt::AppendToSequence { sequence, .. } => {
            if let Some(sym) = get_root_identifier_for_mutability(sequence) {
                targets.insert(sym);
            }
        }
        Stmt::ResolveConflict { object, .. } => {
            if let Some(sym) = get_root_identifier_for_mutability(object) {
                targets.insert(sym);
            }
        }
        // Phase 49b: SetField on MVRegister/LWWRegister uses .set() which requires &mut self
        Stmt::SetField { object, .. } => {
            if let Some(sym) = get_root_identifier_for_mutability(object) {
                targets.insert(sym);
            }
        }
        _ => {}
    }
}

// =============================================================================
// Phase 50: Policy Method Generation
// =============================================================================

/// Generate impl blocks with predicate and capability methods for security policies.
fn codegen_policy_impls(policies: &PolicyRegistry, interner: &Interner) -> String {
    let mut output = String::new();

    // Collect all types that have policies
    let mut type_predicates: HashMap<Symbol, Vec<&PredicateDef>> = HashMap::new();
    let mut type_capabilities: HashMap<Symbol, Vec<&CapabilityDef>> = HashMap::new();

    for (type_sym, predicates) in policies.iter_predicates() {
        type_predicates.entry(*type_sym).or_insert_with(Vec::new).extend(predicates.iter());
    }

    for (type_sym, capabilities) in policies.iter_capabilities() {
        type_capabilities.entry(*type_sym).or_insert_with(Vec::new).extend(capabilities.iter());
    }

    // Get all types that have any policies
    let mut all_types: HashSet<Symbol> = HashSet::new();
    all_types.extend(type_predicates.keys().copied());
    all_types.extend(type_capabilities.keys().copied());

    // Generate impl block for each type
    for type_sym in all_types {
        let type_name = interner.resolve(type_sym);

        writeln!(output, "impl {} {{", type_name).unwrap();

        // Generate predicate methods
        if let Some(predicates) = type_predicates.get(&type_sym) {
            for pred in predicates {
                let pred_name = interner.resolve(pred.predicate_name).to_lowercase();
                writeln!(output, "    pub fn is_{}(&self) -> bool {{", pred_name).unwrap();
                let condition_code = codegen_policy_condition(&pred.condition, interner);
                writeln!(output, "        {}", condition_code).unwrap();
                writeln!(output, "    }}\n").unwrap();
            }
        }

        // Generate capability methods
        if let Some(capabilities) = type_capabilities.get(&type_sym) {
            for cap in capabilities {
                let action_name = interner.resolve(cap.action).to_lowercase();
                let object_type = interner.resolve(cap.object_type);
                let object_param = object_type.to_lowercase();

                writeln!(output, "    pub fn can_{}(&self, {}: &{}) -> bool {{",
                         action_name, object_param, object_type).unwrap();
                let condition_code = codegen_policy_condition(&cap.condition, interner);
                writeln!(output, "        {}", condition_code).unwrap();
                writeln!(output, "    }}\n").unwrap();
            }
        }

        writeln!(output, "}}\n").unwrap();
    }

    output
}

/// Generate Rust code for a policy condition.
fn codegen_policy_condition(condition: &PolicyCondition, interner: &Interner) -> String {
    match condition {
        PolicyCondition::FieldEquals { field, value, is_string_literal } => {
            let field_name = interner.resolve(*field);
            let value_str = interner.resolve(*value);
            if *is_string_literal {
                format!("self.{} == \"{}\"", field_name, value_str)
            } else {
                format!("self.{} == {}", field_name, value_str)
            }
        }
        PolicyCondition::FieldBool { field, value } => {
            let field_name = interner.resolve(*field);
            format!("self.{} == {}", field_name, value)
        }
        PolicyCondition::Predicate { subject: _, predicate } => {
            let pred_name = interner.resolve(*predicate).to_lowercase();
            format!("self.is_{}()", pred_name)
        }
        PolicyCondition::ObjectFieldEquals { subject: _, object, field } => {
            let object_name = interner.resolve(*object).to_lowercase();
            let field_name = interner.resolve(*field);
            format!("self == &{}.{}", object_name, field_name)
        }
        PolicyCondition::Or(left, right) => {
            let left_code = codegen_policy_condition(left, interner);
            let right_code = codegen_policy_condition(right, interner);
            format!("{} || {}", left_code, right_code)
        }
        PolicyCondition::And(left, right) => {
            let left_code = codegen_policy_condition(left, interner);
            let right_code = codegen_policy_condition(right, interner);
            format!("{} && {}", left_code, right_code)
        }
    }
}

/// Collect LWWRegister and MVRegister field paths for special handling in SetField codegen.
/// Returns a set of (type_name, field_name) pairs where the field uses .set() method.
fn collect_lww_fields(registry: &TypeRegistry, interner: &Interner) -> HashSet<(String, String)> {
    let mut lww_fields = HashSet::new();
    for (type_sym, def) in registry.iter_types() {
        if let TypeDef::Struct { fields, .. } = def {
            let type_name = interner.resolve(*type_sym).to_string();
            for field in fields {
                if let FieldType::Generic { base, .. } = &field.ty {
                    let base_name = interner.resolve(*base);
                    // Phase 49b: Both LWWRegister and MVRegister (Divergent) use .set()
                    if base_name == "LastWriteWins" || base_name == "Divergent" || base_name == "MVRegister" {
                        let field_name = interner.resolve(field.name).to_string();
                        lww_fields.insert((type_name.clone(), field_name));
                    }
                }
            }
        }
    }
    lww_fields
}

/// Phase 54: Collect function names that are async.
/// Used by LaunchTask codegen to determine if .await is needed.
fn collect_async_functions(stmts: &[Stmt]) -> HashSet<Symbol> {
    let mut async_fns = HashSet::new();
    for stmt in stmts {
        if let Stmt::FunctionDef { name, body, .. } = stmt {
            if body.iter().any(|s| requires_async_stmt(s)) {
                async_fns.insert(*name);
            }
        }
    }
    async_fns
}

/// Phase 54: Collect parameters that are used as pipe senders in function body.
/// If a param appears in `SendPipe { pipe: Expr::Identifier(param) }`, it's a sender.
fn collect_pipe_sender_params(body: &[Stmt]) -> HashSet<Symbol> {
    let mut senders = HashSet::new();
    for stmt in body {
        collect_pipe_sender_params_stmt(stmt, &mut senders);
    }
    senders
}

fn collect_pipe_sender_params_stmt(stmt: &Stmt, senders: &mut HashSet<Symbol>) {
    match stmt {
        Stmt::SendPipe { pipe, .. } | Stmt::TrySendPipe { pipe, .. } => {
            if let Expr::Identifier(sym) = pipe {
                senders.insert(*sym);
            }
        }
        Stmt::If { then_block, else_block, .. } => {
            for s in *then_block {
                collect_pipe_sender_params_stmt(s, senders);
            }
            if let Some(else_stmts) = else_block {
                for s in *else_stmts {
                    collect_pipe_sender_params_stmt(s, senders);
                }
            }
        }
        Stmt::While { body, .. } | Stmt::Repeat { body, .. } | Stmt::Zone { body, .. } => {
            for s in *body {
                collect_pipe_sender_params_stmt(s, senders);
            }
        }
        _ => {}
    }
}

/// Phase 54: Collect variables that are pipe declarations (created with CreatePipe).
/// These have _tx/_rx suffixes, while pipe parameters don't.
fn collect_pipe_vars(stmts: &[Stmt]) -> HashSet<Symbol> {
    let mut pipe_vars = HashSet::new();
    for stmt in stmts {
        collect_pipe_vars_stmt(stmt, &mut pipe_vars);
    }
    pipe_vars
}

fn collect_pipe_vars_stmt(stmt: &Stmt, pipe_vars: &mut HashSet<Symbol>) {
    match stmt {
        Stmt::CreatePipe { var, .. } => {
            pipe_vars.insert(*var);
        }
        Stmt::If { then_block, else_block, .. } => {
            for s in *then_block {
                collect_pipe_vars_stmt(s, pipe_vars);
            }
            if let Some(else_stmts) = else_block {
                for s in *else_stmts {
                    collect_pipe_vars_stmt(s, pipe_vars);
                }
            }
        }
        Stmt::While { body, .. } | Stmt::Repeat { body, .. } | Stmt::Zone { body, .. } => {
            for s in *body {
                collect_pipe_vars_stmt(s, pipe_vars);
            }
        }
        Stmt::Concurrent { tasks } | Stmt::Parallel { tasks } => {
            for s in *tasks {
                collect_pipe_vars_stmt(s, pipe_vars);
            }
        }
        _ => {}
    }
}

/// Generate complete Rust program with struct definitions and main function.
///
/// Phase 31: Structs are wrapped in `mod user_types` to enforce visibility.
/// Phase 32: Function definitions are emitted before main.
/// Phase 50: Accepts PolicyRegistry to generate security predicate methods.
pub fn codegen_program(stmts: &[Stmt], registry: &TypeRegistry, policies: &PolicyRegistry, interner: &Interner) -> String {
    let mut output = String::new();

    // Prelude
    writeln!(output, "use logos_core::prelude::*;\n").unwrap();

    // Phase 49: Collect LWWRegister fields for special SetField handling
    let lww_fields = collect_lww_fields(registry, interner);

    // Phase 54: Collect async functions for Launch codegen
    let async_functions = collect_async_functions(stmts);

    // Phase 54: Collect pipe declarations (variables with _tx/_rx suffixes)
    let main_pipe_vars = collect_pipe_vars(stmts);

    // Collect user-defined structs from registry (Phase 34: generics, Phase 47: is_portable, Phase 49: is_shared)
    let structs: Vec<_> = registry.iter_types()
        .filter_map(|(name, def)| {
            if let TypeDef::Struct { fields, generics, is_portable, is_shared } = def {
                if !fields.is_empty() || !generics.is_empty() {
                    Some((*name, fields.clone(), generics.clone(), *is_portable, *is_shared))
                } else {
                    None
                }
            } else {
                None
            }
        })
        .collect();

    // Phase 33/34: Collect user-defined enums from registry (generics, Phase 47: is_portable, Phase 49: is_shared)
    let enums: Vec<_> = registry.iter_types()
        .filter_map(|(name, def)| {
            if let TypeDef::Enum { variants, generics, is_portable, is_shared } = def {
                if !variants.is_empty() || !generics.is_empty() {
                    Some((*name, variants.clone(), generics.clone(), *is_portable, *is_shared))
                } else {
                    None
                }
            } else {
                None
            }
        })
        .collect();

    // Emit struct and enum definitions in user_types module if any exist
    if !structs.is_empty() || !enums.is_empty() {
        writeln!(output, "pub mod user_types {{").unwrap();
        writeln!(output, "    use super::*;\n").unwrap();

        for (name, fields, generics, is_portable, is_shared) in &structs {
            output.push_str(&codegen_struct_def(*name, fields, generics, *is_portable, *is_shared, interner, 4));
        }

        for (name, variants, generics, is_portable, is_shared) in &enums {
            output.push_str(&codegen_enum_def(*name, variants, generics, *is_portable, *is_shared, interner, 4));
        }

        writeln!(output, "}}\n").unwrap();
        writeln!(output, "use user_types::*;\n").unwrap();
    }

    // Phase 50: Generate policy impl blocks with predicate and capability methods
    output.push_str(&codegen_policy_impls(policies, interner));

    // Phase 32/38: Emit function definitions before main
    for stmt in stmts {
        if let Stmt::FunctionDef { name, params, body, return_type, is_native } = stmt {
            output.push_str(&codegen_function_def(*name, params, body, return_type.as_ref().copied(), *is_native, interner, &lww_fields, &async_functions));
        }
    }

    // Grand Challenge: Collect variables that need to be mutable
    let main_stmts: Vec<&Stmt> = stmts.iter()
        .filter(|s| !matches!(s, Stmt::FunctionDef { .. }))
        .collect();
    let mut main_mutable_vars = HashSet::new();
    for stmt in &main_stmts {
        collect_mutable_vars_stmt(stmt, &mut main_mutable_vars);
    }

    // Main function
    // Phase 51: Use async main when async operations are present
    if requires_async(stmts) {
        writeln!(output, "#[tokio::main]").unwrap();
        writeln!(output, "async fn main() {{").unwrap();
    } else {
        writeln!(output, "fn main() {{").unwrap();
    }
    // Phase 53: Inject VFS when file operations or persistence is used
    if requires_vfs(stmts) {
        writeln!(output, "    let vfs = logos_core::fs::NativeVfs::new(\".\");").unwrap();
    }
    let mut main_ctx = RefinementContext::new();
    let mut main_synced_vars = HashSet::new();  // Phase 52: Track synced variables in main
    // Phase 56: Pre-scan for Mount+Sync combinations
    let main_var_caps = analyze_variable_capabilities(stmts, interner);
    for stmt in stmts {
        // Skip function definitions - they're already emitted above
        if matches!(stmt, Stmt::FunctionDef { .. }) {
            continue;
        }
        output.push_str(&codegen_stmt(stmt, interner, 1, &main_mutable_vars, &mut main_ctx, &lww_fields, &mut main_synced_vars, &main_var_caps, &async_functions, &main_pipe_vars));
    }
    writeln!(output, "}}").unwrap();
    output
}

/// Phase 32/38: Generate a function definition.
/// Phase 38: Updated for native functions and TypeExpr types.
/// Phase 49: Accepts lww_fields for LWWRegister SetField handling.
fn codegen_function_def(
    name: Symbol,
    params: &[(Symbol, &TypeExpr)],
    body: &[Stmt],
    return_type: Option<&TypeExpr>,
    is_native: bool,
    interner: &Interner,
    lww_fields: &HashSet<(String, String)>,
    async_functions: &HashSet<Symbol>,  // Phase 54
) -> String {
    let mut output = String::new();
    let func_name = interner.resolve(name);

    // Phase 54: Detect which parameters are used as pipe senders
    let pipe_sender_params = collect_pipe_sender_params(body);

    // Build parameter list using TypeExpr
    let params_str: Vec<String> = params.iter()
        .map(|(param_name, param_type)| {
            let name = interner.resolve(*param_name);
            let ty = codegen_type_expr(param_type, interner);
            // Phase 54: If param is used as a pipe sender, wrap type in Sender<T>
            if pipe_sender_params.contains(param_name) {
                format!("{}: tokio::sync::mpsc::Sender<{}>", name, ty)
            } else {
                format!("{}: {}", name, ty)
            }
        })
        .collect();

    // Get return type string from TypeExpr or infer from body
    let return_type_str = return_type
        .map(|t| codegen_type_expr(t, interner))
        .or_else(|| infer_return_type_from_body(body, interner));

    // Phase 51: Check if function body requires async
    let is_async = body.iter().any(|s| requires_async_stmt(s));
    let fn_keyword = if is_async { "async fn" } else { "fn" };

    // Build function signature
    let signature = if let Some(ref ret_ty) = return_type_str {
        if ret_ty != "()" {
            format!("{} {}({}) -> {}", fn_keyword, func_name, params_str.join(", "), ret_ty)
        } else {
            format!("{} {}({})", fn_keyword, func_name, params_str.join(", "))
        }
    } else {
        format!("{} {}({})", fn_keyword, func_name, params_str.join(", "))
    };

    // Phase 38: Handle native functions
    if is_native {
        let (module, core_fn) = map_native_function(func_name);
        writeln!(output, "{} {{", signature).unwrap();

        // Generate call to logos_core
        let arg_names: Vec<&str> = params.iter()
            .map(|(n, _)| interner.resolve(*n))
            .collect();

        writeln!(output, "    logos_core::{}::{}({})", module, core_fn, arg_names.join(", ")).unwrap();
        writeln!(output, "}}\n").unwrap();
    } else {
        // Non-native: emit body
        // Grand Challenge: Collect mutable vars for this function
        let func_mutable_vars = collect_mutable_vars(body);
        writeln!(output, "{} {{", signature).unwrap();
        let mut func_ctx = RefinementContext::new();
        let mut func_synced_vars = HashSet::new();  // Phase 52: Track synced variables in function
        // Phase 56: Pre-scan for Mount+Sync combinations in function body
        let func_var_caps = analyze_variable_capabilities(body, interner);

        // Phase 50: Register parameter types for capability Check resolution
        for (param_name, param_type) in params {
            let type_name = codegen_type_expr(param_type, interner);
            func_ctx.register_variable_type(*param_name, type_name);
        }

        // Phase 54: Functions receive pipe senders as parameters, no local pipe declarations
        let func_pipe_vars = HashSet::new();

        for stmt in body {
            output.push_str(&codegen_stmt(stmt, interner, 1, &func_mutable_vars, &mut func_ctx, lww_fields, &mut func_synced_vars, &func_var_caps, async_functions, &func_pipe_vars));
        }
        writeln!(output, "}}\n").unwrap();
    }

    output
}

/// Phase 38: Map native function names to logos_core module paths.
fn map_native_function(name: &str) -> (&'static str, &'static str) {
    match name {
        "read" => ("file", "read"),
        "write" => ("file", "write"),
        "now" => ("time", "now"),
        "sleep" => ("time", "sleep"),
        "randomInt" => ("random", "randomInt"),
        "randomFloat" => ("random", "randomFloat"),
        "get" => ("env", "get"),
        "args" => ("env", "args"),
        _ => panic!("Unknown native function: {}. Add mapping to map_native_function().", name),
    }
}

/// Phase 38: Convert TypeExpr to Rust type string.
fn codegen_type_expr(ty: &TypeExpr, interner: &Interner) -> String {
    match ty {
        TypeExpr::Primitive(sym) => {
            map_type_to_rust(interner.resolve(*sym))
        }
        TypeExpr::Named(sym) => {
            let name = interner.resolve(*sym);
            // Check for common mappings
            map_type_to_rust(name)
        }
        TypeExpr::Generic { base, params } => {
            let base_name = interner.resolve(*base);
            let params_str: Vec<String> = params.iter()
                .map(|p| codegen_type_expr(p, interner))
                .collect();

            match base_name {
                "Result" => {
                    if params_str.len() == 2 {
                        format!("Result<{}, {}>", params_str[0], params_str[1])
                    } else if params_str.len() == 1 {
                        format!("Result<{}, String>", params_str[0])
                    } else {
                        "Result<(), String>".to_string()
                    }
                }
                "Option" => {
                    if !params_str.is_empty() {
                        format!("Option<{}>", params_str[0])
                    } else {
                        "Option<()>".to_string()
                    }
                }
                "Seq" | "List" | "Vec" => {
                    if !params_str.is_empty() {
                        format!("Vec<{}>", params_str[0])
                    } else {
                        "Vec<()>".to_string()
                    }
                }
                "Map" | "HashMap" => {
                    if params_str.len() >= 2 {
                        format!("std::collections::HashMap<{}, {}>", params_str[0], params_str[1])
                    } else {
                        "std::collections::HashMap<String, String>".to_string()
                    }
                }
                "Set" | "HashSet" => {
                    if !params_str.is_empty() {
                        format!("std::collections::HashSet<{}>", params_str[0])
                    } else {
                        "std::collections::HashSet<()>".to_string()
                    }
                }
                other => {
                    if params_str.is_empty() {
                        other.to_string()
                    } else {
                        format!("{}<{}>", other, params_str.join(", "))
                    }
                }
            }
        }
        TypeExpr::Function { inputs, output } => {
            let inputs_str: Vec<String> = inputs.iter()
                .map(|i| codegen_type_expr(i, interner))
                .collect();
            let output_str = codegen_type_expr(output, interner);
            format!("fn({}) -> {}", inputs_str.join(", "), output_str)
        }
        // Phase 43C: Refinement types use the base type for Rust type annotation
        // The constraint predicate is handled separately via debug_assert!
        TypeExpr::Refinement { base, .. } => {
            codegen_type_expr(base, interner)
        }
        // Phase 53: Persistent storage wrapper
        TypeExpr::Persistent { inner } => {
            let inner_type = codegen_type_expr(inner, interner);
            format!("logos_core::storage::Persistent<{}>", inner_type)
        }
    }
}

/// Infer return type from function body by looking at Return statements.
fn infer_return_type_from_body(body: &[Stmt], _interner: &Interner) -> Option<String> {
    for stmt in body {
        if let Stmt::Return { value: Some(_) } = stmt {
            // For now, assume i64 for any expression return
            // TODO: Implement proper type inference
            return Some("i64".to_string());
        }
    }
    None
}

/// Map LOGOS type names to Rust types.
fn map_type_to_rust(ty: &str) -> String {
    match ty {
        "Int" => "i64".to_string(),
        "Nat" => "u64".to_string(),
        "Text" => "String".to_string(),
        "Bool" | "Boolean" => "bool".to_string(),
        "Real" => "f64".to_string(),
        "Char" => "char".to_string(),
        "Byte" => "u8".to_string(),
        "Unit" | "()" => "()".to_string(),
        other => other.to_string(),
    }
}

/// Generate a single struct definition with derives and visibility.
/// Phase 34: Now supports generic type parameters.
/// Phase 47: Now supports is_portable for Serialize/Deserialize derives.
/// Phase 49: Now supports is_shared for CRDT Merge impl.
fn codegen_struct_def(name: Symbol, fields: &[FieldDef], generics: &[Symbol], is_portable: bool, is_shared: bool, interner: &Interner, indent: usize) -> String {
    let ind = " ".repeat(indent);
    let mut output = String::new();

    // Build generic parameter string: <T, U> or empty
    let generic_str = if generics.is_empty() {
        String::new()
    } else {
        let params: Vec<&str> = generics.iter()
            .map(|g| interner.resolve(*g))
            .collect();
        format!("<{}>", params.join(", "))
    };

    // Phase 47: Add Serialize, Deserialize derives if portable
    // Phase 50: Add PartialEq for policy equality comparisons
    // Phase 52: Shared types also need Serialize/Deserialize for Synced<T>
    if is_portable || is_shared {
        writeln!(output, "{}#[derive(Default, Debug, Clone, PartialEq, serde::Serialize, serde::Deserialize)]", ind).unwrap();
    } else {
        writeln!(output, "{}#[derive(Default, Debug, Clone, PartialEq)]", ind).unwrap();
    }
    writeln!(output, "{}pub struct {}{} {{", ind, interner.resolve(name), generic_str).unwrap();

    for field in fields {
        let vis = if field.is_public { "pub " } else { "" };
        let rust_type = codegen_field_type(&field.ty, interner);
        writeln!(output, "{}    {}{}: {},", ind, vis, interner.resolve(field.name), rust_type).unwrap();
    }

    writeln!(output, "{}}}\n", ind).unwrap();

    // Phase 49: Generate Merge impl for Shared structs
    if is_shared {
        output.push_str(&codegen_merge_impl(name, fields, generics, interner, indent));
    }

    output
}

/// Phase 49: Generate impl Merge for a Shared struct.
fn codegen_merge_impl(name: Symbol, fields: &[FieldDef], generics: &[Symbol], interner: &Interner, indent: usize) -> String {
    let ind = " ".repeat(indent);
    let name_str = interner.resolve(name);
    let mut output = String::new();

    // Build generic parameter string: <T, U> or empty
    let generic_str = if generics.is_empty() {
        String::new()
    } else {
        let params: Vec<&str> = generics.iter()
            .map(|g| interner.resolve(*g))
            .collect();
        format!("<{}>", params.join(", "))
    };

    writeln!(output, "{}impl{} logos_core::crdt::Merge for {}{} {{", ind, generic_str, name_str, generic_str).unwrap();
    writeln!(output, "{}    fn merge(&mut self, other: &Self) {{", ind).unwrap();

    for field in fields {
        let field_name = interner.resolve(field.name);
        // Only merge fields that implement Merge (CRDT types)
        if is_crdt_field_type(&field.ty, interner) {
            writeln!(output, "{}        self.{}.merge(&other.{});", ind, field_name, field_name).unwrap();
        }
    }

    writeln!(output, "{}    }}", ind).unwrap();
    writeln!(output, "{}}}\n", ind).unwrap();

    output
}

/// Phase 49: Check if a field type is a CRDT type that implements Merge.
fn is_crdt_field_type(ty: &FieldType, interner: &Interner) -> bool {
    match ty {
        FieldType::Named(sym) => {
            let name = interner.resolve(*sym);
            matches!(name,
                "ConvergentCount" | "GCounter" |
                "Tally" | "PNCounter"
            )
        }
        FieldType::Generic { base, .. } => {
            let name = interner.resolve(*base);
            matches!(name,
                "LastWriteWins" | "LWWRegister" |
                "SharedSet" | "ORSet" | "SharedSet_AddWins" | "SharedSet_RemoveWins" |
                "SharedSequence" | "RGA" | "SharedSequence_YATA" | "CollaborativeSequence" |
                "SharedMap" | "ORMap" |
                "Divergent" | "MVRegister"
            )
        }
        _ => false,
    }
}

/// Phase 33/34: Generate enum definition with optional generic parameters.
/// Phase 47: Now supports is_portable for Serialize/Deserialize derives.
/// Phase 49: Now accepts is_shared parameter (enums don't generate Merge impl yet).
fn codegen_enum_def(name: Symbol, variants: &[VariantDef], generics: &[Symbol], is_portable: bool, _is_shared: bool, interner: &Interner, indent: usize) -> String {
    let ind = " ".repeat(indent);
    let mut output = String::new();

    // Build generic parameter string: <T, U> or empty
    let generic_str = if generics.is_empty() {
        String::new()
    } else {
        let params: Vec<&str> = generics.iter()
            .map(|g| interner.resolve(*g))
            .collect();
        format!("<{}>", params.join(", "))
    };

    // Phase 47: Add Serialize, Deserialize derives if portable
    if is_portable {
        writeln!(output, "{}#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]", ind).unwrap();
    } else {
        writeln!(output, "{}#[derive(Debug, Clone)]", ind).unwrap();
    }
    writeln!(output, "{}pub enum {}{} {{", ind, interner.resolve(name), generic_str).unwrap();

    for variant in variants {
        let variant_name = interner.resolve(variant.name);
        if variant.fields.is_empty() {
            // Unit variant
            writeln!(output, "{}    {},", ind, variant_name).unwrap();
        } else {
            // Struct variant with named fields
            let fields_str: Vec<String> = variant.fields.iter()
                .map(|f| {
                    let rust_type = codegen_field_type(&f.ty, interner);
                    format!("{}: {}", interner.resolve(f.name), rust_type)
                })
                .collect();
            writeln!(output, "{}    {} {{ {} }},", ind, variant_name, fields_str.join(", ")).unwrap();
        }
    }

    writeln!(output, "{}}}\n", ind).unwrap();
    output
}

/// Convert FieldType to Rust type string.
fn codegen_field_type(ty: &FieldType, interner: &Interner) -> String {
    match ty {
        FieldType::Primitive(sym) => {
            match interner.resolve(*sym) {
                "Int" => "i64".to_string(),
                "Nat" => "u64".to_string(),
                "Text" => "String".to_string(),
                "Bool" | "Boolean" => "bool".to_string(),
                "Real" => "f64".to_string(),
                "Char" => "char".to_string(),
                "Byte" => "u8".to_string(),
                "Unit" => "()".to_string(),
                other => other.to_string(),
            }
        }
        FieldType::Named(sym) => {
            let name = interner.resolve(*sym);
            match name {
                // Phase 49: CRDT type mapping
                "ConvergentCount" => "logos_core::crdt::GCounter".to_string(),
                // Phase 49b: New CRDT types (Wave 5)
                "Tally" => "logos_core::crdt::PNCounter".to_string(),
                _ => name.to_string(),
            }
        }
        FieldType::Generic { base, params } => {
            let base_name = interner.resolve(*base);
            let param_strs: Vec<String> = params.iter()
                .map(|p| codegen_field_type(p, interner))
                .collect();

            // Phase 49c: Handle CRDT types with bias/algorithm modifiers
            match base_name {
                // SharedSet with explicit bias
                "SharedSet_RemoveWins" => {
                    return format!("logos_core::crdt::ORSet<{}, logos_core::crdt::RemoveWins>", param_strs.join(", "));
                }
                "SharedSet_AddWins" => {
                    return format!("logos_core::crdt::ORSet<{}, logos_core::crdt::AddWins>", param_strs.join(", "));
                }
                // SharedSequence with YATA algorithm
                "SharedSequence_YATA" | "CollaborativeSequence" => {
                    return format!("logos_core::crdt::YATA<{}>", param_strs.join(", "));
                }
                _ => {}
            }

            let base_str = match base_name {
                "List" | "Seq" => "Vec",
                "Set" => "std::collections::HashSet",
                "Map" => "std::collections::HashMap",
                "Option" => "Option",
                "Result" => "Result",
                // Phase 49: CRDT generic type
                "LastWriteWins" => "logos_core::crdt::LWWRegister",
                // Phase 49b: New CRDT generic types (Wave 5) - default to AddWins for ORSet
                "SharedSet" | "ORSet" => "logos_core::crdt::ORSet",
                "SharedSequence" | "RGA" => "logos_core::crdt::RGA",
                "SharedMap" | "ORMap" => "logos_core::crdt::ORMap",
                "Divergent" | "MVRegister" => "logos_core::crdt::MVRegister",
                other => other,
            };
            format!("{}<{}>", base_str, param_strs.join(", "))
        }
        // Phase 34: Type parameter reference (T, U, etc.)
        FieldType::TypeParam(sym) => interner.resolve(*sym).to_string(),
    }
}

pub fn codegen_stmt<'a>(
    stmt: &Stmt<'a>,
    interner: &Interner,
    indent: usize,
    mutable_vars: &HashSet<Symbol>,
    ctx: &mut RefinementContext<'a>,
    lww_fields: &HashSet<(String, String)>,
    synced_vars: &mut HashSet<Symbol>,  // Phase 52: Track synced variables
    var_caps: &HashMap<Symbol, VariableCapabilities>,  // Phase 56: Mount+Sync detection
    async_functions: &HashSet<Symbol>,  // Phase 54: Functions that are async
    pipe_vars: &HashSet<Symbol>,  // Phase 54: Pipe declarations (have _tx/_rx suffixes)
) -> String {
    let indent_str = "    ".repeat(indent);
    let mut output = String::new();

    match stmt {
        Stmt::Let { var, ty, value, mutable } => {
            let var_name = interner.resolve(*var);
            let value_str = codegen_expr(value, interner, synced_vars);
            let type_annotation = ty.map(|t| codegen_type_expr(t, interner));

            // Grand Challenge: Variable is mutable if explicitly marked OR if it's a Set target
            let is_mutable = *mutable || mutable_vars.contains(var);

            match (is_mutable, type_annotation) {
                (true, Some(t)) => writeln!(output, "{}let mut {}: {} = {};", indent_str, var_name, t, value_str).unwrap(),
                (true, None) => writeln!(output, "{}let mut {} = {};", indent_str, var_name, value_str).unwrap(),
                (false, Some(t)) => writeln!(output, "{}let {}: {} = {};", indent_str, var_name, t, value_str).unwrap(),
                (false, None) => writeln!(output, "{}let {} = {};", indent_str, var_name, value_str).unwrap(),
            }

            // Phase 43C: Handle refinement type
            if let Some(TypeExpr::Refinement { base: _, var: bound_var, predicate }) = ty {
                emit_refinement_check(var_name, *bound_var, predicate, interner, &indent_str, &mut output);
                ctx.register(*var, *bound_var, predicate);
            }
        }

        Stmt::Set { target, value } => {
            let target_name = interner.resolve(*target);
            let value_str = codegen_expr(value, interner, synced_vars);
            writeln!(output, "{}{} = {};", indent_str, target_name, value_str).unwrap();

            // Phase 43C: Check if this variable has a refinement constraint
            if let Some((bound_var, predicate)) = ctx.get_constraint(*target) {
                emit_refinement_check(target_name, bound_var, predicate, interner, &indent_str, &mut output);
            }
        }

        Stmt::Call { function, args } => {
            let func_name = interner.resolve(*function);
            let args_str: Vec<String> = args.iter().map(|a| codegen_expr(a, interner, synced_vars)).collect();
            writeln!(output, "{}{}({});", indent_str, func_name, args_str.join(", ")).unwrap();
        }

        Stmt::If { cond, then_block, else_block } => {
            let cond_str = codegen_expr(cond, interner, synced_vars);
            writeln!(output, "{}if {} {{", indent_str, cond_str).unwrap();
            ctx.push_scope();
            for stmt in *then_block {
                output.push_str(&codegen_stmt(stmt, interner, indent + 1, mutable_vars, ctx, lww_fields, synced_vars, var_caps, async_functions, pipe_vars));
            }
            ctx.pop_scope();
            if let Some(else_stmts) = else_block {
                writeln!(output, "{}}} else {{", indent_str).unwrap();
                ctx.push_scope();
                for stmt in *else_stmts {
                    output.push_str(&codegen_stmt(stmt, interner, indent + 1, mutable_vars, ctx, lww_fields, synced_vars, var_caps, async_functions, pipe_vars));
                }
                ctx.pop_scope();
            }
            writeln!(output, "{}}}", indent_str).unwrap();
        }

        Stmt::While { cond, body, decreasing: _ } => {
            // decreasing is compile-time only, ignored at runtime
            let cond_str = codegen_expr(cond, interner, synced_vars);
            writeln!(output, "{}while {} {{", indent_str, cond_str).unwrap();
            ctx.push_scope();
            for stmt in *body {
                output.push_str(&codegen_stmt(stmt, interner, indent + 1, mutable_vars, ctx, lww_fields, synced_vars, var_caps, async_functions, pipe_vars));
            }
            ctx.pop_scope();
            writeln!(output, "{}}}", indent_str).unwrap();
        }

        Stmt::Repeat { var, iterable, body } => {
            let var_name = interner.resolve(*var);
            let iter_str = codegen_expr(iterable, interner, synced_vars);
            writeln!(output, "{}for {} in {} {{", indent_str, var_name, iter_str).unwrap();
            ctx.push_scope();
            for stmt in *body {
                output.push_str(&codegen_stmt(stmt, interner, indent + 1, mutable_vars, ctx, lww_fields, synced_vars, var_caps, async_functions, pipe_vars));
            }
            ctx.pop_scope();
            writeln!(output, "{}}}", indent_str).unwrap();
        }

        Stmt::Return { value } => {
            if let Some(v) = value {
                let value_str = codegen_expr(v, interner, synced_vars);
                writeln!(output, "{}return {};", indent_str, value_str).unwrap();
            } else {
                writeln!(output, "{}return;", indent_str).unwrap();
            }
        }

        Stmt::Assert { proposition } => {
            let condition = codegen_assertion(proposition, interner);
            writeln!(output, "{}debug_assert!({});", indent_str, condition).unwrap();
        }

        // Phase 35: Trust with documented justification
        Stmt::Trust { proposition, justification } => {
            let reason = interner.resolve(*justification);
            // Strip quotes if present (string literals include their quotes)
            let reason_clean = reason.trim_matches('"');
            writeln!(output, "{}// TRUST: {}", indent_str, reason_clean).unwrap();
            let condition = codegen_assertion(proposition, interner);
            writeln!(output, "{}debug_assert!({});", indent_str, condition).unwrap();
        }

        Stmt::RuntimeAssert { condition } => {
            let cond_str = codegen_expr(condition, interner, synced_vars);
            writeln!(output, "{}debug_assert!({});", indent_str, cond_str).unwrap();
        }

        // Phase 50: Security Check - mandatory runtime guard (NEVER optimized out)
        Stmt::Check { subject, predicate, is_capability, object, source_text, span } => {
            let subj_name = interner.resolve(*subject);
            let pred_name = interner.resolve(*predicate).to_lowercase();

            let call = if *is_capability {
                let obj_sym = object.expect("capability must have object");
                let obj_word = interner.resolve(obj_sym);

                // Phase 50: Type-based resolution
                // "Check that user can publish the document" -> find variable of type Document
                // First try to find a variable whose type matches the object word
                let obj_name = ctx.find_variable_by_type(obj_word, interner)
                    .unwrap_or_else(|| obj_word.to_string());

                format!("{}.can_{}(&{})", subj_name, pred_name, obj_name)
            } else {
                format!("{}.is_{}()", subj_name, pred_name)
            };

            writeln!(output, "{}if !({}) {{", indent_str, call).unwrap();
            writeln!(output, "{}    logos_core::panic_with(\"Security Check Failed at line {}: {}\");",
                     indent_str, span.start, source_text).unwrap();
            writeln!(output, "{}}}", indent_str).unwrap();
        }

        // Phase 51: P2P Networking - Listen on network address
        Stmt::Listen { address } => {
            let addr_str = codegen_expr(address, interner, synced_vars);
            // Pass &str instead of String
            writeln!(output, "{}logos_core::network::listen(&{}).await.expect(\"Failed to listen\");",
                     indent_str, addr_str).unwrap();
        }

        // Phase 51: P2P Networking - Connect to remote peer
        Stmt::ConnectTo { address } => {
            let addr_str = codegen_expr(address, interner, synced_vars);
            // Pass &str instead of String
            writeln!(output, "{}logos_core::network::connect(&{}).await.expect(\"Failed to connect\");",
                     indent_str, addr_str).unwrap();
        }

        // Phase 51: P2P Networking - Create PeerAgent remote handle
        Stmt::LetPeerAgent { var, address } => {
            let var_name = interner.resolve(*var);
            let addr_str = codegen_expr(address, interner, synced_vars);
            // Pass &str instead of String
            writeln!(output, "{}let {} = logos_core::network::PeerAgent::new(&{}).expect(\"Invalid address\");",
                     indent_str, var_name, addr_str).unwrap();
        }

        // Phase 51: Sleep for milliseconds
        Stmt::Sleep { milliseconds } => {
            let ms_str = codegen_expr(milliseconds, interner, synced_vars);
            // Use tokio async sleep
            writeln!(output, "{}tokio::time::sleep(std::time::Duration::from_millis({} as u64)).await;",
                     indent_str, ms_str).unwrap();
        }

        // Phase 52/56: Sync CRDT variable on topic
        Stmt::Sync { var, topic } => {
            let var_name = interner.resolve(*var);
            let topic_str = codegen_expr(topic, interner, synced_vars);

            // Phase 56: Check if this variable is also mounted
            if let Some(caps) = var_caps.get(var) {
                if caps.mounted {
                    // Both Mount and Sync: use Distributed<T>
                    // Mount statement will handle the Distributed::mount call
                    // Here we just track it as synced
                    synced_vars.insert(*var);
                    return output;  // Skip - Mount will emit Distributed<T>
                }
            }

            // Sync-only: use Synced<T>
            writeln!(
                output,
                "{}let {} = logos_core::crdt::Synced::new({}, &{}).await;",
                indent_str, var_name, var_name, topic_str
            ).unwrap();
            synced_vars.insert(*var);
        }

        // Phase 53/56: Mount persistent CRDT from journal
        Stmt::Mount { var, path } => {
            let var_name = interner.resolve(*var);
            let path_str = codegen_expr(path, interner, synced_vars);

            // Phase 56: Check if this variable is also synced
            if let Some(caps) = var_caps.get(var) {
                if caps.synced {
                    // Both Mount and Sync: use Distributed<T>
                    let topic_str = caps.sync_topic.as_ref()
                        .map(|s| s.as_str())
                        .unwrap_or("\"default\"");
                    writeln!(
                        output,
                        "{}let {} = logos_core::distributed::Distributed::mount(std::sync::Arc::new(vfs.clone()), &{}, Some({}.to_string())).await.expect(\"Failed to mount\");",
                        indent_str, var_name, path_str, topic_str
                    ).unwrap();
                    synced_vars.insert(*var);
                    return output;
                }
            }

            // Mount-only: use Persistent<T>
            writeln!(
                output,
                "{}let {} = logos_core::storage::Persistent::mount(&vfs, &{}).await.expect(\"Failed to mount\");",
                indent_str, var_name, path_str
            ).unwrap();
            synced_vars.insert(*var);
        }

        // =====================================================================
        // Phase 54: Go-like Concurrency Codegen
        // =====================================================================

        Stmt::LaunchTask { function, args } => {
            let fn_name = interner.resolve(*function);
            // Phase 54: When passing a pipe variable, pass the sender (_tx)
            let args_str: Vec<String> = args.iter()
                .map(|a| {
                    if let Expr::Identifier(sym) = a {
                        if pipe_vars.contains(sym) {
                            return format!("{}_tx.clone()", interner.resolve(*sym));
                        }
                    }
                    codegen_expr(a, interner, synced_vars)
                })
                .collect();
            // Phase 54: Add .await only if the function is async
            let await_suffix = if async_functions.contains(function) { ".await" } else { "" };
            writeln!(
                output,
                "{}tokio::spawn(async move {{ {}({}){await_suffix}; }});",
                indent_str, fn_name, args_str.join(", ")
            ).unwrap();
        }

        Stmt::LaunchTaskWithHandle { handle, function, args } => {
            let handle_name = interner.resolve(*handle);
            let fn_name = interner.resolve(*function);
            // Phase 54: When passing a pipe variable, pass the sender (_tx)
            let args_str: Vec<String> = args.iter()
                .map(|a| {
                    if let Expr::Identifier(sym) = a {
                        if pipe_vars.contains(sym) {
                            return format!("{}_tx.clone()", interner.resolve(*sym));
                        }
                    }
                    codegen_expr(a, interner, synced_vars)
                })
                .collect();
            // Phase 54: Add .await only if the function is async
            let await_suffix = if async_functions.contains(function) { ".await" } else { "" };
            writeln!(
                output,
                "{}let {} = tokio::spawn(async move {{ {}({}){await_suffix} }});",
                indent_str, handle_name, fn_name, args_str.join(", ")
            ).unwrap();
        }

        Stmt::CreatePipe { var, element_type, capacity } => {
            let var_name = interner.resolve(*var);
            let type_name = interner.resolve(*element_type);
            let cap = capacity.unwrap_or(32);
            // Map LOGOS types to Rust types
            let rust_type = match type_name {
                "Int" => "i64",
                "Nat" => "u64",
                "Text" => "String",
                "Bool" => "bool",
                _ => type_name,
            };
            writeln!(
                output,
                "{}let ({}_tx, mut {}_rx) = tokio::sync::mpsc::channel::<{}>({});",
                indent_str, var_name, var_name, rust_type, cap
            ).unwrap();
        }

        Stmt::SendPipe { value, pipe } => {
            let val_str = codegen_expr(value, interner, synced_vars);
            let pipe_str = codegen_expr(pipe, interner, synced_vars);
            // Phase 54: Check if pipe is a local declaration (has _tx suffix) or parameter (no suffix)
            let is_local_pipe = if let Expr::Identifier(sym) = pipe {
                pipe_vars.contains(sym)
            } else {
                false
            };
            if is_local_pipe {
                writeln!(
                    output,
                    "{}{}_tx.send({}).await.expect(\"pipe send failed\");",
                    indent_str, pipe_str, val_str
                ).unwrap();
            } else {
                writeln!(
                    output,
                    "{}{}.send({}).await.expect(\"pipe send failed\");",
                    indent_str, pipe_str, val_str
                ).unwrap();
            }
        }

        Stmt::ReceivePipe { var, pipe } => {
            let var_name = interner.resolve(*var);
            let pipe_str = codegen_expr(pipe, interner, synced_vars);
            // Phase 54: Check if pipe is a local declaration (has _rx suffix) or parameter (no suffix)
            let is_local_pipe = if let Expr::Identifier(sym) = pipe {
                pipe_vars.contains(sym)
            } else {
                false
            };
            if is_local_pipe {
                writeln!(
                    output,
                    "{}let {} = {}_rx.recv().await.expect(\"pipe closed\");",
                    indent_str, var_name, pipe_str
                ).unwrap();
            } else {
                writeln!(
                    output,
                    "{}let {} = {}.recv().await.expect(\"pipe closed\");",
                    indent_str, var_name, pipe_str
                ).unwrap();
            }
        }

        Stmt::TrySendPipe { value, pipe, result } => {
            let val_str = codegen_expr(value, interner, synced_vars);
            let pipe_str = codegen_expr(pipe, interner, synced_vars);
            // Phase 54: Check if pipe is a local declaration
            let is_local_pipe = if let Expr::Identifier(sym) = pipe {
                pipe_vars.contains(sym)
            } else {
                false
            };
            let suffix = if is_local_pipe { "_tx" } else { "" };
            if let Some(res) = result {
                let res_name = interner.resolve(*res);
                writeln!(
                    output,
                    "{}let {} = {}{}.try_send({}).is_ok();",
                    indent_str, res_name, pipe_str, suffix, val_str
                ).unwrap();
            } else {
                writeln!(
                    output,
                    "{}let _ = {}{}.try_send({});",
                    indent_str, pipe_str, suffix, val_str
                ).unwrap();
            }
        }

        Stmt::TryReceivePipe { var, pipe } => {
            let var_name = interner.resolve(*var);
            let pipe_str = codegen_expr(pipe, interner, synced_vars);
            // Phase 54: Check if pipe is a local declaration
            let is_local_pipe = if let Expr::Identifier(sym) = pipe {
                pipe_vars.contains(sym)
            } else {
                false
            };
            let suffix = if is_local_pipe { "_rx" } else { "" };
            writeln!(
                output,
                "{}let {} = {}{}.try_recv().ok();",
                indent_str, var_name, pipe_str, suffix
            ).unwrap();
        }

        Stmt::StopTask { handle } => {
            let handle_str = codegen_expr(handle, interner, synced_vars);
            writeln!(output, "{}{}.abort();", indent_str, handle_str).unwrap();
        }

        Stmt::Select { branches } => {
            use crate::ast::stmt::SelectBranch;

            writeln!(output, "{}tokio::select! {{", indent_str).unwrap();
            for branch in branches {
                match branch {
                    SelectBranch::Receive { var, pipe, body } => {
                        let var_name = interner.resolve(*var);
                        let pipe_str = codegen_expr(pipe, interner, synced_vars);
                        writeln!(
                            output,
                            "{}    {} = {}_rx.recv() => {{",
                            indent_str, var_name, pipe_str
                        ).unwrap();
                        writeln!(
                            output,
                            "{}        if let Some({}) = {} {{",
                            indent_str, var_name, var_name
                        ).unwrap();
                        for stmt in *body {
                            let stmt_code = codegen_stmt(stmt, interner, indent + 3, mutable_vars, ctx, lww_fields, synced_vars, var_caps, async_functions, pipe_vars);
                            write!(output, "{}", stmt_code).unwrap();
                        }
                        writeln!(output, "{}        }}", indent_str).unwrap();
                        writeln!(output, "{}    }}", indent_str).unwrap();
                    }
                    SelectBranch::Timeout { milliseconds, body } => {
                        let ms_str = codegen_expr(milliseconds, interner, synced_vars);
                        // Convert seconds to milliseconds if the value looks like seconds
                        writeln!(
                            output,
                            "{}    _ = tokio::time::sleep(std::time::Duration::from_secs({} as u64)) => {{",
                            indent_str, ms_str
                        ).unwrap();
                        for stmt in *body {
                            let stmt_code = codegen_stmt(stmt, interner, indent + 2, mutable_vars, ctx, lww_fields, synced_vars, var_caps, async_functions, pipe_vars);
                            write!(output, "{}", stmt_code).unwrap();
                        }
                        writeln!(output, "{}    }}", indent_str).unwrap();
                    }
                }
            }
            writeln!(output, "{}}}", indent_str).unwrap();
        }

        Stmt::Give { object, recipient } => {
            // Move semantics: pass ownership without borrowing
            let obj_str = codegen_expr(object, interner, synced_vars);
            let recv_str = codegen_expr(recipient, interner, synced_vars);
            writeln!(output, "{}{}({});", indent_str, recv_str, obj_str).unwrap();
        }

        Stmt::Show { object, recipient } => {
            // Borrow semantics: pass immutable reference
            let obj_str = codegen_expr(object, interner, synced_vars);
            let recv_str = codegen_expr(recipient, interner, synced_vars);
            writeln!(output, "{}{}(&{});", indent_str, recv_str, obj_str).unwrap();
        }

        Stmt::SetField { object, field, value } => {
            let obj_str = codegen_expr(object, interner, synced_vars);
            let field_name = interner.resolve(*field);
            let value_str = codegen_expr(value, interner, synced_vars);

            // Phase 49: Check if this field is an LWWRegister - use .set() instead of =
            // We check if ANY type has this field as LWW (heuristic - works for most cases)
            let is_lww = lww_fields.iter().any(|(_, f)| f == field_name);
            if is_lww {
                writeln!(output, "{}{}.{}.set({});", indent_str, obj_str, field_name, value_str).unwrap();
            } else {
                writeln!(output, "{}{}.{} = {};", indent_str, obj_str, field_name, value_str).unwrap();
            }
        }

        Stmt::StructDef { .. } => {
            // Struct definitions are handled in codegen_program, not here
        }

        Stmt::FunctionDef { .. } => {
            // Function definitions are handled in codegen_program, not here
        }

        Stmt::Inspect { target, arms, .. } => {
            let target_str = codegen_expr(target, interner, synced_vars);
            writeln!(output, "{}match {} {{", indent_str, target_str).unwrap();

            for arm in arms {
                if let Some(variant) = arm.variant {
                    let variant_name = interner.resolve(variant);
                    // Get the enum name from the arm, or fallback to just variant name
                    let enum_prefix = arm.enum_name
                        .map(|e| format!("{}::", interner.resolve(e)))
                        .unwrap_or_default();

                    if arm.bindings.is_empty() {
                        // Unit variant pattern
                        writeln!(output, "{}    {}{} => {{", indent_str, enum_prefix, variant_name).unwrap();
                    } else {
                        // Pattern with bindings
                        let bindings_str: Vec<String> = arm.bindings.iter()
                            .map(|(field, binding)| {
                                let field_name = interner.resolve(*field);
                                let binding_name = interner.resolve(*binding);
                                if field_name == binding_name {
                                    field_name.to_string()
                                } else {
                                    format!("{}: {}", field_name, binding_name)
                                }
                            })
                            .collect();
                        writeln!(output, "{}    {}{} {{ {} }} => {{", indent_str, enum_prefix, variant_name, bindings_str.join(", ")).unwrap();
                    }
                } else {
                    // Otherwise (wildcard) pattern
                    writeln!(output, "{}    _ => {{", indent_str).unwrap();
                }

                ctx.push_scope();
                for stmt in arm.body {
                    output.push_str(&codegen_stmt(stmt, interner, indent + 2, mutable_vars, ctx, lww_fields, synced_vars, var_caps, async_functions, pipe_vars));
                }
                ctx.pop_scope();
                writeln!(output, "{}    }}", indent_str).unwrap();
            }

            writeln!(output, "{}}}", indent_str).unwrap();
        }

        Stmt::Push { value, collection } => {
            let val_str = codegen_expr(value, interner, synced_vars);
            let coll_str = codegen_expr(collection, interner, synced_vars);
            writeln!(output, "{}{}.push({});", indent_str, coll_str, val_str).unwrap();
        }

        Stmt::Pop { collection, into } => {
            let coll_str = codegen_expr(collection, interner, synced_vars);
            match into {
                Some(var) => {
                    let var_name = interner.resolve(*var);
                    // Unwrap the Option returned by pop() - panics if empty
                    writeln!(output, "{}let {} = {}.pop().expect(\"Pop from empty collection\");", indent_str, var_name, coll_str).unwrap();
                }
                None => {
                    writeln!(output, "{}{}.pop();", indent_str, coll_str).unwrap();
                }
            }
        }

        Stmt::Add { value, collection } => {
            let val_str = codegen_expr(value, interner, synced_vars);
            let coll_str = codegen_expr(collection, interner, synced_vars);
            writeln!(output, "{}{}.insert({});", indent_str, coll_str, val_str).unwrap();
        }

        Stmt::Remove { value, collection } => {
            let val_str = codegen_expr(value, interner, synced_vars);
            let coll_str = codegen_expr(collection, interner, synced_vars);
            writeln!(output, "{}{}.remove(&{});", indent_str, coll_str, val_str).unwrap();
        }

        Stmt::SetIndex { collection, index, value } => {
            let coll_str = codegen_expr(collection, interner, synced_vars);
            let index_str = codegen_expr(index, interner, synced_vars);
            let value_str = codegen_expr(value, interner, synced_vars);
            // Phase 57: Polymorphic indexing via trait
            writeln!(output, "{}LogosIndexMut::logos_set(&mut {}, {}, {});", indent_str, coll_str, index_str, value_str).unwrap();
        }

        // Phase 8.5: Zone (memory arena) block
        Stmt::Zone { name, capacity, source_file, body } => {
            let zone_name = interner.resolve(*name);

            // Generate zone creation based on type
            if let Some(path_sym) = source_file {
                // Memory-mapped file zone
                let path = interner.resolve(*path_sym);
                writeln!(
                    output,
                    "{}let {} = logos_core::memory::Zone::new_mapped(\"{}\").expect(\"Failed to map file\");",
                    indent_str, zone_name, path
                ).unwrap();
            } else {
                // Heap arena zone
                let cap = capacity.unwrap_or(4096); // Default 4KB
                writeln!(
                    output,
                    "{}let {} = logos_core::memory::Zone::new_heap({});",
                    indent_str, zone_name, cap
                ).unwrap();
            }

            // Open block scope
            writeln!(output, "{}{{", indent_str).unwrap();
            ctx.push_scope();

            // Generate body statements
            for stmt in *body {
                output.push_str(&codegen_stmt(stmt, interner, indent + 1, mutable_vars, ctx, lww_fields, synced_vars, var_caps, async_functions, pipe_vars));
            }

            ctx.pop_scope();
            writeln!(output, "{}}}", indent_str).unwrap();
        }

        // Phase 9: Concurrent execution block (async, I/O-bound)
        // Generates tokio::join! for concurrent task execution
        // Phase 51: Variables used across multiple tasks are cloned to avoid move issues
        Stmt::Concurrent { tasks } => {
            // Collect Let statements to generate tuple destructuring
            let let_bindings: Vec<_> = tasks.iter().filter_map(|s| {
                if let Stmt::Let { var, .. } = s {
                    Some(interner.resolve(*var).to_string())
                } else {
                    None
                }
            }).collect();

            // Collect variables used in Call statements across all tasks
            let used_vars: HashSet<String> = tasks.iter().flat_map(|s| {
                if let Stmt::Call { args, .. } = s {
                    args.iter().filter_map(|arg| {
                        if let Expr::Identifier(sym) = arg {
                            Some(interner.resolve(*sym).to_string())
                        } else {
                            None
                        }
                    }).collect::<Vec<_>>()
                } else {
                    vec![]
                }
            }).collect();

            if !let_bindings.is_empty() {
                // Generate tuple destructuring for concurrent Let bindings
                writeln!(output, "{}let ({}) = tokio::join!(", indent_str, let_bindings.join(", ")).unwrap();
            } else {
                writeln!(output, "{}tokio::join!(", indent_str).unwrap();
            }

            for (i, stmt) in tasks.iter().enumerate() {
                let inner = codegen_stmt(stmt, interner, indent + 1, mutable_vars, ctx, lww_fields, synced_vars, var_caps, async_functions, pipe_vars);

                // Convert call statements to awaited calls for async context
                let inner_awaited = if let Stmt::Call { .. } = stmt {
                    // Add .await before the semicolon for function calls
                    inner.trim().trim_end_matches(';').to_string() + ".await;"
                } else {
                    inner.trim().to_string()
                };

                // For tasks that use shared variables, wrap in a block that clones them
                if !used_vars.is_empty() && i < tasks.len() - 1 {
                    // Clone variables for all tasks except the last one
                    let clones: Vec<String> = used_vars.iter()
                        .map(|v| format!("let {} = {}.clone();", v, v))
                        .collect();
                    write!(output, "{}    {{ {} async move {{ {} }} }}",
                           indent_str, clones.join(" "), inner_awaited).unwrap();
                } else {
                    // Last task can use original variables
                    write!(output, "{}    async {{ {} }}", indent_str, inner_awaited).unwrap();
                }

                if i < tasks.len() - 1 {
                    writeln!(output, ",").unwrap();
                } else {
                    writeln!(output).unwrap();
                }
            }

            writeln!(output, "{});", indent_str).unwrap();
        }

        // Phase 9: Parallel execution block (CPU-bound)
        // Generates rayon::join for two tasks, or thread::spawn for 3+ tasks
        Stmt::Parallel { tasks } => {
            // Collect Let statements to generate tuple destructuring
            let let_bindings: Vec<_> = tasks.iter().filter_map(|s| {
                if let Stmt::Let { var, .. } = s {
                    Some(interner.resolve(*var).to_string())
                } else {
                    None
                }
            }).collect();

            if tasks.len() == 2 {
                // Use rayon::join for exactly 2 tasks
                if !let_bindings.is_empty() {
                    writeln!(output, "{}let ({}) = rayon::join(", indent_str, let_bindings.join(", ")).unwrap();
                } else {
                    writeln!(output, "{}rayon::join(", indent_str).unwrap();
                }

                for (i, stmt) in tasks.iter().enumerate() {
                    let inner = codegen_stmt(stmt, interner, indent + 1, mutable_vars, ctx, lww_fields, synced_vars, var_caps, async_functions, pipe_vars);
                    write!(output, "{}    || {{ {} }}", indent_str, inner.trim()).unwrap();
                    if i == 0 {
                        writeln!(output, ",").unwrap();
                    } else {
                        writeln!(output).unwrap();
                    }
                }
                writeln!(output, "{});", indent_str).unwrap();
            } else {
                // For 3+ tasks, use thread::spawn pattern
                writeln!(output, "{}{{", indent_str).unwrap();
                writeln!(output, "{}    let handles: Vec<_> = vec![", indent_str).unwrap();
                for stmt in *tasks {
                    let inner = codegen_stmt(stmt, interner, indent + 2, mutable_vars, ctx, lww_fields, synced_vars, var_caps, async_functions, pipe_vars);
                    writeln!(output, "{}        std::thread::spawn(move || {{ {} }}),",
                             indent_str, inner.trim()).unwrap();
                }
                writeln!(output, "{}    ];", indent_str).unwrap();
                writeln!(output, "{}    for h in handles {{ h.join().unwrap(); }}", indent_str).unwrap();
                writeln!(output, "{}}}", indent_str).unwrap();
            }
        }

        // Phase 10: Read from console or file
        // Phase 53: File reads now use async VFS
        Stmt::ReadFrom { var, source } => {
            let var_name = interner.resolve(*var);
            match source {
                ReadSource::Console => {
                    writeln!(output, "{}let {} = logos_core::io::read_line();", indent_str, var_name).unwrap();
                }
                ReadSource::File(path_expr) => {
                    let path_str = codegen_expr(path_expr, interner, synced_vars);
                    // Phase 53: Use VFS with async
                    writeln!(
                        output,
                        "{}let {} = vfs.read_to_string(&{}).await.expect(\"Failed to read file\");",
                        indent_str, var_name, path_str
                    ).unwrap();
                }
            }
        }

        // Phase 10: Write to file
        // Phase 53: File writes now use async VFS
        Stmt::WriteFile { content, path } => {
            let content_str = codegen_expr(content, interner, synced_vars);
            let path_str = codegen_expr(path, interner, synced_vars);
            // Phase 53: Use VFS with async
            writeln!(
                output,
                "{}vfs.write(&{}, {}.as_bytes()).await.expect(\"Failed to write file\");",
                indent_str, path_str, content_str
            ).unwrap();
        }

        // Phase 46: Spawn an agent
        Stmt::Spawn { agent_type, name } => {
            let type_name = interner.resolve(*agent_type);
            let agent_name = interner.resolve(*name);
            // Generate agent spawn with tokio channel
            writeln!(
                output,
                "{}let {} = tokio::spawn(async move {{ /* {} agent loop */ }});",
                indent_str, agent_name, type_name
            ).unwrap();
        }

        // Phase 46: Send message to agent
        Stmt::SendMessage { message, destination } => {
            let msg_str = codegen_expr(message, interner, synced_vars);
            let dest_str = codegen_expr(destination, interner, synced_vars);
            writeln!(
                output,
                "{}{}.send({}).await.expect(\"Failed to send message\");",
                indent_str, dest_str, msg_str
            ).unwrap();
        }

        // Phase 46: Await response from agent
        Stmt::AwaitMessage { source, into } => {
            let src_str = codegen_expr(source, interner, synced_vars);
            let var_name = interner.resolve(*into);
            writeln!(
                output,
                "{}let {} = {}.recv().await.expect(\"Failed to receive message\");",
                indent_str, var_name, src_str
            ).unwrap();
        }

        // Phase 49: Merge CRDT state
        Stmt::MergeCrdt { source, target } => {
            let src_str = codegen_expr(source, interner, synced_vars);
            let tgt_str = codegen_expr(target, interner, synced_vars);
            writeln!(
                output,
                "{}{}.merge(&{});",
                indent_str, tgt_str, src_str
            ).unwrap();
        }

        // Phase 49: Increment GCounter
        // Phase 52: If object is synced, wrap in .mutate() for auto-publish
        Stmt::IncreaseCrdt { object, field, amount } => {
            let field_name = interner.resolve(*field);
            let amount_str = codegen_expr(amount, interner, synced_vars);

            // Check if the root object is synced
            let root_sym = get_root_identifier(object);
            if let Some(sym) = root_sym {
                if synced_vars.contains(&sym) {
                    // Synced: use .mutate() for auto-publish
                    let obj_name = interner.resolve(sym);
                    writeln!(
                        output,
                        "{}{}.mutate(|inner| inner.{}.increment({} as u64)).await;",
                        indent_str, obj_name, field_name, amount_str
                    ).unwrap();
                    return output;
                }
            }

            // Not synced: direct access
            let obj_str = codegen_expr(object, interner, synced_vars);
            writeln!(
                output,
                "{}{}.{}.increment({} as u64);",
                indent_str, obj_str, field_name, amount_str
            ).unwrap();
        }

        // Phase 49b: Decrement PNCounter
        Stmt::DecreaseCrdt { object, field, amount } => {
            let field_name = interner.resolve(*field);
            let amount_str = codegen_expr(amount, interner, synced_vars);

            // Check if the root object is synced
            let root_sym = get_root_identifier(object);
            if let Some(sym) = root_sym {
                if synced_vars.contains(&sym) {
                    // Synced: use .mutate() for auto-publish
                    let obj_name = interner.resolve(sym);
                    writeln!(
                        output,
                        "{}{}.mutate(|inner| inner.{}.decrement({} as u64)).await;",
                        indent_str, obj_name, field_name, amount_str
                    ).unwrap();
                    return output;
                }
            }

            // Not synced: direct access
            let obj_str = codegen_expr(object, interner, synced_vars);
            writeln!(
                output,
                "{}{}.{}.decrement({} as u64);",
                indent_str, obj_str, field_name, amount_str
            ).unwrap();
        }

        // Phase 49b: Append to SharedSequence (RGA)
        Stmt::AppendToSequence { sequence, value } => {
            let seq_str = codegen_expr(sequence, interner, synced_vars);
            let val_str = codegen_expr(value, interner, synced_vars);
            writeln!(
                output,
                "{}{}.append({});",
                indent_str, seq_str, val_str
            ).unwrap();
        }

        // Phase 49b: Resolve MVRegister conflicts
        Stmt::ResolveConflict { object, field, value } => {
            let field_name = interner.resolve(*field);
            let val_str = codegen_expr(value, interner, synced_vars);
            let obj_str = codegen_expr(object, interner, synced_vars);
            writeln!(
                output,
                "{}{}.{}.resolve({});",
                indent_str, obj_str, field_name, val_str
            ).unwrap();
        }
    }

    output
}

/// Phase 52: Extract the root identifier from an expression.
/// For `x.field.subfield`, returns `x`.
fn get_root_identifier(expr: &Expr) -> Option<Symbol> {
    match expr {
        Expr::Identifier(sym) => Some(*sym),
        Expr::FieldAccess { object, .. } => get_root_identifier(object),
        _ => None,
    }
}

pub fn codegen_expr(expr: &Expr, interner: &Interner, synced_vars: &HashSet<Symbol>) -> String {
    match expr {
        Expr::Literal(lit) => codegen_literal(lit, interner),

        Expr::Identifier(sym) => interner.resolve(*sym).to_string(),

        Expr::BinaryOp { op, left, right } => {
            let left_str = codegen_expr(left, interner, synced_vars);
            let right_str = codegen_expr(right, interner, synced_vars);
            // Phase 53: String concatenation requires special handling
            if matches!(op, BinaryOpKind::Concat) {
                return format!("format!(\"{{}}{{}}\", {}, {})", left_str, right_str);
            }
            let op_str = match op {
                BinaryOpKind::Add => "+",
                BinaryOpKind::Subtract => "-",
                BinaryOpKind::Multiply => "*",
                BinaryOpKind::Divide => "/",
                BinaryOpKind::Modulo => "%",
                BinaryOpKind::Eq => "==",
                BinaryOpKind::NotEq => "!=",
                BinaryOpKind::Lt => "<",
                BinaryOpKind::Gt => ">",
                BinaryOpKind::LtEq => "<=",
                BinaryOpKind::GtEq => ">=",
                BinaryOpKind::And => "&&",
                BinaryOpKind::Or => "||",
                BinaryOpKind::Concat => unreachable!(), // Handled above
            };
            format!("({} {} {})", left_str, op_str, right_str)
        }

        Expr::Call { function, args } => {
            let func_name = interner.resolve(*function);
            let args_str: Vec<String> = args.iter().map(|a| codegen_expr(a, interner, synced_vars)).collect();
            format!("{}({})", func_name, args_str.join(", "))
        }

        Expr::Index { collection, index } => {
            let coll_str = codegen_expr(collection, interner, synced_vars);
            let index_str = codegen_expr(index, interner, synced_vars);
            // Phase 57: Polymorphic indexing via trait
            format!("LogosIndex::logos_get(&{}, {})", coll_str, index_str)
        }

        Expr::Slice { collection, start, end } => {
            let coll_str = codegen_expr(collection, interner, synced_vars);
            let start_str = codegen_expr(start, interner, synced_vars);
            let end_str = codegen_expr(end, interner, synced_vars);
            // Phase 43D: 1-indexed inclusive to 0-indexed exclusive
            // "items 1 through 3" → &items[0..3] (elements at indices 0, 1, 2)
            format!("&{}[({} - 1) as usize..{} as usize]", coll_str, start_str, end_str)
        }

        Expr::Copy { expr } => {
            let expr_str = codegen_expr(expr, interner, synced_vars);
            // Phase 43D: Explicit clone to owned Vec
            format!("{}.to_vec()", expr_str)
        }

        Expr::Length { collection } => {
            let coll_str = codegen_expr(collection, interner, synced_vars);
            // Phase 43D: Collection length - cast to i64 for LOGOS integer semantics
            format!("({}.len() as i64)", coll_str)
        }

        Expr::Contains { collection, value } => {
            let coll_str = codegen_expr(collection, interner, synced_vars);
            let val_str = codegen_expr(value, interner, synced_vars);
            // Use LogosContains trait for unified contains across List, Set, Map, Text
            format!("{}.logos_contains(&{})", coll_str, val_str)
        }

        Expr::Union { left, right } => {
            let left_str = codegen_expr(left, interner, synced_vars);
            let right_str = codegen_expr(right, interner, synced_vars);
            format!("{}.union(&{}).cloned().collect::<std::collections::HashSet<_>>()", left_str, right_str)
        }

        Expr::Intersection { left, right } => {
            let left_str = codegen_expr(left, interner, synced_vars);
            let right_str = codegen_expr(right, interner, synced_vars);
            format!("{}.intersection(&{}).cloned().collect::<std::collections::HashSet<_>>()", left_str, right_str)
        }

        // Phase 48: Sipping Protocol expressions
        Expr::ManifestOf { zone } => {
            let zone_str = codegen_expr(zone, interner, synced_vars);
            format!("logos_core::network::FileSipper::from_zone(&{}).manifest()", zone_str)
        }

        Expr::ChunkAt { index, zone } => {
            let zone_str = codegen_expr(zone, interner, synced_vars);
            let index_str = codegen_expr(index, interner, synced_vars);
            // LOGOS uses 1-indexed, Rust uses 0-indexed
            format!("logos_core::network::FileSipper::from_zone(&{}).get_chunk(({} - 1) as usize)", zone_str, index_str)
        }

        Expr::List(ref items) => {
            let item_strs: Vec<String> = items.iter()
                .map(|i| codegen_expr(i, interner, synced_vars))
                .collect();
            format!("vec![{}]", item_strs.join(", "))
        }

        Expr::Tuple(ref items) => {
            let item_strs: Vec<String> = items.iter()
                .map(|i| format!("Value::from({})", codegen_expr(i, interner, synced_vars)))
                .collect();
            // Tuples as Vec<Value> for heterogeneous support
            format!("vec![{}]", item_strs.join(", "))
        }

        Expr::Range { start, end } => {
            let start_str = codegen_expr(start, interner, synced_vars);
            let end_str = codegen_expr(end, interner, synced_vars);
            format!("({}..={})", start_str, end_str)
        }

        Expr::FieldAccess { object, field } => {
            let field_name = interner.resolve(*field);

            // Phase 52: Check if root object is synced - use .get().await
            let root_sym = get_root_identifier(object);
            if let Some(sym) = root_sym {
                if synced_vars.contains(&sym) {
                    let obj_name = interner.resolve(sym);
                    return format!("{}.get().await.{}", obj_name, field_name);
                }
            }

            let obj_str = codegen_expr(object, interner, synced_vars);
            format!("{}.{}", obj_str, field_name)
        }

        Expr::New { type_name, type_args, init_fields } => {
            let type_str = interner.resolve(*type_name);
            if !init_fields.is_empty() {
                // Struct initialization with fields: Point { x: 10, y: 20, ..Default::default() }
                // Always add ..Default::default() to handle partial initialization (e.g., CRDT fields)
                let fields_str = init_fields.iter()
                    .map(|(name, value)| {
                        let field_name = interner.resolve(*name);
                        let value_str = codegen_expr(value, interner, synced_vars);
                        format!("{}: {}", field_name, value_str)
                    })
                    .collect::<Vec<_>>()
                    .join(", ");
                format!("{} {{ {}, ..Default::default() }}", type_str, fields_str)
            } else if type_args.is_empty() {
                format!("{}::default()", type_str)
            } else {
                // Phase 34: Turbofish syntax for generic instantiation
                let args_str = type_args.iter()
                    .map(|s| map_type_to_rust(interner.resolve(*s)))
                    .collect::<Vec<_>>()
                    .join(", ");
                format!("{}::<{}>::default()", type_str, args_str)
            }
        }

        Expr::NewVariant { enum_name, variant, fields } => {
            let enum_str = interner.resolve(*enum_name);
            let variant_str = interner.resolve(*variant);
            if fields.is_empty() {
                // Unit variant: Shape::Point
                format!("{}::{}", enum_str, variant_str)
            } else {
                // Struct variant: Shape::Circle { radius: 10 }
                let fields_str: Vec<String> = fields.iter()
                    .map(|(field_name, value)| {
                        let name = interner.resolve(*field_name);
                        let val = codegen_expr(value, interner, synced_vars);
                        format!("{}: {}", name, val)
                    })
                    .collect();
                format!("{}::{} {{ {} }}", enum_str, variant_str, fields_str.join(", "))
            }
        }
    }
}

fn codegen_literal(lit: &Literal, interner: &Interner) -> String {
    match lit {
        Literal::Number(n) => n.to_string(),
        Literal::Float(f) => format!("{}f64", f),
        // String literals are converted to String for consistent Text type handling
        Literal::Text(sym) => format!("String::from(\"{}\")", interner.resolve(*sym)),
        Literal::Boolean(b) => b.to_string(),
        Literal::Nothing => "()".to_string(),
        // Character literals
        Literal::Char(c) => {
            // Handle escape sequences for special characters
            match c {
                '\n' => "'\\n'".to_string(),
                '\t' => "'\\t'".to_string(),
                '\r' => "'\\r'".to_string(),
                '\\' => "'\\\\'".to_string(),
                '\'' => "'\\''".to_string(),
                '\0' => "'\\0'".to_string(),
                c => format!("'{}'", c),
            }
        }
    }
}

/// Converts a LogicExpr to a Rust boolean expression for debug_assert!().
/// Uses RustFormatter to unify all logic-to-Rust translation.
pub fn codegen_assertion(expr: &LogicExpr, interner: &Interner) -> String {
    let mut registry = SymbolRegistry::new();
    let formatter = RustFormatter;
    let mut buf = String::new();

    match expr.write_logic(&mut buf, &mut registry, interner, &formatter) {
        Ok(_) => buf,
        Err(_) => "/* error generating assertion */ false".to_string(),
    }
}

pub fn codegen_term(term: &Term, interner: &Interner) -> String {
    match term {
        Term::Constant(sym) => interner.resolve(*sym).to_string(),
        Term::Variable(sym) => interner.resolve(*sym).to_string(),
        Term::Value { kind, .. } => match kind {
            NumberKind::Integer(n) => n.to_string(),
            NumberKind::Real(f) => f.to_string(),
            NumberKind::Symbolic(sym) => interner.resolve(*sym).to_string(),
        },
        Term::Function(name, args) => {
            let args_str: Vec<String> = args.iter()
                .map(|a| codegen_term(a, interner))
                .collect();
            format!("{}({})", interner.resolve(*name), args_str.join(", "))
        }
        Term::Possessed { possessor, possessed } => {
            let poss_str = codegen_term(possessor, interner);
            format!("{}.{}", poss_str, interner.resolve(*possessed))
        }
        Term::Group(members) => {
            let members_str: Vec<String> = members.iter()
                .map(|m| codegen_term(m, interner))
                .collect();
            format!("({})", members_str.join(", "))
        }
        _ => "/* unsupported Term */".to_string(),
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_literal_number() {
        let interner = Interner::new();
        let synced_vars = HashSet::new();
        let expr = Expr::Literal(Literal::Number(42));
        assert_eq!(codegen_expr(&expr, &interner, &synced_vars), "42");
    }

    #[test]
    fn test_literal_boolean() {
        let interner = Interner::new();
        let synced_vars = HashSet::new();
        assert_eq!(codegen_expr(&Expr::Literal(Literal::Boolean(true)), &interner, &synced_vars), "true");
        assert_eq!(codegen_expr(&Expr::Literal(Literal::Boolean(false)), &interner, &synced_vars), "false");
    }

    #[test]
    fn test_literal_nothing() {
        let interner = Interner::new();
        let synced_vars = HashSet::new();
        assert_eq!(codegen_expr(&Expr::Literal(Literal::Nothing), &interner, &synced_vars), "()");
    }
}

```

---

### Module: compile

**File:** `src/compile.rs`

Additional source module.

```rust
//! LOGOS Compilation Pipeline
//!
//! This module provides the end-to-end compilation pipeline:
//! LOGOS source → Rust source → executable

use std::fs;
use std::io::Write;
use std::path::Path;
use std::process::Command;

// Embed runtime at compile time
const LOGOS_CORE_TOML: &str = include_str!("../logos_core/Cargo.toml");
const LOGOS_CORE_LIB: &str = include_str!("../logos_core/src/lib.rs");
const LOGOS_CORE_TYPES: &str = include_str!("../logos_core/src/types.rs");
const LOGOS_CORE_IO: &str = include_str!("../logos_core/src/io.rs");
// Phase 38: Standard library modules
const LOGOS_CORE_FILE: &str = include_str!("../logos_core/src/file.rs");
const LOGOS_CORE_TIME: &str = include_str!("../logos_core/src/time.rs");
const LOGOS_CORE_RANDOM: &str = include_str!("../logos_core/src/random.rs");
const LOGOS_CORE_ENV: &str = include_str!("../logos_core/src/env.rs");
// Phase 8.5: Zone-based memory management
const LOGOS_CORE_MEMORY: &str = include_str!("../logos_core/src/memory.rs");

use crate::analysis::{DiscoveryPass, EscapeChecker, OwnershipChecker, PolicyRegistry};
use crate::arena::Arena;
use crate::arena_ctx::AstContext;
use crate::ast::{Expr, Stmt, TypeExpr};
use crate::codegen::codegen_program;
use crate::context::DiscourseContext;
use crate::diagnostic::{parse_rustc_json, translate_diagnostics, LogosError};
use crate::error::ParseError;
use crate::intern::Interner;
use crate::lexer::Lexer;
use crate::parser::Parser;
use crate::sourcemap::SourceMap;

/// Compile LOGOS source to Rust source code.
pub fn compile_to_rust(source: &str) -> Result<String, ParseError> {
    let mut interner = Interner::new();
    let mut lexer = Lexer::new(source, &mut interner);
    let tokens = lexer.tokenize();

    // Pass 1: Discovery - scan for type definitions and policies
    let (type_registry, policy_registry) = {
        let mut discovery = DiscoveryPass::new(&tokens, &mut interner);
        let result = discovery.run_full();
        (result.types, result.policies)
    };
    // Clone for codegen (parser takes ownership)
    let codegen_registry = type_registry.clone();
    let codegen_policies = policy_registry.clone();

    let mut ctx = DiscourseContext::new();
    let expr_arena = Arena::new();
    let term_arena = Arena::new();
    let np_arena = Arena::new();
    let sym_arena = Arena::new();
    let role_arena = Arena::new();
    let pp_arena = Arena::new();
    let stmt_arena: Arena<Stmt> = Arena::new();
    let imperative_expr_arena: Arena<Expr> = Arena::new();
    let type_expr_arena: Arena<TypeExpr> = Arena::new();

    let ast_ctx = AstContext::with_types(
        &expr_arena,
        &term_arena,
        &np_arena,
        &sym_arena,
        &role_arena,
        &pp_arena,
        &stmt_arena,
        &imperative_expr_arena,
        &type_expr_arena,
    );

    // Pass 2: Parse with type context
    let mut parser = Parser::with_types(tokens, &mut ctx, &mut interner, ast_ctx, type_registry);
    // Note: Don't call process_block_headers() - parse_program handles blocks itself

    let stmts = parser.parse_program()?;

    // Pass 3: Escape analysis - check for zone escape violations
    // This catches obvious cases like returning zone-local variables
    let mut escape_checker = EscapeChecker::new(&interner);
    escape_checker.check_program(&stmts).map_err(|e| {
        // Convert EscapeError to ParseError for now
        // The error message is already Socratic from EscapeChecker
        ParseError {
            kind: crate::error::ParseErrorKind::Custom(e.to_string()),
            span: e.span,
        }
    })?;

    // Note: Static verification (Phase 42) is available when the `verification`
    // feature is enabled, but must be explicitly invoked via compile_to_rust_verified().

    let rust_code = codegen_program(&stmts, &codegen_registry, &codegen_policies, &interner);

    Ok(rust_code)
}

/// Compile LOGOS source to Rust with ownership checking enabled.
///
/// This runs the lightweight ownership analysis pass (Phase 45) that catches
/// use-after-move errors with control flow awareness in milliseconds.
/// Use this with `--check` flag for instant feedback on ownership errors.
pub fn compile_to_rust_checked(source: &str) -> Result<String, ParseError> {
    let mut interner = Interner::new();
    let mut lexer = Lexer::new(source, &mut interner);
    let tokens = lexer.tokenize();

    // Pass 1: Discovery - scan for type definitions and policies
    let (type_registry, policy_registry) = {
        let mut discovery = DiscoveryPass::new(&tokens, &mut interner);
        let result = discovery.run_full();
        (result.types, result.policies)
    };
    // Clone for codegen (parser takes ownership)
    let codegen_registry = type_registry.clone();
    let codegen_policies = policy_registry.clone();

    let mut ctx = DiscourseContext::new();
    let expr_arena = Arena::new();
    let term_arena = Arena::new();
    let np_arena = Arena::new();
    let sym_arena = Arena::new();
    let role_arena = Arena::new();
    let pp_arena = Arena::new();
    let stmt_arena: Arena<Stmt> = Arena::new();
    let imperative_expr_arena: Arena<Expr> = Arena::new();
    let type_expr_arena: Arena<TypeExpr> = Arena::new();

    let ast_ctx = AstContext::with_types(
        &expr_arena,
        &term_arena,
        &np_arena,
        &sym_arena,
        &role_arena,
        &pp_arena,
        &stmt_arena,
        &imperative_expr_arena,
        &type_expr_arena,
    );

    // Pass 2: Parse with type context
    let mut parser = Parser::with_types(tokens, &mut ctx, &mut interner, ast_ctx, type_registry);
    let stmts = parser.parse_program()?;

    // Pass 3: Escape analysis
    let mut escape_checker = EscapeChecker::new(&interner);
    escape_checker.check_program(&stmts).map_err(|e| {
        ParseError {
            kind: crate::error::ParseErrorKind::Custom(e.to_string()),
            span: e.span,
        }
    })?;

    // Pass 4: Ownership analysis (Phase 45)
    // Catches use-after-move errors with control flow awareness
    let mut ownership_checker = OwnershipChecker::new(&interner);
    ownership_checker.check_program(&stmts).map_err(|e| {
        ParseError {
            kind: crate::error::ParseErrorKind::Custom(e.to_string()),
            span: e.span,
        }
    })?;

    let rust_code = codegen_program(&stmts, &codegen_registry, &codegen_policies, &interner);

    Ok(rust_code)
}

/// Compile LOGOS source to Rust source code with static verification.
///
/// This runs the Z3-based verifier on Assert statements before codegen.
/// Requires the `verification` feature to be enabled.
#[cfg(feature = "verification")]
pub fn compile_to_rust_verified(source: &str) -> Result<String, ParseError> {
    use crate::verification::VerificationPass;

    let mut interner = Interner::new();
    let mut lexer = Lexer::new(source, &mut interner);
    let tokens = lexer.tokenize();

    // Pass 1: Discovery - scan for type definitions and policies
    let (type_registry, policy_registry) = {
        let mut discovery = DiscoveryPass::new(&tokens, &mut interner);
        let result = discovery.run_full();
        (result.types, result.policies)
    };
    // Clone for codegen (parser takes ownership)
    let codegen_registry = type_registry.clone();
    let codegen_policies = policy_registry.clone();

    let mut ctx = DiscourseContext::new();
    let expr_arena = Arena::new();
    let term_arena = Arena::new();
    let np_arena = Arena::new();
    let sym_arena = Arena::new();
    let role_arena = Arena::new();
    let pp_arena = Arena::new();
    let stmt_arena: Arena<Stmt> = Arena::new();
    let imperative_expr_arena: Arena<Expr> = Arena::new();
    let type_expr_arena: Arena<TypeExpr> = Arena::new();

    let ast_ctx = AstContext::with_types(
        &expr_arena,
        &term_arena,
        &np_arena,
        &sym_arena,
        &role_arena,
        &pp_arena,
        &stmt_arena,
        &imperative_expr_arena,
        &type_expr_arena,
    );

    // Pass 2: Parse with type context
    let mut parser = Parser::with_types(tokens, &mut ctx, &mut interner, ast_ctx, type_registry);
    let stmts = parser.parse_program()?;

    // Pass 3: Escape analysis
    let mut escape_checker = EscapeChecker::new(&interner);
    escape_checker.check_program(&stmts).map_err(|e| {
        ParseError {
            kind: crate::error::ParseErrorKind::Custom(e.to_string()),
            span: e.span,
        }
    })?;

    // Pass 4: Static verification
    let mut verifier = VerificationPass::new(&interner);
    verifier.verify_program(&stmts).map_err(|e| {
        ParseError {
            kind: crate::error::ParseErrorKind::Custom(format!(
                "Verification Failed:\n\n{}",
                e
            )),
            span: crate::token::Span::default(),
        }
    })?;

    let rust_code = codegen_program(&stmts, &codegen_registry, &codegen_policies, &interner);

    Ok(rust_code)
}

/// Compile LOGOS source and write output to a directory.
/// Creates a Cargo project with logos_core dependency.
pub fn compile_to_dir(source: &str, output_dir: &Path) -> Result<(), CompileError> {
    let rust_code = compile_to_rust(source).map_err(CompileError::Parse)?;

    // Create output directory structure
    let src_dir = output_dir.join("src");
    fs::create_dir_all(&src_dir).map_err(|e| CompileError::Io(e.to_string()))?;

    // Write main.rs with logos_core import
    let main_rs = format!(
        "use logos_core::prelude::*;\n\n{}",
        rust_code
    );
    let main_path = src_dir.join("main.rs");
    let mut file = fs::File::create(&main_path).map_err(|e| CompileError::Io(e.to_string()))?;
    file.write_all(main_rs.as_bytes()).map_err(|e| CompileError::Io(e.to_string()))?;

    // Write Cargo.toml
    let cargo_toml = format!(
        r#"[package]
name = "logos_output"
version = "0.1.0"
edition = "2021"

[dependencies]
logos_core = {{ path = "./logos_core" }}
"#
    );
    let cargo_path = output_dir.join("Cargo.toml");
    let mut file = fs::File::create(&cargo_path).map_err(|e| CompileError::Io(e.to_string()))?;
    file.write_all(cargo_toml.as_bytes()).map_err(|e| CompileError::Io(e.to_string()))?;

    // Copy logos_core to output directory
    copy_logos_core(output_dir)?;

    Ok(())
}

/// Copy the logos_core crate to the output directory.
/// This recursively copies the entire crate including all modules.
pub fn copy_logos_core(output_dir: &Path) -> Result<(), CompileError> {
    let dest_dir = output_dir.join("logos_core");

    // Find the logos_core source directory relative to the CARGO_MANIFEST_DIR
    // or use the embedded constants as fallback
    let source_dir = std::env::var("CARGO_MANIFEST_DIR")
        .map(|d| Path::new(&d).join("logos_core"))
        .ok()
        .filter(|p| p.exists());

    if let Some(src) = source_dir {
        // Recursively copy the actual logos_core directory
        copy_dir_recursive(&src, &dest_dir)?;
    } else {
        // Fallback to embedded files for distribution builds
        let src_dir = dest_dir.join("src");
        fs::create_dir_all(&src_dir).map_err(|e| CompileError::Io(e.to_string()))?;

        fs::write(dest_dir.join("Cargo.toml"), LOGOS_CORE_TOML)
            .map_err(|e| CompileError::Io(e.to_string()))?;
        fs::write(src_dir.join("lib.rs"), LOGOS_CORE_LIB)
            .map_err(|e| CompileError::Io(e.to_string()))?;
        fs::write(src_dir.join("types.rs"), LOGOS_CORE_TYPES)
            .map_err(|e| CompileError::Io(e.to_string()))?;
        fs::write(src_dir.join("io.rs"), LOGOS_CORE_IO)
            .map_err(|e| CompileError::Io(e.to_string()))?;
        fs::write(src_dir.join("file.rs"), LOGOS_CORE_FILE)
            .map_err(|e| CompileError::Io(e.to_string()))?;
        fs::write(src_dir.join("time.rs"), LOGOS_CORE_TIME)
            .map_err(|e| CompileError::Io(e.to_string()))?;
        fs::write(src_dir.join("random.rs"), LOGOS_CORE_RANDOM)
            .map_err(|e| CompileError::Io(e.to_string()))?;
        fs::write(src_dir.join("env.rs"), LOGOS_CORE_ENV)
            .map_err(|e| CompileError::Io(e.to_string()))?;
        fs::write(src_dir.join("memory.rs"), LOGOS_CORE_MEMORY)
            .map_err(|e| CompileError::Io(e.to_string()))?;
    }

    Ok(())
}

/// Recursively copy a directory.
fn copy_dir_recursive(src: &Path, dst: &Path) -> Result<(), CompileError> {
    fs::create_dir_all(dst).map_err(|e| CompileError::Io(e.to_string()))?;

    for entry in fs::read_dir(src).map_err(|e| CompileError::Io(e.to_string()))? {
        let entry = entry.map_err(|e| CompileError::Io(e.to_string()))?;
        let src_path = entry.path();
        let file_name = entry.file_name();
        let dst_path = dst.join(&file_name);

        // Skip target directory and other build artifacts
        if file_name == "target" || file_name == ".git" {
            continue;
        }

        if src_path.is_dir() {
            copy_dir_recursive(&src_path, &dst_path)?;
        } else if file_name == "Cargo.toml" {
            // Special handling for Cargo.toml: remove [workspace] line
            // which can interfere with nested crate dependencies
            let content = fs::read_to_string(&src_path)
                .map_err(|e| CompileError::Io(e.to_string()))?;
            let filtered: String = content
                .lines()
                .filter(|line| !line.trim().starts_with("[workspace]"))
                .collect::<Vec<_>>()
                .join("\n");
            fs::write(&dst_path, filtered).map_err(|e| CompileError::Io(e.to_string()))?;
        } else {
            fs::copy(&src_path, &dst_path).map_err(|e| CompileError::Io(e.to_string()))?;
        }
    }

    Ok(())
}

/// Compile and run a LOGOS program.
pub fn compile_and_run(source: &str, output_dir: &Path) -> Result<String, CompileError> {
    compile_to_dir(source, output_dir)?;

    // Run cargo build with JSON message format for structured error parsing
    let build_output = Command::new("cargo")
        .arg("build")
        .arg("--message-format=json")
        .current_dir(output_dir)
        .output()
        .map_err(|e| CompileError::Io(e.to_string()))?;

    if !build_output.status.success() {
        let stderr = String::from_utf8_lossy(&build_output.stderr);
        let stdout = String::from_utf8_lossy(&build_output.stdout);

        // Try to parse JSON diagnostics and translate them
        let diagnostics = parse_rustc_json(&stdout);

        if !diagnostics.is_empty() {
            // Create a basic source map with the LOGOS source
            let source_map = SourceMap::new(source.to_string());
            let interner = Interner::new();

            if let Some(logos_error) = translate_diagnostics(&diagnostics, &source_map, &interner) {
                return Err(CompileError::Ownership(logos_error));
            }
        }

        // Fallback to raw error if translation fails
        return Err(CompileError::Build(stderr.to_string()));
    }

    // Run the compiled program
    let run_output = Command::new("cargo")
        .arg("run")
        .arg("--quiet")
        .current_dir(output_dir)
        .output()
        .map_err(|e| CompileError::Io(e.to_string()))?;

    if !run_output.status.success() {
        let stderr = String::from_utf8_lossy(&run_output.stderr);
        return Err(CompileError::Runtime(stderr.to_string()));
    }

    let stdout = String::from_utf8_lossy(&run_output.stdout);
    Ok(stdout.to_string())
}

/// Compile a LOGOS source file.
/// For single-file compilation without dependencies.
pub fn compile_file(path: &Path) -> Result<String, CompileError> {
    let source = fs::read_to_string(path).map_err(|e| CompileError::Io(e.to_string()))?;
    compile_to_rust(&source).map_err(CompileError::Parse)
}

/// Phase 36: Compile a LOGOS project with dependencies.
/// Scans the Abstract for [Alias](URI) links and loads dependencies recursively.
pub fn compile_project(path: &Path) -> Result<String, CompileError> {
    use crate::analysis::discover_with_imports;
    use crate::project::Loader;

    let source = fs::read_to_string(path).map_err(|e| CompileError::Io(e.to_string()))?;
    let root_dir = path.parent().unwrap_or(Path::new(".")).to_path_buf();

    let mut interner = Interner::new();
    let mut loader = Loader::new(root_dir);

    // Pass 1: Recursive discovery with imports
    let type_registry = discover_with_imports(path, &source, &mut loader, &mut interner)
        .map_err(|e| CompileError::Io(e))?;
    let codegen_registry = type_registry.clone();

    // Phase 50: Also discover policies from the main file
    // (discover_with_imports doesn't handle policies yet, so we do a separate pass)
    let mut lexer = Lexer::new(&source, &mut interner);
    let tokens = lexer.tokenize();
    let policy_registry = {
        let mut discovery = DiscoveryPass::new(&tokens, &mut interner);
        discovery.run_full().policies
    };
    let codegen_policies = policy_registry.clone();

    // Re-tokenize for parsing (interner may have been modified)
    let mut lexer = Lexer::new(&source, &mut interner);
    let tokens = lexer.tokenize();

    let mut ctx = DiscourseContext::new();
    let expr_arena = Arena::new();
    let term_arena = Arena::new();
    let np_arena = Arena::new();
    let sym_arena = Arena::new();
    let role_arena = Arena::new();
    let pp_arena = Arena::new();
    let stmt_arena: Arena<Stmt> = Arena::new();
    let imperative_expr_arena: Arena<Expr> = Arena::new();
    let type_expr_arena: Arena<TypeExpr> = Arena::new();

    let ast_ctx = AstContext::with_types(
        &expr_arena,
        &term_arena,
        &np_arena,
        &sym_arena,
        &role_arena,
        &pp_arena,
        &stmt_arena,
        &imperative_expr_arena,
        &type_expr_arena,
    );

    // Pass 2: Parse with type context (includes imported types)
    let mut parser = Parser::with_types(tokens, &mut ctx, &mut interner, ast_ctx, type_registry);
    let stmts = parser.parse_program().map_err(CompileError::Parse)?;
    let rust_code = codegen_program(&stmts, &codegen_registry, &codegen_policies, &interner);

    Ok(rust_code)
}

/// Errors that can occur during compilation.
#[derive(Debug)]
pub enum CompileError {
    Parse(ParseError),
    Io(String),
    Build(String),
    Runtime(String),
    /// Translated ownership/borrow checker error with friendly LOGOS message
    Ownership(LogosError),
}

impl std::fmt::Display for CompileError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            CompileError::Parse(e) => write!(f, "Parse error: {:?}", e),
            CompileError::Io(e) => write!(f, "IO error: {}", e),
            CompileError::Build(e) => write!(f, "Build error: {}", e),
            CompileError::Runtime(e) => write!(f, "Runtime error: {}", e),
            CompileError::Ownership(e) => write!(f, "{}", e),
        }
    }
}

impl std::error::Error for CompileError {}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_compile_let_statement() {
        let source = "## Main\nLet x be 5.";
        let result = compile_to_rust(source);
        assert!(result.is_ok(), "Should compile: {:?}", result);
        let rust = result.unwrap();
        assert!(rust.contains("fn main()"));
        assert!(rust.contains("let x = 5;"));
    }

    #[test]
    fn test_compile_return_statement() {
        let source = "## Main\nReturn 42.";
        let result = compile_to_rust(source);
        assert!(result.is_ok(), "Should compile: {:?}", result);
        let rust = result.unwrap();
        assert!(rust.contains("return 42;"));
    }
}

```

---

### Module: diagnostic

**File:** `src/diagnostic.rs`

Additional source module.

```rust
//! Diagnostic Bridge for LOGOS
//!
//! Translates Rust borrow checker errors into friendly LOGOS error messages.
//! Parses rustc JSON output and maps errors back to LOGOS source.

use crate::intern::Interner;
use crate::sourcemap::{OwnershipRole, SourceMap};
use crate::style::Style;
use crate::token::Span;
use serde::Deserialize;

/// A translated error message for LOGOS users.
#[derive(Debug, Clone)]
pub struct LogosError {
    pub title: String,
    pub explanation: String,
    pub logos_span: Option<Span>,
    pub suggestion: Option<String>,
}

impl std::fmt::Display for LogosError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        writeln!(f, "{}: {}", Style::bold_red("ownership error"), self.title)?;
        writeln!(f)?;
        writeln!(f, "{}", self.explanation)?;
        if let Some(suggestion) = &self.suggestion {
            writeln!(f)?;
            writeln!(f, "{}: {}", Style::cyan("suggestion"), suggestion)?;
        }
        Ok(())
    }
}

// =============================================================================
// Rustc JSON Diagnostic Types
// =============================================================================

/// Rustc JSON diagnostic message (subset of fields we need).
#[derive(Debug, Deserialize)]
pub struct RustcDiagnostic {
    pub message: String,
    pub code: Option<RustcCode>,
    pub level: String,
    pub spans: Vec<RustcSpan>,
    #[serde(default)]
    pub children: Vec<RustcDiagnostic>,
}

#[derive(Debug, Deserialize)]
pub struct RustcCode {
    pub code: String,
}

#[derive(Debug, Deserialize)]
pub struct RustcSpan {
    pub file_name: String,
    pub line_start: u32,
    pub line_end: u32,
    pub column_start: u32,
    pub column_end: u32,
    pub is_primary: bool,
    pub label: Option<String>,
    #[serde(default)]
    pub text: Vec<RustcSpanText>,
}

#[derive(Debug, Deserialize)]
pub struct RustcSpanText {
    pub text: String,
    pub highlight_start: u32,
    pub highlight_end: u32,
}

/// Parsed rustc output: either a diagnostic or artifact info.
#[derive(Debug, Deserialize)]
#[serde(tag = "reason")]
#[serde(rename_all = "kebab-case")]
pub enum RustcMessage {
    CompilerMessage { message: RustcDiagnostic },
    #[serde(other)]
    Other,
}

// =============================================================================
// JSON Parsing
// =============================================================================

/// Parse rustc stderr output from `cargo build --message-format=json`.
pub fn parse_rustc_json(stderr: &str) -> Vec<RustcDiagnostic> {
    let mut diagnostics = Vec::new();

    for line in stderr.lines() {
        // Skip empty lines and non-JSON output
        if !line.starts_with('{') {
            continue;
        }

        match serde_json::from_str::<RustcMessage>(line) {
            Ok(RustcMessage::CompilerMessage { message }) => {
                if message.level == "error" {
                    diagnostics.push(message);
                }
            }
            Ok(RustcMessage::Other) => {} // Ignore artifacts, build-finished, etc.
            Err(_) => {} // Ignore malformed lines
        }
    }

    diagnostics
}

/// Extract error code from a diagnostic.
pub fn get_error_code(diag: &RustcDiagnostic) -> Option<&str> {
    diag.code.as_ref().map(|c| c.code.as_str())
}

/// Extract the primary span from a diagnostic.
pub fn get_primary_span(diag: &RustcDiagnostic) -> Option<&RustcSpan> {
    diag.spans.iter().find(|s| s.is_primary)
}

/// Extract variable name from rustc error message.
/// Example: "use of moved value: `data`" -> "data"
fn extract_var_from_message(message: &str, prefix: &str, suffix: &str) -> Option<String> {
    let start = message.find(prefix)?;
    let after_prefix = &message[start + prefix.len()..];
    let end = after_prefix.find(suffix)?;
    Some(after_prefix[..end].to_string())
}

// =============================================================================
// Diagnostic Bridge
// =============================================================================

/// Translates rustc diagnostics into LOGOS error messages.
pub struct DiagnosticBridge<'a> {
    source_map: &'a SourceMap,
    interner: &'a Interner,
}

impl<'a> DiagnosticBridge<'a> {
    pub fn new(source_map: &'a SourceMap, interner: &'a Interner) -> Self {
        Self { source_map, interner }
    }

    /// Translate a rustc diagnostic into a LOGOS error.
    pub fn translate(&self, diag: &RustcDiagnostic) -> Option<LogosError> {
        let code = get_error_code(diag)?;
        let span = get_primary_span(diag);

        match code {
            "E0382" => self.translate_use_after_move(diag, span),
            "E0505" => self.translate_move_while_borrowed(diag, span),
            "E0597" => self.translate_lifetime_error(diag, span),
            _ => self.translate_generic(diag, span),
        }
    }

    /// E0382: "use of moved value: `x`"
    /// LOGOS: "You already gave X away - you can't use it anymore"
    fn translate_use_after_move(&self, diag: &RustcDiagnostic, span: Option<&RustcSpan>) -> Option<LogosError> {
        let var_name = extract_var_from_message(&diag.message, "value: `", "`")
            .or_else(|| extract_var_from_message(&diag.message, "value `", "`"))?;

        let logos_span = span.and_then(|s| self.source_map.find_nearest_span(s.line_start));

        // Look up variable origin if available
        let (logos_name, role) = if let Some(origin) = self.source_map.get_var_origin(&var_name) {
            (self.interner.resolve(origin.logos_name).to_string(), Some(origin.role))
        } else {
            (var_name.clone(), None)
        };

        let explanation = match role {
            Some(OwnershipRole::GiveObject) => format!(
                "You gave '{}' away with a Give statement, so you can't use it anymore.\n\
                In LOGOS, 'Give X to Y' transfers ownership - X moves to Y and leaves your hands.\n\
                This is like handing someone a physical object: once given, you no longer have it.",
                logos_name
            ),
            Some(OwnershipRole::LetBinding) | None => format!(
                "The value '{}' was moved somewhere else and can't be used again.\n\
                Check if you used 'Give' or passed it to a function that took ownership.",
                logos_name
            ),
            _ => format!(
                "The value '{}' has been moved and is no longer available.",
                logos_name
            ),
        };

        let suggestion = Some(format!(
            "If you need to use '{}' after giving it away, either:\n\
             1. Use 'Show {} to Y' instead (this borrows, keeping ownership)\n\
             2. Use 'a copy of {}' before the Give",
            logos_name, logos_name, logos_name
        ));

        Some(LogosError {
            title: format!("Cannot use '{}' after giving it away", logos_name),
            explanation,
            logos_span,
            suggestion,
        })
    }

    /// E0505: "cannot move out of `x` because it is borrowed"
    /// LOGOS: "You're trying to give X away while someone is still looking at it"
    fn translate_move_while_borrowed(&self, diag: &RustcDiagnostic, span: Option<&RustcSpan>) -> Option<LogosError> {
        let var_name = extract_var_from_message(&diag.message, "out of `", "`")
            .or_else(|| extract_var_from_message(&diag.message, "move out of `", "`"))?;

        let logos_span = span.and_then(|s| self.source_map.find_nearest_span(s.line_start));

        let logos_name = if let Some(origin) = self.source_map.get_var_origin(&var_name) {
            self.interner.resolve(origin.logos_name).to_string()
        } else {
            var_name.clone()
        };

        let explanation = format!(
            "You showed '{}' to someone (creating a temporary view),\n\
            but then tried to give it away before they finished looking.\n\
            In LOGOS, 'Show' creates a promise that the data won't change or disappear\n\
            while being viewed. You can't break that promise by giving it away.",
            logos_name
        );

        let suggestion = Some(format!(
            "Make sure all 'Show' usages of '{}' complete before any 'Give'.\n\
            Alternatively, give away a copy: 'Give a copy of {} to Y'",
            logos_name, logos_name
        ));

        Some(LogosError {
            title: format!("Cannot give '{}' while it's being shown", logos_name),
            explanation,
            logos_span,
            suggestion,
        })
    }

    /// E0597: "borrowed value does not live long enough"
    /// LOGOS: "You can't take a reference outside its zone" (Hotel California)
    fn translate_lifetime_error(&self, diag: &RustcDiagnostic, span: Option<&RustcSpan>) -> Option<LogosError> {
        let logos_span = span.and_then(|s| self.source_map.find_nearest_span(s.line_start));

        // Check if this is zone-related by looking at the message and children
        let is_zone_related = diag.message.contains("borrowed")
            || diag.children.iter().any(|c| c.message.contains("dropped"));

        let explanation = if is_zone_related {
            "A value created inside a Zone cannot be referenced from outside.\n\
            Zones are memory arenas - when the Zone ends, everything inside it is released.\n\
            This is the 'Hotel California' rule: data can check in (be created),\n\
            but references can't check out (escape the Zone).".to_string()
        } else {
            "A borrowed reference is being used after the original value has gone away.\n\
            References are temporary views - they can't outlive what they're viewing.".to_string()
        };

        let suggestion = Some(
            "If you need the data after the Zone ends, either:\n\
             1. Move the data out with 'Give' before the Zone closes\n\
             2. Copy the data: 'Let result be a copy of zone_data'\n\
             3. Restructure so the computation completes inside the Zone".to_string()
        );

        Some(LogosError {
            title: "Reference cannot outlive its data".to_string(),
            explanation,
            logos_span,
            suggestion,
        })
    }

    /// Fallback for other errors - provide the raw message with context.
    fn translate_generic(&self, diag: &RustcDiagnostic, span: Option<&RustcSpan>) -> Option<LogosError> {
        let logos_span = span.and_then(|s| self.source_map.find_nearest_span(s.line_start));

        // Try to extract any variable name
        let var_hint = if let Some(start) = diag.message.find('`') {
            if let Some(end) = diag.message[start + 1..].find('`') {
                Some(&diag.message[start + 1..start + 1 + end])
            } else {
                None
            }
        } else {
            None
        };

        let explanation = if let Some(var) = var_hint {
            format!(
                "The Rust compiler reported an error involving '{}':\n{}",
                var, diag.message
            )
        } else {
            format!("The Rust compiler reported an error:\n{}", diag.message)
        };

        Some(LogosError {
            title: "Compilation error".to_string(),
            explanation,
            logos_span,
            suggestion: None,
        })
    }
}

/// Attempt to translate all diagnostics and return the first translated error.
pub fn translate_diagnostics(
    diagnostics: &[RustcDiagnostic],
    source_map: &SourceMap,
    interner: &Interner,
) -> Option<LogosError> {
    let bridge = DiagnosticBridge::new(source_map, interner);

    for diag in diagnostics {
        if let Some(error) = bridge.translate(diag) {
            return Some(error);
        }
    }

    None
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn parse_rustc_json_extracts_errors() {
        let json_output = r#"{"reason":"compiler-message","message":{"message":"use of moved value: `x`","code":{"code":"E0382"},"level":"error","spans":[{"file_name":"src/main.rs","line_start":5,"line_end":5,"column_start":10,"column_end":11,"is_primary":true,"label":null,"text":[]}],"children":[]}}
{"reason":"build-finished","success":false}"#;

        let diagnostics = parse_rustc_json(json_output);
        assert_eq!(diagnostics.len(), 1);
        assert_eq!(diagnostics[0].message, "use of moved value: `x`");
        assert_eq!(get_error_code(&diagnostics[0]), Some("E0382"));
    }

    #[test]
    fn extract_var_from_message_works() {
        assert_eq!(
            extract_var_from_message("use of moved value: `data`", "value: `", "`"),
            Some("data".to_string())
        );
        assert_eq!(
            extract_var_from_message("cannot move out of `x` because", "out of `", "`"),
            Some("x".to_string())
        );
    }

    #[test]
    fn translate_e0382_creates_friendly_error() {
        let interner = Interner::new();
        let source_map = SourceMap::new("Let data be 5.\nGive data to processor.".to_string());

        let diag = RustcDiagnostic {
            message: "use of moved value: `data`".to_string(),
            code: Some(RustcCode { code: "E0382".to_string() }),
            level: "error".to_string(),
            spans: vec![RustcSpan {
                file_name: "src/main.rs".to_string(),
                line_start: 3,
                line_end: 3,
                column_start: 10,
                column_end: 14,
                is_primary: true,
                label: None,
                text: vec![],
            }],
            children: vec![],
        };

        let bridge = DiagnosticBridge::new(&source_map, &interner);
        let error = bridge.translate(&diag).expect("Should translate");

        assert!(error.title.contains("data"));
        assert!(error.title.contains("giving it away"));
        assert!(error.explanation.contains("moved"));
        assert!(error.suggestion.is_some());
    }

    #[test]
    fn translate_e0597_creates_hotel_california_error() {
        let interner = Interner::new();
        let source_map = SourceMap::new("Inside a zone:\n    Let x be 5.".to_string());

        let diag = RustcDiagnostic {
            message: "borrowed value does not live long enough".to_string(),
            code: Some(RustcCode { code: "E0597".to_string() }),
            level: "error".to_string(),
            spans: vec![RustcSpan {
                file_name: "src/main.rs".to_string(),
                line_start: 5,
                line_end: 5,
                column_start: 1,
                column_end: 10,
                is_primary: true,
                label: None,
                text: vec![],
            }],
            children: vec![],
        };

        let bridge = DiagnosticBridge::new(&source_map, &interner);
        let error = bridge.translate(&diag).expect("Should translate");

        assert!(error.title.contains("outlive"));
        assert!(error.explanation.contains("Zone") || error.explanation.contains("borrowed"));
    }
}

```

---

### Module: drs

**File:** `src/drs.rs`

Additional source module.

```rust
use crate::context::Gender;
use crate::intern::Symbol;

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum ReferentSource {
    /// Indefinite in main clause - gets existential force
    MainClause,
    /// Proper name - no quantifier (constant)
    ProperName,
    /// Indefinite in conditional antecedent - gets universal force (DRS signature)
    ConditionalAntecedent,
    /// Indefinite in universal restrictor (relative clause) - gets universal force
    UniversalRestrictor,
    /// Inside negation scope - inaccessible outward
    NegationScope,
    /// Inside disjunction - inaccessible outward
    Disjunct,
}

impl ReferentSource {
    pub fn gets_universal_force(&self) -> bool {
        matches!(
            self,
            ReferentSource::ConditionalAntecedent | ReferentSource::UniversalRestrictor
        )
    }
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum BoxType {
    /// Top-level discourse box
    Main,
    /// Antecedent of conditional ("if" clause)
    ConditionalAntecedent,
    /// Consequent of conditional ("then" clause)
    ConditionalConsequent,
    /// Scope of negation
    NegationScope,
    /// Restrictor of universal quantifier (relative clause in "every X who...")
    UniversalRestrictor,
    /// Nuclear scope of universal quantifier
    UniversalScope,
    /// Branch of disjunction
    Disjunct,
}

impl BoxType {
    pub fn to_referent_source(&self) -> ReferentSource {
        match self {
            BoxType::Main => ReferentSource::MainClause,
            BoxType::ConditionalAntecedent => ReferentSource::ConditionalAntecedent,
            BoxType::ConditionalConsequent => ReferentSource::MainClause,
            BoxType::NegationScope => ReferentSource::NegationScope,
            BoxType::UniversalRestrictor => ReferentSource::UniversalRestrictor,
            BoxType::UniversalScope => ReferentSource::MainClause,
            BoxType::Disjunct => ReferentSource::Disjunct,
        }
    }
}

#[derive(Debug, Clone)]
pub struct Referent {
    pub variable: Symbol,
    pub noun_class: Symbol,
    pub gender: Gender,
    pub source: ReferentSource,
    pub used_by_pronoun: bool,
}

impl Referent {
    pub fn new(variable: Symbol, noun_class: Symbol, gender: Gender, source: ReferentSource) -> Self {
        Self {
            variable,
            noun_class,
            gender,
            source,
            used_by_pronoun: false,
        }
    }

    pub fn should_be_universal(&self) -> bool {
        self.source.gets_universal_force() || self.used_by_pronoun
    }
}

#[derive(Debug, Clone, Default)]
pub struct DrsBox {
    pub universe: Vec<Referent>,
    pub box_type: Option<BoxType>,
    pub parent: Option<usize>,
}

impl DrsBox {
    pub fn new(box_type: BoxType, parent: Option<usize>) -> Self {
        Self {
            universe: Vec::new(),
            box_type: Some(box_type),
            parent,
        }
    }
}

#[derive(Debug, Clone)]
pub struct Drs {
    boxes: Vec<DrsBox>,
    main_box: usize,
    current_box: usize,
}

impl Drs {
    pub fn new() -> Self {
        let main = DrsBox::new(BoxType::Main, None);
        Self {
            boxes: vec![main],
            main_box: 0,
            current_box: 0,
        }
    }

    pub fn enter_box(&mut self, box_type: BoxType) -> usize {
        let parent = self.current_box;
        let new_box = DrsBox::new(box_type, Some(parent));
        let idx = self.boxes.len();
        self.boxes.push(new_box);
        self.current_box = idx;
        idx
    }

    pub fn exit_box(&mut self) {
        if let Some(parent) = self.boxes[self.current_box].parent {
            self.current_box = parent;
        }
    }

    pub fn current_box_index(&self) -> usize {
        self.current_box
    }

    pub fn current_box_type(&self) -> Option<BoxType> {
        self.boxes.get(self.current_box).and_then(|b| b.box_type)
    }

    pub fn introduce_referent(&mut self, variable: Symbol, noun_class: Symbol, gender: Gender) {
        let source = self.boxes[self.current_box]
            .box_type
            .map(|bt| bt.to_referent_source())
            .unwrap_or(ReferentSource::MainClause);

        let referent = Referent::new(variable, noun_class, gender, source);
        self.boxes[self.current_box].universe.push(referent);
    }

    pub fn introduce_proper_name(&mut self, variable: Symbol, name: Symbol, gender: Gender) {
        let referent = Referent::new(variable, name, gender, ReferentSource::ProperName);
        self.boxes[self.current_box].universe.push(referent);
    }

    /// Check if a referent in box `from_box` can access referents in box `target_box`
    pub fn is_accessible(&self, target_box: usize, from_box: usize) -> bool {
        if target_box == from_box {
            return true;
        }

        let target = &self.boxes[target_box];
        let from = &self.boxes[from_box];

        // Check target box type - some boxes block outward access
        if let Some(bt) = target.box_type {
            match bt {
                BoxType::NegationScope | BoxType::Disjunct => {
                    // These boxes are NOT accessible from outside
                    return false;
                }
                _ => {}
            }
        }

        // Check if from_box can see target_box
        // Consequent can see antecedent
        if let (Some(BoxType::ConditionalConsequent), Some(BoxType::ConditionalAntecedent)) =
            (from.box_type, target.box_type)
        {
            // Check if they share the same parent (same conditional)
            if from.parent == target.parent {
                return true;
            }
        }

        // Universal scope can see universal restrictor
        if let (Some(BoxType::UniversalScope), Some(BoxType::UniversalRestrictor)) =
            (from.box_type, target.box_type)
        {
            if from.parent == target.parent {
                return true;
            }
        }

        // Can always access ancestors (parent chain)
        let mut current = from_box;
        while let Some(parent) = self.boxes[current].parent {
            if parent == target_box {
                return true;
            }
            current = parent;
        }

        false
    }

    /// Resolve a pronoun by finding accessible referents matching gender
    pub fn resolve_pronoun(&mut self, from_box: usize, gender: Gender) -> Option<Symbol> {
        // Search current box and accessible ancestors/siblings
        let mut candidates = Vec::new();

        // Check all boxes for accessibility
        for (box_idx, drs_box) in self.boxes.iter().enumerate() {
            if self.is_accessible(box_idx, from_box) {
                for referent in &drs_box.universe {
                    let gender_match = gender == Gender::Unknown
                        || referent.gender == Gender::Unknown
                        || referent.gender == gender
                        || gender == Gender::Neuter; // "it" can refer to things

                    if gender_match {
                        candidates.push((box_idx, referent.variable));
                    }
                }
            }
        }

        // Return most recent (last) candidate
        if let Some((box_idx, var)) = candidates.last() {
            // Mark as used by pronoun
            let box_idx = *box_idx;
            let var = *var;
            for referent in &mut self.boxes[box_idx].universe {
                if referent.variable == var {
                    referent.used_by_pronoun = true;
                    return Some(var);
                }
            }
        }

        None
    }

    /// Resolve a definite description by finding accessible referent matching noun class
    pub fn resolve_definite(&self, from_box: usize, noun_class: Symbol) -> Option<Symbol> {
        for (box_idx, drs_box) in self.boxes.iter().enumerate() {
            if self.is_accessible(box_idx, from_box) {
                for referent in drs_box.universe.iter().rev() {
                    if referent.noun_class == noun_class {
                        return Some(referent.variable);
                    }
                }
            }
        }
        None
    }

    /// Get all referents that should receive universal quantification
    pub fn get_universal_referents(&self) -> Vec<Symbol> {
        let mut result = Vec::new();
        for drs_box in &self.boxes {
            for referent in &drs_box.universe {
                if referent.should_be_universal() {
                    result.push(referent.variable);
                }
            }
        }
        result
    }

    /// Get all referents that should receive existential quantification
    pub fn get_existential_referents(&self) -> Vec<Symbol> {
        let mut result = Vec::new();
        for drs_box in &self.boxes {
            for referent in &drs_box.universe {
                if !referent.should_be_universal()
                    && !matches!(referent.source, ReferentSource::ProperName)
                {
                    result.push(referent.variable);
                }
            }
        }
        result
    }

    /// Get the most recent event referent (for binding weather adjectives to events)
    pub fn get_last_event_referent(&self, interner: &crate::intern::Interner) -> Option<Symbol> {
        // Search all boxes in reverse order for event referents
        for drs_box in self.boxes.iter().rev() {
            for referent in drs_box.universe.iter().rev() {
                let class_str = interner.resolve(referent.noun_class);
                if class_str == "Event" {
                    return Some(referent.variable);
                }
            }
        }
        None
    }

    /// Check if we're currently in a conditional antecedent
    pub fn in_conditional_antecedent(&self) -> bool {
        matches!(
            self.boxes.get(self.current_box).and_then(|b| b.box_type),
            Some(BoxType::ConditionalAntecedent)
        )
    }

    /// Check if we're currently in a universal restrictor
    pub fn in_universal_restrictor(&self) -> bool {
        matches!(
            self.boxes.get(self.current_box).and_then(|b| b.box_type),
            Some(BoxType::UniversalRestrictor)
        )
    }

    pub fn clear(&mut self) {
        self.boxes.clear();
        let main = DrsBox::new(BoxType::Main, None);
        self.boxes.push(main);
        self.main_box = 0;
        self.current_box = 0;
    }
}

impl Default for Drs {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::intern::Interner;

    #[test]
    fn referent_source_universal_force() {
        assert!(ReferentSource::ConditionalAntecedent.gets_universal_force());
        assert!(ReferentSource::UniversalRestrictor.gets_universal_force());
        assert!(!ReferentSource::MainClause.gets_universal_force());
        assert!(!ReferentSource::ProperName.gets_universal_force());
    }

    #[test]
    fn drs_new_has_main_box() {
        let drs = Drs::new();
        assert_eq!(drs.boxes.len(), 1);
        assert_eq!(drs.current_box, 0);
        assert_eq!(drs.boxes[0].box_type, Some(BoxType::Main));
    }

    #[test]
    fn drs_enter_exit_box() {
        let mut drs = Drs::new();
        assert_eq!(drs.current_box, 0);

        let ant_idx = drs.enter_box(BoxType::ConditionalAntecedent);
        assert_eq!(ant_idx, 1);
        assert_eq!(drs.current_box, 1);
        assert_eq!(drs.boxes[1].parent, Some(0));

        drs.exit_box();
        assert_eq!(drs.current_box, 0);
    }

    #[test]
    fn drs_introduce_referent_tracks_source() {
        let mut interner = Interner::new();
        let mut drs = Drs::new();

        let x = interner.intern("x");
        let farmer = interner.intern("Farmer");

        // In main box - should be MainClause
        drs.introduce_referent(x, farmer, Gender::Male);
        assert_eq!(drs.boxes[0].universe[0].source, ReferentSource::MainClause);

        // Enter conditional antecedent
        drs.enter_box(BoxType::ConditionalAntecedent);
        let y = interner.intern("y");
        let donkey = interner.intern("Donkey");
        drs.introduce_referent(y, donkey, Gender::Neuter);
        assert_eq!(
            drs.boxes[1].universe[0].source,
            ReferentSource::ConditionalAntecedent
        );
    }

    #[test]
    fn drs_conditional_antecedent_accessible_from_consequent() {
        let mut interner = Interner::new();
        let mut drs = Drs::new();

        // Enter conditional antecedent
        let ant_idx = drs.enter_box(BoxType::ConditionalAntecedent);
        let y = interner.intern("y");
        let donkey = interner.intern("Donkey");
        drs.introduce_referent(y, donkey, Gender::Neuter);
        drs.exit_box();

        // Enter conditional consequent
        let cons_idx = drs.enter_box(BoxType::ConditionalConsequent);

        // Consequent should be able to access antecedent
        assert!(drs.is_accessible(ant_idx, cons_idx));
    }

    #[test]
    fn drs_negation_blocks_accessibility() {
        let mut drs = Drs::new();

        // Enter negation scope
        let neg_idx = drs.enter_box(BoxType::NegationScope);
        drs.exit_box();

        // Main box should NOT be able to access negation scope
        assert!(!drs.is_accessible(neg_idx, 0));
    }

    #[test]
    fn drs_get_universal_referents() {
        let mut interner = Interner::new();
        let mut drs = Drs::new();

        let x = interner.intern("x");
        let farmer = interner.intern("Farmer");
        drs.introduce_referent(x, farmer, Gender::Male);

        drs.enter_box(BoxType::ConditionalAntecedent);
        let y = interner.intern("y");
        let donkey = interner.intern("Donkey");
        drs.introduce_referent(y, donkey, Gender::Neuter);

        let universals = drs.get_universal_referents();
        assert_eq!(universals.len(), 1);
        assert_eq!(universals[0], y);
    }

    #[test]
    fn drs_pronoun_resolution_marks_used() {
        let mut interner = Interner::new();
        let mut drs = Drs::new();

        drs.enter_box(BoxType::UniversalRestrictor);
        let y = interner.intern("y");
        let donkey = interner.intern("Donkey");
        drs.introduce_referent(y, donkey, Gender::Neuter);

        // Resolve "it" - should find donkey
        let resolved = drs.resolve_pronoun(drs.current_box, Gender::Neuter);
        assert_eq!(resolved, Some(y));

        // Should be marked as used
        assert!(drs.boxes[1].universe[0].used_by_pronoun);
    }
}

```

---

### Module: game

**File:** `src/game.rs`

Additional source module.

```rust
use crate::progress::UserProgress;
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub struct XpReward {
    pub base: u64,
    pub combo_bonus: u64,
    pub streak_bonus: u64,
    pub critical_bonus: u64,
    pub first_try_bonus: u64,
    pub total: u64,
    pub is_critical: bool,
}

pub fn calculate_xp_reward(
    difficulty: u32,
    combo: u32,
    streak_days: u32,
    first_try: bool,
    rng_seed: u64,
) -> XpReward {
    let base = 10 + (difficulty.saturating_sub(1) * 5) as u64;

    let combo_mult = 1.0 + (combo.min(10) as f64 * 0.1);
    let combo_bonus = ((base as f64) * (combo_mult - 1.0)) as u64;

    let streak_bonus = (streak_days.min(7) * 2) as u64;

    let first_try_bonus = if first_try { 5 } else { 0 };

    let is_critical = (rng_seed % 10) == 0;
    let critical_bonus = if is_critical { base } else { 0 };

    let total = base + combo_bonus + streak_bonus + first_try_bonus + critical_bonus;

    XpReward {
        base,
        combo_bonus,
        streak_bonus,
        critical_bonus,
        first_try_bonus,
        total,
        is_critical,
    }
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum StreakStatus {
    Active { days: u32 },
    AtRisk,
    Frozen,
    Lost { was: u32 },
}

pub fn update_streak(progress: &mut UserProgress, today: &str) -> StreakStatus {
    match &progress.last_streak_date {
        None => {
            progress.streak_days = 1;
            progress.last_streak_date = Some(today.to_string());
            StreakStatus::Active { days: 1 }
        }
        Some(last) if last == today => {
            StreakStatus::Active { days: progress.streak_days }
        }
        Some(last) if is_yesterday(last, today) => {
            progress.streak_days += 1;
            progress.last_streak_date = Some(today.to_string());
            StreakStatus::Active { days: progress.streak_days }
        }
        Some(last) if is_two_days_ago(last, today) && progress.streak_freezes > 0 => {
            progress.streak_freezes -= 1;
            progress.last_streak_date = Some(today.to_string());
            StreakStatus::Frozen
        }
        Some(_) => {
            let was = progress.streak_days;
            progress.streak_days = 1;
            progress.last_streak_date = Some(today.to_string());
            StreakStatus::Lost { was }
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ComboResult {
    pub new_combo: u32,
    pub is_new_record: bool,
    pub multiplier: f64,
}

pub fn update_combo(progress: &mut UserProgress, correct: bool) -> ComboResult {
    if correct {
        progress.combo += 1;
        let is_new_record = progress.combo > progress.best_combo;
        if is_new_record {
            progress.best_combo = progress.combo;
        }
        let multiplier = 1.0 + (progress.combo.min(10) as f64 * 0.1);
        ComboResult { new_combo: progress.combo, is_new_record, multiplier }
    } else {
        progress.combo = 0;
        ComboResult { new_combo: 0, is_new_record: false, multiplier: 1.0 }
    }
}

pub fn level_title(level: u32) -> &'static str {
    match level {
        1 => "Novice",
        2..=4 => "Apprentice",
        5..=9 => "Student",
        10..=14 => "Scholar",
        15..=19 => "Adept",
        20..=29 => "Expert",
        30..=39 => "Master",
        40..=49 => "Sage",
        _ => "Grandmaster",
    }
}

pub fn xp_progress_to_next_level(xp: u64, level: u32) -> (u64, u64, f64) {
    let current_threshold = crate::progress::xp_for_level(level);
    let next_threshold = crate::progress::xp_for_level(level + 1);
    let progress = xp.saturating_sub(current_threshold);
    let needed = next_threshold - current_threshold;
    let percentage = if needed > 0 {
        (progress as f64) / (needed as f64)
    } else {
        0.0
    };
    (progress, needed, percentage)
}

pub struct FreezeGrant {
    pub freezes: u8,
    pub reason: &'static str,
}

pub fn check_level_up_freeze_grants(old_level: u32, new_level: u32) -> Option<FreezeGrant> {
    let freeze_count = (old_level + 1..=new_level)
        .filter(|l| l % 5 == 0)
        .count() as u8;

    if freeze_count > 0 {
        Some(FreezeGrant {
            freezes: freeze_count,
            reason: "Level milestone reward",
        })
    } else {
        None
    }
}

pub fn is_sunday(date: &str) -> bool {
    if let Ok(num) = parse_date_to_days(date) {
        (num + 4) % 7 == 0
    } else {
        false
    }
}

fn is_yesterday(last: &str, today: &str) -> bool {
    if let (Ok(l), Ok(t)) = (parse_date_to_days(last), parse_date_to_days(today)) {
        t - l == 1
    } else {
        false
    }
}

fn is_two_days_ago(last: &str, today: &str) -> bool {
    if let (Ok(l), Ok(t)) = (parse_date_to_days(last), parse_date_to_days(today)) {
        t - l == 2
    } else {
        false
    }
}

fn parse_date_to_days(date: &str) -> Result<i64, ()> {
    let parts: Vec<&str> = date.split('-').collect();
    if parts.len() != 3 {
        return Err(());
    }

    let year: i64 = parts[0].parse().map_err(|_| ())?;
    let month: i64 = parts[1].parse().map_err(|_| ())?;
    let day: i64 = parts[2].parse().map_err(|_| ())?;

    let days = year * 365 + (year / 4) - (year / 100) + (year / 400)
        + (month * 30) + day;
    Ok(days)
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_xp_reward_base() {
        let reward = calculate_xp_reward(1, 0, 0, false, 1);
        assert_eq!(reward.base, 10);
        assert_eq!(reward.combo_bonus, 0);
        assert_eq!(reward.total, 10);
        assert!(!reward.is_critical);
    }

    #[test]
    fn test_xp_reward_with_combo() {
        let reward = calculate_xp_reward(1, 5, 0, false, 1);
        assert_eq!(reward.base, 10);
        assert_eq!(reward.combo_bonus, 5); // 10 * 0.5 = 5
        assert_eq!(reward.total, 15);
    }

    #[test]
    fn test_xp_reward_critical() {
        let reward = calculate_xp_reward(1, 0, 0, false, 10); // seed % 10 == 0
        assert!(reward.is_critical);
        assert_eq!(reward.critical_bonus, 10);
        assert_eq!(reward.total, 20);
    }

    #[test]
    fn test_xp_reward_full() {
        // difficulty 3, combo 10, streak 7, first try, non-crit
        let reward = calculate_xp_reward(3, 10, 7, true, 1);
        // base = 10 + (2 * 5) = 20
        // combo = 20 * 1.0 = 20
        // streak = 14
        // first_try = 5
        // total = 20 + 20 + 14 + 5 = 59
        assert_eq!(reward.base, 20);
        assert_eq!(reward.combo_bonus, 20);
        assert_eq!(reward.streak_bonus, 14);
        assert_eq!(reward.first_try_bonus, 5);
        assert_eq!(reward.total, 59);
    }

    #[test]
    fn test_combo_increment() {
        let mut progress = UserProgress::new();

        let result = update_combo(&mut progress, true);
        assert_eq!(result.new_combo, 1);
        assert!(result.is_new_record);

        let result = update_combo(&mut progress, true);
        assert_eq!(result.new_combo, 2);
        assert!(result.is_new_record);

        let result = update_combo(&mut progress, false);
        assert_eq!(result.new_combo, 0);
        assert!(!result.is_new_record);
    }

    #[test]
    fn test_combo_multiplier() {
        let mut progress = UserProgress::new();

        for _ in 0..10 {
            update_combo(&mut progress, true);
        }

        let result = update_combo(&mut progress, true);
        assert!((result.multiplier - 2.0).abs() < 0.01);
    }

    #[test]
    fn test_level_titles() {
        assert_eq!(level_title(1), "Novice");
        assert_eq!(level_title(5), "Student");
        assert_eq!(level_title(10), "Scholar");
        assert_eq!(level_title(50), "Grandmaster");
    }

    #[test]
    fn test_level_up_freeze_grants() {
        assert!(check_level_up_freeze_grants(1, 4).is_none());

        let grant = check_level_up_freeze_grants(4, 5).unwrap();
        assert_eq!(grant.freezes, 1);

        let grant = check_level_up_freeze_grants(1, 10).unwrap();
        assert_eq!(grant.freezes, 2); // levels 5 and 10
    }

    #[test]
    fn test_is_yesterday() {
        assert!(is_yesterday("2025-01-01", "2025-01-02"));
        assert!(!is_yesterday("2025-01-01", "2025-01-03"));
    }
}

```

---

### Module: interpreter

**File:** `src/interpreter.rs`

Additional source module.

```rust
//! Tree-walking interpreter for LOGOS imperative code.
//!
//! This module provides runtime execution of parsed LOGOS programs,
//! walking the AST and executing statements/expressions directly.
//!
//! Phase 55: Made async for VFS operations (OPFS on WASM, tokio::fs on native).

use std::collections::HashMap;
use std::sync::Arc;

use async_recursion::async_recursion;

use crate::ast::stmt::{BinaryOpKind, Block, Expr, Literal, MatchArm, ReadSource, Stmt, TypeExpr};
use crate::intern::{Interner, Symbol};

// Phase 55: VFS imports
use logos_core::fs::Vfs;

/// Runtime values during interpretation.
#[derive(Debug, Clone)]
pub enum RuntimeValue {
    Int(i64),
    Float(f64),
    Bool(bool),
    Text(String),
    Char(char),
    List(Vec<RuntimeValue>),
    Tuple(Vec<RuntimeValue>),  // Heterogeneous tuple
    Set(Vec<RuntimeValue>),  // HashSet equivalent - Vec for simplicity in interpreter
    Map(HashMap<String, RuntimeValue>),
    Struct {
        type_name: String,
        fields: HashMap<String, RuntimeValue>,
    },
    Nothing,
}

impl RuntimeValue {
    pub fn type_name(&self) -> &'static str {
        match self {
            RuntimeValue::Int(_) => "Int",
            RuntimeValue::Float(_) => "Float",
            RuntimeValue::Bool(_) => "Bool",
            RuntimeValue::Text(_) => "Text",
            RuntimeValue::Char(_) => "Char",
            RuntimeValue::List(_) => "List",
            RuntimeValue::Tuple(_) => "Tuple",
            RuntimeValue::Set(_) => "Set",
            RuntimeValue::Map(_) => "Map",
            RuntimeValue::Struct { .. } => "Struct",
            RuntimeValue::Nothing => "Nothing",
        }
    }

    pub fn is_truthy(&self) -> bool {
        match self {
            RuntimeValue::Bool(b) => *b,
            RuntimeValue::Int(n) => *n != 0,
            RuntimeValue::Nothing => false,
            _ => true,
        }
    }

    pub fn to_display_string(&self) -> String {
        match self {
            RuntimeValue::Int(n) => n.to_string(),
            RuntimeValue::Float(f) => format!("{:.6}", f).trim_end_matches('0').trim_end_matches('.').to_string(),
            RuntimeValue::Bool(b) => if *b { "true" } else { "false" }.to_string(),
            RuntimeValue::Text(s) => s.clone(),
            RuntimeValue::Char(c) => c.to_string(),
            RuntimeValue::List(items) => {
                let parts: Vec<String> = items.iter().map(|v| v.to_display_string()).collect();
                format!("[{}]", parts.join(", "))
            }
            RuntimeValue::Tuple(items) => {
                let parts: Vec<String> = items.iter().map(|v| v.to_display_string()).collect();
                format!("({})", parts.join(", "))
            }
            RuntimeValue::Set(items) => {
                let parts: Vec<String> = items.iter().map(|v| v.to_display_string()).collect();
                format!("{{{}}}", parts.join(", "))
            }
            RuntimeValue::Map(m) => {
                let pairs: Vec<String> = m.iter()
                    .map(|(k, v)| format!("{}: {}", k, v.to_display_string()))
                    .collect();
                format!("{{{}}}", pairs.join(", "))
            }
            RuntimeValue::Struct { type_name, fields } => {
                if fields.is_empty() {
                    // Unit variant - just show the name
                    type_name.clone()
                } else {
                    let field_strs: Vec<String> = fields
                        .iter()
                        .map(|(k, v)| format!("{}: {}", k, v.to_display_string()))
                        .collect();
                    format!("{} {{ {} }}", type_name, field_strs.join(", "))
                }
            }
            RuntimeValue::Nothing => "nothing".to_string(),
        }
    }
}

/// Control flow signals for statement execution.
pub enum ControlFlow {
    Continue,
    Return(RuntimeValue),
    Break,
}

/// Stored function definition for user-defined functions.
pub struct FunctionDef<'a> {
    pub params: Vec<(Symbol, &'a TypeExpr<'a>)>,
    pub body: Block<'a>,
    pub return_type: Option<&'a TypeExpr<'a>>,
}

/// Tree-walking interpreter for LOGOS programs.
///
/// Phase 55: Now async with optional VFS for file operations.
pub struct Interpreter<'a> {
    interner: &'a Interner,
    /// Scope stack - each HashMap is a scope level
    env: Vec<HashMap<Symbol, RuntimeValue>>,
    /// User-defined functions
    functions: HashMap<Symbol, FunctionDef<'a>>,
    /// Struct type definitions (for constructor validation)
    struct_defs: HashMap<Symbol, Vec<(Symbol, Symbol, bool)>>,
    /// Output lines from show() calls
    pub output: Vec<String>,
    /// Phase 55: VFS for file operations (OPFS on WASM, NativeVfs on native)
    vfs: Option<Arc<dyn Vfs>>,
}

impl<'a> Interpreter<'a> {
    pub fn new(interner: &'a Interner) -> Self {
        Interpreter {
            interner,
            env: vec![HashMap::new()], // Global scope
            functions: HashMap::new(),
            struct_defs: HashMap::new(),
            output: Vec::new(),
            vfs: None,
        }
    }

    /// Phase 55: Set the VFS for file operations.
    pub fn with_vfs(mut self, vfs: Arc<dyn Vfs>) -> Self {
        self.vfs = Some(vfs);
        self
    }

    /// Execute a program (list of statements).
    /// Phase 55: Now async for VFS operations.
    pub async fn run(&mut self, stmts: &[Stmt<'a>]) -> Result<(), String> {
        for stmt in stmts {
            match self.execute_stmt(stmt).await? {
                ControlFlow::Return(_) => break,
                ControlFlow::Break => break,
                ControlFlow::Continue => {}
            }
        }
        Ok(())
    }

    /// Execute a single statement.
    /// Phase 55: Now async for VFS operations.
    #[async_recursion(?Send)]
    async fn execute_stmt(&mut self, stmt: &Stmt<'a>) -> Result<ControlFlow, String> {
        match stmt {
            Stmt::Let { var, value, .. } => {
                let val = self.evaluate_expr(value).await?;
                self.define(*var, val);
                Ok(ControlFlow::Continue)
            }

            Stmt::Set { target, value } => {
                let val = self.evaluate_expr(value).await?;
                self.assign(*target, val)?;
                Ok(ControlFlow::Continue)
            }

            Stmt::Call { function, args } => {
                self.call_function(*function, args).await?;
                Ok(ControlFlow::Continue)
            }

            Stmt::If { cond, then_block, else_block } => {
                let condition = self.evaluate_expr(cond).await?;
                if condition.is_truthy() {
                    let flow = self.execute_block(then_block).await?;
                    if !matches!(flow, ControlFlow::Continue) {
                        return Ok(flow);
                    }
                } else if let Some(else_stmts) = else_block {
                    let flow = self.execute_block(else_stmts).await?;
                    if !matches!(flow, ControlFlow::Continue) {
                        return Ok(flow);
                    }
                }
                Ok(ControlFlow::Continue)
            }

            Stmt::While { cond, body, .. } => {
                loop {
                    let condition = self.evaluate_expr(cond).await?;
                    if !condition.is_truthy() {
                        break;
                    }
                    match self.execute_block(body).await? {
                        ControlFlow::Break => break,
                        ControlFlow::Return(v) => return Ok(ControlFlow::Return(v)),
                        ControlFlow::Continue => {}
                    }
                }
                Ok(ControlFlow::Continue)
            }

            Stmt::Repeat { var, iterable, body } => {
                let iter_val = self.evaluate_expr(iterable).await?;
                let items = match iter_val {
                    RuntimeValue::List(list) => list,
                    RuntimeValue::Text(s) => {
                        s.chars().map(|c| RuntimeValue::Text(c.to_string())).collect()
                    }
                    _ => return Err(format!("Cannot iterate over {}", iter_val.type_name())),
                };

                self.push_scope();
                for item in items {
                    self.define(*var, item);
                    match self.execute_block(body).await? {
                        ControlFlow::Break => break,
                        ControlFlow::Return(v) => {
                            self.pop_scope();
                            return Ok(ControlFlow::Return(v));
                        }
                        ControlFlow::Continue => {}
                    }
                }
                self.pop_scope();
                Ok(ControlFlow::Continue)
            }

            Stmt::Return { value } => {
                let ret_val = match value {
                    Some(expr) => self.evaluate_expr(expr).await?,
                    None => RuntimeValue::Nothing,
                };
                Ok(ControlFlow::Return(ret_val))
            }

            Stmt::FunctionDef { name, params, body, return_type, .. } => {
                let func = FunctionDef {
                    params: params.clone(),
                    body: *body,
                    return_type: *return_type,
                };
                self.functions.insert(*name, func);
                Ok(ControlFlow::Continue)
            }

            Stmt::StructDef { name, fields, .. } => {
                self.struct_defs.insert(*name, fields.clone());
                Ok(ControlFlow::Continue)
            }

            Stmt::SetField { object, field, value } => {
                let new_val = self.evaluate_expr(value).await?;
                if let Expr::Identifier(obj_sym) = object {
                    let mut obj_val = self.lookup(*obj_sym)?.clone();
                    if let RuntimeValue::Struct { fields, .. } = &mut obj_val {
                        let field_name = self.interner.resolve(*field).to_string();
                        fields.insert(field_name, new_val);
                        self.assign(*obj_sym, obj_val)?;
                    } else {
                        return Err(format!("Cannot set field on non-struct value"));
                    }
                } else {
                    return Err("SetField target must be an identifier".to_string());
                }
                Ok(ControlFlow::Continue)
            }

            Stmt::Push { value, collection } => {
                let val = self.evaluate_expr(value).await?;
                if let Expr::Identifier(coll_sym) = collection {
                    let mut coll_val = self.lookup(*coll_sym)?.clone();
                    if let RuntimeValue::List(ref mut items) = coll_val {
                        items.push(val);
                        self.assign(*coll_sym, coll_val)?;
                    } else {
                        return Err("Can only push to a List".to_string());
                    }
                } else {
                    return Err("Push collection must be an identifier".to_string());
                }
                Ok(ControlFlow::Continue)
            }

            Stmt::Pop { collection, into } => {
                if let Expr::Identifier(coll_sym) = collection {
                    let mut coll_val = self.lookup(*coll_sym)?.clone();
                    if let RuntimeValue::List(ref mut items) = coll_val {
                        let popped = items.pop().unwrap_or(RuntimeValue::Nothing);
                        self.assign(*coll_sym, coll_val)?;
                        if let Some(into_var) = into {
                            self.define(*into_var, popped);
                        }
                    } else {
                        return Err("Can only pop from a List".to_string());
                    }
                } else {
                    return Err("Pop collection must be an identifier".to_string());
                }
                Ok(ControlFlow::Continue)
            }

            Stmt::Add { value, collection } => {
                let val = self.evaluate_expr(value).await?;
                if let Expr::Identifier(coll_sym) = collection {
                    let mut coll_val = self.lookup(*coll_sym)?.clone();
                    if let RuntimeValue::Set(ref mut items) = coll_val {
                        // Only add if not already present
                        if !items.iter().any(|x| self.values_equal(x, &val)) {
                            items.push(val);
                        }
                        self.assign(*coll_sym, coll_val)?;
                    } else {
                        return Err("Can only add to a Set".to_string());
                    }
                } else {
                    return Err("Add collection must be an identifier".to_string());
                }
                Ok(ControlFlow::Continue)
            }

            Stmt::Remove { value, collection } => {
                let val = self.evaluate_expr(value).await?;
                if let Expr::Identifier(coll_sym) = collection {
                    let mut coll_val = self.lookup(*coll_sym)?.clone();
                    if let RuntimeValue::Set(ref mut items) = coll_val {
                        items.retain(|x| !self.values_equal(x, &val));
                        self.assign(*coll_sym, coll_val)?;
                    } else {
                        return Err("Can only remove from a Set".to_string());
                    }
                } else {
                    return Err("Remove collection must be an identifier".to_string());
                }
                Ok(ControlFlow::Continue)
            }

            Stmt::SetIndex { collection, index, value } => {
                let idx_val = self.evaluate_expr(index).await?;
                let new_val = self.evaluate_expr(value).await?;
                if let Expr::Identifier(coll_sym) = collection {
                    let mut coll_val = self.lookup(*coll_sym)?.clone();
                    match (&mut coll_val, &idx_val) {
                        (RuntimeValue::List(ref mut items), RuntimeValue::Int(n)) => {
                            let idx = *n as usize;
                            if idx == 0 || idx > items.len() {
                                return Err(format!("Index {} out of bounds for list of length {}", idx, items.len()));
                            }
                            items[idx - 1] = new_val;
                        }
                        (RuntimeValue::Map(ref mut map), RuntimeValue::Text(key)) => {
                            map.insert(key.clone(), new_val);
                        }
                        (RuntimeValue::List(_), _) => {
                            return Err("List index must be an integer".to_string());
                        }
                        (RuntimeValue::Map(_), _) => {
                            return Err("Map key must be a string".to_string());
                        }
                        _ => {
                            return Err(format!("Cannot index into {}", coll_val.type_name()));
                        }
                    }
                    self.assign(*coll_sym, coll_val)?;
                } else {
                    return Err("SetIndex collection must be an identifier".to_string());
                }
                Ok(ControlFlow::Continue)
            }

            Stmt::Inspect { target, arms, .. } => {
                let target_val = self.evaluate_expr(target).await?;
                self.execute_inspect(&target_val, arms).await?;
                Ok(ControlFlow::Continue)
            }

            Stmt::Zone { name, body, .. } => {
                self.push_scope();
                self.define(*name, RuntimeValue::Nothing);
                let result = self.execute_block(body).await;
                self.pop_scope();
                result?;
                Ok(ControlFlow::Continue)
            }

            Stmt::Concurrent { tasks } | Stmt::Parallel { tasks } => {
                // In WASM, execute sequentially (no threads)
                for task in tasks.iter() {
                    self.execute_stmt(task).await?;
                }
                Ok(ControlFlow::Continue)
            }

            Stmt::Assert { .. } | Stmt::Trust { .. } => {
                Ok(ControlFlow::Continue)
            }

            Stmt::RuntimeAssert { condition } => {
                let val = self.evaluate_expr(condition).await?;
                if !val.is_truthy() {
                    return Err("Assertion failed".to_string());
                }
                Ok(ControlFlow::Continue)
            }

            Stmt::Give { .. } => {
                Ok(ControlFlow::Continue)
            }

            Stmt::Show { object, recipient } => {
                let obj_val = self.evaluate_expr(object).await?;
                if let Expr::Identifier(sym) = recipient {
                    let name = self.interner.resolve(*sym);
                    if name == "show" {
                        self.output.push(obj_val.to_display_string());
                    }
                }
                Ok(ControlFlow::Continue)
            }

            // Phase 55: VFS operations now supported
            Stmt::ReadFrom { var, source } => {
                let content = match source {
                    ReadSource::Console => {
                        // Console read not available in WASM interpreter
                        String::new()
                    }
                    ReadSource::File(path_expr) => {
                        let path = self.evaluate_expr(path_expr).await?.to_display_string();
                        match &self.vfs {
                            Some(vfs) => {
                                vfs.read_to_string(&path).await
                                    .map_err(|e| format!("Read error: {}", e))?
                            }
                            None => return Err("VFS not initialized. Use Interpreter::with_vfs()".to_string()),
                        }
                    }
                };
                self.define(*var, RuntimeValue::Text(content));
                Ok(ControlFlow::Continue)
            }

            Stmt::WriteFile { content, path } => {
                let content_val = self.evaluate_expr(content).await?.to_display_string();
                let path_val = self.evaluate_expr(path).await?.to_display_string();
                match &self.vfs {
                    Some(vfs) => {
                        vfs.write(&path_val, content_val.as_bytes()).await
                            .map_err(|e| format!("Write error: {}", e))?;
                    }
                    None => return Err("VFS not initialized. Use Interpreter::with_vfs()".to_string()),
                }
                Ok(ControlFlow::Continue)
            }

            Stmt::Spawn { name, .. } => {
                self.define(*name, RuntimeValue::Nothing);
                Ok(ControlFlow::Continue)
            }

            Stmt::SendMessage { .. } => {
                Ok(ControlFlow::Continue)
            }

            Stmt::AwaitMessage { into, .. } => {
                self.define(*into, RuntimeValue::Nothing);
                Ok(ControlFlow::Continue)
            }

            Stmt::MergeCrdt { .. } => {
                Err("CRDT Merge is not supported in the interpreter. Use compiled Rust.".to_string())
            }

            Stmt::IncreaseCrdt { .. } => {
                Err("CRDT Increase is not supported in the interpreter. Use compiled Rust.".to_string())
            }

            Stmt::DecreaseCrdt { .. } => {
                Err("CRDT Decrease is not supported in the interpreter. Use compiled Rust.".to_string())
            }

            Stmt::AppendToSequence { .. } => {
                Err("Append to sequence is not supported in the interpreter. Use compiled Rust.".to_string())
            }

            Stmt::ResolveConflict { .. } => {
                Err("Resolve conflict is not supported in the interpreter. Use compiled Rust.".to_string())
            }

            Stmt::Check { .. } => {
                Err("Security Check is not supported in the interpreter. Use compiled Rust.".to_string())
            }

            Stmt::Listen { .. } => {
                Err("Listen is not supported in the interpreter. Use compiled Rust.".to_string())
            }
            Stmt::ConnectTo { .. } => {
                Err("Connect is not supported in the interpreter. Use compiled Rust.".to_string())
            }
            Stmt::LetPeerAgent { .. } => {
                Err("PeerAgent is not supported in the interpreter. Use compiled Rust.".to_string())
            }
            Stmt::Sleep { .. } => {
                // Phase 55: Sleep could be implemented with gloo-timers on WASM
                Err("Sleep is not yet supported in the interpreter.".to_string())
            }
            Stmt::Sync { .. } => {
                Err("Sync is not supported in the interpreter. Use compiled Rust.".to_string())
            }
            // Phase 55: Mount now supported via VFS
            Stmt::Mount { var, path } => {
                let path_val = self.evaluate_expr(path).await?.to_display_string();
                match &self.vfs {
                    Some(vfs) => {
                        // Read existing content or create empty
                        let content = match vfs.read_to_string(&path_val).await {
                            Ok(s) => s,
                            Err(_) => String::new(),
                        };
                        // Store as a simple value for now (full Persistent<T> requires more work)
                        self.define(*var, RuntimeValue::Text(content));
                    }
                    None => return Err("VFS not initialized. Use Interpreter::with_vfs()".to_string()),
                }
                Ok(ControlFlow::Continue)
            }

            // Phase 54: Go-like concurrency - not supported in interpreter
            // These are compile-to-Rust only features
            Stmt::LaunchTask { .. } |
            Stmt::LaunchTaskWithHandle { .. } |
            Stmt::CreatePipe { .. } |
            Stmt::SendPipe { .. } |
            Stmt::ReceivePipe { .. } |
            Stmt::TrySendPipe { .. } |
            Stmt::TryReceivePipe { .. } |
            Stmt::StopTask { .. } |
            Stmt::Select { .. } => {
                Err("Go-like concurrency (Launch, Pipe, Select) is only supported in compiled mode".to_string())
            }
        }
    }

    /// Execute a block of statements, returning control flow.
    /// Phase 55: Now async.
    #[async_recursion(?Send)]
    async fn execute_block(&mut self, block: Block<'a>) -> Result<ControlFlow, String> {
        self.push_scope();
        for stmt in block.iter() {
            match self.execute_stmt(stmt).await? {
                ControlFlow::Continue => {}
                flow => {
                    self.pop_scope();
                    return Ok(flow);
                }
            }
        }
        self.pop_scope();
        Ok(ControlFlow::Continue)
    }

    /// Execute Inspect (pattern matching).
    /// Phase 55: Now async.
    #[async_recursion(?Send)]
    async fn execute_inspect(&mut self, target: &RuntimeValue, arms: &[MatchArm<'a>]) -> Result<(), String> {
        for arm in arms {
            if arm.variant.is_none() {
                self.execute_block(arm.body).await?;
                return Ok(());
            }
            if let RuntimeValue::Struct { type_name, fields } = target {
                if let Some(variant) = arm.variant {
                    let variant_name = self.interner.resolve(variant);
                    if type_name == variant_name {
                        self.push_scope();
                        for (field_name, binding_name) in &arm.bindings {
                            let field_str = self.interner.resolve(*field_name);
                            if let Some(val) = fields.get(field_str) {
                                self.define(*binding_name, val.clone());
                            }
                        }
                        let result = self.execute_block(arm.body).await;
                        self.pop_scope();
                        result?;
                        return Ok(());
                    }
                }
            }
        }
        Ok(())
    }

    /// Evaluate an expression to a runtime value.
    /// Phase 55: Now async.
    #[async_recursion(?Send)]
    async fn evaluate_expr(&mut self, expr: &Expr<'a>) -> Result<RuntimeValue, String> {
        match expr {
            Expr::Literal(lit) => self.evaluate_literal(lit),

            Expr::Identifier(sym) => {
                self.lookup(*sym).cloned()
            }

            Expr::BinaryOp { op, left, right } => {
                let left_val = self.evaluate_expr(left).await?;
                let right_val = self.evaluate_expr(right).await?;
                self.apply_binary_op(*op, left_val, right_val)
            }

            Expr::Call { function, args } => {
                self.call_function(*function, args).await
            }

            Expr::Index { collection, index } => {
                let coll_val = self.evaluate_expr(collection).await?;
                let idx_val = self.evaluate_expr(index).await?;
                match (&coll_val, &idx_val) {
                    (RuntimeValue::List(items), RuntimeValue::Int(idx)) => {
                        let idx = *idx as usize;
                        if idx == 0 || idx > items.len() {
                            return Err(format!("Index {} out of bounds", idx));
                        }
                        Ok(items[idx - 1].clone())
                    }
                    (RuntimeValue::Tuple(items), RuntimeValue::Int(idx)) => {
                        let idx = *idx as usize;
                        if idx == 0 || idx > items.len() {
                            return Err(format!("Index {} out of bounds", idx));
                        }
                        Ok(items[idx - 1].clone())
                    }
                    (RuntimeValue::Text(s), RuntimeValue::Int(idx)) => {
                        let idx = *idx as usize;
                        if idx == 0 || idx > s.len() {
                            return Err(format!("Index {} out of bounds", idx));
                        }
                        Ok(RuntimeValue::Text(s.chars().nth(idx - 1).unwrap().to_string()))
                    }
                    (RuntimeValue::Map(map), RuntimeValue::Text(key)) => {
                        match map.get(key) {
                            Some(val) => Ok(val.clone()),
                            None => Err(format!("Key '{}' not found in map", key)),
                        }
                    }
                    _ => Err(format!("Cannot index {} with {}", coll_val.type_name(), idx_val.type_name())),
                }
            }

            Expr::Slice { collection, start, end } => {
                let coll_val = self.evaluate_expr(collection).await?;
                let start_val = self.evaluate_expr(start).await?;
                let end_val = self.evaluate_expr(end).await?;
                match (&coll_val, &start_val, &end_val) {
                    (RuntimeValue::List(items), RuntimeValue::Int(s), RuntimeValue::Int(e)) => {
                        let start = (*s as usize).saturating_sub(1);
                        let end = *e as usize;
                        let slice: Vec<RuntimeValue> = items.get(start..end).unwrap_or(&[]).to_vec();
                        Ok(RuntimeValue::List(slice))
                    }
                    _ => Err("Slice requires List and Int indices".to_string()),
                }
            }

            Expr::Copy { expr: inner } => {
                self.evaluate_expr(inner).await
            }

            Expr::Length { collection } => {
                let coll_val = self.evaluate_expr(collection).await?;
                match &coll_val {
                    RuntimeValue::List(items) => Ok(RuntimeValue::Int(items.len() as i64)),
                    RuntimeValue::Tuple(items) => Ok(RuntimeValue::Int(items.len() as i64)),
                    RuntimeValue::Set(items) => Ok(RuntimeValue::Int(items.len() as i64)),
                    RuntimeValue::Text(s) => Ok(RuntimeValue::Int(s.len() as i64)),
                    _ => Err(format!("Cannot get length of {}", coll_val.type_name())),
                }
            }

            Expr::Contains { collection, value } => {
                let coll_val = self.evaluate_expr(collection).await?;
                let val = self.evaluate_expr(value).await?;
                match &coll_val {
                    RuntimeValue::Set(items) => {
                        let found = items.iter().any(|item| self.values_equal(item, &val));
                        Ok(RuntimeValue::Bool(found))
                    }
                    RuntimeValue::List(items) => {
                        let found = items.iter().any(|item| self.values_equal(item, &val));
                        Ok(RuntimeValue::Bool(found))
                    }
                    RuntimeValue::Map(entries) => {
                        // For maps, check if key exists (keys are Strings)
                        if let RuntimeValue::Text(key) = &val {
                            Ok(RuntimeValue::Bool(entries.contains_key(key)))
                        } else {
                            Err(format!("Map key must be Text, got {}", val.type_name()))
                        }
                    }
                    RuntimeValue::Text(s) => {
                        // For text, check if substring exists
                        if let RuntimeValue::Text(needle) = &val {
                            Ok(RuntimeValue::Bool(s.contains(needle.as_str())))
                        } else if let RuntimeValue::Char(c) = &val {
                            Ok(RuntimeValue::Bool(s.contains(*c)))
                        } else {
                            Err(format!("Cannot check if Text contains {}", val.type_name()))
                        }
                    }
                    _ => Err(format!("Cannot check contains on {}", coll_val.type_name())),
                }
            }

            Expr::Union { left, right } => {
                let left_val = self.evaluate_expr(left).await?;
                let right_val = self.evaluate_expr(right).await?;
                match (&left_val, &right_val) {
                    (RuntimeValue::Set(a), RuntimeValue::Set(b)) => {
                        let mut result = a.clone();
                        for item in b.iter() {
                            if !result.iter().any(|x| self.values_equal(x, item)) {
                                result.push(item.clone());
                            }
                        }
                        Ok(RuntimeValue::Set(result))
                    }
                    _ => Err(format!("Cannot union {} and {}", left_val.type_name(), right_val.type_name())),
                }
            }

            Expr::Intersection { left, right } => {
                let left_val = self.evaluate_expr(left).await?;
                let right_val = self.evaluate_expr(right).await?;
                match (&left_val, &right_val) {
                    (RuntimeValue::Set(a), RuntimeValue::Set(b)) => {
                        let result: Vec<RuntimeValue> = a.iter()
                            .filter(|item| b.iter().any(|x| self.values_equal(x, item)))
                            .cloned()
                            .collect();
                        Ok(RuntimeValue::Set(result))
                    }
                    _ => Err(format!("Cannot intersect {} and {}", left_val.type_name(), right_val.type_name())),
                }
            }

            Expr::List(items) => {
                // Can't use .map() with async, so manual loop
                let mut values = Vec::with_capacity(items.len());
                for e in items.iter() {
                    values.push(self.evaluate_expr(e).await?);
                }
                Ok(RuntimeValue::List(values))
            }

            Expr::Tuple(items) => {
                let mut values = Vec::with_capacity(items.len());
                for e in items.iter() {
                    values.push(self.evaluate_expr(e).await?);
                }
                Ok(RuntimeValue::Tuple(values))
            }

            Expr::Range { start, end } => {
                let start_val = self.evaluate_expr(start).await?;
                let end_val = self.evaluate_expr(end).await?;
                match (&start_val, &end_val) {
                    (RuntimeValue::Int(s), RuntimeValue::Int(e)) => {
                        let range: Vec<RuntimeValue> = (*s..=*e)
                            .map(RuntimeValue::Int)
                            .collect();
                        Ok(RuntimeValue::List(range))
                    }
                    _ => Err("Range requires Int bounds".to_string()),
                }
            }

            Expr::FieldAccess { object, field } => {
                let obj_val = self.evaluate_expr(object).await?;
                match &obj_val {
                    RuntimeValue::Struct { fields, .. } => {
                        let field_name = self.interner.resolve(*field);
                        fields.get(field_name).cloned()
                            .ok_or_else(|| format!("Field '{}' not found", field_name))
                    }
                    _ => Err(format!("Cannot access field on {}", obj_val.type_name())),
                }
            }

            Expr::New { type_name, init_fields, .. } => {
                let name = self.interner.resolve(*type_name).to_string();

                if name == "Seq" || name == "List" {
                    return Ok(RuntimeValue::List(vec![]));
                }

                if name == "Set" || name == "HashSet" {
                    return Ok(RuntimeValue::Set(vec![]));
                }

                if name == "Map" || name == "HashMap" {
                    return Ok(RuntimeValue::Map(HashMap::new()));
                }

                let mut fields = HashMap::new();
                for (field_sym, field_expr) in init_fields {
                    let field_name = self.interner.resolve(*field_sym).to_string();
                    let field_val = self.evaluate_expr(field_expr).await?;
                    fields.insert(field_name, field_val);
                }
                Ok(RuntimeValue::Struct { type_name: name, fields })
            }

            Expr::NewVariant { variant, fields, .. } => {
                let name = self.interner.resolve(*variant).to_string();
                let mut field_map = HashMap::new();
                for (field_sym, field_expr) in fields {
                    let field_name = self.interner.resolve(*field_sym).to_string();
                    let field_val = self.evaluate_expr(field_expr).await?;
                    field_map.insert(field_name, field_val);
                }
                Ok(RuntimeValue::Struct { type_name: name, fields: field_map })
            }

            Expr::ManifestOf { .. } => {
                Ok(RuntimeValue::List(vec![]))
            }

            Expr::ChunkAt { .. } => {
                Ok(RuntimeValue::Nothing)
            }
        }
    }

    /// Evaluate a literal to a runtime value.
    fn evaluate_literal(&self, lit: &Literal) -> Result<RuntimeValue, String> {
        match lit {
            Literal::Number(n) => Ok(RuntimeValue::Int(*n)),
            Literal::Float(f) => Ok(RuntimeValue::Float(*f)),
            Literal::Text(sym) => Ok(RuntimeValue::Text(self.interner.resolve(*sym).to_string())),
            Literal::Boolean(b) => Ok(RuntimeValue::Bool(*b)),
            Literal::Nothing => Ok(RuntimeValue::Nothing),
            Literal::Char(c) => Ok(RuntimeValue::Char(*c)),
        }
    }

    /// Apply a binary operator.
    fn apply_binary_op(&self, op: BinaryOpKind, left: RuntimeValue, right: RuntimeValue) -> Result<RuntimeValue, String> {
        match op {
            BinaryOpKind::Add => self.apply_add(left, right),
            BinaryOpKind::Subtract => self.apply_subtract(left, right),
            BinaryOpKind::Multiply => self.apply_multiply(left, right),
            BinaryOpKind::Divide => self.apply_divide(left, right),
            BinaryOpKind::Modulo => self.apply_modulo(left, right),
            BinaryOpKind::Eq => Ok(RuntimeValue::Bool(self.values_equal(&left, &right))),
            BinaryOpKind::NotEq => Ok(RuntimeValue::Bool(!self.values_equal(&left, &right))),
            BinaryOpKind::Lt => self.apply_comparison(left, right, |a, b| a < b),
            BinaryOpKind::Gt => self.apply_comparison(left, right, |a, b| a > b),
            BinaryOpKind::LtEq => self.apply_comparison(left, right, |a, b| a <= b),
            BinaryOpKind::GtEq => self.apply_comparison(left, right, |a, b| a >= b),
            BinaryOpKind::And => Ok(RuntimeValue::Bool(left.is_truthy() && right.is_truthy())),
            BinaryOpKind::Or => Ok(RuntimeValue::Bool(left.is_truthy() || right.is_truthy())),
            // Phase 53: String concatenation
            BinaryOpKind::Concat => self.apply_concat(left, right),
        }
    }

    fn apply_add(&self, left: RuntimeValue, right: RuntimeValue) -> Result<RuntimeValue, String> {
        match (&left, &right) {
            (RuntimeValue::Int(a), RuntimeValue::Int(b)) => Ok(RuntimeValue::Int(a + b)),
            (RuntimeValue::Float(a), RuntimeValue::Float(b)) => Ok(RuntimeValue::Float(a + b)),
            (RuntimeValue::Int(a), RuntimeValue::Float(b)) => Ok(RuntimeValue::Float(*a as f64 + b)),
            (RuntimeValue::Float(a), RuntimeValue::Int(b)) => Ok(RuntimeValue::Float(a + *b as f64)),
            (RuntimeValue::Text(a), RuntimeValue::Text(b)) => Ok(RuntimeValue::Text(format!("{}{}", a, b))),
            (RuntimeValue::Text(a), other) => Ok(RuntimeValue::Text(format!("{}{}", a, other.to_display_string()))),
            (other, RuntimeValue::Text(b)) => Ok(RuntimeValue::Text(format!("{}{}", other.to_display_string(), b))),
            _ => Err(format!("Cannot add {} and {}", left.type_name(), right.type_name())),
        }
    }

    /// Phase 53: String concatenation ("combined with")
    fn apply_concat(&self, left: RuntimeValue, right: RuntimeValue) -> Result<RuntimeValue, String> {
        Ok(RuntimeValue::Text(format!("{}{}", left.to_display_string(), right.to_display_string())))
    }

    fn apply_subtract(&self, left: RuntimeValue, right: RuntimeValue) -> Result<RuntimeValue, String> {
        match (&left, &right) {
            (RuntimeValue::Int(a), RuntimeValue::Int(b)) => Ok(RuntimeValue::Int(a - b)),
            (RuntimeValue::Float(a), RuntimeValue::Float(b)) => Ok(RuntimeValue::Float(a - b)),
            (RuntimeValue::Int(a), RuntimeValue::Float(b)) => Ok(RuntimeValue::Float(*a as f64 - b)),
            (RuntimeValue::Float(a), RuntimeValue::Int(b)) => Ok(RuntimeValue::Float(a - *b as f64)),
            _ => Err(format!("Cannot subtract {} from {}", right.type_name(), left.type_name())),
        }
    }

    fn apply_multiply(&self, left: RuntimeValue, right: RuntimeValue) -> Result<RuntimeValue, String> {
        match (&left, &right) {
            (RuntimeValue::Int(a), RuntimeValue::Int(b)) => Ok(RuntimeValue::Int(a * b)),
            (RuntimeValue::Float(a), RuntimeValue::Float(b)) => Ok(RuntimeValue::Float(a * b)),
            (RuntimeValue::Int(a), RuntimeValue::Float(b)) => Ok(RuntimeValue::Float(*a as f64 * b)),
            (RuntimeValue::Float(a), RuntimeValue::Int(b)) => Ok(RuntimeValue::Float(a * *b as f64)),
            _ => Err(format!("Cannot multiply {} and {}", left.type_name(), right.type_name())),
        }
    }

    fn apply_divide(&self, left: RuntimeValue, right: RuntimeValue) -> Result<RuntimeValue, String> {
        match (&left, &right) {
            (RuntimeValue::Int(a), RuntimeValue::Int(b)) => {
                if *b == 0 {
                    return Err("Division by zero".to_string());
                }
                Ok(RuntimeValue::Int(a / b))
            }
            (RuntimeValue::Float(a), RuntimeValue::Float(b)) => {
                if *b == 0.0 {
                    return Err("Division by zero".to_string());
                }
                Ok(RuntimeValue::Float(a / b))
            }
            (RuntimeValue::Int(a), RuntimeValue::Float(b)) => {
                if *b == 0.0 {
                    return Err("Division by zero".to_string());
                }
                Ok(RuntimeValue::Float(*a as f64 / b))
            }
            (RuntimeValue::Float(a), RuntimeValue::Int(b)) => {
                if *b == 0 {
                    return Err("Division by zero".to_string());
                }
                Ok(RuntimeValue::Float(a / *b as f64))
            }
            _ => Err(format!("Cannot divide {} by {}", left.type_name(), right.type_name())),
        }
    }

    fn apply_modulo(&self, left: RuntimeValue, right: RuntimeValue) -> Result<RuntimeValue, String> {
        match (&left, &right) {
            (RuntimeValue::Int(a), RuntimeValue::Int(b)) => {
                if *b == 0 {
                    return Err("Modulo by zero".to_string());
                }
                Ok(RuntimeValue::Int(a % b))
            }
            _ => Err(format!("Cannot compute modulo of {} and {}", left.type_name(), right.type_name())),
        }
    }

    fn apply_comparison<F>(&self, left: RuntimeValue, right: RuntimeValue, cmp: F) -> Result<RuntimeValue, String>
    where
        F: Fn(i64, i64) -> bool,
    {
        match (&left, &right) {
            (RuntimeValue::Int(a), RuntimeValue::Int(b)) => Ok(RuntimeValue::Bool(cmp(*a, *b))),
            _ => Err(format!("Cannot compare {} and {}", left.type_name(), right.type_name())),
        }
    }

    fn values_equal(&self, left: &RuntimeValue, right: &RuntimeValue) -> bool {
        match (left, right) {
            (RuntimeValue::Int(a), RuntimeValue::Int(b)) => a == b,
            (RuntimeValue::Float(a), RuntimeValue::Float(b)) => (a - b).abs() < f64::EPSILON,
            (RuntimeValue::Bool(a), RuntimeValue::Bool(b)) => a == b,
            (RuntimeValue::Text(a), RuntimeValue::Text(b)) => a == b,
            (RuntimeValue::Char(a), RuntimeValue::Char(b)) => a == b,
            (RuntimeValue::Nothing, RuntimeValue::Nothing) => true,
            _ => false,
        }
    }

    /// Call a function (built-in or user-defined).
    #[async_recursion(?Send)]
    async fn call_function(&mut self, function: Symbol, args: &[&'async_recursion Expr<'a>]) -> Result<RuntimeValue, String> {
        let func_name = self.interner.resolve(function);

        // Built-in functions
        match func_name {
            "show" => {
                for arg in args {
                    let val = self.evaluate_expr(arg).await?;
                    self.output.push(val.to_display_string());
                }
                return Ok(RuntimeValue::Nothing);
            }
            "length" => {
                if args.len() != 1 {
                    return Err("length() takes exactly 1 argument".to_string());
                }
                let val = self.evaluate_expr(args[0]).await?;
                return match &val {
                    RuntimeValue::List(items) => Ok(RuntimeValue::Int(items.len() as i64)),
                    RuntimeValue::Text(s) => Ok(RuntimeValue::Int(s.len() as i64)),
                    _ => Err(format!("Cannot get length of {}", val.type_name())),
                };
            }
            "format" => {
                if args.is_empty() {
                    return Ok(RuntimeValue::Text(String::new()));
                }
                let val = self.evaluate_expr(args[0]).await?;
                return Ok(RuntimeValue::Text(val.to_display_string()));
            }
            "abs" => {
                if args.len() != 1 {
                    return Err("abs() takes exactly 1 argument".to_string());
                }
                let val = self.evaluate_expr(args[0]).await?;
                return match val {
                    RuntimeValue::Int(n) => Ok(RuntimeValue::Int(n.abs())),
                    RuntimeValue::Float(f) => Ok(RuntimeValue::Float(f.abs())),
                    _ => Err(format!("abs() requires a number, got {}", val.type_name())),
                };
            }
            "min" => {
                if args.len() != 2 {
                    return Err("min() takes exactly 2 arguments".to_string());
                }
                let a = self.evaluate_expr(args[0]).await?;
                let b = self.evaluate_expr(args[1]).await?;
                return match (&a, &b) {
                    (RuntimeValue::Int(x), RuntimeValue::Int(y)) => Ok(RuntimeValue::Int(*x.min(y))),
                    _ => Err("min() requires integers".to_string()),
                };
            }
            "max" => {
                if args.len() != 2 {
                    return Err("max() takes exactly 2 arguments".to_string());
                }
                let a = self.evaluate_expr(args[0]).await?;
                let b = self.evaluate_expr(args[1]).await?;
                return match (&a, &b) {
                    (RuntimeValue::Int(x), RuntimeValue::Int(y)) => Ok(RuntimeValue::Int(*x.max(y))),
                    _ => Err("max() requires integers".to_string()),
                };
            }
            "copy" => {
                if args.len() != 1 {
                    return Err("copy() takes exactly 1 argument".to_string());
                }
                let val = self.evaluate_expr(args[0]).await?;
                return Ok(val.clone());
            }
            _ => {}
        }

        // User-defined function lookup
        // Need to get the function separately to avoid borrow conflicts
        let func_data = self.functions.get(&function)
            .map(|f| (f.params.clone(), f.body))
            .ok_or_else(|| format!("Unknown function: {}", func_name))?;

        let (params, body) = func_data;

        if args.len() != params.len() {
            return Err(format!(
                "Function {} expects {} arguments, got {}",
                func_name,
                params.len(),
                args.len()
            ));
        }

        // Evaluate arguments before pushing scope
        let mut arg_values = Vec::new();
        for arg in args {
            arg_values.push(self.evaluate_expr(arg).await?);
        }

        // Push new scope and bind parameters
        self.push_scope();
        for ((param_name, _), arg_val) in params.iter().zip(arg_values) {
            self.define(*param_name, arg_val);
        }

        // Execute function body
        let mut return_value = RuntimeValue::Nothing;
        for stmt in body.iter() {
            match self.execute_stmt(stmt).await? {
                ControlFlow::Return(val) => {
                    return_value = val;
                    break;
                }
                ControlFlow::Break => break,
                ControlFlow::Continue => {}
            }
        }

        self.pop_scope();
        Ok(return_value)
    }

    // Scope management

    fn push_scope(&mut self) {
        self.env.push(HashMap::new());
    }

    fn pop_scope(&mut self) {
        if self.env.len() > 1 {
            self.env.pop();
        }
    }

    fn define(&mut self, name: Symbol, value: RuntimeValue) {
        if let Some(scope) = self.env.last_mut() {
            scope.insert(name, value);
        }
    }

    fn assign(&mut self, name: Symbol, value: RuntimeValue) -> Result<(), String> {
        // Search from innermost to outermost scope
        for scope in self.env.iter_mut().rev() {
            if scope.contains_key(&name) {
                scope.insert(name, value);
                return Ok(());
            }
        }
        Err(format!("Undefined variable: {}", self.interner.resolve(name)))
    }

    fn lookup(&self, name: Symbol) -> Result<&RuntimeValue, String> {
        // Search from innermost to outermost scope
        for scope in self.env.iter().rev() {
            if let Some(value) = scope.get(&name) {
                return Ok(value);
            }
        }
        Err(format!("Undefined variable: {}", self.interner.resolve(name)))
    }
}

/// Result from interpretation.
#[derive(Debug, Clone)]
pub struct InterpreterResult {
    pub lines: Vec<String>,
    pub error: Option<String>,
}

```

---

### Module: learn_state

**File:** `src/learn_state.rs`

Additional source module.

```rust
//! Tab & Focus State Management for Learn Page
//!
//! Manages the state for the integrated learn page experience:
//! - Tab modes (Lesson, Examples, Practice, Test)
//! - Focus state (which era/module is expanded)
//! - Exercise navigation within modes

/// The four tab modes available for each module
#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
pub enum TabMode {
    #[default]
    Lesson,
    Examples,
    Practice,
    Test,
}

impl TabMode {
    /// Get display label for the tab
    pub fn label(&self) -> &'static str {
        match self {
            TabMode::Lesson => "LESSON",
            TabMode::Examples => "EXAMPLES",
            TabMode::Practice => "PRACTICE",
            TabMode::Test => "TEST",
        }
    }

    /// Get all tab modes in order
    pub fn all() -> [TabMode; 4] {
        [TabMode::Lesson, TabMode::Examples, TabMode::Practice, TabMode::Test]
    }
}

/// State for a single module's tab interface
#[derive(Debug, Clone, Default)]
pub struct ModuleTabState {
    pub module_id: String,
    pub current_tab: TabMode,
    pub exercise_index: usize,
    pub submitted: bool,
}

impl ModuleTabState {
    pub fn new(module_id: &str) -> Self {
        Self {
            module_id: module_id.to_string(),
            current_tab: TabMode::Lesson,
            exercise_index: 0,
            submitted: false,
        }
    }

    /// Switch to a new tab, resetting exercise state
    pub fn switch_tab(&mut self, tab: TabMode) {
        self.current_tab = tab;
        self.exercise_index = 0;
        self.submitted = false;
    }

    /// Reset exercise state without changing tab
    pub fn reset_exercise(&mut self) {
        self.exercise_index = 0;
        self.submitted = false;
    }
}

/// Tracks which era is currently focused (expanded)
#[derive(Debug, Clone, Default)]
pub struct FocusState {
    /// The currently focused era (None = no focus, all eras visible)
    pub focused_era: Option<String>,
    /// The currently expanded module within the focused era
    pub expanded_module: Option<(String, String)>, // (era_id, module_id)
}

impl FocusState {
    pub fn new() -> Self {
        Self::default()
    }

    /// Focus on a specific era
    pub fn focus_era(&mut self, era_id: &str) {
        self.focused_era = Some(era_id.to_string());
    }

    /// Expand a module within an era
    pub fn expand_module(&mut self, era_id: &str, module_id: &str) {
        self.focused_era = Some(era_id.to_string());
        self.expanded_module = Some((era_id.to_string(), module_id.to_string()));
    }

    /// Collapse the current module (but keep era focused)
    pub fn collapse_module(&mut self) {
        self.expanded_module = None;
    }

    /// Unfocus completely (show all eras)
    pub fn unfocus(&mut self) {
        self.focused_era = None;
        self.expanded_module = None;
    }

    /// Check if a specific era is visible (either focused or no focus)
    pub fn is_era_visible(&self, era_id: &str) -> bool {
        match &self.focused_era {
            None => true,
            Some(focused) => focused == era_id,
        }
    }

    /// Check if a specific module is expanded
    pub fn is_module_expanded(&self, era_id: &str, module_id: &str) -> bool {
        match &self.expanded_module {
            None => false,
            Some((e, m)) => e == era_id && m == module_id,
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_tab_modes_all_four_exist() {
        let tabs = TabMode::all();
        assert_eq!(tabs.len(), 4);
        assert_eq!(tabs[0], TabMode::Lesson);
        assert_eq!(tabs[1], TabMode::Examples);
        assert_eq!(tabs[2], TabMode::Practice);
        assert_eq!(tabs[3], TabMode::Test);
    }

    #[test]
    fn test_initial_tab_is_lesson() {
        let state = ModuleTabState::new("test-module");
        assert_eq!(state.current_tab, TabMode::Lesson);
    }

    #[test]
    fn test_tab_switch_resets_exercise_index() {
        let mut state = ModuleTabState::new("test-module");
        state.exercise_index = 5;
        state.submitted = true;

        state.switch_tab(TabMode::Practice);

        assert_eq!(state.current_tab, TabMode::Practice);
        assert_eq!(state.exercise_index, 0);
        assert!(!state.submitted);
    }

    #[test]
    fn test_focus_state_toggles_era() {
        let mut focus = FocusState::new();
        assert!(focus.focused_era.is_none());

        focus.focus_era("first-steps");
        assert_eq!(focus.focused_era, Some("first-steps".to_string()));

        focus.unfocus();
        assert!(focus.focused_era.is_none());
    }

    #[test]
    fn test_is_era_visible_when_focused() {
        let mut focus = FocusState::new();

        // No focus = all eras visible
        assert!(focus.is_era_visible("first-steps"));
        assert!(focus.is_era_visible("mastery"));

        // Focus on one era = only that era visible
        focus.focus_era("first-steps");
        assert!(focus.is_era_visible("first-steps"));
        assert!(!focus.is_era_visible("mastery"));
    }

    #[test]
    fn test_module_expansion() {
        let mut focus = FocusState::new();

        focus.expand_module("first-steps", "introduction");
        assert!(focus.is_module_expanded("first-steps", "introduction"));
        assert!(!focus.is_module_expanded("first-steps", "syllogistic"));

        focus.collapse_module();
        assert!(!focus.is_module_expanded("first-steps", "introduction"));
        // Era should still be focused
        assert!(focus.is_era_visible("first-steps"));
    }
}

```

---

### Module: mwe

**File:** `src/mwe.rs`

Additional source module.

```rust
//! Multi-Word Expression (MWE) processing
//!
//! Post-tokenization pipeline that collapses multi-token sequences
//! into single semantic units (e.g., "fire engine" -> FireEngine).

use std::collections::HashMap;
use crate::token::{Token, TokenType};
use crate::lexicon::{VerbClass, Time, Aspect};
use crate::intern::Interner;

#[derive(Debug, Clone)]
pub struct MweTarget {
    pub lemma: &'static str,
    pub pos: &'static str,
    pub class: Option<VerbClass>,
}

#[derive(Default, Debug)]
pub struct MweTrie {
    pub children: HashMap<String, MweTrie>,
    pub target: Option<MweTarget>,
}

impl MweTrie {
    pub fn insert(&mut self, pattern: &[&str], target: MweTarget) {
        if pattern.is_empty() {
            self.target = Some(target);
            return;
        }
        self.children
            .entry(pattern[0].to_lowercase())
            .or_default()
            .insert(&pattern[1..], target);
    }
}

/// Apply MWE collapsing to a token stream.
/// Matches on lemmas (not raw strings) to handle morphological variants.
pub fn apply_mwe_pipeline(
    tokens: Vec<Token>,
    trie: &MweTrie,
    interner: &mut Interner,
) -> Vec<Token> {
    let mut result = Vec::new();
    let mut i = 0;

    while i < tokens.len() {
        if let Some((match_len, target)) = find_longest_match(&tokens[i..], trie, interner) {
            let merged = create_merged_token(&tokens[i], target, interner);
            result.push(merged);
            i += match_len;
        } else {
            result.push(tokens[i].clone());
            i += 1;
        }
    }
    result
}

/// Extract lemma from a token for MWE matching.
/// Uses lowercase for case-insensitive matching.
fn get_lemma(token: &Token, interner: &Interner) -> String {
    match &token.kind {
        TokenType::Verb { lemma, .. } => interner.resolve(*lemma).to_lowercase(),
        TokenType::Noun(sym) => interner.resolve(*sym).to_lowercase(),
        TokenType::Adjective(sym) => interner.resolve(*sym).to_lowercase(),
        TokenType::NonIntersectiveAdjective(sym) => interner.resolve(*sym).to_lowercase(),
        TokenType::Preposition(sym) => interner.resolve(*sym).to_lowercase(),
        TokenType::Particle(sym) => interner.resolve(*sym).to_lowercase(),
        TokenType::Article(_) => interner.resolve(token.lexeme).to_lowercase(),
        _ => interner.resolve(token.lexeme).to_lowercase(),
    }
}

/// Find the longest MWE match starting at the beginning of the token slice.
fn find_longest_match<'a>(
    tokens: &[Token],
    trie: &'a MweTrie,
    interner: &Interner,
) -> Option<(usize, &'a MweTarget)> {
    let mut node = trie;
    let mut best: Option<(usize, &MweTarget)> = None;

    for (i, token) in tokens.iter().enumerate() {
        let lemma = get_lemma(token, interner);
        if let Some(child) = node.children.get(&lemma) {
            node = child;
            if let Some(target) = &node.target {
                best = Some((i + 1, target));
            }
        } else {
            break;
        }
    }
    best
}

/// Create a merged token from the MWE target, inheriting tense from the head token.
fn create_merged_token(head: &Token, target: &MweTarget, interner: &mut Interner) -> Token {
    let lemma_sym = interner.intern(target.lemma);

    let kind = match target.pos {
        "Noun" => TokenType::Noun(lemma_sym),
        "Verb" => {
            let (time, aspect) = match &head.kind {
                TokenType::Verb { time, aspect, .. } => (*time, *aspect),
                _ => (Time::Present, Aspect::Simple),
            };
            TokenType::Verb {
                lemma: lemma_sym,
                time,
                aspect,
                class: target.class.unwrap_or(VerbClass::Activity),
            }
        }
        "Preposition" => TokenType::Preposition(lemma_sym),
        "Conjunction" => TokenType::And,
        "Quantifier" => TokenType::NoOne,
        _ => TokenType::Noun(lemma_sym),
    };

    Token {
        kind,
        lexeme: lemma_sym,
        span: head.span,
    }
}

include!(concat!(env!("OUT_DIR"), "/mwe_data.rs"));

```

---

### Module: ontology

**File:** `src/ontology.rs`

Additional source module.

```rust
//! Ontology module for bridging anaphora and sort compatibility checking.
//!
//! This module provides:
//! - Part-whole relationship lookup for bridging anaphora resolution
//! - Predicate sort requirements for metaphor detection

use crate::lexicon::Sort;

include!(concat!(env!("OUT_DIR"), "/ontology_data.rs"));

/// Find possible whole objects for a given part noun.
/// Returns None if the noun is not a known part of any whole.
pub fn find_bridging_wholes(part_noun: &str) -> Option<&'static [&'static str]> {
    let wholes = get_possible_wholes(&part_noun.to_lowercase());
    if wholes.is_empty() {
        None
    } else {
        Some(wholes)
    }
}

/// Check if a predicate is compatible with a subject's sort.
/// Returns true if compatible or no sort requirement exists.
pub fn check_sort_compatibility(predicate: &str, subject_sort: Sort) -> bool {
    match get_predicate_sort(&predicate.to_lowercase()) {
        Some(required) => subject_sort.is_compatible_with(required),
        None => true,
    }
}

/// Get the required sort for a predicate, if any.
pub fn required_sort(predicate: &str) -> Option<Sort> {
    get_predicate_sort(&predicate.to_lowercase())
}

```

---

### Module: progress

**File:** `src/progress.rs`

Additional source module.

```rust
use serde::{Deserialize, Serialize};
use std::collections::{HashMap, HashSet};

#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct UserProgress {
    pub xp: u64,
    pub level: u32,
    pub streak_days: u32,
    pub last_session: Option<String>,
    pub exercises: HashMap<String, ExerciseProgress>,
    pub modules: HashMap<String, ModuleProgress>,
    #[serde(default)]
    pub combo: u32,
    #[serde(default)]
    pub best_combo: u32,
    #[serde(default)]
    pub streak_freezes: u8,
    #[serde(default)]
    pub last_streak_date: Option<String>,
    #[serde(default)]
    pub achievements: HashSet<String>,
    #[serde(default)]
    pub title: Option<String>,
    #[serde(default)]
    pub last_weekly_freeze_date: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExerciseProgress {
    pub exercise_id: String,
    pub attempts: u32,
    pub correct_count: u32,
    pub last_attempt: Option<String>,
    pub srs: SrsData,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SrsData {
    pub ease_factor: f64,
    pub interval: u32,
    pub repetitions: u32,
    pub next_review: Option<String>,
}

impl Default for SrsData {
    fn default() -> Self {
        Self {
            ease_factor: 2.5,
            interval: 1,
            repetitions: 0,
            next_review: None,
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModuleProgress {
    pub module_id: String,
    pub unlocked: bool,
    pub completed: bool,
    pub stars: u8,
    pub best_score: u32,
    pub attempts: u32,
}

impl Default for ModuleProgress {
    fn default() -> Self {
        Self {
            module_id: String::new(),
            unlocked: false,
            completed: false,
            stars: 0,
            best_score: 0,
            attempts: 0,
        }
    }
}

impl UserProgress {
    pub fn new() -> Self {
        Self {
            level: 1,
            ..Default::default()
        }
    }

    pub fn load() -> Self {
        #[cfg(target_arch = "wasm32")]
        {
            crate::storage::load_raw()
                .and_then(|json| serde_json::from_str(&json).ok())
                .unwrap_or_else(Self::new)
        }
        #[cfg(not(target_arch = "wasm32"))]
        {
            Self::new()
        }
    }

    pub fn save(&self) {
        #[cfg(target_arch = "wasm32")]
        {
            if let Ok(json) = serde_json::to_string(self) {
                crate::storage::save_raw(&json);
            }
        }
    }

    pub fn add_xp(&mut self, amount: u64) {
        self.xp += amount;
        self.level = calculate_level(self.xp);
        self.save();
    }

    pub fn record_attempt(&mut self, exercise_id: &str, correct: bool) {
        let entry = self.exercises.entry(exercise_id.to_string()).or_insert_with(|| {
            ExerciseProgress {
                exercise_id: exercise_id.to_string(),
                attempts: 0,
                correct_count: 0,
                last_attempt: None,
                srs: SrsData::default(),
            }
        });

        entry.attempts += 1;
        if correct {
            entry.correct_count += 1;
        }

        self.save();
    }

    pub fn get_exercise_progress(&self, exercise_id: &str) -> Option<&ExerciseProgress> {
        self.exercises.get(exercise_id)
    }

    pub fn get_module_progress(&self, module_id: &str) -> Option<&ModuleProgress> {
        self.modules.get(module_id)
    }

    pub fn update_module_score(&mut self, module_id: &str, score: u32) {
        let entry = self.modules.entry(module_id.to_string()).or_insert_with(|| {
            ModuleProgress {
                module_id: module_id.to_string(),
                ..Default::default()
            }
        });

        entry.attempts += 1;
        if score > entry.best_score {
            entry.best_score = score;
        }

        self.save();
    }
}

pub fn calculate_level(xp: u64) -> u32 {
    ((xp as f64).sqrt() / 10.0).floor() as u32 + 1
}

pub fn xp_for_level(level: u32) -> u64 {
    let l = level as u64;
    l * l * 100
}

pub fn calculate_xp_reward(difficulty: u32, first_try: bool, streak_days: u32) -> u64 {
    let base: u64 = 10;
    let difficulty_bonus = (difficulty.saturating_sub(1) as u64) * 5;
    let first_try_bonus = if first_try { 5 } else { 0 };
    let streak_bonus = (streak_days.min(7) as u64) * 2;

    base + difficulty_bonus + first_try_bonus + streak_bonus
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_level_calculation() {
        assert_eq!(calculate_level(0), 1);
        assert_eq!(calculate_level(100), 2);
        assert_eq!(calculate_level(400), 3);
        assert_eq!(calculate_level(900), 4);
    }

    #[test]
    fn test_xp_reward() {
        assert_eq!(calculate_xp_reward(1, false, 0), 10);
        assert_eq!(calculate_xp_reward(1, true, 0), 15);
        assert_eq!(calculate_xp_reward(2, false, 0), 15);
        assert_eq!(calculate_xp_reward(1, false, 3), 16);
        assert_eq!(calculate_xp_reward(3, true, 5), 10 + 10 + 5 + 10);
    }

    #[test]
    fn test_user_progress_record() {
        let mut progress = UserProgress::new();
        progress.record_attempt("test_q1", true);
        progress.record_attempt("test_q1", false);

        let ex = progress.get_exercise_progress("test_q1").unwrap();
        assert_eq!(ex.attempts, 2);
        assert_eq!(ex.correct_count, 1);
    }
}

```

---

### Module: scope

**File:** `src/scope.rs`

Additional source module.

```rust
use std::collections::HashMap;
use crate::context::OwnershipState;

#[derive(Debug, Clone)]
pub struct ScopeEntry {
    pub symbol: String,
    pub ownership: OwnershipState,
}

impl ScopeEntry {
    pub fn variable(name: &str) -> Self {
        Self {
            symbol: name.to_string(),
            ownership: OwnershipState::Owned,
        }
    }
}

#[derive(Debug, Default)]
pub struct ScopeStack {
    scopes: Vec<HashMap<String, ScopeEntry>>,
}

impl ScopeStack {
    pub fn new() -> Self {
        Self::default()
    }

    pub fn push_scope(&mut self) {
        self.scopes.push(HashMap::new());
    }

    pub fn pop_scope(&mut self) {
        self.scopes.pop();
    }

    pub fn bind(&mut self, name: &str, entry: ScopeEntry) {
        if let Some(scope) = self.scopes.last_mut() {
            scope.insert(name.to_string(), entry);
        }
    }

    pub fn lookup(&self, name: &str) -> Option<&ScopeEntry> {
        for scope in self.scopes.iter().rev() {
            if let Some(entry) = scope.get(name) {
                return Some(entry);
            }
        }
        None
    }

    pub fn lookup_mut(&mut self, name: &str) -> Option<&mut ScopeEntry> {
        for scope in self.scopes.iter_mut().rev() {
            if let Some(entry) = scope.get_mut(name) {
                return Some(entry);
            }
        }
        None
    }
}

```

---

### Module: sourcemap

**File:** `src/sourcemap.rs`

Additional source module.

```rust
//! Source Map for Diagnostic Bridge
//!
//! Maps generated Rust code back to LOGOS source positions,
//! enabling friendly error messages for ownership/lifetime errors.

use crate::intern::Symbol;
use crate::token::Span;
use std::collections::HashMap;

/// Semantic role of a variable in LOGOS ownership semantics.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum OwnershipRole {
    /// The object being moved in "Give X to Y"
    GiveObject,
    /// The recipient in "Give X to Y"
    GiveRecipient,
    /// The object being borrowed in "Show X to Y"
    ShowObject,
    /// The recipient in "Show X to Y"
    ShowRecipient,
    /// A Let-bound variable
    LetBinding,
    /// Target of a Set statement
    SetTarget,
    /// Variable allocated inside a Zone
    ZoneLocal,
}

/// Variable origin tracking for error translation.
#[derive(Debug, Clone)]
pub struct VarOrigin {
    pub logos_name: Symbol,
    pub span: Span,
    pub role: OwnershipRole,
}

/// Maps generated Rust code back to LOGOS source.
#[derive(Debug, Clone, Default)]
pub struct SourceMap {
    /// Maps line in generated Rust -> Span in LOGOS source
    line_to_span: HashMap<u32, Span>,

    /// Maps generated Rust variable names -> LOGOS origin info
    var_origins: HashMap<String, VarOrigin>,

    /// The original LOGOS source code (for error display)
    logos_source: String,
}

impl SourceMap {
    /// Create a new empty source map.
    pub fn new(logos_source: String) -> Self {
        Self {
            line_to_span: HashMap::new(),
            var_origins: HashMap::new(),
            logos_source,
        }
    }

    /// Get the LOGOS span for a given Rust line number.
    pub fn get_span_for_line(&self, line: u32) -> Option<Span> {
        self.line_to_span.get(&line).copied()
    }

    /// Get the origin info for a Rust variable name.
    pub fn get_var_origin(&self, rust_var: &str) -> Option<&VarOrigin> {
        self.var_origins.get(rust_var)
    }

    /// Get the original LOGOS source.
    pub fn logos_source(&self) -> &str {
        &self.logos_source
    }

    /// Find the closest LOGOS span by searching nearby lines.
    pub fn find_nearest_span(&self, rust_line: u32) -> Option<Span> {
        // Try exact match first
        if let Some(span) = self.line_to_span.get(&rust_line) {
            return Some(*span);
        }

        // Search nearby lines (within 5 lines)
        for offset in 1..=5 {
            if rust_line > offset {
                if let Some(span) = self.line_to_span.get(&(rust_line - offset)) {
                    return Some(*span);
                }
            }
            if let Some(span) = self.line_to_span.get(&(rust_line + offset)) {
                return Some(*span);
            }
        }

        None
    }
}

/// Builder for constructing a SourceMap during code generation.
#[derive(Debug)]
pub struct SourceMapBuilder {
    current_line: u32,
    map: SourceMap,
}

impl SourceMapBuilder {
    /// Create a new builder with the LOGOS source.
    pub fn new(logos_source: &str) -> Self {
        Self {
            current_line: 1,
            map: SourceMap::new(logos_source.to_string()),
        }
    }

    /// Record a mapping from current Rust line to LOGOS span.
    pub fn record_line(&mut self, logos_span: Span) {
        self.map.line_to_span.insert(self.current_line, logos_span);
    }

    /// Record a variable origin.
    pub fn record_var(&mut self, rust_name: &str, logos_name: Symbol, span: Span, role: OwnershipRole) {
        self.map.var_origins.insert(
            rust_name.to_string(),
            VarOrigin {
                logos_name,
                span,
                role,
            },
        );
    }

    /// Advance to the next line.
    pub fn newline(&mut self) {
        self.current_line += 1;
    }

    /// Add multiple newlines.
    pub fn add_lines(&mut self, count: u32) {
        self.current_line += count;
    }

    /// Get current line number.
    pub fn current_line(&self) -> u32 {
        self.current_line
    }

    /// Build the final source map.
    pub fn build(self) -> SourceMap {
        self.map
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn source_map_stores_line_mappings() {
        let mut map = SourceMap::new("Let x be 5.".to_string());
        map.line_to_span.insert(1, Span::new(0, 11));

        assert_eq!(map.get_span_for_line(1), Some(Span::new(0, 11)));
        assert_eq!(map.get_span_for_line(2), None);
    }

    #[test]
    fn source_map_builder_tracks_lines() {
        let mut builder = SourceMapBuilder::new("test source");
        assert_eq!(builder.current_line(), 1);

        builder.newline();
        assert_eq!(builder.current_line(), 2);

        builder.add_lines(3);
        assert_eq!(builder.current_line(), 5);
    }

    #[test]
    fn source_map_builder_records_spans() {
        let mut builder = SourceMapBuilder::new("Let x be 5.\nLet y be 10.");
        builder.record_line(Span::new(0, 11));
        builder.newline();
        builder.record_line(Span::new(12, 24));

        let map = builder.build();
        assert_eq!(map.get_span_for_line(1), Some(Span::new(0, 11)));
        assert_eq!(map.get_span_for_line(2), Some(Span::new(12, 24)));
    }

    #[test]
    fn find_nearest_span_searches_nearby() {
        let mut builder = SourceMapBuilder::new("source");
        builder.record_line(Span::new(0, 10));
        builder.add_lines(5);
        // Line 1 has span, lines 2-6 don't

        let map = builder.build();
        // Line 3 should find line 1's span
        assert_eq!(map.find_nearest_span(3), Some(Span::new(0, 10)));
    }
}

```

---

### Module: srs

**File:** `src/srs.rs`

Additional source module.

```rust
use crate::progress::SrsData;

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum ResponseQuality {
    Blackout = 0,
    Incorrect = 1,
    IncorrectEasy = 2,
    CorrectDifficult = 3,
    CorrectHesitation = 4,
    Perfect = 5,
}

impl ResponseQuality {
    pub fn from_score(score: u8) -> Self {
        match score {
            0 => Self::Blackout,
            1 => Self::Incorrect,
            2 => Self::IncorrectEasy,
            3 => Self::CorrectDifficult,
            4 => Self::CorrectHesitation,
            _ => Self::Perfect,
        }
    }

    pub fn is_correct(self) -> bool {
        (self as u8) >= 3
    }
}

pub fn sm2_update(srs: &mut SrsData, quality: ResponseQuality) {
    let q = quality as u8 as f64;

    if quality.is_correct() {
        srs.repetitions += 1;
        srs.interval = match srs.repetitions {
            1 => 1,
            2 => 6,
            _ => (srs.interval as f64 * srs.ease_factor).round() as u32,
        };

        srs.ease_factor += 0.1 - (5.0 - q) * (0.08 + (5.0 - q) * 0.02);
        if srs.ease_factor < 1.3 {
            srs.ease_factor = 1.3;
        }
    } else {
        srs.repetitions = 0;
        srs.interval = 1;
    }
}

pub fn calculate_next_review(current_date: &str, interval_days: u32) -> String {
    if let Ok(date) = parse_date(current_date) {
        let next = date + interval_days as i64;
        format_date(next)
    } else {
        current_date.to_string()
    }
}

pub fn is_due(next_review: Option<&str>, today: &str) -> bool {
    match next_review {
        None => true,
        Some(review_date) => {
            if let (Ok(review), Ok(now)) = (parse_date(review_date), parse_date(today)) {
                review <= now
            } else {
                true
            }
        }
    }
}

fn parse_date(date_str: &str) -> Result<i64, ()> {
    let parts: Vec<&str> = date_str.split('-').collect();
    if parts.len() != 3 {
        return Err(());
    }

    let year: i64 = parts[0].parse().map_err(|_| ())?;
    let month: i64 = parts[1].parse().map_err(|_| ())?;
    let day: i64 = parts[2].parse().map_err(|_| ())?;

    Ok(year * 10000 + month * 100 + day)
}

fn format_date(date_num: i64) -> String {
    let year = date_num / 10000;
    let month = (date_num % 10000) / 100;
    let day = date_num % 100;

    let (year, month, day) = normalize_date(year as i32, month as i32, day as i32);
    format!("{:04}-{:02}-{:02}", year, month, day)
}

fn normalize_date(year: i32, month: i32, day: i32) -> (i32, i32, i32) {
    let days_in_month = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31];

    let mut y = year;
    let mut m = month;
    let mut d = day;

    while d > days_in_month[(m - 1) as usize] {
        d -= days_in_month[(m - 1) as usize];
        m += 1;
        if m > 12 {
            m = 1;
            y += 1;
        }
    }

    (y, m, d)
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_sm2_first_correct() {
        let mut srs = SrsData::default();
        sm2_update(&mut srs, ResponseQuality::Perfect);

        assert_eq!(srs.repetitions, 1);
        assert_eq!(srs.interval, 1);
        assert!(srs.ease_factor > 2.5);
    }

    #[test]
    fn test_sm2_second_correct() {
        let mut srs = SrsData::default();
        sm2_update(&mut srs, ResponseQuality::Perfect);
        sm2_update(&mut srs, ResponseQuality::Perfect);

        assert_eq!(srs.repetitions, 2);
        assert_eq!(srs.interval, 6);
    }

    #[test]
    fn test_sm2_incorrect_resets() {
        let mut srs = SrsData::default();
        sm2_update(&mut srs, ResponseQuality::Perfect);
        sm2_update(&mut srs, ResponseQuality::Perfect);
        sm2_update(&mut srs, ResponseQuality::Incorrect);

        assert_eq!(srs.repetitions, 0);
        assert_eq!(srs.interval, 1);
    }

    #[test]
    fn test_sm2_ease_factor_minimum() {
        let mut srs = SrsData::default();
        srs.ease_factor = 1.3;
        sm2_update(&mut srs, ResponseQuality::CorrectDifficult);

        assert!(srs.ease_factor >= 1.3);
    }

    #[test]
    fn test_is_due_none() {
        assert!(is_due(None, "2025-01-01"));
    }

    #[test]
    fn test_is_due_past() {
        assert!(is_due(Some("2025-01-01"), "2025-01-02"));
    }

    #[test]
    fn test_is_due_future() {
        assert!(!is_due(Some("2025-01-05"), "2025-01-02"));
    }

    #[test]
    fn test_is_due_today() {
        assert!(is_due(Some("2025-01-01"), "2025-01-01"));
    }

    #[test]
    fn test_calculate_next_review() {
        let next = calculate_next_review("2025-01-15", 6);
        assert_eq!(next, "2025-01-21");
    }

    #[test]
    fn test_calculate_next_review_month_overflow() {
        let next = calculate_next_review("2025-01-28", 6);
        assert_eq!(next, "2025-02-03");
    }

    #[test]
    fn test_response_quality_is_correct() {
        assert!(!ResponseQuality::Blackout.is_correct());
        assert!(!ResponseQuality::Incorrect.is_correct());
        assert!(!ResponseQuality::IncorrectEasy.is_correct());
        assert!(ResponseQuality::CorrectDifficult.is_correct());
        assert!(ResponseQuality::CorrectHesitation.is_correct());
        assert!(ResponseQuality::Perfect.is_correct());
    }
}

```

---

### Module: storage

**File:** `src/storage.rs`

Additional source module.

```rust
use wasm_bindgen::prelude::*;

const PROGRESS_KEY: &str = "logos_user_progress";

#[wasm_bindgen]
extern "C" {
    #[wasm_bindgen(js_namespace = localStorage, js_name = getItem)]
    fn local_storage_get(key: &str) -> Option<String>;

    #[wasm_bindgen(js_namespace = localStorage, js_name = setItem)]
    fn local_storage_set(key: &str, value: &str);

    #[wasm_bindgen(js_namespace = localStorage, js_name = removeItem)]
    fn local_storage_remove(key: &str);
}

pub fn load_raw() -> Option<String> {
    local_storage_get(PROGRESS_KEY)
}

pub fn save_raw(json: &str) {
    local_storage_set(PROGRESS_KEY, json);
}

pub fn clear() {
    local_storage_remove(PROGRESS_KEY);
}

```

---

### Module: struggle

**File:** `src/struggle.rs`

Additional source module.

```rust
//! Struggle Detection Logic
//!
//! Detects when a user is struggling with an exercise based on:
//! - Inactivity (no answer attempt after threshold time)
//! - Wrong attempts (incorrect answers)

/// Reasons why a user might be struggling
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum StruggleReason {
    Inactivity,
    WrongAttempt,
}

impl StruggleReason {
    /// Get a message describing the struggle reason
    pub fn message(&self) -> &'static str {
        match self {
            StruggleReason::Inactivity => "Taking your time? Here's a hint to help you along.",
            StruggleReason::WrongAttempt => "Not quite! Let me help you think through this.",
        }
    }
}

/// Configuration for struggle detection
#[derive(Debug, Clone, Copy)]
pub struct StruggleConfig {
    /// Seconds of inactivity before considering the user stuck
    pub inactivity_threshold_secs: u64,
    /// Number of wrong attempts before showing help
    pub wrong_attempt_threshold: u32,
}

impl Default for StruggleConfig {
    fn default() -> Self {
        Self {
            inactivity_threshold_secs: 5,
            wrong_attempt_threshold: 1,
        }
    }
}

/// Tracks struggle state for an exercise
#[derive(Debug, Clone, Default)]
pub struct StruggleDetector {
    pub config: StruggleConfig,
    pub is_struggling: bool,
    pub reason: Option<StruggleReason>,
    pub wrong_attempts: u32,
    pub inactivity_triggered: bool,
}

impl StruggleDetector {
    pub fn new() -> Self {
        Self::default()
    }

    pub fn with_config(config: StruggleConfig) -> Self {
        Self {
            config,
            ..Default::default()
        }
    }

    /// Record a wrong attempt - may trigger struggle state
    pub fn record_wrong_attempt(&mut self) {
        self.wrong_attempts += 1;
        if self.wrong_attempts >= self.config.wrong_attempt_threshold {
            self.is_struggling = true;
            self.reason = Some(StruggleReason::WrongAttempt);
        }
    }

    /// Record a correct attempt - resets inactivity but keeps struggle state for hints
    pub fn record_correct_attempt(&mut self) {
        // User got it right - they're no longer struggling
        self.is_struggling = false;
        self.inactivity_triggered = false;
    }

    /// Record user activity (typing, clicking) - resets inactivity timer
    pub fn record_activity(&mut self) {
        // Activity resets inactivity detection
        self.inactivity_triggered = false;
    }

    /// Called when inactivity threshold is reached
    pub fn trigger_inactivity(&mut self) {
        if !self.inactivity_triggered {
            self.inactivity_triggered = true;
            self.is_struggling = true;
            // Only set reason if not already struggling from wrong attempts
            if self.reason.is_none() {
                self.reason = Some(StruggleReason::Inactivity);
            }
        }
    }

    /// Reset struggle state (e.g., when moving to next exercise)
    pub fn reset(&mut self) {
        self.is_struggling = false;
        self.reason = None;
        self.wrong_attempts = 0;
        self.inactivity_triggered = false;
    }

    /// Check if we should show hints
    pub fn should_show_hints(&self) -> bool {
        self.is_struggling
    }

    /// Get the current struggle reason
    pub fn reason(&self) -> Option<StruggleReason> {
        self.reason
    }

    /// Get the current struggle reason for display
    pub fn struggle_message(&self) -> Option<&'static str> {
        match self.reason {
            Some(StruggleReason::Inactivity) => Some("Taking your time? Here's a hint to help you along."),
            Some(StruggleReason::WrongAttempt) => Some("Not quite! Let me help you think through this."),
            None => None,
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_no_struggle_initially() {
        let detector = StruggleDetector::new();
        assert!(!detector.is_struggling);
        assert!(detector.reason.is_none());
    }

    #[test]
    fn test_struggle_after_5s_inactivity() {
        let mut detector = StruggleDetector::new();
        assert!(!detector.is_struggling);

        detector.trigger_inactivity();

        assert!(detector.is_struggling);
        assert_eq!(detector.reason, Some(StruggleReason::Inactivity));
    }

    #[test]
    fn test_struggle_after_wrong_attempt() {
        let mut detector = StruggleDetector::new();
        assert!(!detector.is_struggling);

        detector.record_wrong_attempt();

        assert!(detector.is_struggling);
        assert_eq!(detector.reason, Some(StruggleReason::WrongAttempt));
    }

    #[test]
    fn test_reset_clears_struggle() {
        let mut detector = StruggleDetector::new();
        detector.record_wrong_attempt();
        assert!(detector.is_struggling);

        detector.reset();

        assert!(!detector.is_struggling);
        assert!(detector.reason.is_none());
        assert_eq!(detector.wrong_attempts, 0);
    }

    #[test]
    fn test_configurable_threshold() {
        let config = StruggleConfig {
            inactivity_threshold_secs: 10,
            wrong_attempt_threshold: 2,
        };
        let mut detector = StruggleDetector::with_config(config);

        // First wrong attempt shouldn't trigger with threshold of 2
        detector.record_wrong_attempt();
        assert!(!detector.is_struggling);

        // Second wrong attempt should trigger
        detector.record_wrong_attempt();
        assert!(detector.is_struggling);
    }

    #[test]
    fn test_inactivity_only_triggers_once() {
        let mut detector = StruggleDetector::new();

        detector.trigger_inactivity();
        assert!(detector.inactivity_triggered);

        // Triggering again shouldn't change the reason
        detector.reason = None;
        detector.trigger_inactivity();
        assert!(detector.reason.is_none()); // Didn't set it again
    }

    #[test]
    fn test_should_show_hints() {
        let mut detector = StruggleDetector::new();
        assert!(!detector.should_show_hints());

        detector.record_wrong_attempt();
        assert!(detector.should_show_hints());
    }

    #[test]
    fn test_struggle_message() {
        let mut detector = StruggleDetector::new();
        assert!(detector.struggle_message().is_none());

        detector.trigger_inactivity();
        assert!(detector.struggle_message().is_some());
        assert!(detector.struggle_message().unwrap().contains("hint"));
    }
}

```

---

### Module: symbol_dict

**File:** `src/symbol_dict.rs`

Additional source module.

```rust
//! Symbol Dictionary Extraction
//!
//! Extracts logical symbols from FOL strings for display in a symbol dictionary.
//! Groups symbols by kind and provides descriptions.

use std::collections::HashSet;

/// Categories of logical symbols
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum SymbolKind {
    Quantifier,
    Connective,
    Variable,
    Predicate,
    Constant,
    Modal,
    Identity,
    Punctuation,
    Temporal,
}

impl SymbolKind {
    pub fn label(&self) -> &'static str {
        match self {
            SymbolKind::Quantifier => "Quantifier",
            SymbolKind::Connective => "Connective",
            SymbolKind::Variable => "Variable",
            SymbolKind::Predicate => "Predicate",
            SymbolKind::Constant => "Constant",
            SymbolKind::Modal => "Modal",
            SymbolKind::Identity => "Identity",
            SymbolKind::Punctuation => "Punctuation",
            SymbolKind::Temporal => "Temporal",
        }
    }
}

/// A single symbol entry in the dictionary
#[derive(Debug, Clone, PartialEq, Eq, Hash)]
pub struct SymbolEntry {
    pub symbol: String,
    pub kind: SymbolKind,
    pub description: String,
}

/// Extract symbols from a FOL logic string
pub fn extract_symbols(logic: &str) -> Vec<SymbolEntry> {
    let mut entries = Vec::new();
    let mut seen: HashSet<String> = HashSet::new();

    // Quantifiers
    if logic.contains("∀") && seen.insert("∀".to_string()) {
        entries.push(SymbolEntry {
            symbol: "∀".to_string(),
            kind: SymbolKind::Quantifier,
            description: "Universal quantifier: \"for all\"".to_string(),
        });
    }
    if logic.contains("∃") && seen.insert("∃".to_string()) {
        entries.push(SymbolEntry {
            symbol: "∃".to_string(),
            kind: SymbolKind::Quantifier,
            description: "Existential quantifier: \"there exists\"".to_string(),
        });
    }
    if logic.contains("∃!") && seen.insert("∃!".to_string()) {
        entries.push(SymbolEntry {
            symbol: "∃!".to_string(),
            kind: SymbolKind::Quantifier,
            description: "Unique existence: \"there exists exactly one\"".to_string(),
        });
    }
    if logic.contains("MOST") && seen.insert("MOST".to_string()) {
        entries.push(SymbolEntry {
            symbol: "MOST".to_string(),
            kind: SymbolKind::Quantifier,
            description: "Generalized quantifier: \"most\"".to_string(),
        });
    }
    if logic.contains("FEW") && seen.insert("FEW".to_string()) {
        entries.push(SymbolEntry {
            symbol: "FEW".to_string(),
            kind: SymbolKind::Quantifier,
            description: "Generalized quantifier: \"few\"".to_string(),
        });
    }

    // Connectives
    if logic.contains("∧") && seen.insert("∧".to_string()) {
        entries.push(SymbolEntry {
            symbol: "∧".to_string(),
            kind: SymbolKind::Connective,
            description: "Conjunction: \"and\"".to_string(),
        });
    }
    if logic.contains("∨") && seen.insert("∨".to_string()) {
        entries.push(SymbolEntry {
            symbol: "∨".to_string(),
            kind: SymbolKind::Connective,
            description: "Disjunction: \"or\"".to_string(),
        });
    }
    if logic.contains("→") && seen.insert("→".to_string()) {
        entries.push(SymbolEntry {
            symbol: "→".to_string(),
            kind: SymbolKind::Connective,
            description: "Implication: \"if...then\"".to_string(),
        });
    }
    if logic.contains("↔") && seen.insert("↔".to_string()) {
        entries.push(SymbolEntry {
            symbol: "↔".to_string(),
            kind: SymbolKind::Connective,
            description: "Biconditional: \"if and only if\"".to_string(),
        });
    }
    if logic.contains("¬") && seen.insert("¬".to_string()) {
        entries.push(SymbolEntry {
            symbol: "¬".to_string(),
            kind: SymbolKind::Connective,
            description: "Negation: \"not\"".to_string(),
        });
    }

    // Modal operators
    if logic.contains("□") && seen.insert("□".to_string()) {
        entries.push(SymbolEntry {
            symbol: "□".to_string(),
            kind: SymbolKind::Modal,
            description: "Necessity: \"it is necessary that\"".to_string(),
        });
    }
    if logic.contains("◇") && seen.insert("◇".to_string()) {
        entries.push(SymbolEntry {
            symbol: "◇".to_string(),
            kind: SymbolKind::Modal,
            description: "Possibility: \"it is possible that\"".to_string(),
        });
    }
    if logic.contains("O_") && seen.insert("O".to_string()) {
        entries.push(SymbolEntry {
            symbol: "O".to_string(),
            kind: SymbolKind::Modal,
            description: "Deontic obligation: \"it ought to be that\"".to_string(),
        });
    }

    // Identity
    if logic.contains(" = ") && seen.insert("=".to_string()) {
        entries.push(SymbolEntry {
            symbol: "=".to_string(),
            kind: SymbolKind::Identity,
            description: "Identity: \"is identical to\"".to_string(),
        });
    }

    // Extract predicates (uppercase letters followed by parenthesis)
    extract_predicates(logic, &mut entries, &mut seen);

    // Extract variables (lowercase x, y, z, etc.)
    extract_variables(logic, &mut entries, &mut seen);

    // Extract constants (uppercase single letters not followed by parenthesis)
    extract_constants(logic, &mut entries, &mut seen);

    entries
}

fn extract_predicates(logic: &str, entries: &mut Vec<SymbolEntry>, seen: &mut HashSet<String>) {
    // Match patterns like "Dog(", "Mortal(", "Loves("
    let chars: Vec<char> = logic.chars().collect();
    let mut i = 0;

    while i < chars.len() {
        if chars[i].is_ascii_uppercase() {
            let start = i;
            while i < chars.len() && (chars[i].is_ascii_alphanumeric() || chars[i] == '_') {
                i += 1;
            }
            if i < chars.len() && chars[i] == '(' {
                let predicate: String = chars[start..i].iter().collect();
                if seen.insert(format!("pred_{}", predicate)) {
                    entries.push(SymbolEntry {
                        symbol: predicate.clone(),
                        kind: SymbolKind::Predicate,
                        description: format!("Predicate: {}", predicate),
                    });
                }
            }
        }
        i += 1;
    }
}

fn extract_variables(logic: &str, entries: &mut Vec<SymbolEntry>, seen: &mut HashSet<String>) {
    // Variables are lowercase letters typically x, y, z, w
    for var in ['x', 'y', 'z', 'w', 'e'] {
        let var_str = var.to_string();
        // Check if variable appears in context (not as part of a word)
        if logic.contains(&format!("({})", var))
            || logic.contains(&format!("({},", var))
            || logic.contains(&format!(", {})", var))
            || logic.contains(&format!("{}.", var))
            || logic.contains(&format!(" {}", var))
        {
            if seen.insert(format!("var_{}", var)) {
                entries.push(SymbolEntry {
                    symbol: var_str,
                    kind: SymbolKind::Variable,
                    description: "Bound variable".to_string(),
                });
            }
        }
    }
}

fn extract_constants(logic: &str, entries: &mut Vec<SymbolEntry>, seen: &mut HashSet<String>) {
    // Constants are uppercase letters like J (John), M (Mary), etc.
    // But not predicates (followed by parenthesis)
    let chars: Vec<char> = logic.chars().collect();
    let mut i = 0;

    while i < chars.len() {
        if chars[i].is_ascii_uppercase() {
            let start = i;
            // Collect the full name (may have numbers like J2)
            while i < chars.len() && (chars[i].is_ascii_alphanumeric()) {
                i += 1;
            }
            // Check if NOT followed by parenthesis (would be predicate)
            if i >= chars.len() || chars[i] != '(' {
                let constant: String = chars[start..i].iter().collect();
                // Skip very long names (likely predicates) and known quantifiers
                if constant.len() <= 3
                    && !["MOST", "FEW", "ALL", "THE"].contains(&constant.as_str())
                    && seen.insert(format!("const_{}", constant))
                {
                    entries.push(SymbolEntry {
                        symbol: constant.clone(),
                        kind: SymbolKind::Constant,
                        description: format!("Constant: {}", constant),
                    });
                }
            }
        }
        i += 1;
    }
}

/// Get symbols grouped by kind for display
pub fn group_symbols_by_kind(entries: &[SymbolEntry]) -> Vec<(SymbolKind, Vec<&SymbolEntry>)> {
    let kinds = [
        SymbolKind::Quantifier,
        SymbolKind::Connective,
        SymbolKind::Modal,
        SymbolKind::Identity,
        SymbolKind::Predicate,
        SymbolKind::Variable,
        SymbolKind::Constant,
    ];

    kinds
        .iter()
        .filter_map(|&kind| {
            let matching: Vec<_> = entries.iter().filter(|e| e.kind == kind).collect();
            if matching.is_empty() {
                None
            } else {
                Some((kind, matching))
            }
        })
        .collect()
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_extract_quantifier_symbols() {
        let logic = "∀x(Dog(x) → Mortal(x))";
        let symbols = extract_symbols(logic);

        let quantifiers: Vec<_> = symbols.iter().filter(|s| s.kind == SymbolKind::Quantifier).collect();
        assert!(quantifiers.iter().any(|s| s.symbol == "∀"), "Should find universal quantifier");
    }

    #[test]
    fn test_extract_existential() {
        let logic = "∃x(Cat(x) ∧ Black(x))";
        let symbols = extract_symbols(logic);

        assert!(symbols.iter().any(|s| s.symbol == "∃"), "Should find existential quantifier");
    }

    #[test]
    fn test_extract_connective_symbols() {
        let logic = "∀x(Dog(x) → (Loyal(x) ∧ Friendly(x)))";
        let symbols = extract_symbols(logic);

        let connectives: Vec<_> = symbols.iter().filter(|s| s.kind == SymbolKind::Connective).collect();
        assert!(connectives.iter().any(|s| s.symbol == "∧"), "Should find conjunction");
        assert!(connectives.iter().any(|s| s.symbol == "→"), "Should find implication");
    }

    #[test]
    fn test_extract_predicate_names() {
        let logic = "∀x(Dog(x) → Mammal(x))";
        let symbols = extract_symbols(logic);

        let predicates: Vec<_> = symbols.iter().filter(|s| s.kind == SymbolKind::Predicate).collect();
        assert!(predicates.iter().any(|s| s.symbol == "Dog"), "Should find Dog predicate");
        assert!(predicates.iter().any(|s| s.symbol == "Mammal"), "Should find Mammal predicate");
    }

    #[test]
    fn test_extract_variable_names() {
        let logic = "∀x∃y(Loves(x, y))";
        let symbols = extract_symbols(logic);

        let variables: Vec<_> = symbols.iter().filter(|s| s.kind == SymbolKind::Variable).collect();
        assert!(variables.iter().any(|s| s.symbol == "x"), "Should find variable x");
        assert!(variables.iter().any(|s| s.symbol == "y"), "Should find variable y");
    }

    #[test]
    fn test_no_duplicate_symbols() {
        let logic = "∀x(Dog(x) → Dog(x))";
        let symbols = extract_symbols(logic);

        let dog_count = symbols.iter().filter(|s| s.symbol == "Dog").count();
        assert_eq!(dog_count, 1, "Should not have duplicate predicates");
    }

    #[test]
    fn test_symbol_has_description() {
        let logic = "∀x(P(x))";
        let symbols = extract_symbols(logic);

        for symbol in &symbols {
            assert!(!symbol.description.is_empty(), "Every symbol should have a description");
        }
    }

    #[test]
    fn test_modal_symbols() {
        let logic = "□(P(x)) ∧ ◇(Q(y))";
        let symbols = extract_symbols(logic);

        assert!(symbols.iter().any(|s| s.symbol == "□"), "Should find necessity operator");
        assert!(symbols.iter().any(|s| s.symbol == "◇"), "Should find possibility operator");
    }

    #[test]
    fn test_group_symbols_by_kind() {
        let logic = "∀x(Dog(x) → ∃y(Loves(x, y)))";
        let symbols = extract_symbols(logic);
        let grouped = group_symbols_by_kind(&symbols);

        // Should have multiple groups
        assert!(!grouped.is_empty(), "Should have grouped symbols");

        // Check quantifiers group exists
        assert!(grouped.iter().any(|(k, _)| *k == SymbolKind::Quantifier), "Should have quantifier group");
    }
}

```

---

### Module: unlock

**File:** `src/unlock.rs`

Additional source module.

```rust
//! Module Unlock Logic
//!
//! Rules:
//! - First module in each era is always unlocked
//! - Subsequent modules unlock when the previous module is completed
//! - Last two modules in each era are locked until at least one module has 100% completion

use crate::content::ContentEngine;
use crate::progress::UserProgress;

/// State of a module for the user
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum ModuleState {
    /// Module is locked and cannot be accessed
    Locked,
    /// Module is unlocked but not started
    Available,
    /// Module has been started (score < 50%)
    Started,
    /// Module is in progress (50-89% score)
    Progressing,
    /// Module has been completed but not perfected (90%+ score)
    Completed,
    /// Module has been perfected (100% or 3 stars)
    Perfected,
}

/// Get the current state of a module for the user
pub fn get_module_state(
    progress: &UserProgress,
    engine: &ContentEngine,
    era_id: &str,
    module_id: &str,
) -> ModuleState {
    // Check if locked
    if !check_module_unlocked(progress, engine, era_id, module_id) {
        return ModuleState::Locked;
    }

    // Check progress
    match progress.modules.get(module_id) {
        None => ModuleState::Available,
        Some(mp) => {
            if mp.completed && (mp.best_score >= 90 || mp.stars >= 3) {
                ModuleState::Perfected
            } else if mp.completed {
                ModuleState::Completed
            } else if mp.best_score >= 50 {
                ModuleState::Progressing
            } else if mp.attempts > 0 || mp.best_score > 0 {
                ModuleState::Started
            } else {
                ModuleState::Available
            }
        }
    }
}

/// Check if a specific module is unlocked for the user
pub fn check_module_unlocked(
    progress: &UserProgress,
    engine: &ContentEngine,
    era_id: &str,
    module_id: &str,
) -> bool {
    let Some(era) = engine.get_era(era_id) else {
        return false;
    };

    let module_ids: Vec<&str> = era.modules.iter().map(|m| m.meta.id.as_str()).collect();
    let Some(module_index) = module_ids.iter().position(|&id| id == module_id) else {
        return false;
    };

    let total_modules = module_ids.len();

    // First module is always unlocked
    if module_index == 0 {
        return true;
    }

    // Check if this is one of the last two modules
    let is_final_module = total_modules >= 2 && module_index >= total_modules - 2;

    if is_final_module {
        // Last two modules require at least one module to be 100% complete
        let has_perfect_completion = module_ids.iter().take(total_modules.saturating_sub(2)).any(|&mid| {
            progress.modules.get(mid).map_or(false, |mp| mp.completed && mp.best_score >= 100)
        });

        if !has_perfect_completion {
            return false;
        }
    }

    // Check if previous module is completed
    let prev_module_id = module_ids[module_index - 1];
    progress.modules.get(prev_module_id).map_or(false, |mp| mp.completed)
}

/// Get list of locked module IDs for an era
pub fn get_locked_module_ids(
    progress: &UserProgress,
    engine: &ContentEngine,
    era_id: &str,
) -> Vec<String> {
    let Some(era) = engine.get_era(era_id) else {
        return Vec::new();
    };

    era.modules
        .iter()
        .filter(|m| !check_module_unlocked(progress, engine, era_id, &m.meta.id))
        .map(|m| m.meta.id.clone())
        .collect()
}

/// Check if any module in the era has 100% completion
pub fn has_perfect_module(progress: &UserProgress, engine: &ContentEngine, era_id: &str) -> bool {
    let Some(era) = engine.get_era(era_id) else {
        return false;
    };

    era.modules.iter().any(|m| {
        progress.modules.get(&m.meta.id).map_or(false, |mp| mp.completed && mp.best_score >= 100)
    })
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::progress::ModuleProgress;

    fn make_progress_with_completed(completed_modules: &[(&str, bool, u32)]) -> UserProgress {
        let mut progress = UserProgress::new();
        for (id, completed, score) in completed_modules {
            progress.modules.insert(id.to_string(), ModuleProgress {
                module_id: id.to_string(),
                unlocked: true,
                completed: *completed,
                stars: 0,
                best_score: *score,
                attempts: 1,
            });
        }
        progress
    }

    #[test]
    fn test_first_module_always_unlocked() {
        let progress = UserProgress::new();
        let engine = ContentEngine::new();

        // First module of first era should always be unlocked
        if let Some(era) = engine.eras().first() {
            if let Some(module) = era.modules.first() {
                assert!(check_module_unlocked(&progress, &engine, &era.meta.id, &module.meta.id));
            }
        }
    }

    #[test]
    fn test_module_locked_until_previous_complete() {
        let engine = ContentEngine::new();

        if let Some(era) = engine.eras().first() {
            if era.modules.len() >= 2 {
                let first_id = &era.modules[0].meta.id;
                let second_id = &era.modules[1].meta.id;

                // Without completing first module, second should be locked
                let progress = UserProgress::new();
                assert!(!check_module_unlocked(&progress, &engine, &era.meta.id, second_id));

                // After completing first module, second should be unlocked
                let progress = make_progress_with_completed(&[(first_id.as_str(), true, 80)]);
                assert!(check_module_unlocked(&progress, &engine, &era.meta.id, second_id));
            }
        }
    }

    #[test]
    fn test_last_two_locked_until_one_module_100_complete() {
        let engine = ContentEngine::new();

        // Find an era with at least 4 modules
        for era in engine.eras() {
            if era.modules.len() >= 4 {
                let module_ids: Vec<&str> = era.modules.iter().map(|m| m.meta.id.as_str()).collect();
                let last_module_id = module_ids[module_ids.len() - 1];
                let second_last_id = module_ids[module_ids.len() - 2];

                // Complete all modules except last two, but none at 100%
                let mut completed: Vec<(&str, bool, u32)> = module_ids[..module_ids.len()-2]
                    .iter()
                    .map(|id| (*id, true, 80u32))
                    .collect();

                let progress = make_progress_with_completed(&completed);

                // Last two should still be locked (no 100% completion)
                assert!(!check_module_unlocked(&progress, &engine, &era.meta.id, second_last_id),
                    "Second-to-last module should be locked without 100% completion");
                assert!(!check_module_unlocked(&progress, &engine, &era.meta.id, last_module_id),
                    "Last module should be locked without 100% completion");

                // Now complete one module at 100%
                completed[0].2 = 100;
                let progress = make_progress_with_completed(&completed);

                // Second-to-last should now be unlocked
                assert!(check_module_unlocked(&progress, &engine, &era.meta.id, second_last_id),
                    "Second-to-last module should be unlocked with 100% completion");

                break;
            }
        }
    }

    #[test]
    fn test_get_locked_module_ids() {
        let progress = UserProgress::new();
        let engine = ContentEngine::new();

        if let Some(era) = engine.eras().first() {
            let locked = get_locked_module_ids(&progress, &engine, &era.meta.id);

            // All modules except the first should be locked initially
            assert_eq!(locked.len(), era.modules.len() - 1);

            // First module should NOT be in the locked list
            if let Some(first_module) = era.modules.first() {
                assert!(!locked.contains(&first_module.meta.id));
            }
        }
    }
}

```

---

### Module: verification

**File:** `src/verification.rs`

Additional source module.

```rust
//! Verification Pass: AST to Verification IR Mapper
//!
//! This module bridges the LOGOS AST to the Z3-based verification system.
//! It maps LogicExpr, Stmt, and Term types to the lightweight Verification IR,
//! which is then encoded into Z3 constraints.
//!
//! Strategy: Smart Full Mapping with Uninterpreted Functions
//! - Int, Bool → direct Z3 sorts
//! - Object → uninterpreted sort for entities
//! - Predicates, Modals, Temporals → Apply (uninterpreted functions)
//! - Z3 reasons structurally without semantic knowledge

use crate::ast::{LogicExpr, ModalDomain, NumberKind, QuantifierKind, Term};
use crate::ast::stmt::{BinaryOpKind, Expr, Literal, Stmt, TypeExpr};
use crate::intern::{Interner, Symbol};
use crate::token::TokenType;

use logos_verification::{VerificationSession, VerifyExpr, VerifyOp, VerifyType};

/// The verification pass that maps LOGOS AST to Z3 constraints.
pub struct VerificationPass<'a> {
    session: VerificationSession,
    interner: &'a Interner,
}

impl<'a> VerificationPass<'a> {
    /// Create a new verification pass.
    pub fn new(interner: &'a Interner) -> Self {
        Self {
            session: VerificationSession::new(),
            interner,
        }
    }

    /// Run verification on a list of statements.
    ///
    /// This processes Let statements to build up assumptions,
    /// then verifies Assert statements against those assumptions.
    pub fn verify_program(&mut self, stmts: &[Stmt]) -> Result<(), String> {
        for stmt in stmts {
            self.visit_stmt(stmt)?;
        }
        Ok(())
    }

    fn visit_stmt(&mut self, stmt: &Stmt) -> Result<(), String> {
        match stmt {
            Stmt::Let { var, ty, value, .. } => {
                let name = self.interner.resolve(*var);

                // Phase 43D: Check refinement constraints BEFORE declaring variable
                if let Some(TypeExpr::Refinement { var: bound_var, predicate, .. }) = ty {
                    self.check_refinement(name, *bound_var, predicate, value)?;
                }

                // Infer type from the value
                let inferred_ty = self.infer_type(value);
                self.session.declare(name, inferred_ty);

                // Map the value to IR and assume var = value
                if let Some(val_ir) = self.map_imperative_expr(value) {
                    let constraint = VerifyExpr::eq(
                        VerifyExpr::var(name),
                        val_ir,
                    );
                    self.session.assume(&constraint);
                }
                Ok(())
            }

            Stmt::Set { target, value } => {
                // Mutation: add new constraint (simplified SSA)
                // In full verification, this would use SSA renaming
                let name = self.interner.resolve(*target);
                if let Some(val_ir) = self.map_imperative_expr(value) {
                    let constraint = VerifyExpr::eq(
                        VerifyExpr::var(name),
                        val_ir,
                    );
                    self.session.assume(&constraint);
                }
                Ok(())
            }

            Stmt::Assert { proposition } => {
                let ir = self.map_logic_expr(proposition);
                // Skip verification if the assertion maps to a trivial True
                // This handles complex linguistic constructs we can't verify yet
                if matches!(&ir, VerifyExpr::Bool(true)) {
                    return Ok(());
                }
                self.session.verify(&ir).map_err(|e| format!("{}", e))
            }

            Stmt::Trust { proposition, justification } => {
                // Trust is like Assert but with documented justification
                // For static verification, we verify it like an assertion
                let ir = self.map_logic_expr(proposition);
                // Skip verification if the assertion maps to a trivial True
                if matches!(&ir, VerifyExpr::Bool(true)) {
                    return Ok(());
                }
                let reason = self.interner.resolve(*justification);
                self.session.verify(&ir).map_err(|e| {
                    format!("Trust verification failed (justification: {}): {}", reason, e)
                })
            }

            // Recurse into blocks (simplified - no path-sensitive analysis yet)
            Stmt::If { then_block, else_block, .. } => {
                // Verify both branches independently
                for stmt in *then_block {
                    self.visit_stmt(stmt)?;
                }
                if let Some(else_stmts) = else_block {
                    for stmt in *else_stmts {
                        self.visit_stmt(stmt)?;
                    }
                }
                Ok(())
            }

            Stmt::While { body, decreasing, .. } => {
                // Phase 44: Termination checking
                if let Some(variant_expr) = decreasing {
                    self.check_termination(variant_expr, body)?;
                }

                // Visit body statements
                for stmt in *body {
                    self.visit_stmt(stmt)?;
                }
                Ok(())
            }

            Stmt::Repeat { body, .. } => {
                for stmt in *body {
                    self.visit_stmt(stmt)?;
                }
                Ok(())
            }

            Stmt::Zone { body, .. } => {
                for stmt in *body {
                    self.visit_stmt(stmt)?;
                }
                Ok(())
            }

            Stmt::FunctionDef { body, .. } => {
                for stmt in *body {
                    self.visit_stmt(stmt)?;
                }
                Ok(())
            }

            // Skip statements that don't affect verification
            Stmt::Return { .. }
            | Stmt::Call { .. }
            | Stmt::Give { .. }
            | Stmt::Show { .. }
            | Stmt::SetField { .. }
            | Stmt::StructDef { .. }
            | Stmt::Inspect { .. }
            | Stmt::Push { .. }
            | Stmt::Pop { .. }
            | Stmt::SetIndex { .. }
            | Stmt::Concurrent { .. }
            | Stmt::Parallel { .. }
            | Stmt::ReadFrom { .. }
            | Stmt::WriteFile { .. }
            // Phase 51: P2P Networking
            | Stmt::Listen { .. }
            | Stmt::ConnectTo { .. }
            | Stmt::LetPeerAgent { .. } => Ok(()),
        }
    }

    /// Infer the verification type from an imperative expression.
    fn infer_type(&self, expr: &Expr) -> VerifyType {
        match expr {
            Expr::Literal(Literal::Number(_)) => VerifyType::Int,
            Expr::Literal(Literal::Boolean(_)) => VerifyType::Bool,
            Expr::Literal(Literal::Text(_)) => VerifyType::Object,
            Expr::Literal(Literal::Nothing) => VerifyType::Object,
            Expr::BinaryOp { op, .. } => {
                match op {
                    // Comparison operators produce Bool
                    BinaryOpKind::Eq
                    | BinaryOpKind::NotEq
                    | BinaryOpKind::Lt
                    | BinaryOpKind::Gt
                    | BinaryOpKind::LtEq
                    | BinaryOpKind::GtEq
                    | BinaryOpKind::And
                    | BinaryOpKind::Or => VerifyType::Bool,
                    // Arithmetic operators produce Int
                    BinaryOpKind::Add
                    | BinaryOpKind::Subtract
                    | BinaryOpKind::Multiply
                    | BinaryOpKind::Divide => VerifyType::Int,
                }
            }
            // Default to Int for other expressions
            _ => VerifyType::Int,
        }
    }

    /// Phase 43D: Check that a value satisfies a refinement type constraint.
    fn check_refinement(
        &self,
        var_name: &str,
        bound_var: Symbol,
        predicate: &LogicExpr,
        value: &Expr,
    ) -> Result<(), String> {
        // 1. Map the value to IR
        let val_ir = self.map_imperative_expr(value)
            .ok_or_else(|| format!(
                "Cannot verify refinement for '{}': value expression not supported for verification",
                var_name
            ))?;

        // 2. Map the predicate to IR
        let pred_ir = self.map_logic_expr(predicate);

        // Skip if predicate maps to trivial True (complex linguistic constructs)
        if matches!(&pred_ir, VerifyExpr::Bool(true)) {
            return Ok(());
        }

        // 3. Get the bound variable name (e.g., "it" or "x")
        let bound_name = self.interner.resolve(bound_var);

        // 4. Verify with the binding
        self.session.verify_with_binding(
            bound_name,
            VerifyType::Int, // Refinements are typically on Int
            &val_ir,
            &pred_ir,
        ).map_err(|e| format!(
            "Refinement type verification failed for '{}': {}",
            var_name, e
        ))
    }

    /// Phase 44: Verify that a loop terminates by checking its decreasing variant.
    fn check_termination(
        &self,
        variant_expr: &Expr,
        body: &[Stmt],
    ) -> Result<(), String> {
        // 1. Map the variant to IR (this is V₀ - value before loop body)
        let v0 = self.map_imperative_expr(variant_expr)
            .ok_or_else(|| "Cannot verify termination: variant expression not supported".to_string())?;

        // 2. Get the variant variable name (must be a simple identifier for now)
        let variant_name = match variant_expr {
            Expr::Identifier(sym) => self.interner.resolve(*sym),
            _ => return Err("Decreasing clause must be a simple variable".to_string()),
        };

        // 3. Simulate the loop body to find V₁ (value after one iteration)
        let v1 = self.simulate_body_for_variant(variant_name, body)?;

        // 4. Verify: V₁ < V₀ (strictly decreasing)
        let decreasing_constraint = VerifyExpr::lt(v1.clone(), v0.clone());

        // 5. Verify: V₀ >= 0 (bounded below)
        let bounded_constraint = VerifyExpr::gte(v0.clone(), VerifyExpr::int(0));

        // 6. Combined: decreasing AND bounded
        let termination_proof = VerifyExpr::and(decreasing_constraint, bounded_constraint);

        self.session.verify(&termination_proof).map_err(|e| {
            format!("Termination verification failed for '{}': {}", variant_name, e)
        })
    }

    /// Simulate the loop body to determine the final value of the variant.
    fn simulate_body_for_variant(
        &self,
        variant_name: &str,
        body: &[Stmt],
    ) -> Result<VerifyExpr, String> {
        use std::collections::HashMap;

        // Track all bindings in the loop body
        let mut bindings: HashMap<String, VerifyExpr> = HashMap::new();
        let mut latest_value: Option<VerifyExpr> = None;

        for stmt in body {
            match stmt {
                Stmt::Let { var, value, .. } => {
                    let var_name = self.interner.resolve(*var);
                    if let Some(val_ir) = self.map_imperative_expr_with_bindings(value, &bindings) {
                        bindings.insert(var_name.to_string(), val_ir);
                    }
                }
                Stmt::Set { target, value } => {
                    let target_name = self.interner.resolve(*target);
                    if target_name == variant_name {
                        latest_value = self.map_imperative_expr_with_bindings(value, &bindings);
                    } else {
                        // Track other Set statements that might affect bindings
                        if let Some(val_ir) = self.map_imperative_expr_with_bindings(value, &bindings) {
                            bindings.insert(target_name.to_string(), val_ir);
                        }
                    }
                }
                _ => {
                    // TODO: Handle nested If/While for more complex cases
                }
            }
        }

        latest_value.ok_or_else(|| {
            format!("Variant '{}' is not modified in loop body", variant_name)
        })
    }

    /// Map an imperative expression to Verification IR, substituting known bindings.
    fn map_imperative_expr_with_bindings(
        &self,
        expr: &Expr,
        bindings: &std::collections::HashMap<String, VerifyExpr>,
    ) -> Option<VerifyExpr> {
        match expr {
            Expr::Literal(Literal::Number(n)) => Some(VerifyExpr::int(*n)),
            Expr::Literal(Literal::Boolean(b)) => Some(VerifyExpr::bool(*b)),
            Expr::Literal(Literal::Text(_)) => None,
            Expr::Literal(Literal::Nothing) => None,

            Expr::Identifier(sym) => {
                let name = self.interner.resolve(*sym);
                // Check if we have a known binding for this variable
                if let Some(bound_val) = bindings.get(name) {
                    Some(bound_val.clone())
                } else {
                    Some(VerifyExpr::var(name))
                }
            }

            Expr::BinaryOp { op, left, right } => {
                let l = self.map_imperative_expr_with_bindings(left, bindings)?;
                let r = self.map_imperative_expr_with_bindings(right, bindings)?;
                let verify_op = match op {
                    BinaryOpKind::Add => VerifyOp::Add,
                    BinaryOpKind::Subtract => VerifyOp::Sub,
                    BinaryOpKind::Multiply => VerifyOp::Mul,
                    BinaryOpKind::Divide => VerifyOp::Div,
                    BinaryOpKind::Eq => VerifyOp::Eq,
                    BinaryOpKind::NotEq => VerifyOp::Neq,
                    BinaryOpKind::Gt => VerifyOp::Gt,
                    BinaryOpKind::Lt => VerifyOp::Lt,
                    BinaryOpKind::GtEq => VerifyOp::Gte,
                    BinaryOpKind::LtEq => VerifyOp::Lte,
                    BinaryOpKind::And => VerifyOp::And,
                    BinaryOpKind::Or => VerifyOp::Or,
                };
                Some(VerifyExpr::binary(verify_op, l, r))
            }

            Expr::Call { function, args } => {
                let func_name = self.interner.resolve(*function);
                let verify_args: Vec<VerifyExpr> = args
                    .iter()
                    .filter_map(|a| self.map_imperative_expr_with_bindings(a, bindings))
                    .collect();
                Some(VerifyExpr::apply(func_name, verify_args))
            }

            // Unsupported expressions
            _ => None,
        }
    }

    /// Map an imperative expression to Verification IR.
    fn map_imperative_expr(&self, expr: &Expr) -> Option<VerifyExpr> {
        match expr {
            Expr::Literal(Literal::Number(n)) => Some(VerifyExpr::int(*n)),
            Expr::Literal(Literal::Boolean(b)) => Some(VerifyExpr::bool(*b)),
            Expr::Literal(Literal::Text(_)) => None, // Text not supported in Z3
            Expr::Literal(Literal::Nothing) => None,

            Expr::Identifier(sym) => {
                let name = self.interner.resolve(*sym);
                Some(VerifyExpr::var(name))
            }

            Expr::BinaryOp { op, left, right } => {
                let l = self.map_imperative_expr(left)?;
                let r = self.map_imperative_expr(right)?;
                let verify_op = match op {
                    BinaryOpKind::Add => VerifyOp::Add,
                    BinaryOpKind::Subtract => VerifyOp::Sub,
                    BinaryOpKind::Multiply => VerifyOp::Mul,
                    BinaryOpKind::Divide => VerifyOp::Div,
                    BinaryOpKind::Eq => VerifyOp::Eq,
                    BinaryOpKind::NotEq => VerifyOp::Neq,
                    BinaryOpKind::Gt => VerifyOp::Gt,
                    BinaryOpKind::Lt => VerifyOp::Lt,
                    BinaryOpKind::GtEq => VerifyOp::Gte,
                    BinaryOpKind::LtEq => VerifyOp::Lte,
                    BinaryOpKind::And => VerifyOp::And,
                    BinaryOpKind::Or => VerifyOp::Or,
                };
                Some(VerifyExpr::binary(verify_op, l, r))
            }

            Expr::Call { function, args } => {
                let func_name = self.interner.resolve(*function);
                let verify_args: Vec<VerifyExpr> = args
                    .iter()
                    .filter_map(|a| self.map_imperative_expr(a))
                    .collect();
                Some(VerifyExpr::apply(func_name, verify_args))
            }

            // Unsupported expressions
            Expr::Index { .. }
            | Expr::Slice { .. }
            | Expr::Copy { .. }
            | Expr::Length { .. }
            | Expr::List(_)
            | Expr::Range { .. }
            | Expr::FieldAccess { .. }
            | Expr::New { .. }
            | Expr::NewVariant { .. } => None,
        }
    }

    /// Map a logic expression to Verification IR.
    ///
    /// This is the core of the "Smart Full Mapping" strategy:
    /// - Simple types (Int, Bool) map directly
    /// - Complex types (Predicates, Modals) become uninterpreted functions
    fn map_logic_expr(&self, expr: &LogicExpr) -> VerifyExpr {
        match expr {
            LogicExpr::Atom(sym) => {
                // Atoms are boolean variables or 0-arity predicates
                let name = self.interner.resolve(*sym);
                VerifyExpr::var(name)
            }

            LogicExpr::Predicate { name, args } => {
                let pred_name = self.interner.resolve(*name);
                let verify_args: Vec<VerifyExpr> = args
                    .iter()
                    .map(|t| self.map_term(t))
                    .collect();

                // Phase 43D: Handle comparison predicates from refinement types
                // The parser creates predicates like "Greater(it, 0)" for "it > 0"
                if verify_args.len() == 2 {
                    let left = verify_args[0].clone();
                    let right = verify_args[1].clone();
                    match pred_name {
                        "Greater" => return VerifyExpr::gt(left, right),
                        "Less" => return VerifyExpr::lt(left, right),
                        "GreaterEqual" => return VerifyExpr::gte(left, right),
                        "LessEqual" => return VerifyExpr::lte(left, right),
                        "Equal" => return VerifyExpr::eq(left, right),
                        "NotEqual" => return VerifyExpr::neq(left, right),
                        _ => {}
                    }
                }

                // Default: treat as uninterpreted function
                VerifyExpr::apply(pred_name, verify_args)
            }

            LogicExpr::Identity { left, right } => {
                let l = self.map_term(left);
                let r = self.map_term(right);
                VerifyExpr::eq(l, r)
            }

            LogicExpr::BinaryOp { left, op, right } => {
                let l = self.map_logic_expr(left);
                let r = self.map_logic_expr(right);
                let verify_op = match op {
                    TokenType::And => VerifyOp::And,
                    TokenType::Or => VerifyOp::Or,
                    TokenType::If | TokenType::Then => VerifyOp::Implies,
                    TokenType::Iff => VerifyOp::Eq, // Biconditional is boolean equality
                    _ => VerifyOp::And, // Fallback
                };
                VerifyExpr::binary(verify_op, l, r)
            }

            LogicExpr::UnaryOp { op, operand } => {
                match op {
                    TokenType::Not => VerifyExpr::not(self.map_logic_expr(operand)),
                    _ => self.map_logic_expr(operand),
                }
            }

            // Smart Mapping: Modal operators become uninterpreted functions
            LogicExpr::Modal { vector, operand } => {
                let op_name = match vector.domain {
                    ModalDomain::Alethic => {
                        if vector.force > 0.5 { "Necessarily" } else { "Possibly" }
                    }
                    ModalDomain::Deontic => {
                        if vector.force > 0.5 { "Obligatory" } else { "Permissible" }
                    }
                };
                VerifyExpr::apply(op_name, vec![self.map_logic_expr(operand)])
            }

            // Smart Mapping: Temporal operators become uninterpreted functions
            LogicExpr::Temporal { operator, body } => {
                let op_name = match operator {
                    crate::ast::TemporalOperator::Past => "Past",
                    crate::ast::TemporalOperator::Future => "Future",
                };
                VerifyExpr::apply(op_name, vec![self.map_logic_expr(body)])
            }

            // Smart Mapping: Aspectual operators become uninterpreted functions
            LogicExpr::Aspectual { operator, body } => {
                let op_name = match operator {
                    crate::ast::AspectOperator::Progressive => "Progressive",
                    crate::ast::AspectOperator::Perfect => "Perfect",
                    crate::ast::AspectOperator::Habitual => "Habitual",
                    crate::ast::AspectOperator::Iterative => "Iterative",
                };
                VerifyExpr::apply(op_name, vec![self.map_logic_expr(body)])
            }

            // Quantifiers map to IR quantifiers
            LogicExpr::Quantifier { kind, variable, body, .. } => {
                let var_name = self.interner.resolve(*variable);
                let body_ir = self.map_logic_expr(body);
                match kind {
                    QuantifierKind::Universal => {
                        VerifyExpr::forall(
                            vec![(var_name.to_string(), VerifyType::Object)],
                            body_ir,
                        )
                    }
                    QuantifierKind::Existential => {
                        VerifyExpr::exists(
                            vec![(var_name.to_string(), VerifyType::Object)],
                            body_ir,
                        )
                    }
                    // Generalized quantifiers become uninterpreted
                    QuantifierKind::Most => {
                        VerifyExpr::apply("Most", vec![VerifyExpr::var(var_name), body_ir])
                    }
                    QuantifierKind::Few => {
                        VerifyExpr::apply("Few", vec![VerifyExpr::var(var_name), body_ir])
                    }
                    QuantifierKind::Many => {
                        VerifyExpr::apply("Many", vec![VerifyExpr::var(var_name), body_ir])
                    }
                    QuantifierKind::Cardinal(n) => {
                        VerifyExpr::apply(
                            &format!("Exactly{}", n),
                            vec![VerifyExpr::var(var_name), body_ir],
                        )
                    }
                    QuantifierKind::AtLeast(n) => {
                        VerifyExpr::apply(
                            &format!("AtLeast{}", n),
                            vec![VerifyExpr::var(var_name), body_ir],
                        )
                    }
                    QuantifierKind::AtMost(n) => {
                        VerifyExpr::apply(
                            &format!("AtMost{}", n),
                            vec![VerifyExpr::var(var_name), body_ir],
                        )
                    }
                    QuantifierKind::Generic => {
                        VerifyExpr::apply("Generic", vec![VerifyExpr::var(var_name), body_ir])
                    }
                }
            }

            // Lambda abstractions become uninterpreted
            LogicExpr::Lambda { variable, body } => {
                let var_name = self.interner.resolve(*variable);
                VerifyExpr::apply(
                    "Lambda",
                    vec![VerifyExpr::var(var_name), self.map_logic_expr(body)],
                )
            }

            // Function application
            LogicExpr::App { function, argument } => {
                VerifyExpr::apply(
                    "App",
                    vec![self.map_logic_expr(function), self.map_logic_expr(argument)],
                )
            }

            // Counterfactuals: if-then with special modal semantics
            LogicExpr::Counterfactual { antecedent, consequent } => {
                VerifyExpr::apply(
                    "Counterfactual",
                    vec![self.map_logic_expr(antecedent), self.map_logic_expr(consequent)],
                )
            }

            // Causation
            LogicExpr::Causal { cause, effect } => {
                VerifyExpr::apply(
                    "Causes",
                    vec![self.map_logic_expr(cause), self.map_logic_expr(effect)],
                )
            }

            // Questions become uninterpreted (for query semantics)
            LogicExpr::Question { wh_variable, body } => {
                let var_name = self.interner.resolve(*wh_variable);
                VerifyExpr::apply(
                    "Question",
                    vec![VerifyExpr::var(var_name), self.map_logic_expr(body)],
                )
            }

            LogicExpr::YesNoQuestion { body } => {
                VerifyExpr::apply("YesNo", vec![self.map_logic_expr(body)])
            }

            // Intensional contexts
            LogicExpr::Intensional { operator, content } => {
                let op_name = self.interner.resolve(*operator);
                VerifyExpr::apply(op_name, vec![self.map_logic_expr(content)])
            }

            // Speech acts
            LogicExpr::SpeechAct { performer, act_type, content } => {
                let performer_name = self.interner.resolve(*performer);
                let act_name = self.interner.resolve(*act_type);
                VerifyExpr::apply(
                    act_name,
                    vec![VerifyExpr::var(performer_name), self.map_logic_expr(content)],
                )
            }

            // Comparatives
            LogicExpr::Comparative { adjective, subject, object, difference } => {
                let adj_name = self.interner.resolve(*adjective);
                let mut args = vec![
                    self.map_term(subject),
                    self.map_term(object),
                ];
                if let Some(diff) = difference {
                    args.push(self.map_term(diff));
                }
                VerifyExpr::apply(&format!("More{}", adj_name), args)
            }

            // Superlatives
            LogicExpr::Superlative { adjective, subject, domain } => {
                let adj_name = self.interner.resolve(*adjective);
                let domain_name = self.interner.resolve(*domain);
                VerifyExpr::apply(
                    &format!("Most{}", adj_name),
                    vec![self.map_term(subject), VerifyExpr::var(domain_name)],
                )
            }

            // Focus
            LogicExpr::Focus { focused, scope, .. } => {
                VerifyExpr::apply(
                    "Focus",
                    vec![self.map_term(focused), self.map_logic_expr(scope)],
                )
            }

            // Presupposition
            LogicExpr::Presupposition { assertion, presupposition } => {
                // Verify both assertion and presupposition
                VerifyExpr::and(
                    self.map_logic_expr(presupposition),
                    self.map_logic_expr(assertion),
                )
            }

            // Fallback for complex types: map to True to avoid false positives
            LogicExpr::Metaphor { .. }
            | LogicExpr::Categorical(_)
            | LogicExpr::Relation(_)
            | LogicExpr::Voice { .. }
            | LogicExpr::Event { .. }
            | LogicExpr::NeoEvent(_)
            | LogicExpr::Imperative { .. }
            | LogicExpr::TemporalAnchor { .. }
            | LogicExpr::Distributive { .. }
            | LogicExpr::GroupQuantifier { .. }
            | LogicExpr::Scopal { .. }
            | LogicExpr::Control { .. } => {
                // These complex linguistic constructs are assumed valid
                VerifyExpr::bool(true)
            }
        }
    }

    /// Map a term to Verification IR.
    fn map_term(&self, term: &Term) -> VerifyExpr {
        match term {
            Term::Constant(sym) | Term::Variable(sym) => {
                let name = self.interner.resolve(*sym);
                VerifyExpr::var(name)
            }

            Term::Value { kind, .. } => {
                match kind {
                    NumberKind::Integer(n) => VerifyExpr::int(*n),
                    NumberKind::Real(r) => VerifyExpr::int(*r as i64), // Truncate for now
                    NumberKind::Symbolic(s) => {
                        let name = self.interner.resolve(*s);
                        VerifyExpr::var(name)
                    }
                }
            }

            Term::Function(name, args) => {
                let func_name = self.interner.resolve(*name);
                let verify_args: Vec<VerifyExpr> = args
                    .iter()
                    .map(|t| self.map_term(t))
                    .collect();
                VerifyExpr::apply(func_name, verify_args)
            }

            Term::Group(terms) => {
                // Group terms become a special "Group" function
                let verify_args: Vec<VerifyExpr> = terms
                    .iter()
                    .map(|t| self.map_term(t))
                    .collect();
                VerifyExpr::apply("Group", verify_args)
            }

            Term::Possessed { possessor, possessed } => {
                let poss_name = self.interner.resolve(*possessed);
                VerifyExpr::apply(
                    &format!("{}Of", poss_name),
                    vec![self.map_term(possessor)],
                )
            }

            Term::Sigma(sym) => {
                let name = self.interner.resolve(*sym);
                VerifyExpr::apply("Sigma", vec![VerifyExpr::var(name)])
            }

            Term::Intension(sym) => {
                let name = self.interner.resolve(*sym);
                VerifyExpr::apply("Intension", vec![VerifyExpr::var(name)])
            }

            Term::Proposition(expr) => {
                self.map_logic_expr(expr)
            }
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    fn make_interner() -> Interner {
        Interner::new()
    }

    #[test]
    fn test_verification_pass_creation() {
        let interner = make_interner();
        let pass = VerificationPass::new(&interner);
        // Just verify it constructs without panic
        drop(pass);
    }
}

```

---

## Build Configuration

### Package Manifest

**File:** `Cargo.toml`

Rust package configuration with dependencies: bumpalo (arena allocator), dioxus (desktop UI).

```toml
[package]
name = "logos"
version = "0.5.5"
edition = "2021"
authors = ["Tristen Harr <tristen@brahmastra-labs.com>"]
license = "BUSL-1.1"
description = "English-to-Logic Transpiler targeting Logicaffeine notation"
repository = "https://github.com/Brahmastra-Labs/logicaffeine"
homepage = "https://logicaffeine.com"
keywords = ["logic", "transpiler", "natural-language", "fol", "compiler"]
categories = ["compilers", "development-tools"]
build = "build.rs"

[[bin]]
name = "logos"
path = "src/main.rs"

[[bin]]
name = "largo"
path = "src/main.rs"
required-features = ["cli"]

[workspace]
exclude = ["logos_core", "logos_verification"]

[dependencies]
bumpalo = "3.19.1"
dioxus = { version = "0.6", features = ["web", "router"] }
wasm-bindgen = "0.2"
js-sys = "0.3"
web-sys = { version = "0.3", features = [
    "Document", "Element", "HtmlElement", "Window", "History",
    "HtmlDivElement", "Event", "KeyboardEvent", "InputEvent",
    "Storage", "Navigator", "Clipboard", "UrlSearchParams",
    "IntersectionObserver", "IntersectionObserverInit", "IntersectionObserverEntry",
    "DomRect", "ScrollIntoViewOptions", "ScrollBehavior", "ScrollLogicalPosition",
    "ScrollToOptions"
] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
getrandom = { version = "0.2", features = ["js"] }
rand = "0.8"
include_dir = "0.7"
gloo-timers = { version = "0.3", features = ["futures"] }
gloo-net = "0.6"
wasm-bindgen-futures = "0.4"
# Phase 55: logos_core for VFS and Persistent<T> in interpreter
logos_core = { path = "./logos_core" }
# Phase 55: async-recursion for clean async interpreter
async-recursion = "1.1"
clap = { version = "4.4", features = ["derive"], optional = true }
toml = { version = "0.8", optional = true }
ureq = { version = "2.9", features = ["json"], optional = true }
flate2 = { version = "1.0", optional = true }
tar = { version = "0.4", optional = true }
dirs = { version = "5.0", optional = true }
logos_verification = { path = "./logos_verification", optional = true }

[features]
default = []
cli = ["clap", "toml", "ureq", "flate2", "tar", "dirs"]
verification = ["logos_verification"]

[build-dependencies]
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

[dev-dependencies]
tempfile = "3"
toml = "0.8"
bincode = "1.3"

[profile]

[profile.wasm-dev]
inherits = "dev"
opt-level = 1

[profile.server-dev]
inherits = "dev"

[profile.android-dev]
inherits = "dev"

```

---

### Build Script

**File:** `build.rs`

Generates compile-time lookup functions from lexicon.json. Expands verbs into irregular verb entries and feature-based VerbDbEntry records. Derives behavioral lists (is_ditransitive_verb, is_subject_control_verb, is_object_control_verb, is_raising_verb, is_opaque_verb, is_collective_verb, is_performative) from feature arrays. Generates lookup_verb_db(), lookup_noun_db(), lookup_adjective_db() returning metadata with feature slices. Produces is_* check functions for closed classes and morphology rules.

```rust
use serde::Deserialize;
use std::collections::HashMap;
use std::env;
use std::fs;
use std::io::Write;
use std::path::Path;

// ═══════════════════════════════════════════════════════════════════
// JSON Schema for Refactored Lexicon
// ═══════════════════════════════════════════════════════════════════

#[derive(Deserialize)]
struct RefactoredLexiconData {
    keywords: HashMap<String, String>,
    pronouns: Vec<PronounEntry>,
    articles: HashMap<String, String>,
    auxiliaries: HashMap<String, String>,
    presupposition_triggers: HashMap<String, String>,
    number_words: HashMap<String, u32>,
    verbs: Vec<VerbDefinition>,
    nouns: Vec<NounDefinition>,
    adjectives: Vec<AdjectiveDefinition>,
    prepositions: Vec<String>,
    adverbs: Vec<String>,
    scopal_adverbs: Vec<String>,
    temporal_adverbs: Vec<String>,
    #[serde(default)]
    particles: Vec<String>,
    #[serde(default)]
    phrasal_verbs: HashMap<String, PhrasalVerbEntry>,
    not_adverbs: Vec<String>,
    noun_patterns: Vec<String>,
    disambiguation_not_verbs: Vec<String>,
    morphology: Morphology,
    #[serde(default)]
    units: HashMap<String, String>,
    #[serde(default)]
    multi_word_expressions: Vec<MweEntry>,
    #[serde(default)]
    ontology: Option<OntologyData>,
    #[serde(default)]
    axioms: Option<AxiomData>,
    #[serde(default)]
    agentive_nouns: HashMap<String, String>,
}

#[derive(Deserialize)]
struct PronounEntry {
    word: String,
    gender: String,
    number: String,
    case: String,
}

#[derive(Deserialize)]
struct VerbDefinition {
    lemma: String,
    class: String,
    #[serde(default)]
    forms: Option<VerbForms>,
    #[serde(default)]
    regular: bool,
    #[serde(default)]
    features: Vec<String>,
    #[serde(default)]
    synonyms: Vec<String>,
    #[serde(default)]
    antonyms: Vec<String>,
}

#[derive(Deserialize, Default)]
struct VerbForms {
    #[serde(default)]
    present3s: Option<String>,
    #[serde(default)]
    past: Option<String>,
    #[serde(default)]
    participle: Option<String>,
    #[serde(default)]
    gerund: Option<String>,
}

#[derive(Deserialize)]
struct NounDefinition {
    lemma: String,
    #[serde(default)]
    forms: Option<NounForms>,
    #[serde(default)]
    features: Vec<String>,
    #[serde(default)]
    sort: Option<String>,
}

#[derive(Deserialize, Default)]
struct NounForms {
    #[serde(default)]
    plural: Option<String>,
}

#[derive(Deserialize)]
struct AdjectiveDefinition {
    lemma: String,
    #[serde(default)]
    regular: bool,
    #[serde(default)]
    features: Vec<String>,
}

#[derive(Deserialize)]
struct Morphology {
    needs_e_ing: Vec<String>,
    needs_e_ed: Vec<String>,
    stemming_exceptions: Vec<String>,
}

#[derive(Deserialize)]
struct MweEntry {
    pattern: Vec<String>,
    lemma: String,
    pos: String,
    #[serde(default)]
    class: Option<String>,
    #[serde(default)]
    features: Vec<String>,
}

#[derive(Deserialize)]
struct PhrasalVerbEntry {
    lemma: String,
    class: String,
}

#[derive(Deserialize, Default)]
struct OntologyData {
    #[serde(default)]
    part_whole: Vec<PartWholeEntry>,
    #[serde(default)]
    predicate_sorts: HashMap<String, String>,
}

#[derive(Deserialize)]
struct PartWholeEntry {
    whole: String,
    parts: Vec<String>,
}

#[derive(Deserialize, Default)]
struct AxiomData {
    #[serde(default)]
    nouns: HashMap<String, NounAxiom>,
    #[serde(default)]
    adjectives: HashMap<String, AdjectiveAxiom>,
    #[serde(default)]
    verbs: HashMap<String, VerbAxiom>,
}

#[derive(Deserialize, Default)]
struct NounAxiom {
    #[serde(default)]
    entails: Vec<String>,
    #[serde(default)]
    hypernyms: Vec<String>,
}

#[derive(Deserialize)]
struct AdjectiveAxiom {
    #[serde(rename = "type")]
    axiom_type: String,
}

#[derive(Deserialize, Default)]
struct VerbAxiom {
    #[serde(default)]
    entails: Option<String>,
    #[serde(default)]
    manner: Vec<String>,
}

// Intermediate representation for irregular verb entries
struct IrregularVerbEntry {
    word: String,
    lemma: String,
    time: String,
    aspect: String,
    class: String,
}

// Full verb database entry with features
struct VerbDbEntry {
    word: String,
    lemma: String,
    time: String,
    aspect: String,
    class: String,
    features: Vec<String>,
}

// Noun database entry with features
struct NounDbEntry {
    word: String,
    lemma: String,
    number: String,
    features: Vec<String>,
}

// Adjective database entry with features
struct AdjectiveDbEntry {
    word: String,
    lemma: String,
    features: Vec<String>,
}

// ═══════════════════════════════════════════════════════════════════
// Main Build Function
// ═══════════════════════════════════════════════════════════════════

fn main() {
    let manifest_dir = env::var("CARGO_MANIFEST_DIR").unwrap();
    let json_path = Path::new(&manifest_dir).join("assets/lexicon.json");

    println!("cargo:rerun-if-changed=assets/lexicon.json");

    let json_content = fs::read_to_string(&json_path)
        .unwrap_or_else(|_| panic!("Failed to read {}", json_path.display()));

    let data: RefactoredLexiconData = serde_json::from_str(&json_content)
        .unwrap_or_else(|e| panic!("Failed to parse refactored_lexicon.json: {}", e));

    let out_dir = env::var("OUT_DIR").unwrap();
    let dest_path = Path::new(&out_dir).join("lexicon_data.rs");
    let mut file = fs::File::create(&dest_path).unwrap();

    // Generate unchanged lookup functions
    generate_lookup_keyword(&mut file, &data.keywords);
    generate_lookup_pronoun(&mut file, &data.pronouns);
    generate_lookup_article(&mut file, &data.articles);
    generate_lookup_auxiliary(&mut file, &data.auxiliaries);
    generate_lookup_presup_trigger(&mut file, &data.presupposition_triggers);
    generate_word_to_number(&mut file, &data.number_words);

    // Expand verbs into irregular verb entries and generate lookup
    let irregular_verbs = expand_verbs_to_entries(&data.verbs);
    generate_lookup_irregular_verb(&mut file, &irregular_verbs);

    // Generate singularize from noun forms
    let irregular_plurals = derive_irregular_plurals(&data.nouns);
    generate_singularize(&mut file, &irregular_plurals);

    // Generate closed class checks
    generate_is_check(&mut file, "is_preposition", &data.prepositions);
    generate_is_check(&mut file, "is_noun_pattern", &data.noun_patterns);
    generate_is_check(&mut file, "is_scopal_adverb", &data.scopal_adverbs);
    generate_is_check(&mut file, "is_temporal_adverb", &data.temporal_adverbs);
    generate_is_check(&mut file, "is_particle", &data.particles);
    generate_is_check(&mut file, "is_adverb", &data.adverbs);
    generate_is_check(&mut file, "is_not_adverb", &data.not_adverbs);
    generate_is_check(&mut file, "is_disambiguation_not_verb", &data.disambiguation_not_verbs);
    generate_is_check(&mut file, "needs_e_ing", &data.morphology.needs_e_ing);
    generate_is_check(&mut file, "needs_e_ed", &data.morphology.needs_e_ed);
    generate_is_check(&mut file, "is_stemming_exception", &data.morphology.stemming_exceptions);
    generate_is_check(
        &mut file,
        "is_irregular_plural",
        &irregular_plurals.keys().cloned().collect::<Vec<_>>(),
    );

    // Derive behavioral lists from verb features
    let (
        ditransitive_verbs,
        subject_control_verbs,
        object_control_verbs,
        raising_verbs,
        opaque_verbs,
        collective_verbs,
        performatives,
        mixed_verbs,
    ) = derive_verb_feature_lists(&data.verbs);

    generate_is_check(&mut file, "is_ditransitive_verb", &ditransitive_verbs);
    generate_is_check(&mut file, "is_subject_control_verb", &subject_control_verbs);
    generate_is_check(&mut file, "is_object_control_verb", &object_control_verbs);
    generate_is_check(&mut file, "is_raising_verb", &raising_verbs);
    generate_is_check(&mut file, "is_opaque_verb", &opaque_verbs);
    generate_is_check(&mut file, "is_collective_verb", &collective_verbs);
    generate_is_check(&mut file, "is_performative", &performatives);
    generate_is_check(&mut file, "is_mixed_verb", &mixed_verbs);

    // Generate base verb list from all verb lemmas
    let base_verbs: Vec<String> = data.verbs.iter().map(|v| v.lemma.to_lowercase()).collect();
    generate_is_check(&mut file, "is_base_verb", &base_verbs);
    generate_is_check(&mut file, "is_base_verb_early", &base_verbs[..base_verbs.len().min(30)].to_vec());
    generate_is_check(&mut file, "is_infinitive_verb", &base_verbs);

    // Derive adjective lists from features
    let (adjectives, non_intersective, subsective, gradable, event_modifier) = derive_adjective_lists(&data.adjectives);
    generate_is_check(&mut file, "is_adjective", &adjectives);
    generate_is_check(&mut file, "is_non_intersective", &non_intersective);
    generate_is_check(&mut file, "is_subsective", &subsective);
    generate_is_check(&mut file, "is_gradable_adjective", &gradable);
    generate_is_check(&mut file, "is_event_modifier_adjective", &event_modifier);

    // Generate agentive noun lookup (dancer -> Dance)
    generate_lookup_agentive_noun(&mut file, &data.agentive_nouns);

    // Derive noun lists from features
    let (common_nouns, male_names, female_names, male_nouns, female_nouns) =
        derive_noun_lists(&data.nouns);
    generate_is_check(&mut file, "is_common_noun", &common_nouns);
    generate_is_check(&mut file, "is_male_name", &male_names);
    generate_is_check(&mut file, "is_female_name", &female_names);
    generate_is_check(&mut file, "is_male_noun", &male_nouns);
    generate_is_check(&mut file, "is_female_noun", &female_nouns);

    // Generate verb class lookup from verb definitions
    let (state_verbs, activity_verbs, accomplishment_verbs, achievement_verbs, semelfactive_verbs) =
        derive_verb_class_lists(&data.verbs);
    generate_lookup_verb_class(
        &mut file,
        &state_verbs,
        &activity_verbs,
        &accomplishment_verbs,
        &achievement_verbs,
        &semelfactive_verbs,
    );

    // Generate feature-based metadata databases
    let verb_db_entries = expand_verbs_to_db_entries(&data.verbs);
    generate_lookup_verb_db(&mut file, &verb_db_entries);

    let noun_db_entries = expand_nouns_to_db_entries(&data.nouns);
    generate_lookup_noun_db(&mut file, &noun_db_entries);

    let adjective_db_entries = expand_adjectives_to_db_entries(&data.adjectives);
    generate_lookup_adjective_db(&mut file, &adjective_db_entries);

    // Generate unit dimension lookup for degree semantics
    generate_lookup_unit_dimension(&mut file, &data.units);

    // Generate phrasal verb lookup for particle movement
    generate_lookup_phrasal_verb(&mut file, &data.phrasal_verbs);

    // Generate sort lookup for semantic type system
    generate_lookup_sort(&mut file, &data.nouns);

    // Generate MWE trie initialization
    let mwe_path = Path::new(&out_dir).join("mwe_data.rs");
    let mut mwe_file = fs::File::create(&mwe_path).unwrap();
    generate_mwe_trie_init(&mut mwe_file, &data.multi_word_expressions);

    // Generate ontology lookup functions
    let ontology_path = Path::new(&out_dir).join("ontology_data.rs");
    let mut ontology_file = fs::File::create(&ontology_path).unwrap();
    generate_ontology_data(&mut ontology_file, &data.ontology);

    // Generate axiom lookup functions
    let axiom_path = Path::new(&out_dir).join("axiom_data.rs");
    let mut axiom_file = fs::File::create(&axiom_path).unwrap();
    generate_axiom_data(&mut axiom_file, &data.axioms);

    // Generate canonical mapping lookup for synonyms/antonyms
    generate_canonical_mapping(&mut file, &data.verbs);
}

// ═══════════════════════════════════════════════════════════════════
// Verb Form Expansion
// ═══════════════════════════════════════════════════════════════════

fn expand_verbs_to_entries(verbs: &[VerbDefinition]) -> Vec<IrregularVerbEntry> {
    let mut entries = Vec::new();

    for verb in verbs {
        let lemma = &verb.lemma;
        let class = &verb.class;
        let lower_lemma = lemma.to_lowercase();

        // Always add the base form (present)
        entries.push(IrregularVerbEntry {
            word: lower_lemma.clone(),
            lemma: lemma.clone(),
            time: "Present".to_string(),
            aspect: "Simple".to_string(),
            class: class.clone(),
        });

        if let Some(forms) = &verb.forms {
            // Irregular verb with explicit forms
            if let Some(present3s) = &forms.present3s {
                entries.push(IrregularVerbEntry {
                    word: present3s.to_lowercase(),
                    lemma: lemma.clone(),
                    time: "Present".to_string(),
                    aspect: "Simple".to_string(),
                    class: class.clone(),
                });
            }

            if let Some(past) = &forms.past {
                entries.push(IrregularVerbEntry {
                    word: past.to_lowercase(),
                    lemma: lemma.clone(),
                    time: "Past".to_string(),
                    aspect: "Simple".to_string(),
                    class: class.clone(),
                });
            }

            if let Some(participle) = &forms.participle {
                // Participle is past aspect simple (for "has eaten", "was broken")
                entries.push(IrregularVerbEntry {
                    word: participle.to_lowercase(),
                    lemma: lemma.clone(),
                    time: "Past".to_string(),
                    aspect: "Simple".to_string(),
                    class: class.clone(),
                });
            }

            if let Some(gerund) = &forms.gerund {
                entries.push(IrregularVerbEntry {
                    word: gerund.to_lowercase(),
                    lemma: lemma.clone(),
                    time: "None".to_string(),
                    aspect: "Progressive".to_string(),
                    class: class.clone(),
                });
            }
        }
        // Note: Regular verbs (regular: true without forms) are handled by
        // Lexicon::lookup_verb's morphological rules, not the irregular table
    }

    entries
}

// ═══════════════════════════════════════════════════════════════════
// Feature Derivation Functions
// ═══════════════════════════════════════════════════════════════════

fn derive_verb_feature_lists(
    verbs: &[VerbDefinition],
) -> (
    Vec<String>,
    Vec<String>,
    Vec<String>,
    Vec<String>,
    Vec<String>,
    Vec<String>,
    Vec<String>,
    Vec<String>,
) {
    let mut ditransitive = Vec::new();
    let mut subject_control = Vec::new();
    let mut object_control = Vec::new();
    let mut raising = Vec::new();
    let mut opaque = Vec::new();
    let mut collective = Vec::new();
    let mut performative = Vec::new();
    let mut mixed = Vec::new();

    for verb in verbs {
        let lower = verb.lemma.to_lowercase();
        for feature in &verb.features {
            match feature.as_str() {
                "Ditransitive" => ditransitive.push(lower.clone()),
                "SubjectControl" => subject_control.push(lower.clone()),
                "ObjectControl" => object_control.push(lower.clone()),
                "Raising" => raising.push(lower.clone()),
                "Opaque" => {
                    // Include base form and conjugated forms for opaque verb checks
                    opaque.push(lower.clone());
                    opaque.push(format!("{}s", lower)); // third person singular
                    opaque.push(format!("{}ed", lower)); // past tense (regular)
                    // Also include irregular forms if present
                    if let Some(forms) = &verb.forms {
                        if let Some(past) = &forms.past {
                            opaque.push(past.to_lowercase());
                        }
                        if let Some(participle) = &forms.participle {
                            opaque.push(participle.to_lowercase());
                        }
                    }
                }
                "Collective" => collective.push(lower.clone()),
                "Performative" => performative.push(lower.clone()),
                "Mixed" => mixed.push(lower.clone()),
                _ => {}
            }
        }
    }

    (
        ditransitive,
        subject_control,
        object_control,
        raising,
        opaque,
        collective,
        performative,
        mixed,
    )
}

fn derive_verb_class_lists(
    verbs: &[VerbDefinition],
) -> (Vec<String>, Vec<String>, Vec<String>, Vec<String>, Vec<String>) {
    let mut state = Vec::new();
    let mut activity = Vec::new();
    let mut accomplishment = Vec::new();
    let mut achievement = Vec::new();
    let mut semelfactive = Vec::new();

    for verb in verbs {
        let lower = verb.lemma.to_lowercase();
        match verb.class.as_str() {
            "State" => state.push(lower),
            "Activity" => activity.push(lower),
            "Accomplishment" => accomplishment.push(lower),
            "Achievement" => achievement.push(lower),
            "Semelfactive" => semelfactive.push(lower),
            _ => activity.push(lower),
        }
    }

    (state, activity, accomplishment, achievement, semelfactive)
}

fn derive_adjective_lists(
    adjectives: &[AdjectiveDefinition],
) -> (Vec<String>, Vec<String>, Vec<String>, Vec<String>, Vec<String>) {
    let mut all_adj = Vec::new();
    let mut non_intersective = Vec::new();
    let mut subsective = Vec::new();
    let mut gradable = Vec::new();
    let mut event_modifier = Vec::new();

    for adj in adjectives {
        let lower = adj.lemma.to_lowercase();
        all_adj.push(lower.clone());

        for feature in &adj.features {
            match feature.as_str() {
                "NonIntersective" => non_intersective.push(lower.clone()),
                "Subsective" => subsective.push(lower.clone()),
                "Gradable" => gradable.push(lower.clone()),
                "EventModifier" => event_modifier.push(lower.clone()),
                _ => {}
            }
        }
    }

    (all_adj, non_intersective, subsective, gradable, event_modifier)
}

fn derive_noun_lists(
    nouns: &[NounDefinition],
) -> (Vec<String>, Vec<String>, Vec<String>, Vec<String>, Vec<String>) {
    let mut common_nouns = Vec::new();
    let mut male_names = Vec::new();
    let mut female_names = Vec::new();
    let mut male_nouns = Vec::new();
    let mut female_nouns = Vec::new();

    for noun in nouns {
        let lower = noun.lemma.to_lowercase();
        let is_proper = noun.features.iter().any(|f| f == "Proper");
        let is_masculine = noun.features.iter().any(|f| f == "Masculine");
        let is_feminine = noun.features.iter().any(|f| f == "Feminine");

        if is_proper {
            if is_masculine {
                male_names.push(lower.clone());
            }
            if is_feminine {
                female_names.push(lower.clone());
            }
        } else {
            common_nouns.push(lower.clone());
            if is_masculine {
                male_nouns.push(lower.clone());
            }
            if is_feminine {
                female_nouns.push(lower.clone());
            }
        }
    }

    (common_nouns, male_names, female_names, male_nouns, female_nouns)
}

fn derive_irregular_plurals(nouns: &[NounDefinition]) -> HashMap<String, String> {
    let mut plurals = HashMap::new();
    for noun in nouns {
        if let Some(forms) = &noun.forms {
            if let Some(plural) = &forms.plural {
                plurals.insert(plural.to_lowercase(), noun.lemma.clone());
            }
        }
    }
    plurals
}

// ═══════════════════════════════════════════════════════════════════
// Code Generation Functions
// ═══════════════════════════════════════════════════════════════════

fn generate_lookup_keyword(file: &mut fs::File, keywords: &HashMap<String, String>) {
    writeln!(
        file,
        "pub fn lookup_keyword(s: &str) -> Option<crate::token::TokenType> {{"
    )
    .unwrap();
    writeln!(file, "    match s.to_lowercase().as_str() {{").unwrap();

    for (word, token_type) in keywords {
        let token_expr = match token_type.as_str() {
            "All" => "crate::token::TokenType::All",
            "No" => "crate::token::TokenType::No",
            "Some" => "crate::token::TokenType::Some",
            "Any" => "crate::token::TokenType::Any",
            "Both" => "crate::token::TokenType::Both",
            "Most" => "crate::token::TokenType::Most",
            "Few" => "crate::token::TokenType::Few",
            "Many" => "crate::token::TokenType::Many",
            "And" => "crate::token::TokenType::And",
            "Or" => "crate::token::TokenType::Or",
            "If" => "crate::token::TokenType::If",
            "Then" => "crate::token::TokenType::Then",
            "Not" => "crate::token::TokenType::Not",
            "Is" => "crate::token::TokenType::Is",
            "Are" => "crate::token::TokenType::Are",
            "Was" => "crate::token::TokenType::Was",
            "Were" => "crate::token::TokenType::Were",
            "That" => "crate::token::TokenType::That",
            "Who" => "crate::token::TokenType::Who",
            "What" => "crate::token::TokenType::What",
            "Where" => "crate::token::TokenType::Where",
            "When" => "crate::token::TokenType::When",
            "Why" => "crate::token::TokenType::Why",
            "Does" => "crate::token::TokenType::Does",
            "Do" => "crate::token::TokenType::Do",
            "Must" => "crate::token::TokenType::Must",
            "Shall" => "crate::token::TokenType::Shall",
            "Should" => "crate::token::TokenType::Should",
            "Can" => "crate::token::TokenType::Can",
            "May" => "crate::token::TokenType::May",
            "Cannot" => "crate::token::TokenType::Cannot",
            "Would" => "crate::token::TokenType::Would",
            "Could" => "crate::token::TokenType::Could",
            "Might" => "crate::token::TokenType::Might",
            "Had" => "crate::token::TokenType::Had",
            "Than" => "crate::token::TokenType::Than",
            "Reflexive" => "crate::token::TokenType::Reflexive",
            "Because" => "crate::token::TokenType::Because",
            "Anything" => "crate::token::TokenType::Anything",
            "Anyone" => "crate::token::TokenType::Anyone",
            "Nothing" => "crate::token::TokenType::Nothing",
            "Nobody" => "crate::token::TokenType::Nobody",
            "Nowhere" => "crate::token::TokenType::Nowhere",
            "Ever" => "crate::token::TokenType::Ever",
            "Never" => "crate::token::TokenType::Never",
            "Repeat" => "crate::token::TokenType::Repeat",
            "For" => "crate::token::TokenType::For",
            "In" => "crate::token::TokenType::In",
            "From" => "crate::token::TokenType::From",
            "Respectively" => "crate::token::TokenType::Respectively",
            _ => continue,
        };
        writeln!(file, "        \"{}\" => Some({}),", word, token_expr).unwrap();
    }

    writeln!(file, "        _ => None,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}\n").unwrap();
}

fn format_pronoun_token(p: &PronounEntry) -> String {
    let gender = match p.gender.as_str() {
        "Male" => "crate::context::Gender::Male",
        "Female" => "crate::context::Gender::Female",
        "Neuter" => "crate::context::Gender::Neuter",
        _ => "crate::context::Gender::Unknown",
    };
    let number = match p.number.as_str() {
        "Singular" => "crate::context::Number::Singular",
        _ => "crate::context::Number::Plural",
    };
    let case = match p.case.as_str() {
        "Subject" => "crate::context::Case::Subject",
        "Possessive" => "crate::context::Case::Possessive",
        _ => "crate::context::Case::Object",
    };
    format!(
        "crate::token::TokenType::Pronoun {{ gender: {}, number: {}, case: {} }}",
        gender, number, case
    )
}

fn generate_lookup_pronoun(file: &mut fs::File, pronouns: &[PronounEntry]) {
    use std::collections::BTreeMap;

    writeln!(
        file,
        "pub fn lookup_pronoun(s: &str) -> Option<crate::token::TokenType> {{"
    )
    .unwrap();
    writeln!(file, "    match s.to_lowercase().as_str() {{").unwrap();

    let mut map: BTreeMap<String, Vec<&PronounEntry>> = BTreeMap::new();
    for p in pronouns {
        map.entry(p.word.to_lowercase()).or_default().push(p);
    }

    for (word, entries) in map {
        if entries.len() == 1 {
            let code = format_pronoun_token(entries[0]);
            writeln!(file, "        \"{}\" => Some({}),", word, code).unwrap();
        } else {
            let primary_code = format_pronoun_token(entries[0]);
            let mut alt_codes = Vec::new();
            for p in &entries[1..] {
                alt_codes.push(format_pronoun_token(p));
            }
            let alts_str = alt_codes.join(", ");

            writeln!(
                file,
                "        \"{}\" => Some(crate::token::TokenType::Ambiguous {{ primary: Box::new({}), alternatives: vec![{}] }}),",
                word, primary_code, alts_str
            ).unwrap();
        }
    }

    writeln!(file, "        _ => None,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}\n").unwrap();
}

fn generate_lookup_article(file: &mut fs::File, articles: &HashMap<String, String>) {
    writeln!(
        file,
        "pub fn lookup_article(s: &str) -> Option<crate::lexicon::Definiteness> {{"
    )
    .unwrap();
    writeln!(file, "    match s.to_lowercase().as_str() {{").unwrap();

    for (word, def) in articles {
        let def_expr = match def.as_str() {
            "Definite" => "crate::lexicon::Definiteness::Definite",
            "Proximal" => "crate::lexicon::Definiteness::Proximal",
            "Distal" => "crate::lexicon::Definiteness::Distal",
            _ => "crate::lexicon::Definiteness::Indefinite",
        };
        writeln!(file, "        \"{}\" => Some({}),", word, def_expr).unwrap();
    }

    writeln!(file, "        _ => None,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}\n").unwrap();
}

fn generate_lookup_auxiliary(file: &mut fs::File, auxiliaries: &HashMap<String, String>) {
    writeln!(
        file,
        "pub fn lookup_auxiliary(s: &str) -> Option<crate::lexicon::Time> {{"
    )
    .unwrap();
    writeln!(file, "    match s.to_lowercase().as_str() {{").unwrap();

    for (word, time) in auxiliaries {
        let time_expr = match time.as_str() {
            "Future" => "crate::lexicon::Time::Future",
            "Past" => "crate::lexicon::Time::Past",
            "Present" => "crate::lexicon::Time::Present",
            _ => "crate::lexicon::Time::None",
        };
        writeln!(file, "        \"{}\" => Some({}),", word, time_expr).unwrap();
    }

    writeln!(file, "        _ => None,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}\n").unwrap();
}

fn generate_lookup_irregular_verb(file: &mut fs::File, verbs: &[IrregularVerbEntry]) {
    use std::collections::BTreeMap;

    writeln!(
        file,
        "pub fn lookup_irregular_verb(s: &str) -> Option<crate::lexicon::VerbEntry> {{"
    )
    .unwrap();
    writeln!(file, "    match s.to_lowercase().as_str() {{").unwrap();

    let mut seen: BTreeMap<String, &IrregularVerbEntry> = BTreeMap::new();
    for v in verbs {
        seen.entry(v.word.to_lowercase()).or_insert(v);
    }

    for (word, v) in seen {
        let time_expr = match v.time.as_str() {
            "Past" => "crate::lexicon::Time::Past",
            "Present" => "crate::lexicon::Time::Present",
            "Future" => "crate::lexicon::Time::Future",
            _ => "crate::lexicon::Time::None",
        };
        let aspect_expr = match v.aspect.as_str() {
            "Progressive" => "crate::lexicon::Aspect::Progressive",
            "Perfect" => "crate::lexicon::Aspect::Perfect",
            _ => "crate::lexicon::Aspect::Simple",
        };
        let class_expr = match v.class.as_str() {
            "State" => "crate::lexicon::VerbClass::State",
            "Activity" => "crate::lexicon::VerbClass::Activity",
            "Accomplishment" => "crate::lexicon::VerbClass::Accomplishment",
            "Achievement" => "crate::lexicon::VerbClass::Achievement",
            "Semelfactive" => "crate::lexicon::VerbClass::Semelfactive",
            _ => "crate::lexicon::VerbClass::Activity",
        };

        writeln!(
            file,
            "        \"{}\" => Some(crate::lexicon::VerbEntry {{ lemma: \"{}\".to_string(), time: {}, aspect: {}, class: {} }}),",
            word, v.lemma, time_expr, aspect_expr, class_expr
        )
        .unwrap();
    }

    writeln!(file, "        _ => None,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}\n").unwrap();
}

fn generate_lookup_presup_trigger(file: &mut fs::File, triggers: &HashMap<String, String>) {
    writeln!(
        file,
        "pub fn lookup_presup_trigger(s: &str) -> Option<crate::token::PresupKind> {{"
    )
    .unwrap();
    writeln!(file, "    match s.to_lowercase().as_str() {{").unwrap();

    for (word, kind) in triggers {
        let kind_expr = match kind.as_str() {
            "Stop" => "crate::token::PresupKind::Stop",
            "Start" => "crate::token::PresupKind::Start",
            "Regret" => "crate::token::PresupKind::Regret",
            "Continue" => "crate::token::PresupKind::Continue",
            "Realize" => "crate::token::PresupKind::Realize",
            "Know" => "crate::token::PresupKind::Know",
            _ => continue,
        };
        writeln!(file, "        \"{}\" => Some({}),", word, kind_expr).unwrap();
    }

    writeln!(file, "        _ => None,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}\n").unwrap();
}

fn generate_singularize(file: &mut fs::File, plurals: &HashMap<String, String>) {
    writeln!(
        file,
        "pub fn singularize(s: &str) -> Option<&'static str> {{"
    )
    .unwrap();
    writeln!(file, "    match s.to_lowercase().as_str() {{").unwrap();

    for (plural, singular) in plurals {
        writeln!(file, "        \"{}\" => Some(\"{}\"),", plural, singular).unwrap();
    }

    writeln!(file, "        _ => None,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}\n").unwrap();
}

fn generate_word_to_number(file: &mut fs::File, numbers: &HashMap<String, u32>) {
    writeln!(
        file,
        "pub fn word_to_number(s: &str) -> Option<u32> {{"
    )
    .unwrap();
    writeln!(file, "    match s.to_lowercase().as_str() {{").unwrap();

    for (word, num) in numbers {
        writeln!(file, "        \"{}\" => Some({}),", word, num).unwrap();
    }

    writeln!(file, "        _ => None,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}\n").unwrap();
}

fn generate_is_check(file: &mut fs::File, fn_name: &str, words: &[String]) {
    use std::collections::BTreeSet;

    writeln!(file, "pub fn {}(s: &str) -> bool {{", fn_name).unwrap();
    writeln!(file, "    match s.to_lowercase().as_str() {{").unwrap();

    let unique_words: BTreeSet<String> = words.iter().map(|w| w.to_lowercase()).collect();
    for word in unique_words {
        writeln!(file, "        \"{}\" => true,", word).unwrap();
    }

    writeln!(file, "        _ => false,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}\n").unwrap();
}

fn generate_lookup_verb_class(
    file: &mut fs::File,
    state_verbs: &[String],
    activity_verbs: &[String],
    accomplishment_verbs: &[String],
    achievement_verbs: &[String],
    semelfactive_verbs: &[String],
) {
    use std::collections::BTreeMap;

    writeln!(
        file,
        "pub fn lookup_verb_class(lemma: &str) -> crate::lexicon::VerbClass {{"
    )
    .unwrap();
    writeln!(file, "    match lemma.to_lowercase().as_str() {{").unwrap();

    let mut verb_classes: BTreeMap<String, &str> = BTreeMap::new();
    for verb in state_verbs {
        verb_classes.insert(verb.to_lowercase(), "State");
    }
    for verb in activity_verbs {
        verb_classes.entry(verb.to_lowercase()).or_insert("Activity");
    }
    for verb in accomplishment_verbs {
        verb_classes.entry(verb.to_lowercase()).or_insert("Accomplishment");
    }
    for verb in achievement_verbs {
        verb_classes.entry(verb.to_lowercase()).or_insert("Achievement");
    }
    for verb in semelfactive_verbs {
        verb_classes.entry(verb.to_lowercase()).or_insert("Semelfactive");
    }

    for (verb, class) in verb_classes {
        let class_expr = match class {
            "State" => "crate::lexicon::VerbClass::State",
            "Activity" => "crate::lexicon::VerbClass::Activity",
            "Accomplishment" => "crate::lexicon::VerbClass::Accomplishment",
            "Achievement" => "crate::lexicon::VerbClass::Achievement",
            "Semelfactive" => "crate::lexicon::VerbClass::Semelfactive",
            _ => "crate::lexicon::VerbClass::Activity",
        };
        writeln!(file, "        \"{}\" => {},", verb, class_expr).unwrap();
    }

    writeln!(file, "        _ => crate::lexicon::VerbClass::Activity,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}\n").unwrap();
}

// ═══════════════════════════════════════════════════════════════════
// Feature-Based Database Generation
// ═══════════════════════════════════════════════════════════════════

fn expand_verbs_to_db_entries(verbs: &[VerbDefinition]) -> Vec<VerbDbEntry> {
    let mut entries = Vec::new();

    for verb in verbs {
        let lemma = &verb.lemma;
        let class = &verb.class;
        let features = verb.features.clone();
        let lower_lemma = lemma.to_lowercase();

        // Base form (present)
        entries.push(VerbDbEntry {
            word: lower_lemma.clone(),
            lemma: lemma.clone(),
            time: "Present".to_string(),
            aspect: "Simple".to_string(),
            class: class.clone(),
            features: features.clone(),
        });

        if let Some(forms) = &verb.forms {
            if let Some(present3s) = &forms.present3s {
                entries.push(VerbDbEntry {
                    word: present3s.to_lowercase(),
                    lemma: lemma.clone(),
                    time: "Present".to_string(),
                    aspect: "Simple".to_string(),
                    class: class.clone(),
                    features: features.clone(),
                });
            }

            if let Some(past) = &forms.past {
                entries.push(VerbDbEntry {
                    word: past.to_lowercase(),
                    lemma: lemma.clone(),
                    time: "Past".to_string(),
                    aspect: "Simple".to_string(),
                    class: class.clone(),
                    features: features.clone(),
                });
            }

            if let Some(participle) = &forms.participle {
                entries.push(VerbDbEntry {
                    word: participle.to_lowercase(),
                    lemma: lemma.clone(),
                    time: "Past".to_string(),
                    aspect: "Simple".to_string(),
                    class: class.clone(),
                    features: features.clone(),
                });
            }

            if let Some(gerund) = &forms.gerund {
                entries.push(VerbDbEntry {
                    word: gerund.to_lowercase(),
                    lemma: lemma.clone(),
                    time: "None".to_string(),
                    aspect: "Progressive".to_string(),
                    class: class.clone(),
                    features: features.clone(),
                });
            }
        }
    }

    entries
}

fn expand_nouns_to_db_entries(nouns: &[NounDefinition]) -> Vec<NounDbEntry> {
    let mut entries = Vec::new();

    for noun in nouns {
        let lemma = &noun.lemma;
        let features = noun.features.clone();
        let lower_lemma = lemma.to_lowercase();

        // Singular form
        entries.push(NounDbEntry {
            word: lower_lemma.clone(),
            lemma: lemma.clone(),
            number: "Singular".to_string(),
            features: features.clone(),
        });

        // Plural form
        if let Some(forms) = &noun.forms {
            if let Some(plural) = &forms.plural {
                entries.push(NounDbEntry {
                    word: plural.to_lowercase(),
                    lemma: lemma.clone(),
                    number: "Plural".to_string(),
                    features: features.clone(),
                });
            }
        }
    }

    entries
}

fn expand_adjectives_to_db_entries(adjectives: &[AdjectiveDefinition]) -> Vec<AdjectiveDbEntry> {
    let mut entries = Vec::new();

    for adj in adjectives {
        let lemma = &adj.lemma;
        let features = adj.features.clone();
        let lower_lemma = lemma.to_lowercase();

        entries.push(AdjectiveDbEntry {
            word: lower_lemma,
            lemma: lemma.clone(),
            features,
        });
    }

    entries
}

fn format_features(features: &[String]) -> String {
    if features.is_empty() {
        return "&[]".to_string();
    }
    let feature_strs: Vec<String> = features
        .iter()
        .map(|f| format!("crate::lexicon::Feature::{}", f))
        .collect();
    format!("&[{}]", feature_strs.join(", "))
}

fn generate_lookup_verb_db(file: &mut fs::File, entries: &[VerbDbEntry]) {
    use std::collections::BTreeMap;

    writeln!(
        file,
        "pub fn lookup_verb_db(word: &str) -> Option<crate::lexicon::VerbMetadata> {{"
    )
    .unwrap();
    writeln!(file, "    match word.to_lowercase().as_str() {{").unwrap();

    let mut seen: BTreeMap<String, &VerbDbEntry> = BTreeMap::new();
    for entry in entries {
        seen.entry(entry.word.to_lowercase()).or_insert(entry);
    }

    for (word, entry) in seen {
        let time_expr = match entry.time.as_str() {
            "Past" => "crate::lexicon::Time::Past",
            "Present" => "crate::lexicon::Time::Present",
            "Future" => "crate::lexicon::Time::Future",
            _ => "crate::lexicon::Time::None",
        };
        let aspect_expr = match entry.aspect.as_str() {
            "Progressive" => "crate::lexicon::Aspect::Progressive",
            "Perfect" => "crate::lexicon::Aspect::Perfect",
            _ => "crate::lexicon::Aspect::Simple",
        };
        let class_expr = match entry.class.as_str() {
            "State" => "crate::lexicon::VerbClass::State",
            "Activity" => "crate::lexicon::VerbClass::Activity",
            "Accomplishment" => "crate::lexicon::VerbClass::Accomplishment",
            "Achievement" => "crate::lexicon::VerbClass::Achievement",
            "Semelfactive" => "crate::lexicon::VerbClass::Semelfactive",
            _ => "crate::lexicon::VerbClass::Activity",
        };
        let features_expr = format_features(&entry.features);

        writeln!(
            file,
            "        \"{}\" => Some(crate::lexicon::VerbMetadata {{ lemma: \"{}\", class: {}, time: {}, aspect: {}, features: {} }}),",
            word, entry.lemma, class_expr, time_expr, aspect_expr, features_expr
        )
        .unwrap();
    }

    writeln!(file, "        _ => None,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}\n").unwrap();
}

fn generate_lookup_noun_db(file: &mut fs::File, entries: &[NounDbEntry]) {
    use std::collections::BTreeMap;

    writeln!(
        file,
        "pub fn lookup_noun_db(word: &str) -> Option<crate::lexicon::NounMetadata> {{"
    )
    .unwrap();
    writeln!(file, "    match word.to_lowercase().as_str() {{").unwrap();

    let mut seen: BTreeMap<String, &NounDbEntry> = BTreeMap::new();
    for entry in entries {
        seen.entry(entry.word.to_lowercase()).or_insert(entry);
    }

    for (word, entry) in seen {
        let number_expr = match entry.number.as_str() {
            "Plural" => "crate::lexicon::Number::Plural",
            _ => "crate::lexicon::Number::Singular",
        };
        let features_expr = format_features(&entry.features);

        writeln!(
            file,
            "        \"{}\" => Some(crate::lexicon::NounMetadata {{ lemma: \"{}\", number: {}, features: {} }}),",
            word, entry.lemma, number_expr, features_expr
        )
        .unwrap();
    }

    writeln!(file, "        _ => None,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}\n").unwrap();
}

fn generate_lookup_adjective_db(file: &mut fs::File, entries: &[AdjectiveDbEntry]) {
    use std::collections::BTreeMap;

    writeln!(
        file,
        "pub fn lookup_adjective_db(word: &str) -> Option<crate::lexicon::AdjectiveMetadata> {{"
    )
    .unwrap();
    writeln!(file, "    match word.to_lowercase().as_str() {{").unwrap();

    let mut seen: BTreeMap<String, &AdjectiveDbEntry> = BTreeMap::new();
    for entry in entries {
        seen.entry(entry.word.to_lowercase()).or_insert(entry);
    }

    for (word, entry) in seen {
        let features_expr = format_features(&entry.features);

        writeln!(
            file,
            "        \"{}\" => Some(crate::lexicon::AdjectiveMetadata {{ lemma: \"{}\", features: {} }}),",
            word, entry.lemma, features_expr
        )
        .unwrap();
    }

    writeln!(file, "        _ => None,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}\n").unwrap();
}

fn generate_lookup_unit_dimension(file: &mut fs::File, units: &HashMap<String, String>) {
    writeln!(
        file,
        "pub fn lookup_unit_dimension(word: &str) -> Option<crate::ast::Dimension> {{"
    )
    .unwrap();
    writeln!(file, "    match word.to_lowercase().as_str() {{").unwrap();

    for (word, dimension) in units {
        let dim_expr = match dimension.as_str() {
            "Length" => "crate::ast::Dimension::Length",
            "Time" => "crate::ast::Dimension::Time",
            "Weight" => "crate::ast::Dimension::Weight",
            "Temperature" => "crate::ast::Dimension::Temperature",
            "Cardinality" => "crate::ast::Dimension::Cardinality",
            _ => continue,
        };
        writeln!(file, "        \"{}\" => Some({}),", word, dim_expr).unwrap();
    }

    writeln!(file, "        _ => None,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}\n").unwrap();
}

fn generate_lookup_phrasal_verb(file: &mut fs::File, phrasal_verbs: &HashMap<String, PhrasalVerbEntry>) {
    writeln!(
        file,
        "pub fn lookup_phrasal_verb(verb: &str, particle: &str) -> Option<(&'static str, crate::lexicon::VerbClass)> {{"
    )
    .unwrap();
    writeln!(file, "    let key = format!(\"{{}}_{{}}\", verb.to_lowercase(), particle.to_lowercase());").unwrap();
    writeln!(file, "    match key.as_str() {{").unwrap();

    for (key, entry) in phrasal_verbs {
        let class_expr = match entry.class.as_str() {
            "State" => "crate::lexicon::VerbClass::State",
            "Activity" => "crate::lexicon::VerbClass::Activity",
            "Accomplishment" => "crate::lexicon::VerbClass::Accomplishment",
            "Achievement" => "crate::lexicon::VerbClass::Achievement",
            "Semelfactive" => "crate::lexicon::VerbClass::Semelfactive",
            _ => "crate::lexicon::VerbClass::Activity",
        };
        writeln!(
            file,
            "        \"{}\" => Some((\"{}\", {})),",
            key, entry.lemma, class_expr
        )
        .unwrap();
    }

    writeln!(file, "        _ => None,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}\n").unwrap();
}

fn generate_lookup_agentive_noun(file: &mut fs::File, agentive_nouns: &HashMap<String, String>) {
    writeln!(
        file,
        "/// Lookup the base verb for an agentive noun (e.g., dancer -> Dance)"
    )
    .unwrap();
    writeln!(
        file,
        "pub fn lookup_agentive_noun(word: &str) -> Option<&'static str> {{"
    )
    .unwrap();
    writeln!(file, "    match word.to_lowercase().as_str() {{").unwrap();

    for (noun, verb) in agentive_nouns {
        writeln!(file, "        \"{}\" => Some(\"{}\"),", noun, verb).unwrap();
    }

    writeln!(file, "        _ => None,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}\n").unwrap();
}

fn generate_lookup_sort(file: &mut fs::File, nouns: &[NounDefinition]) {
    writeln!(
        file,
        "pub fn lookup_sort(word: &str) -> Option<crate::lexicon::Sort> {{"
    )
    .unwrap();
    writeln!(file, "    match word.to_lowercase().as_str() {{").unwrap();

    for noun in nouns {
        if let Some(sort) = &noun.sort {
            let sort_expr = match sort.as_str() {
                "Entity" => "crate::lexicon::Sort::Entity",
                "Physical" => "crate::lexicon::Sort::Physical",
                "Animate" => "crate::lexicon::Sort::Animate",
                "Human" => "crate::lexicon::Sort::Human",
                "Plant" => "crate::lexicon::Sort::Plant",
                "Place" => "crate::lexicon::Sort::Place",
                "Time" => "crate::lexicon::Sort::Time",
                "Abstract" => "crate::lexicon::Sort::Abstract",
                "Information" => "crate::lexicon::Sort::Information",
                "Event" => "crate::lexicon::Sort::Event",
                "Celestial" => "crate::lexicon::Sort::Celestial",
                "Value" => "crate::lexicon::Sort::Value",
                "Group" => "crate::lexicon::Sort::Group",
                _ => continue,
            };
            writeln!(
                file,
                "        \"{}\" => Some({}),",
                noun.lemma.to_lowercase(),
                sort_expr
            )
            .unwrap();
        }
    }

    writeln!(file, "        _ => None,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}\n").unwrap();
}

// ═══════════════════════════════════════════════════════════════════
// Multi-Word Expression (MWE) Generation
// ═══════════════════════════════════════════════════════════════════

fn generate_mwe_trie_init(file: &mut fs::File, mwes: &[MweEntry]) {
    writeln!(file, "/// Build the MWE trie from lexicon data.").unwrap();
    writeln!(file, "pub fn build_mwe_trie() -> MweTrie {{").unwrap();
    writeln!(file, "    let mut trie = MweTrie::default();").unwrap();

    for mwe in mwes {
        let pattern: Vec<String> = mwe
            .pattern
            .iter()
            .map(|s| format!("\"{}\"", s.to_lowercase()))
            .collect();
        let class_expr = match &mwe.class {
            Some(c) => format!("Some(crate::lexicon::VerbClass::{})", c),
            None => "None".to_string(),
        };
        writeln!(
            file,
            "    trie.insert(&[{}], MweTarget {{ lemma: \"{}\", pos: \"{}\", class: {} }});",
            pattern.join(", "),
            mwe.lemma,
            mwe.pos,
            class_expr
        )
        .unwrap();
    }

    writeln!(file, "    trie").unwrap();
    writeln!(file, "}}").unwrap();
}

fn generate_ontology_data(file: &mut fs::File, ontology: &Option<OntologyData>) {
    let default_ontology = OntologyData::default();
    let ontology = ontology.as_ref().unwrap_or(&default_ontology);

    // Build reverse mapping: part -> list of wholes
    let mut part_to_wholes: HashMap<String, Vec<String>> = HashMap::new();
    for entry in &ontology.part_whole {
        for part in &entry.parts {
            part_to_wholes
                .entry(part.to_lowercase())
                .or_default()
                .push(entry.whole.clone());
        }
    }

    // Generate get_possible_wholes function
    writeln!(file, "/// Get possible whole objects for a given part noun.").unwrap();
    writeln!(file, "pub fn get_possible_wholes(part: &str) -> &'static [&'static str] {{").unwrap();
    writeln!(file, "    match part {{").unwrap();
    for (part, wholes) in &part_to_wholes {
        let wholes_str: Vec<String> = wholes.iter().map(|w| format!("\"{}\"", w)).collect();
        writeln!(file, "        \"{}\" => &[{}],", part, wholes_str.join(", ")).unwrap();
    }
    writeln!(file, "        _ => &[],").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}").unwrap();
    writeln!(file).unwrap();

    // Generate get_predicate_sort function
    writeln!(file, "/// Get the required sort for a predicate (adjective or verb).").unwrap();
    writeln!(file, "pub fn get_predicate_sort(predicate: &str) -> Option<crate::lexicon::Sort> {{").unwrap();
    writeln!(file, "    match predicate {{").unwrap();
    for (predicate, sort) in &ontology.predicate_sorts {
        writeln!(file, "        \"{}\" => Some(crate::lexicon::Sort::{}),", predicate.to_lowercase(), sort).unwrap();
    }
    writeln!(file, "        _ => None,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}").unwrap();
}

// ═══════════════════════════════════════════════════════════════════
// Axiom (Meaning Postulate) Generation
// ═══════════════════════════════════════════════════════════════════

fn generate_axiom_data(file: &mut fs::File, axioms: &Option<AxiomData>) {
    let default_axioms = AxiomData::default();
    let axioms = axioms.as_ref().unwrap_or(&default_axioms);

    // Generate lookup_noun_entailments
    writeln!(file, "/// Get entailment predicates for a noun (e.g., bachelor -> [Unmarried, Male]).").unwrap();
    writeln!(file, "pub fn lookup_noun_entailments(noun: &str) -> &'static [&'static str] {{").unwrap();
    writeln!(file, "    match noun.to_lowercase().as_str() {{").unwrap();
    for (noun, axiom) in &axioms.nouns {
        if !axiom.entails.is_empty() {
            let entails_str: Vec<String> = axiom.entails.iter().map(|e| format!("\"{}\"", e)).collect();
            writeln!(file, "        \"{}\" => &[{}],", noun, entails_str.join(", ")).unwrap();
        }
    }
    writeln!(file, "        _ => &[],").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}").unwrap();
    writeln!(file).unwrap();

    // Generate lookup_noun_hypernyms
    writeln!(file, "/// Get hypernym predicates for a noun (e.g., dog -> [Animal, Mammal]).").unwrap();
    writeln!(file, "pub fn lookup_noun_hypernyms(noun: &str) -> &'static [&'static str] {{").unwrap();
    writeln!(file, "    match noun.to_lowercase().as_str() {{").unwrap();
    for (noun, axiom) in &axioms.nouns {
        if !axiom.hypernyms.is_empty() {
            let hypernyms_str: Vec<String> = axiom.hypernyms.iter().map(|h| format!("\"{}\"", h)).collect();
            writeln!(file, "        \"{}\" => &[{}],", noun, hypernyms_str.join(", ")).unwrap();
        }
    }
    writeln!(file, "        _ => &[],").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}").unwrap();
    writeln!(file).unwrap();

    // Generate is_privative_adjective
    writeln!(file, "/// Check if an adjective is privative (e.g., fake, counterfeit).").unwrap();
    writeln!(file, "pub fn is_privative_adjective(adj: &str) -> bool {{").unwrap();
    writeln!(file, "    match adj.to_lowercase().as_str() {{").unwrap();
    for (adj, axiom) in &axioms.adjectives {
        if axiom.axiom_type == "Privative" {
            writeln!(file, "        \"{}\" => true,", adj).unwrap();
        }
    }
    writeln!(file, "        _ => false,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}").unwrap();
    writeln!(file).unwrap();

    // Generate lookup_verb_entailment
    writeln!(file, "/// Get verb entailment (e.g., murder -> (Kill, [Intentional])).").unwrap();
    writeln!(file, "pub fn lookup_verb_entailment(verb: &str) -> Option<(&'static str, &'static [&'static str])> {{").unwrap();
    writeln!(file, "    match verb.to_lowercase().as_str() {{").unwrap();
    for (verb, axiom) in &axioms.verbs {
        if let Some(entails) = &axiom.entails {
            let manner_str: Vec<String> = axiom.manner.iter().map(|m| format!("\"{}\"", m)).collect();
            writeln!(file, "        \"{}\" => Some((\"{}\", &[{}])),", verb, entails, manner_str.join(", ")).unwrap();
        }
    }
    writeln!(file, "        _ => None,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}").unwrap();
}

// ═══════════════════════════════════════════════════════════════════
// Canonical Mapping Generation (Synonyms/Antonyms)
// ═══════════════════════════════════════════════════════════════════

fn generate_canonical_mapping(file: &mut fs::File, verbs: &[VerbDefinition]) {
    // Generate Polarity enum
    writeln!(file, "/// Polarity for canonical mapping (positive = synonym, negative = antonym).").unwrap();
    writeln!(file, "#[derive(Debug, Clone, Copy, PartialEq, Eq)]").unwrap();
    writeln!(file, "pub enum Polarity {{").unwrap();
    writeln!(file, "    Positive,").unwrap();
    writeln!(file, "    Negative,").unwrap();
    writeln!(file, "}}").unwrap();
    writeln!(file).unwrap();

    // Generate CanonicalMapping struct
    writeln!(file, "/// Maps a word to its canonical form with polarity.").unwrap();
    writeln!(file, "#[derive(Debug, Clone, Copy)]").unwrap();
    writeln!(file, "pub struct CanonicalMapping {{").unwrap();
    writeln!(file, "    pub lemma: &'static str,").unwrap();
    writeln!(file, "    pub polarity: Polarity,").unwrap();
    writeln!(file, "}}").unwrap();
    writeln!(file).unwrap();

    // Generate lookup_canonical function
    writeln!(file, "/// Look up canonical form for a word (synonym/antonym normalization).").unwrap();
    writeln!(file, "/// Returns the canonical lemma and polarity (Negative for antonyms).").unwrap();
    writeln!(file, "pub fn lookup_canonical(word: &str) -> Option<CanonicalMapping> {{").unwrap();
    writeln!(file, "    match word.to_lowercase().as_str() {{").unwrap();

    for verb in verbs {
        let lemma = &verb.lemma;

        // Map synonyms -> Positive polarity
        for syn in &verb.synonyms {
            writeln!(
                file,
                "        \"{}\" => Some(CanonicalMapping {{ lemma: \"{}\", polarity: Polarity::Positive }}),",
                syn.to_lowercase(),
                lemma
            ).unwrap();
        }

        // Map antonyms -> Negative polarity
        for ant in &verb.antonyms {
            writeln!(
                file,
                "        \"{}\" => Some(CanonicalMapping {{ lemma: \"{}\", polarity: Polarity::Negative }}),",
                ant.to_lowercase(),
                lemma
            ).unwrap();
        }
    }

    writeln!(file, "        _ => None,").unwrap();
    writeln!(file, "    }}").unwrap();
    writeln!(file, "}}").unwrap();
}

```

---


---

## Metadata

- **Generated:** Fri Jan  2 16:33:31 CST 2026
- **Repository:** /Users/tristen/logicaffeine/logicaffeine
- **Git Branch:** main
- **Git Commit:** 13c987f
- **Documentation Size:** 3.0M

---

**Note:** This documentation is auto-generated. Run `./generate-docs.sh` to regenerate after code changes.
